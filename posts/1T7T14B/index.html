<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"powerlzy.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="When gradient is small 一、Critical Point 1.1 Training Fails because 现在我们要讲的是Optimization的部分,所以我们要讲的东西基本上跟Overfitting没有什么太大的关联,我们只讨论Optimization的时候,怎么把gradient descent做得更好,那为什么Optimization会失败呢？  你常常在做Op">
<meta property="og:type" content="article">
<meta property="og:title" content="模型训练（6）Local Minimum And Saddle Point">
<meta property="og:url" content="https://powerlzy.github.io/posts/1T7T14B/index.html">
<meta property="og:site_name" content="PowerLZY&#39;s Blog">
<meta property="og:description" content="When gradient is small 一、Critical Point 1.1 Training Fails because 现在我们要讲的是Optimization的部分,所以我们要讲的东西基本上跟Overfitting没有什么太大的关联,我们只讨论Optimization的时候,怎么把gradient descent做得更好,那为什么Optimization会失败呢？  你常常在做Op">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220616161429257.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626143535169.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220616161554342.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626143850955.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626143927098.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626143956011.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626144155017.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626144347777.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626144425820.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626145009069.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626145041635.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626145125121.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626145206428.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626145319827.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626145640713.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626145734569.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626145742180.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626145756118.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626145931496.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626150135469.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220626150207285.png">
<meta property="og:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220616164405732.png">
<meta property="article:published_time" content="2022-06-09T03:34:59.000Z">
<meta property="article:modified_time" content="2022-07-13T15:19:27.945Z">
<meta property="article:author" content="lzy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://powerlzy.github.io/Library/Application%20Support/typora-user-images/image-20220616161429257.png">


<link rel="canonical" href="https://powerlzy.github.io/posts/1T7T14B/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://powerlzy.github.io/posts/1T7T14B/","path":"posts/1T7T14B/","title":"模型训练（6）Local Minimum And Saddle Point"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>模型训练（6）Local Minimum And Saddle Point | PowerLZY's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">PowerLZY's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">本博客主要用于记录个人学习笔记（测试阶段）</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-text">When gradient is small</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-text">一、Critical Point</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-text">1.1 Training Fails because</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-text">1.2 Warning of Math</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-text"> Tayler
Series Approximation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-text">Hession</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-text">判断 \(θ&#39;\)它是一个&#x3D;&#x3D;local
minima&#x3D;&#x3D;,还是一个&#x3D;&#x3D;saddle point&#x3D;&#x3D;。</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-text">1.3 Don&#39;t afraid of saddle
point</span></a></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-text">1.4 Saddle Point v.s. Local
Minima</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="lzy"
      src="/images/cat_mac.jpg">
  <p class="site-author-name" itemprop="name">lzy</p>
  <div class="site-description" itemprop="description">相比到达的地方，同行的人更重要！</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">255</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">52</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">47</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/PowerLZY" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;PowerLZY" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:3289218653@qq.com" title="E-Mail → mailto:3289218653@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/1T7T14B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="模型训练（6）Local Minimum And Saddle Point | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          模型训练（6）Local Minimum And Saddle Point
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-06-09 11:34:59" itemprop="dateCreated datePublished" datetime="2022-06-09T11:34:59+08:00">2022-06-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-07-13 23:19:27" itemprop="dateModified" datetime="2022-07-13T23:19:27+08:00">2022-07-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E3%80%90draft%E3%80%91%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">【draft】深度学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E3%80%90draft%E3%80%91%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7/" itemprop="url" rel="index"><span itemprop="name">训练技巧</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>10k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>19 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1><span id="when-gradient-is-small">When gradient is small</span></h1>
<h3><span id="一-critical-point">一、Critical Point</span></h3>
<h4><span id="11-training-fails-because">1.1 Training Fails because</span></h4>
<p>现在我们要讲的是Optimization的部分,所以我们要讲的东西基本上跟Overfitting没有什么太大的关联,我们只讨论Optimization的时候,怎么把gradient
descent做得更好,那为什么Optimization会失败呢？</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220616161429257.png" alt="image-20220616161429257" style="zoom:67%;"></p>
<p>你常常在做Optimization的时候,你会发现,<strong>随著你的参数不断的update,你的training的loss不会再下降</strong>,但是你对这个loss仍然不满意,就像我刚才说的,你可以把deep的network,跟linear的model,或比较shallow
network
比较,发现说它没有做得更好,所以你觉得deepnetwork,没有发挥它完整的力量,所以Optimization显然是有问题的。</p>
<p><strong>但有时候你会甚至发现,一开始你的model就train不起来,一开始你不管怎么update你的参数,你的loss通通都掉不下去,那这个时候到底发生了什么事情呢？</strong></p>
<p>过去常见的一个猜想,是因为我们现在走到了一个地方,<strong>这个地方参数对loss的微分为零</strong>,当你的参数对loss微分为零的时候,gradient
descent就没有办法再update参数了,这个时候training就停下来了,loss当然就不会再下降了。</p>
<p>讲到gradient为零的时候,大家通常脑海中最先浮现的,可能就是==<strong>local
minima</strong>==,所以常有人说做deep learning,用gradient
descent会卡在local minima,然后所以gradient descent不work,所以deep
learning不work。</p>
<p><strong>但是如果有一天你要写,跟deep
learning相关paper的时候,你千万不要讲卡在local
minima这种事情,别人会觉得你非常没有水准,为什么？</strong></p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626143535169.png" alt="image-20220626143535169"></p>
<p>因为<strong>不是只有local
minima的gradient是零</strong>,还有其他可能会让gradient是零,比如说
==<strong>saddle point</strong>==,所谓的saddle
point,其实就是gradient是零,但是不是local minima,也不是local
maxima的地方,像在右边这个例子里面
红色的这个点,它在左右这个方向是比较高的,前后这个方向是比较低的,它就像是一个马鞍的形状,所以叫做saddle
point,那中文就翻成<strong>鞍点</strong>。</p>
<p>像saddle point这种地方,它也是gradient为零,但它不是local
minima,那像这种gradient为零的点,统称为==critical
point==,所以<strong>你可以说你的loss,没有办法再下降,也许是因为卡在了critical
point,但你不能说是卡在local minima,因为saddle
point也是微分为零的点</strong></p>
<p>但是今天如果你发现你的gradient,真的很靠近零,卡在了某个critical
point,我们有没有办法知道,到底是local minima,还是saddle
point？其实是有办法的</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220616161554342.png" alt="image-20220616161554342" style="zoom:50%;"></p>
<p><strong>为什么我们想要知道到底是卡在local minima,还是卡在saddle
point呢</strong></p>
<ul>
<li>因为如果是<strong>卡在local
minima,那可能就没有路可以走了</strong>,因为四周都比较高,你现在所在的位置已经是最低的点,loss最低的点了,往四周走
loss都会比较高,你会不知道怎么走到其他的地方去</li>
<li>但saddle point就比较没有这个问题,如果你今天是<strong>卡在saddle
point的话,saddle
point旁边还是有路可以走的,</strong>还是有路可以让你的loss更低的,你只要逃离saddle
point,你就有可能让你的loss更低</li>
</ul>
<p><strong>所以鉴别今天我们走到,critical point的时候,到底是local
minima,还是saddle
point,是一个值得去探讨的问题,那怎么知道今天一个critical
point,到底是属于local minima,还是saddle point呢？</strong></p>
<h4><span id="12-warning-of-math">1.2 Warning of Math</span></h4>
<p>这边需要用到一点数学,以下这段其实没有很难的数学,就只是微积分跟线性代数,但如果你没有听懂的话,以下这段skip掉是没有关系的，那怎么知道说一个点,到底是local
minima,还是saddle point呢？</p>
<p>你要知道我们loss function的形状,可是我们怎么知道,loss
function的形状呢,network本身很复杂,用复杂network算出来的loss
function,显然也很复杂,我们怎么知道loss
function,长什么样子,虽然我们没有办法完整知道,整个loss function的样子</p>
<h4><span id="taylerseries-approximation"><strong><font color="red"> Tayler
Series Approximation</font></strong></span></h4>
<p>但是如果给定某一组参数,比如说蓝色的这个<span class="math inline">\(θ&#39;\)</span>,在<span class="math inline">\(θ&#39;\)</span>附近的loss
function,是有办法被写出来的,它写出来就像是这个样子：</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626143850955.png" alt="image-20220626143850955" style="zoom:67%;"></p>
<p>所以这个<span class="math inline">\(L(θ)\)</span>完整的样子写不出来,但是它在<span class="math inline">\(θ&#39;\)</span>附近,你可以用这个式子来表示它,这个式子是,Tayler
Series
Appoximation泰勒级数展开,这个假设你在微积分的时候,已经学过了,所以我就不会细讲这一串是怎么来的,但我们就只讲一下它的概念,这一串里面包含什么东西呢?</p>
<ul>
<li><p>第一项是<span class="math inline">\(L(θ&#39;)\)</span>,就告诉我们说,当<span class="math inline">\(θ\)</span>跟<span class="math inline">\(θ&#39;\)</span>很近的时候,<span class="math inline">\(L(θ)\)</span>应该跟<span class="math inline">\(L(θ&#39;)\)</span>还蛮靠近的</p></li>
<li><p>第二项是<span class="math inline">\((θ-θ&#39;)^Tg\)</span></p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626143927098.png" alt="image-20220626143927098" style="zoom:67%;"></p>
<p><strong><span class="math inline">\(g\)</span>是一个向量,这个g就是我们的gradient</strong>,我们用绿色的这个g来代表gradient,这个<strong>gradient会来弥补,<span class="math inline">\(θ&#39;\)</span>跟<span class="math inline">\(θ\)</span>之间的差距</strong>,我们虽然刚才说<span class="math inline">\(θ&#39;\)</span>跟<span class="math inline">\(θ\)</span>,它们应该很接近,但是中间还是有一些差距的,那这个差距,第一项我们用这个gradient,来表示他们之间的差距,有时候gradient会写成<span class="math inline">\(∇L(θ&#39;)\)</span>,这个地方的<span class="math inline">\(g\)</span>是一个向量,<strong>它的第i个component,就是θ的第i个component对L的微分</strong>,光是看g还是没有办法,完整的描述L(θ),你还要看第三项</p></li>
<li><p>第三项跟Hessian有关,这边有一个$H $</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626143956011.png" alt="image-20220626143956011" style="zoom:67%;"></p>
<p>这个<span class="math inline">\(H\)</span>叫做Hessian,它是一个矩阵,这个第三项是,再<span class="math inline">\((θ-θ&#39;)^TH(θ-θ&#39;)\)</span>,所以第三项会再补足,再加上gradient以后,与真正的L(θ)之间的差距.<strong>H里面放的是L的二次微分</strong>,<strong>它第i个row,第j个column的值,就是把θ的第i个component,对L作微分,再把θ的第j个component,对L作微分,再把θ的第i个component,对L作微分,做两次微分以后的结果</strong>
就是这个<span class="math inline">\(H_i{_j}\)</span></p></li>
</ul>
<p>如果这边你觉得有点听不太懂的话,也没有关系,反正你就记得这个<span class="math inline">\(L(θ)\)</span>,这个loss function,这个error
surface在<span class="math inline">\(θ&#39;\)</span>附近,可以写成这个样子,这个式子跟两个东西有关系,<strong>跟gradient有关系,跟hessian有关系,gradient就是一次微分,hessian就是里面有二次微分的项目</strong></p>
<h4><span id="hession">Hession</span></h4>
<p><strong>那如果我们今天走到了一个critical
point,意味著gradient为零,也就是绿色的这一项完全都不见了</strong></p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626144155017.png" alt="image-20220626144155017" style="zoom:50%;"></p>
<p><span class="math inline">\(g\)</span><strong>是一个zero
vector,绿色的这一项完全都不见了</strong>,只剩下红色的这一项,所以当在critical
point的时候,这个loss function,它可以被近似为<span class="math inline">\(L(θ&#39;)\)</span>,加上红色的这一项。我们可以<strong>根据红色的这一项来判断</strong>,在<span class="math inline">\(θ&#39;\)</span>附近的error
surface,到底长什么样子。知道error surface长什么样子,我就可以判断。</p>
<h4><span id="判断-θ39它是一个localminima还是一个saddle-point"><strong><font color="red">判断 <span class="math inline">\(θ&#39;\)</span>它是一个==local
minima==,还是一个==saddle point==</font>。</strong></span></h4>
<p>我们可以靠这一项来了解,这个error
surface的地貌,大概长什么样子,知道它地貌长什么样子,我们就可以知道说,现在是在什么样的状态,这个是Hessian。</p>
<p>那我们就来看一下怎么根据Hessian,怎么根据红色的这一项,来判断θ'附近的地貌。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626144347777.png" alt="image-20220626144347777" style="zoom:67%;"></p>
<p>我们现在为了等一下符号方便起见,我们<strong>把<span class="math inline">\((θ-θ&#39;)\)</span>用<span class="math inline">\(v\)</span>这个向量来表示</strong></p>
<ul>
<li>如果今天对任何可能的<span class="math inline">\(v\)</span><strong>,<span class="math inline">\(v^THv\)</span>都大于零</strong>,也就是说
现在θ不管代任何值,v可以是任何的v,也就是θ可以是任何值,不管θ代任何值,<strong>红色框框里面通通都大于零</strong>,那意味著说
<span class="math inline">\(L(θ)&gt;L(θ&#39;)\)</span>。<span class="math inline">\(L(θ)\)</span>不管代多少 只要在<span class="math inline">\(θ&#39;\)</span>附近,<span class="math inline">\(L(θ)\)</span>都大于<span class="math inline">\(L(θ&#39;)\)</span>,<strong>代表<span class="math inline">\(L(θ&#39;)\)</span>是附近的一个最低点,所以它是local
minima</strong></li>
<li>如果今天反过来说,对所有的<span class="math inline">\(v\)</span>而言,<strong><span class="math inline">\(v^THv\)</span>都小于零,也就是红色框框里面永远都小于零</strong>,也就是说<span class="math inline">\(θ\)</span>不管代什么值,红色框框里面都小于零,意味著说<span class="math inline">\(L(θ)&lt;L(θ&#39;)\)</span>,<strong>代表<span class="math inline">\(L(θ&#39;)\)</span>是附近最高的一个点,所以它是local
maxima</strong></li>
<li>第三个可能是假设,<strong><span class="math inline">\(v^THv\)</span>,有时候大于零
有时候小于零</strong>,你代不同的v进去
代不同的θ进去,红色这个框框里面有时候大于零,有时候小于零,意味著说在θ'附近,有时候L(θ)&gt;L(θ')
有时候L(θ)&lt;L(θ'),在L(θ')附近,有些地方高
有些地方低,这意味著什么,<strong>这意味著这是一个saddle
point</strong></li>
</ul>
<p>但是你这边是说我们要代所有的<span class="math inline">\(v\)</span>,去看<span class="math inline">\(v^THv\)</span>是大于零,还是小于零.我们怎么有可能把所有的v,都拿来试试看呢,所以有一个更简便的方法,去确认说这一个条件或这一个条件,会不会发生.</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626144425820.png" alt="image-20220626144425820" style="zoom:67%;"></p>
<p><strong><font color="red">
这个就直接告诉你结论,线性代数理论上是有教过这件事情的,如果今天对所有的v而言,<span class="math inline">\(v^THv\)</span>都大于零,那这种矩阵叫做positive
definite 正定矩阵,positive definite的矩阵,它所有的eigen
value特征值都是正的</font></strong></p>
<p>所以如果你今天算出一个hessian,你不需要把它跟所有的v都乘看看,你只要去直接看这个H的eigen
value,如果你发现：</p>
<ul>
<li><strong>所有eigen
value都是正的</strong>,那就代表说这个条件成立,就<span class="math inline">\(v^THv\)</span>,会大于零,也就代表说是一个local
minima。所以你从hessian metric可以看出,它是不是local
minima,你只要算出hessian metric算完以后,看它的eigen
value发现都是正的,它就是local minima。</li>
<li>那反过来说也是一样,如果今天在这个状况,对所有的v而言,<span class="math inline">\(v^THv\)</span>小于零,那H是negative
definite,那就代表所有<strong>eigen
value都是负的</strong>,就保证他是local maxima</li>
<li><strong>那如果eigen value有正有负</strong>,那就代表是saddle
point,</li>
</ul>
<p>那假设在这里你没有听得很懂的话,你就可以记得结论,<strong>你只要算出一个东西,这个东西的名字叫做hessian,它是一个矩阵,这个矩阵如果它所有的eigen
value,都是正的,那就代表我们现在在local
minima,如果它有正有负,就代表在saddle point。</strong></p>
<p>那如果刚才讲的,你觉得你没有听得很懂的话,我们这边举一个例子：</p>
<figure>
<img src="../../../../../../Library/Application%20Support/typora-user-images/image-20220626145009069.png" alt="image-20220626145009069">
<figcaption aria-hidden="true">image-20220626145009069</figcaption>
</figure>
<p>我们现在有一个史上最废的network,输入一个x,它只有一个neuron，乘上<span class="math inline">\(w₁\)</span>,而且这个neuron,还没有activation
function,所以x乘上<span class="math inline">\(w₁\)</span>以后
之后就输出,然后再乘上<span class="math inline">\(w₂\)</span>
然后就再输出,就得到最终的数据就是y.总之这个function非常的简单 <span class="math display">\[
y= w₁×w₂×x
\]</span> 我们有一个史上最废的training set,这个data
set说,我们只有一笔data,这笔data是x,是1的时候,它的level是1
所以输入1进去,你希望最终的输出跟1越接近越好</p>
<p>而这个史上最废的training,它的error
surface,也是有办法直接画出来的,因为反正只有两个参数 w₁
w₂,连bias都没有,假设没有bias,只有w₁跟w₂两个参数,这个network只有两个参数
w₁跟w₂,那我们可以穷举所有w₁跟w₂的数值,算出所有w₁
w₂数值所代来的loss,然后就画出error surface 长这个样</p>
<figure>
<img src="../../../../../../Library/Application%20Support/typora-user-images/image-20220626145041635.png" alt="image-20220626145041635">
<figcaption aria-hidden="true">image-20220626145041635</figcaption>
</figure>
<p>四个角落loss是高的,好 那这个图上你可以看出来说,有一些critical
point,这个黑点点的地方(0,0),<strong>原点的地方是critical
point</strong>,然后事实上,<strong>右上三个黑点也是一排critical
point,左下三个点也是一排critical
point</strong>。如果你更进一步要分析,他们是saddle point,还是local
minima的话,那圆心这个地方,<strong>原点这个地方 它是saddle
point</strong>,为什么它是saddle point呢？你往左上这个方向走
loss会变大,往右下这个方向走 loss会变大,往左下这个方向走
loss会变小,往右下这个方向走 loss会变小,它是一个saddle point。</p>
<p>而这两群critical point,它们都是local
minima,所以这个山沟里面,有一排local minima,这一排山沟里面有一排local
minima,然后在原点的地方,有一个saddle point,这个是我们把error
surface,暴力所有的参数,得到的loss
function以后,得到的loss的值以后,画出error
surface,可以得到这样的结论。</p>
<p>现在假设如果不暴力所有可能的loss,如果要直接算说一个点,是local
minima,还是saddle point的话 怎么算呢</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626145125121.png" alt="image-20220626145125121" style="zoom: 67%;"></p>
<p>我们可以把loss的function写出来,这个loss的function 这个L是 <span class="math display">\[
L=(\hat{y}-w_1 w_2 x)^2
\]</span> 正确答案 ŷ减掉model的输出,也就是w₁ w₂x,这边取square
error,这边<strong>只有一笔data,所以就不会summation over所有的training
data</strong>,因为反正只有一笔data,x代1
ŷ代1,我刚才说过只有一笔训练资料最废的,所以只有一笔训练资料,所以loss
function就是<span class="math inline">\(L=(\hat{y}-w_1 w_2
x)^2\)</span>,那你可以把这一个loss
function,它的gradient求出来,w₁对L的微分,w₂对L的微分写出来是这个样子
<span class="math display">\[
\frac{∂L}{∂w_1 }=2(1-w_1 w_2 )(-w_2 )
\]</span></p>
<p><span class="math display">\[
\frac{∂L}{∂w_2 }=2(1-w_1 w_2 )(-w_1 )
\]</span></p>
<p>​ 这个东西 <span class="math display">\[
\begin{bmatrix}
\frac{∂L}{∂w_1 }\\\
\frac{∂L}{∂w_2 }
\end{bmatrix}
\]</span>
就是所谓的g,所谓的gradient,什么时候gradient会零呢,什么时候会到一个critical
point呢?</p>
<p>举例来说 如果w₁=0 w₂=0,就在圆心这个地方,如果w₁代0 w₂代0,w₁对L的微分
w₂对L的微分,算出来就都是零
就都是零,这个时候我们就知道说,原点就是一个critical
point,但<strong>它是local maxima,它是local maxima,local
minima,还是saddle point呢,那你就要看hessian才能够知道了</strong></p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626145206428.png" alt="image-20220626145206428" style="zoom:67%;"></p>
<p>当然 我们刚才已经暴力所有可能的w₁
w₂了,所以你已经知道说,它显然是一个saddle
point,但是现在假设还没有暴力所有可能的loss,所以我们要看看能不能够用H,用Hessian看出它是什么样的critical
point,那怎么算出这个H呢？</p>
<p><strong>H它是一个矩阵,这个矩阵里面元素就是L的二次微分</strong>,所以这个矩阵里面第一个row,第一个coloumn的位置,就是w₁对L微分两次,第一个row
第二个coloumn的位置,就是先用w₂对L作微分,再用w₁对L作微分,然后这边就是w₁对L作微分,w₂对L作微分,然后w₂对L微分两次,这四个值组合起来,就是我们的hessian,那这个hessian的值是多少呢</p>
<p>这个hessian的式子,我都已经把它写出来了,你只要把w₁=0 w₂=0代进去,代进去
你就得到在原点的地方,hessian是这样的一个矩阵 <span class="math display">\[
\begin{bmatrix}
{0}&amp;-2\\\
{-2}&amp;0
\end{bmatrix}
\]</span> 这个hessian告诉我们,它是local minima,还是saddle
point呢,那你就要看这个矩阵的eigen value,算一下发现,这个矩阵有两个eigen
value,2跟-2 <strong>eigen value有正有负,代表saddle point</strong></p>
<p>所以我们现在就是用一个例子,跟你操作一下
告诉你说,你怎么从hessian看出一个点,它一个critical point 它是saddle
point,还是local minima</p>
<h3><span id="13-dont-afraid-of-saddlepoint">1.3 Don't afraid of saddle
point</span></h3>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626145319827.png" alt="image-20220626145319827" style="zoom:67%;"></p>
<p>如果今天你卡的地方是saddle
point,也许你就不用那么害怕了,因为如果你今天你发现,你停下来的时候,是因为saddle
point 停下来了,那其实就有机会可以放心了。</p>
<p>因为H它不只可以帮助我们判断,现在是不是在一个saddle
point,它还指出了我们参数,可以update的方向,就之前我们参数update的时候,都是看gradient
看g,但是我们走到某个地方以后,发现g变成0了 不能再看g了,g不见了
gradient没有了<strong>,但如果是一个saddle
point的话,还可以再看H,怎么再看H呢,H怎么告诉我们,怎么update参数呢</strong></p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626145640713.png" alt="image-20220626145640713" style="zoom:67%;"></p>
<p>我们这边假设<span class="math inline">\(\mu\)</span>是H的eigenvector特征向量,然后<span class="math inline">\(λ\)</span>是u的eigen
value特征值。如果我们把这边的<span class="math inline">\(v\)</span>换成<span class="math inline">\(\mu\)</span>的话,我们把<span class="math inline">\(\mu\)</span>乘在H的左边,跟H的右边,也就是<span class="math inline">\(\mu^TH\mu\)</span>, <span class="math inline">\(H\mu\)</span>会得到<span class="math inline">\(λ\mu\)</span>，因为<span class="math inline">\(\mu\)</span>是一个eigen vector。H乘上eigen
vector特征向量会得到特征向量λ eigen value乘上eigen vector即<span class="math inline">\(λ\mu\)</span></p>
<figure>
<img src="../../../../../../Library/Application%20Support/typora-user-images/image-20220626145734569.png" alt="image-20220626145734569">
<figcaption aria-hidden="true">image-20220626145734569</figcaption>
</figure>
<p>所以我们在这边得到uᵀ乘上λu,然后再整理一下,把uᵀ跟u乘起来,得到‖u‖²,所以得到λ‖u‖²</p>
<figure>
<img src="../../../../../../Library/Application%20Support/typora-user-images/image-20220626145742180.png" alt="image-20220626145742180">
<figcaption aria-hidden="true">image-20220626145742180</figcaption>
</figure>
<p>假设我们这边v,代的是一个eigen vector,我们这边θ减θ',放的是一个eigen
vector的话,会发现说我们这个红色的项里面,其实就是λ‖u‖²</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626145756118.png" alt="image-20220626145756118" style="zoom:67%;"></p>
<p>那今天如果λ<strong>小于零</strong>,eigen
value小于零的话,那λ‖u‖²就会小于零,因为‖u‖²一定是正的,所以eigen
value是负的,那这一整项就会是<strong>负的</strong>,也就是u的transpose乘上H乘上u,它是负的,也就是<strong>红色这个框里是负的</strong>。所以这意思是说假设<span class="math inline">\(θ-θ&#39;=\mu\)</span>,那这一项<span class="math inline">\((θ-θ&#39;)^TH(θ-θ&#39;)\)</span>就是负的,也就是<span class="math inline">\(L(θ)&lt;L(θ&#39;)\)</span>。也就是说假设<span class="math inline">\(θ-θ&#39;=\mu\)</span>,也就是,<strong>你在θ'的位置加上u,沿著u的方向做update得到θ,你就可以让loss变小</strong>。</p>
<p>因为根据这个式子,你只要θ减θ'等于u,loss就会变小,所以你今天只要让θ等于θ'加u,你就可以让loss变小,你只要沿著u,也就是eigen
vector的方向,去更新你的参数 去改变你的参数,你就可以让loss变小了</p>
<p><strong><font color="red"> 所以虽然在critical
point没有gradient,如果我们今天是在一个saddle
point,你也不一定要惊慌,你只要找出负的eigen value,再找出它对应的eigen
vector,用这个eigen
vector去加θ',就可以找到一个新的点,这个点的loss比原来还要低。</font></strong></p>
<h5><span id="举具体的例子">举具体的例子：</span></h5>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626145931496.png" alt="image-20220626145931496" style="zoom: 67%;"></p>
<p>刚才我们已经发现,原点是一个critical
point,它的Hessian长这个样,那我现在发现说,这个Hessian有一个负的eigen
value,这个eigen value等于-2,那它对应的eigen
vector,它有很多个,其实是无穷多个对应的eigen
vector,我们就取一个出来,我们取<span class="math inline">\(\begin{bmatrix}{1} \\\
{1}\end{bmatrix}\)</span>是它对应的一个eigen
vector,那我们其实只要顺著这个u的方向,顺著<span class="math inline">\(\begin{bmatrix}{1} \\\
{1}\end{bmatrix}\)</span>这个vector的方向,去更新我们的参数,就可以找到一个,比saddle
point的loss还要更低的点。</p>
<p>如果以今天这个例子来看的话,你的saddle
point在(0,0)这个地方,你在这个地方会没有gradient,Hessian的eigen
vector告诉我们,只要往<span class="math inline">\(\begin{bmatrix}{1} \\\
{1}\end{bmatrix}\)</span>的方向更新,你就可以让loss变得更小,也就是说你可以逃离你的saddle
point,然后让你的loss变小,所以从这个角度来看,似乎saddle
point并没有那么可怕。如果你今天在training的时候,你的gradient你的训练停下来,你的gradient变成零,你的训练停下来,是因为saddle
point的话,那似乎还有解。</p>
<p><strong>但是当然实际上,在实际的implementation里面,你几乎不会真的把Hessian算出来</strong>,这个要是二次微分,要计算这个矩阵的computation,需要的运算量非常非常的大,更遑论你还要把它的eigen
value,跟 eigen
vector找出来,所以在实作上,你几乎没有看到,有人用这一个方法来逃离saddle
point。</p>
<p><strong>等一下我们会讲其他,也有机会逃离saddle
point的方法,他们的运算量都比要算这个H,还要小很多</strong>,那今天之所以我们把,这个saddle
point跟 eigen vector,跟Hessian的eigen
vector拿出来讲,是想要告诉你说,如果是卡在saddle
point,也许没有那么可怕,最糟的状况下你还有这一招,可以告诉你要往哪一个方向走.</p>
<h3><span id="14-saddle-point-vs-localminima">1.4 Saddle Point v.s. Local
Minima</span></h3>
<p>讲到这边你就会有一个问题了,这个问题是,那到底<strong>saddle
point跟local minima,谁比较常见呢</strong>,我们说,saddle
point其实并没有很可怕,那如果我们今天,常遇到的是saddle
point,比较少遇到local minima,那就太好了,那到底saddle point跟local
minima,哪一个比较常见呢?</p>
<p>总之这个<strong>从三维的空间来看,是没有路可以走的东西,在高维的空间中是有路可以走的,error
surface会不会也一样呢？</strong></p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626150135469.png" alt="image-20220626150135469" style="zoom:67%;"></p>
<p>而经验上,如果你自己做一些实验的话,也支持这个假说</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220626150207285.png" alt="image-20220626150207285" style="zoom: 67%;"></p>
<p>这边是训练某一个network的结果,每一个点代表,训练那个network训练完之后,把它的Hessian拿出来进行计算,所以这边的每一个点,都代表一个network,就我们训练某一个network,然后把它训练训练,训练到gradient很小,卡在critical
point,把那组参数出来分析,看看它比较像是saddle point,还是比较像是local
minima</p>
<ul>
<li>纵轴代表training的时候的loss,就是我们今天卡住了,那个loss没办法再下降了,那个loss是多少,那很多时候,你的loss在还很高的时候,训练就不动了
就卡在critical point,那很多时候loss可以降得很低,才卡在critical
point,这是纵轴的部分</li>
<li>横轴的部分是minimum ratio,minimum ratio是<strong>eigen
value的数目分之正的eigen value的数目</strong>,又<strong>如果所有的eigen
value都是正的,代表我们今天的critical point,是local
minima,如果有正有负代表saddle
point</strong>,那在实作上你会发现说,你几乎找不到完全所有eigen
value都是正的critical point,你看这边这个例子里面,这个minimum
ratio代表eigen value的数目分之正的eigen
value的数目,最大也不过0.5到0.6间而已,代表说只有一半的eigen
value是正的,还有一半的eigen value是负的,</li>
</ul>
<p>所以今天虽然在这个图上,越往右代表我们的critical point越像local
minima,<strong>但是它们都没有真的,变成local
minima</strong>,就算是在最极端的状况,我们仍然有一半的case,我们的eigen
value是负的,这一半的case eigen
value是正的,代表说在所有的维度里面有一半的路,这一半的路
如果要让loss上升,还有一半的路可以让loss下降。</p>
<p><strong><font color="red"> 所以从经验上看起来,其实local
minima并没有那么常见,多数的时候,你觉得你train到一个地方,你gradient真的很小,然后所以你的参数不再update了,往往是因为你卡在了一个saddle
point。</font></strong></p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220616164405732.png" alt="image-20220616164405732" style="zoom: 33%;"></p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>lzy
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://powerlzy.github.io/posts/1T7T14B/" title="模型训练（6）Local Minimum And Saddle Point">https://powerlzy.github.io/posts/1T7T14B/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/TYS9XF/" rel="prev" title="特征工程（8）【draft】时间序列处理">
                  <i class="fa fa-chevron-left"></i> 特征工程（8）【draft】时间序列处理
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/1HFEDWZ/" rel="next" title="模型训练（5）Batch Normalization">
                  模型训练（5）Batch Normalization <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lzy</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>-->
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("03/01/2023 10:00:00"); //此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒.";
    }
setInterval("createtime()",250);
</script>

    </div>
  </footer>

  

  <a href="https://github.com/PowerLZY" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.4.3/mermaid.min.js","integrity":"sha256-e0o3JYsdjqKajf9eOe22FhioYSz9WofRY4dLKo3F6do="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>




        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        const hasAttr = (e,a) => a.some(_=> e.attr(_)!==undefined);
        $('a').each(function() {
          const $this = $(this);
          if(hasAttr($this,["data-fancybox","ignore-external-link"])) return;
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'powerlzy.github.io' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script></body>
</html>
