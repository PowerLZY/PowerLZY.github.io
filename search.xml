<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>hadoop基础</title>
    <url>/posts/3NVTGC1/</url>
    <content><![CDATA[<blockquote>
<p>应该是指可以打通整个项目开发过程的，比如基于BS架构的话，就是熟悉前后端，知道怎么把算法模型部署到后端服务器，熟悉分布式计算，能玩转mapreduce，spark，hadoop，能熟练搭建项目框架</p>
</blockquote>
<p>三、大数据（简单了解其中一二个）</p>
<p>Hadoop基础、MapReduce、spark、hive、flink</p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>局部敏感哈希LSH</title>
    <url>/posts/R9HZV9/</url>
    <content><![CDATA[<h2><span id="一-局部敏感哈希函数">一、局部敏感哈希函数</span></h2>
<blockquote>
<p>python_mmdt:ssdeep、tlsh、vhash、mmdthash对比 :
https://www.freebuf.com/sectool/321011.html</p>
<p>局部敏感哈希(Locality Sensitive
Hashing，LSH)总结：http://yangyi-bupt.github.io/ml/2015/08/28/lsh.html</p>
</blockquote>
<h3><span id="11-局部敏感哈希的基本概念">1.1 局部敏感哈希的基本概念</span></h3>
<p>局部敏感哈希(Locality Sensitive
Hashing，LSH)的基本思想类似于一种空间域转换思想，LSH算法基于一个假设，<strong>如果两个文本在原有的数据空间是相似的，那么分别经过哈希函数转换以后的它们也具有很高的相似度</strong>；相反，如果它们本身是不相似的，那么经过转换后它们应仍不具有相似性。</p>
<h3><span id="12-hash方法">1.2 hash方法</span></h3>
<p><strong><a href="https://ssdeep-project.github.io/ssdeep/index.html">CTPH(ssdeep)</a>：Context
Triggered Piecewise Hashes(CTPH)</strong>，又叫模糊哈希，最早由Jesse
Kornblum博士在2006年提出，论文地址点击<a href="https://ssdeep-project.github.io/ssdeep/index.html">这里</a>。CTPH可用于文件/数据的<strong>同源性判定</strong>。据官方文档介绍，其计算速度是<code>tlsh</code>的两倍（测试了一下，好像并没有）。</p>
<blockquote>
<p>当使用传统的加密散列时，会为整个文件创建一个散列。单个位的变化会对输出哈希值产生雪崩效应。另一方面，CTPH
为文件的多个固定大小段计算多个传统加密哈希。它使用<em>滚动哈希</em>。</p>
</blockquote>
<p><strong><a href="https://tlsh.org/index.html">tlsh</a>：是趋势科技开源的一款模糊哈希计算工具</strong>，将50字节以上的数据计算生成一个哈希值，通过计算哈希值之间的相似度，从而得到原始文件之间的同源性关联。据官方文档介绍，<code>tlsh</code>比<code>ssdeep</code>和<code>sdhash</code>等其他模糊哈希算法更难攻击和绕过。</p>
<p><a href="https://developers.virustotal.com/reference/files">vhash</a>：（翻遍了整个virustotal的文档，就找到这么一句话）“an
in-house similarity clustering algorithm value, based on a simple
structural feature hash allows you to find similar
files”，大概就是说是个内部相似性聚类算法，允许你通过这个简单的值，找到相似的样本。</p>
<p><a href="https://github.com/a232319779/python_mmdt">mmdthash</a>：是开源的一款模糊哈希计算工具，将任意数据计算生成一个模糊哈希值，通过计算模糊哈希值之间的相似度，从而判断两个数据之间的关联性。详情前文1-5篇。</p>
<blockquote>
<p>#### mmdthash：</p>
<p>通过重采样之后的数据，我们假设其满足独立同分布。同时，我们将重采样的数据，平均分成N块，每块之间的数据进行累计求和，和值分布近似服从正态分布，我们取和值高x位的一个byte做为本块数据的敏感哈希值。</p>
<p>51030000:D6E26822530202020202020202020202：</p>
<ul>
<li><code>51030000</code>是4字节<strong>索引</strong>敏感哈希</li>
<li><code>D6E26822530202020202020202020202</code>是16字节敏感哈希</li>
</ul>
</blockquote>
<h3><span id="13-应用">1.3 应用</span></h3>
<p>简单应用如，索引敏感哈希可以转成一个int32的数字，当<strong>索引敏感哈希相等</strong>时，<strong>再比较敏感哈希的距离</strong>（如曼哈顿距离，将敏感哈希转成N个<code>unsigned char</code>类型计算敏感哈希，此时<code>00</code>和<code>FF</code>之间的距离可算作1，也可算作255，具体看实现）。</p>
<p>由于特征向量的维度是固定的，因此可以很方便的使用其他数学方法，进行大规模计算。</p>
<ul>
<li>如结合矩阵运算，快速得到上万特征向量（样本）的相似度矩阵，</li>
<li>如用于机器学习的分类（KNN）、聚类（Kmeans）等</li>
</ul>
<h3><span id></span></h3>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>hadoop&amp;spark的</title>
    <url>/posts/2T4G0D4/</url>
    <content><![CDATA[<h1><span id="hadoop和spark的区别和联系">hadoop和spark的区别和联系</span></h1>
<blockquote>
<p>==<strong>总结一句话：spark在hadoop肩膀上可以让大数据跑的更快</strong>==</p>
</blockquote>
<h3><span id="一-hadoop">一、 hadoop</span></h3>
<h4><span id="11-hadoop简介">1.1 hadoop简介</span></h4>
<p><strong>Hadoop是一个由Apache基金会所开发的分布式系统基础架构</strong>。
<strong>Hadoop实现了一个分布式文件系统HDFS</strong>。HDFS有高容错性的特点，并且设计用来部署在低廉的硬件上；而且它提供高吞吐量来访问应用程序的数据，适合那些有着超大数据集的应用程序。Hadoop的框架最核心的设计就是：HDFS和MapReduce。<strong>HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算</strong>。</p>
<h4><span id="12-hadoop优点">1.2 hadoop优点</span></h4>
<p><strong>Hadoop
以一种可靠、高效、可伸缩的方式进行数据处理。</strong></p>
<ul>
<li><p><strong>可靠性</strong>:
Hadoop将数据存储在多个备份，Hadoop提供高吞吐量来访问应用程序的数据。</p></li>
<li><p><strong>高扩展性</strong>：
Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。</p></li>
<li><p><strong>高效性</strong>：
Hadoop以并行的方式工作，通过并行处理加快处理速度。</p></li>
<li><p><strong>高容错性</strong>：
Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。</p></li>
<li><p><strong>低成本</strong>：
Hadoop能够部署在低廉的（low-cost）硬件上。</p></li>
</ul>
<h3><span id="二-spark"><strong>二、spark</strong></span></h3>
<h4><span id="21-spark简介">2.1 spark简介</span></h4>
<p><strong>Spark
是专为大规模数据处理而设计的快速通用的计算引擎</strong>。Spark拥有Hadoop
MapReduce所具有的优点，Spark在Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark性能以及运算速度高于MapReduce。</p>
<h4><span id="22-spark优点">2.2 spark优点</span></h4>
<p><strong>计算速度快</strong>:
因为spark从磁盘中读取数据，把<strong>中间数据放到内存中</strong>，，完成所有必须的分析处理，将结果写回集群，所以spark更快。</p>
<ul>
<li><p><strong>Spark 提供了大量的库</strong>: 包括Spark Core、Spark
SQL、Spark Streaming、MLlib、GraphX。</p></li>
<li><p><strong>支持多种资源管理器</strong>: Spark 支持 Hadoop
YARN，及其自带的独立集群管理器</p></li>
<li><p><strong>操作简单</strong>: 高级 API 剥离了对集群本身的关注，Spark
应用开发者可以专注于应用所要做的计算本身</p></li>
</ul>
<h3><span id="三-spark与hadoop的不同点">三、spark与hadoop的不同点</span></h3>
<h4><span id="31-应用场景不同">3.1 应用场景不同</span></h4>
<p>Hadoop和Spark两者都是大数据框架，但是各自应用场景是不同的。<strong>Hadoop是一个分布式数据存储架构，它将巨大的数据集分派到一个由普通计算机组成的集群中的多个节点进行存储，降低了硬件的成本</strong>。<strong>Spark是那么一个专门用来对那些分布式存储的大数据进行处理的工具，它要借助hdfs的数据存储</strong>。</p>
<h4><span id="32-处理速度不同">3.2 处理速度不同</span></h4>
<p><strong>hadoop的MapReduce是分步对数据进行处理的，从磁盘中读取数据，进行一次处理，将结果写到磁盘</strong>，然后在从磁盘中读取更新后的数据，再次进行的处理，最后再将结果存入磁盘，这存取磁盘的过程会影响处理速度。<strong>spark从磁盘中读取数据，把中间数据放到内存中</strong>，，完成所有必须的分析处理，将结果写回集群，所以spark更快。</p>
<h4><span id="33-容错性不同">3.3 容错性不同</span></h4>
<p><strong>Hadoop将每次处理后的数据都写入到磁盘上，基本谈不上断电或者出错数据丢失的情况</strong>。Spark的数据对象存储在弹性分布式数据集
RDD，RDD是分布在一组节点中的只读对象集合，如果数据集一部分丢失，则可以根据于数据衍生过程对它们进行重建。而且RDD
计算时可以通过 CheckPoint 来实现容错。</p>
<h3><span id="四-spark与hadoop的联系">四、spark与hadoop的联系</span></h3>
<p>Hadoop提供分布式数据存储功能HDFS，还提供了用于数据处理的MapReduce。
MapReduce是可以不依靠spark数据的处理的。当然spark也可以不依靠HDFS进行运作，它可以依靠其它的分布式文件系统。但是两者完全可以结合在一起，<strong>hadoop提供分布式集群和分布式文件系统</strong>，<strong>spark可以依附在hadoop的HDFS代替MapReduce弥补MapReduce计算能力不足的问题。</strong></p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>数据湖</title>
    <url>/posts/16YPX72/</url>
    <content><![CDATA[<h1><span id="数据湖data-lake-总结">数据湖（Data Lake） 总结</span></h1>
<ul>
<li>https://zhuanlan.zhihu.com/p/91165577</li>
</ul>
<blockquote>
<p>数据湖从本质上来讲，是一种企业数据架构方法，物理实现上则是一个数据存储平台，用来集中化存储企业内海量的、多来源，多种类的数据，并支持对数据进行快速加工和分析。</p>
</blockquote>
<p>数据湖是一种在系统或存储库中以自然格式存储数据的方法，它有助于以各种模式和结构形式配置数据，通常是对象块或文件。<strong>数据湖的主要思想是对企业中的所有数据进行统一存储，从原始数据（源系统数据的精确副本）转换为用于报告、可视化、分析和机器学习等各种任务的目标数据。数据湖中的数据包括==结构化数据==（关系数据库数据），==半结构化数据==（CSV、XML、JSON等），==非结构化数据==（电子邮件，文档，PDF）和==二进制数据==（图像、音频、视频），从而形成一个容纳所有形式数据的==集中式数据存储==。</strong></p>
<p>从实现方式来看，目前Hadoop是最常用的部署数据湖的技术，但并不意味着数据湖就是指Hadoop集群。为了应对不同业务需求的特点，MPP数据库+Hadoop集群+传统数据仓库这种“混搭”架构的数据湖也越来越多出现在企业信息化建设规划中。</p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>大数据处理Q&amp;A</title>
    <url>/posts/10D4W42/</url>
    <content><![CDATA[<h4><span id="面试常见的大数据相关问题">面试常见的大数据相关问题</span></h4>
<ul>
<li>https://anchorety.github.io/2019/08/14/%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/</li>
</ul>
<h4><span id="海量日志数据提取出某日访问百度次数最多的那个ip">海量日志数据，提取出某日访问百度次数最多的那个IP？</span></h4>
<ul>
<li>http://zoeyyoung.github.io/get-most-visit-ip.html</li>
</ul>
<p>具体做法如下：</p>
<ol type="1">
<li>按照IP地址的Hash(IP)%1024值,
把海量IP日志分别存储到1024个小文件中.</li>
<li>对于每一个小文件, 构建一个以IP为key, 出现次数为value的HashMap,
同时记录当前出现次数最多的那个IP地址;</li>
<li>得到1024个小文件中的出现次数最多的IP,
再依据常规的排序算法得到总体上出现次数最多的IP.</li>
</ol>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>大数据处理（1）高维向量相似度匹配</title>
    <url>/posts/DTTFVX/</url>
    <content><![CDATA[<h2><span id="文本相似度匹配">文本相似度匹配</span></h2>
<blockquote>
<p>from 《Scaling Up All Pairs Similarity Search》</p>
<p>海量文本的成对相似度的高性能计算（待续） - 马东什么的文章 - 知乎
https://zhuanlan.zhihu.com/p/457947482</p>
</blockquote>
<h4><span id="摘要">摘要：</span></h4>
<p>对于高维空间中的大量稀疏向量数据，我们研究了寻找相似性分数(由余弦距离等函数确定)高于给定阈值的所有向量对的问题。我们提出了一个简单的算法<strong>，基于新的索引和优化策略，解决了这个问题，而不依赖于近似方法或广泛的参数调整</strong>。我们展示了该方法在广泛的相似阈值设置中有效地处理各种数据集，与以前的最先进的方法相比有很大的加速。</p>
<p>(海量成对文本相似度问题对于反欺诈而言非常重要，因为无论是电商中重要的地址信息，还是设备或用户的离散features之间的相似度计算和构图，都依赖于高性能的文本相似度计算方法，在实践中，我们不可能直接写双循环去做计算，即使是离线也往往需要耗费大量的时间)</p>
<h3><span id="一-介绍">一、介绍</span></h3>
<p>许多现实世界的应用程序需要解决一个相似度搜索问题，在这个问题中，人们对所有相似度高于指定阈值的对象对都感兴趣。</p>
<ul>
<li>web搜索的查询细化:搜索引擎通常会建议其他查询公式（例如你在百度中输入百，会给你推荐百度）。生成此类查询建议的一种方法是根据查询[19]的搜索结果的相似性来查找所有的相似查询对。由于目标是只提供高质量的建议，所以我们只需要找到相似度高于阈值的查询对（topk问题）。</li>
<li>协同过滤:协同过滤算法通过确定哪些用户有相似的品味来进行推荐。因此，算法需要计算相似度高于某个阈值的相似用户对。</li>
<li>接近重复的文档检测和消除:特别是在文档索引领域，检测和清除等价的文档是重要的。在许多情况下，由于简单的相等性检验不再满足要求，微小修改的存在使这种检测变得困难。通过具有很高的相似度阈值的相似度搜索，可以实现近重复检测（这方面的工作之前看过simhash，google做海量网页去重的方法）。</li>
<li>团伙检测:最近的工作已经应用算法在一个应用程序中寻找所有相似的用户，以识别点击欺诈者[13]团伙。</li>
</ul>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征-Hot100</title>
    <url>/posts/1SP3CDD/</url>
    <content><![CDATA[<h2><span id="一-前缀树">一、前缀树</span></h2>
<blockquote>
<p>一种好用的树结构：Trie树:https://zhuanlan.zhihu.com/p/508575094</p>
</blockquote>
<h3><span id="11trie树简介-有限状态自动机-文本词频统计"><strong>1.1
Trie树简介</strong> [有限状态自动机] [文本词频统计]</span></h3>
<p>在计算机科学中，trie，又称<strong>前缀树</strong>或<strong>字典树</strong>，是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。</p>
<p>Trie这个术语来自于retrieval。根据词源学，trie的发明者Edward
Fredkin把它读作/ˈtriː/ "tree"。但是，其他作者把它读作/ˈtraɪ/ "try"。</p>
<p>在图示中，键标注在节点中，值标注在节点之下。每一个完整的英文单词对应一个特定的整数。<strong>Trie可以看作是一个确定有限状态自动机，尽管边上的符号一般是隐含在分支的顺序中的</strong>。
Eg.一个保存了8个单词的字典树的结构如下图所示，8个单词分别是：“A”，“to”，“tea”，“ted”，“ten”，“i”
，“in”，“inn”。</p>
<p><img src="https://pic1.zhimg.com/80/v2-8740aeac82cd2fc980cd1148ab1a64dc_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>另外，<strong>单词查找树，Trie树，是一种树形结构，是一种哈希树的变种</strong>。<strong>典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计</strong>。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。</p>
<h3><span id="12-trie树性质">1.2 <strong>Trie树性质</strong></span></h3>
<p>它有3个基本性质：</p>
<ul>
<li>根节点不包含字符，除根节点外每一个节点都只包含一个字符；</li>
<li>从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串；</li>
<li>每个节点的所有子节点包含的字符都不相同。</li>
</ul>
<h3><span id="13-基本操作">1.3 <strong>基本操作</strong></span></h3>
<p>其基本操作有：查找、插入和删除,当然删除操作比较少见。</p>
<h2><span id="二-lru">二、LRU</span></h2>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征-代码随想录</title>
    <url>/posts/2WTQDCR/</url>
    <content><![CDATA[<ul>
<li><a href="https://programmercarl.com/">代码随想录</a></li>
<li><a href>labuladong</a></li>
</ul>
<h2><span id="一-树状数组">一、树状数组</span></h2>
<p>leecode 题目：<a href="https://leetcode-cn.com/problems/shu-zu-zhong-de-ni-xu-dui-lcof/">数组中的逆序对</a></p>
<blockquote>
<p>在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组，求出这个数组中的逆序对的总数。</p>
<p>示例 1:</p>
<p>输入: [7,5,6,4] 输出: 5</p>
</blockquote>
<p><strong>「树状数组」</strong>是一种可以<strong>动态维护序列前缀和</strong>的数据结构，它的功能是：</p>
<ul>
<li><strong>单点更新<code>update(i, v)</code></strong>:把序列 <span class="math inline">\(i\)</span> 位置的数加上一个值<span class="math inline">\(v\)</span>，这题 v = 1</li>
<li><strong>区间查询 <code>query(i)</code>：</strong>
查询序列[1⋯<em>i</em>] 区间的区间和，即 <em>i</em> 位置的前缀和</li>
</ul>
<p>修改和查询的时间代价都是 <span class="math inline">\(O(\log
n)\)</span>，其中 <em>n</em> 为需要维护前缀和的序列的长度。</p>
<h2><span id="二-单调栈">二、单调栈</span></h2>
<p>通常是一维数组，要==寻找任一个元素的右边或者左边第一个比自己大或者小的元素的位置==，此时我们就要想到可以用<strong>单调栈</strong>了。</p>
<ul>
<li><p><strong>单调栈里存放的元素是什么？</strong></p>
<p>单调栈里只需要存放元素的下标i就可以了，如果需要使用对应的元素，直接T[i]就可以获取。</p></li>
<li><p><strong>单调栈里元素是递增呢？ 还是递减呢？</strong></p>
<p><strong>注意一下顺序为
从栈头到栈底的顺序</strong>，因为单纯的说从左到右或者从前到后，不说栈头朝哪个方向的话，大家一定会越看越懵。</p></li>
<li><p><strong>目标列表遍历顺序？</strong> 倒序？正序？</p></li>
</ul>
<h3><span id="21-下一个更大元素">2.1 下一个更大元素</span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nextGreaterElement</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">    <span class="comment"># 下一个更大的元素：单调栈(不增的不要) + 哈希 </span></span><br><span class="line">    res = &#123;&#125;</span><br><span class="line">    stack = []</span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">reversed</span>(nums2): <span class="comment"># 倒序？</span></span><br><span class="line">        <span class="keyword">while</span> stack <span class="keyword">and</span> num &gt;= stack[-<span class="number">1</span>]:</span><br><span class="line">            stack.pop()</span><br><span class="line">        res[num] = stack[-<span class="number">1</span>] <span class="keyword">if</span> stack <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">        stack.append(num)</span><br><span class="line">    <span class="keyword">return</span> [res[num] <span class="keyword">for</span> num <span class="keyword">in</span> nums1]</span><br></pre></td></tr></table></figure>
<h3><span id="21下一个更大元素2循环数组又tm是循环">2.1
下一个更大元素2（循环数组）又TM是循环</span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">    <span class="keyword">def</span> <span class="title function_">nextGreaterElements</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># 三次逆转</span></span><br><span class="line">        s = <span class="built_in">list</span>(nums[::-<span class="number">1</span>])</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums[::-<span class="number">1</span>]:</span><br><span class="line">            <span class="keyword">while</span> s <span class="keyword">and</span> s[-<span class="number">1</span>] &lt;= num:</span><br><span class="line">                s.pop()</span><br><span class="line">            <span class="keyword">if</span> s:</span><br><span class="line">                res.append(s[-<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res.append(-<span class="number">1</span>)</span><br><span class="line">            s.append(num)</span><br><span class="line">        res.reverse()</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    def nextGreaterElements(self, nums: List[int]) -&gt; List[int]:</span></span><br><span class="line"><span class="string">        # 2n 遍历</span></span><br><span class="line"><span class="string">        n = len(nums)</span></span><br><span class="line"><span class="string">        ret = [-1] * n</span></span><br><span class="line"><span class="string">        stk = list()</span></span><br><span class="line"><span class="string">        for i in range(n * 2 - 1):</span></span><br><span class="line"><span class="string">            while stk and nums[stk[-1]] &lt; nums[i % n]:</span></span><br><span class="line"><span class="string">                ret[stk.pop()] = nums[i % n]</span></span><br><span class="line"><span class="string">            stk.append(i % n)</span></span><br><span class="line"><span class="string">        return ret</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    def nextGreaterElements(self, nums: List[int]) -&gt; List[int]:</span></span><br><span class="line"><span class="string">        # 栈留判断</span></span><br><span class="line"><span class="string">        n = len(nums)</span></span><br><span class="line"><span class="string">        ans = [-1 for _ in range(n)]</span></span><br><span class="line"><span class="string">        stack = [0]</span></span><br><span class="line"><span class="string">        stack2 = []</span></span><br><span class="line"><span class="string">        for i in range(1, n):</span></span><br><span class="line"><span class="string">            while stack and nums[i] &gt; nums[stack[-1]]: # ？</span></span><br><span class="line"><span class="string">                ans[stack[-1]] = nums[i]</span></span><br><span class="line"><span class="string">                stack.pop() </span></span><br><span class="line"><span class="string">            stack.append(i)</span></span><br><span class="line"><span class="string">        while len(stack) &gt; 1: # 栈顶是最大的保留</span></span><br><span class="line"><span class="string">            for num in nums: # 从头找？</span></span><br><span class="line"><span class="string">                if num &gt; nums[stack[-1]]:</span></span><br><span class="line"><span class="string">                    ans[stack[-1]] = num</span></span><br><span class="line"><span class="string">                    break</span></span><br><span class="line"><span class="string">            stack.pop()</span></span><br><span class="line"><span class="string">        return ans</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3><span id="23-每日温度">2.3 每日温度</span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dailyTemperatures</span>(<span class="params">self, temperatures: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">    <span class="comment"># next Geater </span></span><br><span class="line">    n = <span class="built_in">len</span>(temperatures)</span><br><span class="line">    res = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)] </span><br><span class="line">    stack = [<span class="number">0</span>] <span class="comment"># 存的初始索引</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n): <span class="comment"># 正序</span></span><br><span class="line">        <span class="keyword">while</span> stack <span class="keyword">and</span> temperatures[i] &gt; temperatures[stack[-<span class="number">1</span>]]:</span><br><span class="line">            res[stack[-<span class="number">1</span>]] = i - stack[-<span class="number">1</span>]  <span class="comment"># stack[-1]</span></span><br><span class="line">            stack.pop() </span><br><span class="line">        stack.append(i)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h3><span id="24-接雨水">2.4 接雨水</span></h3>
<p>接雨水是找每个柱子<strong>左右两边第一个大于该柱子高度的柱子</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">trap</span>(<span class="params">self, height: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="comment"># 单调栈 左 弹出后 s.top() 中 s.pop()  右 height[i]</span></span><br><span class="line">    n = <span class="built_in">len</span>(height)</span><br><span class="line">    stack = [<span class="number">0</span>]</span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">while</span> stack <span class="keyword">and</span> height[i] &gt; height[stack[-<span class="number">1</span>]]:</span><br><span class="line">            mid = stack.pop() <span class="comment"># 弹一个左面还有的话就是有坑</span></span><br><span class="line">            <span class="keyword">if</span> stack:</span><br><span class="line">                high = <span class="built_in">min</span>(height[stack[-<span class="number">1</span>]], height[i]) - height[mid] </span><br><span class="line">                <span class="comment"># 高 = 左右最小 - 低</span></span><br><span class="line">                weith = i - stack[-<span class="number">1</span>] - <span class="number">1</span> <span class="comment"># 宽</span></span><br><span class="line">                res += weith * high </span><br><span class="line">        stack.append(i)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h3><span id="25-柱状图的最大矩形">2.5 柱状图的最大矩形</span></h3>
<p><strong>找每个柱子左右两边第一个小于该柱子的柱子。</strong>：==<strong>栈顶和栈顶的下一个元素以及要入栈的三个元素组成了我们要求最大面积的高度和宽度</strong>==</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">largestRectangleArea</span>(<span class="params">self, heights: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="comment"># 单调栈 左右两边都可以用</span></span><br><span class="line">    heights.insert(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">    heights.append(<span class="number">0</span>)</span><br><span class="line">    stack = [<span class="number">0</span>]</span><br><span class="line">    ans = heights[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(heights)):</span><br><span class="line">        <span class="keyword">while</span> stack <span class="keyword">and</span> heights[i] &lt; heights[stack[-<span class="number">1</span>]]:</span><br><span class="line">            mid = stack.pop()</span><br><span class="line">            <span class="keyword">if</span> stack: <span class="comment"># 存在左右最小</span></span><br><span class="line">                weith = i - stack[-<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">                <span class="comment"># high = max(heights[i], heights[stack[-1]])</span></span><br><span class="line">                ans = <span class="built_in">max</span>(ans, heights[mid] * weith)</span><br><span class="line">        stack.append(i)</span><br><span class="line">    <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h2><span id="三-单调队列">三、单调队列</span></h2>
<h2><span id="四-贪心算法"></span></h2>
<p><img src="https://code-thinking-1253855093.file.myqcloud.com/pics/20210917104315.png" alt="贪心算法大纲"></p>
<h3><span id="什么是贪心">什么是贪心</span></h3>
<p><strong>贪心的本质是选择每一阶段的局部最优，从而达到全局最优</strong>。</p>
<h3><span id="贪心一般解题步骤">贪心一般解题步骤</span></h3>
<p>贪心算法一般分为如下四步：</p>
<ul>
<li>将问题分解为若干个子问题</li>
<li>找出适合的贪心策略</li>
<li>求解每一个子问题的最优解</li>
<li>将局部最优解堆叠成全局最优解</li>
</ul>
<h2><span id="五-动态规划"></span></h2>
<figure>
<img src="https://images.zsxq.com/FvoG8qppuOWSNhXBbj27ShBAJw0G?imageMogr2/auto-orient/quality/100!/ignore-error/1&amp;e=1648742399&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:q36Nzw1NTcg-NvuvnNyOWSZ_mdI=" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>首先，动态规划问题的一般形式就是==求最值==</strong>。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，比如说让你求<strong>最长</strong>递增子序列呀，<strong>最小</strong>编辑距离呀等等。<strong>求解动态规划的核心问题是穷举</strong>。首先，动态规划的穷举有点特别，因为这类问题<strong>存在「重叠子问题」</strong>，如果暴力穷举的话效率会极其低下，所以需要「==备忘录」或者「DP
table」==来优化穷举过程，避免不必要的计算。而且，动态规划问题一定会<strong>具备「最优子结构」</strong>，才能通过子问题的最值得到原问题的最值。</p>
<p>另外，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，只有列出<strong>正确的「状态转移方程」</strong>，才能正确地穷举。</p>
<p>以上提到的<strong>重叠子问题、最优子结构、状态转移方程</strong>就是动态规划三要素。具体什么意思等会会举例详解，但是在实际的算法问题中，<strong>写出状态转移方程是最困难的</strong>，这也就是为什么很多朋友觉得动态规划问题困难的原因，我来提供我研究出来的一个思维框架，辅助你思考状态转移方程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 初始化 base case</span></span><br><span class="line">dp[<span class="number">0</span>][<span class="number">0</span>][...] = base</span><br><span class="line"><span class="comment"># 进行状态转移</span></span><br><span class="line"><span class="keyword">for</span> 状态<span class="number">1</span> <span class="keyword">in</span> 状态<span class="number">1</span>的所有取值：</span><br><span class="line">    <span class="keyword">for</span> 状态<span class="number">2</span> <span class="keyword">in</span> 状态<span class="number">2</span>的所有取值：</span><br><span class="line">        <span class="keyword">for</span> ...</span><br><span class="line">            dp[状态<span class="number">1</span>][状态<span class="number">2</span>][...] = 求最值(选择<span class="number">1</span>，选择<span class="number">2.</span>..)</span><br></pre></td></tr></table></figure>
<h3><span id="51-背包问题"><strong>5.1 背包问题</strong></span></h3>
<p>https://leetcode-cn.com/problems/coin-change/solution/dai-ma-sui-xiang-lu-dai-ni-xue-tou-wan-q-80r7/</p>
<figure>
<img src="https://img-blog.csdnimg.cn/20210117171307407.png" alt="416.分割等和子集1">
<figcaption aria-hidden="true">416.分割等和子集1</figcaption>
</figure>
<blockquote>
<p><strong>1、确定dp数组以及下标的含义</strong></p>
<p><strong>2、确定递推公式</strong></p>
<p><strong>3、dp数组如何初始化</strong></p>
<ul>
<li><strong>最大长度</strong></li>
<li><strong>递推等号左侧要初始化</strong></li>
</ul>
<p><strong>4、确定遍历顺序</strong></p>
<ul>
<li><strong>滚动数组</strong></li>
</ul>
<p><strong>5、举例推导dp数组</strong></p>
</blockquote>
<h4><span id="511-背包递推公式">5.1.1 背包递推公式</span></h4>
<p><strong>问==能否装满背包==</strong>（或者<strong>最多装多少</strong>）：dp[j]
= max(dp[j], dp[j - nums[i]] + nums[i]); ，对应题目如下：</p>
<ul>
<li><a href="https://programmercarl.com/0416.分割等和子集.html">动态规划：416.分割等和子集(opens
new window)</a></li>
<li><a href="https://leetcode-cn.com/problems/partition-to-k-equal-sum-subsets/">划分为k个相等的子集</a></li>
<li><a href="https://programmercarl.com/1049.最后一块石头的重量II.html">动态规划：1049.最后一块石头的重量
II</a></li>
</ul>
<p><strong>==问装满背包有几种方法==</strong>：dp[j] += dp[j - nums[i]]
，对应题目如下：</p>
<ul>
<li><p><a href="https://programmercarl.com/0494.目标和.html">动态规划：494.目标和(opens
new window)</a></p></li>
<li><p><a href="https://programmercarl.com/0518.零钱兑换II.html">动态规划：518.
零钱兑换 II(opens new window)</a></p></li>
<li><p><a href="https://programmercarl.com/0377.组合总和Ⅳ.html">动态规划：377.组合总和Ⅳ(opens
new window)</a></p>
<blockquote>
<p><strong>如果求组合数就是外层for循环遍历物品，内层for遍历背包</strong>。</p>
<p><strong>如果求排列数就是外层for遍历背包，内层for循环遍历物品</strong>。</p>
</blockquote></li>
<li><p><a href="https://programmercarl.com/0070.爬楼梯完全背包版本.html">动态规划：70.
爬楼梯进阶版（完全背包）</a></p></li>
</ul>
<p><strong>问背包装满==最大价值==</strong>：dp[j] = max(dp[j], dp[j -
weight[i]] + value[i]); ，对应题目如下：</p>
<ul>
<li><a href="https://programmercarl.com/0474.一和零.html">动态规划：474.一和零</a></li>
</ul>
<p><strong>问装满背包所有物品的==最小个数==</strong>：dp[j] = min(dp[j -
coins[i]] + 1, dp[j]); ，对应题目如下：</p>
<ul>
<li><a href="https://programmercarl.com/0322.零钱兑换.html">动态规划：322.零钱兑换(opens
new window)</a></li>
<li><a href="https://programmercarl.com/0279.完全平方数.html">动态规划：279.完全平方数(opens
new window)</a></li>
</ul>
<h4><span id="512-遍历顺序">5.1.2 遍历顺序</span></h4>
<h5><span id="01背包">01背包</span></h5>
<p>在<a href="https://programmercarl.com/背包理论基础01背包-1.html">动态规划：关于01背包问题，你该了解这些！
(opens new
window)</a>中我们讲解二维dp数组01背包先遍历物品还是先遍历背包都是可以的，且第二层for循环是从小到大遍历。</p>
<p>和<a href="https://programmercarl.com/背包理论基础01背包-2.html">动态规划：关于01背包问题，你该了解这些！（滚动数组）
(opens new
window)</a>中，我们讲解一维dp数组01背包只能先遍历物品再遍历背包容量，且第二层for循环是从大到小遍历。</p>
<p><strong>一维dp数组的背包在遍历顺序上和二维dp数组实现的01背包其实是有很大差异的，大家需要注意！</strong></p>
<h5><span id="完全背包">完全背包</span></h5>
<p>说完01背包，再看看完全背包。</p>
<p>在<a href="https://programmercarl.com/背包问题理论基础完全背包.html">动态规划：关于完全背包，你该了解这些！
(opens new
window)</a>中，讲解了纯完全背包的一维dp数组实现，先遍历物品还是先遍历背包都是可以的，且第二层for循环是从小到大遍历。</p>
<p>但是仅仅是纯完全背包的遍历顺序是这样的，题目稍有变化，两个for循环的先后顺序就不一样了。</p>
<p><strong>如果求==组合数==就是外层for循环遍历物品，内层for遍历背包</strong>。</p>
<p><strong>如果==求排列数==就是外层for遍历背包，内层for循环遍历物品</strong>。</p>
<p>相关题目如下：</p>
<ul>
<li>求组合数：<a href="https://programmercarl.com/0518.零钱兑换II.html">动态规划：518.零钱兑换II(opens
new window)</a></li>
<li>求排列数：<a href="https://mp.weixin.qq.com/s/Iixw0nahJWQgbqVNk8k6gA">动态规划：377.
组合总和 Ⅳ (opens new window)</a>、<a href="https://programmercarl.com/0070.爬楼梯完全背包版本.html">动态规划：70.
爬楼梯进阶版（完全背包）(opens new window)</a></li>
</ul>
<p>如果求最小数，那么两层for循环的先后顺序就无所谓了，相关题目如下：</p>
<ul>
<li>求最小数：<a href="https://programmercarl.com/0322.零钱兑换.html">动态规划：322.
零钱兑换 (opens new window)</a>、<a href="https://programmercarl.com/0279.完全平方数.html">动态规划：279.完全平方数(opens
new window)</a></li>
</ul>
<p><strong>对于背包问题，其实递推公式算是容易的，难是难在遍历顺序上，如果把遍历顺序搞透，才算是真正理解了</strong>。</p>
<h3><span id="52-子序列问题">5.2 <strong>子序列问题</strong></span></h3>
<p><img src="https://code-thinking.cdn.bcebos.com/pics/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-%E5%AD%90%E5%BA%8F%E5%88%97%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.jpg" alt="img" style="zoom:50%;"></p>
<ul>
<li><p><a href="https://programmercarl.com/0300.最长上升子序列.html">动态规划：最长递增子序列</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 子序列 </span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLIS</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(nums)</span><br><span class="line">        dp = [<span class="number">1</span>] * <span class="built_in">len</span>(nums)</span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, i):</span><br><span class="line">                <span class="keyword">if</span> nums[i] &gt; nums[j]:</span><br><span class="line">                    dp[i] = <span class="built_in">max</span>(dp[i], dp[j] + <span class="number">1</span>)</span><br><span class="line">            result = <span class="built_in">max</span>(result, dp[i]) <span class="comment">#取长的子序列</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></li>
<li><h5><span id="动态规划最长斐波那契数列"></span></h5></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lenLongestFibSubseq</span>(<span class="params">self, A: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="comment"># 基本顺序是 k，i，j 或者 A[k] = A[j] - A[i]</span></span><br><span class="line">    n = <span class="built_in">len</span>(A)</span><br><span class="line">    dic = &#123;&#125;</span><br><span class="line">    <span class="comment"># 创建索引字典，提速</span></span><br><span class="line">    <span class="keyword">for</span> ind,val <span class="keyword">in</span> <span class="built_in">enumerate</span>(A):</span><br><span class="line">        dic[val] = ind</span><br><span class="line">    <span class="comment"># 初始化，行代表的是i，不需要取到n-1，为了给j留出位置</span></span><br><span class="line">    <span class="comment"># 初始为2，只要包含了 j i 位置，则意味着已经有了2个数字。</span></span><br><span class="line">    dp = [[<span class="number">2</span>]*n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>)]</span><br><span class="line">    ret = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 因此i只能取到n-2，给j留出空间</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n-<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># j从i+1开始，毕竟j在i后面</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>,n):</span><br><span class="line">            diff = A[j] - A[i]</span><br><span class="line">            <span class="keyword">if</span> diff <span class="keyword">in</span> dic <span class="keyword">and</span> dic[diff] &lt; i:</span><br><span class="line">                k = dic[diff]</span><br><span class="line">                dp[i][j] = dp[k][i] + <span class="number">1</span> <span class="comment"># 这个1，代表着k位置数字</span></span><br><span class="line">                ret = <span class="built_in">max</span>(ret,dp[i][j])</span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure>
<ul>
<li><p><a href="https://programmercarl.com/0718.最长重复子数组.html">动态规划：最长重复子数组</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findLength</span>(<span class="params">self, A: <span class="type">List</span>[<span class="built_in">int</span>], B: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        dp = [<span class="number">0</span>] * (<span class="built_in">len</span>(B) + <span class="number">1</span>)</span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(A)+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(B), <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> A[i-<span class="number">1</span>] == B[j-<span class="number">1</span>]:</span><br><span class="line">                    dp[j] = dp[j-<span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[j] = <span class="number">0</span> <span class="comment">#注意这里不相等的时候要有赋0的操作</span></span><br><span class="line">                result = <span class="built_in">max</span>(result, dp[j])</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></li>
<li><p><a href="https://programmercarl.com/1143.最长公共子序列.html">动态规划：最长公共子序列</a>、
<a href="https://programmercarl.com/1035.不相交的线.html">动态规划：不相交的线</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestCommonSubsequence</span>(<span class="params">self, text1: <span class="built_in">str</span>, text2: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 最长子序列 </span></span><br><span class="line">        m, n = <span class="built_in">len</span>(text1), <span class="built_in">len</span>(text2)</span><br><span class="line">        dp = [[<span class="number">0</span>] * (n+<span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m+<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> text2[j-<span class="number">1</span>] == text1[i-<span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = dp[i-<span class="number">1</span>][j-<span class="number">1</span>] +<span class="number">1</span> </span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>][j], dp[i][j-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure></li>
<li><p><a href="https://programmercarl.com/0053.最大子序和（动态规划）.html">动态规划：最大子序和</a>
【贪心】【动态规划】</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">maxSubArray</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="comment"># 为什么dp[-1]不是最大？需要res</span></span><br><span class="line">    <span class="comment"># dp[i] 以i结尾的最大子数组和</span></span><br><span class="line">    n = <span class="built_in">len</span>(nums)</span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    dp = [<span class="number">0</span>] * (n)</span><br><span class="line">    dp[<span class="number">0</span>] = nums[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">        dp[i] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>]+nums[i], nums[i])</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(dp)</span><br></pre></td></tr></table></figure>
<ul>
<li><a href="https://programmercarl.com/0392.判断子序列.html">动态规划：判断子序列</a>
【双指针】</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isSubsequence</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        n, m = <span class="built_in">len</span>(s), <span class="built_in">len</span>(t)</span><br><span class="line">        i = j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; n <span class="keyword">and</span> j &lt; m:</span><br><span class="line">            <span class="keyword">if</span> s[i] == t[j]:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> i == n</span><br></pre></td></tr></table></figure>
<ul>
<li><p><a href="https://programmercarl.com/0115.不同的子序列.html">动态规划：不同的子序列</a></p></li>
<li><p><a href="https://programmercarl.com/0583.两个字符串的删除操作.html">动态规划：两个字符串的删除操作</a></p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dp[i][j] : word1[i-1], word1[j-1] 最少步数</span></span><br><span class="line"><span class="comment"># word1[i - 1] 与 word2[j - 1]不相同的时候，有2种情况 *  min(dp[i-1][j], dp[i][j-1])+1  </span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">minDistance</span>(<span class="params">self, word1: <span class="built_in">str</span>, word2: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        m, n = <span class="built_in">len</span>(word1), <span class="built_in">len</span>(word2)</span><br><span class="line">        dp = [[<span class="number">0</span>] * (n+<span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m+<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>):</span><br><span class="line">            dp[<span class="number">0</span>][i] = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m+<span class="number">1</span>):</span><br><span class="line">            dp[j][<span class="number">0</span>] = j</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> word1[i-<span class="number">1</span>] == word2[j-<span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = dp[i-<span class="number">1</span>][j-<span class="number">1</span>]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="built_in">min</span>(dp[i-<span class="number">1</span>][j], dp[i][j-<span class="number">1</span>])+<span class="number">1</span> <span class="comment"># , dp[i-1][j-1]+1</span></span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li><a href="https://programmercarl.com/0072.编辑距离.html">动态规划：编辑距离</a></li>
<li><a href="https://programmercarl.com/为了绝杀编辑距离，卡尔做了三步铺垫.html">为了绝杀编辑距离，我做了三步铺垫，你都知道么？</a></li>
<li><a href="https://programmercarl.com/0647.回文子串.html">动态规划：回文子串</a></li>
<li><a href="https://leetcode-cn.com/problems/longest-palindromic-substring/">最长回文子串</a>
==<a href="#manacher-算法">Manacher 算法</a>==</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 中心扩展法</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="comment"># 枚举+中心扩展法</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">extendCenter</span>(<span class="params">left, right</span>):</span><br><span class="line">            <span class="keyword">while</span> <span class="number">0</span> &lt;= left <span class="keyword">and</span> right &lt; <span class="built_in">len</span>(s) <span class="keyword">and</span> s[left] == s[right]:</span><br><span class="line">                left -= <span class="number">1</span></span><br><span class="line">                right += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 返回的为while不成立的值</span></span><br><span class="line">            <span class="keyword">return</span> left+<span class="number">1</span>, right-<span class="number">1</span> </span><br><span class="line">        start, end = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            left1, right1 = extendCenter(i,i)</span><br><span class="line">            left2, right2 = extendCenter(i,i+<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> right1 - left1 &gt; end - start:</span><br><span class="line">                start, end = left1, right1</span><br><span class="line">            <span class="keyword">if</span> right2 - left2 &gt; end - start:</span><br><span class="line">                start, end = left2, right2</span><br><span class="line">        <span class="keyword">return</span> s[start:end+<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">longestPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="comment"># dp[i][j]: 是否是回文 dp[i+1][j-1] -&gt; dp[i][j]</span></span><br><span class="line">    <span class="comment"># 返回的子串，不是数字 不能记录长度</span></span><br><span class="line">    n = <span class="built_in">len</span>(s)</span><br><span class="line">    dp = [[<span class="literal">False</span>] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="comment"># 右上为1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        dp[i][i] = <span class="literal">True</span></span><br><span class="line">    begin = <span class="number">0</span></span><br><span class="line">    maxlen = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 判断是否是回文子串中，如果是则记录begin and len</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>, -<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i,n):</span><br><span class="line">            <span class="keyword">if</span> s[i] == s[j]:</span><br><span class="line">                <span class="keyword">if</span> j - i &lt;=<span class="number">1</span>:</span><br><span class="line">                    dp[i][j] = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">elif</span> dp[i+<span class="number">1</span>][j-<span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = <span class="literal">True</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> dp[i][j] <span class="keyword">and</span> j - i + <span class="number">1</span> &gt; maxlen:</span><br><span class="line">                maxlen = j - i + <span class="number">1</span></span><br><span class="line">                begin = i</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> s[begin:begin+maxlen]</span><br></pre></td></tr></table></figure>
<h4><span id="manacher-算法">Manacher 算法</span></h4>
<p><strong>Manacher
算法是在线性时间内求解最长回文子串的算法</strong>。在本题中，我们要求解回文串的个数，为什么也能使用
Manacher 算法呢？这里我们就需要理解一下 Manacher 的基本原理。</p>
<ul>
<li><p>奇偶长度处理： abaaabaa 会被处理成
#a#b#a#a##<em>a</em>#<em>b</em>#<em>a</em>#<em>a</em>#</p></li>
<li><p>==<strong><span class="math inline">\(f(i)\)</span></strong>
来表示以 s 的第 i 位为回文中心，可以拓展出的<strong>最大回文半径 （包括
# ）</strong>==，那么$ f(i) - 1$就是以 i 为中心的最大回文串长度
。</p></li>
<li><p>利用已经计算出来的状态来更新 f(i）：<strong>回文右端点rm</strong>
：i + f(i) - 1</p></li>
<li><p><a href="https://programmercarl.com/0516.最长回文子序列.html">动态规划：最长回文子序列</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestPalindromeSubseq</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 动态规划 dp[i][j]: s[i:j] 最大回文长度</span></span><br><span class="line">        <span class="comment"># dp[i+1][j-1] -&gt; dp[i][j] 遍历顺序 and j - i &gt;=2</span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        dp = [[<span class="number">0</span>] * i +[<span class="number">1</span>] * (n-i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="comment"># 从定义出发 右上三角 = 1 有意义</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>,n): <span class="comment"># j - i &gt;=2</span></span><br><span class="line">                <span class="keyword">if</span> s[i] == s[j]:</span><br><span class="line">                    dp[i][j] = dp[i+<span class="number">1</span>][j-<span class="number">1</span>] + <span class="number">2</span> </span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="built_in">max</span>(dp[i+<span class="number">1</span>][j], dp[i][j-<span class="number">1</span>])                </span><br><span class="line">        <span class="keyword">return</span> dp[<span class="number">0</span>][n-<span class="number">1</span>]</span><br></pre></td></tr></table></figure></li>
<li><h5><span id="最少回文分割"></span></h5></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minCut</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 动态规划1:判断回文</span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        g = [[<span class="literal">True</span>] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, n):</span><br><span class="line">                g[i][j] = (s[i] == s[j]) <span class="keyword">and</span> g[i + <span class="number">1</span>][j - <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># </span></span><br><span class="line">        f = [<span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)] * n</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> g[<span class="number">0</span>][i]:</span><br><span class="line">                f[i] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">                    <span class="keyword">if</span> g[j + <span class="number">1</span>][i]:</span><br><span class="line">                        <span class="comment"># （0, j) + (j+1, i)</span></span><br><span class="line">                        f[i] = <span class="built_in">min</span>(f[i], f[j] + <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> f[n - <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li><h5><span id="最长连续序列"></span></h5></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestConsecutive</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 动态规划</span></span><br><span class="line">        dic, res = <span class="built_in">dict</span>(), <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> num <span class="keyword">not</span> <span class="keyword">in</span> dic:</span><br><span class="line">                left, right = dic.get(num - <span class="number">1</span>, <span class="number">0</span>), dic.get(num + <span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">                cur = <span class="number">1</span> + left +right</span><br><span class="line">                <span class="keyword">if</span> res &lt; cur:</span><br><span class="line">                    res = cur</span><br><span class="line">                dic[num] = cur</span><br><span class="line">                dic[num - left] = cur</span><br><span class="line">                dic[num + right] = cur</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h3><span id="53-打家劫舍问题">5.3 打家劫舍问题</span></h3>
<ul>
<li><a href="https://programmercarl.com/0198.打家劫舍.html">动态规划：开始打家劫舍</a></li>
<li><a href="https://programmercarl.com/0213.打家劫舍II.html">动态规划：继续打家劫舍
环</a></li>
<li><a href="https://programmercarl.com/0337.打家劫舍III.html">动态规划：还要打家劫舍
树状dp</a></li>
</ul>
<h3><span id="54-股票问题">5.4 股票问题</span></h3>
<figure>
<img src="https://code-thinking.cdn.bcebos.com/pics/%E8%82%A1%E7%A5%A8%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.jpg" alt="股票问题总结">
<figcaption aria-hidden="true">股票问题总结</figcaption>
</figure>
<ul>
<li><p><a href="https://programmercarl.com/0121.买卖股票的最佳时机.html">动态规划：121.买卖股票的最佳时机(opens
new window)</a> 股票只能买卖一次，问最大利润</p></li>
<li><p><a href="https://programmercarl.com/0122.买卖股票的最佳时机II（动态规划）.html">动态规划：122.买卖股票的最佳时机II(opens
new window)</a> 可以多次买卖股票，问最大收益。</p></li>
<li><p><a href="https://programmercarl.com/0123.买卖股票的最佳时机III.html">动态规划：123.买卖股票的最佳时机III(opens
new window)</a> 最多买卖两次，问最大收益。</p></li>
<li><p><a href="https://programmercarl.com/0188.买卖股票的最佳时机IV.html">动态规划：188.买卖股票的最佳时机IV(opens
new window)</a> 最多买卖k笔交易，问最大收益。</p></li>
<li><p><a href="https://programmercarl.com/0309.最佳买卖股票时机含冷冻期.html">动态规划：309.最佳买卖股票时机含冷冻期(opens
new window)</a> 可以多次买卖但每次卖出有冷冻期1天。</p></li>
<li><p><a href="https://programmercarl.com/0714.买卖股票的最佳时机含手续费（动态规划）.html">动态规划：714.买卖股票的最佳时机含手续费(opens
new window)</a> 可以多次买卖，但每次有手续费。</p></li>
</ul>
<h3><span id="55-编辑距离问题">5.5 编辑距离问题</span></h3>
<h4><span id="判断子序列">判断子序列</span></h4>
<p><a href="https://programmercarl.com/0392.判断子序列.html">动态规划：392.判断子序列
(opens new window)</a>给定字符串 s 和 t ，判断 s 是否为 t 的子序列。</p>
<p>这道题目
其实是可以用<strong>双指针</strong>或者<strong>贪心</strong>的的，但是我在开篇的时候就说了这是编辑距离的入门题目，因为从题意中我们也可以发现，只需要计算删除的情况，不用考虑增加和替换的情况。</p>
<ul>
<li>if (s[i - 1] == t[j - 1])
<ul>
<li>t中找到了一个字符在s中也出现了</li>
</ul></li>
<li>if (s[i - 1] != t[j - 1])
<ul>
<li>相当于t要删除元素，继续匹配</li>
</ul></li>
</ul>
<p>状态转移方程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (s[i - <span class="number">1</span>] == t[j - <span class="number">1</span>]) dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">else</span> dp[i][j] = dp[i][j - <span class="number">1</span>];</span><br></pre></td></tr></table></figure>
<h4><span id="不同的子序列">不同的子序列</span></h4>
<p><a href="https://programmercarl.com/0115.不同的子序列.html">动态规划：115.不同的子序列
(opens new window)</a>给定一个字符串 s 和一个字符串 t ，计算在 s
的子序列中 t 出现的个数。</p>
<p>本题虽然也只有删除操作，不用考虑替换增加之类的，但相对于<a href="https://programmercarl.com/0392.判断子序列.html">动态规划：392.判断子序列
(opens new window)</a>就有难度了，这道题目双指针法可就做不了。</p>
<p>当s[i - 1] 与 t[j - 1]相等时，dp[i][j]可以有两部分组成。</p>
<p>一部分是用s[i - 1]来匹配，那么个数为 dp[i - 1] [j - 1]</p>
<p>一部分是不用s[i - 1]来匹配，个数为 dp[i - 1] [j]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (s[i - <span class="number">1</span>] == t[j - <span class="number">1</span>]) &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + dp[i - <span class="number">1</span>][j];</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="两个字符串的删除操作">两个字符串的删除操作</span></h4>
<p><a href="https://programmercarl.com/0583.两个字符串的删除操作.html">动态规划：583.两个字符串的删除操作
(opens new window)</a>给定两个单词 word1 和 word2，找到使得 word1 和
word2 相同所需的最小步数，每步可以删除任意一个字符串中的一个字符。</p>
<p>本题和<a href="https://programmercarl.com/0115.不同的子序列.html">动态规划：115.不同的子序列
(opens new
window)</a>相比，其实就是两个字符串可以都可以删除了，情况虽说复杂一些，但整体思路是不变的。</p>
<ul>
<li>当word1[i - 1] 与 word2[j - 1]相同的时候</li>
<li>当word1[i - 1] 与 word2[j - 1]不相同的时候</li>
</ul>
<p>当word1[i - 1] 与 word2[j - 1]相同的时候，dp[i][j] = dp[i - 1] [j -
1];</p>
<p>当word1[i - 1] 与 word2[j - 1]不相同的时候，有2种情况：</p>
<p>情况一：删word1[i - 1]，最少操作次数为dp[i - 1] [j] + 1</p>
<p>情况二：删word2[j - 1]，最少操作次数为dp[i][j - 1] + 1</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (word1[i - <span class="number">1</span>] == word2[j - <span class="number">1</span>]) &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>];</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    dp[i][j] = <span class="built_in">min</span>(&#123;dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">2</span>, dp[i - <span class="number">1</span>][j] + <span class="number">1</span>, dp[i][j - <span class="number">1</span>] + <span class="number">1</span>&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="编辑距离">编辑距离</span></h4>
<p><a href="https://programmercarl.com/0072.编辑距离.html">动态规划：72.编辑距离
(opens new window)</a>给你两个单词 word1 和 word2，请你计算出将 word1
转换成 word2 所使用的最少操作数 。</p>
<p>编辑距离终于来了，<strong>有了前面三道题目的铺垫，应该有思路了</strong>，本题是两个字符串可以增删改，比
<a href="https://programmercarl.com/0392.判断子序列.html">动态规划：判断子序列
(opens new window)</a>，<a href="https://programmercarl.com/0115.不同的子序列.html">动态规划：不同的子序列
(opens new window)</a>，<a href="https://programmercarl.com/0583.两个字符串的删除操作.html">动态规划：两个字符串的删除操作
(opens new window)</a>都要复杂的多。</p>
<p>在确定递推公式的时候，首先要考虑清楚编辑的几种操作，整理如下：</p>
<ul>
<li>if (word1[i - 1] == word2[j - 1])
<ul>
<li>不操作</li>
</ul></li>
<li>if (word1[i - 1] != word2[j - 1])
<ul>
<li>增</li>
<li>删</li>
<li>换</li>
</ul></li>
</ul>
<p>也就是如上四种情况。</p>
<p>if (word1[i - 1] == word2[j - 1]) 那么说明不用任何编辑，dp[i][j]
就应该是 dp[i - 1] [j - 1]，即dp[i][j] = dp[i - 1] [j - 1];</p>
<p><strong>在整个动规的过程中，最为关键就是正确理解dp[i]
[j]的定义！</strong></p>
<p>if (word1[i - 1] != word2[j - 1])，此时就需要编辑了，如何编辑呢？</p>
<p>操作一：word1增加一个元素，使其word1[i - 1]与word2[j -
1]相同，那么就是以下标i-2为结尾的word1 与 i-1为结尾的word2的最近编辑距离
加上一个增加元素的操作。</p>
<p>即 dp[i][j] = dp[i - 1] [j] + 1;</p>
<p>操作二：word2添加一个元素，使其word1[i - 1]与word2[j -
1]相同，那么就是以下标i-1为结尾的word1 与 j-2为结尾的word2的最近编辑距离
加上一个增加元素的操作。</p>
<p>即 dp[i][j] = dp[i][j - 1] + 1;</p>
<p>这里有同学发现了，怎么都是添加元素，删除元素去哪了。</p>
<p><strong>word2添加一个元素，相当于word1删除一个元素</strong>，例如
word1 = "ad" ，word2 =
"a"，word2添加一个元素d，也就是相当于word1删除一个元素d，操作数是一样！</p>
<p>操作三：替换元素，word1替换word1[i - 1]，使其与word2[j -
1]相同，此时不用增加元素，那么以下标i-2为结尾的word1 与
j-2为结尾的word2的最近编辑距离 加上一个替换元素的操作。</p>
<p>即 dp[i][j] = dp[i - 1] [j - 1] + 1;</p>
<p>综上，当 if (word1[i - 1] != word2[j - 1]) 时取最小的，即：dp[i] [j]
= min({dp[i - 1] [j - 1], dp[i - 1] [j], dp[i][j - 1]}) + 1;</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (word1[i - <span class="number">1</span>] == word2[j - <span class="number">1</span>]) &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>];</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    dp[i][j] = <span class="built_in">min</span>(&#123;dp[i - <span class="number">1</span>][j - <span class="number">1</span>], dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>]&#125;) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3><span id="让字符串成为最小回文">==让字符串成为最小回文==</span></h3>
<p>https://leetcode-cn.com/problems/minimum-insertion-steps-to-make-a-string-palindrome/</p>
<h2><span id="六-回溯法">六、回溯法</span></h2>
<p><strong>一个决策树的遍历过程（回溯法）</strong>：一种通过探索所有可能的候选解来找出所有的解的算法。如果候选解被确认不是一个解（或者至少不是最后一个解），回溯算法会通过在上一步进行一些变化抛弃该解，即回溯并且再次尝试。</p>
<p>回溯法，一般可以解决如下几种问题：</p>
<ul>
<li>组合问题：N个数里面按一定规则找出k个数的集合</li>
<li>切割问题：一个字符串按一定规则有几种切割方式</li>
<li>子集问题：一个N个数的集合里有多少符合条件的子集</li>
<li>排列问题：N个数按一定规则全排列，有几种排列方式</li>
<li><strong>棋盘问题</strong>：N皇后，解数独等等</li>
</ul>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>博客分类目录设计</title>
    <url>/posts/3859BFD/</url>
    <content><![CDATA[<h2><span id="powelzys-blog">PoweLZY’s Blog</span></h2>
<blockquote>
<ul>
<li><p>比赛相关整理</p></li>
<li><p>好论文整理</p></li>
<li><p>公司整理的可开源笔记</p></li>
</ul>
</blockquote>
<h3><span id="分类目录">分类目录</span></h3>
<h4><span id="一-工程">一、[工程]</span></h4>
<ul>
<li><strong><font color="red"> 大数据处理</font></strong>
<ul>
<li>高维向量相似度匹配</li>
<li>Spark 基础</li>
</ul></li>
<li>计算机基础
<ul>
<li>计算机网络</li>
<li>数据库</li>
<li>操作系统</li>
</ul></li>
<li><strong><font color="blue">【开源工具】2.0</font></strong>
<ul>
<li>网络安全
<ul>
<li>【沙箱】</li>
<li>【zeek】</li>
</ul></li>
<li>深度学习
<ul>
<li>【Pytorch框架】</li>
</ul></li>
<li>画图
<ul>
<li>【network】</li>
<li>【matplotlib】</li>
</ul></li>
</ul></li>
<li><strong>数据结构</strong></li>
<li><strong>流畅的Python</strong></li>
</ul>
<h4><span id="二-算法">二、算法</span></h4>
<ul>
<li><strong>机器学习</strong>
<ul>
<li>理论基础</li>
<li>线性模型</li>
<li>决策树（拆分 + 总结）</li>
<li>支持向量机</li>
<li>贝叶斯分类器</li>
<li>集成学习</li>
<li>聚类</li>
<li>降维</li>
<li>【概率图模型】</li>
<li>推荐算法</li>
<li>异常检测</li>
<li><strong><font color="red">【社区发现】</font></strong>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/556291759">万物皆网络，万字长文详解<em>社区发现</em>算法Louvain</a></li>
</ul></li>
<li><strong><font color="red">反欺诈算法</font></strong>
<ul>
<li>SynchroTrap、Oddball、LockInfer、CatchSync等<a href="https://www.zhihu.com/search?q=反欺诈算法&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2937955407%7D">反欺诈算法</a>，深入研究应用，春花秋月又一年。</li>
</ul></li>
</ul></li>
<li>特征工程</li>
<li>模型部署</li>
<li><strong><font color="red">[深度学习]</font></strong>
<ul>
<li>CNN</li>
<li>RNN
<ul>
<li>RNN</li>
<li>LSTM</li>
<li>GRU</li>
</ul></li>
<li>Seq2Seq
<ul>
<li>Attention</li>
<li>Transformer</li>
<li>AutoEncoder</li>
</ul></li>
<li>GNN</li>
<li>NLP</li>
<li>模型训练</li>
<li>优化算法</li>
</ul></li>
</ul>
<h4><span id="三-应用">三、[应用]</span></h4>
<ul>
<li><strong><font color="red"> 算法应用</font></strong>
<ul>
<li>网络安全
<ul>
<li>【身份认证】</li>
<li><strong><font color="red">恶意软件检测</font></strong>【tags：对论文，开源项目，比赛WP等总结性整理】</li>
<li><strong><font color="red">恶意加密流量检测</font></strong></li>
<li>【恶意域名识别】</li>
<li>【智能安全运维】
<ul>
<li>【TODO】：《信息安全技术-网络安全态势感知通用技术要求》：https://mp.weixin.qq.com/s/Cla3XmPIVaCBKIVNU-TAFQ</li>
</ul></li>
<li>【威胁情报】</li>
<li>高级威胁检测</li>
</ul></li>
<li>业务安全
<ul>
<li>业务安全常用算法归纳</li>
<li>风控算法基础</li>
<li>【接口安全-waap】</li>
</ul></li>
<li>【AI安全】
<ul>
<li></li>
</ul></li>
</ul></li>
<li><strong>工业落地：企业公开发表的论文或白皮书</strong>
<ul>
<li>网络安全
<ul>
<li><strong><font color="red">恶意软件检测</font></strong></li>
</ul></li>
<li>业务安全
<ul>
<li><strong><font color="red">
【补充WAAP产品白皮书】</font></strong></li>
</ul></li>
</ul></li>
<li><strong>算法比赛：算法比赛的top方案</strong>
<ul>
<li><font color="red">网络安全</font>
<ul>
<li>【360
BDCI】：https://github.com/PowerLZY/malware_classification_bdci</li>
<li>【2021 Datacon】：</li>
<li>【2020 Datacon】：</li>
</ul></li>
<li>业务安全</li>
</ul></li>
<li><strong>学术前沿：学术论文</strong>
<ul>
<li>网络安全
<ul>
<li><strong><font color="red">恶意软件检测</font></strong></li>
<li><strong><font color="red">恶意加密流量检测</font></strong></li>
<li>【AI安全】</li>
</ul></li>
<li>业务安全
<ul>
<li></li>
</ul></li>
</ul></li>
</ul>
<h4><span id="四-随笔">四、随笔</span></h4>
<ul>
<li>面试准备</li>
<li>面试汇总</li>
<li>面试必看-ML整理</li>
<li>面试必看-DL整理</li>
<li>安全算法工程师的自我修养
<ul>
<li>风控心得</li>
<li>内容安全心得</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>博客搭建</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（10）回溯</title>
    <url>/posts/2G4BJ32/</url>
    <content><![CDATA[<h2><span id="回溯-子集-组合-排列-岛屿">回溯 - 子集、组合、排列、岛屿</span></h2>
<blockquote>
<p>result = [] def backtrack(路径, 选择列表): if 满足结束条件:
result.add(路径) return for 选择 in 选择列表: 做选择 backtrack(路径,
选择列表) 撤销选择</p>
</blockquote>
<h4><span id="剑指-offer-ii-079所有子集"></span></h4>
<blockquote>
<p><a href="https://leetcode-cn.com/problems/combination-sum/">39.组合总和</a></p>
<p><a href="https://leetcode-cn.com/problems/combination-sum-ii/">40.
组合总和 II</a></p>
<p><a href="https://leetcode-cn.com/problems/permutations/">46.
全排列</a></p>
<p><a href="https://leetcode-cn.com/problems/permutations-ii/">47.
全排列 II</a></p>
<p><a href="https://leetcode-cn.com/problems/subsets/">78. 子集</a></p>
<p><a href="https://leetcode-cn.com/problems/subsets-ii/">90. 子集
II</a></p>
</blockquote>
<p>给定一个整数数组 <code>nums</code> ，数组中的元素
<strong>互不相同</strong> 。返回该数组所有可能的子集（幂集）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">输出：[[],[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">1</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">subsets</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        ans = []</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtrace</span>(<span class="params">idx, tmp</span>):</span><br><span class="line">            ans.append(tmp[:])</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(idx, n):</span><br><span class="line">                tmp.append(nums[j])</span><br><span class="line">                backtrace(j + <span class="number">1</span>, tmp)</span><br><span class="line">                tmp.pop()</span><br><span class="line">        backtrace(<span class="number">0</span>, [])</span><br><span class="line">        <span class="keyword">return</span> ans</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">subsets</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="comment"># import itertools.combinations</span></span><br><span class="line">        ans = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums) + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> tmp <span class="keyword">in</span> itertools.combinations(nums, i):</span><br><span class="line">                ans.append(tmp)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-12-矩阵中的路径"></span></h4>
<p>给定一个 m x n 二维字符网格 board 和一个字符串单词 word 。如果 word
存在于网格中，返回 true ；否则，返回 false
。单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。</p>
<p>例如，在下面的 3×4 的矩阵中包含单词
"ABCCED"（单词中的字母已标出）。</p>
<figure>
<img src="https://assets.leetcode.com/uploads/2020/11/04/word2.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">exist</span>(<span class="params">self, board: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">str</span>]], word: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">      m = <span class="built_in">len</span>(board)</span><br><span class="line">      n = <span class="built_in">len</span>(board[<span class="number">0</span>])</span><br><span class="line">      <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">x, y, index</span>):</span><br><span class="line">           <span class="keyword">if</span> index == <span class="built_in">len</span>(word):</span><br><span class="line">           		<span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">           <span class="keyword">for</span> dx, dy <span class="keyword">in</span> ((-<span class="number">1</span>, <span class="number">0</span>), (<span class="number">1</span>, <span class="number">0</span>), (<span class="number">0</span>, -<span class="number">1</span>), (<span class="number">0</span>, <span class="number">1</span>)):</span><br><span class="line">               nx, ny = x + dx, y + dy</span><br><span class="line">               <span class="keyword">if</span> <span class="number">0</span> &lt;= nx &lt; m <span class="keyword">and</span> <span class="number">0</span> &lt;= ny &lt; n <span class="keyword">and</span> board[nx][ny] == word[index]:</span><br><span class="line">                   board[nx][ny] = <span class="string">&#x27;/&#x27;</span></span><br><span class="line">               		 <span class="keyword">if</span> dfs(nx, ny, index + <span class="number">1</span>):</span><br><span class="line">                       <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">                   board[nx][ny] = word[index]</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">      <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">          <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">              <span class="keyword">if</span> board[i][j] == word[<span class="number">0</span>]:</span><br><span class="line">                  board[i][j] = <span class="string">&#x27;/&#x27;</span></span><br><span class="line">              		<span class="keyword">if</span> dfs(i, j, <span class="number">1</span>):</span><br><span class="line">                  		<span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">               		board[i][j] = word[<span class="number">0</span>]</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-13-机器人的运动范围"></span></h4>
<p>地上有一个m行n列的方格，从坐标 [0,0] 到坐标 [m-1,n-1]
。<strong>一个机器人从坐标 [0, 0]
的格子开始移动，它每次可以向左、右、上、下移动一格（不能移动到方格外），也不能进入行坐标和列坐标的数位之和大于k的格子</strong>。例如，当k为18时，机器人能够进入方格
[35, 37] ，因为3+5+3+7=18。但它不能进入方格 [35,
38]，因为3+5+3+8=19。请问该机器人能够到达多少个格子？</p>
<ul>
<li>bfs、bfs、岛屿面积</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">movingCount</span>(<span class="params">self, m: <span class="built_in">int</span>, n: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># bfs</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">sum_</span>(<span class="params">x, y</span>):</span><br><span class="line">            <span class="keyword">return</span> x%<span class="number">10</span> + x//<span class="number">10</span> +  y%<span class="number">10</span> + y//<span class="number">10</span></span><br><span class="line">        que = collections.deque()</span><br><span class="line">        que.append((<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">        s = <span class="built_in">set</span>()</span><br><span class="line">        s.add((<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">        <span class="keyword">while</span> que:</span><br><span class="line">            x, y = que.popleft()</span><br><span class="line">            <span class="keyword">for</span> i, j <span class="keyword">in</span> [(x + <span class="number">1</span>, y), (x, y + <span class="number">1</span>)]:</span><br><span class="line">                <span class="keyword">if</span> <span class="number">0</span> &lt;= i &lt; m <span class="keyword">and</span> <span class="number">0</span> &lt;= j &lt; n <span class="keyword">and</span> (i, j) <span class="keyword">not</span> <span class="keyword">in</span> s <span class="keyword">and</span> sum_(i,j) &lt;= k:</span><br><span class="line">                    que.append((i, j))</span><br><span class="line">                    s.add((i, j))</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(s)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">movingCount</span>(<span class="params">self, m: <span class="built_in">int</span>, n: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># dfs【向下向右】</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">i: <span class="built_in">int</span>, j: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">if</span> i &gt;= m <span class="keyword">or</span> j &gt;= n <span class="keyword">or</span> sum_(i, j) &gt; k <span class="keyword">or</span> f[i][j] == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            f[i][j] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span> + dfs(i + <span class="number">1</span>, j) + dfs(i, j + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">sum_</span>(<span class="params">x, y</span>):</span><br><span class="line">            <span class="keyword">return</span> x%<span class="number">10</span> + x//<span class="number">10</span> +  y%<span class="number">10</span> + y//<span class="number">10</span></span><br><span class="line">        </span><br><span class="line">        f = [[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m)]</span><br><span class="line">        <span class="keyword">return</span> dfs(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">movingCount</span>(<span class="params">self, m: <span class="built_in">int</span>, n: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 回溯: 岛屿面积  </span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">sumGrid</span>(<span class="params">x, y</span>):</span><br><span class="line">            <span class="keyword">return</span> x%<span class="number">10</span> + x//<span class="number">10</span> +  y%<span class="number">10</span> + y//<span class="number">10</span></span><br><span class="line">        visited = <span class="built_in">set</span>()</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtrace</span>(<span class="params">x, y</span>):</span><br><span class="line">            visited.add((x, y))</span><br><span class="line">            <span class="keyword">for</span> i, j <span class="keyword">in</span> [(x-<span class="number">1</span>, y), (x, y-<span class="number">1</span>), (x, y+<span class="number">1</span>), (x+<span class="number">1</span>, y)]:</span><br><span class="line">                <span class="keyword">if</span> <span class="number">0</span> &lt;= i &lt; m <span class="keyword">and</span> <span class="number">0</span>&lt;= j &lt; n <span class="keyword">and</span> (i, j) <span class="keyword">not</span> <span class="keyword">in</span> visited <span class="keyword">and</span> sumGrid(i, j) &lt;= k:</span><br><span class="line">                    backtrace(i, j)</span><br><span class="line">        backtrace(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(visited) </span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-34-二叉树中和为某一值的路径"></span></h4>
<p>给你二叉树的根节点 root 和一个整数目标和 targetSum
，<strong>找出==所有==从根节点到叶子节点
路径总和等于给定目标和的路径。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pathSum</span>(<span class="params">self, root: TreeNode, target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtrace</span>(<span class="params">root, tmp, target</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right <span class="keyword">and</span> target == root.val:</span><br><span class="line">                ans.append(tmp[:] + [root.val])</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            tmp.append(root.val)</span><br><span class="line">            backtrace(root.left, tmp, target - root.val)</span><br><span class="line">            backtrace(root.right, tmp, target - root.val)</span><br><span class="line">            tmp.pop()</span><br><span class="line">        ans = []</span><br><span class="line">        backtrace(root, [], target)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-38-字符串的排列"></span></h4>
<ul>
<li>https://leetcode.cn/problems/zi-fu-chuan-de-pai-lie-lcof/solution/dai-ma-sui-xiang-lu-jian-zhi-offer-38-zi-gwt6/</li>
</ul>
<p>输入一个字符串，打印出该字符串中字符的<strong>所有排列</strong>。</p>
<ul>
<li><strong>还要强调的是==去重一定要对元素经行排序==，这样我们才方便通过相邻的节点来判断是否重复使用了</strong>。</li>
<li><strong>组合问题和排列问题是在树形结构的叶子节点上收集结果，而子集问题就是取树上所有节点的结果</strong>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">  	<span class="keyword">def</span> <span class="title function_">permutation</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">        <span class="comment"># itertools.permutations(s)</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">set</span>(<span class="string">&quot;&quot;</span>.join(t) <span class="keyword">for</span> t <span class="keyword">in</span> itertools.permutations(s)))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">permuteUnique</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> nums: </span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        res = []</span><br><span class="line">        used = <span class="built_in">set</span>() <span class="comment"># [0] * len(nums)</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtracking</span>(<span class="params">path</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(path) == <span class="built_in">len</span>(nums):</span><br><span class="line">                res.append(path[:])</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">                <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> used:</span><br><span class="line">                    <span class="keyword">if</span> i&gt;<span class="number">0</span> <span class="keyword">and</span> nums[i] == nums[i-<span class="number">1</span>] <span class="keyword">and</span> i-<span class="number">1</span> <span class="keyword">not</span> <span class="keyword">in</span> used:</span><br><span class="line">                      	<span class="comment"># 重复剪枝</span></span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                    used.add(i)</span><br><span class="line">                    path.append(nums[i])</span><br><span class="line">                    backtracking(path)</span><br><span class="line">                    path.pop()</span><br><span class="line">                    used.remove(i)</span><br><span class="line">        <span class="comment"># 记得给nums排序</span></span><br><span class="line">        nums.sort()</span><br><span class="line">        backtracking([])</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-081允许重复选择元素的组合"></span></h4>
<p><strong>给定一个无重复元素的正整数数组 candidates 和一个正整数
target</strong> ，找出 candidates 中所有可以使数字和为目标数 target
的唯一组合。<strong>candidates
中的数字可以无限制重复被选取。如果至少一个所选数字数量不同，则两种组合是不同的</strong>。</p>
<blockquote>
<p>输入: candidates = [2,3,6,7], target = 7 输出: [[7],[2,2,3]]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">combinationSum</span>(<span class="params">self, candidates: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="comment"># 回溯，无重复元素，根据剩余值凑成目标</span></span><br><span class="line">        ans = []</span><br><span class="line">        path = []</span><br><span class="line">        candidates.sort() <span class="comment"># 预先排序，</span></span><br><span class="line">        <span class="comment"># 收集逻辑为target == 0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtracking</span>(<span class="params">index,path,target</span>):</span><br><span class="line">            <span class="keyword">if</span> index &gt;= <span class="built_in">len</span>(candidates) <span class="keyword">or</span> target &lt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line">            <span class="keyword">if</span> target == <span class="number">0</span>: <span class="comment"># 收集条件</span></span><br><span class="line">                ans.append(path[:])</span><br><span class="line">                <span class="keyword">return</span>    </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(index,<span class="built_in">len</span>(candidates)):  <span class="comment"># 注意可以重复收集          </span></span><br><span class="line">                path.append(candidates[i])  <span class="comment"># 做选择</span></span><br><span class="line">                backtracking(i,path,target-candidates[i])</span><br><span class="line">                path.pop() <span class="comment"># 取消选择</span></span><br><span class="line">         </span><br><span class="line">        backtracking(<span class="number">0</span>,[],target)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-082含有重复元素集合的组合"></span></h4>
<p><strong>给定一个可能有重复数字的整数数组 <code>candidates</code>
和一个目标数 <code>target</code></strong> ，找出 <code>candidates</code>
中所有可以使数字和为 <code>target</code> 的组合。</p>
<p><code>candidates</code>
中的每个数字在每个组合中只能使用一次，解集不能包含重复的组合。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入: candidates = [<span class="number">10</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">6</span>,<span class="number">1</span>,<span class="number">5</span>], target = <span class="number">8</span>,</span><br><span class="line">输出:</span><br><span class="line">[</span><br><span class="line">[<span class="number">1</span>,<span class="number">1</span>,<span class="number">6</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>],</span><br><span class="line">[<span class="number">1</span>,<span class="number">7</span>],</span><br><span class="line">[<span class="number">2</span>,<span class="number">6</span>]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">combinationSum2</span>(<span class="params">self, candidates: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        ans, n = [], <span class="built_in">len</span>(candidates)</span><br><span class="line">        candidates.sort()</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtrace</span>(<span class="params">idx, tmp, target</span>):</span><br><span class="line">            <span class="keyword">if</span> idx &gt; n <span class="keyword">or</span> target &lt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">if</span> target == <span class="number">0</span>:</span><br><span class="line">                ans.append(tmp[:])</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(idx, n):</span><br><span class="line">                <span class="keyword">if</span> i &gt; idx <span class="keyword">and</span> candidates[i] == candidates[i - <span class="number">1</span>]:</span><br><span class="line">                    <span class="comment"># 去重：让递归的同一级不出现相同元素、递归的不同级可以出现相同元素</span></span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                tmp.append(candidates[i])</span><br><span class="line">                backtrace(i + <span class="number">1</span>, tmp, target - candidates[i])</span><br><span class="line">                tmp.pop()</span><br><span class="line">        backtrace(<span class="number">0</span>, [], target)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-083没有重复元素集合的全排列"></span></h4>
<p>给定一个不含重复数字的整数数组 <code>nums</code> ，返回其
<strong>所有可能的全排列</strong> 。可以 <strong>按任意顺序</strong>
返回答案。</p>
<blockquote>
<p>输入：nums = [1,2,3]
输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">permute</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="comment"># 库函数[数组交换]、回溯模版</span></span><br><span class="line">        <span class="comment"># return list(itertools.permutations(nums))</span></span><br><span class="line">        ans, n = [], <span class="built_in">len</span>(nums)</span><br><span class="line">        visited = <span class="built_in">set</span>()</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtrace</span>(<span class="params">idx, tmp</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(tmp) == n:</span><br><span class="line">                ans.append(tmp[:])</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">                    visited.add(i)</span><br><span class="line">                    tmp.append(nums[i])</span><br><span class="line">                    backtrace(i + <span class="number">1</span>, tmp)</span><br><span class="line">                    tmp.pop()</span><br><span class="line">                    visited.remove(i)</span><br><span class="line">        backtrace(<span class="number">0</span> ,[])</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-084含有重复元素集合的全排列"></span></h4>
<p>给定一个可包含重复数字的整数集合 <code>nums</code>
，<strong>按任意顺序</strong> 返回它所有不重复的全排列。</p>
<blockquote>
<p>输入：nums = [1,1,2] 输出： [[1,1,2], [1,2,1], [2,1,1]]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">permuteUnique</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="comment"># visited 记录访问节点的集合</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        ans = []</span><br><span class="line">        vis = <span class="built_in">set</span>()</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtrace</span>(<span class="params">tmp</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(tmp) == n:</span><br><span class="line">                ans.append(tmp[:])</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                <span class="keyword">if</span> i <span class="keyword">in</span> vis:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>] <span class="keyword">and</span> i - <span class="number">1</span> <span class="keyword">not</span> <span class="keyword">in</span> vis:</span><br><span class="line">                    <span class="comment"># not in 保留顺序剪枝 </span></span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                vis.add(i)</span><br><span class="line">                backtrace(tmp + [nums[i]])</span><br><span class="line">                vis.remove(i)</span><br><span class="line">        nums.sort()</span><br><span class="line">        backtrace([])</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="22-括号生成"></span></h4>
<p>数字 <code>n</code>
代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且
<strong>有效的</strong> 括号组合。</p>
<blockquote>
<p>输入：n = 3 输出：["((()))","(()())","(())()","()(())","()()()"]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generateParenthesis</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">        <span class="comment"># 回溯</span></span><br><span class="line">        <span class="comment"># 第一步：得到全部 2^(2n) 种组合，然后再根据我们刚才总结出的合法括号组合的性质筛选出合法的组合</span></span><br><span class="line">        <span class="comment"># 第二步：剪枝  1、可用左括号大于右括号 2、括号可用小于0</span></span><br><span class="line">        ans = []</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtrace</span>(<span class="params">left, right, tmp</span>):</span><br><span class="line">            <span class="keyword">if</span> left &gt; right:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">if</span> left &lt; <span class="number">0</span>  <span class="keyword">or</span> right &lt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">if</span> left == <span class="number">0</span> <span class="keyword">and</span> right == <span class="number">0</span>:</span><br><span class="line">                ans.append(<span class="string">&quot;&quot;</span>.join(tmp[:]))</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            tmp.append(<span class="string">&#x27;(&#x27;</span>)</span><br><span class="line">            backtrace(left - <span class="number">1</span>, right, tmp)</span><br><span class="line">            tmp.pop()</span><br><span class="line"></span><br><span class="line">            tmp.append(<span class="string">&#x27;)&#x27;</span>)</span><br><span class="line">            backtrace(left, right - <span class="number">1</span>, tmp)</span><br><span class="line">            tmp.pop()</span><br><span class="line">        backtrace(n, n, [])</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-086-分割回文子字符串"></span></h4>
<p>给定一个字符串 s ，请将 s 分割成一些子串，使每个子串都是 回文串
，返回 s 所有可能的分割方案。回文串 是正着读和反着读都一样的字符串。</p>
<blockquote>
<p>输入：s = "google"
输出：[["g","o","o","g","l","e"],["g","oo","g","l","e"],["goog","l","e"]]</p>
</blockquote>
<ul>
<li><strong><font color="red"> 动态规划预处理 +
回溯全排列</font></strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">partition</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">str</span>]]:</span><br><span class="line">        <span class="comment"># 动态规划预处理 + 回溯全排列条件</span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        dp = [[<span class="literal">False</span>] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            dp[i][i] = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, n):</span><br><span class="line">                <span class="keyword">if</span> s[i] == s[j]:</span><br><span class="line">                    <span class="keyword">if</span> j - i &lt;= <span class="number">1</span> <span class="keyword">or</span> dp[i + <span class="number">1</span>][j - <span class="number">1</span>]:</span><br><span class="line">                        dp[i][j] = <span class="literal">True</span></span><br><span class="line">        ans = []</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtrace</span>(<span class="params">idx, tmp</span>):</span><br><span class="line">            <span class="keyword">if</span> idx == n:</span><br><span class="line">                ans.append(tmp[:])</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(idx, n):</span><br><span class="line">                <span class="keyword">if</span> dp[idx][i]:</span><br><span class="line">                    tmp.append(s[idx: i + <span class="number">1</span>])</span><br><span class="line">                    backtrace(i + <span class="number">1</span>, tmp)</span><br><span class="line">                    tmp.pop()</span><br><span class="line">        backtrace(<span class="number">0</span>, [])</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="93-复原-ip-地址-回溯剪枝"></span></h4>
<p><strong>有效 IP 地址</strong> 正好由四个整数（每个整数位于
<code>0</code> 到 <code>255</code> 之间组成，且不能含有前导
<code>0</code>），整数之间用 <code>'.'</code> 分隔。</p>
<ul>
<li>例如："0.1.2.201" 和 "192.168.1.1" 是 有效 IP 地址，但是
"0.011.255.245"、"192.168.1.312" 和 "192.168@1.1" 是 <strong>无效 IP
地址。</strong></li>
</ul>
<p><strong>给定一个只包含数字的字符串 s ，用以表示一个 IP
地址，返回所有可能的有效 IP 地址，这些地址可以通过在 s 中插入 '.'
来形成。</strong>你 不能 重新排序或删除 s 中的任何数字。你可以按 任何
顺序返回答案。</p>
<blockquote>
<p>输入：s = "25525511135" 输出：["255.255.11.135","255.255.111.35"]</p>
</blockquote>
<p><img src="https://pic.leetcode-cn.com/b581bdde1cef982f0af3182af17fc3c41960c76a7445af0dcfd445c89b4c2eaa-「力扣」第 93 题：复原 IP 地址-1.png" alt="「力扣」第 93 题：复原 IP 地址-1.png" style="zoom: 33%;"></p>
<ul>
<li>如果还没有找到 4 段 IP 地址就已经遍历完了字符串，那么提前回溯;</li>
<li>由于不能有前导零，如果当前数字为 0，那么这一段 IP 地址只能为 0;</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">restoreIpAddresses</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">        SEG_COUNT = <span class="number">4</span></span><br><span class="line">        ans = <span class="built_in">list</span>()</span><br><span class="line">        segments = [<span class="number">0</span>] * SEG_COUNT</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">segId: <span class="built_in">int</span>, segStart: <span class="built_in">int</span></span>):</span><br><span class="line">            <span class="comment"># 如果找到了 4 段 IP 地址并且遍历完了字符串，那么就是一种答案</span></span><br><span class="line">            <span class="keyword">if</span> segId == SEG_COUNT:</span><br><span class="line">                <span class="keyword">if</span> segStart == <span class="built_in">len</span>(s):</span><br><span class="line">                    ipAddr = <span class="string">&quot;.&quot;</span>.join(<span class="built_in">str</span>(seg) <span class="keyword">for</span> seg <span class="keyword">in</span> segments)</span><br><span class="line">                    ans.append(ipAddr)</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="comment"># 如果还没有找到 4 段 IP 地址就已经遍历完了字符串，那么提前回溯</span></span><br><span class="line">            <span class="keyword">if</span> segStart == <span class="built_in">len</span>(s):</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="comment"># 由于不能有前导零，如果当前数字为 0，那么这一段 IP 地址只能为 0</span></span><br><span class="line">            <span class="keyword">if</span> s[segStart] == <span class="string">&quot;0&quot;</span>:</span><br><span class="line">                segments[segId] = <span class="number">0</span></span><br><span class="line">                dfs(segId + <span class="number">1</span>, segStart + <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 一般情况，枚举每一种可能性并递归</span></span><br><span class="line">            addr = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> segEnd <span class="keyword">in</span> <span class="built_in">range</span>(segStart, <span class="built_in">len</span>(s)):</span><br><span class="line">                addr = addr * <span class="number">10</span> + (<span class="built_in">ord</span>(s[segEnd]) - <span class="built_in">ord</span>(<span class="string">&quot;0&quot;</span>))</span><br><span class="line">                <span class="keyword">if</span> <span class="number">0</span> &lt; addr &lt;= <span class="number">0xFF</span>:</span><br><span class="line">                    segments[segId] = addr</span><br><span class="line">                    dfs(segId + <span class="number">1</span>, segEnd + <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        dfs(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（12）图</title>
    <url>/posts/BZK9HE/</url>
    <content><![CDATA[<h2><span id="图论算法从入门到放下">图论算法从入门到放下</span></h2>
<blockquote>
<p>https://leetcode.cn/circle/discuss/FyPTTM/</p>
</blockquote>
<h4><span id="主要内容一览">主要内容一览</span></h4>
<p><img src="https://pic.leetcode-cn.com/1655461415-YbBmuc-graph_mind.png" alt="graph_mind.png" style="zoom: 33%;"></p>
<h2><span id="岛屿问题">岛屿问题</span></h2>
<h4><span id="剑指-offer-ii-105岛屿的最大面积"></span></h4>
<p>给定一个由 0 和 1 组成的非空二维数组 grid
，用来表示海洋岛屿地图。一个 岛屿 是由一些相邻的 1 (代表土地)
构成的组合，这里的「相邻」要求两个 1
必须在水平或者竖直方向上相邻。你可以假设 grid 的四个边缘都被
0（代表水）包围着。</p>
<p>找到给定的二维数组中最大的岛屿面积。如果没有岛屿，则返回面积为 0
。</p>
<p>示例 1:</p>
<p><img src="https://pic.leetcode-cn.com/1626667010-nSGPXz-image.png" alt="img" style="zoom:33%;"></p>
<p>输入: grid =
[[0,0,1,0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,0,1,1,1,0,0,0],[0,1,1,0,1,0,0,0,0,0,0,0,0],[0,1,0,0,1,1,0,0,1,0,1,0,0],[0,1,0,0,1,1,0,0,1,1,1,0,0],[0,0,0,0,0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,1,1,1,0,0,0],[0,0,0,0,0,0,0,1,1,0,0,0,0]]
输出: 6 解释: 对于上面这个给定矩阵应返回 6。注意答案不应该是 11
，因为岛屿只能包含水平或垂直的四个方向的 1 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxAreaOfIsland</span>(<span class="params">self, grid: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 深度优先搜索 空间复杂度o(m*n)</span></span><br><span class="line">        m, n = <span class="built_in">len</span>(grid), <span class="built_in">len</span>(grid[<span class="number">0</span>])</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">x, y</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            s = <span class="number">1</span></span><br><span class="line">            grid[x][y] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i, j <span class="keyword">in</span> [(x - <span class="number">1</span>, y), (x, y - <span class="number">1</span>), (x + <span class="number">1</span>, y), (x, y + <span class="number">1</span>)]:</span><br><span class="line">                <span class="keyword">if</span> i &lt; <span class="number">0</span> <span class="keyword">or</span> j &lt; <span class="number">0</span> <span class="keyword">or</span> i == m <span class="keyword">or</span> j == n <span class="keyword">or</span> grid[i][j]!=<span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                s += dfs(i, j)</span><br><span class="line">            <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                <span class="keyword">if</span> grid[i][j] == <span class="number">1</span>:</span><br><span class="line">                    res = <span class="built_in">max</span>(res, dfs(i, j))</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="743网络延迟时间"></span></h4>
<p>有 n 个网络节点，标记为 1 到 n。给你一个列表 times，表示信号经过 有向
边的传递时间。 times[i] = (ui, vi, wi)，其中 ui 是源节点，vi
是目标节点， wi 是一个信号从源节点传递到目标节点的时间。</p>
<p>现在，从某个节点 K
发出一个信号。需要多久才能使所有节点都收到信号？如果不能使所有节点收到信号，返回
-1 。</p>
<ul>
<li>图最短路径【<strong>优先队列</strong>】</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">networkDelayTime</span>(<span class="params">self, times: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], n: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        g = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        <span class="keyword">for</span> x, y, time <span class="keyword">in</span> times:</span><br><span class="line">            g[x - <span class="number">1</span>].append((y - <span class="number">1</span>, time))</span><br><span class="line"></span><br><span class="line">        dist = [<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)] * n</span><br><span class="line">        dist[k - <span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">        q = [(<span class="number">0</span>, k - <span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">while</span> q:</span><br><span class="line">            time, x = heapq.heappop(q)</span><br><span class="line">            <span class="keyword">if</span> dist[x] &lt; time:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">for</span> y, time <span class="keyword">in</span> g[x]:</span><br><span class="line">                <span class="keyword">if</span> (d := dist[x] + time) &lt; dist[y]:</span><br><span class="line">                    dist[y] = d</span><br><span class="line">                    heapq.heappush(q, (d, y))</span><br><span class="line"></span><br><span class="line">        ans = <span class="built_in">max</span>(dist)</span><br><span class="line">        <span class="keyword">return</span> ans <span class="keyword">if</span> ans &lt; <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">else</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-106二分图"></span></h4>
<p>存在一个 无向图 ，图中有 n 个节点。其中每个节点都有一个介于 0 到 n -
1 之间的唯一编号。给定一个二维数组 graph ，表示图，其中 graph[u]
是一个节点数组，由节点 u 的邻接节点组成。形式上，对于 graph[u] 中的每个
v ，都存在一条位于节点 u 和节点 v 之间的无向边。</p>
<p><strong>二分图
定义</strong>：如果能将一个图的节点集合分割成两个独立的子集 A 和 B
，并使图中的每一条边的两个节点一个来自 A 集合，一个来自 B
集合，就将这个图称为 二分图 。</p>
<p><strong>示例 1：</strong></p>
<figure>
<img src="https://assets.leetcode.com/uploads/2020/10/21/bi2.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>输入：graph = [[1,2,3],[0,2],[0,1,3],[0,2]] 输出：false
解释：不能将节点分割成两个独立的子集，以使每条边都连通一个子集中的一个节点与另一个子集中的一个节点。</p>
<ul>
<li>DFS【染色问题】、并查集</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isBipartite</span>(<span class="params">self, graph: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="comment"># 广度优先遍历 [推荐]</span></span><br><span class="line">        n = <span class="built_in">len</span>(graph)</span><br><span class="line">        uncolor, red, green = <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">        color = [<span class="number">0</span>] * n</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> color[i] == uncolor:</span><br><span class="line">                color[i] = red</span><br><span class="line">                q = deque([i])</span><br><span class="line">                <span class="keyword">while</span> q:</span><br><span class="line">                    node = q.popleft()</span><br><span class="line">                    nei = green <span class="keyword">if</span> color[node] == red <span class="keyword">else</span> red</span><br><span class="line">                    <span class="keyword">for</span> j <span class="keyword">in</span> graph[node]:</span><br><span class="line">                        <span class="keyword">if</span> color[j] == uncolor:</span><br><span class="line">                            color[j] = nei</span><br><span class="line">                            q.append(j)</span><br><span class="line">                        <span class="keyword">elif</span> color[j] != nei:</span><br><span class="line">                            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isBipartite</span>(<span class="params">self, graph: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="comment"># 深度优先遍历 【不推荐】</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">i: <span class="built_in">int</span>, c: <span class="built_in">int</span></span>):</span><br><span class="line">            <span class="keyword">nonlocal</span> res</span><br><span class="line">            nei = green <span class="keyword">if</span> c == red <span class="keyword">else</span> red</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> graph[i]:</span><br><span class="line">                <span class="keyword">if</span> color[j] == uncolor:</span><br><span class="line">                    color[j] = nei</span><br><span class="line">                    dfs(j, nei)</span><br><span class="line">                <span class="keyword">elif</span> color[j] != nei:</span><br><span class="line">                    res = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        n = <span class="built_in">len</span>(graph)</span><br><span class="line">        uncolor, red, green = <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span></span><br><span class="line">        color = [<span class="number">0</span>] * n</span><br><span class="line">        res = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> color[i] == uncolor <span class="keyword">and</span> res:</span><br><span class="line">                dfs(i, red)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># def isBipartite(self, graph: List[List[int]]) -&gt; bool:</span></span><br><span class="line">    <span class="comment">#     # 并查集 【了解】</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（11）动态规划</title>
    <url>/posts/1QG49BK/</url>
    <content><![CDATA[<h1><span id="五-动态规划"></span></h1>
<figure>
<img src="https://images.zsxq.com/FvoG8qppuOWSNhXBbj27ShBAJw0G?imageMogr2/auto-orient/quality/100!/ignore-error/1&amp;e=1648742399&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:q36Nzw1NTcg-NvuvnNyOWSZ_mdI=" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>首先，动态规划问题的一般形式就是==求最值==</strong>。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，比如说让你求<strong>最长</strong>递增子序列呀，<strong>最小</strong>编辑距离呀等等。<strong>求解动态规划的核心问题是穷举</strong>。首先，动态规划的穷举有点特别，因为这类问题<strong>存在「重叠子问题」</strong>，如果暴力穷举的话效率会极其低下，所以需要「==备忘录」或者「DP
table」==来优化穷举过程，避免不必要的计算。而且，动态规划问题一定会<strong>具备「最优子结构」</strong>，才能通过子问题的最值得到原问题的最值。</p>
<p>另外，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，只有列出<strong>正确的「状态转移方程」</strong>，才能正确地穷举。</p>
<p>以上提到的<strong>重叠子问题、最优子结构、状态转移方程</strong>就是动态规划三要素。具体什么意思等会会举例详解，但是在实际的算法问题中，<strong>写出状态转移方程是最困难的</strong>，这也就是为什么很多朋友觉得动态规划问题困难的原因，我来提供我研究出来的一个思维框架，辅助你思考状态转移方程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 初始化 base case</span></span><br><span class="line">dp[<span class="number">0</span>][<span class="number">0</span>][...] = base</span><br><span class="line"><span class="comment"># 进行状态转移</span></span><br><span class="line"><span class="keyword">for</span> 状态<span class="number">1</span> <span class="keyword">in</span> 状态<span class="number">1</span>的所有取值：</span><br><span class="line">    <span class="keyword">for</span> 状态<span class="number">2</span> <span class="keyword">in</span> 状态<span class="number">2</span>的所有取值：</span><br><span class="line">        <span class="keyword">for</span> ...</span><br><span class="line">            dp[状态<span class="number">1</span>][状态<span class="number">2</span>][...] = 求最值(选择<span class="number">1</span>，选择<span class="number">2.</span>..)</span><br></pre></td></tr></table></figure>
<h2><span id="51-背包问题"><strong>5.1 背包问题</strong></span></h2>
<p>https://leetcode-cn.com/problems/coin-change/solution/dai-ma-sui-xiang-lu-dai-ni-xue-tou-wan-q-80r7/</p>
<figure>
<img src="https://img-blog.csdnimg.cn/20210117171307407.png" alt="416.分割等和子集1">
<figcaption aria-hidden="true">416.分割等和子集1</figcaption>
</figure>
<blockquote>
<p><strong>1、确定dp数组以及下标的含义</strong></p>
<p><strong>2、确定递推公式</strong></p>
<p><strong>3、dp数组如何初始化</strong></p>
<ul>
<li><strong>最大长度</strong></li>
<li><strong>递推等号左侧要初始化</strong></li>
</ul>
<p><strong>4、确定遍历顺序</strong></p>
<ul>
<li><strong>滚动数组</strong></li>
</ul>
<p><strong>5、举例推导dp数组</strong></p>
</blockquote>
<h3><span id="511-背包递推公式">5.1.1 背包递推公式</span></h3>
<p><strong>问==能否装满背包==</strong>（或者<strong>最多装多少</strong>）：dp[j]
= max(dp[j], dp[j - nums[i]] + nums[i]); ，对应题目如下：</p>
<ul>
<li><a href="https://programmercarl.com/0416.分割等和子集.html">动态规划：416.分割等和子集(opens
new window)</a></li>
<li><a href="https://leetcode-cn.com/problems/partition-to-k-equal-sum-subsets/">划分为k个相等的子集</a></li>
<li><a href="https://programmercarl.com/1049.最后一块石头的重量II.html">动态规划：1049.最后一块石头的重量
II</a></li>
</ul>
<p><strong>==问装满背包有几种方法==</strong>：dp[j] += dp[j - nums[i]]
，对应题目如下：</p>
<ul>
<li><p><a href="https://programmercarl.com/0494.目标和.html">动态规划：494.目标和(opens
new window)</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">canPartition</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="comment"># 背包问题</span></span><br><span class="line">        total, n = <span class="built_in">sum</span>(nums), <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">if</span> total % <span class="number">2</span> != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        target = total // <span class="number">2</span></span><br><span class="line">        dp = [<span class="literal">True</span>] + [<span class="literal">False</span>] * target</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(target, nums[i] - <span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">                <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                逆序更新</span></span><br><span class="line"><span class="string">                dp[i][j] = dp[i - 1][j] or dp[i - 1][j - nums[i]]</span></span><br><span class="line"><span class="string">                &quot;&quot;&quot;</span></span><br><span class="line">                dp[j] |= dp[j - nums[i]]</span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure></li>
<li><p><a href="https://programmercarl.com/0518.零钱兑换II.html">动态规划：518.
零钱兑换 II(opens new window)</a></p></li>
<li><p><a href="https://programmercarl.com/0377.组合总和Ⅳ.html">动态规划：377.组合总和Ⅳ(opens
new window)</a></p>
<blockquote>
<p><strong>如果求组合数就是外层for循环遍历物品，内层for遍历背包</strong>。</p>
<p><strong>如果求排列数就是外层for遍历背包，内层for循环遍历物品</strong>。</p>
</blockquote></li>
<li><p><a href="https://programmercarl.com/0070.爬楼梯完全背包版本.html">动态规划：70.
爬楼梯进阶版（完全背包）</a></p></li>
</ul>
<p><strong>问背包装满==最大价值==</strong>：dp[j] = max(dp[j], dp[j -
weight[i]] + value[i]); ，对应题目如下：</p>
<ul>
<li><a href="https://programmercarl.com/0474.一和零.html">动态规划：474.一和零</a></li>
</ul>
<p><strong>问装满背包所有物品的==最小个数==</strong>：dp[j] = min(dp[j -
coins[i]] + 1, dp[j]); ，对应题目如下：</p>
<ul>
<li><a href="https://programmercarl.com/0322.零钱兑换.html">动态规划：322.零钱兑换(opens
new window)</a></li>
<li><a href="https://programmercarl.com/0279.完全平方数.html">动态规划：279.完全平方数(opens
new window)</a></li>
</ul>
<h3><span id="512-遍历顺序">5.1.2 遍历顺序</span></h3>
<h4><span id="01背包">01背包</span></h4>
<p>在<a href="https://programmercarl.com/背包理论基础01背包-1.html">动态规划：关于01背包问题，你该了解这些！
(opens new
window)</a>中我们讲解二维dp数组01背包先遍历物品还是先遍历背包都是可以的，且第二层for循环是从小到大遍历。</p>
<p>和<a href="https://programmercarl.com/背包理论基础01背包-2.html">动态规划：关于01背包问题，你该了解这些！（滚动数组）
(opens new
window)</a>中，我们讲解一维dp数组01背包只能先遍历物品再遍历背包容量，且第二层for循环是从大到小遍历。</p>
<p><strong>一维dp数组的背包在遍历顺序上和二维dp数组实现的01背包其实是有很大差异的，大家需要注意！</strong></p>
<h4><span id="完全背包">完全背包</span></h4>
<p>说完01背包，再看看完全背包。</p>
<p>在<a href="https://programmercarl.com/背包问题理论基础完全背包.html">动态规划：关于完全背包，你该了解这些！
(opens new
window)</a>中，讲解了纯完全背包的一维dp数组实现，先遍历物品还是先遍历背包都是可以的，且第二层for循环是从小到大遍历。</p>
<p>但是仅仅是纯完全背包的遍历顺序是这样的，题目稍有变化，两个for循环的先后顺序就不一样了。</p>
<p><strong>如果求==组合数==就是外层for循环遍历物品，内层for遍历背包</strong>。</p>
<p><strong>如果==求排列数==就是外层for遍历背包，内层for循环遍历物品</strong>。</p>
<p>相关题目如下：</p>
<ul>
<li>求组合数：<a href="https://programmercarl.com/0518.零钱兑换II.html">动态规划：518.零钱兑换II(opens
new window)</a></li>
<li>求排列数：<a href="https://mp.weixin.qq.com/s/Iixw0nahJWQgbqVNk8k6gA">动态规划：377.
组合总和 Ⅳ (opens new window)</a>、<a href="https://programmercarl.com/0070.爬楼梯完全背包版本.html">动态规划：70.
爬楼梯进阶版（完全背包）(opens new window)</a></li>
</ul>
<p>如果求最小数，那么两层for循环的先后顺序就无所谓了，相关题目如下：</p>
<ul>
<li>求最小数：<a href="https://programmercarl.com/0322.零钱兑换.html">动态规划：322.
零钱兑换 (opens new window)</a>、<a href="https://programmercarl.com/0279.完全平方数.html">动态规划：279.完全平方数(opens
new window)</a></li>
</ul>
<p><strong>对于背包问题，其实递推公式算是容易的，难是难在遍历顺序上，如果把遍历顺序搞透，才算是真正理解了</strong>。</p>
<h2><span id="52-子序列数组问题">5.2 <strong>子序列（数组）问题</strong></span></h2>
<p><img src="https://code-thinking.cdn.bcebos.com/pics/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-%E5%AD%90%E5%BA%8F%E5%88%97%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="剑指offer-42-连续子数组的最大和"></span></h4>
<p>输入一个整型数组，数组中的一个或连续多个整数组成一个子数组。求所有子数组的和的最大值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxSubArray</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        dp = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums))]</span><br><span class="line">        dp[<span class="number">0</span>] = nums[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            dp[i] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>] + nums[i], nums[i])</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(dp)</span><br></pre></td></tr></table></figure>
<h4><span id="动态规划最长递增子序列"></span></h4>
<p>给你一个整数数组 <code>nums</code>
，找到其中最长严格递增子序列的长度。</p>
<ul>
<li><strong>动态规划</strong>
位置i的最长升序子序列等于j从0到i-1各个位置的最长升序子序列 + 1
的最大值。</li>
<li><strong>贪心 + 二分查找</strong> tail[i] :
记录i长度的末尾是什么</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLIS</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(nums)</span><br><span class="line">        dp = [<span class="number">1</span>] * <span class="built_in">len</span>(nums)</span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, i):</span><br><span class="line">                <span class="keyword">if</span> nums[j] &lt; numa[i]:</span><br><span class="line">                    dp[i] = <span class="built_in">max</span>(dp[i], dp[j] + <span class="number">1</span>)</span><br><span class="line">            result = <span class="built_in">max</span>(result, dp[i]) <span class="comment">#取长的子序列</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">     <span class="keyword">def</span> <span class="title function_">lengthOfLIS</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 贪心 + 二分查找 tail[i] : 记录i长度的末尾是什么</span></span><br><span class="line">        tails, res = [<span class="number">0</span>] * <span class="built_in">len</span>(nums), <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            i = bisect.bisect_left(tails[:res], num)</span><br><span class="line">            <span class="string">&quot;&quot;&quot;左边界</span></span><br><span class="line"><span class="string">            while i &lt; j:</span></span><br><span class="line"><span class="string">                mid = (i + j)//2</span></span><br><span class="line"><span class="string">                if tails[m] &lt; num:</span></span><br><span class="line"><span class="string">                    i = m + 1 </span></span><br><span class="line"><span class="string">                else:</span></span><br><span class="line"><span class="string">                    j = m</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span></span><br><span class="line">            tails[i] = num</span><br><span class="line">            <span class="keyword">if</span> i == res:</span><br><span class="line">                res += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h5><span id="动态规划最长斐波那契数列"></span></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lenLongestFibSubseq</span>(<span class="params">self, A: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="comment"># 基本顺序是 k，i，j 或者 A[k] = A[j] - A[i]</span></span><br><span class="line">    n = <span class="built_in">len</span>(A)</span><br><span class="line">    dic = &#123;&#125;</span><br><span class="line">    <span class="comment"># 创建索引字典，提速</span></span><br><span class="line">    <span class="keyword">for</span> ind,val <span class="keyword">in</span> <span class="built_in">enumerate</span>(A):</span><br><span class="line">        dic[val] = ind</span><br><span class="line">    <span class="comment"># 初始化，行代表的是i，不需要取到n-1，为了给j留出位置</span></span><br><span class="line">    <span class="comment"># 初始为2，只要包含了 j i 位置，则意味着已经有了2个数字。</span></span><br><span class="line">    dp = [[<span class="number">2</span>]*n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>)]</span><br><span class="line">    ret = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 因此i只能取到n-2，给j留出空间</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n-<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># j从i+1开始，毕竟j在i后面</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>,n):</span><br><span class="line">            diff = A[j] - A[i]</span><br><span class="line">            <span class="keyword">if</span> diff <span class="keyword">in</span> dic <span class="keyword">and</span> dic[diff] &lt; i:</span><br><span class="line">                k = dic[diff]</span><br><span class="line">                dp[i][j] = dp[k][i] + <span class="number">1</span> <span class="comment"># 这个1，代表着k位置数字</span></span><br><span class="line">                ret = <span class="built_in">max</span>(ret,dp[i][j])</span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure>
<h4><span id="动态规划最长重复子数组"></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findLength</span>(<span class="params">self, A: <span class="type">List</span>[<span class="built_in">int</span>], B: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        dp = [<span class="number">0</span>] * (<span class="built_in">len</span>(B) + <span class="number">1</span>)</span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(A)+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(B), <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> A[i-<span class="number">1</span>] == B[j-<span class="number">1</span>]:</span><br><span class="line">                    dp[j] = dp[j-<span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[j] = <span class="number">0</span> <span class="comment">#注意这里不相等的时候要有赋0的操作</span></span><br><span class="line">                result = <span class="built_in">max</span>(result, dp[j])</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h4><span id="动态规划最长公共子序列"></span></h4>
<p>给定两个字符串 <code>text1</code> 和
<code>text2</code>，返回这两个字符串的最长 <strong>公共子序列</strong>
的长度。如果不存在 <strong>公共子序列</strong> ，返回 <code>0</code>
。</p>
<p>一个字符串的 <strong>子序列</strong>
是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestCommonSubsequence</span>(<span class="params">self, text1: <span class="built_in">str</span>, text2: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        m, n = <span class="built_in">len</span>(text1), <span class="built_in">len</span>(text2)</span><br><span class="line">        dp = [[<span class="number">0</span>] * (n + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m + <span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> text1[i - <span class="number">1</span>] == text2[j - <span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="built_in">max</span>(dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> dp[m][n]</span><br></pre></td></tr></table></figure>
<h4><span id="动态规划不相交的线"></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestCommonSubsequence</span>(<span class="params">self, text1: <span class="built_in">str</span>, text2: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 最长子序列 </span></span><br><span class="line">        m, n = <span class="built_in">len</span>(text1), <span class="built_in">len</span>(text2)</span><br><span class="line">        dp = [[<span class="number">0</span>] * (n+<span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m+<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> text2[j-<span class="number">1</span>] == text1[i-<span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = dp[i-<span class="number">1</span>][j-<span class="number">1</span>] +<span class="number">1</span> </span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>][j], dp[i][j-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p><a href="https://programmercarl.com/0053.最大子序和（动态规划）.html">动态规划：最大子序和</a>
【贪心】【动态规划】</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">maxSubArray</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="comment"># 为什么dp[-1]不是最大？需要res</span></span><br><span class="line">    <span class="comment"># dp[i] 以i结尾的最大子数组和</span></span><br><span class="line">    n = <span class="built_in">len</span>(nums)</span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    dp = [<span class="number">0</span>] * (n)</span><br><span class="line">    dp[<span class="number">0</span>] = nums[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">        dp[i] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>]+nums[i], nums[i])</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(dp)</span><br></pre></td></tr></table></figure>
<p><a href="https://programmercarl.com/0392.判断子序列.html">动态规划：判断子序列</a>
【双指针】</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isSubsequence</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        n, m = <span class="built_in">len</span>(s), <span class="built_in">len</span>(t)</span><br><span class="line">        i = j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; n <span class="keyword">and</span> j &lt; m:</span><br><span class="line">            <span class="keyword">if</span> s[i] == t[j]:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> i == n</span><br></pre></td></tr></table></figure>
<p><a href="https://programmercarl.com/0115.不同的子序列.html">动态规划：不同的子序列</a></p>
<p><a href="https://programmercarl.com/0583.两个字符串的删除操作.html">动态规划：两个字符串的删除操作</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dp[i][j] : word1[i-1], word1[j-1] 最少步数</span></span><br><span class="line"><span class="comment"># word1[i - 1] 与 word2[j - 1]不相同的时候，有2种情况 *  min(dp[i-1][j], dp[i][j-1])+1  </span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">minDistance</span>(<span class="params">self, word1: <span class="built_in">str</span>, word2: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        m, n = <span class="built_in">len</span>(word1), <span class="built_in">len</span>(word2)</span><br><span class="line">        dp = [[<span class="number">0</span>] * (n+<span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m+<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>):</span><br><span class="line">            dp[<span class="number">0</span>][i] = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m+<span class="number">1</span>):</span><br><span class="line">            dp[j][<span class="number">0</span>] = j</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> word1[i-<span class="number">1</span>] == word2[j-<span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = dp[i-<span class="number">1</span>][j-<span class="number">1</span>]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="built_in">min</span>(dp[i-<span class="number">1</span>][j], dp[i][j-<span class="number">1</span>])+<span class="number">1</span> <span class="comment"># , dp[i-1][j-1]+1</span></span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p><a href="https://programmercarl.com/0072.编辑距离.html">动态规划：编辑距离</a></p>
<p><a href="https://programmercarl.com/为了绝杀编辑距离，卡尔做了三步铺垫.html">为了绝杀编辑距离，我做了三步铺垫，你都知道么？</a></p>
<h4><span id="剑指-offer-ii-020回文子字符串的个数"></span></h4>
<p>给定一个字符串 <code>s</code>
，请计算这个字符串中有多少个回文子字符串。具有不同开始位置或结束位置的子串，即使是由相同的字符组成，也会被视作不同的子串。</p>
<ul>
<li>动态规划、双指针+中心扩展、<strong>==Manacher算法==</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">countSubstrings</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 双指针+中心扩散</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_extend</span>(<span class="params">s, i, j, n</span>):</span><br><span class="line">            res = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &gt;= <span class="number">0</span> <span class="keyword">and</span> j &lt; n <span class="keyword">and</span> s[i] == s[j]: <span class="comment"># 确定中心点</span></span><br><span class="line">                i -= <span class="number">1</span></span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">                res += <span class="number">1</span> <span class="comment"># 扩散过程也是答案</span></span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            result += _extend(s, i, i, <span class="built_in">len</span>(s)) <span class="comment">#以i为中心</span></span><br><span class="line">            result += _extend(s, i, i+<span class="number">1</span>, <span class="built_in">len</span>(s)) <span class="comment">#以i和i+1为中心</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">countSubstrings</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 动态规划 dp[i][j]: s[i:j] 是否为回文子串</span></span><br><span class="line">        <span class="comment"># dp[i+1][j-1] -&gt; dp[i][j] 遍历顺序 </span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        dp = [[<span class="literal">False</span>] * (n) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i,n):</span><br><span class="line">                <span class="keyword">if</span> s[i] == s[j]:</span><br><span class="line">                    <span class="keyword">if</span> j - i &lt;= <span class="number">1</span>:</span><br><span class="line">                        ans += <span class="number">1</span></span><br><span class="line">                        dp[i][j] = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">elif</span> dp[i+<span class="number">1</span>][j-<span class="number">1</span>]:</span><br><span class="line">                        ans += <span class="number">1</span></span><br><span class="line">                        dp[i][j] = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<p><a href="https://leetcode-cn.com/problems/longest-palindromic-substring/">最长回文子串</a>
==[Manacher 算法]==</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 中心扩展法</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="comment"># 枚举+中心扩展法</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">extendCenter</span>(<span class="params">left, right</span>):</span><br><span class="line">            <span class="keyword">while</span> <span class="number">0</span> &lt;= left <span class="keyword">and</span> right &lt; <span class="built_in">len</span>(s) <span class="keyword">and</span> s[left] == s[right]:</span><br><span class="line">                left -= <span class="number">1</span></span><br><span class="line">                right += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 返回的为while不成立的值</span></span><br><span class="line">            <span class="keyword">return</span> left+<span class="number">1</span>, right-<span class="number">1</span> </span><br><span class="line">        start, end = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            left1, right1 = extendCenter(i,i)</span><br><span class="line">            left2, right2 = extendCenter(i,i+<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> right1 - left1 &gt; end - start:</span><br><span class="line">                start, end = left1, right1</span><br><span class="line">            <span class="keyword">if</span> right2 - left2 &gt; end - start:</span><br><span class="line">                start, end = left2, right2</span><br><span class="line">        <span class="keyword">return</span> s[start:end+<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">longestPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="comment"># dp[i][j]: 是否是回文 dp[i+1][j-1] -&gt; dp[i][j]</span></span><br><span class="line">    <span class="comment"># 返回的子串，不是数字 不能记录长度</span></span><br><span class="line">    n = <span class="built_in">len</span>(s)</span><br><span class="line">    dp = [[<span class="literal">False</span>] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="comment"># 右上为1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        dp[i][i] = <span class="literal">True</span></span><br><span class="line">    begin = <span class="number">0</span></span><br><span class="line">    maxlen = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 判断是否是回文子串中，如果是则记录begin and len</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>, -<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i,n):</span><br><span class="line">            <span class="keyword">if</span> s[i] == s[j]:</span><br><span class="line">                <span class="keyword">if</span> j - i &lt;=<span class="number">1</span>:</span><br><span class="line">                    dp[i][j] = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">elif</span> dp[i+<span class="number">1</span>][j-<span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = <span class="literal">True</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> dp[i][j] <span class="keyword">and</span> j - i + <span class="number">1</span> &gt; maxlen:</span><br><span class="line">                maxlen = j - i + <span class="number">1</span></span><br><span class="line">                begin = i</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> s[begin:begin+maxlen]</span><br></pre></td></tr></table></figure>
<ul>
<li><p>Manacher 算法：<strong>Manacher
算法是在线性时间内求解最长回文子串的算法</strong>。在本题中，我们要求解回文串的个数，为什么也能使用
Manacher 算法呢？这里我们就需要理解一下 Manacher 的基本原理。</p>
<ul>
<li><p>奇偶长度处理： abaaabaa 会被处理成
#a#b#a#a##<em>a</em>#<em>b</em>#<em>a</em>#<em>a</em>#</p></li>
<li><p>==<strong><span class="math inline">\(f(i)\)</span></strong>
来表示以 s 的第 i 位为回文中心，可以拓展出的<strong>最大回文半径 （包括
# ）</strong>==，那么$ f(i) - 1$就是以 i 为中心的最大回文串长度
。</p></li>
<li><p>利用已经计算出来的状态来更新 f(i）：<strong>回文右端点rm</strong>
：i + f(i) - 1</p></li>
</ul></li>
</ul>
<p><a href="https://programmercarl.com/0516.最长回文子序列.html">动态规划：最长回文子序列</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestPalindromeSubseq</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 动态规划 dp[i][j]: s[i:j] 最大回文长度</span></span><br><span class="line">        <span class="comment"># dp[i+1][j-1] -&gt; dp[i][j] 遍历顺序 and j - i &gt;=2</span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        dp = [[<span class="number">0</span>] * i +[<span class="number">1</span>] * (n-i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="comment"># 从定义出发 右上三角 = 1 有意义</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>,n): <span class="comment"># j - i &gt;=2</span></span><br><span class="line">                <span class="keyword">if</span> s[i] == s[j]:</span><br><span class="line">                    dp[i][j] = dp[i+<span class="number">1</span>][j-<span class="number">1</span>] + <span class="number">2</span> </span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="built_in">max</span>(dp[i+<span class="number">1</span>][j], dp[i][j-<span class="number">1</span>])                </span><br><span class="line">        <span class="keyword">return</span> dp[<span class="number">0</span>][n-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h5><span id="最少回文分割"></span></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minCut</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 动态规划1:判断回文</span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        g = [[<span class="literal">True</span>] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, n):</span><br><span class="line">                g[i][j] = (s[i] == s[j]) <span class="keyword">and</span> g[i + <span class="number">1</span>][j - <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># </span></span><br><span class="line">        f = [<span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)] * n</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> g[<span class="number">0</span>][i]:</span><br><span class="line">                f[i] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">                    <span class="keyword">if</span> g[j + <span class="number">1</span>][i]:</span><br><span class="line">                        <span class="comment"># （0, j) + (j+1, i)</span></span><br><span class="line">                        f[i] = <span class="built_in">min</span>(f[i], f[j] + <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> f[n - <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h5><span id="最长连续序列"></span></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestConsecutive</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 动态规划</span></span><br><span class="line">        dic, res = <span class="built_in">dict</span>(), <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> num <span class="keyword">not</span> <span class="keyword">in</span> dic:</span><br><span class="line">                left, right = dic.get(num - <span class="number">1</span>, <span class="number">0</span>), dic.get(num + <span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">                cur = <span class="number">1</span> + left +right</span><br><span class="line">                <span class="keyword">if</span> res &lt; cur:</span><br><span class="line">                    res = cur</span><br><span class="line">                dic[num] = cur</span><br><span class="line">                dic[num - left] = cur</span><br><span class="line">                dic[num + right] = cur</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h3><span id="53-打家劫舍问题">5.3 打家劫舍问题</span></h3>
<ul>
<li><a href="https://programmercarl.com/0198.打家劫舍.html">动态规划：开始打家劫舍</a></li>
<li><a href="https://programmercarl.com/0213.打家劫舍II.html">动态规划：继续打家劫舍
环</a></li>
<li><a href="https://programmercarl.com/0337.打家劫舍III.html">动态规划：还要打家劫舍
树状dp</a></li>
</ul>
<h3><span id="54-股票问题">5.4 股票问题</span></h3>
<p><img src="https://code-thinking.cdn.bcebos.com/pics/%E8%82%A1%E7%A5%A8%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.jpg" alt="股票问题总结" style="zoom:50%;"></p>
<p><a href="https://programmercarl.com/0121.买卖股票的最佳时机.html">动态规划：121.买卖股票的最佳时机(opens
new window)</a></p>
<p>股票只能买卖一次，问最大利润</p>
<ul>
<li><strong>动态规划、贪心算法</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxProfit</span>(<span class="params">self, prices: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">      	<span class="comment"># 动态规划</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> prices:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        dp = [[<span class="number">0</span>] * <span class="number">2</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(prices))] </span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = -prices[<span class="number">0</span>]<span class="comment"># 已持有的状态</span></span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">1</span>] = <span class="number">0</span> <span class="comment"># 未持有的状态</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(prices)):</span><br><span class="line">            dp[i][<span class="number">0</span>] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>][<span class="number">0</span>], -prices[i])</span><br><span class="line">            dp[i][<span class="number">1</span>] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>][<span class="number">1</span>], dp[i-<span class="number">1</span>][<span class="number">0</span>] + prices[i])</span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxProfit</span>(<span class="params">self, prices: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 贪心算法</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> prices:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        buy, profit = prices[<span class="number">0</span>], <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(prices)):</span><br><span class="line">            profit = <span class="built_in">max</span>(profit, prices[i] - buy)</span><br><span class="line">            <span class="keyword">if</span> prices[i] &lt; buy:</span><br><span class="line">                buy = prices[i]</span><br><span class="line">        <span class="keyword">return</span> profit    </span><br></pre></td></tr></table></figure>
<p><a href="https://programmercarl.com/0122.买卖股票的最佳时机II（动态规划）.html">动态规划：122.买卖股票的最佳时机II(opens
new window)</a> 可以多次买卖股票，问最大收益。</p>
<p><a href="https://programmercarl.com/0123.买卖股票的最佳时机III.html">动态规划：123.买卖股票的最佳时机III(opens
new window)</a> 最多买卖两次，问最大收益。</p>
<p><a href="https://programmercarl.com/0188.买卖股票的最佳时机IV.html">动态规划：188.买卖股票的最佳时机IV(opens
new window)</a> 最多买卖k笔交易，问最大收益。</p>
<p><a href="https://programmercarl.com/0309.最佳买卖股票时机含冷冻期.html">动态规划：309.最佳买卖股票时机含冷冻期(opens
new window)</a> 可以多次买卖但每次卖出有冷冻期1天。</p>
<p><a href="https://programmercarl.com/0714.买卖股票的最佳时机含手续费（动态规划）.html">动态规划：714.买卖股票的最佳时机含手续费(opens
new window)</a> 可以多次买卖，但每次有手续费。</p>
<h3><span id="55-编辑距离问题">5.5 编辑距离问题</span></h3>
<h4><span id="判断子序列">判断子序列</span></h4>
<p><a href="https://programmercarl.com/0392.判断子序列.html">动态规划：392.判断子序列
(opens new window)</a>给定字符串 s 和 t ，判断 s 是否为 t 的子序列。</p>
<p>这道题目
其实是可以用<strong>双指针</strong>或者<strong>贪心</strong>的的，但是我在开篇的时候就说了这是编辑距离的入门题目，因为从题意中我们也可以发现，只需要计算删除的情况，不用考虑增加和替换的情况。</p>
<ul>
<li>if (s[i - 1] == t[j - 1])
<ul>
<li>t中找到了一个字符在s中也出现了</li>
</ul></li>
<li>if (s[i - 1] != t[j - 1])
<ul>
<li>相当于t要删除元素，继续匹配</li>
</ul></li>
</ul>
<p>状态转移方程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (s[i - <span class="number">1</span>] == t[j - <span class="number">1</span>]) dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">else</span> dp[i][j] = dp[i][j - <span class="number">1</span>];</span><br></pre></td></tr></table></figure>
<h4><span id="不同的子序列">不同的子序列</span></h4>
<p><a href="https://programmercarl.com/0115.不同的子序列.html">动态规划：115.不同的子序列
(opens new window)</a>给定一个字符串 s 和一个字符串 t ，计算在 s
的子序列中 t 出现的个数。</p>
<p>本题虽然也只有删除操作，不用考虑替换增加之类的，但相对于<a href="https://programmercarl.com/0392.判断子序列.html">动态规划：392.判断子序列
(opens new window)</a>就有难度了，这道题目双指针法可就做不了。</p>
<p>当s[i - 1] 与 t[j - 1]相等时，dp[i][j]可以有两部分组成。</p>
<p>一部分是用s[i - 1]来匹配，那么个数为 dp[i - 1] [j - 1]</p>
<p>一部分是不用s[i - 1]来匹配，个数为 dp[i - 1] [j]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (s[i - <span class="number">1</span>] == t[j - <span class="number">1</span>]) &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + dp[i - <span class="number">1</span>][j];</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="两个字符串的删除操作">两个字符串的删除操作</span></h4>
<p><a href="https://programmercarl.com/0583.两个字符串的删除操作.html">动态规划：583.两个字符串的删除操作
(opens new window)</a>给定两个单词 word1 和 word2，找到使得 word1 和
word2 相同所需的最小步数，每步可以删除任意一个字符串中的一个字符。</p>
<p>本题和<a href="https://programmercarl.com/0115.不同的子序列.html">动态规划：115.不同的子序列
(opens new
window)</a>相比，其实就是两个字符串可以都可以删除了，情况虽说复杂一些，但整体思路是不变的。</p>
<ul>
<li>当word1[i - 1] 与 word2[j - 1]相同的时候</li>
<li>当word1[i - 1] 与 word2[j - 1]不相同的时候</li>
</ul>
<p>当word1[i - 1] 与 word2[j - 1]相同的时候，dp[i][j] = dp[i - 1] [j -
1];</p>
<p>当word1[i - 1] 与 word2[j - 1]不相同的时候，有2种情况：</p>
<p>情况一：删word1[i - 1]，最少操作次数为dp[i - 1] [j] + 1</p>
<p>情况二：删word2[j - 1]，最少操作次数为dp [i] [j - 1] + 1</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (word1[i - <span class="number">1</span>] == word2[j - <span class="number">1</span>]) &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>];</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    dp[i][j] = <span class="built_in">min</span>(&#123;dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">2</span>, dp[i - <span class="number">1</span>][j] + <span class="number">1</span>, dp[i][j - <span class="number">1</span>] + <span class="number">1</span>&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="编辑距离">编辑距离</span></h4>
<p><a href="https://programmercarl.com/0072.编辑距离.html">动态规划：72.编辑距离
(opens new window)</a>给你两个单词 word1 和 word2，请你计算出将 word1
转换成 word2 所使用的最少操作数 。</p>
<p>编辑距离终于来了，<strong>有了前面三道题目的铺垫，应该有思路了</strong>，本题是两个字符串可以增删改，比
<a href="https://programmercarl.com/0392.判断子序列.html">动态规划：判断子序列
(opens new window)</a>，<a href="https://programmercarl.com/0115.不同的子序列.html">动态规划：不同的子序列
(opens new window)</a>，<a href="https://programmercarl.com/0583.两个字符串的删除操作.html">动态规划：两个字符串的删除操作
(opens new window)</a>都要复杂的多。</p>
<p>在确定递推公式的时候，首先要考虑清楚编辑的几种操作，整理如下：</p>
<ul>
<li>if (word1[i - 1] == word2[j - 1])
<ul>
<li>不操作</li>
</ul></li>
<li>if (word1[i - 1] != word2[j - 1])
<ul>
<li>增</li>
<li>删</li>
<li>换</li>
</ul></li>
</ul>
<p>也就是如上四种情况。</p>
<p>if (word1[i - 1] == word2[j - 1]) 那么说明不用任何编辑，dp[i][j]
就应该是 dp[i - 1] [j - 1]，即dp[i][j] = dp[i - 1] [j - 1];</p>
<p><strong>在整个动规的过程中，最为关键就是正确理解dp[i]
[j]的定义！</strong></p>
<p>if (word1[i - 1] != word2[j - 1])，此时就需要编辑了，如何编辑呢？</p>
<p>操作一：word1增加一个元素，使其word1[i - 1]与word2[j -
1]相同，那么就是以下标i-2为结尾的word1 与 i-1为结尾的word2的最近编辑距离
加上一个增加元素的操作。</p>
<p>即 dp[i][j] = dp[i - 1] [j] + 1;</p>
<p>操作二：word2添加一个元素，使其word1[i - 1]与word2[j -
1]相同，那么就是以下标i-1为结尾的word1 与 j-2为结尾的word2的最近编辑距离
加上一个增加元素的操作。</p>
<p>即 dp[i][j] = dp[i][j - 1] + 1;</p>
<p>这里有同学发现了，怎么都是添加元素，删除元素去哪了。</p>
<p><strong>word2添加一个元素，相当于word1删除一个元素</strong>，例如
word1 = "ad" ，word2 =
"a"，word2添加一个元素d，也就是相当于word1删除一个元素d，操作数是一样！</p>
<p>操作三：替换元素，word1替换word1[i - 1]，使其与word2[j -
1]相同，此时不用增加元素，那么以下标i-2为结尾的word1 与
j-2为结尾的word2的最近编辑距离 加上一个替换元素的操作。</p>
<p>即 dp[i][j] = dp[i - 1] [j - 1] + 1;</p>
<p>综上，当 if (word1[i - 1] != word2[j - 1]) 时取最小的，即：dp[i] [j]
= min({dp[i - 1] [j - 1], dp[i - 1] [j], dp[i][j - 1]}) + 1;</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (word1[i - <span class="number">1</span>] == word2[j - <span class="number">1</span>]) &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>];</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    dp[i][j] = <span class="built_in">min</span>(&#123;dp[i - <span class="number">1</span>][j - <span class="number">1</span>], dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>]&#125;) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="让字符串成为最小回文">==让字符串成为最小回文==</span></h4>
<p>https://leetcode-cn.com/problems/minimum-insertion-steps-to-make-a-string-palindrome/</p>
<h4><span id="剑指offer-19-正则表达式匹配"></span></h4>
<p>请实现一个函数用来<strong>匹配包含'.
'和'<em>'的正则表达式<strong>。</strong>模式中的字符'.'表示任意一个字符，而'
</em>
'表示它前面的字符可以出现任意次（含0次）</strong>。在本题中，匹配是指字符串的所有字符匹配整个模式。例如，字符串"aaa"与模式"a.a"和"ab<em>ac</em>a"匹配，但与"aa.a"和"ab*a"均不匹配。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isMatch</span>(<span class="params">self, s: <span class="built_in">str</span>, p: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="comment"># 【dp含义】dp[i][j] : s[:i - 1] 可以正则匹配 p[:j - 1]</span></span><br><span class="line">        m, n = <span class="built_in">len</span>(s), <span class="built_in">len</span>(p)</span><br><span class="line">        <span class="comment"># 【初始化】</span></span><br><span class="line">        dp = [[<span class="literal">False</span>] * (n + <span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m + <span class="number">1</span>)]</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n + <span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line">            dp[<span class="number">0</span>][j] = dp[<span class="number">0</span>][j - <span class="number">2</span>] <span class="keyword">and</span> p[j - <span class="number">1</span>] == <span class="string">&#x27;*&#x27;</span></span><br><span class="line">        <span class="comment"># 【遍历顺序】</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">                <span class="comment"># 【状态转移推导】</span></span><br><span class="line">                <span class="keyword">if</span> p[j - <span class="number">1</span>] == <span class="string">&#x27;*&#x27;</span>: </span><br><span class="line">                    <span class="keyword">if</span> dp[i][j - <span class="number">2</span>]:</span><br><span class="line">                        dp[i][j] = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">elif</span> dp[i - <span class="number">1</span>][j] <span class="keyword">and</span> (p[j - <span class="number">2</span>] == <span class="string">&#x27;.&#x27;</span> <span class="keyword">or</span> s[i - <span class="number">1</span>] == p[j - <span class="number">2</span>]):</span><br><span class="line">                        dp[i][j] = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> dp[i-<span class="number">1</span>][j-<span class="number">1</span>] <span class="keyword">and</span> (p[j - <span class="number">1</span>] == <span class="string">&#x27;.&#x27;</span> <span class="keyword">or</span> s[i - <span class="number">1</span>] == p[j - <span class="number">1</span>]):</span><br><span class="line">                        dp[i][j] = <span class="literal">True</span></span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h2><span id="六-其他">六、其他</span></h2>
<h4><span id="剑指offer-66-构建乘积数组"></span></h4>
<p>给定一个数组 A[0,1,…,n-1]，请构建一个数组 B[0,1,…,n-1]，其中 B[i]
的值是数组 A 中除了下标 i 以外的元素的积, 即
B[i]=A[0]×A[1]×…×A[i-1]×A[i+1]×…×A[n-1]。不能使用除法。【求三角矩阵非对角线】</p>
<ul>
<li>动态规划双向遍历</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">constructArr</span>(<span class="params">self, a: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        b, tmp = [<span class="number">1</span>] * <span class="built_in">len</span>(a), <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(a)):</span><br><span class="line">            b[i] = b[i - <span class="number">1</span>] * a[i - <span class="number">1</span>] <span class="comment"># 下三角</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(a) - <span class="number">2</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            tmp *= a[i + <span class="number">1</span>]            <span class="comment"># 上三角</span></span><br><span class="line">            b[i] *= tmp                <span class="comment"># 下三角 * 上三角</span></span><br><span class="line">        <span class="keyword">return</span> b</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-49丑数"></span></h4>
<p>我们<strong>把只包含质因子 2、3 和 5 的数称作丑数</strong>（Ugly
Number）。求按从小到大的顺序的第 n 个丑数。</p>
<ul>
<li>三指针、<strong>优先队列（质数的线性筛算法）</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">nthUglyNumber</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 维护3个 2，3，5的动态个数</span></span><br><span class="line">        dp = [<span class="number">0</span>] * (n + <span class="number">1</span>)</span><br><span class="line">        dp[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">        p2 = p3 = p5 = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n + <span class="number">1</span>):</span><br><span class="line">          	<span class="comment"># </span></span><br><span class="line">            u2, u3, u5 = <span class="number">2</span> * dp[p2], <span class="number">3</span> * dp[p3], <span class="number">5</span> * dp[p5]</span><br><span class="line">            dp[i] = <span class="built_in">min</span>(u2, u3, u5)</span><br><span class="line">            <span class="keyword">if</span> dp[i] == u5:</span><br><span class="line">                p5 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> dp[i] == u3:</span><br><span class="line">                p3 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> dp[i] == u2:</span><br><span class="line">                p2 += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">nthUglyNumber</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        H = [(<span class="number">2</span>, <span class="number">2</span>), (<span class="number">3</span>, <span class="number">3</span>), (<span class="number">5</span>, <span class="number">5</span>)]</span><br><span class="line">        heapify(H)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>):</span><br><span class="line">            num, p = heappop(H)</span><br><span class="line">            heappush(H, (num * <span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">            <span class="keyword">if</span> p &gt;= <span class="number">3</span>:</span><br><span class="line">                heappush(H, (num * <span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">                <span class="keyword">if</span> p &gt;= <span class="number">5</span>:</span><br><span class="line">                    heappush(H, (num * <span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">        <span class="comment">#print(len(H)) #n = 1670时, H长度为162</span></span><br><span class="line">        <span class="keyword">return</span> num                </span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-60-n个骰子的点数"></span></h4>
<p><strong>把n个骰子扔在地上，所有骰子朝上一面的点数之和为s。输入n，打印出s的所有可能的值出现的概率。</strong></p>
<ul>
<li>已知n - 1个骰子的解为f(n - 1),
添加一个骰子，求n个骰子的点数和为x的概率f（n， x）</li>
</ul>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220608212653374.png" alt="image-20220608212653374" style="zoom:50%;"></p>
<p><img src="https://pic.leetcode-cn.com/1614960989-tpJNRQ-Picture2.png" alt="Picture2.png" style="zoom: 33%;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dicesProbability</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">float</span>]:</span><br><span class="line">        dp = [<span class="number">1</span> / <span class="number">6</span>] * <span class="number">6</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n + <span class="number">1</span>):</span><br><span class="line">            tmp = [<span class="number">0</span>] * (<span class="number">5</span> * i + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dp)):</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>): <span class="comment"># 防止越界</span></span><br><span class="line">                    tmp[j + k] += dp[j] / <span class="number">6</span></span><br><span class="line">            dp = tmp</span><br><span class="line">        <span class="keyword">return</span> dp</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>Changelog</title>
    <url>/posts/15B7952/</url>
    <content><![CDATA[<h2><span id="blog-修改">Blog 修改</span></h2>
<ul class="task-list">
<li><input type="checkbox"><strong><font color="red"> Fluid
主题很好看</font></strong>：https://lizhening.github.io/links/</li>
<li><input type="checkbox"><strong><font color="red"> NEXT
主题学习</font></strong>
<ul>
<li>https://cs-cshi.github.io/</li>
<li>https://benn314.github.io/2022/11/22/Hexo-Next%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B/</li>
</ul></li>
<li><input type="checkbox">整个blog目录，git私有化管理</li>
<li><input type="checkbox" checked>图片显示：阿里云OSS or 七牛云 or
sm.sm +Gopic图床管理</li>
<li><input type="checkbox">有的短知乎链接改了；mathpix 重新绘制</li>
<li><input type="checkbox" checked>mathpix
公式编辑？淘宝33元5000次</li>
<li><input type="checkbox" checked>Post自动编号，显示章节？：https://blog.csdn.net/Passerby_Wang/article/details/121342829</li>
<li><input type="checkbox" checked>Hexo表格对齐：https://javahikers.github.io/2019/06/15/hexo-inserts-tables-in-a-variety-of-ways/</li>
<li><input type="checkbox" checked>Hexo功能增强插件：https://segmentfault.com/a/1190000018402194</li>
<li><input type="checkbox" checked>优化博客路径：npm install
hexo-abbrlink --save：https://github.com/rozbo/hexo-abbrlink</li>
<li><input type="checkbox">HEXO优化：https://zhuanlan.zhihu.com/p/30836436
<ul class="task-list">
<li><input type="checkbox"><strong><font color="red">添加 tags，<span id="more"></span>，修改章节</font></strong></li>
<li><input type="checkbox">配图？思维导图绘制？</li>
<li><input type="checkbox" checked><strong>给代码添加复制、高亮功能</strong>
<ul>
<li>https://hexo.io/zh-cn/docs/syntax-highlight.html</li>
</ul></li>
<li><input type="checkbox"><font color="red">友联。安全相关的网站:</font>
<ul class="task-list">
<li><input type="checkbox">小伍哥、马东、Bold-Falcon;</li>
</ul></li>
<li><input type="checkbox" checked>主页文章阴影加深</li>
<li><input type="checkbox" checked>表格里不能有公式？？<a href="https://blog.csdn.net/lx_ros/article/details/124240258?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-124240258-blog-126924064.235%5Ev29%5Epc_relevant_default_base3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-124240258-blog-126924064.235%5Ev29%5Epc_relevant_default_base3&amp;utm_relevant_index=2">公式显示优化</a>
<ul>
<li>https://www.jianshu.com/p/7ab21c7f0674</li>
</ul></li>
<li><input type="checkbox">新建404界面</li>
<li><input type="checkbox"><strong>分类界面优化，分类介绍（专栏的描述），排序</strong>
<ul>
<li>分级收起</li>
<li>分类文章top设置</li>
</ul></li>
<li><input type="checkbox">标签界面优化-词云页面：https://zhuanlan.zhihu.com/p/149575559</li>
<li><input type="checkbox">图片加水印</li>
<li><input type="checkbox" checked><strong>更改字体 和
段落间距</strong></li>
<li><input type="checkbox">统一参考文献</li>
<li><input type="checkbox"><strong>引用两边对齐？</strong></li>
<li><input type="checkbox">相关文章</li>
<li><input type="checkbox">文章置顶</li>
<li><input type="checkbox">toc 侧边栏中文跳转</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>博客搭建</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（13）结构设计</title>
    <url>/posts/2G3EX7Q/</url>
    <content><![CDATA[<h2><span id="一-前缀树">一、前缀树</span></h2>
<blockquote>
<p>一种好用的树结构：Trie树:https://zhuanlan.zhihu.com/p/508575094</p>
</blockquote>
<h3><span id="11trie树简介-有限状态自动机-文本词频统计"><strong>1.1
Trie树简介</strong> [有限状态自动机] [文本词频统计]</span></h3>
<p>在计算机科学中，trie，又称<strong>前缀树</strong>或<strong>字典树</strong>，是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。</p>
<p>Trie这个术语来自于retrieval。根据词源学，trie的发明者Edward
Fredkin把它读作/ˈtriː/ "tree"。但是，其他作者把它读作/ˈtraɪ/ "try"。</p>
<p>在图示中，键标注在节点中，值标注在节点之下。每一个完整的英文单词对应一个特定的整数。<strong>Trie可以看作是一个确定有限状态自动机，尽管边上的符号一般是隐含在分支的顺序中的</strong>。
Eg.一个保存了8个单词的字典树的结构如下图所示，8个单词分别是：“A”，“to”，“tea”，“ted”，“ten”，“i”
，“in”，“inn”。</p>
<p><img src="https://pic1.zhimg.com/80/v2-8740aeac82cd2fc980cd1148ab1a64dc_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>另外，<strong>单词查找树，Trie树，是一种树形结构，是一种哈希树的变种</strong>。<strong>典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计</strong>。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。</p>
<h3><span id="12-trie树性质">1.2 <strong>Trie树性质</strong></span></h3>
<p>它有3个基本性质：</p>
<ul>
<li>根节点不包含字符，除根节点外每一个节点都只包含一个字符；</li>
<li>从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串；</li>
<li>每个节点的所有子节点包含的字符都不相同。</li>
</ul>
<h3><span id="13-基本操作">1.3 <strong>基本操作</strong></span></h3>
<p>其基本操作有：查找、插入和删除,当然删除操作比较少见。</p>
<h3><span id="14-实现方法"><strong>1.4 实现方法</strong></span></h3>
<p>搜索字典项目的方法为：</p>
<ul>
<li>从根结点开始一次搜索；</li>
<li>取得要查找关键词的第一个字母，并根据该字母选择对应的子树并转到该子树继续进行检索；</li>
<li>在相应的子树上，取得要查找关键词的第二个字母,并进一步选择对应的子树进行检索。</li>
<li>迭代过程……</li>
<li>在某个结点处，关键词的所有字母已被取出，则读取附在该结点上的信息，即完成查找。
其他操作类似处理</li>
</ul>
<h3><span id="15-实现trie-前缀树">1.5 实现<strong>Trie (前缀树)</strong></span></h3>
<p>Trie（发音类似 "try"）或者说 前缀树
是一种树形数据结构，用于高效地存储和检索字符串数据集中的键。这一数据结构有相当多的应用情景，例如自动补完和拼写检查。</p>
<p><strong>请你实现 Trie 类：</strong></p>
<ul>
<li><strong>Trie()</strong> :初始化前缀树对象。
<ul>
<li>self.children = [None] * 26 , <strong>指向子节点的指针数组
children</strong></li>
<li>self.isEnd = False ,
表示该节点<strong>是否为字符串的结尾</strong>。</li>
</ul></li>
<li><strong>void insert(String word)</strong> :向前缀树中插入字符串 word
。
<ul>
<li>我们<strong>从字典树的根开始</strong>，插入字符串。对于当前字符对应的子节点，有两种情况：
<ul>
<li><strong>子节点存在</strong>。沿着指针移动到子节点，继续处理下一个字符。</li>
<li><strong>子节点不存在</strong>。创建一个新的子节点，记录在children
数组的对应位置上，然后沿着指针移动到子节点，继续搜索下一个字符。</li>
</ul></li>
<li>重复以上步骤，直到处理字符串的最后一个字符，然后将当前节点标记为字符串的结尾。</li>
</ul></li>
<li><strong>boolean search(String word)</strong> 如果字符串 word
在前缀树中，返回 true（即，在检索之前已经插入）；否则，返回 false 。
<ul>
<li>我们从字典树的根开始，查找前缀。对于当前字符对应的子节点，有两种情况：
<ul>
<li>子节点存在。沿着指针移动到子节点，继续搜索下一个字符。</li>
<li>子节点不存在。说明字典树中不包含该前缀，返回空指针。</li>
</ul></li>
<li>重复以上步骤，直到返回空指针或搜索完前缀的最后一个字符。</li>
</ul></li>
<li><strong>boolean startsWith(String prefix)</strong>
如果之前已经插入的字符串 word 的前缀之一为 prefix ，返回 true
；否则，返回 false 。</li>
</ul>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">输入</span><br><span class="line">[&quot;Trie&quot;, &quot;insert&quot;, &quot;search&quot;, &quot;search&quot;, &quot;startsWith&quot;, &quot;insert&quot;, &quot;search&quot;]</span><br><span class="line">[[], [&quot;apple&quot;], [&quot;apple&quot;], [&quot;app&quot;], [&quot;app&quot;], [&quot;app&quot;], [&quot;app&quot;]]</span><br><span class="line">输出</span><br><span class="line">[null, null, true, false, true, null, true]</span><br><span class="line"></span><br><span class="line">解释</span><br><span class="line">Trie trie = new Trie();</span><br><span class="line">trie.insert(&quot;apple&quot;);</span><br><span class="line">trie.search(&quot;apple&quot;);   // 返回 True</span><br><span class="line">trie.search(&quot;app&quot;);     // 返回 False</span><br><span class="line">trie.startsWith(&quot;app&quot;); // 返回 True</span><br><span class="line">trie.insert(&quot;app&quot;);</span><br><span class="line">trie.search(&quot;app&quot;);     // 返回 True</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Trie</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.children = [<span class="literal">None</span>] * <span class="number">26</span></span><br><span class="line">        self.isEnd = <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">searchPrefix</span>(<span class="params">self, prefix: <span class="built_in">str</span></span>) -&gt; <span class="string">&quot;Trie&quot;</span>:</span><br><span class="line">        node = self <span class="comment"># 根节点</span></span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> prefix:</span><br><span class="line">            ch = <span class="built_in">ord</span>(ch) - <span class="built_in">ord</span>(<span class="string">&quot;a&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.children[ch]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">            node = node.children[ch]</span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">insert</span>(<span class="params">self, word: <span class="built_in">str</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        node = self</span><br><span class="line">        <span class="keyword">for</span> ch <span class="keyword">in</span> word:</span><br><span class="line">            ch = <span class="built_in">ord</span>(ch) - <span class="built_in">ord</span>(<span class="string">&quot;a&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> node.children[ch]:</span><br><span class="line">                node.children[ch] = Trie()</span><br><span class="line">            node = node.children[ch]</span><br><span class="line">        node.isEnd = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">search</span>(<span class="params">self, word: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        node = self.searchPrefix(word)</span><br><span class="line">        <span class="keyword">return</span> node <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> node.isEnd</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">startsWith</span>(<span class="params">self, prefix: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">return</span> self.searchPrefix(prefix) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<h2><span id="二-lru">二、LRU</span></h2>
<h4><span id="146lru-缓存"></span></h4>
<p>请你设计并实现一个满足 <a href="https://baike.baidu.com/item/LRU">LRU
(最近最少使用) 缓存</a> 约束的数据结构。</p>
<p>实现 <code>LRUCache</code> 类：</p>
<ul>
<li><code>LRUCache(int capacity)</code> 以 <strong>正整数</strong>
作为容量 <code>capacity</code> 初始化 LRU 缓存</li>
<li><code>int get(int key)</code> 如果关键字 <code>key</code>
存在于缓存中，则返回关键字的值，否则返回 <code>-1</code> 。</li>
<li><code>void put(int key, int value)</code> 如果关键字
<code>key</code> 已经存在，则变更其数据值 <code>value</code>
；如果不存在，则向缓存中插入该组 key-value
。如果插入操作导致关键字数量超过 capacity ，则应该 逐出
最久未使用的关键字。</li>
</ul>
<p>函数 <code>get</code> 和 <code>put</code> 必须以 <code>O(1)</code>
的平均时间复杂度运行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DLinkedNode</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, key = <span class="number">0</span>, value = <span class="number">0</span></span>):</span><br><span class="line">        self.key = key</span><br><span class="line">        self.value = value</span><br><span class="line">        self.prev = <span class="literal">None</span></span><br><span class="line">        self.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LRUCache</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, capacity: <span class="built_in">int</span></span>):</span><br><span class="line">      	<span class="comment"># 使用伪头部和伪尾部节点    </span></span><br><span class="line">        self.cache = <span class="built_in">dict</span>()</span><br><span class="line">        self.head = DLinkedNode()</span><br><span class="line">        self.tail = DLinkedNode()</span><br><span class="line">        self.head.<span class="built_in">next</span> = self.tail</span><br><span class="line">        self.tail.prev = self.head</span><br><span class="line">        self.capacity = capacity</span><br><span class="line">        self.size = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get</span>(<span class="params">self, key: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">not</span> <span class="keyword">in</span> self.cache:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        <span class="comment"># 如果 key 存在，先通过哈希表定位，再移到头部</span></span><br><span class="line">        node = self.cache[key]</span><br><span class="line">        self.moveToHead(node)<span class="comment"># &quot;如果数据被访问过。那未来的访问几率更高&quot;</span></span><br><span class="line">        <span class="keyword">return</span> node.value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">put</span>(<span class="params">self, key: <span class="built_in">int</span>, value: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">not</span> <span class="keyword">in</span> self.cache:</span><br><span class="line">          	<span class="comment"># 如果 key 不存在，创建一个新的节点</span></span><br><span class="line">            node = DLinkedNode(key, value)</span><br><span class="line">            <span class="comment"># 添加进哈希表</span></span><br><span class="line">            self.cache[key] = node</span><br><span class="line">            <span class="comment"># 添加至双向链表的头部</span></span><br><span class="line">            self.size += <span class="number">1</span></span><br><span class="line">            self.addToHead(node)</span><br><span class="line">            <span class="keyword">if</span> self.size &gt; self.capacity:</span><br><span class="line">              	<span class="comment"># 如果超出容量，删除双向链表的尾部节点</span></span><br><span class="line">                removed = self.removeTail()</span><br><span class="line">                <span class="comment"># 删除哈希表中对应的项</span></span><br><span class="line">                self.cache.pop(removed.key)</span><br><span class="line">                self.size -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          	<span class="comment"># 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部</span></span><br><span class="line">            node = self.cache[key]</span><br><span class="line">            node.value = value</span><br><span class="line">            self.moveToHead(node)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">addToHead</span>(<span class="params">self, node</span>):</span><br><span class="line">        node.prev = self.head</span><br><span class="line">        node.<span class="built_in">next</span> = self.head.<span class="built_in">next</span></span><br><span class="line">        self.head.<span class="built_in">next</span>.prev = node</span><br><span class="line">        self.head.<span class="built_in">next</span> = node</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">removeNode</span>(<span class="params">self, node</span>): </span><br><span class="line">        node.prev.<span class="built_in">next</span> = node.<span class="built_in">next</span></span><br><span class="line">        node.<span class="built_in">next</span>.prev = node.prev</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">moveToHead</span>(<span class="params">self, node</span>):</span><br><span class="line">        self.removeNode(node)</span><br><span class="line">        self.addToHead(node)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">removeTail</span>(<span class="params">self</span>):</span><br><span class="line">        node = self.tail.prev</span><br><span class="line">        self.removeNode(node)</span><br><span class="line">        <span class="keyword">return</span> node</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>LFU，最近不经常使用</strong>，把数据加入到链表中，按频次排序，一个数据被访问过，把它的频次+1，发生淘汰的时候，把频次低的淘汰掉。
比如有数据 1，1，1，2，2，3 缓存中有（1(3次)，2(2次)）
当3加入的时候，得把后面的2淘汰，变成（1(3次)，3(1次)） 区别：LRU 是得把
1 淘汰。</p>
</blockquote>
<h2><span id="三-并查集">三、并查集</span></h2>
<h4><span id="剑指-offer-ii-117相似的字符串"></span></h4>
<p>如果交换字符串 <code>X</code> 中的两个不同位置的字母，使得它和字符串
<code>Y</code> 相等，那么称 <code>X</code> 和 <code>Y</code>
两个字符串相似。如果这两个字符串本身是相等的，那它们也是相似的。例如，"tars"
和 "rats" 是相似的 (交换 0 与 2 的位置)； "rats" 和 "arts"
也是相似的，但是 "star" 不与 "tars"，"rats"，或 "arts" 相似。</p>
<p>总之，它们通过相似性形成了两个关联组：{"tars", "rats", "arts"} 和
{"star"}。注意，"tars" 和 "arts"
是在同一组中，即使它们并不相似。形式上，对每个组而言，要确定一个单词在组中，只需要这个词和该组中至少一个单词相似。</p>
<p>给定一个字符串列表 strs。列表中的每个字符串都是 strs
中其它所有字符串的一个 字母异位词 。请问 strs
中有多少个相似字符串组？</p>
<p><strong>字母异位词（anagram）</strong>，一种把某个字符串的字母的位置（顺序）加以改换所形成的新词。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UnionFind</span>:</span><br><span class="line">  	<span class="comment"># 并查集</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n</span>):</span><br><span class="line">        self.parent = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        self.count = n</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">if</span> self.parent[x] == x:</span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line">        self.parent[x] = self.find(self.parent[x])</span><br><span class="line">        <span class="keyword">return</span> self.parent[x]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">union</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        x, y = self.find(x), self.find(y)</span><br><span class="line">        <span class="keyword">if</span> x != y:</span><br><span class="line">            self.parent[x] = y</span><br><span class="line">            self.count -= <span class="number">1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numSimilarGroups</span>(<span class="params">self, strs: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">      	<span class="comment"># 相似的字符串</span></span><br><span class="line">        m, n = <span class="built_in">len</span>(strs), <span class="built_in">len</span>(strs[<span class="number">0</span>])</span><br><span class="line">        un = UnionFind(m)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, m):</span><br><span class="line">                cnt = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                    <span class="keyword">if</span> strs[i][k] != strs[j][k]:</span><br><span class="line">                        cnt += <span class="number">1</span></span><br><span class="line">                        <span class="keyword">if</span> cnt &gt; <span class="number">2</span>:</span><br><span class="line">                            <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">else</span>: <span class="comment"># 上下文管理器</span></span><br><span class="line">                    un.union(i, j)</span><br><span class="line">        <span class="keyword">return</span> un.count</span><br></pre></td></tr></table></figure>
<h2><span id="四-序列化与反序列化">四、序列化与反序列化</span></h2>
<ul>
<li>https://zhuanlan.zhihu.com/p/40462507</li>
</ul>
<p><strong>序列化：</strong>把对象转化为可传输的字节序列过程称为序列化。</p>
<p><strong>反序列化：</strong>把字节序列还原为对象的过程称为反序列化。</p>
<h4><span id="41-序列化的定义">4.1 序列化的定义</span></h4>
<p><strong>序列化</strong>：把对象转化为可传输的字节序列过程称为序列化。</p>
<p><strong>反序列化</strong>：把字节序列还原为对象的过程称为反序列化。</p>
<h4><span id="42-为什么要序列化">4.2 为什么要序列化？</span></h4>
<p>其实序列化最终的目的是为了对象可以<strong>跨平台存储，和进行网络传输</strong>。而我们进行跨平台存储和网络传输的方式就是IO，而我们的IO支持的数据格式就是字节数组。序列化只是一种拆装组装对象的规则，那么这种规则肯定也可能有多种多样，比如现在常见的序列化方式有：</p>
<p><strong>JDK（不支持跨语言）、JSON、XML、Hessian、Kryo（不支持跨语言）、Thrift、Protostuff、FST（不支持跨语言）</strong></p>
<h4><span id="剑指offer-37-序列化二叉树"></span></h4>
<p>请实现两个函数，分别用来序列化和反序列化二叉树。你需要设计一个算法来实现二叉树的序列化与反序列化。这里不限定你的序列
/
反序列化算法执行逻辑，你只需要保证一个二叉树可以被序列化为一个字符串并且将这个字符串反序列化为原始的树结构。</p>
<ul>
<li><h5><span id="深度优先遍历">深度优先遍历</span></h5></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Codec</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">serialize</span>(<span class="params">self, root</span>):</span><br><span class="line">        <span class="comment"># 后续遍历 比 前序遍历快很多 pop(), pop(0)</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; DFS : ncodes a tree to a single string.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        :type root: TreeNode</span></span><br><span class="line"><span class="string">        :rtype: str</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;None&#x27;</span></span><br><span class="line">        <span class="keyword">return</span>  <span class="built_in">str</span>(self.serialize(root.left)) + <span class="string">&#x27;,&#x27;</span> + <span class="built_in">str</span>(self.serialize(root.right)) + <span class="string">&#x27;,&#x27;</span> + <span class="built_in">str</span>(root.val) </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">deserialize</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Decodes your encoded data to tree.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        :type data: str</span></span><br><span class="line"><span class="string">        :rtype: TreeNode</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">dfslist:<span class="built_in">list</span>(<span class="params"></span>)</span>):</span><br><span class="line">            val = dfslist.pop()</span><br><span class="line">            <span class="keyword">if</span> val == <span class="string">&#x27;None&#x27;</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">            root = TreeNode(<span class="built_in">int</span>(val))</span><br><span class="line">            root.right = dfs(dfslist)</span><br><span class="line">            root.left = dfs(dfslist)</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        dfslist = data.split(<span class="string">&#x27;,&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> dfs(dfslist)</span><br></pre></td></tr></table></figure>
<h2><span id="五-线段树">五、线段树</span></h2>
<ul>
<li>算法学习笔记(14):
线段树：https://zhuanlan.zhihu.com/p/106118909</li>
</ul>
<p><strong>线段树</strong>（Segment
Tree）几乎是算法竞赛最常用的数据结构了，它主要用于维护<strong>区间信息</strong>（要求满足结合律）。与树状数组相比，它可以实现
<img src="https://www.zhihu.com/equation?tex=O%28%5Clog+n%29" alt="[公式]">
的<strong>区间修改</strong>，还可以同时支持<strong>多种操作</strong>（加、乘)，更具通用性。</p>
<p><img src="https://pic1.zhimg.com/80/v2-5e9124a6147143e51cea46755e9a0398_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BIT</span>:</span><br><span class="line">    <span class="comment"># 线段树: 动态维护前缀和数据的结构</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n</span>):</span><br><span class="line">        self.n = n</span><br><span class="line">        self.tree = [<span class="number">0</span>] * (n+<span class="number">1</span>)</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lowbit</span>(<span class="params">x</span>):</span><br><span class="line">        <span class="comment"># 二进制最小位1的位置</span></span><br><span class="line">        <span class="keyword">return</span> x&amp;(-x)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">query</span>(<span class="params">self, x</span>):</span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> x&gt;<span class="number">0</span>:</span><br><span class="line">            ans += self.tree[x]</span><br><span class="line">            x -= BIT.lowbit(x)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">while</span> x&lt;=self.n:</span><br><span class="line">            self.tree[x] += <span class="number">1</span></span><br><span class="line">            x += BIT.lowbit(x)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-51-数组中的逆序对"></span></h4>
<p>在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组，求出这个数组中的逆序对的总数。</p>
<ul>
<li><h4><span id="离散化树状数组">离散化树状数组</span></h4>
<ul>
<li><strong>单点更新 <code>update(i, v)</code>：</strong> 把序列
i<em>i</em> 位置的数加上一个值 v<em>，这题 v</em>=1</li>
<li><strong>区间查询 <code>query(i)</code>：</strong> 查询序列
[1⋯<em>i</em>] 区间的区间和，即 i<em>i</em> 位置的前缀和</li>
</ul></li>
</ul>
<p><strong>修改和查询的时间代价都是 O<em>(log</em>n<em>)，其中
n</em>为需要维护前缀和的序列的长度。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reversePairs</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 离散化+线性数组 nums = [7,5,6,4]</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="comment"># 求每个数比他小的有几个</span></span><br><span class="line">        tmp = <span class="built_in">sorted</span>(nums)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            nums[i] = bisect.bisect_left(tmp, nums[i]) + <span class="number">1</span></span><br><span class="line">        <span class="comment"># nums = [4,2,3,1]</span></span><br><span class="line">        bit = BIT(n) <span class="comment"># [0,0,0,0,0]</span></span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            ans += bit.query(nums[i] - <span class="number">1</span>)</span><br><span class="line">            bit.update(nums[i])</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h2><span id="自动机">自动机</span></h2>
<p><strong>字符串处理的题目往往涉及复杂的流程以及条件情况</strong>，如果直接上手写程序，一不小心就会写出极其臃肿的代码。</p>
<p>因此，为了有条理地分析每个输入字符的处理方法，我们可以使用自动机这个概念：</p>
<p>我们的程序在每个时刻有一个状态 s，每次从序列中输入一个字符
c，并根据字符 c 转移到下一个状态
s'。这样，我们只需要建立一个覆盖所有情况的从 s 与 c 映射到 s'
的表格即可解决题目中的问题。</p>
<h4><span id="算法">算法：</span></h4>
<p>本题可以建立如下图所示的自动机：</p>
<p><img src="https://assets.leetcode-cn.com/solution-static/8/fig1.png" alt="fig1" style="zoom: 50%;"></p>
<p>我们也可以用下面的表格来表示这个自动机：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220617125627816.png" alt="image-20220617125627816" style="zoom:50%;"></p>
<p>接下来编程部分就非常简单了：我们只需要把上面这个状态转换表抄进代码即可。另外自动机也需要记录当前已经输入的数字，只要在
s' 为 in_number 时，更新我们输入的数字，即可最终得到输入的数字。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">INT_MAX = <span class="number">2</span> ** <span class="number">31</span> - <span class="number">1</span></span><br><span class="line">INT_MIN = -<span class="number">2</span> ** <span class="number">31</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Automaton</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.state = <span class="string">&#x27;start&#x27;</span></span><br><span class="line">        self.sign = <span class="number">1</span></span><br><span class="line">        self.ans = <span class="number">0</span></span><br><span class="line">        self.table = &#123;</span><br><span class="line">            <span class="string">&#x27;start&#x27;</span>: [<span class="string">&#x27;start&#x27;</span>, <span class="string">&#x27;signed&#x27;</span>, <span class="string">&#x27;in_number&#x27;</span>, <span class="string">&#x27;end&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;signed&#x27;</span>: [<span class="string">&#x27;end&#x27;</span>, <span class="string">&#x27;end&#x27;</span>, <span class="string">&#x27;in_number&#x27;</span>, <span class="string">&#x27;end&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;in_number&#x27;</span>: [<span class="string">&#x27;end&#x27;</span>, <span class="string">&#x27;end&#x27;</span>, <span class="string">&#x27;in_number&#x27;</span>, <span class="string">&#x27;end&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;end&#x27;</span>: [<span class="string">&#x27;end&#x27;</span>, <span class="string">&#x27;end&#x27;</span>, <span class="string">&#x27;end&#x27;</span>, <span class="string">&#x27;end&#x27;</span>],</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_col</span>(<span class="params">self, c</span>):</span><br><span class="line">        <span class="keyword">if</span> c.isspace():</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> c == <span class="string">&#x27;+&#x27;</span> <span class="keyword">or</span> c == <span class="string">&#x27;-&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> c.isdigit():</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get</span>(<span class="params">self, c</span>):</span><br><span class="line">        self.state = self.table[self.state][self.get_col(c)]</span><br><span class="line">        <span class="keyword">if</span> self.state == <span class="string">&#x27;in_number&#x27;</span>:</span><br><span class="line">            self.ans = self.ans * <span class="number">10</span> + <span class="built_in">int</span>(c)</span><br><span class="line">            self.ans = <span class="built_in">min</span>(self.ans, INT_MAX) <span class="keyword">if</span> self.sign == <span class="number">1</span> <span class="keyword">else</span> <span class="built_in">min</span>(self.ans, -INT_MIN)</span><br><span class="line">        <span class="keyword">elif</span> self.state == <span class="string">&#x27;signed&#x27;</span>:</span><br><span class="line">            self.sign = <span class="number">1</span> <span class="keyword">if</span> c == <span class="string">&#x27;+&#x27;</span> <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">myAtoi</span>(<span class="params">self, <span class="built_in">str</span>: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        automaton = Automaton()</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">str</span>:</span><br><span class="line">            automaton.get(c)</span><br><span class="line">        <span class="keyword">return</span> automaton.sign * automaton.ans</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（15）排序*</title>
    <url>/posts/3XW082X/</url>
    <content><![CDATA[<h2><span id="排序">排序</span></h2>
<h3><span id="一-快速排序">一、快速排序</span></h3>
<h4><span id="剑指-offer40-最小的k个数"></span></h4>
<p>输入整数数组 <code>arr</code> ，找出其中<strong>最小的 <code>k</code>
个数</strong>。例如，输入4、5、1、6、2、7、3、8这8个数字，则最小的4个数字是1、2、3、4。</p>
<p><strong>（最小）堆排序算法</strong>：https://docs.python.org/zh-cn/3/library/heapq.html</p>
<ul>
<li>==<strong>快速选择、堆排序</strong>==</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getLeastNumbers</span>(<span class="params">self, arr: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># 堆排序</span></span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">list</span>()</span><br><span class="line">        hp = [ -x <span class="keyword">for</span> x <span class="keyword">in</span> arr[:k]]</span><br><span class="line">        heapq.heapify(hp)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k, <span class="built_in">len</span>(arr)):</span><br><span class="line">            <span class="keyword">if</span> -hp[<span class="number">0</span>] &gt; arr[i]:</span><br><span class="line">                heapq.heappop(hp)</span><br><span class="line">                heapq.heappush(hp, -arr[i])</span><br><span class="line">        arr = [-x <span class="keyword">for</span> x <span class="keyword">in</span> hp]</span><br><span class="line">        <span class="keyword">return</span> arr   </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getLeastNumbers</span>(<span class="params">self, arr: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># 快速选择</span></span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">quickSelect</span>(<span class="params">low, high, k</span>):</span><br><span class="line">            pvoit = random.randint(low, high)</span><br><span class="line">            arr[pvoit], arr[low] = arr[low], arr[pvoit]</span><br><span class="line">            base = arr[low] </span><br><span class="line">            i = low</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(low+<span class="number">1</span>, high+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> arr[j] &lt; base:</span><br><span class="line">                    arr[i+<span class="number">1</span>], arr[j] = arr[j], arr[i+<span class="number">1</span>]</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">            arr[low], arr[i] = arr[i], arr[low] </span><br><span class="line">            <span class="keyword">if</span> i == k - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> arr[:k]</span><br><span class="line">            <span class="keyword">elif</span> i &lt; k - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> quickSelect(i+<span class="number">1</span>, high, k)</span><br><span class="line">            <span class="keyword">else</span>: </span><br><span class="line">                <span class="keyword">return</span> quickSelect(low, i-<span class="number">1</span>, k)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> quickSelect(<span class="number">0</span>, <span class="built_in">len</span>(arr) - <span class="number">1</span>, k)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-076数组中的第-k-大的数字"></span></h4>
<blockquote>
<p>https://leetcode.cn/problems/kth-largest-element-in-an-array/solution/cpython3java-1da-gen-dui-diao-ku-2shou-l-xveq/</p>
</blockquote>
<p>给定整数数组 <code>nums</code> 和整数 <code>k</code>，请返回数组中第
<code>k</code> 个最大的元素。请注意，你需要找的是<strong>数组排序后的第
<code>k</code> 个最大的元素，而不是第 <code>k</code>
个不同的元素。</strong></p>
<ul>
<li>小根堆调库、快速选择</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findKthLargest</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        heap = []</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(heap) &gt;= k:</span><br><span class="line">                <span class="keyword">if</span> num &gt; heap[<span class="number">0</span>]: <span class="comment"># 注意替换条件</span></span><br><span class="line">                    heapq.heapreplace(heap, num)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                heapq.heappush(heap, num)</span><br><span class="line">        <span class="keyword">return</span> heap[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findKthLargest</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 快速选择</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">findTopk</span>(<span class="params">low, high</span>):</span><br><span class="line">            pvoit = random.randint(low, high)</span><br><span class="line">            nums[pvoit], nums[low] = nums[low], nums[pvoit]</span><br><span class="line">            base = nums[low]</span><br><span class="line">            i = low </span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(low + <span class="number">1</span>, high + <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> nums[j] &gt; base:</span><br><span class="line">                    nums[i + <span class="number">1</span>], nums[j] = nums[j], nums[i + <span class="number">1</span>]</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">            nums[i], nums[low] = nums[low], nums[i]</span><br><span class="line">            <span class="keyword">if</span> i == k - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> nums[i]</span><br><span class="line">            <span class="keyword">elif</span> i &lt; k - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> findTopk(i + <span class="number">1</span>, high)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> findTopk(low, i - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> findTopk(<span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-45-把数组排成最小的数"></span></h4>
<p>输入一个<strong>非负</strong>整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。</p>
<ul>
<li>【基于快排】+【<strong>拼接字符串</strong>】</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_smallA</span>(<span class="params">a, b</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span> <span class="keyword">if</span> a + b &lt; b + a <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">partition</span>(<span class="params">l, r</span>):</span><br><span class="line">            pivot = random.randint(l, r)</span><br><span class="line">            nums[pivot], nums[l] = nums[l], nums[pivot]</span><br><span class="line">            base = nums[l]</span><br><span class="line">            i = l</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(l+<span class="number">1</span>, r+<span class="number">1</span>): <span class="comment"># r+1 遍历到r</span></span><br><span class="line">                <span class="keyword">if</span> _smallA(nums[j], base):</span><br><span class="line">                    nums[j], nums[i+<span class="number">1</span>] = nums[i+<span class="number">1</span>], nums[j] <span class="comment"># i + 1 与i前面的换</span></span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">            nums[l], nums[i] = nums[i], nums[l]</span><br><span class="line">            <span class="keyword">return</span> i</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">quick_sort</span>(<span class="params">l, r</span>):</span><br><span class="line">            <span class="keyword">if</span> r - l &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            mid = partition(l, r)</span><br><span class="line">            quick_sort(l, mid - <span class="number">1</span>)</span><br><span class="line">            quick_sort(mid + <span class="number">1</span>, r)</span><br><span class="line">        nums = [<span class="built_in">str</span>(num) <span class="keyword">for</span> num <span class="keyword">in</span> nums]</span><br><span class="line">        quick_sort(<span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join(nums).lstrip()</span><br></pre></td></tr></table></figure>
<ul>
<li><h5><span id="内置函数cmp_to_key单个元素并没有一个绝对的大小的情况">内置函数：cmp_to_key，单个元素并没有一个绝对的大小的情况</span></h5></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:    </span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">largestNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        nums.sort(key=cmp_to_key(<span class="keyword">lambda</span> x,y: <span class="built_in">int</span>(<span class="built_in">str</span>(y)+<span class="built_in">str</span>(x)) - <span class="built_in">int</span>(<span class="built_in">str</span>(x)+<span class="built_in">str</span>(y))))</span><br><span class="line">        ans = <span class="string">&#x27;&#x27;</span>.join([<span class="built_in">str</span>(num) <span class="keyword">for</span> num <span class="keyword">in</span> nums])</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">str</span>(<span class="built_in">int</span>(ans))</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-61-扑克牌中的顺子"></span></h4>
<p>从若干副扑克牌中随机抽 5
张牌，判断是不是一个顺子，即这5张牌是不是连续的。2～10为数字本身，A为1，J为11，Q为12，K为13，而大、小王为
0 ，可以看成任意数字。A 不能视为 14。</p>
<ul>
<li>集合 Set + 遍历，排序 + 遍历</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isStraight</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        pset = <span class="built_in">set</span>()</span><br><span class="line">        mi, ma = <span class="number">14</span>, -<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> num <span class="keyword">in</span> pset:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            mi = <span class="built_in">min</span>(mi, num)</span><br><span class="line">            ma = <span class="built_in">max</span>(ma, num)</span><br><span class="line">            pset.add(num)</span><br><span class="line">        <span class="keyword">return</span> ma - mi &lt; <span class="number">5</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isStraight</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        joker = <span class="number">0</span></span><br><span class="line">        nums.sort() <span class="comment"># 数组排序</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            <span class="keyword">if</span> nums[i] == <span class="number">0</span>: joker += <span class="number">1</span> <span class="comment"># 统计大小王数量</span></span><br><span class="line">            <span class="keyword">elif</span> nums[i] == nums[i + <span class="number">1</span>]: <span class="keyword">return</span> <span class="literal">False</span> <span class="comment"># 若有重复，提前返回 false</span></span><br><span class="line">        <span class="keyword">return</span> nums[<span class="number">4</span>] - nums[joker] &lt; <span class="number">5</span> <span class="comment"># 最大牌 - 最小牌 &lt; 5 则可构成顺子</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-41-数据流中的中位数"></span></h4>
<p>如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。</p>
<ul>
<li>大小堆排序</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">heappush(self.B, -heappushpop(self.A, num))<span class="keyword">class</span> <span class="title class_">MedianFinder</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        initialize your data structure here.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.minheap = []</span><br><span class="line">        self.maxheap = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">addNum</span>(<span class="params">self, num: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.minheap) != <span class="built_in">len</span>(self.maxheap):</span><br><span class="line">          	<span class="comment"># heappush(self.B, -heappushpop(self.A, num))</span></span><br><span class="line">            heappush(self.minheap, num)</span><br><span class="line">            heappush(self.maxheap, -heappop(self.minheap))</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># 【len等于时，min多】</span></span><br><span class="line">            heappush(self.maxheap, -num)</span><br><span class="line">            heappush(self.minheap, -heappop(self.maxheap))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findMedian</span>(<span class="params">self</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="keyword">return</span> self.minheap[<span class="number">0</span>] <span class="keyword">if</span> <span class="built_in">len</span>(self.minheap) != <span class="built_in">len</span>(self.maxheap) <span class="keyword">else</span> (self.minheap[<span class="number">0</span>] - self.maxheap[<span class="number">0</span>] ) / <span class="number">2.0</span></span><br></pre></td></tr></table></figure>
<h3><span id="二-归并排序">二、归并排序</span></h3>
<p>「归并排序」是分治思想的典型应用。</p>
<h4><span id="剑指offer-51-数组中的逆序对"></span></h4>
<p>在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组，求出这个数组中的逆序对的总数。</p>
<p><strong><font color="red">那么求逆序对和归并排序又有什么关系呢？
</font></strong></p>
<p>两个已排序的序列等待<strong>合并</strong>，记录计算逆序对的数量；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reversePairs</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">mergeSort</span>(<span class="params">nums, low, high</span>):</span><br><span class="line">            <span class="keyword">if</span> low &gt;= high:     <span class="comment"># 递归终止</span></span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>        </span><br><span class="line">            ans = <span class="number">0</span>             <span class="comment"># 记录当前逆序对数目</span></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;递归排序&#x27;&#x27;&#x27;</span></span><br><span class="line">            mid = low+(high-low)//<span class="number">2</span>     </span><br><span class="line">            ans += mergeSort(nums, low, mid)        <span class="comment"># 左半部分逆序对数目</span></span><br><span class="line">            ans += mergeSort(nums, mid+<span class="number">1</span>, high)     <span class="comment"># 右半部分逆序对数目</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;nums[low, mid] 和 nums[mid+1, high] 已排序好&#x27;&#x27;&#x27;</span></span><br><span class="line">            tmp = []        <span class="comment"># 记录nums[low, high]排序结果</span></span><br><span class="line">            left, right = low, mid+<span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> left&lt;=mid <span class="keyword">and</span> right&lt;=high:</span><br><span class="line">                <span class="keyword">if</span> nums[left] &lt;= nums[right]:</span><br><span class="line">                    tmp.append(nums[left])</span><br><span class="line">                    left += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:       <span class="comment"># 后半部分值较小，出现了逆序</span></span><br><span class="line">                    tmp.append(nums[right])</span><br><span class="line">                    right += <span class="number">1</span></span><br><span class="line">                    ans += mid+<span class="number">1</span>-left       <span class="comment"># 当前值 nums[right] 贡献的逆序对个数为 mid+1-left</span></span><br><span class="line">                    <span class="string">&#x27;&#x27;&#x27;解释：若nums[left] &gt; nums[right]，</span></span><br><span class="line"><span class="string">                       则nums[left, mid] &gt; nums[right]均成立，共 mid+1-left 项&#x27;&#x27;&#x27;</span></span><br><span class="line">            </span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;左或右数组需遍历完（最多只有一个未遍历完）&#x27;&#x27;&#x27;</span></span><br><span class="line">            <span class="keyword">while</span> left&lt;=mid:</span><br><span class="line">                tmp.append(nums[left])</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> right&lt;=high:</span><br><span class="line">                tmp.append(nums[right])</span><br><span class="line">                right += <span class="number">1</span></span><br><span class="line">                <span class="comment"># ans += mid+1-left     # 此时，前半部分一定已经遍历完了，即left=mid+1，因此无需再更新结果</span></span><br><span class="line">            nums[low:high+<span class="number">1</span>] = tmp</span><br><span class="line">            <span class="keyword">return</span> ans</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;主程序&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> mergeSort(nums, <span class="number">0</span>, <span class="built_in">len</span>(nums)-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-077-链表归并排序"></span></h4>
<p>给定链表的头结点 <code>head</code> ，请将其按 <strong>升序</strong>
排列并返回 <strong>排序后的链表</strong> 。</p>
<p><img src="https://assets.leetcode.com/uploads/2020/09/14/sort_list_1.jpg" alt="img" style="zoom: 67%;"></p>
<blockquote>
<p>输入：head = [4,2,1,3] 输出：[1,2,3,4]</p>
</blockquote>
<ul>
<li><strong>归并排序 + 递归</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sortList</span>(<span class="params">self, head: <span class="type">Optional</span>[ListNode]</span>) -&gt; <span class="type">Optional</span>[ListNode]:</span><br><span class="line">        <span class="comment"># 时间空间复杂度分别为 O(nlogn) 和 O(1) 【归并排序】</span></span><br><span class="line">        <span class="comment"># 【切分数组】</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head <span class="keyword">or</span> <span class="keyword">not</span> head.<span class="built_in">next</span>:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        slow, fast = head, head.<span class="built_in">next</span> <span class="comment"># 快慢指针【如何】初始化</span></span><br><span class="line">        <span class="keyword">while</span> fast <span class="keyword">and</span> fast.<span class="built_in">next</span>:</span><br><span class="line">            fast, slow = fast.<span class="built_in">next</span>.<span class="built_in">next</span>, slow.<span class="built_in">next</span></span><br><span class="line">        mid, slow.<span class="built_in">next</span> = slow.<span class="built_in">next</span>, <span class="literal">None</span> <span class="comment"># None截断</span></span><br><span class="line">        left, right = self.sortList(head), self.sortList(mid) <span class="comment"># 递归</span></span><br><span class="line">        <span class="comment"># 【合并链表】</span></span><br><span class="line">        h = dummy = ListNode(<span class="number">0</span>) <span class="comment"># 新建节点的合并</span></span><br><span class="line">        <span class="keyword">while</span> left <span class="keyword">and</span> right:</span><br><span class="line">            <span class="keyword">if</span> left.val &lt; right.val:</span><br><span class="line">                h.<span class="built_in">next</span> = left</span><br><span class="line">                left = left.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                h.<span class="built_in">next</span> = right</span><br><span class="line">                right = right.<span class="built_in">next</span></span><br><span class="line">            h = h.<span class="built_in">next</span></span><br><span class="line">        h.<span class="built_in">next</span> = left <span class="keyword">if</span> left <span class="keyword">else</span> right</span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-078-合并排序链表"></span></h4>
<p><strong>给定一个链表数组，每个链表都已经按升序排列</strong>。请将所有链表合并到一个升序链表中，返回合并后的链表。</p>
<blockquote>
<p>输入：lists = [[1,4,5], [1,3,4], [2,6]] 输出：[1,1,2,3,4,4,5,6]
解释：链表数组如下： [ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6 ]
将它们合并到一个有序链表中得到。
1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6</p>
</blockquote>
<ul>
<li><strong><font color="red"> 【优先队列】[推荐]
维护多个链表对象</font></strong>；时间：O(nlog(k))，<code>n</code>
是所有链表中元素总和，<code>k</code> 是链表个数；</li>
<li>【<strong>归并排序</strong>】链表两两合并，递归占用很多空间；</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mergeKLists</span>(<span class="params">self, lists: <span class="type">List</span>[ListNode]</span>) -&gt; ListNode:</span><br><span class="line">        <span class="comment"># 优先队列 维护多个链表对象</span></span><br><span class="line">        h = dummy = ListNode(<span class="number">0</span>)</span><br><span class="line">        heap = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lists)):</span><br><span class="line">            <span class="keyword">if</span> lists[i]:</span><br><span class="line">                heapq.heappush(heap, (lists[i].val, i))</span><br><span class="line">                lists[i] = lists[i].<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">while</span> heap:</span><br><span class="line">            val, idx = heapq.heappop(heap)</span><br><span class="line">            h.<span class="built_in">next</span> = ListNode(val)</span><br><span class="line">            h = h.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">if</span> lists[idx]:</span><br><span class="line">                heapq.heappush(heap, (lists[idx].val, idx))</span><br><span class="line">                lists[idx] = lists[idx].<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mergeKLists</span>(<span class="params">self, lists: <span class="type">List</span>[ListNode]</span>) -&gt; ListNode:</span><br><span class="line">      	<span class="comment"># 【归并排序】链表两两合并</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> lists:<span class="keyword">return</span> </span><br><span class="line">        n = <span class="built_in">len</span>(lists)</span><br><span class="line">        <span class="keyword">return</span> self.merge(lists, <span class="number">0</span>, n-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">merge</span>(<span class="params">self,lists, left, right</span>):</span><br><span class="line">        <span class="keyword">if</span> left == right:</span><br><span class="line">            <span class="keyword">return</span> lists[left]</span><br><span class="line">        mid = left + (right - left) // <span class="number">2</span></span><br><span class="line">        l1 = self.merge(lists, left, mid)</span><br><span class="line">        l2 = self.merge(lists, mid+<span class="number">1</span>, right)</span><br><span class="line">        <span class="keyword">return</span> self.mergeTwoLists(l1, l2)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mergeTwoLists</span>(<span class="params">self,l1, l2</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> l1:<span class="keyword">return</span> l2</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> l2:<span class="keyword">return</span> l1</span><br><span class="line">        <span class="keyword">if</span> l1.val &lt; l2.val:</span><br><span class="line">            l1.<span class="built_in">next</span> = self.mergeTwoLists(l1.<span class="built_in">next</span>, l2)</span><br><span class="line">            <span class="keyword">return</span> l1</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            l2.<span class="built_in">next</span> = self.mergeTwoLists(l1, l2.<span class="built_in">next</span>)</span><br><span class="line">            <span class="keyword">return</span> l2</span><br></pre></td></tr></table></figure>
<h2><span id="三-堆排序">三、堆排序</span></h2>
<blockquote>
<p>Python
十大排序算法：https://leetcode.cn/problems/sort-an-array/solution/python-shi-xian-de-shi-da-jing-dian-pai-xu-suan-fa/</p>
</blockquote>
<p>堆排序是利用堆这个数据结构设计的排序算法。</p>
<h4><span id="算法描述">算法描述：</span></h4>
<ul>
<li><strong>建堆，从底向上==调整堆==</strong>，使得父亲节点比孩子节点值大，构成大顶堆；</li>
<li>交换堆顶和最后一个元素，重新调整堆。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 递归写法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">adjust_heap</span>(<span class="params">nums, startpos, endpos</span>):</span><br><span class="line">        pos = startpos</span><br><span class="line">        chilidpos = pos * <span class="number">2</span> + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> chilidpos &lt; endpos:</span><br><span class="line">            rightpos = chilidpos + <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> rightpos &lt; endpos <span class="keyword">and</span> nums[rightpos] &gt; nums[chilidpos]:</span><br><span class="line">                chilidpos = rightpos</span><br><span class="line">            <span class="keyword">if</span> nums[chilidpos] &gt; nums[pos]:</span><br><span class="line">                nums[pos], nums[chilidpos] = nums[chilidpos], nums[pos]</span><br><span class="line">                adjust_heap(nums, pos, endpos)</span><br><span class="line">    <span class="comment"># 迭代写法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">adjust_heap</span>(<span class="params">nums, startpos, endpos</span>):</span><br><span class="line">        newitem = nums[startpos]</span><br><span class="line">        pos = startpos</span><br><span class="line">        childpos = pos * <span class="number">2</span> + <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> childpos &lt; endpos:</span><br><span class="line">            rightpos = childpos + <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> rightpos &lt; endpos <span class="keyword">and</span> nums[rightpos] &gt;= nums[childpos]:</span><br><span class="line">                childpos = rightpos</span><br><span class="line">            <span class="keyword">if</span> newitem &lt; nums[childpos]:</span><br><span class="line">                nums[pos] = nums[childpos]</span><br><span class="line">                pos = childpos</span><br><span class="line">                childpos = pos * <span class="number">2</span> + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        nums[pos] = newitem</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-059数据流的第-k-大数值"></span></h4>
<p>设计一个找到数据流中第 <code>k</code>
大元素的类（class）。注意是排序后的第 <code>k</code> 大元素，不是第
<code>k</code> 个不同的元素。</p>
<p><strong>请实现 KthLargest 类：</strong></p>
<ul>
<li>KthLargest(int k, int[] nums) 使用整数 k 和整数流 nums
初始化对象。</li>
<li>int add(int val) 将 val 插入数据流 nums 后，返回当前数据流中第 k
大的元素。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">KthLargest</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, k: <span class="built_in">int</span>, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>):</span><br><span class="line">        self.heap = []</span><br><span class="line">        self.size = k </span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            self._push(num)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_push</span>(<span class="params">self, num</span>):</span><br><span class="line">        <span class="keyword">if</span> self.size &lt;= <span class="built_in">len</span>(self.heap):</span><br><span class="line">            <span class="keyword">if</span> self.heap[<span class="number">0</span>] &lt; num:</span><br><span class="line">                heapq.heappop(self.heap)</span><br><span class="line">                heapq.heappush(self.heap, num)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            heapq.heappush(self.heap, num)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, val: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        self._push(val)</span><br><span class="line">        <span class="keyword">return</span> self.heap[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-060出现频率最高的-k-个数字"></span></h4>
<p>给定一个整数数组 <code>nums</code> 和一个整数 <code>k</code>
，请返回其中出现频率前 <code>k</code> 高的元素。可以按
<strong>任意顺序</strong> 返回答案。</p>
<ul>
<li>API :
<code>return [c[0] for c in Counter(nums).most_common(k)]</code></li>
<li>快速选择</li>
<li>堆排序</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">topKFrequent</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">findTopk</span>(<span class="params">low, high</span>):</span><br><span class="line">            pivot = random.randint(low, high)</span><br><span class="line">            nums_cnt[pivot], nums_cnt[low] = nums_cnt[low], nums_cnt[pivot]</span><br><span class="line">            base = nums_cnt[low][<span class="number">1</span>]</span><br><span class="line">            i = low</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(low + <span class="number">1</span>, high + <span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> nums_cnt[j][<span class="number">1</span>] &gt; base:</span><br><span class="line">                    nums_cnt[i + <span class="number">1</span>], nums_cnt[j] = nums_cnt[j], nums_cnt[i + <span class="number">1</span>]</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">            nums_cnt[i], nums_cnt[low] = nums_cnt[low], nums_cnt[i]</span><br><span class="line">            <span class="keyword">if</span> i == k - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> nums_cnt[:k]</span><br><span class="line">            <span class="keyword">elif</span> i &lt; k - <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> findTopk(i + <span class="number">1</span>, high)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> findTopk(low, i - <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        nums_cnt = <span class="built_in">list</span>(Counter(nums).items())</span><br><span class="line">        res = findTopk(<span class="number">0</span>, <span class="built_in">len</span>(nums_cnt) - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> [r[<span class="number">0</span>] <span class="keyword">for</span> r <span class="keyword">in</span> res]</span><br><span class="line">		<span class="keyword">def</span> <span class="title function_">topKFrequent</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># 堆排序</span></span><br><span class="line">        <span class="comment"># heapq.nlargest(n, iterable, key=None)</span></span><br><span class="line">        <span class="comment"># 【val, key】 heapq 中优先比[0]</span></span><br><span class="line">        conter = Counter(nums)</span><br><span class="line">        heap = []</span><br><span class="line">        <span class="keyword">for</span> key, val <span class="keyword">in</span> conter.items():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(heap) &gt;= k:</span><br><span class="line">                <span class="keyword">if</span> val &gt; heap[<span class="number">0</span>][<span class="number">0</span>]:</span><br><span class="line">                    heapq.heapreplace(heap,(val, key))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                heapq.heappush(heap,(val, key))</span><br><span class="line">        <span class="keyword">return</span> [item[<span class="number">1</span>] <span class="keyword">for</span> item <span class="keyword">in</span> heap]</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-061-和最小的k-个数对"></span></h4>
<p>给定两个<strong>以升序排列</strong>的整数数组 nums1 和 nums2 ,
以及一个整数 k 。定义一对值 (u,v)，其中第一个元素来自
nums1，第二个元素来自 nums2 。请找到和最小的 k 个数对 (u1,v1), (u2,v2)
... (uk,vk) 。</p>
<blockquote>
<p><strong>输入</strong>: nums1 = [1,7,11], nums2 = [2,4,6], k = 3
<strong>输出</strong>: [1,2],[1,4],[1,6] <strong>解释</strong>:
返回序列中的前 3 对数：
[1,2],[1,4],[1,6],[7,2],[7,4],[11,2],[7,6],[11,4],[11,6]</p>
</blockquote>
<ul>
<li><strong>多路归并【优先队列】</strong>、<strong>二分查找</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">kSmallestPairs</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="comment"># 【BFS】【优先队列, 排序输出交给堆】【去重】</span></span><br><span class="line">        m, n = <span class="built_in">len</span>(nums1), <span class="built_in">len</span>(nums2)</span><br><span class="line">        heap = [(nums1[<span class="number">0</span>] + nums2[<span class="number">0</span>], <span class="number">0</span>, <span class="number">0</span>)]</span><br><span class="line">        res = []</span><br><span class="line">        visited = <span class="built_in">set</span>()</span><br><span class="line">        <span class="keyword">while</span> heap:</span><br><span class="line">            val, i, j = heapq.heappop(heap) </span><br><span class="line">            res.append((nums1[i], nums2[j]))</span><br><span class="line">            visited.add((i, j))</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(res) == k:</span><br><span class="line">                <span class="keyword">return</span> res</span><br><span class="line">            <span class="keyword">if</span> i + <span class="number">1</span> &lt; m <span class="keyword">and</span> (i + <span class="number">1</span>, j) <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">                heapq.heappush(heap, (nums1[i + <span class="number">1</span>] + nums2[j], i + <span class="number">1</span>, j))</span><br><span class="line">                visited.add((i + <span class="number">1</span>, j))</span><br><span class="line">            <span class="keyword">if</span> j + <span class="number">1</span> &lt; n <span class="keyword">and</span> (i, j + <span class="number">1</span>) <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">                heapq.heappush(heap, (nums1[i] + nums2[j + <span class="number">1</span>], i, j + <span class="number">1</span>))</span><br><span class="line">                visited.add((i, j + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="56合并区间"></span></h4>
<p>以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] =
[starti, endi] 。请你合并所有重叠的区间，并返回
一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间 。</p>
<blockquote>
<p>输入：intervals = [[1,3],[2,6],[8,10],[15,18]]
输出：[[1,6],[8,10],[15,18]] 解释：区间 [1,3] 和 [2,6] 重叠,
将它们合并为 [1,6].</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">merge</span>(<span class="params">self, intervals: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        n = <span class="built_in">len</span>(intervals)</span><br><span class="line">        intervals.sort(key = <span class="keyword">lambda</span> x: x[<span class="number">0</span>])</span><br><span class="line">        ans = []</span><br><span class="line">        ans.append(intervals[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">if</span> ans[-<span class="number">1</span>][<span class="number">1</span>] &gt;= intervals[i][<span class="number">0</span>]:</span><br><span class="line">                <span class="keyword">if</span> (t := intervals[i][<span class="number">1</span>]) &gt; ans[-<span class="number">1</span>][<span class="number">1</span>]:</span><br><span class="line">                    ans[-<span class="number">1</span>][<span class="number">1</span>] = t</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                ans.append(intervals[i])</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-075数组相对排序"></span></h4>
<p>给定两个数组，arr1 和 arr2，</p>
<ul>
<li>arr2 中的元素各不相同</li>
<li>arr2 中的每个元素都出现在 arr1 中</li>
</ul>
<p>对 arr1 中的元素进行排序，使 arr1 中项的相对顺序和 arr2
中的相对顺序相同。未在 arr2 中出现过的元素需要按照升序放在 arr1
的末尾。</p>
<ul>
<li><strong>自定义排序</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">relativeSortArray</span>(<span class="params">self, arr1: <span class="type">List</span>[<span class="built_in">int</span>], arr2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">cmp</span>(<span class="params">k</span>):</span><br><span class="line">            <span class="keyword">return</span> (<span class="number">0</span>, cmpDict[k]) <span class="keyword">if</span> k <span class="keyword">in</span> cmpDict <span class="keyword">else</span> (<span class="number">1</span>, k) </span><br><span class="line">        cmpDict = &#123;val:i <span class="keyword">for</span> i, val <span class="keyword">in</span> <span class="built_in">enumerate</span>(arr2)&#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sorted</span>(arr1, key = cmp)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（2）链表</title>
    <url>/posts/2T4SP03/</url>
    <content><![CDATA[<h2><span id="链表">链表</span></h2>
<blockquote>
<p>在对链表进行操作时，一种常用的技巧是添加一个哑节点（dummy
node），它的 next
指针指向链表的头节点。这样一来，我们就不需要对头节点进行特殊的判断了。</p>
</blockquote>
<h4><span id="剑指offer-06-从尾到头打印链表"></span></h4>
<ul>
<li><strong>递归、辅助栈</strong></li>
</ul>
<p>输入一个链表的头节点，<strong>从尾到头反过来返回每个节点的值（用数组返回）</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">  	<span class="keyword">def</span> <span class="title function_">reversePrint</span>(<span class="params">self, head: ListNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">    		<span class="comment"># 递归法</span></span><br><span class="line">        <span class="keyword">return</span> self.reversePrint(head.<span class="built_in">next</span>) + [head.val] <span class="keyword">if</span> head <span class="keyword">else</span> []</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reversePrint</span>(<span class="params">self, head: ListNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">      	<span class="comment"># 辅助栈法</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        ans = []</span><br><span class="line">        <span class="keyword">while</span> head:</span><br><span class="line">            ans.append(head.val)</span><br><span class="line">            head = head.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">reversed</span>(ans))</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-24-反转链表"></span></h4>
<p>定义一个函数，输入一个链表的头节点，<strong>反转该链表并输出反转后链表的头节点</strong>。</p>
<ul>
<li><strong>递归、迭代</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverseList</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span><br><span class="line">      	<span class="comment"># 迭代</span></span><br><span class="line">        cur, pre = head, <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            tmp = cur.<span class="built_in">next</span> <span class="comment"># 暂存后继节点 cur.next</span></span><br><span class="line">            cur.<span class="built_in">next</span> = pre <span class="comment"># 修改 next 引用指向</span></span><br><span class="line">            pre = cur      <span class="comment"># pre 暂存 cur</span></span><br><span class="line">            cur = tmp      <span class="comment"># cur 访问下一节点</span></span><br><span class="line">        <span class="keyword">return</span> pre</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverseList</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span><br><span class="line">      	<span class="comment"># 递归</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">recur</span>(<span class="params">cur, pre</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> cur: <span class="keyword">return</span> pre     <span class="comment"># 终止条件</span></span><br><span class="line">            res = recur(cur.<span class="built_in">next</span>, cur) <span class="comment"># 递归后继节点</span></span><br><span class="line">            cur.<span class="built_in">next</span> = pre             <span class="comment"># 修改节点引用指向</span></span><br><span class="line">            <span class="keyword">return</span> res                 <span class="comment"># 返回反转链表的头节点</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> recur(head, <span class="literal">None</span>)       <span class="comment"># 调用递归并返回</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-35-复杂链表的复制"></span></h4>
<p>请实现 copyRandomList
函数，复制一个复杂链表。<strong>在复杂链表中，每个节点除了有一个 next
指针指向下一个节点，还有一个 random 指针指向链表中的任意节点或者
null</strong>。</p>
<ul>
<li>defaultdict()，空为0</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">copyRandomList</span>(<span class="params">self, head: <span class="string">&#x27;Node&#x27;</span></span>) -&gt; <span class="string">&#x27;Node&#x27;</span>:</span><br><span class="line">        <span class="comment"># 拼接+拆分 【哈希表】</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        dic = collections.defaultdict()</span><br><span class="line">        cur = head</span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            dic[cur] = Node(cur.val)</span><br><span class="line">            cur = cur.<span class="built_in">next</span></span><br><span class="line">        cur = head</span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            dic[cur].<span class="built_in">next</span> = dic[cur.<span class="built_in">next</span>] <span class="keyword">if</span> cur.<span class="built_in">next</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">            dic[cur].random = dic[cur.random] <span class="keyword">if</span> cur.random <span class="keyword">else</span> <span class="literal">None</span><span class="comment"># keyerror</span></span><br><span class="line">            cur = cur.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> dic[head]</span><br></pre></td></tr></table></figure></p>
<h4><span id="剑指-offer-ii-021删除链表的倒数第-n-个结点"></span></h4>
<p>给定一个链表，<strong>删除链表的倒数第 <code>n</code>
个结点</strong>，并且返回链表的头结点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">removeNthFromEnd</span>(<span class="params">self, head: ListNode, n: <span class="built_in">int</span></span>) -&gt; ListNode:</span><br><span class="line">        dummy = ListNode(<span class="number">0</span>, head)</span><br><span class="line">        first = head</span><br><span class="line">        second = dummy</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            first = first.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">while</span> first:</span><br><span class="line">            first = first.<span class="built_in">next</span></span><br><span class="line">            second = second.<span class="built_in">next</span></span><br><span class="line">        second.<span class="built_in">next</span> = second.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-022链表中环的入口节点"></span></h4>
<p>给定一个链表，返回链表开始入环的第一个节点。 从链表的头节点开始沿着
next 指针进入环的第一个节点为环的入口节点。如果链表无环，则返回
null。</p>
<p>为了表示给定链表中的环，我们使用整数 pos
来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是
-1，则在该链表中没有环。注意，pos
仅仅是用于标识环的情况，并不会作为参数传递到函数中。</p>
<p>说明：不允许修改给定的链表。</p>
<p><strong>示例 1：</strong></p>
<p><img src="https://assets.leetcode-cn.com/aliyun-lc-upload/uploads/2018/12/07/circularlinkedlist.png" alt="img" style="zoom:50%;"></p>
<blockquote>
<p>输入：head = [3,2,0,-4], pos = 1 输出：返回索引为 1 的链表节点
解释：链表中有一个环，其尾部连接到第二个节点。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">detectCycle</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span><br><span class="line">        fast = slow = head</span><br><span class="line">        <span class="keyword">while</span> fast <span class="keyword">and</span> fast.<span class="built_in">next</span>:</span><br><span class="line">            fast = fast.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">            slow = slow.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">if</span> fast == slow:</span><br><span class="line">                fast = head</span><br><span class="line">                <span class="keyword">while</span> fast != slow:</span><br><span class="line">                    fast = fast.<span class="built_in">next</span></span><br><span class="line">                    slow = slow.<span class="built_in">next</span></span><br><span class="line">                <span class="keyword">return</span> slow</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-023两个链表的第一个重合节点"></span></h4>
<p>给定两个单链表的头节点 <code>headA</code> 和 <code>headB</code>
，请找出并返回两个单链表相交的起始节点。如果两个链表没有交点，返回
<code>null</code> 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getIntersectionNode</span>(<span class="params">self, headA: ListNode, headB: ListNode</span>) -&gt; ListNode:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> headA <span class="keyword">and</span> <span class="keyword">not</span> headB:</span><br><span class="line">            <span class="keyword">return</span> headA</span><br><span class="line">        p, q = headA, headB</span><br><span class="line">        <span class="keyword">while</span> p != q:</span><br><span class="line">            p = p.<span class="built_in">next</span> <span class="keyword">if</span> p <span class="keyword">else</span> headB</span><br><span class="line">            q = q.<span class="built_in">next</span> <span class="keyword">if</span> q <span class="keyword">else</span> headA</span><br><span class="line">        <span class="keyword">return</span> p</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-025-链表中的两数相加"></span></h4>
<p>给定两个 <strong>非空链表</strong> <code>l1</code>和 <code>l2</code>
来代表两个非负整数。数字最高位位于链表开始位置。它们的每个节点只存储一位数字。将这两数相加会返回一个新的链表。</p>
<ul>
<li>从后往前加【反转链表初始化】、倒序添加</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">addTwoNumbers</span>(<span class="params">self, l1: ListNode, l2: ListNode</span>) -&gt; ListNode:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">reverseList</span>(<span class="params">head: ListNode</span>) -&gt; ListNode:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> head:</span><br><span class="line">                <span class="keyword">return</span> head</span><br><span class="line">            pre, cur = <span class="literal">None</span>, head</span><br><span class="line">            <span class="keyword">while</span> cur:</span><br><span class="line">                tmp = cur.<span class="built_in">next</span></span><br><span class="line">                cur.<span class="built_in">next</span> = pre</span><br><span class="line">                pre = cur</span><br><span class="line">                cur = tmp</span><br><span class="line">            <span class="keyword">return</span> pre</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> l1 <span class="keyword">and</span> <span class="keyword">not</span> l2:</span><br><span class="line">            <span class="keyword">return</span> </span><br><span class="line">        l1 = reverseList(l1)</span><br><span class="line">        l2 = reverseList(l2)</span><br><span class="line">        more = <span class="number">0</span></span><br><span class="line">        p = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> l1 <span class="keyword">or</span> l2:</span><br><span class="line">            <span class="comment"># 倒序添加</span></span><br><span class="line">            val1 = l1.val <span class="keyword">if</span> l1 <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">            val2 = l2.val <span class="keyword">if</span> l2 <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">            total = val1 + val2 + more</span><br><span class="line">            more, cur = <span class="built_in">divmod</span>(total, <span class="number">10</span>)</span><br><span class="line">            p = ListNode(cur, p)</span><br><span class="line">            l1 = l1.<span class="built_in">next</span> <span class="keyword">if</span> l1 <span class="keyword">else</span> l1</span><br><span class="line">            l2 = l2.<span class="built_in">next</span> <span class="keyword">if</span> l2 <span class="keyword">else</span> l2</span><br><span class="line">        <span class="keyword">if</span> more != <span class="number">0</span>:</span><br><span class="line">            p = ListNode(more, p)</span><br><span class="line">        <span class="keyword">return</span> p</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-026重排链表"></span></h4>
<p>给定一个单链表 L 的头节点 head ，单链表 L 表示为：</p>
<p>L0 → L1 → … → Ln-1 → Ln 请将其重新排列后变为：</p>
<p>L0 → Ln → L1 → Ln-1 → L2 → Ln-2 → …</p>
<p>不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。</p>
<ul>
<li><strong>列表的中点、插入节点</strong>; 线性表存储</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reorderList</span>(<span class="params">self, head: ListNode</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify head in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">reverseList</span>(<span class="params">head: ListNode</span>) -&gt; ListNode:</span><br><span class="line">            pre, cur = <span class="literal">None</span>, head</span><br><span class="line">            <span class="keyword">while</span> cur:</span><br><span class="line">                tmp = cur.<span class="built_in">next</span></span><br><span class="line">                cur.<span class="built_in">next</span> = pre</span><br><span class="line">                pre = cur</span><br><span class="line">                cur = tmp</span><br><span class="line">            <span class="keyword">return</span> pre</span><br><span class="line">        fast, slow = head.<span class="built_in">next</span>, head</span><br><span class="line">        <span class="keyword">while</span> fast <span class="keyword">and</span> fast.<span class="built_in">next</span>:</span><br><span class="line">            slow, fast = slow.<span class="built_in">next</span>, fast.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">        mid, slow.<span class="built_in">next</span> = slow.<span class="built_in">next</span>, <span class="literal">None</span></span><br><span class="line">        left, cur = head, reverseList(mid)</span><br><span class="line">        slow.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            tmp = cur.<span class="built_in">next</span></span><br><span class="line">            cur.<span class="built_in">next</span> = left.<span class="built_in">next</span></span><br><span class="line">            left.<span class="built_in">next</span> = cur</span><br><span class="line">            left = cur.<span class="built_in">next</span></span><br><span class="line">            cur = tmp</span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-027回文链表"></span></h4>
<p>给定一个链表的 <strong>头节点</strong> <code>head</code>
<strong>，</strong>请判断其是否为回文链表。如果一个链表是回文，那么链表节点序列从前往后看和从后往前看是相同的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isPalindrome</span>(<span class="params">self, head: ListNode</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">reverseList</span>(<span class="params">head: ListNode</span>) -&gt; ListNode:</span><br><span class="line">            pre, cur = <span class="literal">None</span>, head</span><br><span class="line">            <span class="keyword">while</span> cur:</span><br><span class="line">                tmp = cur.<span class="built_in">next</span></span><br><span class="line">                cur.<span class="built_in">next</span> = pre</span><br><span class="line">                pre = cur</span><br><span class="line">                cur = tmp</span><br><span class="line">            <span class="keyword">return</span> pre</span><br><span class="line">        slow = fast = head</span><br><span class="line">        <span class="keyword">while</span> fast.<span class="built_in">next</span> <span class="keyword">and</span> fast.<span class="built_in">next</span>.<span class="built_in">next</span>:</span><br><span class="line">            slow, fast = slow.<span class="built_in">next</span>, fast.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">        left, right = head, slow.<span class="built_in">next</span></span><br><span class="line">        slow.<span class="built_in">next</span> = <span class="literal">None</span></span><br><span class="line">        right = reverseList(right)</span><br><span class="line">        <span class="keyword">while</span> left <span class="keyword">and</span> right:</span><br><span class="line">            <span class="keyword">if</span> left.val != right.val:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            left, right = left.<span class="built_in">next</span>, right.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-028-展平多级双向链表"></span></h4>
<p>多级双向链表中，除了指向下一个节点和前一个节点指针之外，它还有一个子链表指针，可能指向单独的双向链表。这些子列表也可能会有一个或多个自己的子项，依此类推，生成多级数据结构，如下面的示例所示。</p>
<p>给定位于列表第一级的头节点，请扁平化列表，即将这样的多级双向链表展平成普通的双向链表，使所有结点出现在单级双链表中。</p>
<ul>
<li><strong>深度优先搜索</strong>、<strong>栈迭代</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">flatten</span>(<span class="params">self, head: <span class="string">&#x27;Node&#x27;</span></span>) -&gt; <span class="string">&#x27;Node&#x27;</span>:</span><br><span class="line">      	<span class="comment"># 栈迭代</span></span><br><span class="line">        <span class="keyword">if</span> head == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        dummy = Node(-<span class="number">1</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line">        pre = dummy</span><br><span class="line">        stk = [head]</span><br><span class="line">        <span class="keyword">while</span> stk:</span><br><span class="line">            x = stk.pop()</span><br><span class="line">            pre.<span class="built_in">next</span> = x</span><br><span class="line">            x.prev = pre</span><br><span class="line">            <span class="keyword">if</span> x.<span class="built_in">next</span>:</span><br><span class="line">                stk.append(x.<span class="built_in">next</span>)</span><br><span class="line">            <span class="keyword">if</span> x.child:</span><br><span class="line">                stk.append(x.child)</span><br><span class="line">                x.child = <span class="literal">None</span></span><br><span class="line">            pre = x</span><br><span class="line">        dummy.<span class="built_in">next</span>.prev = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br><span class="line">		<span class="keyword">def</span> <span class="title function_">flatten</span>(<span class="params">self, head: <span class="string">&#x27;Node&#x27;</span></span>) -&gt; <span class="string">&#x27;Node&#x27;</span>:</span><br><span class="line">        <span class="keyword">if</span> head == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        dummy = Node(-<span class="number">1</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">pre: <span class="string">&#x27;Node&#x27;</span>, cur: <span class="string">&#x27;Node&#x27;</span></span>) -&gt; <span class="string">&#x27;Node&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> cur == <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">return</span> pre   </span><br><span class="line">            pre.<span class="built_in">next</span> = cur</span><br><span class="line">            cur.prev = pre</span><br><span class="line"></span><br><span class="line">            nxt_head = cur.<span class="built_in">next</span>         <span class="comment">#相当于4</span></span><br><span class="line"></span><br><span class="line">            tail = dfs(cur, cur.child)  <span class="comment">#相当于dfs(3, 7)</span></span><br><span class="line">            cur.child = <span class="literal">None</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">return</span> dfs(tail, nxt_head)  <span class="comment">#相当于dfs(12, 4)</span></span><br><span class="line">        dfs(dummy, head)</span><br><span class="line">        dummy.<span class="built_in">next</span>.prev = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-029排序的循环链表"></span></h4>
<p>给定<strong>循环单调非递减列表中的一个点</strong>，<strong>写一个函数向这个列表中插入一个新元素
insertVal</strong>
，使这个列表仍然是循环升序的。给定的可以是这个列表中任意一个顶点的指针，并不一定是这个列表中最小元素的指针。</p>
<p>如果有多个满足条件的插入位置，可以选择任意一个位置插入新的值，插入后整个列表仍然保持有序。如果列表为空（给定的节点是
null），需要创建一个循环有序列表并返回这个节点。否则。请返回原先给定的节点。</p>
<ul>
<li>循环链表边界判断</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">insert</span>(<span class="params">self, head: <span class="string">&#x27;Node&#x27;</span>, insertVal: <span class="built_in">int</span></span>) -&gt; <span class="string">&#x27;Node&#x27;</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head:</span><br><span class="line">            node =  Node(insertVal)</span><br><span class="line">            node.<span class="built_in">next</span> = node</span><br><span class="line">            <span class="keyword">return</span> node</span><br><span class="line">        cur = head</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">if</span> cur.val &lt;= insertVal &lt;= cur.<span class="built_in">next</span>.val:</span><br><span class="line">                cur.<span class="built_in">next</span> = Node(insertVal, cur.<span class="built_in">next</span>)</span><br><span class="line">                <span class="keyword">return</span> head</span><br><span class="line">            <span class="keyword">elif</span> cur.<span class="built_in">next</span>.val &lt; cur.val:</span><br><span class="line">                <span class="keyword">if</span> insertVal &gt;= cur.val <span class="keyword">or</span> insertVal &lt;= cur.<span class="built_in">next</span>.val:</span><br><span class="line">                    cur.<span class="built_in">next</span> = Node(insertVal, cur.<span class="built_in">next</span>)</span><br><span class="line">                    <span class="keyword">return</span> head</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 走到原点了，还是没有</span></span><br><span class="line">                <span class="keyword">if</span> cur.<span class="built_in">next</span> == head:</span><br><span class="line">                    cur.<span class="built_in">next</span> = Node(insertVal, cur.<span class="built_in">next</span>)</span><br><span class="line">                    <span class="keyword">return</span> head</span><br><span class="line">            cur = cur.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<h4><span id="列表反转二">列表反转二</span></h4>
<h4><span id></span></h4>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（1）数组</title>
    <url>/posts/141Q0J3/</url>
    <content><![CDATA[<h4><span id="剑指offer-17-打印从1到最大的n位数"></span></h4>
<p>输入数字 <code>n</code>，按顺序打印出从 1 到最大的 n
位十进制数。比如输入 3，则打印出 1、2、3 一直到最大的 3 位数
999。【分治】【==<strong>大数打印解法</strong>==】</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">printNumbers</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">index, num, digit</span>):</span><br><span class="line">            <span class="keyword">if</span> index == digit:</span><br><span class="line">                res.append(<span class="built_in">int</span>(<span class="string">&#x27;&#x27;</span>.join(num)))</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">                num.append(<span class="built_in">str</span>(i))</span><br><span class="line">                dfs(index + <span class="number">1</span>, num, digit)</span><br><span class="line">                num.pop()</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> digit <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> first <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">                num = [<span class="built_in">str</span>(first)]</span><br><span class="line">                dfs(<span class="number">1</span>, num, digit)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="560-和为-k的子数组"></span></h4>
<p>给你一个整数数组 <code>nums</code> 和一个整数 <code>k</code>
，请你统计并返回 <em>该数组中和为 <code>k</code>
的<strong>==子数组==</strong>的个数</em> 。</p>
<ul>
<li><code>-1000 &lt;= nums[i] &lt;= 1000</code></li>
<li>前缀和 + 哈希表优化</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">subarraySum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        dic = collections.defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        dic[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        res = preNum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            preNum += nums[i]</span><br><span class="line">            res += dic[preNum - k]</span><br><span class="line">            dic[preNum] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（3）哈希表</title>
    <url>/posts/6M6SM4/</url>
    <content><![CDATA[<h2><span id="dict-字典">dict 字典</span></h2>
<h4><span id="剑指offer-39-数组中出现次数超过一半的数字"></span></h4>
<p>数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。</p>
<ul>
<li>Counter(nums).most_common(1)[0] [0]</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">majorityElement</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">return</span> Counter(nums).most_common(<span class="number">1</span>)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">majorityElement</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        majority_count = <span class="built_in">len</span>(nums) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            candidate = random.choice(nums)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">sum</span>(<span class="number">1</span> <span class="keyword">for</span> elem <span class="keyword">in</span> nums <span class="keyword">if</span> elem == candidate) &gt; majority_count:</span><br><span class="line">                <span class="keyword">return</span> candidate</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-034外星语言是否排序"></span></h4>
<p>某种外星语也使用英文小写字母，但可能顺序 order
不同。字母表的顺序（order）是一些小写字母的排列。</p>
<p>给定一组用外星语书写的单词 words，以及其字母表的顺序
order，只有当给定的单词在这种外星语中按字典序排列时，返回
true；否则，返回 false。</p>
<p><strong>示例 1：</strong></p>
<p>输入：words = ["hello","leetcode"], order =
"hlabcdefgijkmnopqrstuvwxyz" 输出：true 解释：在该语言的字母表中，'h'
位于 'l' 之前，所以单词序列是按字典序排列的。</p>
<ul>
<li>迭代器 pairwise</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">isAlienSorted</span>(<span class="params">self, words: <span class="type">List</span>[<span class="built_in">str</span>], order: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">       index = &#123;c: i <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(order)&#125;</span><br><span class="line">       <span class="keyword">return</span> <span class="built_in">all</span>(s &lt;= t <span class="keyword">for</span> s, t <span class="keyword">in</span> pairwise([index[c] <span class="keyword">for</span> c <span class="keyword">in</span> word] <span class="keyword">for</span> word <span class="keyword">in</span> words))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（3）二叉树</title>
    <url>/posts/1G12BTE/</url>
    <content><![CDATA[<h2><span id="二叉树">二叉树</span></h2>
<h4><span id="剑指offer-07-重建二叉树"></span></h4>
<p>输入某二叉树的<strong>前序遍历</strong>和<strong>中序遍历</strong>的结果，请构建该二叉树并返回其根节点。</p>
<ul>
<li>数组切片、<strong>字典递归</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">buildTree</span>(<span class="params">self, preorder: <span class="type">List</span>[<span class="built_in">int</span>], inorder: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; TreeNode:</span><br><span class="line">        <span class="comment"># 切片</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(preorder) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        rootVal = preorder[<span class="number">0</span>]</span><br><span class="line">        rootindex = inorder.index(rootVal)</span><br><span class="line">        leftsize = rootindex</span><br><span class="line">        root = TreeNode(rootVal)</span><br><span class="line">        root.left = self.buildTree(preorder[<span class="number">1</span>:leftsize+<span class="number">1</span>], inorder[:rootindex])</span><br><span class="line">        root.right = self.buildTree(preorder[leftsize+<span class="number">1</span>:], inorder[rootindex+<span class="number">1</span>:])</span><br><span class="line">        <span class="keyword">return</span> root</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">buildTree</span>(<span class="params">self, preorder: <span class="type">List</span>[<span class="built_in">int</span>], inorder: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; TreeNode:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">recur</span>(<span class="params">root, left, right</span>):</span><br><span class="line">            <span class="keyword">if</span> left &gt; right: <span class="keyword">return</span>                               <span class="comment"># 递归终止</span></span><br><span class="line">            node = TreeNode(preorder[root])                       <span class="comment"># 建立根节点</span></span><br><span class="line">            i = dic[preorder[root]]                               <span class="comment"># 划分根节点、左子树、右子树</span></span><br><span class="line">            node.left = recur(root + <span class="number">1</span>, left, i - <span class="number">1</span>)              <span class="comment"># 开启左子树递归</span></span><br><span class="line">            node.right = recur(i - left + root + <span class="number">1</span>, i + <span class="number">1</span>, right) <span class="comment"># 开启右子树递归</span></span><br><span class="line">            <span class="keyword">return</span> node                                           <span class="comment"># 回溯返回根节点</span></span><br><span class="line"></span><br><span class="line">        dic = &#123;val: i <span class="keyword">for</span> i, val <span class="keyword">in</span> <span class="built_in">enumerate</span>(inorder)&#125;</span><br><span class="line">        <span class="keyword">return</span> recur(<span class="number">0</span>, <span class="number">0</span>, <span class="built_in">len</span>(inorder) - <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-33-二叉搜索树的后序遍历序列"></span></h4>
<p>输入一个整数数组，<strong>判断该数组是不是某二叉搜索树的后序遍历结果</strong>。如果是则返回
<code>true</code>，否则返回
<code>false</code>。假设输入的数组的任意两个数字都互不相同。</p>
<ul>
<li>分治、<strong>辅助单调栈</strong></li>
</ul>
<p><strong>辅助单调栈：</strong></p>
<p><img src="https://pic.leetcode-cn.com/0b0f77f90c68ecf5d0d154f66971f32fa6feb5d50f01a2b2b627df2029a0a103-Picture10.png" alt="Picture10.png" style="zoom:50%;"></p>
<ul>
<li>借助一个单调栈 stack 存储值递增的节点；</li>
<li>每当遇到值递减的节点 <span class="math inline">\(r_i\)</span>
，则通过出栈来更新节点 <span class="math inline">\(r_i\)</span>的父节点
<span class="math inline">\(root\)</span> ；</li>
<li>每轮判断 <span class="math inline">\(r_i和 root\)</span>的值关系：
<ul>
<li>若 <span class="math inline">\(r_i &gt;
root\)</span>则说明不满足二叉搜索树定义，直接返回 false。</li>
<li>若 <span class="math inline">\(r_i &lt; root\)</span>
则说明满足二叉搜索树定义，则继续遍历。</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">verifyPostorder</span>(<span class="params">self, postorder: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(postorder) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        inorder = <span class="built_in">sorted</span>(postorder)</span><br><span class="line">        rootval = postorder[-<span class="number">1</span>]</span><br><span class="line">        rootindex = inorder.index(rootval)</span><br><span class="line">        rightsize = <span class="built_in">len</span>(inorder) - rootindex - <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">set</span>(inorder[rootindex+<span class="number">1</span>:]) != <span class="built_in">set</span>(postorder[-<span class="number">1</span>-rightsize:-<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">set</span>(inorder[:rootindex]) != <span class="built_in">set</span>(postorder[:-<span class="number">1</span>-rightsize]):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> self.verifyPostorder(postorder[-<span class="number">1</span>-rightsize:-<span class="number">1</span>]) <span class="keyword">and</span> self.verifyPostorder(postorder[:-<span class="number">1</span>-rightsize])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">verifyPostorder</span>(<span class="params">self, postorder: [<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="comment"># 分治递归</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">recur</span>(<span class="params">i, j</span>):</span><br><span class="line">            <span class="keyword">if</span> i &gt;= j: </span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            p = i</span><br><span class="line">            <span class="keyword">while</span> postorder[p] &lt; postorder[j]: </span><br><span class="line">                p += <span class="number">1</span></span><br><span class="line">            m = p</span><br><span class="line">            <span class="keyword">while</span> postorder[p] &gt; postorder[j]: </span><br><span class="line">                p += <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> p == j <span class="keyword">and</span> recur(i, m - <span class="number">1</span>) <span class="keyword">and</span> recur(m, j - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> recur(<span class="number">0</span>, <span class="built_in">len</span>(postorder) - <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">verifyPostorder</span>(<span class="params">self, postorder: [<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="comment"># 单调队列</span></span><br><span class="line">        stack, root = [], <span class="built_in">float</span>(<span class="string">&quot;+inf&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(postorder) - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> postorder[i] &gt; root: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">while</span>(stack <span class="keyword">and</span> postorder[i] &lt; stack[-<span class="number">1</span>]):</span><br><span class="line">                root = stack.pop()</span><br><span class="line">            stack.append(postorder[i])</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-044二叉树每层的最大值"></span></h4>
<p>给定一棵二叉树的根节点 <code>root</code>
，请找出该二叉树中每一层的最大值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">largestValues</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        q = deque([root])</span><br><span class="line">        ans = []</span><br><span class="line">        <span class="keyword">while</span> q:</span><br><span class="line">            k = <span class="built_in">len</span>(q)</span><br><span class="line">            tmp = <span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>)</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">                node = q.popleft()</span><br><span class="line">                <span class="keyword">if</span> (t:= node.val) &gt; tmp:</span><br><span class="line">                    tmp = t</span><br><span class="line">                <span class="keyword">if</span> node.left:</span><br><span class="line">                    q.append(node.left)</span><br><span class="line">                <span class="keyword">if</span> node.right:</span><br><span class="line">                    q.append(node.right)</span><br><span class="line">            ans.append(tmp)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="513找树左下角的值"></span></h4>
<p>给定一个二叉树的 <strong>根节点</strong>
<code>root</code>，请找出该二叉树的 <strong>最底层 最左边</strong>
节点的值。</p>
<ul>
<li>深度优先遍历、广度优先遍历</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findBottomLeftValue</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        curVal = curHeight = <span class="number">0</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">node: <span class="type">Optional</span>[TreeNode], height: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> node <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            height += <span class="number">1</span></span><br><span class="line">            dfs(node.left, height)</span><br><span class="line">            dfs(node.right, height)</span><br><span class="line">            <span class="keyword">nonlocal</span> curVal, curHeight</span><br><span class="line">            <span class="keyword">if</span> height &gt; curHeight:</span><br><span class="line">                curHeight = height</span><br><span class="line">                curVal = node.val</span><br><span class="line">        dfs(root, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> curVal</span><br><span class="line">		<span class="keyword">def</span> <span class="title function_">findBottomLeftValue</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        q = deque([root])</span><br><span class="line">        <span class="keyword">while</span> q:</span><br><span class="line">            node = q.popleft()</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                q.append(node.right)</span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                q.append(node.left)</span><br><span class="line">            ans = node.val</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h2><span id="搜索">搜索</span></h2>
<h4><span id="剑指offer-32-i-从上到下打印二叉树层序遍历">【层序遍历】</span></h4>
<p>从上到下打印出二叉树的每个节点，同一层的节点按照从左到右的顺序打印。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">levelOrder</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> []</span><br><span class="line">        res, queue = [], collections.deque()</span><br><span class="line">        queue.append(root)</span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            node = queue.popleft()</span><br><span class="line">            res.append(node.val)</span><br><span class="line">            <span class="keyword">if</span> node.left: queue.append(node.left)</span><br><span class="line">            <span class="keyword">if</span> node.right: queue.append(node.right)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-32-ii-从上到下打印二叉树-ii"></span></h4>
<p>从上到下按层打印二叉树，同一层的节点按从左到右的顺序打印，每一层打印到一行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">levelOrder</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        ans, q = [], collections.deque()</span><br><span class="line">        q.append(root)</span><br><span class="line">        <span class="keyword">while</span> q:</span><br><span class="line">            tmp = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(q)):</span><br><span class="line">                node = q.popleft()</span><br><span class="line">                tmp.append(node.val)</span><br><span class="line">                <span class="keyword">if</span> node.left:</span><br><span class="line">                    q.append(node.left)</span><br><span class="line">                <span class="keyword">if</span> node.right:</span><br><span class="line">                    q.append(node.right)</span><br><span class="line">            ans.append(tmp)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-32-iii-从上到下打印二叉树-iii"></span></h4>
<p>请实现一个函数按照之字形顺序打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右到左的顺序打印，第三行再按照从左到右的顺序打印，其他行以此类推。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">levelOrder</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        ans, q = [], collections.deque()</span><br><span class="line">        q.append(root)</span><br><span class="line">        <span class="keyword">while</span> q:</span><br><span class="line">            tmp = []</span><br><span class="line">            k = <span class="built_in">len</span>(q)</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">                node = q.popleft()</span><br><span class="line">                tmp.append(node.val)</span><br><span class="line">                <span class="keyword">if</span> node.left:</span><br><span class="line">                    q.append(node.left)</span><br><span class="line">                <span class="keyword">if</span> node.right:</span><br><span class="line">                    q.append(node.right)</span><br><span class="line">            ans.append(tmp[::-<span class="number">1</span>] <span class="keyword">if</span> <span class="built_in">len</span>(ans) % <span class="number">2</span> <span class="keyword">else</span> tmp)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="104二叉树的最大深度"></span></h4>
<p>给定一个二叉树，<strong>找出其最大深度</strong>。二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxDepth</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        left_high = self.maxDepth(root.left)</span><br><span class="line">        right_high = self.maxDepth(root.right)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(left_high, right_high)+<span class="number">1</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxDepth</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 空树，高度为 0</span></span><br><span class="line">        <span class="keyword">if</span> root == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 初始化队列和层次</span></span><br><span class="line">        queue = [root]</span><br><span class="line">        depth = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 当队列不为空</span></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            <span class="comment"># 当前层的节点数</span></span><br><span class="line">            n = <span class="built_in">len</span>(queue)</span><br><span class="line">            <span class="comment"># 弹出当前层的所有节点，并将所有子节点入队列</span></span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                node = queue.pop(<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">if</span> node.left:</span><br><span class="line">                    queue.append(node.left)</span><br><span class="line">                <span class="keyword">if</span> node.right:</span><br><span class="line">                    queue.append(node.right)</span><br><span class="line">            depth += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 二叉树最大层次即为二叉树最深深度</span></span><br><span class="line">        <span class="keyword">return</span> depth</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-27-二叉树的镜像"></span></h4>
<p>请完成一个函数，输入一个二叉树，该函数<strong>输出它的镜像</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mirrorTree</span>(<span class="params">self, root: TreeNode</span>) -&gt; TreeNode:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        stack = [root]</span><br><span class="line">        <span class="keyword">while</span> stack:</span><br><span class="line">            node = stack.pop()</span><br><span class="line">            node.left, node.right = node.right, node.left</span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                stack.append(node.left)</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                stack.append(node.right)</span><br><span class="line">        <span class="keyword">return</span> root</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mirrorTree</span>(<span class="params">self, root: TreeNode</span>) -&gt; TreeNode:</span><br><span class="line">        <span class="comment"># 反转左右子树</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        root.left, root.right = root.right, root.left</span><br><span class="line">        root.left = self.mirrorTree(root.left)</span><br><span class="line">        root.right = self.mirrorTree(root.right)</span><br><span class="line">   </span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer26-树的子结构-辅助函数"> [辅助函数]</span></h4>
<p><strong>输入两棵二叉树A和B，判断B是不是A的子结构</strong>。(约定空树不是任意一个树的子结构)，B是A的子结构，
即 A中有出现和B相同的结构和节点值。</p>
<ul>
<li><strong>==对称性递归==</strong>：https://leetcode.cn/problems/shu-de-zi-jie-gou-lcof/solution/yi-pian-wen-zhang-dai-ni-chi-tou-dui-che-uhgs/</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isSubStructure</span>(<span class="params">self, A: TreeNode, B: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">recur</span>(<span class="params">A, B</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> B: </span><br><span class="line">              	<span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> A <span class="keyword">or</span> A.val != B.val: </span><br><span class="line">              	<span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">return</span> recur(A.left, B.left) <span class="keyword">and</span> recur(A.right, B.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">bool</span>(A <span class="keyword">and</span> B) <span class="keyword">and</span> (recur(A, B) <span class="keyword">or</span> self.isSubStructure(A.left, B) <span class="keyword">or</span> self.isSubStructure(A.right, B))</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-28-对称的二叉树-辅助函数"> [辅助函数]</span></h4>
<p><strong>请实现一个函数，用来判断一棵二叉树是不是对称的</strong>。如果一棵二叉树和它的镜像一样，那么它是对称的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isSymmetric</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">recur</span>(<span class="params">left, right</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> left <span class="keyword">and</span> <span class="keyword">not</span> right:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> left <span class="keyword">or</span> <span class="keyword">not</span> right <span class="keyword">or</span> left.val != right.val:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            <span class="keyword">return</span> recur(left.left, right.right) <span class="keyword">and</span> recur(left.right, right.left)</span><br><span class="line">        <span class="keyword">return</span> recur(root.left, root.right)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-36-二叉搜索树与双向链表"></span></h4>
<p>==<strong>输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的循环双向链表</strong>==。要求不能创建任何新的节点，只能调整树中节点指针的指向。为了让您更好地理解问题，以下面的二叉搜索树为例：</p>
<p><img src="https://assets.leetcode.com/uploads/2018/10/12/bstdlloriginalbst.png" alt="img" style="zoom:50%;"></p>
<p>我们希望<strong>将这个二叉搜索树转化为双向循环链表</strong>。链表中的每个节点都有一个前驱和后继指针。对于双向循环链表，第一个节点的前驱是最后一个节点，最后一个节点的后继是第一个节点。</p>
<p><img src="https://assets.leetcode.com/uploads/2018/10/12/bstdllreturndll.png" alt="img" style="zoom:50%;"></p>
<h5><span id="算法流程">算法流程：</span></h5>
<p><strong><code>dfs(cur):</code></strong> 递归法中序遍历；</p>
<ul>
<li><strong>终止条件：</strong> 当节点 <code>cur</code>
为空，代表越过叶节点，直接返回；</li>
<li>递归左子树，即 <code>dfs(cur.left)</code> ；</li>
<li><strong>构建链表：</strong>
<ul>
<li><strong>当 <code>pre</code> 为空时：</strong>
代表正在访问链表头节点，记为 <code>head</code> ；</li>
<li><strong>当 <code>pre</code> 不为空时：</strong> 修改双向节点引用，即
<code>pre.right = cur</code> ， <code>cur.left = pre</code> ；</li>
<li><strong>保存 <code>cur</code> ：</strong> 更新
<code>pre = cur</code> ，即节点 <code>cur</code> 是后继节点的
<code>pre</code> ；</li>
</ul></li>
<li>递归右子树，即 <code>dfs(cur.right)</code> ；</li>
</ul>
<p><strong><code>treeToDoublyList(root)：</code></strong></p>
<ul>
<li><strong>特例处理：</strong> 若节点 <code>root</code>
为空，则直接返回；</li>
<li><strong>初始化：</strong> 空节点 <code>pre</code> ；</li>
<li><strong>转化为双向链表：</strong> 调用 <code>dfs(root)</code>
；</li>
<li><strong>构建循环链表：</strong> 中序遍历完成后，<code>head</code>
指向头节点， <code>pre</code> 指向尾节点，因此修改 <code>head</code> 和
<code>pre</code> 的双向节点引用即可；</li>
<li><strong>返回值：</strong> 返回链表的头节点 <code>head</code>
即可；</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">treeToDoublyList</span>(<span class="params">self, root: <span class="string">&#x27;Node&#x27;</span></span>) -&gt; <span class="string">&#x27;Node&#x27;</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">cur</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> cur: </span><br><span class="line">              	<span class="keyword">return</span></span><br><span class="line">            dfs(cur.left) <span class="comment"># 递归左子树</span></span><br><span class="line">            <span class="keyword">if</span> self.pre: <span class="comment"># 修改节点引用</span></span><br><span class="line">                self.pre.right, cur.left = cur, self.pre</span><br><span class="line">            <span class="keyword">else</span>: <span class="comment"># 记录头节点</span></span><br><span class="line">                self.head = cur</span><br><span class="line">            self.pre = cur <span class="comment"># 保存 cur</span></span><br><span class="line">            dfs(cur.right) <span class="comment"># 递归右子树</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">        self.pre = <span class="literal">None</span></span><br><span class="line">        dfs(root)</span><br><span class="line">        self.head.left, self.pre.right = self.pre, self.head</span><br><span class="line">        <span class="keyword">return</span> self.head</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-54-二叉搜索树的第k大节点"></span></h4>
<p>给定一棵二叉搜索树，请找出其中<strong>第 <code>k</code>
大的节点的值</strong>。</p>
<ul>
<li><strong>从大到小：倒序遍历</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">kthLargest</span>(<span class="params">self, root: TreeNode, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 中序遍历是单调的</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">root</span>):</span><br><span class="line">            <span class="keyword">nonlocal</span> k, res</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root: </span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            dfs(root.right)</span><br><span class="line">            k -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> k == <span class="number">0</span>: </span><br><span class="line">                res = root.val</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            dfs(root.left)</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        dfs(root)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">kthLargest</span>(<span class="params">self, root: TreeNode, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">TreeSize</span>(<span class="params">root: TreeNode</span>):<span class="comment"># 求子树节点个数</span></span><br><span class="line">          	<span class="comment"># 子树的深度</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root: </span><br><span class="line">              	<span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right: </span><br><span class="line">             		<span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> TreeSize(root.left) + TreeSize(root.right) + <span class="number">1</span></span><br><span class="line">        nright = TreeSize(root.right)</span><br><span class="line">        <span class="keyword">if</span> nright &gt;= k: <span class="comment">#在右子树</span></span><br><span class="line">            <span class="keyword">return</span> self.kthLargest(root.right, k)</span><br><span class="line">        <span class="keyword">elif</span> nright == k - <span class="number">1</span>: <span class="keyword">return</span> root.val</span><br><span class="line">        <span class="keyword">else</span>: </span><br><span class="line">            <span class="keyword">return</span> self.kthLargest(root.left, k - nright - <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-55-i-二叉树的深度"></span></h4>
<p>输入一棵二叉树的根节点，求该树的深度。从根节点到叶节点依次经过的节点（含根、叶节点）形成树的一条路径，最长路径的长度为树的深度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxDepth</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root: <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        queue, res = deque([root]), <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            k = <span class="built_in">len</span>(queue)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">                node = queue.popleft()</span><br><span class="line">                <span class="keyword">if</span> node.left:</span><br><span class="line">                    queue.append(node.left)</span><br><span class="line">                <span class="keyword">if</span> node.right: </span><br><span class="line">                    queue.append(node.right)</span><br><span class="line">            res += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxDepth</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> + <span class="built_in">max</span>(self.maxDepth(root.left), self.maxDepth(root.right))</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-55-ii-平衡二叉树-辅助函数"> [辅助函数]</span></h4>
<p>输入一棵二叉树的根节点，判断该树是不是平衡二叉树。如果某二叉树中任意节点的左右子树的深度相差不超过1，那么它就是一棵平衡二叉树。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isBalanced</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">height</span>(<span class="params">root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            leftH = height(root.left)</span><br><span class="line">            rightH = height(root.right)</span><br><span class="line">            <span class="keyword">if</span> leftH == -<span class="number">1</span> <span class="keyword">or</span> rightH == -<span class="number">1</span> <span class="keyword">or</span> <span class="built_in">abs</span>(leftH - rightH) &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">max</span>(leftH, rightH) + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> height(root) &gt;= <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-64求12n"></span></h4>
<p>求 <code>1+2+...+n</code>
，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sumNums</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">sumStop</span>(<span class="params">n</span>):</span><br><span class="line">            <span class="keyword">return</span> n &gt;= <span class="number">1</span> <span class="keyword">and</span> n + sumStop(n-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> sumStop(n)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-68-i-二叉搜索树的最近公共祖先"></span></h4>
<p>给定一个<strong>二叉搜索树</strong>,
找到该树中两个指定节点的最近公共祖先。</p>
<ul>
<li>若 root.val &lt; p.val，则 pp 在 root 右子树 中；</li>
<li>若 root.val &gt; p.val ，则 pp 在 root 左子树 中；</li>
</ul>
<blockquote>
<p>输入: root = [6,2,8,0,4,7,9,null,null,3,5], p = 2, q = 8 输出: 6
解释: 节点 2 和节点 8 的最近公共祖先是 6。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lowestCommonAncestor</span>(<span class="params">self, root: <span class="string">&#x27;TreeNode&#x27;</span>, p: <span class="string">&#x27;TreeNode&#x27;</span>, q: <span class="string">&#x27;TreeNode&#x27;</span></span>) -&gt; <span class="string">&#x27;TreeNode&#x27;</span>:</span><br><span class="line">      	<span class="comment"># 迭代优化</span></span><br><span class="line">        <span class="keyword">if</span> p.val &gt; q.val: p, q = q, p <span class="comment"># 保证 p.val &lt; q.val</span></span><br><span class="line">        <span class="keyword">while</span> root:</span><br><span class="line">            <span class="keyword">if</span> root.val &lt; p.val: <span class="comment"># p,q 都在 root 的右子树中</span></span><br><span class="line">                root = root.right <span class="comment"># 遍历至右子节点</span></span><br><span class="line">            <span class="keyword">elif</span> root.val &gt; q.val: <span class="comment"># p,q 都在 root 的左子树中</span></span><br><span class="line">                root = root.left <span class="comment"># 遍历至左子节点</span></span><br><span class="line">            <span class="keyword">else</span>: </span><br><span class="line">              	<span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> root</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lowestCommonAncestor</span>(<span class="params">self, root: <span class="string">&#x27;TreeNode&#x27;</span>, p: <span class="string">&#x27;TreeNode&#x27;</span>, q: <span class="string">&#x27;TreeNode&#x27;</span></span>) -&gt; <span class="string">&#x27;TreeNode&#x27;</span>:</span><br><span class="line">      	<span class="comment"># 递归</span></span><br><span class="line">        <span class="keyword">if</span> root.val &lt; p.val <span class="keyword">and</span> root.val &lt; q.val:</span><br><span class="line">            <span class="keyword">return</span> self.lowestCommonAncestor(root.right, p, q)</span><br><span class="line">        <span class="keyword">if</span> root.val &gt; p.val <span class="keyword">and</span> root.val &gt; q.val:</span><br><span class="line">            <span class="keyword">return</span> self.lowestCommonAncestor(root.left, p, q)</span><br><span class="line">        <span class="keyword">return</span> root	</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-68-ii-二叉树的最近公共祖先"></span></h4>
<p>给定一个<strong>二叉树,</strong>
找到该树中两个指定节点的最近公共祖先。深度优先遍历是从下往上返回，所以第一个满足的就是<strong>最近公共祖先节点</strong>
。</p>
<h5><span id="递归解析">递归解析：</span></h5>
<ul>
<li><strong>终止条件：</strong>
<ul>
<li>当越过叶节点，则直接返回 null；</li>
<li>当 root等于 p, q ，则直接返回 root；</li>
</ul></li>
<li><strong>递推工作：</strong>
<ul>
<li>开启递归左子节点，返回值记为 left；</li>
<li>开启递归右子节点，返回值记为 right ；</li>
</ul></li>
<li><strong>返回值</strong>：根据 left 和 right ，可展开为四种情况；
<ul>
<li>当 left 和 right 同时为空 ：说明 root的左 / 右子树中都不包含 p,q
，返回 null；</li>
<li>当 left 和 right 同时不为空 ：说明 p, q分列在 root的 异侧 （分别在
左 / 右子树），因此 root为最近公共祖先，返回 root；</li>
<li>当 left为空 ，right不为空 ：p,q都不在 root的左子树中，直接返回
right。具体可分为两种情况：
<ul>
<li>p,q 其中一个在 root的 右子树 中，此时 right 指向 p（假设为 p
）；</li>
<li>p,q 两节点都在 root的 右子树 中，此时的 right指向
<strong>最近公共祖先节点</strong> ；</li>
</ul></li>
<li>当 left不为空 ， right为空 ：与情况 3. 同理；</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lowestCommonAncestor</span>(<span class="params">self, root: TreeNode, p: TreeNode, q: TreeNode</span>) -&gt; TreeNode:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root <span class="keyword">or</span> root == q <span class="keyword">or</span> root == p:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        left = self.lowestCommonAncestor(root.left, p, q)</span><br><span class="line">        right = self.lowestCommonAncestor(root.right, p, q)</span><br><span class="line">        <span class="keyword">if</span> left <span class="keyword">and</span> right:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line">        <span class="keyword">return</span> left <span class="keyword">if</span> left <span class="keyword">else</span> right</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-049从根节点到叶节点的路径数字之和"></span></h4>
<p>给定一个二叉树的根节点 root ，树中每个节点都存放有一个 0 到 9
之间的数字。每条从根节点到叶节点的路径都代表一个数字：</p>
<p>例如，从根节点到叶节点的路径 1 -&gt; 2 -&gt; 3 表示数字 123
。计算从根节点到叶节点生成的 所有数字之和 。</p>
<ul>
<li><strong>深度优先遍历</strong>、回溯【没有return】</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sumNumbers</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># dfs , 回溯</span></span><br><span class="line">        ans = []</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">root, prevTotal</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            total = prevTotal * <span class="number">10</span> + root.val</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">                <span class="keyword">return</span> total</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> dfs(root.left, total) + dfs(root.right, total)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtrace</span>(<span class="params">root, tmp</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span> root</span><br><span class="line">            tmp.append(<span class="built_in">str</span>(root.val))</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right:</span><br><span class="line">                ans.append(tmp[:])</span><br><span class="line">                <span class="comment"># 【没有return, 就会执行一次 pop() 】</span></span><br><span class="line">            backtrace(root.left, tmp)</span><br><span class="line">            backtrace(root.right, tmp)</span><br><span class="line">            tmp.pop()</span><br><span class="line">        backtrace(root, [])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>([<span class="built_in">int</span>(<span class="string">&quot;&quot;</span>.join(nums)) <span class="keyword">for</span> nums <span class="keyword">in</span> ans])</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-047二叉树剪枝"></span></h4>
<p>给定一个二叉树 <strong>根节点</strong> <code>root</code>
，树的每个节点的值要么是 <code>0</code>，要么是
<code>1</code>。请剪除该二叉树中所有节点的值为 <code>0</code>
的子树。节点 <code>node</code> 的子树为 <code>node</code> 本身，以及所有
<code>node</code> 的后代。</p>
<ul>
<li>建树【dfs 有返回值】</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pruneTree</span>(<span class="params">self, root: TreeNode</span>) -&gt; TreeNode:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">root</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span> root</span><br><span class="line">            root.left = dfs(root.left)</span><br><span class="line">            root.right = dfs(root.right)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right <span class="keyword">and</span> root.val == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">            <span class="keyword">return</span> root    </span><br><span class="line">        <span class="keyword">return</span> dfs(root)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-050-向下的路径节点之和"></span></h4>
<p>给定一个二叉树的根节点 <code>root</code> ，和一个整数
<code>targetSum</code> ，求该二叉树里节点值之和等于
<code>targetSum</code> 的 <strong>路径</strong>
的数目。<strong>路径</strong>
不需要从根节点开始，也不需要在叶子节点结束，但是路径方向必须是向下的（只能从父节点到子节点）。</p>
<p>示例 1：</p>
<p><img src="https://assets.leetcode.com/uploads/2021/04/09/pathsum3-1-tree.jpg" alt="img" style="zoom:50%;"></p>
<p>输入：root = [10,5,-3,3,2,null,11,3,-2,null,1], targetSum = 8 输出：3
解释：和等于 8 的路径有 3 条，如图所示。</p>
<ul>
<li><strong>前缀和+回溯</strong> o(n)、深度优先遍历【双重递归 0（n^2)
】</li>
</ul>
<p>DFS中存在许多重复计算，我们定义节点的前缀和为：</p>
<ul>
<li><strong>curr</strong> 由根结点到当前结点的路径上所有节点的和；</li>
<li>利用先序遍历二叉树，<strong>记录下根节点 root 到当前节点 <em>p</em>
的路径上除当前节点以外所有节点的前缀和；</strong></li>
<li>在已保存的路径前缀和中<strong>查找是否存在前缀和刚好等于当前节点到根节点的前缀和
curr 减去 targetSum。</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pathSum</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode], targetSum: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 深度优先遍历</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">root, total</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            ans = <span class="number">0</span></span><br><span class="line">            total += root.val</span><br><span class="line">            <span class="keyword">if</span> total == targetSum:</span><br><span class="line">                ans += <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> ans + dfs(root.left, total) + dfs(root.right, total)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> dfs(root, <span class="number">0</span>) + self.pathSum(root.left, targetSum) + self.pathSum(root.right, targetSum)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pathSum</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode], targetSum: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 前缀和 + 回溯</span></span><br><span class="line">        pre = collections.defaultdict(<span class="built_in">int</span>) <span class="comment"># 根节点到当前节点和</span></span><br><span class="line">        pre[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backstace</span>(<span class="params">root, curr</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            curr += root.val <span class="comment"># 根节点到当前节点和</span></span><br><span class="line">            ans = <span class="number">0</span></span><br><span class="line">            ans += pre[curr - targetSum]</span><br><span class="line">            <span class="comment"># 回溯</span></span><br><span class="line">            pre[curr] += <span class="number">1</span></span><br><span class="line">            ans += backstace(root.left, curr)</span><br><span class="line">            ans += backstace(root.right, curr)</span><br><span class="line">            pre[curr] -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> ans</span><br><span class="line">        <span class="keyword">return</span> backstace(root, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-051-节点之和最大的路径"></span></h4>
<p><strong>路径</strong>
被定义为一条从树中任意节点出发，沿父节点-子节点连接，达到任意节点的序列。同一个节点在一条路径序列中
<strong>至多出现一次</strong> 。该路径 <strong>至少包含一个</strong>
节点，且不一定经过根节点。</p>
<p>给定一个二叉树的根节点 <code>root</code> ，返回其
<strong>最大路径和</strong>，即所有路径上节点值之和的最大值。</p>
<p><strong>示例 2：</strong></p>
<p><img src="https://assets.leetcode.com/uploads/2020/10/13/exx2.jpg" alt="img" style="zoom:50%;"></p>
<p>输入：root = [-10,9,20,null,null,15,7] 输出：42
解释：<strong>最优路径是 15 -&gt; 20 -&gt; 7 ，路径和为 15 + 20 + 7 =
42</strong></p>
<ul>
<li><strong>节点贡献值</strong> root + max(left, right) /
最大路径和：当前节点 + 左子树max + 右子树max</li>
<li><strong>动态过程保存</strong>：ans</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxPathSum</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        ans = -inf</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">pathSum</span>(<span class="params">root</span>):</span><br><span class="line">            <span class="keyword">nonlocal</span> ans</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">            left = <span class="built_in">max</span>(pathSum(root.left), <span class="number">0</span>)</span><br><span class="line">            right = <span class="built_in">max</span>(pathSum(root.right), <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> (t := root.val + left + right) &gt; ans:</span><br><span class="line">                ans = t</span><br><span class="line">            <span class="keyword">return</span> root.val + <span class="built_in">max</span>(left, right)</span><br><span class="line">        pathSum(root)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-052展平二叉搜索树"></span></h4>
<p>给你一棵二叉搜索树，请 <strong>按中序遍历</strong>
将其重新排列为一棵递增顺序搜索树，使树中最左边的节点成为树的根节点，并且每个节点没有左子节点，只有一个右子节点。</p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（4）字符串</title>
    <url>/posts/4VXEX1/</url>
    <content><![CDATA[<h2><span id="字符串">字符串</span></h2>
<h4><span id="剑指-offer-05替换空格"></span></h4>
<p>请实现一个函数，把字符串 <code>s</code> 中的每个空格替换成"%20"。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">replaceSpace</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="keyword">return</span> s.replace(<span class="string">&quot; &quot;</span>, <span class="string">&quot;%20&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-58-ii-左旋转字符串"></span></h4>
<p>字符串的左旋转操作是把字符串前面的若干个字符转移到字符串的尾部。请定义一个函数实现字符串左旋转操作的功能。比如，输入字符串"abcdefg"和数字2，该函数将返回左旋转两位得到的结果"cdefgab"。</p>
<ul>
<li>字符串切片、列表遍历拼接、字符串遍历拼接</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverseLeftWords</span>(<span class="params">self, s: <span class="built_in">str</span>, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="keyword">return</span> s[n:] + s[:n]</span><br><span class="line">		<span class="keyword">def</span> <span class="title function_">reverseLeftWords</span>(<span class="params">self, s: <span class="built_in">str</span>, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">      	<span class="comment"># 列表遍历拼接</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n, <span class="built_in">len</span>(s)):</span><br><span class="line">            res.append(s[i])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            res.append(s[i])</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(res)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverseLeftWords</span>(<span class="params">self, s: <span class="built_in">str</span>, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">      	<span class="comment"># 字符串遍历拼接</span></span><br><span class="line">        res = <span class="string">&quot;&quot;</span> <span class="comment"># 字符为不可变对象，每轮都新建</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n, <span class="built_in">len</span>(s)):</span><br><span class="line">            res += s[i]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            res += s[i]</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>以 Python 为例开展三种方法的效率测试：</p>
<p><img src="https://pic.leetcode-cn.com/ef68413b3366b97af3ed76037c6a9d1e40ac09c74fd6e5cb6d5173cbd7116beb-Picture4.png" alt="Picture4.png" style="zoom:48%;"></p>
<h4><span id="567字符串的排列"></span></h4>
<p>给你两个字符串 <code>s1</code> 和 <code>s2</code> ，写一个函数来判断
<code>s2</code> 是否包含 <code>s1</code> 的排列。如果是，返回
<code>true</code> ；否则，返回 <code>false</code> 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">checkInclusion</span>(<span class="params">self, s1: <span class="built_in">str</span>, s2: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        m, n = <span class="built_in">len</span>(s1), <span class="built_in">len</span>(s2)</span><br><span class="line">        <span class="keyword">if</span> m &gt; n:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        key = [<span class="number">0</span>] * <span class="number">26</span></span><br><span class="line">        cur = [<span class="number">0</span>] * <span class="number">26</span> </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            key[<span class="built_in">ord</span>(s1[i]) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)] += <span class="number">1</span></span><br><span class="line">            cur[<span class="built_in">ord</span>(s2[i]) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> key == cur:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n - m):</span><br><span class="line">            cur[<span class="built_in">ord</span>(s2[j]) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)] -= <span class="number">1</span></span><br><span class="line">            cur[<span class="built_in">ord</span>(s2[j + m]) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> key == cur:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h4><span id="438找到字符串中所有字母异位词"></span></h4>
<p>给定两个字符串 <code>s</code> 和 <code>p</code>，找到 <code>s</code>
中所有 <code>p</code> 的 <strong>异位词</strong>
的子串，返回这些子串的起始索引。不考虑答案输出的顺序。</p>
<ul>
<li><strong>字典数组</strong>、滑动窗口</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findAnagrams</span>(<span class="params">self, s: <span class="built_in">str</span>, p: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        s_len, p_len = <span class="built_in">len</span>(s), <span class="built_in">len</span>(p)</span><br><span class="line">        <span class="keyword">if</span> s_len &lt; p_len:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        ans = []</span><br><span class="line">        s_count = [<span class="number">0</span>] * <span class="number">26</span></span><br><span class="line">        p_count = [<span class="number">0</span>] * <span class="number">26</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(p_len):</span><br><span class="line">            s_count[<span class="built_in">ord</span>(s[i]) - <span class="number">97</span>] += <span class="number">1</span></span><br><span class="line">            p_count[<span class="built_in">ord</span>(p[i]) - <span class="number">97</span>] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> s_count == p_count:</span><br><span class="line">            ans.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(s_len - p_len):</span><br><span class="line">            s_count[<span class="built_in">ord</span>(s[i]) - <span class="number">97</span>] -= <span class="number">1</span></span><br><span class="line">            s_count[<span class="built_in">ord</span>(s[i + p_len]) - <span class="number">97</span>] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> s_count == p_count:</span><br><span class="line">                ans.append(i + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-016不含重复字符的最长子字符串"></span></h4>
<p>给定一个字符串 <code>s</code> ，请你找出其中不含有重复字符的
<strong>最长连续子字符串</strong> 的长度。</p>
<ul>
<li><strong>滑动窗口</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLongestSubstring</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> s:<span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        left, lookup, n = <span class="number">0</span>, <span class="built_in">set</span>(), <span class="built_in">len</span>(s)</span><br><span class="line">        max_len, cur_len = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            cur_len += <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> s[i] <span class="keyword">in</span> lookup:</span><br><span class="line">                lookup.remove(s[left]) <span class="comment"># 移除做元素直到无重复，到最小无重复子串</span></span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">                cur_len -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> cur_len &gt; max_len:</span><br><span class="line">                max_len = cur_len</span><br><span class="line">            lookup.add(s[i])</span><br><span class="line">        <span class="keyword">return</span> max_len</span><br></pre></td></tr></table></figure>
<h4><span id="76最小覆盖子串"></span></h4>
<p>给你一个字符串 <code>s</code> 、一个字符串 <code>t</code> 。返回
<code>s</code> 中涵盖 <code>t</code> 所有字符的最小子串。如果
<code>s</code> 中不存在涵盖 <code>t</code>
所有字符的子串，则返回空字符串 <code>""</code> 。</p>
<ul>
<li><strong>滑动窗口</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minWindow</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        s_len, t_len = <span class="built_in">len</span>(s), <span class="built_in">len</span>(t)</span><br><span class="line">        <span class="keyword">if</span> s_len &lt; t_len:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 0 不删除</span></span><br><span class="line">        sdict, tdict = defaultdict(<span class="built_in">int</span>), Counter(t)</span><br><span class="line">        left, conut = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        res = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(s_len):</span><br><span class="line">            sdict[s[i]] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> sdict[s[i]] &lt;= tdict[s[i]]:</span><br><span class="line">                conut += <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> left &lt;= i <span class="keyword">and</span> sdict[s[left]] &gt; tdict[s[left]]:</span><br><span class="line">                <span class="comment"># 加一个A就减一个A...(无用后缀)</span></span><br><span class="line">                sdict[s[left]] -= <span class="number">1</span></span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> conut == t_len:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> res <span class="keyword">or</span> (i - left + <span class="number">1</span> &lt; <span class="built_in">len</span>(res)):</span><br><span class="line">                    res = s[left:i + <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="125验证回文串"></span></h4>
<p>给定一个字符串，验证它是否是回文串，只考虑字母和数字字符，可以忽略字母的大小写。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        left, right = <span class="number">0</span>, n - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> <span class="keyword">not</span> s[left].isalnum():</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> <span class="keyword">not</span> s[right].isalnum():</span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> left &lt; right:</span><br><span class="line">                <span class="keyword">if</span> s[left].lower() != s[right].lower():</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                left, right = left + <span class="number">1</span>, right - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-019最多删除一个字符得到回文"></span></h4>
<p>给定一个非空字符串 <code>s</code>，请判断如果 <strong>最多</strong>
从字符串中删除一个字符能否得到一个回文字符串。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">validPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="comment"># 回溯， 广度优先 【字符串长度，暴搜必定超时】</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">checkPalind</span>(<span class="params">l, r</span>):</span><br><span class="line">            <span class="keyword">while</span> l &lt; r:</span><br><span class="line">                <span class="keyword">if</span> s[l] != s[r]:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                l += <span class="number">1</span></span><br><span class="line">                r -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        left, right = <span class="number">0</span>, n - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            <span class="keyword">if</span> s[left] == s[right]:</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> checkPalind(left + <span class="number">1</span>, right) <span class="keyword">or</span> checkPalind(left, right - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-020回文子字符串的个数"></span></h4>
<p>给定一个字符串 <code>s</code>
，请计算这个字符串中有多少个回文子字符串。具有不同开始位置或结束位置的子串，即使是由相同的字符组成，也会被视作不同的子串。</p>
<ul>
<li>动态规划、双指针+中心扩展、<strong>==Manacher算法==</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">countSubstrings</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 双指针+中心扩散</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_extend</span>(<span class="params">s, i, j, n</span>):</span><br><span class="line">            res = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &gt;= <span class="number">0</span> <span class="keyword">and</span> j &lt; n <span class="keyword">and</span> s[i] == s[j]: <span class="comment"># 确定中心点</span></span><br><span class="line">                i -= <span class="number">1</span></span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">                res += <span class="number">1</span> <span class="comment"># 扩散过程也是答案</span></span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            result += _extend(s, i, i, <span class="built_in">len</span>(s)) <span class="comment">#以i为中心</span></span><br><span class="line">            result += _extend(s, i, i+<span class="number">1</span>, <span class="built_in">len</span>(s)) <span class="comment">#以i和i+1为中心</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">countSubstrings</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 动态规划 dp[i][j]: s[i:j] 是否为回文子串</span></span><br><span class="line">        <span class="comment"># dp[i+1][j-1] -&gt; dp[i][j] 遍历顺序 </span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        dp = [[<span class="literal">False</span>] * (n) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i,n):</span><br><span class="line">                <span class="keyword">if</span> s[i] == s[j]:</span><br><span class="line">                    <span class="keyword">if</span> j - i &lt;= <span class="number">1</span>:</span><br><span class="line">                        ans += <span class="number">1</span></span><br><span class="line">                        dp[i][j] = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">elif</span> dp[i+<span class="number">1</span>][j-<span class="number">1</span>]:</span><br><span class="line">                        ans += <span class="number">1</span></span><br><span class="line">                        dp[i][j] = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（4）查找算法</title>
    <url>/posts/24PQ9K6/</url>
    <content><![CDATA[<h2><span id="查找算法">查找算法</span></h2>
<blockquote>
<p><strong>bisect
文档</strong>:https://docs.python.org/zh-cn/3.6/library/bisect.html</p>
<ul>
<li><strong>二分查找求左边界</strong> <a href="https://leetcode.cn/problems/find-first-and-last-position-of-element-in-sorted-array/">第一个
False</a> : 不小于target的第一个数</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">leftMargin</span>(): <span class="comment"># 左边界</span></span><br><span class="line">   left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">	<span class="keyword">while</span> left &lt;= right:</span><br><span class="line">       mid = (left + right) // <span class="number">2</span></span><br><span class="line">       <span class="keyword">if</span> nums[mid] &lt; target: <span class="comment"># ... Ture # False ...</span></span><br><span class="line">          left = mid + <span class="number">1</span></span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">          right = mid - <span class="number">1</span></span><br><span class="line">   <span class="keyword">return</span> left <span class="keyword">if</span> nums[left] == target <span class="keyword">else</span> -<span class="number">1</span> <span class="comment"># 越界检验</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong>二分查找右边界</strong> [第一个 True ]</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">rightMargin</span>(): <span class="comment"># 右边界</span></span><br><span class="line">		left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> left &lt;= right:</span><br><span class="line">    		mid = (left + right) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> nums[mid] &gt; target: <span class="comment"># ... False # Ture ...</span></span><br><span class="line">           right = mid - <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">           left = mid + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> right <span class="keyword">if</span> nums[right] == target <span class="keyword">else</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure></p>
</blockquote>
<h4><span id="剑指offer-03-数组中重复的数字"></span></h4>
<p><strong>找出数组中重复的数字</strong>。<strong>==在一个长度为 n
的数组 nums 里的所有数字都在 0～n-1
的范围内==</strong>。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。</p>
<ul>
<li>哈希表 / Set、原地交换（空间0（1））</li>
<li>合理利用 <strong>val</strong> 和 <strong>key</strong> 的关系</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findRepeatNumber</span>(<span class="params">self, nums: [<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        dic = <span class="built_in">set</span>()</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> num <span class="keyword">in</span> dic: <span class="keyword">return</span> num</span><br><span class="line">            dic.add(num)</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">		<span class="keyword">def</span> <span class="title function_">findRepeatNumber</span>(<span class="params">self, nums: [<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(nums):</span><br><span class="line">            <span class="keyword">if</span> nums[i] == i:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> nums[nums[i]] == nums[i]: </span><br><span class="line">              	<span class="keyword">return</span> nums[i]</span><br><span class="line">            nums[nums[i]], nums[i] = nums[i], nums[nums[i]]</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-53-i-在排序数组中查找数字-i"></span></h4>
<p>统计一个数字在<strong>排序数组</strong>中出现的<strong>次数</strong>。</p>
<ul>
<li>找到目标值「最后」出现的分割点，并「往前」进行统计</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">search</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="comment"># 求右边界</span></span><br><span class="line">        <span class="keyword">while</span> left &lt;= right:</span><br><span class="line">            mid = (right + left) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid] &gt; target:</span><br><span class="line">                right = mid - <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">        <span class="comment"># 最后要检查 right 越界的情况</span></span><br><span class="line">        <span class="keyword">if</span> right &lt; <span class="number">0</span> <span class="keyword">or</span> nums[right] != target:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> right &gt;= <span class="number">0</span> <span class="keyword">and</span> nums[right] == target :</span><br><span class="line">            right -= <span class="number">1</span></span><br><span class="line">            ans += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer53-ii-0~n-1中缺失的数字"></span></h4>
<p><strong>一个长度为n-1的递增排序数组</strong>中的所有数字都是唯一的，并且每个数字都在范围0～n-1之内。在范围0～n-1内的n个数字中有且只有一个数字不在该数组中，请找出这个数字。</p>
<ul>
<li>排序数组中的搜索问题，首先想到 <strong>二分法</strong> 解决。
<ul>
<li>根据题意，数组可以按照以下规则划分为两部分
<ul>
<li><strong>左子数组：</strong> nums[i] = i</li>
<li><strong>右子数组：</strong> nums[i]  = i</li>
</ul></li>
</ul></li>
<li>缺失的数字等于 <strong>“右子数组的首位元素”</strong>
对应的索引；因此考虑使用二分法查找 “右子数组的首位元素” 。</li>
</ul>
<p><img src="https://pic.leetcode-cn.com/df7e04fbab0937ff74e5f29e958c7b1d531af066789ff363be5e1c8e75f17f56-Picture1.png" alt="Picture1.png" style="zoom:48%;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">missingNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        i, j = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> i &lt;= j:</span><br><span class="line">            m = (i + j) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[m] == m: </span><br><span class="line">              	i = m + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>: </span><br><span class="line">              	j = m - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> i</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-04-二维数组中的查找"></span></h4>
<p>在一个 n * m
的<strong>二维数组</strong>中，每一行都按照<strong>从左到右递增</strong>的顺序排序，每一列都按照<strong>从上到下递增</strong>的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</p>
<ul>
<li>我们将矩阵逆时针旋转 45° ，并将其转化为图形式，发现其类似于
<strong>二叉搜索树</strong></li>
</ul>
<p><img src="https://pic.leetcode-cn.com/6584ea93812d27112043d203ea90e4b0950117d45e0452d0c630fcb247fbc4af-Picture1.png" alt="Picture1.png" style="zoom:48%;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findNumberIn2DArray</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        i, j = <span class="built_in">len</span>(matrix) - <span class="number">1</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &gt;= <span class="number">0</span> <span class="keyword">and</span> j &lt; <span class="built_in">len</span>(matrix[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">if</span> matrix[i][j] &gt; target: </span><br><span class="line">              	i -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> matrix[i][j] &lt; target: </span><br><span class="line">              	j += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>: </span><br><span class="line">              	<span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-11-旋转数组的最小数字"></span></h4>
<p><strong>把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转</strong>。给你一个可能存在
重复 元素值的数组 numbers
，它原来是一个升序排列的数组，并按上述情形进行了一次旋转。请返回旋转数组的最小元素。例如，数组
[3,4,5,1,2] 为 [1,2,3,4,5] 的一次旋转，该数组的最小值为 1。</p>
<ul>
<li>二分查找</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minArray</span>(<span class="params">self, numbers: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 无法判断左右， right -= 1 缩小范围</span></span><br><span class="line">        left, right = <span class="number">0</span>, <span class="built_in">len</span>(numbers) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            mid = left + (right - left) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> numbers[mid] &lt; numbers[right]:</span><br><span class="line">                right = mid</span><br><span class="line">            <span class="keyword">elif</span> numbers[mid] &gt; numbers[right]:</span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> numbers[left]</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-50-第一个只出现一次的字符"></span></h4>
<p>在字符串 s 中找出第一个只出现一次的字符。如果没有，返回一个单空格。 s
只包含小写字母。</p>
<ul>
<li>哈希表存储频数、索引</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">firstUniqChar</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        frequency = collections.Counter(s)</span><br><span class="line">        <span class="keyword">for</span> i, ch <span class="keyword">in</span> <span class="built_in">enumerate</span>(s):</span><br><span class="line">            <span class="keyword">if</span> frequency[ch] == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> ch</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>队列：使用了「<strong>延迟删除</strong>」这一技巧</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">firstUniqChar</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        position = <span class="built_in">dict</span>()</span><br><span class="line">        q = collections.deque()</span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        <span class="keyword">for</span> i, ch <span class="keyword">in</span> <span class="built_in">enumerate</span>(s):</span><br><span class="line">            <span class="keyword">if</span> ch <span class="keyword">not</span> <span class="keyword">in</span> position:</span><br><span class="line">                position[ch] = i</span><br><span class="line">                q.append((s[i], i))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                position[ch] = -<span class="number">1</span></span><br><span class="line">                <span class="keyword">while</span> q <span class="keyword">and</span> position[q[<span class="number">0</span>][<span class="number">0</span>]] == -<span class="number">1</span>:</span><br><span class="line">                    q.popleft()</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span> <span class="keyword">if</span> <span class="keyword">not</span> q <span class="keyword">else</span> q[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-51-数组中的逆序对"></span></h4>
<p>在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组，求出这个数组中的逆序对的总数。</p>
<ul>
<li><code>from sortedcontainers import SortedList</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reversePairs</span>(<span class="params">self, nums</span>):</span><br><span class="line">        <span class="comment"># 逆序 + 二分插入</span></span><br><span class="line">        <span class="keyword">import</span> bisect</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        q = []</span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">            s = nums[i]</span><br><span class="line">            j = bisect.bisect_left(q, s)</span><br><span class="line">            res += j</span><br><span class="line">            q[j:j] = [s] </span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reversePairs</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        n = <span class="built_in">len</span>(nums)       </span><br><span class="line">        sl = SortedList()</span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):        <span class="comment"># 反向遍历</span></span><br><span class="line">            cnt = sl.bisect_left(nums[i])   <span class="comment"># 找到右边比当前值小的元素个数</span></span><br><span class="line">            ans += cnt                      <span class="comment"># 记入答案</span></span><br><span class="line">            sl.add(nums[i])                 <span class="comment"># 将当前值加入有序数组中</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="167两数之和-ii-输入有序数组"></span></h4>
<p>给你一个下标从 1 开始的整数数组 numbers
，该<strong>数组已按非递减顺序排列
，请你从数组中找出满足相加之和等于目标数 target
的两个数</strong>。如果设这两个数分别是 numbers[index1] 和
numbers[index2] ，则 1 &lt;= index1 &lt; index2 &lt;= numbers.length
。</p>
<ul>
<li>二分查找、双指针</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">twoSum</span>(<span class="params">self, numbers: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># 二分查找</span></span><br><span class="line">        n = <span class="built_in">len</span>(numbers)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            left, right = i + <span class="number">1</span>, n - <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> left &lt;= right:</span><br><span class="line">                mid = (left + right) // <span class="number">2</span></span><br><span class="line">                <span class="keyword">if</span> numbers[mid] == target - numbers[i]:</span><br><span class="line">                    <span class="keyword">return</span> [i + <span class="number">1</span>, mid + <span class="number">1</span>]</span><br><span class="line">                <span class="keyword">elif</span> numbers[mid] &gt; target - numbers[i]:</span><br><span class="line">                    right = mid - <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    left = mid + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> [-<span class="number">1</span>, -<span class="number">1</span>] </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">twoSum</span>(<span class="params">self, numbers: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># 双指针</span></span><br><span class="line">        low, high = <span class="number">0</span>, <span class="built_in">len</span>(numbers) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> low &lt; high:</span><br><span class="line">            total = numbers[low] + numbers[high]</span><br><span class="line">            <span class="keyword">if</span> total == target:</span><br><span class="line">                <span class="keyword">return</span> [low + <span class="number">1</span>, high + <span class="number">1</span>]</span><br><span class="line">            <span class="keyword">elif</span> total &lt; target:</span><br><span class="line">                low += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                high -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> [-<span class="number">1</span>, -<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h4><span id="15三数之和"></span></h4>
<p>给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素
a，b，c ，使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。</p>
<ul>
<li>排序 + 双指针 + 去重</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">threeSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        <span class="comment"># 排序 + 双指针 + 去冲</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        nums.sort()</span><br><span class="line">        ans = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            <span class="keyword">if</span> nums[i] &gt; <span class="number">0</span>: <span class="comment"># 剪枝加速</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> nums[i] == nums[i-<span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            left, right = i + <span class="number">1</span>, n - <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> left &lt; right:</span><br><span class="line">                cur = nums[i] + nums[left] + nums[right]</span><br><span class="line">                <span class="keyword">if</span> cur == <span class="number">0</span>:</span><br><span class="line">                    ans.append([nums[i], nums[left], nums[right]])</span><br><span class="line">                    <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> nums[right] == nums[right - <span class="number">1</span>]: right -= <span class="number">1</span></span><br><span class="line">                    right -= <span class="number">1</span></span><br><span class="line">                    <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> nums[left] == nums[left + <span class="number">1</span>]: left += <span class="number">1</span></span><br><span class="line">                    left += <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> cur &gt; <span class="number">0</span>:</span><br><span class="line">                    right -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    left += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-008-和大于等于-target的最短子数组"></span></h4>
<p>给定一个含有 <code>n</code>
个<strong>正整数</strong>的数组和一个正整数 <code>target</code>
<strong>。</strong>找出该数组中满足其和 <strong>≥ target</strong>
的<strong>长度最小的连续子数组</strong> [numsl, numsl+1, ..., numsr-1,
numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。</p>
<ul>
<li>前缀和 + 二分查找
o(nlogn)、<strong>滑动窗口o(n)</strong>【连续，正整数】</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minSubArrayLen</span>(<span class="params">self, target: <span class="built_in">int</span>, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 【前缀和 + 二分查找 o(nlogn)】</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">sum</span>(nums) &lt; target:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        pre = <span class="built_in">list</span>(accumulate([<span class="number">0</span>] + nums)) <span class="comment"># itertools.accumulate()</span></span><br><span class="line">        ans = n + <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n + <span class="number">1</span>):</span><br><span class="line">            cur = target + pre[i]</span><br><span class="line">            <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            left = bisect.bisect_left(pre, cur)</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span> </span><br><span class="line">            left = i + <span class="number">1</span></span><br><span class="line">            right = n</span><br><span class="line">            <span class="keyword">while</span> left &lt;= right:</span><br><span class="line">                mid = (left + right) // <span class="number">2</span></span><br><span class="line">                <span class="keyword">if</span> pre[mid] &lt; cur:</span><br><span class="line">                    left = mid + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    right = mid - <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> left != n+<span class="number">1</span>: </span><br><span class="line">                ans = <span class="built_in">min</span>(ans, left - i)</span><br><span class="line">        <span class="keyword">return</span> ans </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minSubArrayLen</span>(<span class="params">self, target: <span class="built_in">int</span>, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">sum</span>(nums) &lt; target:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        cur, res = <span class="number">0</span>, <span class="built_in">len</span>(nums) + <span class="number">1</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> j, var <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            cur += var</span><br><span class="line">            <span class="keyword">while</span> i &lt;= j <span class="keyword">and</span> cur &gt;= target:</span><br><span class="line">                <span class="keyword">if</span> (t:= j - i + <span class="number">1</span>) &lt; res:</span><br><span class="line">                    res = t </span><br><span class="line">                cur -= nums[i]</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-009-乘积小于k-的子数组"></span></h4>
<p>给定一个正整数数组 <code>nums</code>和整数 <code>k</code>
，请找出该数组内乘积小于 <code>k</code> 的连续的子数组的个数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numSubarrayProductLessThanK</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 前缀和单调 + 二分查找</span></span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        k = math.log(k)</span><br><span class="line">        pre = [<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            pre.append(pre[-<span class="number">1</span>] + math.log(num))</span><br><span class="line">        cur = res =  <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(pre)):</span><br><span class="line">            cur = k + pre[i - <span class="number">1</span>]</span><br><span class="line">            j = bisect.bisect_left(pre, cur, lo = i)</span><br><span class="line">            res += j - i </span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">numSubarrayProductLessThanK</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 滑动窗口</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        left, right = <span class="number">0</span>, n - <span class="number">1</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        i, cur =<span class="number">0</span>,  <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> j, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            cur *= num</span><br><span class="line">            <span class="keyword">while</span> i &lt;= j <span class="keyword">and</span> cur &gt;= k: <span class="comment"># 左跟着右</span></span><br><span class="line">                cur //= nums[i]</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            res += j - i + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-070排序数组中只出现一次的数字"></span></h4>
<p>给定一个只包含整数的<strong>有序数组 nums</strong>
，每个元素都会出现两次，唯有一个数只会出现一次，请找出这个唯一的数字。<strong>你设计的解决方案必须满足
O(log n) 时间复杂度和 O(1) 空间复杂度。</strong></p>
<ul>
<li>二分查找 o(logN)</li>
</ul>
<p>利用按位异或的性质，可以得到mid 和相邻的数之间的如下关系，其中 ⊕
是按位异或运算符：</p>
<ul>
<li><p>当mid 是偶数时，mid+1=mid⊕1；</p></li>
<li><p>当mid 是奇数时，mid−1=mid⊕1。</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">singleNonDuplicate</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        low, high = <span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> low &lt; high:</span><br><span class="line">            mid = (low + high) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid] == nums[mid ^ <span class="number">1</span>]:</span><br><span class="line">                low = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                high = mid</span><br><span class="line">        <span class="keyword">return</span> nums[low]</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-071按权重生成随机数"></span></h4>
<p>给定一个正整数数组 w ，其中 w[i] 代表下标 i 的权重（下标从 0
开始），请写一个函数 pickIndex ，它可以随机地获取下标 i，选取下标 i
的概率与 w[i] 成正比。</p>
<p>例如，对于 w = [1, 3]，挑选下标 0 的概率为 1 / (1 + 3) = 0.25
（即，25%），而选取下标 1 的概率为 3 / (1 + 3) = 0.75（即，75%）。</p>
<p>也就是说，选取下标 i 的概率为 w[i] / sum(w) 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, w: <span class="type">List</span>[<span class="built_in">int</span>]</span>):</span><br><span class="line">        self.pre = <span class="built_in">list</span>(accumulate(w))</span><br><span class="line">        self.total = <span class="built_in">sum</span>(w)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pickIndex</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 前缀和 + 二分查找</span></span><br><span class="line">        r = random.randint(<span class="number">1</span>, self.total)</span><br><span class="line">        <span class="keyword">return</span> bisect_left(self.pre, r)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-073狒狒吃香蕉"></span></h4>
<p><strong>狒狒喜欢吃香蕉。这里有 n 堆香蕉，第 i 堆中有 piles[i]
根香蕉。警卫已经离开了，将在 h
小时后回来。</strong>狒狒可以决定她吃香蕉的速度 k
（单位：根/小时）。每个小时，她将会选择一堆香蕉，从中吃掉 k
根。如果这堆香蕉少于 k
根，她将吃掉这堆的所有香蕉，然后这一小时内不会再吃更多的香蕉，下一个小时才会开始吃另一堆的香蕉。<strong>返回她可以在
h 小时内吃掉所有香蕉的最小速度 k（k 为整数）。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minEatingSpeed</span>(<span class="params">self, piles: <span class="type">List</span>[<span class="built_in">int</span>], h: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        left, right = <span class="built_in">max</span>(<span class="number">1</span>, <span class="built_in">sum</span>(piles) // h), <span class="built_in">max</span>(piles)</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">check</span>(<span class="params">k</span>):</span><br><span class="line">            count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> pile <span class="keyword">in</span> piles:</span><br><span class="line">                count += ceil(pile / k)</span><br><span class="line">            <span class="keyword">return</span> count &gt; h</span><br><span class="line">        <span class="keyword">while</span> left &lt;= right: </span><br><span class="line">            mid = (left + right) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> check(mid): <span class="comment"># ... Ture # False(r) ...</span></span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                right = mid - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> left</span><br></pre></td></tr></table></figure>
<h4><span id="378-有序矩阵中第-k-小的元素"></span></h4>
<p>给你一个 n x n 矩阵 matrix
，其中<strong>每行和每列元素均按升序排序</strong>，<strong>找到矩阵中第
k 小的元素</strong>。 请注意，它是 排序后 的第 k 小元素，而不是第 k 个
不同 的元素。</p>
<p><strong>你必须找到一个内存复杂度优于 O(n2) 的解决方案。</strong></p>
<blockquote>
<p>输入：matrix = [[1,5,9],[10,11,13],[12,13,15]], k = 8 输出：13
解释：矩阵中的元素为 [1,5,9,10,11,12,13,13,15]，第 8 小元素是 13</p>
</blockquote>
<ul>
<li><strong>优先队列</strong>：这个矩阵的每一行均为一个有序数组。问题即转化为从这
n<em>n</em> 个有序数组中找第 k<em>k</em>
大的数，可以想到利用归并排序的做法，归并到第 k<em>k</em>
个数即可停止。<strong>需要用小根堆维护，以优化时间复杂度。</strong></li>
<li><strong>二分查找</strong>
<ul>
<li>初始位置在 matrix [n - 1] [0]（即左下角）；</li>
<li>设当前位置为 matrix [i] [j]。若 matrix [i] [j]
≤mid，则将当前所在列的不大于 mid 的数的数量（即 i +
1i+1）累加到答案中，<strong>并向右移动，否则向上移动</strong>；</li>
<li><strong>可以线性计算对于任意一个
mid，矩阵中有多少数不大于它。这满足了二分查找的性质。</strong></li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">kthSmallest</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 优先队列</span></span><br><span class="line">        n = <span class="built_in">len</span>(matrix)</span><br><span class="line">        heap = [(matrix[i][<span class="number">0</span>], i, <span class="number">0</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        heapq.heapify(heap)</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k - <span class="number">1</span>):</span><br><span class="line">            num, x, y = heapq.heappop(heap)</span><br><span class="line">            <span class="keyword">if</span> y != n - <span class="number">1</span>:</span><br><span class="line">                heapq.heappush(heap, (matrix[x][y + <span class="number">1</span>], x, y + <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> heap[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">kthSmallest</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 二分查找</span></span><br><span class="line">        n = <span class="built_in">len</span>(matrix)</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">check</span>(<span class="params">mid</span>):</span><br><span class="line">            i, j = n - <span class="number">1</span>, <span class="number">0</span></span><br><span class="line">            num = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> i &gt;= <span class="number">0</span> <span class="keyword">and</span> j &lt; n:</span><br><span class="line">                <span class="keyword">if</span> matrix[i][j] &lt;= mid:</span><br><span class="line">                    num += i + <span class="number">1</span></span><br><span class="line">                    j += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    i -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> num &lt; k </span><br><span class="line">        <span class="comment"># 【第一个False】</span></span><br><span class="line">        left, right = matrix[<span class="number">0</span>][<span class="number">0</span>], matrix[-<span class="number">1</span>][-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">while</span> left &lt;= right:</span><br><span class="line">            mid = (left + right) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> check(mid):</span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                right = mid - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> left</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（7）队列</title>
    <url>/posts/33W7JW8/</url>
    <content><![CDATA[<h2><span id="队列">队列</span></h2>
<h4><span id="剑指offer-09-用两个栈实现队列"></span></h4>
<p>用两个栈实现一个队列。队列的声明如下，<strong>请实现它的两个函数
appendTail 和 deleteHead</strong>
，<strong>分别完成在队列尾部插入整数和在队列头部删除整数的功能</strong>。(若队列中没有元素，deleteHead
操作返回 -1 )</p>
<ul>
<li>初始化<strong>两个栈</strong>（s1输入栈、s2输出栈）</li>
<li><strong>将输入栈导出到输出栈</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CQueue</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.s1 = [] <span class="comment"># 输入栈</span></span><br><span class="line">        self.s2 = [] <span class="comment"># 输出栈</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">appendTail</span>(<span class="params">self, value: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.s1.append(value)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">deleteHead</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> self.s2:</span><br><span class="line">            <span class="keyword">return</span> self.s2.pop()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.s1:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> self.s1: <span class="comment"># 清空输入栈</span></span><br><span class="line">            self.s2.append(self.s1.pop())</span><br><span class="line">        <span class="keyword">return</span> self.s2.pop()</span><br></pre></td></tr></table></figure>
<h2><span id="优先队列">优先队列</span></h2>
<h4><span id="239-滑动窗口最大值"></span></h4>
<p>给你一个整数数组 <code>nums</code>，有一个大小为 <code>k</code>
的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的
<code>k</code> 个数字。滑动窗口每次只向右移动一位。</p>
<blockquote>
<p>示例 1：</p>
<p>输入：nums = [1,3,-1,-3,5,3,6,7], k = 3 输出：[3,3,5,5,6,7] 解释：
滑动窗口的位置 最大值 --------------- ----- [1 3 -1] -3 5 3 6 7 3 1 [3
-1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3
[5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7</p>
</blockquote>
<ul>
<li><strong>单调队列</strong> 0(1) 线性时间算出滑动窗口最大值</li>
<li><strong>优先队列</strong>（<strong>大根堆</strong>）
时间复杂度：O(nlogn) 空间复杂度：O(n) 【<strong>注意 Python
默认的优先队列是小根堆</strong>】</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxSlidingWindow</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># 单调队列 0(1) 线性时间算出滑动窗口最大值 </span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        q = collections.deque() <span class="comment"># 保存最大索引</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            <span class="keyword">while</span> q <span class="keyword">and</span> nums[i] &gt;= nums[q[-<span class="number">1</span>]]:</span><br><span class="line">                <span class="comment"># 较小的备用,交大的删除前面小的</span></span><br><span class="line">                q.pop()</span><br><span class="line">            q.append(i)</span><br><span class="line">        ans = [nums[q[<span class="number">0</span>]]] <span class="comment"># 第一个窗口初始化</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k, n):</span><br><span class="line">            <span class="keyword">while</span> q <span class="keyword">and</span> nums[i] &gt;= nums[q[-<span class="number">1</span>]]:</span><br><span class="line">                <span class="comment"># 较小的备用,交大的删除前面小的</span></span><br><span class="line">                q.pop()</span><br><span class="line">            q.append(i)</span><br><span class="line">            <span class="keyword">while</span> q[<span class="number">0</span>] &lt;= i-k: <span class="comment"># 最大的退役了</span></span><br><span class="line">                q.popleft()</span><br><span class="line">            ans.append(nums[q[<span class="number">0</span>]])</span><br><span class="line">        <span class="keyword">return</span> ans</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maxSlidingWindow</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># 优先队列（大根堆） 时间复杂度：O(nlogn) 空间复杂度：O(n)</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="comment"># 注意 Python 默认的优先队列是小根堆</span></span><br><span class="line">        q = [(-nums[i], i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k)]</span><br><span class="line">        heapq.heapify(q) <span class="comment">#list2最小堆</span></span><br><span class="line">        ans = [-q[<span class="number">0</span>][<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k, n):</span><br><span class="line">            heapq.heappush(q, (-nums[i], i))</span><br><span class="line">            <span class="keyword">while</span> q[<span class="number">0</span>][<span class="number">1</span>] &lt;= i - k: <span class="comment"># 弹出历史最大值的索引</span></span><br><span class="line">                heapq.heappop(q)</span><br><span class="line">            ans.append(-q[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-041滑动窗口的平均值"></span></h4>
<p>给定一个整数数据流和一个窗口大小，根据该滑动窗口的大小，计算滑动窗口里所有数字的平均值。</p>
<p><strong>实现 MovingAverage 类：</strong></p>
<ul>
<li>MovingAverage(int size) 用窗口大小 size 初始化对象。</li>
<li>double next(int val) 成员函数 next
每次调用的时候都会往滑动窗口增加一个整数，请计算并返回数据流中最后 size
个值的移动平均值，即滑动窗口里所有数字的平均值。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MovingAverage</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Initialize your data structure here.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.nums = deque()</span><br><span class="line">        self.total = <span class="number">0</span></span><br><span class="line">        self.size = size</span><br><span class="line">        self.<span class="built_in">len</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">next</span>(<span class="params">self, val: <span class="built_in">int</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="keyword">if</span> self.<span class="built_in">len</span> &gt;= self.size:</span><br><span class="line">            self.total -= self.nums.popleft()</span><br><span class="line">            self.<span class="built_in">len</span> -= <span class="number">1</span></span><br><span class="line">        self.nums.append(val)</span><br><span class="line">        self.total += val</span><br><span class="line">        self.<span class="built_in">len</span> += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> self.total / self.<span class="built_in">len</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-042最近请求次数"></span></h4>
<p>写一个 RecentCounter 类来计算特定时间范围内最近的请求。</p>
<p><strong>请实现 RecentCounter 类：</strong></p>
<ul>
<li><p>RecentCounter() 初始化计数器，请求数为 0 。</p></li>
<li><p>int ping(int t) 在时间 t 添加一个新请求，其中 t
表示以毫秒为单位的某个时间，并返回过去 3000
毫秒内发生的所有请求数（包括新请求）。确切地说，返回在 [t-3000, t]
内发生的请求数。</p></li>
<li><p><strong>优先队列、二分查找</strong></p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RecentCounter</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    def __init__(self):</span></span><br><span class="line"><span class="string">        self.q = deque()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def ping(self, t: int) -&gt; int:</span></span><br><span class="line"><span class="string">        while self.q and (self.q[0] + 3000) &lt; t:</span></span><br><span class="line"><span class="string">            self.q.popleft()</span></span><br><span class="line"><span class="string">        self.q.append(t)</span></span><br><span class="line"><span class="string">        return len(self.q)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.ping_list = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ping</span>(<span class="params">self, t: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        self.ping_list.append(t)</span><br><span class="line">        left = bisect_left(self.ping_list, t-<span class="number">3000</span>) </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.ping_list) - left</span><br></pre></td></tr></table></figure>
<h2><span id="单调队列">单调队列</span></h2>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（5）双指针</title>
    <url>/posts/2WGWZ88/</url>
    <content><![CDATA[<h2><span id="双指针">双指针</span></h2>
<h4><span id="剑指offer-48-最长不含重复字符的子字符串"></span></h4>
<p>请从字符串中找出一个最长的<strong>不包含重复字符的子字符串</strong>，<strong>计算该最长子字符串的长度</strong>。</p>
<ul>
<li><strong>双指针、队列</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLongestSubstring</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 回溯 + set</span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        que = collections.deque()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(s) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        que.append(s[<span class="number">0</span>])</span><br><span class="line">        res = <span class="number">1</span></span><br><span class="line">        tmp = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">if</span> s[i] <span class="keyword">not</span> <span class="keyword">in</span> que:</span><br><span class="line">                tmp += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">while</span> que <span class="keyword">and</span> que.popleft() != s[i]:</span><br><span class="line">                    tmp -= <span class="number">1</span></span><br><span class="line">            que.append(s[i])</span><br><span class="line">            res = <span class="built_in">max</span>(res, tmp)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLongestSubstring</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">      	<span class="comment"># 双指针 + 哈希表</span></span><br><span class="line">        dic, res, i = &#123;&#125;, <span class="number">0</span>, -<span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="keyword">if</span> s[j] <span class="keyword">in</span> dic:</span><br><span class="line">                i = <span class="built_in">max</span>(dic[s[j]], i) <span class="comment"># 更新左指针 i</span></span><br><span class="line">            dic[s[j]] = j <span class="comment"># 哈希表记录</span></span><br><span class="line">            res = <span class="built_in">max</span>(res, j - i) <span class="comment"># 更新结果</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-18-删除链表的节点"></span></h4>
<p>给定单向链表的头指针和一个要删除的节点的值，定义一个<strong>函数删除该节点</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">deleteNode</span>(<span class="params">self, head: ListNode, val: <span class="built_in">int</span></span>) -&gt; ListNode:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        cur = dummy = ListNode(<span class="number">0</span>, head)</span><br><span class="line">        <span class="keyword">while</span> cur.<span class="built_in">next</span>:</span><br><span class="line">            <span class="keyword">if</span> cur.<span class="built_in">next</span>.val == val:</span><br><span class="line">                cur.<span class="built_in">next</span> = cur.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cur = cur.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-22-链表中倒数第k个节点"></span></h4>
<p>输入一个链表，输出该链表中倒数第k个节点。为了符合大多数人的习惯，本题从1开始计数，即链表的尾节点是倒数第1个节点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getKthFromEnd</span>(<span class="params">self, head: ListNode, k: <span class="built_in">int</span></span>) -&gt; ListNode:</span><br><span class="line">        fast, slow = head, head</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            fast = fast.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">while</span> fast:</span><br><span class="line">            fast = fast.<span class="built_in">next</span></span><br><span class="line">            slow = slow.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> slow</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-25-合并两个排序的链表"></span></h4>
<p>输入两个递增排序的链表，<strong>合并这两个链表并使新链表中的节点仍然是递增排序的。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mergeTwoLists</span>(<span class="params">self, l1: ListNode, l2: ListNode</span>) -&gt; ListNode:</span><br><span class="line">        cur = dummy = ListNode(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">while</span> l1 <span class="keyword">and</span> l2:</span><br><span class="line">            <span class="keyword">if</span> l1.val &gt; l2.val:</span><br><span class="line">                cur.<span class="built_in">next</span>, l2 = l2, l2.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cur.<span class="built_in">next</span>, l1 = l1, l1.<span class="built_in">next</span></span><br><span class="line">            cur = cur.<span class="built_in">next</span></span><br><span class="line">        cur.<span class="built_in">next</span> = l1 <span class="keyword">if</span> l1 <span class="keyword">else</span> l2</span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-52-两个链表的第一个公共节点"></span></h4>
<p>输入两个<strong>链表</strong>，找出它们的<strong>第一个公共节点</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getIntersectionNode</span>(<span class="params">self, headA: ListNode, headB: ListNode</span>) -&gt; ListNode:</span><br><span class="line">        p1, p2 = headA, headB</span><br><span class="line">        <span class="keyword">while</span> p1 != p2:</span><br><span class="line">            p1 = p1.<span class="built_in">next</span> <span class="keyword">if</span> p1 <span class="keyword">else</span> headB</span><br><span class="line">            p2 = p2.<span class="built_in">next</span> <span class="keyword">if</span> p2 <span class="keyword">else</span> headA</span><br><span class="line">        <span class="keyword">return</span> p1</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-21-调整数组顺序使奇数位于偶数前面"></span></h4>
<p>输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有奇数在数组的前半部分，所有偶数在数组的后半部分。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">exchange</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            <span class="keyword">while</span> nums[left]%<span class="number">2</span> == <span class="number">1</span> <span class="keyword">and</span> left &lt; right: </span><br><span class="line">              	left += <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> nums[right]%<span class="number">2</span> == <span class="number">0</span> <span class="keyword">and</span> left &lt; right: </span><br><span class="line">              	right -= <span class="number">1</span></span><br><span class="line">            nums[left], nums[right] = nums[right], nums[left]</span><br><span class="line">        <span class="keyword">return</span> nums</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">exchange</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">    		<span class="keyword">return</span> <span class="built_in">sorted</span>(nums, key = <span class="keyword">lambda</span> x: x%<span class="number">2</span>, reverse = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-57-和为s的两个数字"></span></h4>
<p>输入一个递增排序的数组和一个数字s，在数组中查找两个数，使得它们的和正好是s。如果有多对数字的和等于s，则输出任意一对即可。</p>
<h5><span id="解题思路">解题思路：</span></h5>
<ul>
<li><p>利用 HashMap 可以通过遍历数组找到数字组合，时间和空间复杂度均为
O(N)；</p></li>
<li><p>注意本题的 nums 是<strong>排序数组</strong> ，因此可使用 双指针法
将空间复杂度降低至 O(1)。</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">twoSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        ndict = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">if</span> target-nums[i] <span class="keyword">in</span> ndict:</span><br><span class="line">                <span class="keyword">return</span> [target-nums[i], nums[i]]</span><br><span class="line">            ndict[nums[i]] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">twoSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        left, right = <span class="number">0</span>, <span class="built_in">len</span>(nums)-<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            s = nums[left] + nums[right]</span><br><span class="line">            <span class="keyword">if</span> s &gt; target:</span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> s &lt; target:</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> [nums[left], nums[right]]</span><br><span class="line">        <span class="keyword">return</span> []</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-58-i-翻转单词顺序"></span></h4>
<p>输入一个英文句子，翻转句子中单词的顺序，但单词内字符的顺序不变。为简单起见，标点符号和普通字母一样处理。例如输入字符串"I
am a student. "，则输出"student. a am I"。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverseWords</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot; &quot;</span>.join(<span class="built_in">reversed</span>(s.strip().split()))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverseWords</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        s = s.strip() <span class="comment"># 删除首尾空格</span></span><br><span class="line">        i = j = <span class="built_in">len</span>(s) - <span class="number">1</span></span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">while</span> i &gt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">while</span> i &gt;= <span class="number">0</span> <span class="keyword">and</span> s[i] != <span class="string">&#x27; &#x27;</span>: i -= <span class="number">1</span> <span class="comment"># 搜索首个空格</span></span><br><span class="line">            res.append(s[i + <span class="number">1</span>: j + <span class="number">1</span>]) <span class="comment"># 添加单词</span></span><br><span class="line">            <span class="keyword">while</span> s[i] == <span class="string">&#x27; &#x27;</span>: i -= <span class="number">1</span> <span class="comment"># 跳过单词间空格</span></span><br><span class="line">            j = i <span class="comment"># j 指向下个单词的尾字符</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(res) <span class="comment"># 拼接并返回</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（6）栈</title>
    <url>/posts/3C0HSVJ/</url>
    <content><![CDATA[<h2><span id="栈">栈</span></h2>
<h4><span id="剑指offer-30-包含min函数的栈"></span></h4>
<p>定义栈的数据结构，请在该类型中实现一个能够<strong>得到栈的最小元素的
min 函数在该栈中</strong>，调用 min、push 及 pop 的时间复杂度都是
<strong>O(1)</strong>。</p>
<ul>
<li>self.smin = []
<strong>存储最小栈元素</strong>，记录当前最小值是什么。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MinStack</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.sdata = []</span><br><span class="line">        self.smin = []</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">push</span>(<span class="params">self, x: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.sdata.append(x)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.smin <span class="keyword">or</span> self.smin[-<span class="number">1</span>] &gt;= x:</span><br><span class="line">            self.smin.append(x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">pop</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> self.sdata.pop() == self.smin[-<span class="number">1</span>]:</span><br><span class="line">            self.smin.pop()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">top</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">return</span> self.sdata[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">min</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">return</span> self.smin[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h4><span id="150逆波兰表达式求值"></span></h4>
<p>有效的算符包括 +、-、*、/
。每个运算对象可以是整数，也可以是另一个逆波兰表达式。<strong>注意
两个整数之间的除法只保留整数部分。</strong></p>
<p>示例 1：</p>
<p>输入：tokens = ["2","1","+","3","*"] 输出：9
解释：该算式转化为常见的中缀算术表达式为：((2 + 1) * 3) = 9</p>
<ul>
<li><strong><font color="red">
函数字典</font></strong>，<strong>isdigit只能判断正整数</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">evalRPN</span>(<span class="params">self, tokens: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        n = <span class="built_in">len</span>(tokens)</span><br><span class="line">        op = &#123;</span><br><span class="line">                <span class="string">&#x27;+&#x27;</span>: add,</span><br><span class="line">                <span class="string">&#x27;-&#x27;</span>: sub,</span><br><span class="line">                <span class="string">&#x27;*&#x27;</span>: mul,</span><br><span class="line">                <span class="string">&#x27;/&#x27;</span>: <span class="keyword">lambda</span> x, y: <span class="built_in">int</span>(x / y)</span><br><span class="line">        &#125;</span><br><span class="line">        stack = []</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> tokens:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                num = <span class="built_in">int</span>(t)</span><br><span class="line">            <span class="keyword">except</span> ValueError:</span><br><span class="line">                b = stack.pop()</span><br><span class="line">                a = stack.pop()</span><br><span class="line">                num = op[t](a, b)</span><br><span class="line">            <span class="keyword">finally</span>:</span><br><span class="line">                stack.append(num)</span><br><span class="line">        <span class="keyword">return</span> stack[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h2><span id="单调栈">单调栈</span></h2>
<h4><span id="剑指-offer-ii-039-直方图最大矩形面积"></span></h4>
<p>给定非负整数数组 <code>heights</code>
，数组中的数字用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为
<code>1</code> 。求在该柱状图中，能够勾勒出来的矩形的最大面积。</p>
<p><strong>示例 1:</strong></p>
<figure>
<img src="https://assets.leetcode.com/uploads/2021/01/04/histogram.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：heights = [<span class="number">2</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">输出：<span class="number">10</span></span><br><span class="line">解释：最大的矩形为图中红色区域，面积为 <span class="number">10</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">largestRectangleArea</span>(<span class="params">self, heights: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        heights = [<span class="number">0</span>] + heights + [<span class="number">0</span>] <span class="comment"># 哨兵</span></span><br><span class="line">        stack, res = [<span class="number">0</span>], <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(heights)):</span><br><span class="line">            <span class="keyword">while</span> stack <span class="keyword">and</span> heights[i] &lt;= heights[stack[-<span class="number">1</span>]]:</span><br><span class="line">                tmp = stack.pop()</span><br><span class="line">                <span class="keyword">if</span> stack:</span><br><span class="line">                    weith = i - stack[-<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> (t := heights[tmp] * weith) &gt; res:</span><br><span class="line">                        res = t</span><br><span class="line">            stack.append(i)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-040矩阵中最大的矩形"></span></h4>
<p>给定一个由 <code>0</code> 和 <code>1</code> 组成的矩阵
<code>matrix</code> ，找出只包含 <code>1</code>
的最大矩形，并返回其面积。</p>
<p><strong>注意：</strong>此题 <code>matrix</code> 输入格式为一维
<code>01</code> 字符串数组。</p>
<p><strong>示例 1：</strong></p>
<figure>
<img src="https://assets.leetcode.com/uploads/2020/09/14/maximal.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line">输入：<span class="built_in">matrix</span> = [<span class="string">&quot;10100&quot;</span>,<span class="string">&quot;10111&quot;</span>,<span class="string">&quot;11111&quot;</span>,<span class="string">&quot;10010&quot;</span>]</span><br><span class="line">输出：<span class="number">6</span></span><br><span class="line">解释：最大矩形如上图所示。</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">maximalRectangle</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">maximalhist</span>(<span class="params">heights</span>):</span><br><span class="line">            heights = [<span class="number">0</span>] + heights + [<span class="number">0</span>]</span><br><span class="line">            res, stack = <span class="number">0</span>, [<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(heights)):</span><br><span class="line">                <span class="keyword">while</span> stack <span class="keyword">and</span> heights[i] &lt;= heights[stack[-<span class="number">1</span>]]:</span><br><span class="line">                    tmp = stack.pop()</span><br><span class="line">                    <span class="keyword">if</span> stack:</span><br><span class="line">                        weith = i - stack[-<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">                        <span class="keyword">if</span> (t := heights[tmp] * weith) &gt; res:</span><br><span class="line">                            res = t </span><br><span class="line">                stack.append(i)</span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> matrix:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        m, n = <span class="built_in">len</span>(matrix), <span class="built_in">len</span>(matrix[<span class="number">0</span>])</span><br><span class="line">        pre = [<span class="number">0</span>] * n</span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                <span class="comment"># if else 缩减</span></span><br><span class="line">                <span class="keyword">if</span> matrix[i][j] != <span class="string">&#x27;0&#x27;</span>:</span><br><span class="line">                    pre[j] += <span class="built_in">int</span>(matrix[i][j])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    pre[j] = <span class="number">0</span></span><br><span class="line">            ans = <span class="built_in">max</span>(ans, maximalhist(pre))</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-037小行星碰撞"></span></h4>
<p>给定一个整数数组
asteroids，表示在同一行的小行星。对于数组中的每一个元素，其绝对值表示小行星的大小，正负表示小行星的移动方向（正表示向右移动，负表示向左移动）。每一颗小行星以相同的速度移动。<strong>找出碰撞后剩下的所有小行星。碰撞规则：两个行星相互碰撞，较小的行星会爆炸。如果两颗行星大小相同，则两颗行星都会爆炸。两颗移动方向相同的行星，永远不会发生碰撞。</strong></p>
<blockquote>
<p><strong>示例 1：</strong></p>
<p>输入：asteroids = [5,10,-5] 输出：[5,10] 解释：10 和 -5 碰撞后只剩下
10 。 5 和 10 永远不会发生碰撞。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">asteroidCollision</span>(<span class="params">self, asteroids: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        n = <span class="built_in">len</span>(asteroids)</span><br><span class="line">        stack = [<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">while</span> stack <span class="keyword">and</span> asteroids[stack[-<span class="number">1</span>]] &gt; <span class="number">0</span> <span class="keyword">and</span> asteroids[i] &lt; <span class="number">0</span>:</span><br><span class="line">                a = asteroids[stack[-<span class="number">1</span>]]</span><br><span class="line">                b = asteroids[i]</span><br><span class="line">                <span class="keyword">if</span> a + b &lt; <span class="number">0</span>:</span><br><span class="line">                    stack.pop()</span><br><span class="line">                <span class="keyword">elif</span> a + b &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">elif</span> a + b == <span class="number">0</span>:</span><br><span class="line">                    stack.pop()</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                stack.append(i)</span><br><span class="line">        <span class="keyword">return</span> [asteroids[i] <span class="keyword">for</span> i <span class="keyword">in</span> stack]</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-038每日温度"></span></h4>
<p>给定一个整数数组 temperatures ，表示每天的温度，<strong>返回一个数组
answer ，其中 answer[i] 是指对于第 i
天，下一个更高温度出现在几天后</strong>。如果气温在这之后都不会升高，请在该位置用
0 来代替。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dailyTemperatures</span>(<span class="params">self, temperatures: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        n = <span class="built_in">len</span>(temperatures)</span><br><span class="line">        stack, ans = [<span class="number">0</span>], [<span class="number">0</span>] * n</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">while</span> stack <span class="keyword">and</span> temperatures[stack[-<span class="number">1</span>]] &lt; temperatures[i]:</span><br><span class="line">                tmp = stack.pop()</span><br><span class="line">                ans[tmp] = i - tmp</span><br><span class="line">            stack.append(i)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（8）BFS&amp;DFS</title>
    <url>/posts/1TJZXJZ/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>算法长征（8）贪心</title>
    <url>/posts/2T8VZBZ/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
  </entry>
  <entry>
    <title>Python（2）多进程</title>
    <url>/posts/2RCG5GH/</url>
    <content><![CDATA[<h2><span id="python多进程可以多核多线程no协程">Python多进程[可以多核]
多线程【No】协程</span></h2>
<blockquote>
<p><strong>multiprocessing ---
基于进程的并行</strong>:https://docs.python.org/zh-cn/3/library/multiprocessing.html</p>
<p><strong>Python进阶</strong>：https://ebook-python-study.readthedocs.io/zh_CN/latest/index.html</p>
</blockquote>
<h3><span id="一-进程的定义">一、进程的定义</span></h3>
<h5><span id="进程一个程序运行起来后代码用到的资源称之为进程它是操作系统分配资源的基本单元">进程：一个程序运行起来后，代码+用到的资源
称之为进程，它是操作系统分配资源的基本单元。</span></h5>
<h5><span id="线程操作系统能够进行运算调度的最小单位">线程：<strong>操作系统能够进行运算调度的最小单位</strong>。</span></h5>
<h5><span id="协程协程是python个中另外一种实现多任务的方式只不过比线程更小占用更小执行单元理解为需要的资源-因为它自带cpu上下文-这样只要在合适的时机-我们可以把一个协程切换到另一个协程-只要这个过程中保存或恢复cpu上下文那么程序还是可以运行的">协程：协程是python个中另外一种实现多任务的方式，只不过比线程更小占用更小执行单元（理解为需要的资源）。
因为它自带CPU上下文。这样只要在合适的时机， 我们可以把一个协程
切换到另一个协程。 只要这个过程中保存或恢复
CPU上下文那么程序还是可以运行的。</span></h5>
<p>https://anchorety.github.io/2018/12/30/python%E5%A4%9A%E8%BF%9B%E7%A8%8B/</p>
<p>在介绍Python中的线程之前，先明确一个问题，Python中的多线程是<strong>假的多线程</strong>！
为什么这么说，我们先明确一个概念，<strong>全局解释器锁</strong>（GIL）。</p>
<p>Python代码的执行由Python虚拟机（解释器）来控制。Python在设计之初就考虑要在主循环中，同时只有一个线程在执行，就像单CPU的系统中运行多个进程那样，内存中可以存放多个程序，但任意时刻，只有一个程序在CPU中运行。同样地，虽然Python解释器可以运行多个线程，只有一个线程在解释器中运行。</p>
<p><strong>对Python虚拟机的访问由全局解释器锁（GIL）来控制，正是这个锁能保证同时只有一个线程在运行</strong>。在多线程环境中，Python虚拟机按照以下方式执行。</p>
<blockquote>
<p>1.设置GIL。</p>
<p>2.切换到一个线程去执行。</p>
<p>3.运行。</p>
<p>4.把线程设置为睡眠状态。</p>
<p>5.解锁GIL。</p>
<p>6.再次重复以上步骤。</p>
</blockquote>
<p>对所有面向I/O的（会调用内建的操作系统C代码的）程序来说，GIL会在这个I/O调用之前被释放，以<strong>允许其他线程在这个线程等待I/O的时候运行</strong>。</p>
<p>如果某线程并未使用很多I/O操作，它会在自己的时间片内一直占用处理器和GIL。也就是说，I/O密集型的Python程序比CPU密集型的Python程序更能充分利用多线程的好处。</p>
<p>任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。</p>
<h3><span id="11-multiprocessing">1.1 multiprocessing</span></h3>
<h3><span id="12-joblib">1.2 joblib</span></h3>
<blockquote>
<p>Python之并行--基于joblib - 半个冯博士的文章 - 知乎
https://zhuanlan.zhihu.com/p/180347090</p>
</blockquote>
<p>首先<code>joblib</code>里面最常用到的一个类和一个方法分别是<code>Parallel</code>和<code>delayed</code>。<code>Parallel</code>主要用于初始化并行计算时需要用到的参数，而<code>delayed</code>则主要用来指定需要被并行的参数。比如官方给出的以下示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt</span><br><span class="line"><span class="keyword">from</span> joblib <span class="keyword">import</span> Parallel, delayed</span><br><span class="line">Parallel(n_jobs=<span class="number">2</span>)(delayed(sqrt)(i ** <span class="number">2</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>))</span><br><span class="line">[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>]</span><br></pre></td></tr></table></figure>
<p>这段代码其实已经基本看出方法的主要使用模式了。</p>
<p>解释一下：</p>
<ul>
<li><code>Parallel(n_jobs=2)</code>:
指定两个CPU（默认是分配给不同的CPU）</li>
<li>后面的<code>delayed(sqrt)</code>表示要用的函数是<code>sqrt</code>，这里这种用法就非常类似<code>C++</code>里面的<strong>委托(delegate)</strong>。</li>
<li><code>(i ** 2) for i in range(10)</code>:
这里注意<code>(i**2)</code>的括号和<code>delayed(sqrt)</code>是紧挨着的。这一小段表示<strong>要传递给<code>delayed</code>中指定的函数的参数是<code>i^2</code>。</strong></li>
</ul>
<p>那么结合这么一小段程序，其实已经能大致理解它的使用方法了。这里最开始可能主要不习惯的是要用到了Python里面的<a href="https://link.zhihu.com/?target=https%3A//blog.mioshu.com/archives/328.html">内部函数</a>机制。</p>
<h2><span id="二-多进程应用">二、多进程应用</span></h2>
<h3><span id="21-python多进程读写公共数据-异步读取">2.1、python多进程读写公共数据 -
异步读取</span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing, os, time  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#公共数据</span></span><br><span class="line">temp = np.zeros((<span class="number">4</span>,<span class="number">12</span>))</span><br><span class="line"><span class="comment"># 回调函数，用于多进程读写公共数据的，我的理解：多进程在回调函数这里是串行的，否则同时读写会乱掉</span></span><br><span class="line"><span class="comment"># 回调函数必须只有一个输入参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mycallback</span>(<span class="params">index</span>):</span><br><span class="line">    i,j = index[<span class="number">0</span>],index[<span class="number">1</span>]</span><br><span class="line">    temp[i,j] = i+j</span><br><span class="line"><span class="comment"># 多进程处理的耗时的算法函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">multiprocess</span>(<span class="params">i,j</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;子进程开始执行&gt;&gt;&gt; pid=&#123;&#125;,ppid=&#123;&#125;,编号&#123;&#125;&quot;</span>.<span class="built_in">format</span>(os.getpid(), os.getppid(), i))</span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> (i,j)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    time_start = time.time()</span><br><span class="line">    MultiP = multiprocessing.Pool(<span class="number">2</span>)  <span class="comment"># 多进程</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;主进程开始执行&gt;&gt;&gt; parent_pid=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(os.getpid()))</span><br><span class="line">            MultiP.apply_async(multiprocess, args=(i, j), callback=mycallback)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 关闭进程池，停止接受其它进程</span></span><br><span class="line">    MultiP.close()</span><br><span class="line">    <span class="comment"># 阻塞进程 等待进程池中的所有进程执行完毕，必须在close()之后调用</span></span><br><span class="line">    MultiP.join()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;主进程终止&quot;</span>)</span><br><span class="line">    time_end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;totally cost&#x27;</span>, time_end - time_start)</span><br><span class="line">    <span class="built_in">print</span>(temp)</span><br></pre></td></tr></table></figure>
<h5><span id="异步非阻塞式">异步非阻塞式：</span></h5>
<p>正因为是异步非阻塞式的，不用等待当前运行的子进程执行完毕，随时根据系统调度来进行进程切换。基本上主进程和三个子进程，四个进程是同时运行的。</p>
<h3><span id="22python中多进程读取excel文件-异步读取返回值管理">2.2
python中多进程读取excel文件 - 异步读取，返回值管理</span></h3>
<blockquote>
<p>https://blog.csdn.net/hynkoala/article/details/93895004</p>
</blockquote>
<p>首先准备:当前文件上级目录下有个excels目录，目录里存在15份.xls文件，每个文件1000条数据，需要通过多进程对这些文件读取为pandas的dataframe格式</p>
<blockquote>
<p>进程池最大数量设为10：6.580815315246582</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># @datetime:6/26/0026</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;通过多进程加速读取excel的测试&quot;&quot;&quot;</span></span><br><span class="line">__author__ = <span class="string">&quot;hanyaning@deri.energy&quot;</span></span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> service <span class="keyword">import</span> logger</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"></span><br><span class="line">logger = logger.MyLogger(<span class="string">&quot;multi_process&quot;</span>).getLogger()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getExcelData</span>(<span class="params">path</span>):</span><br><span class="line">    logger.info(<span class="string">&quot;开始读取excel，当前进程pid：&quot;</span> + <span class="built_in">str</span>(os.getpid()))</span><br><span class="line">    data = pd.DataFrame()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">        <span class="keyword">raise</span> FileNotFoundError()</span><br><span class="line">    <span class="keyword">if</span> os.path.isfile(path):</span><br><span class="line">        logger.info(<span class="string">&quot;读取Excel文件完毕，当前进程pid：&quot;</span> + <span class="built_in">str</span>(os.getpid()))</span><br><span class="line">    <span class="keyword">return</span> data.append(pd.read_excel(path, skiprows=<span class="number">1</span>, skipfooter=<span class="number">1</span>), sort=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    excel_path = os.path.join(os.getcwd(), <span class="string">&quot;../excels&quot;</span>)</span><br><span class="line">    xls_names = [x <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(excel_path) <span class="keyword">if</span> x.endswith(<span class="string">&quot;.xls&quot;</span>)]</span><br><span class="line">    startTime = time.time()</span><br><span class="line"></span><br><span class="line">    p_list = []</span><br><span class="line">    <span class="comment"># 使用进程池Pool</span></span><br><span class="line">    pool = Pool(processes=<span class="number">10</span>)</span><br><span class="line">    pool_data_list = []</span><br><span class="line">    data = pd.DataFrame()</span><br><span class="line">    <span class="keyword">for</span> file_name <span class="keyword">in</span> xls_names:</span><br><span class="line">        <span class="comment"># 需要注意不能直接在这里调用get方法获取数据,原因是apply_async后面 get()等待线程运行结束才会下一个,这里多进程会变成阻塞执行</span></span><br><span class="line">        pool_data_list.append(pool.apply_async(getExcelData, (os.path.join(excel_path, file_name))))</span><br><span class="line">    pool.close()</span><br><span class="line">    <span class="comment"># 需要阻塞以下，等所有子进程执行完毕后主线程才继续执行</span></span><br><span class="line">    pool.join()</span><br><span class="line">    <span class="keyword">for</span> pool_data <span class="keyword">in</span> pool_data_list:</span><br><span class="line">        <span class="comment"># 这里再使用get()方法可以获取返回值</span></span><br><span class="line">        data = data.append(pool_data.get())</span><br><span class="line">    endTime = time.time()</span><br><span class="line">    <span class="built_in">print</span>(endTime - startTime)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(data))</span><br></pre></td></tr></table></figure>
<h4><span id="单进程读取对照测试">单进程读取对照测试</span></h4>
<blockquote>
<p>耗时：12.019948959350586</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ExcelReader</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path, file_suffix=<span class="string">&quot;.xls&quot;</span></span>):</span><br><span class="line">        self.path = path</span><br><span class="line">        self.file_suffix = file_suffix</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">getData</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(self.path):</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError()</span><br><span class="line">        data = pd.DataFrame()</span><br><span class="line">        <span class="keyword">if</span> os.path.isdir(self.path):</span><br><span class="line">            xls_names = [x <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(self.path) <span class="keyword">if</span> x.endswith(self.file_suffix)]</span><br><span class="line">            logger.info(<span class="string">&quot;开始&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> xls_name <span class="keyword">in</span> xls_names:</span><br><span class="line">                df = pd.read_excel(os.path.join(self.path, xls_name), skiprows=<span class="number">1</span>, skipfooter=<span class="number">1</span>)</span><br><span class="line">                data = data.append(df, sort=<span class="literal">False</span>)</span><br><span class="line">            logger.info(<span class="string">&quot;读取Excel文件完毕，共读取&quot;</span> + <span class="built_in">str</span>(xls_names.__len__()) + <span class="string">&quot;个文件&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    start = time.time()</span><br><span class="line">    reader = ExcelReader(os.path.join(os.getcwd(), <span class="string">&quot;../excels&quot;</span>))</span><br><span class="line">    data = reader.getData()</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="built_in">print</span>(end - start)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(data))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>流程的Python</category>
      </categories>
  </entry>
  <entry>
    <title>Python（1）《流畅的Python》</title>
    <url>/posts/PVPCFM/</url>
    <content><![CDATA[<h1><span id="流畅的python阅读笔记">《流畅的python》阅读笔记</span></h1>
<p>《流畅的python》是一本适合python进阶的书,
里面介绍的基本都是高级的python用法. 对于初学python的人来说,
基础大概也就够用了, 但往往由于够用让他们忘了深入, 去精通.
我们希望全面了解这个语言的能力边界,
可能一些高级的特性并不能马上掌握使用, 因此这本书是工作之余,
还有余力的人来阅读, 我这边就将其有用, 精妙的进阶内容整理出来.</p>
<p><strong>笔记链接</strong>：https://juejin.cn/post/6844903503987474446</p>
<figure>
<img src="../../../../Desktop/《流畅的python》阅读笔记.png" alt="《流畅的python》阅读笔记">
<figcaption aria-hidden="true">《流畅的python》阅读笔记</figcaption>
</figure>
<h2><span id="第0章基础知识">第0章：基础知识</span></h2>
<h4><span id="迭代器">迭代器：</span></h4>
<h2><span id="第一章-python数据模型">第一章: python数据模型</span></h2>
<ul>
<li>https://www.cnblogs.com/chenhuabin/p/13752770.html</li>
<li><a href="https://zhuanlan.zhihu.com/p/344951719">Python：实例讲解Python中的魔法函数（高级语法)</a></li>
<li><strong>更多的特殊方法</strong>: <a href="https://link.juejin.cn/?target=https%3A%2F%2Fdocs.python.org%2F3%2Freference%2Fdatamodel.html">docs.python.org/3/reference…</a></li>
</ul>
<p>常用魔法函数： <code>__init__</code> , <code>__lt__</code>,
<code>__len__</code>，<code>__str__</code> 与 <code>__repr__</code> ，
<code>__call__</code> <code>__iter__</code></p>
<p>这部分主要介绍了python的<strong>魔术方法</strong>,
它们经常是两个下划线包围来命名的(比如 <code>__init__</code> ,
<code>__lt__</code>, <code>__len__</code> ).
<strong>这些特殊方法是为了被python解释器调用的,
这些方法会注册到他们的类型中方法集合中</strong>,
相当于为cpython提供抄近路. 这些方法的速度也比普通方法要快,
当然在自己不清楚这些魔术方法的用途时, 不要随意添加.</p>
<p>关于字符串的表现形式是两种, <code>__str__</code> 与
<code>__repr__</code> . python的内置函数 <code>repr</code> 就是通过
<code>__repr__</code> 这个特殊方法来得到一个对象的字符串表示形式.
这个在交互模式下比较常用, 如果没有实现 <code>__repr__</code> ,
当控制台打印一个对象时往往是 <code>&lt;A object at 0x000&gt;</code> . 而
<code>__str__</code> 则是 <code>str()</code> 函数时使用的, 或是在
<code>print</code> 函数打印一个对象的时候才被调用, 终端用户友好.</p>
<p>两者还有一个区别, 在字符串格式化时, <code>"%s"</code> 对应了
<code>__str__</code> . 而 <code>"%r"</code> 对应了
<code>__repr__</code>. <code>__str__</code> 和 <code>__repr__</code>
在使用上比较推荐的是，前者是给终端用户看，而后者则更方便我们调试和记录日志.</p>
<ul>
<li>字符串表示：<code>__str__</code>、<code>__repr__</code></li>
<li>集合、序列相关：<code>__len__</code>、<code>__getitem__</code>、<code>__setitem__</code>、<code>__delitem__</code>、<code>__contains__</code></li>
<li>迭代相关：<code>__iter__</code>、<code>__next__</code></li>
<li>可调用：<code>__call__</code></li>
<li>with上下文管理器：<code>__enter__</code>、<code>__exit__</code></li>
<li>属性相关：<code>__getattr__</code>、<code>__setattr__</code>、<code>__getattribute__</code></li>
</ul>
<p><img src="https://pic4.zhimg.com/80/v2-82a512ae404403ff00ed790d8f2569f7_1440w.jpg" alt="img" style="zoom:75%;"></p>
<h2><span id="第二章-序列构成的数组">第二章: 序列构成的数组</span></h2>
<p>这部分主要是介绍<strong>序列</strong>,
着重介绍<strong>数组</strong>和<strong>元组</strong>的一些高级用法.</p>
<p>序列按照容纳数据的类型可以分为:</p>
<ul>
<li><strong>容器序列</strong>: list、tuple 和 collections.deque
这些序列能<strong>存放不同类型的数据</strong>。</li>
<li><strong>扁平序列</strong>: str、bytes、bytearray、memoryview 和
array.array，这类<strong>序列只能容纳一种类型</strong>。</li>
</ul>
<p>如果按照是否能被修改可以分为:</p>
<ul>
<li><strong>可变序列</strong>:
list、bytearray、array.array、collections.deque 和 memoryview</li>
<li><strong>不可变序列</strong>: tuple、str 和 bytes</li>
</ul>
<h3><span id="列表推导">列表推导</span></h3>
<p><strong>列表推导是构建列表的快捷方式,
可读性更好且效率更高.</strong></p>
<p>例如, 把<strong>一个字符串变成unicode的码</strong>位列表的例子,
一般:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">symbols = <span class="string">&#x27;$¢£¥€¤&#x27;</span></span><br><span class="line">codes = []</span><br><span class="line"><span class="keyword">for</span> symbol <span class="keyword">in</span> symbols:</span><br><span class="line">    codes.append(<span class="built_in">ord</span>(symbol))复制代码</span><br></pre></td></tr></table></figure>
<p>使用列表推导:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">symbols = <span class="string">&#x27;$¢£¥€¤&#x27;</span></span><br><span class="line">codes = [<span class="built_in">ord</span>(symbol) <span class="keyword">for</span> symbol <span class="keyword">in</span> symbols]复制代码</span><br></pre></td></tr></table></figure>
<p>能用列表推导来创建一个列表, 尽量使用推导, 并且保持它简短.</p>
<h3><span id="笛卡尔积与生成器表达式">笛卡尔积与生成器表达式</span></h3>
<p>生成器表达式是能逐个产出元素, 节省内存. 例如:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>colors = [<span class="string">&#x27;black&#x27;</span>, <span class="string">&#x27;white&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sizes = [<span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;M&#x27;</span>, <span class="string">&#x27;L&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> tshirt <span class="keyword">in</span> (<span class="string">&#x27;%s %s&#x27;</span> % (c, s) <span class="keyword">for</span> c <span class="keyword">in</span> colors <span class="keyword">for</span> s <span class="keyword">in</span> sizes):</span><br><span class="line"><span class="meta">... </span><span class="built_in">print</span>(tshirt)复制代码</span><br></pre></td></tr></table></figure>
<p>实例中列表元素比较少, 如果换成两个各有1000个元素的列表,
显然这样组合的笛卡尔积是一个含有100万元素的列表, 内存将会占用很大,
而是用生成器表达式就可以帮忙省掉for循环的开销.</p>
<h3><span id="具名元组">具名元组</span></h3>
<p>元组经常被作为 <code>不可变列表</code> 的代表.
经常只要数字索引获取元素, 但其实它还可以给元素命名:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>City = namedtuple(<span class="string">&#x27;City&#x27;</span>, <span class="string">&#x27;name country population coordinates&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokyo = City(<span class="string">&#x27;Tokyo&#x27;</span>, <span class="string">&#x27;JP&#x27;</span>, <span class="number">36.933</span>, (<span class="number">35.689722</span>, <span class="number">139.691667</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokyo</span><br><span class="line">City(name=<span class="string">&#x27;Tokyo&#x27;</span>, country=<span class="string">&#x27;JP&#x27;</span>, population=<span class="number">36.933</span>, coordinates=(<span class="number">35.689722</span>,</span><br><span class="line"><span class="number">139.691667</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokyo.population</span><br><span class="line"><span class="number">36.933</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokyo.coordinates</span><br><span class="line">(<span class="number">35.689722</span>, <span class="number">139.691667</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tokyo[<span class="number">1</span>]</span><br><span class="line"><span class="string">&#x27;JP&#x27;</span></span><br></pre></td></tr></table></figure>
<h3><span id="切片">切片</span></h3>
<p>列表中是以0作为第一个元素的下标, 切片可以根据下标提取某一个片段.</p>
<p>用 <code>s[a:b:c]</code> 的形式对 <code>s</code> 在 <code>a</code> 和
<code>b</code> 之间以 <code>c</code> 为间隔取值。<code>c</code>
的值还可以为负, 负值意味着反向取值.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = <span class="string">&#x27;bicycle&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s[::<span class="number">3</span>]</span><br><span class="line"><span class="string">&#x27;bye&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s[::-<span class="number">1</span>]</span><br><span class="line"><span class="string">&#x27;elcycib&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s[::-<span class="number">2</span>]</span><br><span class="line"><span class="string">&#x27;eccb&#x27;</span></span><br></pre></td></tr></table></figure>
<h2><span id="第三章-字典和集合">第三章: 字典和集合</span></h2>
<p><strong><code>dict</code> 类型不但在各种程序里广泛使用, 它也是
<code>Python</code> 语言的基石</strong>. 正是因为 <code>dict</code>
类型的重要, <code>Python</code> 对其的实现做了高度的优化,
其中最重要的原因就是背后的「散列表」 set（集合）和dict一样,
其实现基础也是依赖于散列表.</p>
<p>散列表也叫哈希表, 对于dict类型, 它的key必须是可哈希的数据类型.
什么是可哈希的数据类型呢, 它的官方解释是:</p>
<blockquote>
<p><strong>如果一个对象是可散列的，那么在这个对象的生命周期中，它的散列值是不变</strong></p>
</blockquote>
<p>的，而且这个对象需要实现 <code>__hash__()</code>
方法。另外可散列对象还要有 <code>__qe__()</code>
方法，这样才能跟其他键做比较。如果两个可散列对象是相等的，那么它们的散列值一定是一样的……</p>
<p><code>str</code>, <code>bytes</code>, <code>frozenset</code> 和
<code>数值</code> 都是可散列类型.</p>
<h3><span id="字典推导式">字典推导式</span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DIAL_CODE = [</span><br><span class="line">    (<span class="number">86</span>, <span class="string">&#x27;China&#x27;</span>),</span><br><span class="line">    (<span class="number">91</span>, <span class="string">&#x27;India&#x27;</span>),</span><br><span class="line">    (<span class="number">7</span>, <span class="string">&#x27;Russia&#x27;</span>),</span><br><span class="line">    (<span class="number">81</span>, <span class="string">&#x27;Japan&#x27;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment">### 利用字典推导快速生成字典</span></span><br><span class="line">country_code = &#123;country: code <span class="keyword">for</span> code, country <span class="keyword">in</span> DIAL_CODE&#125;</span><br><span class="line"><span class="built_in">print</span>(country_code)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">OUT:</span></span><br><span class="line"><span class="string">&#123;&#x27;China&#x27;: 86, &#x27;India&#x27;: 91, &#x27;Russia&#x27;: 7, &#x27;Japan&#x27;: 81&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span>复制代码</span><br></pre></td></tr></table></figure>
<h3><span id="defaultdict处理找不到的键的一个选择">defaultdict：处理找不到的键的一个选择</span></h3>
<p>当某个键不在映射里, 我们也希望也能得到一个默认值. 这就是
<code>defaultdict</code> , 它是 <code>dict</code> 的子类, 并实现了
<code>__missing__</code> 方法.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line">index = collections.defaultdict(<span class="built_in">list</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> nums:</span><br><span class="line">    key = item % <span class="number">2</span></span><br><span class="line">    index[key].append(item)</span><br></pre></td></tr></table></figure>
<h3><span id="字典的变种">字典的变种</span></h3>
<p>标准库里 <code>collections</code> 模块中，除了
<code>defaultdict</code> 之外的不同映射类型:</p>
<ul>
<li><strong>OrderDict</strong>：
这个类型在添加键的时候，会保存顺序，因此键的迭代顺序总是一致的</li>
<li><strong>ChainMap</strong>：
该类型可以容纳数个不同的映射对像，在进行键的查找时，这些对象会被当做一个整体逐个查找，直到键被找到为止
<code>pylookup = ChainMap(locals(), globals())</code></li>
<li><strong>Counter</strong>：
这个映射类型会给键准备一个整数技术器，每次更行一个键的时候都会增加这个计数器，所以这个类型可以用来给散列表对象计数，或者当成多重集来用.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line">ct = collections.Counter(<span class="string">&#x27;abracadabra&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(ct)   <span class="comment"># Counter(&#123;&#x27;a&#x27;: 5, &#x27;b&#x27;: 2, &#x27;r&#x27;: 2, &#x27;c&#x27;: 1, &#x27;d&#x27;: 1&#125;)</span></span><br><span class="line">ct.update(<span class="string">&#x27;aaaaazzz&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(ct)   <span class="comment"># Counter(&#123;&#x27;a&#x27;: 10, &#x27;z&#x27;: 3, &#x27;b&#x27;: 2, &#x27;r&#x27;: 2, &#x27;c&#x27;: 1, &#x27;d&#x27;: 1&#125;)</span></span><br><span class="line"><span class="built_in">print</span>(ct.most_common(<span class="number">2</span>)) <span class="comment"># [(&#x27;a&#x27;, 10), (&#x27;z&#x27;, 3)]复制代码</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>UserDict</strong>: 这个类其实就是把标准 dict 用纯 Python
又实现了一遍</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StrKeyDict</span>(collections.UserDict):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__missing__</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(key, <span class="built_in">str</span>):</span><br><span class="line">            <span class="keyword">raise</span> KeyError(key)</span><br><span class="line">        <span class="keyword">return</span> self[<span class="built_in">str</span>(key)]</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__contains__</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">str</span>(key) <span class="keyword">in</span> self.data</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__setitem__</span>(<span class="params">self, key, item</span>):</span><br><span class="line">        self.data[<span class="built_in">str</span>(key)] = item</span><br></pre></td></tr></table></figure>
<h3><span id="不可变映射类型mappingproxytype">不可变映射类型【MappingProxyType】</span></h3>
<p>说到不可变, 第一想到的肯定是元组, 但是对于字典来说,
要将key和value的对应关系变成不可变, <code>types</code> 模块的
<code>MappingProxyType</code> 可以做到:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> types <span class="keyword">import</span> MappingProxyType</span><br><span class="line">d = &#123;<span class="number">1</span>:<span class="string">&#x27;A&#x27;</span>&#125;</span><br><span class="line">d_proxy = MappingProxyType(d)</span><br><span class="line">d_proxy[<span class="number">1</span>]=<span class="string">&#x27;B&#x27;</span> <span class="comment"># TypeError: &#x27;mappingproxy&#x27; object does not support item assignment</span></span><br><span class="line"></span><br><span class="line">d[<span class="number">2</span>] = <span class="string">&#x27;B&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(d_proxy) <span class="comment"># mappingproxy(&#123;1: &#x27;A&#x27;, 2: &#x27;B&#x27;&#125;)复制代码</span></span><br></pre></td></tr></table></figure>
<p><code>d_proxy</code> 是动态的, 也就是说对 <code>d</code>
所做的任何改动都会反馈到它上面.</p>
<h3><span id="集合论本身不可散列元素必须可散列">集合论：本身不可散列，元素必须可散列</span></h3>
<p>集合的本质是许多唯一对象的聚集. 因此, <strong>集合可以用于去重.
集合中的元素必须是可散列的</strong>, 但是 <code>set</code>
本身是不可散列的, 而 <code>frozenset</code> 本身可以散列.</p>
<p>集合具有唯一性, 与此同时, 集合还实现了很多基础的中缀运算符.
给定两个集合 a 和 b, <code>a | b</code> 返 回的是它们的合集,
<code>a &amp; b</code> 得到的是交集, 而 <code>a - b</code>
得到的是差集.</p>
<p>合理的利用这些特性, 不仅能减少代码的数量, 更能增加运行效率.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 集合的创建</span></span><br><span class="line">s = <span class="built_in">set</span>([<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># 空集合</span></span><br><span class="line">s = <span class="built_in">set</span>()</span><br><span class="line"><span class="comment"># 集合字面量</span></span><br><span class="line">s = &#123;<span class="number">1</span>, <span class="number">2</span>&#125;</span><br><span class="line"><span class="comment"># 集合推导</span></span><br><span class="line">s = &#123;<span class="built_in">chr</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">23</span>, <span class="number">45</span>)&#125;</span><br></pre></td></tr></table></figure>
<h2><span id="第四章-文本和字节序列">第四章: 文本和字节序列</span></h2>
<p>本章讨论了<strong>文本字符串</strong>和<strong>字节序列</strong>,
以及一些编码上的转换. 本章讨论的 <code>str</code> 指的是python3下的.</p>
<h3><span id="字符问题">字符问题</span></h3>
<p>字符串是个比较简单的概念: 一个字符串是一个字符序列. 但是关于
<code>"字符"</code> 的定义却五花八门, 其中, <code>"字符"</code>
的最佳定义是 <code>Unicode 字符</code> . 因此, python3中的
<code>str</code> 对象中获得的元素就是 unicode 字符.</p>
<p>把码位转换成字节序列的过程就是 <code>编码</code>,
把字节序列转换成码位的过程就是 <code>编码</code> :</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>s = <span class="string">&#x27;café&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(s)</span><br><span class="line"><span class="number">4</span> </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = s.encode(<span class="string">&#x27;utf8&#x27;</span>) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line"><span class="string">b&#x27;caf\xc3\xa9&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(b)</span><br><span class="line"><span class="number">5</span> </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b.decode(<span class="string">&#x27;utf8&#x27;</span>) <span class="comment">#&#x27;café复制代码</span></span><br></pre></td></tr></table></figure>
<p><strong>码位可以认为是人类可读的文本</strong>,
而字符序列则可以认为是对机器更友好. 所以要区分 <code>.decode()</code> 和
<code>.encode()</code> 也很简单.
从字节序列到人类能理解的文本就是解码(decode).
而把人类能理解的变成人类不好理解的字节序列就是编码(encode).</p>
<h3><span id="字节概要">字节概要</span></h3>
<p>python3有两种字节序列, 不可变的 <code>bytes</code> 类型和可变的
<code>bytearray</code> 类型. 字节序列中的各个元素都是介于
<code>[0, 255]</code> 之间的整数.</p>
<h3><span id="处理编码问题">处理编码问题</span></h3>
<p>python自带了超过100中编解码器. 每个编解码器都有一个名称,
甚至有的会有一些别名, 如 <code>utf_8</code> 就有 <code>utf8</code>,
<code>utf-8</code>, <code>U8</code> 这些别名.</p>
<p>如果字符序列和预期不符, 在进行解码或编码时容易抛出
<code>Unicode*Error</code> 的异常.
造成这种错误是因为目标编码中没有定义某个字符(没有定义某个码位对应的字符),
这里说说解决这类问题的方式.</p>
<ul>
<li>使用python3, python3可以避免95%的字符问题.</li>
<li>主流编码尝试下: latin1, cp1252, cp437, gb2312, utf-8, utf-16le</li>
<li>留意BOM头部 <code>b'\xff\xfe'</code> ,
UTF-16编码的序列开头也会有这几个额外字节.</li>
<li>找出序列的编码, 建议使用 <code>codecs</code> 模块</li>
</ul>
<h3><span id="规范化unicode字符串">规范化unicode字符串</span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s1 = <span class="string">&#x27;café&#x27;</span></span><br><span class="line">s2 = <span class="string">&#x27;caf\u00e9&#x27;</span>复制代码</span><br></pre></td></tr></table></figure>
<p>这两行代码完全等价. 而有一种是要避免的是, 在Unicode标准中
<code>é</code> 和 <code>e\u0301</code> 这样的序列叫
<code>"标准等价物"</code>.
这种情况用NFC使用最少的码位构成等价的字符串:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>s1 = <span class="string">&#x27;café&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s2 = <span class="string">&#x27;cafe\u0301&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s1, s2</span><br><span class="line">(<span class="string">&#x27;café&#x27;</span>, <span class="string">&#x27;café&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(s1), <span class="built_in">len</span>(s2)</span><br><span class="line">(<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s1  s2</span><br><span class="line"><span class="literal">False</span>复制代码</span><br></pre></td></tr></table></figure>
<p>改进后:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> unicodedata <span class="keyword">import</span> normalize</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s1 = <span class="string">&#x27;café&#x27;</span> <span class="comment"># 把&quot;e&quot;和重音符组合在一起</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>s2 = <span class="string">&#x27;cafe\u0301&#x27;</span> <span class="comment"># 分解成&quot;e&quot;和重音符</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(s1), <span class="built_in">len</span>(s2)</span><br><span class="line">(<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(normalize(<span class="string">&#x27;NFC&#x27;</span>, s1)), <span class="built_in">len</span>(normalize(<span class="string">&#x27;NFC&#x27;</span>, s2))</span><br><span class="line">(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(normalize(<span class="string">&#x27;NFD&#x27;</span>, s1)), <span class="built_in">len</span>(normalize(<span class="string">&#x27;NFD&#x27;</span>, s2))</span><br><span class="line">(<span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>normalize(<span class="string">&#x27;NFC&#x27;</span>, s1)  normalize(<span class="string">&#x27;NFC&#x27;</span>, s2)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>normalize(<span class="string">&#x27;NFD&#x27;</span>, s1)  normalize(<span class="string">&#x27;NFD&#x27;</span>, s2)</span><br><span class="line"><span class="literal">True</span>复制代码</span><br></pre></td></tr></table></figure>
<h3><span id="unicode文本排序">unicode文本排序</span></h3>
<p>对于字符串来说, 比较的码位. 所以在非 ascii 字符时,
得到的结果可能会不尽人意.</p>
<h2><span id="第五章-一等函数">第五章: 一等函数</span></h2>
<p>在python中, 函数是一等对象. 编程语言把 <code>"一等对象"</code>
定义为满足下列条件:</p>
<ul>
<li>在运行时创建</li>
<li>能赋值给变量或数据结构中的元素</li>
<li>能作为参数传给函数</li>
<li>能作为函数的返回结果</li>
</ul>
<p>在python中, 整数, 字符串, 列表, 字典都是一等对象.</p>
<h3><span id="51-把函数视作对象">5.1 把函数视作对象</span></h3>
<p>Python即可以函数式编程，也可以面向对象编程. 这里我们创建了一个函数,
然后读取它的 <code>__doc__</code> 属性, 并且确定函数对象其实是
<code>function</code> 类的实例:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">factorial</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    return n</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> n &lt; <span class="number">2</span> <span class="keyword">else</span> n * factorial(n-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(factorial.__doc__)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(factorial))</span><br><span class="line"><span class="built_in">print</span>(factorial(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">OUT</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return n</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;class &#x27;function&#x27;&gt;</span></span><br><span class="line"><span class="string">6</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span>复制代码</span><br></pre></td></tr></table></figure>
<h3><span id="52-高阶函数">5.2 高阶函数</span></h3>
<p><strong>高阶函数就是接受函数作为参数,
或者把函数作为返回结果的函数</strong>. 如 <code>map</code>,
<code>filter</code> , <code>reduce</code> 等.</p>
<p>比如调用 <code>sorted</code> 时, 将 <code>len</code>
作为参数传递:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fruits = [<span class="string">&#x27;strawberry&#x27;</span>, <span class="string">&#x27;fig&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;cherry&#x27;</span>, <span class="string">&#x27;raspberry&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>]</span><br><span class="line"><span class="built_in">sorted</span>(fruits, key=<span class="built_in">len</span>)</span><br><span class="line"><span class="comment"># [&#x27;fig&#x27;, &#x27;apple&#x27;, &#x27;cherry&#x27;, &#x27;banana&#x27;, &#x27;raspberry&#x27;, &#x27;strawberry&#x27;]复制代码</span></span><br></pre></td></tr></table></figure>
<h3><span id="53-匿名函数">5.3 匿名函数</span></h3>
<p><code>lambda</code> 关键字是用来创建匿名函数. 匿名函数一些限制,
匿名函数的定义体只能使用纯表达式. 换句话说, <code>lambda</code>
函数内不能赋值, 也不能使用while和try等语句.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fruits = [<span class="string">&#x27;strawberry&#x27;</span>, <span class="string">&#x27;fig&#x27;</span>, <span class="string">&#x27;apple&#x27;</span>, <span class="string">&#x27;cherry&#x27;</span>, <span class="string">&#x27;raspberry&#x27;</span>, <span class="string">&#x27;banana&#x27;</span>]</span><br><span class="line"><span class="built_in">sorted</span>(fruits, key=<span class="keyword">lambda</span> word: word[::-<span class="number">1</span>])</span><br><span class="line"><span class="comment"># [&#x27;banana&#x27;, &#x27;apple&#x27;, &#x27;fig&#x27;, &#x27;raspberry&#x27;, &#x27;strawberry&#x27;, &#x27;cherry&#x27;]复制代码</span></span><br></pre></td></tr></table></figure>
<h3><span id="54-可调用对象">5.4 可调用对象</span></h3>
<p>除了用户定义的函数, 调用运算符即 <code>()</code>
还可以应用到其他对象上. 如果像判断对象能否被调用, 可以使用内置的
<code>callable()</code> 函数进行判断.
python的数据模型中有7种可是可以被调用的:</p>
<ul>
<li><strong>用户定义的函数</strong>: 使用def语句或lambda表达式创建</li>
<li><strong>内置函数</strong>:如len</li>
<li><strong>内置方法</strong>:如dict.get</li>
<li><strong>方法</strong>:在类定义体中的函数</li>
<li><strong>类</strong></li>
<li><strong>类的实例</strong>: 如果类定义了 <code>__call__</code> ,
那么它的实例可以作为函数调用.</li>
<li><strong>生成器函数</strong>: 使用 <code>yield</code>
关键字的函数或方法.</li>
</ul>
<h3><span id="55-从定位参数到仅限关键字参数">5.5 从定位参数到仅限关键字参数</span></h3>
<p>就是可变参数和关键字参数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">name, age, *args, **kwargs</span>):</span><br><span class="line">    <span class="keyword">pass</span>复制代码</span><br></pre></td></tr></table></figure>
<p>其中 <code>*args</code> 和 <code>**kwargs</code> 都是可迭代对象,
展开后映射到单个参数. <strong>args是个元组, kwargs是字典</strong>.</p>
<h2><span id="第六章-python设计模式">第六章 Python设计模式</span></h2>
<p>https://github.com/faif/python-patterns</p>
<p>https://refactoringguru.cn/design-patterns/python</p>
<p><strong>设计模式是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易地被他人理解、保证代码可靠性。</strong></p>
<h2><span id="第七章-函数装饰器和闭包">第七章: 函数装饰器和闭包</span></h2>
<blockquote>
<p>函数装饰器用于在源码中“标记”函数，以某种方式增强函数的行为。这是一项强大的功能，但是若想掌握，必须理解闭包。</p>
</blockquote>
<p>修饰器和闭包经常在一起讨论,
因为<strong>修饰器就是闭包的一种形式</strong>.
闭包还是<strong>回调式异步编程</strong>和<strong>函数式编程风格</strong>的基础.</p>
<h3><span id="装饰器基础知识">装饰器基础知识</span></h3>
<p><strong>装饰器</strong>是<strong>可调用的对象</strong>,
其<strong>参数是另一个函数</strong>(被装饰的函数).
装饰器可能会处理被装饰的函数, 然后把它返回,
或者将其替换成<strong>另一个函数或可调用对象</strong>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@decorate</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">target</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;running target()&#x27;</span>)复制代码</span><br></pre></td></tr></table></figure>
<p>这种写法与下面写法完全等价:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">target</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;running target()&#x27;</span>)</span><br><span class="line">target = decorate(target)</span><br></pre></td></tr></table></figure>
<p>装饰器是语法糖, 它其实是将函数作为参数让其他函数处理.
装饰器有两大特征:</p>
<ul>
<li><strong>把被装饰的函数替换成其他函数</strong></li>
<li><strong>装饰器在加载模块时立即执行</strong></li>
</ul>
<p>要理解立即执行看下等价的代码就知道了,
<code>target = decorate(target)</code> 这句调用了函数.
一般情况下装饰函数都会将某个函数作为返回值.</p>
<h3><span id="变量作用域规则">变量作用域规则</span></h3>
<p>要理解装饰器中变量的作用域, 应该要理解闭包,
我觉得书里将闭包和作用域的顺序换一下比较好. <strong>在python中,
一个变量的查找顺序是 <code>LEGB</code> (L：Local 局部环境，E：Enclosing
闭包，G：Global 全局，B：Built-in 内置).</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">base = <span class="number">20</span> <span class="comment"># 3</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_compare</span>():</span><br><span class="line">    base = <span class="number">10</span> <span class="comment"># 2</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">real_compare</span>(<span class="params">value</span>):</span><br><span class="line">    		base = <span class="number">5</span> <span class="comment"># 1</span></span><br><span class="line">        <span class="keyword">return</span> value &gt; base</span><br><span class="line">    <span class="keyword">return</span> real_compare</span><br><span class="line">    </span><br><span class="line">compare_10 = get_compare()</span><br><span class="line"><span class="built_in">print</span>(compare_10(<span class="number">5</span>))复制代码</span><br></pre></td></tr></table></figure>
<p>在闭包的函数 <code>real_compare</code> 中, 使用的变量
<code>base</code> 其实是 <code>base = 10</code> 的.
因为base这个变量在闭包中就能命中, 而不需要去 <code>global</code>
中获取.</p>
<h3><span id="闭包">闭包</span></h3>
<p>闭包其实挺好理解的, 当匿名函数出现的时候, 才使得这部分难以掌握.
简单简短的解释闭包就是:</p>
<p><strong>名字空间与函数捆绑后的结果被称为一个闭包(closure).</strong></p>
<p>这个名字空间就是 <code>LEGB</code> 中的 <code>E</code> .
所以闭包不仅仅是将函数作为返回值.
而是将名字空间和函数捆绑后作为返回值的. 多少人忘了理解这个
<code>"捆绑"</code> , 不知道变量最终取的哪和哪啊. 哎.</p>
<h3><span id="标准库中的装饰器">标准库中的装饰器</span></h3>
<p>python内置了三个用于装饰方法的函数: <code>property</code> 、
<code>classmethod</code> 和 <code>staticmethod</code> .
这些是用来丰富类的.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">age</span>():</span><br><span class="line">        <span class="keyword">return</span> <span class="number">12</span></span><br></pre></td></tr></table></figure>
<h2><span id="第八章对象引用-可变性和垃圾回收">第八章:
对象引用、可变性和垃圾回收</span></h2>
<h3><span id="变量不是盒子">变量不是盒子</span></h3>
<p>很多人把变量理解为盒子, 要存什么数据往盒子里扔就行了.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">b = a </span><br><span class="line">a.append(<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(b) <span class="comment"># [1, 2, 3, 4]复制代码</span></span><br></pre></td></tr></table></figure>
<p>变量 <code>a</code> 和 <code>b</code> 引用同一个列表,
而不是那个列表的副本.
因此赋值语句应该理解为将变量和值进行引用的关系而已.</p>
<h3><span id="标识-相等性和别名">标识、相等性和别名</span></h3>
<p><strong>要知道变量a和b是否是同一个值的引用,</strong> 可以用
<code>is</code> 来进行判断:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = b = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a <span class="keyword">is</span> b</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x <span class="keyword">is</span> c</span><br><span class="line"><span class="literal">False</span>复制代码</span><br></pre></td></tr></table></figure>
<p>如果两个变量都是指向同一个对象, 我们通常会说变量是另一个变量的
<code>别名</code> .</p>
<p><strong>在 和 is 之间选择</strong> 运算符
<code>是用来判断两个对象值是否相等(注意是**对象值**). 而 `is` 则是用于判断两个变量是否指向同一个对象, 或者说判断变量是不是两一个的别名, is 并不关心对象的值. 从使用上,</code>
使用比较多, 而 <code>is</code> 的执行速度比较快.</p>
<h3><span id="默认做浅复制">默认做浅复制</span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">l1 = [<span class="number">3</span>, [<span class="number">55</span>, <span class="number">44</span>], (<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)]</span><br><span class="line"></span><br><span class="line">l2 = <span class="built_in">list</span>(l1) <span class="comment"># 通过构造方法进行复制 </span></span><br><span class="line">l2 = l1[:]  <span class="comment">#也可以这样想写</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l2  l1</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>l2 <span class="keyword">is</span> l1</span><br><span class="line"><span class="literal">False</span>复制代码</span><br></pre></td></tr></table></figure>
<p>尽管 l2 是 l1 的副本, 但是复制的过程是先复制
(即复制了<strong>最外层容器</strong>，<strong>副本中的元素是源容器中元素的引用</strong>)
. 因此在操作 l2[1] 时, l1[1] 也会跟着变化.
而如果列表中的所有元素是不可变的, 那么就没有这样的问题,
而且还能节省内存. 但是, 如果有可变元素存在,
就可能造成意想不到的问题.</p>
<p>python标准库中提供了两个工具 <code>copy</code> 和
<code>deepcopy</code> .
分别用于<strong>浅拷贝</strong>与<strong>深拷贝</strong>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line">l1 = [<span class="number">3</span>, [<span class="number">55</span>, <span class="number">44</span>], (<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)]</span><br><span class="line"></span><br><span class="line">l2 = copy.copy(l1)</span><br><span class="line">l2 = copy.deepcopy(l1)复制代码</span><br></pre></td></tr></table></figure>
<h3><span id="函数的参数做引用时">函数的参数做引用时</span></h3>
<p>python中的函数参数都是采用共享传参.
共享传参指函数的各个形式参数获得实参中各个引用的副本. 也就是说,
函数内部的形参是实参的别名.</p>
<p>这种方案就是当传入参数是可变对象时,
在函数内对参数的修改也就是对外部可变对象进行修改.
但这种参数试图重新赋值为一个新的对象时则无效,
因为这只是相当于把参数作为另一个东西的引用, 原有的对象并不变. 也就是说,
在函数内, 参数是不能把一个对象替换成另一个对象的.</p>
<h3><span id="不要使用可变类型作为参数的默认值">不要使用可变类型作为参数的默认值</span></h3>
<p>参数默认值是个很棒的特性. 对于开发者来说,
应该避免使用可变对象作为参数默认值. 因为如果参数默认值是可变对象,
而且修改了它的内容, 那么后续的函数调用上都会收到影响.</p>
<h3><span id="del和垃圾回收">del和垃圾回收</span></h3>
<p>在python中, 当一个对象失去了最后一个引用时, 会当做垃圾, 然后被回收掉.
虽然python提供了 <code>del</code> 语句用来删除变量.
但实际上只是删除了变量和对象之间的引用, 并不一定能让对象进行回收,
因为这个对象可能还存在其他引用.</p>
<p>在CPython中,
<strong>垃圾回收</strong>主要用的是<strong>引用计数</strong>的算法.
每个对象都会统计有多少引用指向自己. 当引用计数归零时,
意味着这个对象没有在使用, 对象就会被立即销毁.【分代垃圾回收算法】</p>
<h2><span id="符合python风格的对象">符合Python风格的对象</span></h2>
<blockquote>
<p>得益于 Python
数据模型，自定义类型的行为可以像内置类型那样自然。实现如此自然的行为，靠的不是继承，而是<strong>鸭子类型</strong>（duck
typing）：我们只需按照预定行为实现对象所需的方法即可。</p>
</blockquote>
<h3><span id="对象表示形式">对象表示形式</span></h3>
<p>每门面向对象的语言至少都有一种<strong>获取对象的字符串表示形式的标准方式</strong>。Python
提供了两种方式。</p>
<ul>
<li><code>repr()</code> :
以便于开发者理解的方式返回对象的字符串表示形式。</li>
<li><code>str()</code> :
以便于用户理解的方式返回对象的字符串表示形式。</li>
</ul>
<h3><span id="classmethod-与-staticmethod">classmethod 与 staticmethod</span></h3>
<p>这两个都是python内置提供了装饰器,
一般python教程都没有提到这两个装饰器. 这两个都是在类 <code>class</code>
定义中使用的, 一般情况下, class 里面定义的函数是与其类的实例进行绑定的.
而这两个装饰器则可以改变这种调用方式.</p>
<p>先来看看 <code>classmethod</code> , 这个装饰器不是操作实例的方法,
并且将类本身作为第一个参数. 而 <code>staticmethod</code>
装饰器也会改变方法的调用方式, 它就是一个普通的函数,</p>
<p><code>classmethod</code> 与 <code>staticmethod</code> 的区别就是
<code>classmethod</code> <strong>会把类本身作为第一个参数传入</strong>,
其他都一样了.</p>
<h3><span id="格式化显示">格式化显示</span></h3>
<p>内置的 <code>format()</code> 函数和 <code>str.format()</code>
方法把各个类型的格式化方式委托给相应的
<code>.__format__(format_spec)</code> 方法. <code>format_spec</code>
是格式说明符，它是：</p>
<ul>
<li><code>format(my_obj, format_spec)</code> 的第二个参数</li>
<li><code>str.format()</code> 方法的格式字符串，{}
里代换字段中冒号后面的部分</li>
</ul>
<h3><span id="python的私有属性和受保护的属性">Python的私有属性和"受保护的"属性</span></h3>
<p>python中对于实例变量没有像 <code>private</code>
这样的修饰符来创建私有属性, 在python中,
有一个简单的机制来处理私有属性.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.__x = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">a = A()</span><br><span class="line"><span class="built_in">print</span>(a.__x) <span class="comment"># AttributeError: &#x27;A&#x27; object has no attribute &#x27;__x&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(a.__dict__)复制代码</span><br></pre></td></tr></table></figure>
<p>如果属性以 <code>__name</code> 的
<code>两个下划线为前缀, 尾部最多一个下划线</code> 命名的实例属性,
python会把它名称前面加一个下划线加类名, 再放入 <code>__dict__</code> 中,
以 <code>__name</code> 为例, 就会变成 <code>_A__name</code> .</p>
<p><strong>名称改写算是一种安全措施</strong>, 但是不能保证万无一失,
它能避免意外访问, 但不能阻止故意做坏事.</p>
<p>只要知道私有属性的机制, 任何人都能直接读取和改写私有属性.
因此很多python程序员严格规定:
<code>遵守使用一个下划线标记对象的私有属性</code> . Python
解释器不会对使用单个下划线的属性名做特殊处理, 由程序员自行控制,
不在类外部访问这些属性. 这种方法也是所推荐的,
两个下划线的那种方式就不要再用了. 引用python大神的话:</p>
<blockquote>
<p>绝对不要使用两个前导下划线，这是很烦人的自私行为。如果担心名称冲突，应该明确使用一种名称改写方式（如
_MyThing_blahblah）。这其实与使用双下划线一样，不过自己定的规则比双下划线易于理解。</p>
</blockquote>
<p><strong>Python中的把使用一个下划线前缀标记的属性称为"受保护的"属性</strong>。</p>
<h3><span id="使用-slots类属性节省空间">使用 <strong>slots</strong>
类属性节省空间</span></h3>
<p>默认情况下, <strong>python在各个实例中, 用 <code>__dict__</code>
的字典存储实例属性</strong>. 因此实例的属性是动态变化的,
可以在运行期间任意添加属性. 而字典是消耗内存比较大的结构.
因此当对象的属性名称确定时, 使用 <code>__slots__</code>
可以节约内存.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Vector2d</span>:</span><br><span class="line">    __slots__ = (<span class="string">&#x27;__x&#x27;</span>, <span class="string">&#x27;__y&#x27;</span>)</span><br><span class="line">    typecode = <span class="string">&#x27;d&#x27;</span></span><br><span class="line">    <span class="comment"># 下面是各个方法（因排版需要而省略了）复制代码</span></span><br></pre></td></tr></table></figure>
<p>在类中定义<code>__slots__</code>
属性的目的是告诉解释器："这个类中的所有实例属性都在这儿了！" 这样,
Python 会在各个实例中使用类似元组的结构存储实例变量,
从而避免使用消耗内存的 <code>__dict__</code> 属性.
如果有数百万个实例同时活动, 这样做能节省大量内存.</p>
<h2><span id="第十五章-上下文管理器和-else块">第十五章: 上下文管理器和 else
块</span></h2>
<p>本章讨论的是其他语言不常见的流程控制特性, 正因如此,
python新手往往忽视或没有充分使用这些特性. 下面讨论的特性有:</p>
<ul>
<li>with 语句和上下文管理器</li>
<li>for while try 语句的 else 子句</li>
</ul>
<p><code>with</code> 语句会设置一个临时的上下文,
交给<strong>上下文管理器对象控制</strong>,
并且负<strong>责清理上下文</strong>.
这么做能避免错误并<strong>减少代码量</strong>,
因此<strong>API更安全</strong>, 而且更易于使用. 除了自动关闭文件之外,
with 块还有其他很多用途.</p>
<p><code>else</code> 子句先做这个，选择性再做那个的作用.</p>
<h3><span id="if语句之外的else块">if语句之外的else块</span></h3>
<p>这里的 else 不是在在 if 语句中使用的, 而是在 for while try
语句中使用的.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> lst:</span><br><span class="line">    <span class="keyword">if</span> i &gt; <span class="number">10</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;no num bigger than 10&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>else</strong> 子句的行为如下:</p>
<ul>
<li><code>for</code> : 仅当 for 循环运行完毕时（即 <strong>for
循环没有被 break 语句中止</strong>）才运行 else 块。</li>
<li><code>while</code> : 仅当 while 循环因为条件为假值而退出时（即 while
循环没有被 <code>break</code> 语句中止）才运行 else 块。</li>
<li><code>try</code> : 仅当 <strong>try
块中没有异常抛出时</strong>才运行 else 块。</li>
</ul>
<p><strong>在所有情况下, 如果异常或者 <code>return</code> ,
<code>break</code> 或 <code>continue</code>
语句导致控制权跳到了复合语句的住块外, <code>else</code>
子句也会被跳过.</strong></p>
<p>这一些情况下, 使用 else 子句通常让代码更便于阅读, 而且能省去一些麻烦,
<strong>不用设置控制标志作用的变量和额外的if判断.</strong></p>
<h3><span id="上下文管理器和with块">上下文管理器和with块</span></h3>
<p><strong>上下文管理器对象的目的就是管理 with 语句,</strong>
<strong>with 语句的目的是简化 <code>try/finally</code> 模式</strong>.
<strong>这种模式用于保证一段代码运行完毕后执行某项操作,
即便那段代码由于异常</strong>, <code>return</code> 或者
<code>sys.exit()</code> 调用而终止, 也会执行执行的操作.
<code>finally</code> 子句中的代码通常用于释放重要的资源,
或者还原临时变更的状态.</p>
<p>上下文管理器协议包含 <code>__enter__</code> 和 <code>__exit__</code>
两个方法. <strong>with 语句开始运行时, 会在上下文管理器上调用
<code>__enter__</code> 方法, 待 with 语句运行结束后, 再调用
<code>__exit__</code> 方法, 以此扮演了 <code>finally</code>
子句的角色.</strong></p>
<p>with 最常见的例子就是确保关闭文件对象.</p>
<p>上下文管理器调用 <code>__enter__</code> 没有参数, 而调用
<code>__exit__</code> 时, 会传入3个参数:</p>
<ul>
<li><code>exc_type</code> : 异常类（例如 ZeroDivisionError）</li>
<li><code>exc_value</code> :
异常实例。有时会有参数传给异常构造方法，例如错误消息，这些参数可以使用
<code>exc_value.args</code> 获取</li>
<li><code>traceback</code> : <code>traceback</code> 对象</li>
</ul>
<h3><span id="contextlib模块中的实用工具">contextlib模块中的实用工具</span></h3>
<p>在ptyhon的标准库中, contextlib
模块中还有一些类和其他函数，使用范围更广。</p>
<ul>
<li><code>closing</code>: 如果对象提供了 <code>close()</code>
方法，但没有实现 <code>__enter__/__exit__</code>
协议，那么可以使用这个函数构建上下文管理器。</li>
<li><code>suppress</code>: 构建临时忽略指定异常的上下文管理器。</li>
<li><strong><code>@contextmanager</code>:
这个装饰器把简单的生成器函数变成上下文管理器，这样就不用创建类去实现管理器协议了。</strong></li>
<li><code>ContextDecorator</code>:
这是个基类，用于定义基于类的上下文管理器。这种上下文管理器也能用于装饰函数，在受管理的上下文中运行整个函数。</li>
<li><code>ExitStack</code>: 这个上下文管理器能进入多个上下文管理器。with
块结束时，ExitStack 按照后进先出的顺序调用栈中各个上下文管理器的
<code>__exit__</code> 方法。如果事先不知道 with
块要进入多少个上下文管理器，可以使用这个类。例如，同时打开任意一个文件列表中的所有文件。</li>
</ul>
<p>显然，在这些实用工具中，使用最广泛的是 <code>@contextmanager</code>
装饰器，因此要格外留心。这个装饰器也有迷惑人的一面，因为它与迭代无关，却要使用
yield 语句。</p>
<h3><span id="使用contextmanager">使用@contextmanager</span></h3>
<p><strong><span class="citation" data-cites="contextmanager">@contextmanager</span>
装饰器能减少创建上下文管理器的样板代码量, 因为不用定义
<code>__enter__</code> 和 <code>__exit__</code> 方法, 只需要实现一个
<code>yield</code> 语句的生成器.</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> contextlib</span><br><span class="line"><span class="meta">@contextlib.contextmanager</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">looking_glass</span>():</span><br><span class="line"></span><br><span class="line">    original_write = sys.stdout.write</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverse_write</span>(<span class="params">text</span>):</span><br><span class="line">        original_write(text[::-<span class="number">1</span>])</span><br><span class="line">    sys.stdout.write = reverse_write</span><br><span class="line">    <span class="keyword">yield</span> <span class="string">&#x27;JABBERWOCKY&#x27;</span></span><br><span class="line">    sys.stdout.write = original_write</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> looking_glass() <span class="keyword">as</span> f:</span><br><span class="line">    <span class="built_in">print</span>(f)        <span class="comment"># YKCOWREBBAJ</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;ABCD&quot;</span>)   <span class="comment"># DCBA</span></span><br><span class="line">    复制代码</span><br></pre></td></tr></table></figure>
<p><code>yield</code> 语句起到了分割的作用, yield 语句前面的所有代码在
with 块开始时（即解释器调用 <code>__enter__</code> 方法时）执行， yield
语句后面的代码在 with 块结束时（即调用 <code>__exit__</code>
方法时）执行.</p>
<h2><span id="第十六章-协程">第十六章: 协程</span></h2>
<p>为了理解协程的概念, 先从 <code>yield</code> 来说.
<code>yield item</code> 会产出一个值, 提供给 <code>next(...)</code>
调用方; 此外还会做出让步, 暂停执行生成器, 让调用方继续工作,
直到需要使用另一个值时再调用 <code>next(...)</code>
从暂停的地方继续执行.</p>
<p>从句子语法上看, 协程与生成器类似, 都是通过 <code>yield</code>
关键字的函数. <strong>可是, 在协程中, <code>yield</code>
通常出现在表达式的右边(datum = yield), 可以产出值,
也可以不产出(如果yield后面没有表达式, 那么会产出None).</strong>
协程可能会从调用方接收数据, 不过调用方把数据提供给协程使用的是
<code>.send(datum)</code> 方法. 而不是 <code>next(...)</code> . 通常,
调用方会把值推送给协程.</p>
<p>生成器调用方是一直索要数据, 而协程这是调用方可以想它传入数据,
协程也不一定要产出数据.</p>
<p><strong>不管数据如何流动, <code>yield</code> 都是一种流程控制工具,
使用它可以实现写作式多任务: 协程可以把控制器让步给中心调度程序,
从而激活其他的协程.</strong></p>
<h3><span id="生成器如何进化成协程">生成器如何进化成协程</span></h3>
<p>协程的底层框架实现后, 生成器API中增加了 <code>.send(value)</code>
方法. 生成器的调用方可以使用 <code>.send(...)</code> 来发送数据,
发送的数据会变成生成器函数中 <code>yield</code> 表达式的值. 因此,
生成器可以作为协程使用. 除了 <code>.send(...)</code> 方法, 还添加了
<code>.throw(...)</code> 和 <code>.close()</code> 方法,
用来让调用方<strong>抛出异常</strong>和<strong>终止生成器</strong>.</p>
<h3><span id="用作协程的生成器的基本行为">用作协程的生成器的基本行为</span></h3>
<blockquote>
<p><strong>优势：</strong></p>
<ul>
<li>一个线程中运行，非抢占式的</li>
<li>无需使用实例属性或者闭包, 在多次调用之间都能保持上下文</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">simple_coroutine</span>():</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&#x27;-&gt; coroutine started&#x27;</span>)</span><br><span class="line"><span class="meta">... </span>    x = <span class="keyword">yield</span></span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&#x27;-&gt; coroutine received:&#x27;</span>, x)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_coro = simple_coroutine()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_coro</span><br><span class="line">&lt;generator <span class="built_in">object</span> simple_coroutine at <span class="number">0x100c2be10</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(my_coro)</span><br><span class="line">-&gt; coroutine started</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_coro.send(<span class="number">42</span>)</span><br><span class="line">-&gt; coroutine received: <span class="number">42</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">...</span><br><span class="line">StopIteration</span><br></pre></td></tr></table></figure>
<p>在 <code>yield</code> 表达式中, 如果协程只需从调用那接受数据,
那么产出的值是 <code>None</code> . 与创建生成器的方式一样,
调用函数得到生成器对象. 协程都要先调用 <code>next(...)</code> 函数,
因为生成器还没启动, 没在 yield 出暂定, 所以一开始无法发送数据.
如果控制器流动到协程定义体末尾, 会像迭代器一样抛出
<code>StopIteration</code> 异常.</p>
<p><strong>使用协程的好处是不用加锁, 因为所有协程只在一个线程中运行,
他们是非抢占式的. 协程也有一些状态, 可以调用
<code>inspect.getgeneratorstate(...)</code> 来获得,
协程都是这4个状态中的一种:</strong></p>
<ul>
<li><code>'GEN_CREATED'</code> 等待开始执行。</li>
<li><code>'GEN_RUNNING'</code> 解释器正在执行。</li>
<li><code>'GEN_SUSPENDED'</code> 在 yield 表达式处暂停。</li>
<li><code>'GEN_CLOSED'</code> 执行结束。</li>
</ul>
<p>只有在多线程应用中才能看到这个状态。此外，生成器对象在自己身上调用
<code>getgeneratorstate</code> 函数也行，不过这样做没什么用。</p>
<p>为了更好理解继承的行为, 来看看产生两个值的协程:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> inspect <span class="keyword">import</span> getgeneratorstate</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">simple_coro2</span>(<span class="params">a</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&#x27;-&gt; Started: a =&#x27;</span>, a)</span><br><span class="line"><span class="meta">... </span>    b = <span class="keyword">yield</span> a</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&#x27;-&gt; Received: b =&#x27;</span>, b)</span><br><span class="line"><span class="meta">... </span>    c = <span class="keyword">yield</span> a + b</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&#x27;-&gt; Received: c =&#x27;</span>, c)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_coro2 = simple_coro2(<span class="number">14</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>getgeneratorstate(my_coro2) <span class="comment"># 协程处于未启动的状态</span></span><br><span class="line"><span class="string">&#x27;GEN_CREATED&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">next</span>(my_coro2)              <span class="comment"># 向前执行到yield表达式, 产出值 a, 暂停并等待 b 赋值</span></span><br><span class="line">-&gt; Started: a = <span class="number">14</span></span><br><span class="line"><span class="number">14</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>getgeneratorstate(my_coro2) <span class="comment"># 协程处于暂停状态</span></span><br><span class="line"><span class="string">&#x27;GEN_SUSPENDED&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_coro2.send(<span class="number">28</span>)           <span class="comment"># 数字28发给协程, yield 表达式中 b 得到28, 协程向前执行, 产出 a + b 值</span></span><br><span class="line">-&gt; Received: b = <span class="number">28</span></span><br><span class="line"><span class="number">42</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>my_coro2.send(<span class="number">99</span>)           <span class="comment"># 同理, c 得到 99, 但是由于协程终止, 导致生成器对象抛出 StopIteration 异常</span></span><br><span class="line">-&gt; Received: c = <span class="number">99</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">StopIteration</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>getgeneratorstate(my_coro2) <span class="comment"># 协程处于终止状态</span></span><br><span class="line"><span class="string">&#x27;GEN_CLOSED&#x27;</span>复制代码</span><br></pre></td></tr></table></figure>
<p>关键的一点是, 协程在 <code>yield</code> 关键字所在的位置暂停执行.
<strong>对于 <code>b = yield a</code> 这行代码来说,
等到客户端代码再激活协程时才会设定 b 的值</strong>.
这种方式要花点时间才能习惯, 理解了这个, 才能弄懂异步编程中
<code>yield</code> 的作用.</p>
<h3><span id="示例使用协程计算移动平均值">示例：使用协程计算移动平均值</span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">averager</span>():</span><br><span class="line">    total = <span class="number">0.0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    average = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        term = <span class="keyword">yield</span> average</span><br><span class="line">        total += term</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        average = total/count复制代码</span><br></pre></td></tr></table></figure>
<p>这是一个动态计算平均值的协程代码, 这个无限循环表明,
它会一直接收值然后生成结果. 只有当调用方在协程上调用
<code>.close()</code> 方法, 或者没有该协程的引用时, 协程才会终止.</p>
<p><strong>协程的好处是, 无需使用实例属性或者闭包,
在多次调用之间都能保持上下文.</strong></p>
<h3><span id="使用-yield-from">使用 yield from</span></h3>
<p><code>yield from</code> 是全新的语法结构. 它的作用比
<code>yield</code> 多很多.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">gen</span>():</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">for</span> c <span class="keyword">in</span> <span class="string">&#x27;AB&#x27;</span>:</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">yield</span> c</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">yield</span> i</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(gen())</span><br><span class="line">[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">1</span>, <span class="number">2</span>]复制代码</span><br></pre></td></tr></table></figure>
<p>可以改写成:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">gen</span>():</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> <span class="keyword">from</span> <span class="string">&#x27;AB&#x27;</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">yield</span> <span class="keyword">from</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(gen())</span><br><span class="line">[<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="number">1</span>, <span class="number">2</span>]复制代码</span><br></pre></td></tr></table></figure>
<p>在生成器 <code>gen</code> 中使用 <code>yield form subgen()</code> 时,
subgen 会得到控制权, 把产出的值传给 gen 的调用方, 既调用方可以直接调用
subgen. 而此时, gen 会阻塞, 等待 subgen 终止.</p>
<p><strong><code>yield from x</code> 表达式对 <code>x</code>
对象所做的第一件事是, 调用 <code>iter(x)</code> 获得迭代器. 因此, x
对象可以是任何可迭代对象.</strong></p>
<p>这个语义过于复杂, 来看看作者 <code>Greg Ewing</code> 的解释:</p>
<blockquote>
<p>“把迭代器当作生成器使用，相当于把子生成器的定义体内联在 yield from
表达式</p>
</blockquote>
<p>中。此外，子生成器可以执行 return 语句，返回一个值，而返回的值会成为
yieldfrom 表达式的值。”</p>
<p>子生成器是从 <code>yield from &lt;iterable&gt;</code> 中获得的生成器.
而后, 如果调用方使用 <code>send()</code> 方法, 其实也是直接传给子生成器.
如果发送的是 <code>None</code> , 那么会调用子生成器的
<code>__next__()</code> 方法. 如果不是 <code>None</code> ,
那么会调用子生成器的 <code>send()</code> 方法. 当子生成器抛出
<code>StopIteration</code> 异常, 那么委派生成器恢复运行.
任何其他异常都会向上冒泡, 传给委派生成器.</p>
<p>生成器在 <code>return expr</code> 表达式中会触发
<code>StopIteration</code> 异常.</p>
<h2><span id="第十七章-使用-futrues包处理并发">第十七章: 使用 futrues包
处理并发</span></h2>
<p><code>"futures"</code> 是什么概念呢? 期物指一种对象,
表示异步执行的操作. 这个概念是 <code>concurrent.futures</code> 模块和
<code>asyncio</code> 包的基础.</p>
<h3><span id="阻塞型io和gil">阻塞型I/O和GIL</span></h3>
<p><strong>CPython解释器不是线程安全的, 因此有全局解释锁(GIL),
一次只允许使用一个线程执行 python 字节码,
所以一个python进程不能同时使用多个 CPU 核心.</strong></p>
<p>python程序员编写代码时无法控制 GIL, 然而,
在标准库中所有执行阻塞型I/O操作的函数,
在登台操作系统返回结果时都会释放GIL.
这意味着IO密集型python程序能从中受益.</p>
<h3><span id="使用concurrentfutures模块启动进程">使用concurrent.futures模块启动进程</span></h3>
<p><strong>一个python进程只有一个 GIL. 多个python进程就能绕开GIL,
因此这种方法就能利用所有的 CPU 核心.</strong>
<code>concurrent.futures</code> 模块就实现了真正的并行计算, 因为它使用
<code>ProcessPoolExecutor</code> 把工作交个多个python进程处理.</p>
<p><code>ProcessPoolExecutor</code> 和 <code>ThreadPoolExecutor</code>
类都实现了通用的 <code>Executor</code> 接口, 因此使用
<code>concurrent.futures</code>
能很轻松把基于线程的方案转成基于进程的方案.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">download_many</span>(<span class="params">cc_list</span>):</span><br><span class="line">    workers = <span class="built_in">min</span>(MAX_WORKERS, <span class="built_in">len</span>(cc_list))</span><br><span class="line">    <span class="keyword">with</span> futures.ThreadPoolExecutor(workers) <span class="keyword">as</span> executor:</span><br><span class="line">        res = executor.<span class="built_in">map</span>(download_one, <span class="built_in">sorted</span>(cc_list))复制代码</span><br></pre></td></tr></table></figure>
<p>改成:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">download_many</span>(<span class="params">cc_list</span>):</span><br><span class="line">    <span class="keyword">with</span> futures.ProcessPoolExecutor() <span class="keyword">as</span> executor:</span><br><span class="line">        res = executor.<span class="built_in">map</span>(download_one, <span class="built_in">sorted</span>(cc_list))复制代码</span><br></pre></td></tr></table></figure>
<p><code>ThreadPoolExecutor.__init__</code> 方法需要
<code>max_workers</code> 参数，指定线程池中线程的数量; 在
<code>ProcessPoolExecutor</code> 类中, 这个参数是可选的.</p>
<h2><span id="第十八章-使用-asyncio包处理并发">第十八章: 使用 asyncio
包处理并发</span></h2>
<blockquote>
<p><strong>并发是指一次处理多件事。</strong></p>
</blockquote>
<p>并行是指一次做多件事。 二者不同，但是有联系。
一个关于结构，一个关于执行。
并发用于制定方案，用来解决可能（但未必）并行的问题。—— Rob Pike Go
语言的创造者之一</p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>流程的Python</category>
      </categories>
  </entry>
  <entry>
    <title>python-dict和set</title>
    <url>/posts/2105FD/</url>
    <content><![CDATA[<h2><span id="python-dict和set">Python - dict和set</span></h2>
<p>前言：我们经常会听见很多的概念，<strong>哈希值，哈希表，可哈希对象，不可哈希对象，散列表，字典，映射</strong>，等等，那么这么多的概念后面到底又有什么区别和联系，它们的本质又是怎么样的，本此系列文章将针对这些概念进行说明，鉴于篇幅较多，本次系列文章将分为两篇来说明，此为第一篇，介绍数据结构哈希表与哈希值。</p>
<h3><span id="一-可哈希对象与不可哈希对象">一、可哈希对象与不可哈希对象</span></h3>
<h4><span id="11-哈希表散列表hash-table">1.1 哈希表（散列表）——hash table</span></h4>
<p><strong>哈希表，又称之为散列表，是一种空间换时间的存储结构</strong>，是在算法中提升效率的一种比较常用的方式，但是所需空间太大也会让人头疼，所以通常需要在二者之间权衡。我们会在之后的具体算法章节中得到更多的领悟。</p>
<p><strong>哈希表（散列表），是能够通过给定的关键字的值直接访问到具体对应的值的一个数据结构</strong>。也就是说，把关键字映射到一个表中的位置来直接访问记录，以加快访问速度。</p>
<ul>
<li>关键字，也称之为<strong>键</strong>，或者是Key，这就是我们哈希函数计算的依据</li>
<li><strong>记录</strong>，也称之为<strong>值</strong>，，也称之为<strong><em>哈希值</em></strong>，或者是<strong><em>Value</em></strong>，也就是我们通过key然后经过哈希函数运算之后得到的结果，存储这个记录，即存放哈希函数得到的结果的数组称之为
<strong><em>哈希表</em></strong> 或者是
<strong><em>散列表</em></strong></li>
</ul>
<h4><span id="12哈希表的问题碰撞clollision">1.2
<strong>哈希表的问题——碰撞Clollision</strong></span></h4>
<p>其中有个特殊情况，就是通过不同的
Key，可能访问到同一个地址，这种现象叫作碰撞（Collision）。</p>
<p>如果“键-值对”在加入哈希表的时候产生了冲突，就必须找另外一个地方来存放它，冲突太多会降低数据插入和搜索的效率，因此希望能找到一个不容易产生冲突的函数，即构造一个地址分布比较均匀的哈希函数。</p>
<p>一个好的<a href="https://so.csdn.net/so/search?q=散列表&amp;spm=1001.2101.3001.7020">散列表</a>设计，除了需要选择一个性能较好的哈希函数，否则冲突是无法避免的，所以通常还需要有一个好的冲突处理方式，目前，这个哈希函数比较常用的实现方法比较多，通常需要考虑几个因素：关键字的长度、哈希表的大小、关键字的分布情况、记录的查找频率，等等。常见的一些哈希函数有：</p>
<ul>
<li>直接寻址法</li>
<li>数字分析法</li>
<li>平方取中法</li>
<li>取随机数法</li>
<li>除留取余法</li>
</ul>
<p>当出现冲突的时候，处理冲突的一些方法有：</p>
<ul>
<li>开放地址法（也叫开放寻址法）</li>
<li>再哈希法</li>
<li>链地址法</li>
<li>建立一个公共溢出区</li>
</ul>
<h4><span id="13什么是可哈希hashable">1.3
<strong>什么是可哈希(hashable)？</strong></span></h4>
<p><strong>不可变的数据结构(数字类型（int，float，bool）、字符串str、元组tuple、自定义类的对象)。</strong></p>
<p><strong>不可哈希的数据类型，即可变的数据结构
(字典dict，列表list，集合set)</strong></p>
<blockquote>
<p>An object is hashable if it has a hash value which never changes
during its lifetime (it needs a <strong>hash</strong>() method), and can
be compared to other objects (it needs an <strong>eq</strong>()or
<strong>cmp</strong>() method). Hashable objects which compare equal
must have the same hash value.</p>
</blockquote>
<p>如果一个对象是可哈希的,那么在它的<strong>生存期内必须不可变</strong>(而且该对象需要一个哈希函数),而且<strong>可以和其他对象比较</strong>(需要比较方法).比较值相同的对象一定有相同的哈希值，即一个对象必须要包含有以下几个魔术方法：</p>
<ul>
<li>__eq__():用于比较两个对象是否相等</li>
<li>__ cmp__() :
用于比较两个对象的大小关系，它与__eq__只要有一个就可以了</li>
<li>__hash__()：实际上就是哈希函数（散列函数），返回经过运算得到的哈希值</li>
</ul>
<h3><span id="二-dict">二、dict</span></h3>
<p>CPython 的字典实现为可调整大小的哈希表。与
B-树相比，这在大多数情况下为查找（目前最常见的操作）提供了更好的性能，并且实现更简单。</p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>流程的Python</category>
      </categories>
  </entry>
  <entry>
    <title>python-matplotlib画图</title>
    <url>/posts/1EVEKH1/</url>
    <content><![CDATA[<h2><span id="matplotlib画图">matplotlib画图</span></h2>
<p>https://matplotlib.org/</p>
<p>https://zhuanlan.zhihu.com/p/109245779</p>
<p>简洁优雅的Matplotlib可视化 |
绘制论文曲线图：https://zhuanlan.zhihu.com/p/81336415</p>
<ul>
<li>训练的loss可视化</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plot_train_history</span>(<span class="params">train_loss_history, val_loss_history, save_title</span>):</span><br><span class="line">    save_path = <span class="string">&quot;/home/lizy/ml/Malware_Adversarial_Ensemble/figures/&quot;</span></span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    time_ = <span class="built_in">range</span>(<span class="built_in">len</span>(train_loss_history))</span><br><span class="line">    ax.set_xlabel(<span class="string">&quot;Epochs&quot;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&quot;BCE Loss&quot;</span>)</span><br><span class="line">    ax.grid(linestyle=<span class="string">&quot;--&quot;</span>)</span><br><span class="line">    ax.plot(time_, train_loss_history, color=<span class="string">&quot;blue&quot;</span>, label=<span class="string">&quot;train loss&quot;</span>)</span><br><span class="line">    ax.plot(time_, val_loss_history, color=<span class="string">&quot;red&quot;</span>, label=<span class="string">&quot;val loss&quot;</span>)</span><br><span class="line">    ax.legend(loc=<span class="string">&quot;best&quot;</span>)</span><br><span class="line">    fig.savefig(os.path.join(save_path, <span class="string">f&quot;<span class="subst">&#123;save_title&#125;</span>_train_history.png&quot;</span>), dpi=<span class="number">300</span>)</span><br><span class="line">    plt.close(fig)</span><br></pre></td></tr></table></figure>
<ul>
<li>绘制三个折线子图</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_subplots</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="comment"># 数据</span></span><br><span class="line">    x = data[<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">    ys = data[<span class="string">&#x27;ys&#x27;</span>]</span><br><span class="line">    labels = data[<span class="string">&#x27;labels&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个1x3的子图布局，并设置整个图形的大小</span></span><br><span class="line">    fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">15</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘制每个子图</span></span><br><span class="line">    <span class="keyword">for</span> i, ax <span class="keyword">in</span> <span class="built_in">enumerate</span>(axs):</span><br><span class="line">        <span class="keyword">for</span> j, y <span class="keyword">in</span> <span class="built_in">enumerate</span>(ys[i]):</span><br><span class="line">            ax.plot(x, y, label=labels[j])</span><br><span class="line">        ax.set_title(<span class="string">f&#x27;Subplot <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>&#x27;</span>)</span><br><span class="line">        ax.legend()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置图的标题</span></span><br><span class="line">    fig.suptitle(<span class="string">&#x27;Three subplots with shared legend&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调整子图布局和间距</span></span><br><span class="line">    fig.subplots_adjust(wspace=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示图形</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>流程的Python</category>
      </categories>
  </entry>
  <entry>
    <title>python-pandas</title>
    <url>/posts/3KC92N6/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>流程的Python</category>
      </categories>
  </entry>
  <entry>
    <title>python-正则表达式</title>
    <url>/posts/3VPSMN7/</url>
    <content><![CDATA[<h1><span id="python3爬虫笔记-正则表达式">Python3爬虫笔记 --
正则表达式</span></h1>
<p>https://blog.csdn.net/Sc0fie1d/article/details/102724298?spm=1001.2014.3001.5502</p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>流程的Python</category>
      </categories>
  </entry>
  <entry>
    <title>python-环境变量</title>
    <url>/posts/2MJ41K7/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>流程的Python</category>
      </categories>
  </entry>
  <entry>
    <title>python-装饰器</title>
    <url>/posts/X5SQ7R/</url>
    <content><![CDATA[<h2><span id="python-函数装饰器和闭包">Python 函数装饰器和闭包</span></h2>
<blockquote>
<p>函数装饰器用于在源码中“标记”函数，以某种方式增强函数的行为。这是一项强大的功能，但是若想掌握，必须理解闭包。</p>
</blockquote>
<p>修饰器和闭包经常在一起讨论,
因为<strong>修饰器就是闭包的一种形式</strong>.
闭包还是<strong>回调式异步编程</strong>和<strong>函数式编程风格</strong>的基础.装饰器是语法糖,
它其实是将函数作为参数让其他函数处理. 装饰器有两大特征:</p>
<ul>
<li><strong>把被装饰的函数替换成其他函数</strong></li>
<li><font color="red">
<strong>装饰器在加载模块时立即执行</strong></font></li>
</ul>
<h3><span id="一-装饰器基础知识">一、装饰器基础知识</span></h3>
<p><strong>装饰器</strong>是<strong>可调用的对象</strong>,
其<strong>参数是另一个函数</strong>(被装饰的函数).
装饰器可能会处理被装饰的函数, 然后把它返回,
或者将其替换成<strong>另一个函数或可调用对象</strong>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@decorate</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">target</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;running target()&#x27;</span>)复制代码</span><br></pre></td></tr></table></figure>
<p>这种写法与下面写法完全等价:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">target</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;running target()&#x27;</span>)</span><br><span class="line">target = decorate(target)</span><br></pre></td></tr></table></figure>
<p>要理解立即执行看下等价的代码就知道了,
<code>target = decorate(target)</code> 这句调用了函数.
一般情况下装饰函数都会将某个函数作为返回值.</p>
<h3><span id="二-变量作用域规则">二、变量作用域规则</span></h3>
<p>要理解装饰器中变量的作用域, 应该要理解闭包,
我觉得书里将闭包和作用域的顺序换一下比较好. <strong>在python中,
一个变量的查找顺序是 <code>LEGB</code> (L：Local 局部环境，E：Enclosing
闭包，G：Global 全局，B：Built-in 内置).</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">base = <span class="number">20</span> <span class="comment"># 3</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_compare</span>():</span><br><span class="line">    base = <span class="number">10</span> <span class="comment"># 2</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">real_compare</span>(<span class="params">value</span>):</span><br><span class="line">    		base = <span class="number">5</span> <span class="comment"># 1</span></span><br><span class="line">        <span class="keyword">return</span> value &gt; base</span><br><span class="line">    <span class="keyword">return</span> real_compare</span><br><span class="line">    </span><br><span class="line">compare_10 = get_compare()</span><br><span class="line"><span class="built_in">print</span>(compare_10(<span class="number">5</span>))复制代码</span><br></pre></td></tr></table></figure>
<p>在闭包的函数 <code>real_compare</code> 中, 使用的变量
<code>base</code> 其实是 <code>base = 10</code> 的.
因为base这个变量在闭包中就能命中, 而不需要去 <code>global</code>
中获取.</p>
<h3><span id="三-闭包">三、闭包</span></h3>
<p>闭包其实挺好理解的, 当匿名函数出现的时候, 才使得这部分难以掌握.
简单简短的解释闭包就是:</p>
<p><strong>名字空间与函数捆绑后的结果被称为一个闭包(closure).</strong></p>
<p>这个名字空间就是 <code>LEGB</code> 中的 <code>E</code> .
所以闭包不仅仅是将函数作为返回值.
而是将名字空间和函数捆绑后作为返回值的. 多少人忘了理解这个
<code>"捆绑"</code> , 不知道变量最终取的哪和哪啊. 哎.</p>
<h4><span id="标准库中的装饰器">标准库中的装饰器</span></h4>
<p>python内置了三个用于装饰方法的函数: <code>property</code> 、
<code>classmethod</code> 和 <code>staticmethod</code> .
这些是用来丰富类的.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">age</span>():</span><br><span class="line">        <span class="keyword">return</span> <span class="number">12</span></span><br></pre></td></tr></table></figure>
<h3><span id="四-应用">四、应用</span></h3>
<p>非常适合有切面需求的场景，比如<strong>权限校验，日志记录和性能测试</strong>等等。比如你想要执行某个函数前记录日志或者记录时间来统计性能，又不想改动这个函数，就可以通过装饰器来实现。</p>
<h5><span id="不用装饰器我们会这样来实现在函数执行前插入日志">不用装饰器，我们会这样来实现在函数执行前插入日志：</span></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;i am foo&#x27;</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;foo is running&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;i am foo&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>虽然这样写是满足了需求，但是改动了原有的代码，如果有其他的函数也需要插入日志的话，就需要改写所有的函数，不能复用代码。<strong>可以这么写</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">use_logg</span>(<span class="params">func</span>):</span><br><span class="line">    logging.warn(<span class="string">&quot;%s is running&quot;</span> % func.__name__)</span><br><span class="line">    func()</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bar</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;i am bar&#x27;</span>)</span><br><span class="line">use_log(bar)    <span class="comment">#将函数作为参数传入</span></span><br></pre></td></tr></table></figure>
<p>这样写的确可以复用插入的日志，缺点就是显示的封装原来的函数，我们希望透明的做这件事。<strong>用装饰器来写</strong>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">use_log</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args,**kwargs</span>):</span><br><span class="line">        logging.warn(<span class="string">&#x27;%s is running&#x27;</span> % func.__name___)</span><br><span class="line">        <span class="keyword">return</span> func(*args,**kwargs)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bar</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;I am bar&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">bar = use_log(bar)</span><br><span class="line">bar()</span><br></pre></td></tr></table></figure>
<p><code>use_log()</code> 就是装饰器，它把真正我们想要执行的函数
<code>bar()</code>
封装在里面，返回一个封装了加入代码的新函数，看起来就像是
<code>bar()</code>
被装饰了一样。这个例子中的切面就是函数进入的时候，在这个时候，我们插入了一句记录日志的代码。这样写还是不够透明，通过@语法糖来起到
<code>bar = use_log(bar)</code> 的作用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bar = use_log(bar)<span class="keyword">def</span> <span class="title function_">use_log</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args,**kwargs</span>):</span><br><span class="line">        logging.warn(<span class="string">&#x27;%s is running&#x27;</span> % func.__name___)</span><br><span class="line">        <span class="keyword">return</span> func(*args,**kwargs)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@use_log</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bar</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;I am bar&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="meta">@use_log</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">haha</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;I am haha&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">bar()</span><br><span class="line">haha()</span><br></pre></td></tr></table></figure>
<h5><span id="装饰器也是可以带参数的这位装饰器提供了更大的灵活性">装饰器也是可以带参数的，这位装饰器提供了更大的灵活性。</span></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">use_log</span>(<span class="params">level</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decorator</span>(<span class="params">func</span>): </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">            <span class="keyword">if</span> level == <span class="string">&quot;warn&quot;</span>:</span><br><span class="line">                logging.warn(<span class="string">&quot;%s is running&quot;</span> % func.__name__)</span><br><span class="line">            <span class="keyword">return</span> func(*args)</span><br><span class="line">        <span class="keyword">return</span> wrapper</span><br><span class="line">    <span class="keyword">return</span> decorator</span><br><span class="line"></span><br><span class="line"><span class="meta">@use_log(<span class="params">level=<span class="string">&quot;warn&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">name=<span class="string">&#x27;foo&#x27;</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;i am %s&quot;</span> % name)</span><br><span class="line">foo()</span><br></pre></td></tr></table></figure>
<p><font color="red"><strong>实际上是对装饰器的一个函数封装，并返回一个装饰器。</strong></font><strong>这里涉及到作用域的概念，之前有一篇博客提到过。可以把它看成一个带参数的闭包</strong>。当使用
<code>@use_log(level='warn')</code> 时，会将 <code>level</code>
的值传给装饰器的环境中。它的效果相当于
<code>use_log(level='warn')(foo)</code> ，也就是一个三层的调用。</p>
<p>这里有一个美中不足，<code>decorator</code>
不会改变装饰的函数的功能，但会悄悄的改变一个 <code>__name__</code>
的属性(还有其他一些元信息)，因为 <code>__name__</code>
是跟着函数命名走的。<font color="red"> <strong>可以用
<code>@functools.wraps(func)</code> 来让装饰器仍然使用 <code>func</code>
的名字。</strong></font><strong>functools.wraps
也是一个装饰器，它将原函数的元信息拷贝到装饰器环境中，从而不会被所替换的新函数覆盖掉。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">log</span>(<span class="params">func</span>):</span><br><span class="line"><span class="meta">    @functools.wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kw</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;call %s():&#x27;</span> % func.__name__)</span><br><span class="line">        <span class="keyword">return</span> func(*args, **kw)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>流程的Python</category>
      </categories>
  </entry>
  <entry>
    <title>比赛WriteUp补充</title>
    <url>/posts/1B3RWJ6/</url>
    <content><![CDATA[<h3><span id="比赛writeup补充">比赛WriteUp补充</span></h3>
<ul>
<li>360 BDCI</li>
<li>邮件安全</li>
<li>Datacon 2020</li>
<li>Datacon 2021</li>
<li>Datacon 2022</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>算法比赛</category>
      </categories>
  </entry>
  <entry>
    <title>Python常见问题</title>
    <url>/posts/31DSKYD/</url>
    <content><![CDATA[<h2><span id="python-面试考点">Python-面试考点</span></h2>
<ul>
<li>运行可视化网站： https://pythontutor.com/</li>
<li>吐血总结！40道Python面试题集锦（附答案） - 幽默的程序猿日常的文章 -
知乎 https://zhuanlan.zhihu.com/p/366679675</li>
</ul>
<h3><span id="1基础知识">1.基础知识</span></h3>
<h4><span id="a基础要求">a.基础要求</span></h4>
<ul>
<li><p><strong>参数中的 * 和 </strong> 的作用（要求：基础知识）**</p>
<blockquote>
<p>python
从参数定位到<strong>仅限关键字参数</strong>：https://blog.csdn.net/littleRpl/article/details/89457557</p>
<p>参数中*以及**的作用：https://blog.csdn.net/weixin_41978699/article/details/121008512</p>
</blockquote>
<p>*参数：将任何剩余的参数都以元组的方式传入这个可变参数。允许省略可变参数的函数名</p>
<p>**参数：会将所有参数放入一个<code>dict</code>供函数使用</p></li>
<li><p><strong>选代器（iterator）和生成器（generator)
(要求：基础知识）</strong></p>
<ul>
<li></li>
</ul></li>
<li><p><strong>str和unicode的区别（python2下）（要求：基础知识）</strong></p></li>
<li><p><strong>装饰器用途（要求：基础知识）</strong></p></li>
<li><p><strong>is和＝＝的区别（要求：基础知识）</strong></p>
<ul>
<li>== 符号比较的是两个对象的值，is 比较的是两个的对象的标识【id()函数 ,
Cpython中内存地址】</li>
<li>x is None</li>
<li>is 符号比 == 运算快【不能重载】，== 是语法糖，【a.__ eq __(b)】</li>
</ul></li>
<li><p>**双下划线开头的魔法方法，比如＿add__（至少知道一个，以及其作用）**</p></li>
<li><p><strong>字符串编码：ascii/unicode/utf-8
分别是什么，以及三者的区别（要求：要求至少能回答一个）</strong></p></li>
<li><p><strong>内置数据结构</strong></p>
<ul>
<li><p>dict (要求：至少知道底层实现是基于hash表，可以扩展提问）</p></li>
<li><p>list (要求：至少知道底层实现类似链表，可以扩展提问）</p></li>
<li><p>tuple(要求：知道其与list(异同）</p>
<ul>
<li><strong>元组的相对不可变形</strong>：标识不变，值可变</li>
<li></li>
</ul></li>
<li><p>set(要求：知道使用场景）</p></li>
</ul></li>
</ul>
<h4><span id="b进阶要求">b.进阶要求</span></h4>
<ul>
<li>yield / yield from的区别（要求：可选）</li>
</ul>
<p>yield只是将普通函数变成生成器，yield一个值，迭代时可以得到一个值；而yield
from是将后面的值变成一个可迭代对象。</p>
<ul>
<li><p>python 性能优化（要求：基础知识）</p>
<ul>
<li><p>python为什么慢？</p>
<ul>
<li><p>python是动态语言</p></li>
<li><p>python是解释执行</p></li>
<li><p>python中一切都是对象</p></li>
<li><p>python GIL</p></li>
<li><p><strong>垃圾回收</strong></p></li>
</ul></li>
</ul></li>
<li><p>python
模块查找顺序（要求：发挥空间比较大，junior岗位至少知道基本知识）</p></li>
<li><p>python
字符串编码问题为什么这么复杂（要求：非必须，发挥空间较大，可以引导被面者深入牌答，以及与其他语言的对比）</p></li>
</ul>
<h3><span id="2-正则表达式">2 正则表达式</span></h3>
<h4><span id="a基础要求">a.基础要求</span></h4>
<p>能够根据实际需求，实现中等难度的正则表达式</p>
<h4><span id="b进阶要求">b.进阶要求</span></h4>
<p>贪婪与非贫要模式（要求：非junior岗位需要掌握）
捕获与命名捕获（要求：非junior岗位需要掌握）</p>
<h3><span id="3-常见模块使用待补充完善">3 常见模块使用（待补充完善）</span></h3>
<h4><span id="a基础要求">a.基础要求：</span></h4>
<p>能够熟练应用基础python模块，如string,logging,json,collections(熟悉其中一个）</p>
<h4><span id="b进阶要求">b.进阶要求：</span></h4>
<p>1requests,itertools,multiprocessing等</p>
<h3><span id="4垃圾回收">==4.垃圾回收==</span></h3>
<h4><span id="a基础要求">a.基础要求：</span></h4>
<p>垃圾回收过程（要求：必须目产出<strong>引用计数</strong>，其他非必须，发挥里间级大，可以引导面试者深
入回答） 引用计数的缺点（要求：必須掌握）</p>
<h4><span id="b进阶要求">b.进阶要求：</span></h4>
<p>分线回收</p>
<hr>
<h2><span id="pythonqampa">PythonQ&amp;A</span></h2>
<blockquote>
<p>https://blog.csdn.net/u013486414/article/details/119701505</p>
</blockquote>
<h4><span id="代码效率优化">代码效率优化？</span></h4>
<ul>
<li><h5><span id="尽量使用python内置函数">尽量使用python内置函数</span></h5></li>
<li><h5><span id="字符串拼接使用python的标准式">字符串拼接使用python的标准式</span></h5></li>
<li><h5><span id="需要单次遍历的迭代的数组采用生成器替代惰性计算">需要单次遍历的迭代的数组采用生成器替代【惰性计算】</span></h5></li>
<li><h5><span id="if-x代替if-xtrue">if x代替if x==True</span></h5></li>
</ul>
<h4><span id="什么是duck-type">什么是duck type?</span></h4>
<p>鸭子类型更关注对象的行为，只要实现了某种接口方法就行，而不在乎是什么类型（比如说定义了
__iter__魔法方法的类实例对象都可以用for来迭代）</p>
<h4><span id="py3和py2的区别">py3和py2的区别</span></h4>
<ul>
<li>print在py3里是一个函数，在py2里只是一个关键字</li>
<li>py3文件的默认编码是utf8，py2文件的默认编码是ascii</li>
<li>py3的str是unicode字符串，而py2的str是bytes</li>
<li>py3的range()返回一个可迭代对象，py2的
range()返回一个列表，xrange()返回一个可迭代对象,</li>
<li>py3的除法返回float，py2的除法返回int</li>
</ul>
<h4><span id="可变对象与不可变对象">可变对象与不可变对象</span></h4>
<ul>
<li><strong>可变对象</strong>: list，dict，set</li>
<li><strong>不可变对象</strong>: bool，int，float，tuple，str,
frozenset</li>
</ul>
<h4><span id="可哈希和不可哈希对象">可哈希和不可哈希对象</span></h4>
<h4><span id="什么时候需要捕获异常">什么时候需要捕获异常?</span></h4>
<ul>
<li>Django的ORM框架操作数据库时，获取数据，更新数据等都有可能会异常</li>
<li>socket通信时，recv()方法可能会因为对方突然中断连接导致异常</li>
</ul>
<h4><span id="什么是cpython-gil">什么是CPython GIL?</span></h4>
<p>GIL，Global Interpreter
Lock，即<strong>全局解释器锁</strong>，引入GIL是因为CPython的<strong>内存管理并不是线程安全的,</strong>为了保护多线程下对python对象的访问，每个线程在执行过程中都需要先获取GIL，保证同一时刻只有一个线程在执行代码，GIL使得python的多线程不能充分发挥多核CPU的性能，对CPU密集型程序的影响较大。</p>
<h4><span id="什么是生成器">什么是生成器?</span></h4>
<p>生成器是一种可迭代对象，可以挂起并保持当前的状态</p>
<p>生成器遇到yield处会停止执行，调用next()或send()才会继续执行</p>
<p>定义一个生成器有两种方式，一种是<strong>生成器推导式</strong>，一种是在普通函数中添加<strong>yield语句并实例化</strong></p>
<h4><span id="浅拷贝和深拷贝">浅拷贝和深拷贝</span></h4>
<p>浅拷贝出来的是一个独立的对象，但<strong>它的子对象还是原对象中的子对象</strong></p>
<p><strong>深拷贝会递归地拷贝原对象中的每一个子对象，因此拷贝后的对象和原对象互不相关。</strong></p>
<h4><span id="迭代器与可迭代对象的区别">迭代器与可迭代对象的区别</span></h4>
<p>可迭代对象类，必须自定义__iter__()魔法方法，range，list类的实例化对象都是可迭代对象</p>
<p>迭代器类，必须自定义__iter__()和__next__()魔法方法，用iter()函数可以创建可迭代对象的迭代器</p>
<h4><span id="闭包">闭包</span></h4>
<p>闭包就是一个嵌套函数，它的内部函数 使用
外部函数的变量或参数,它的外部函数返回了内部函数</p>
<p>可以保存外部函数内的变量，不会随着外部函数调用完而销毁。</p>
<h4><span id="python垃圾回收机制">python垃圾回收机制</span></h4>
<p><strong>引用计数</strong>为主，<strong>标记清除</strong>和<strong>分代回收</strong>为辅</p>
<p>引用计数机制是这样的：</p>
<ul>
<li><p>当对象被创建，被引用，作为参数传递，存储到容器中，引用计数+1</p></li>
<li><p>当对象离开作用域，引用指向别的对象，del，从容器中移除，引用计数-1</p></li>
<li><p>当引用计数降为0，python就会自动回收该对象所在的内存空间，</p></li>
<li><p>但是引用计数无法<strong>解决循环引用</strong>的问题，所以引入了<strong>标记清除</strong>和<strong>分代回收机制</strong></p></li>
</ul>
<h4><span id="async和await的作用">async和await的作用</span></h4>
<p>async: 声明一个函数为异步函数，函数内只要有await就要声明为async</p>
<p>await:
搭配asyncio.sleep()时会切换协程，当切换回来后再继续执行下面的语句</p>
<h4><span id="内置的数据结构和算法">内置的数据结构和算法</span></h4>
<ul>
<li>内置数据结构: list，dict，tuple，set</li>
<li>内置算法: sorted，max</li>
</ul>
<h4><span id="collections模块">collections模块</span></h4>
<p>collections模块提供了一些好用的容器数据类型，其中常用的有:
namedtuple，<strong>deque</strong>，<strong>Counter</strong>，<strong>OrderedDict，defaultdict</strong></p>
<h4><span id="为什么dict查找的时间复杂度是o1">为什么dict查找的时间复杂度是O(1)?</span></h4>
<p>dict底层是哈希表，哈希表类似于C语言的数组，可以实现按索引随机访问</p>
<p>但dict的key不一定是整数，需要先通过哈希函数，再经过取余操作转换为索引</p>
<h4><span id="list-tuple的底层结构">list tuple的底层结构</span></h4>
<p>list和tuple底层都是顺序表结构</p>
<p>list底层是可变数组，数组里存放的是元素对象的指针</p>
<h4><span id="set的底层结构">set的底层结构</span></h4>
<p>哈希表，key就是元素，value都是空</p>
<h4><span id="class方法-和static方法的区别">class方法 和
static方法的区别</span></h4>
<p>class方法的第一个参数是cls，可以访问类属性，类方法</p>
<p>static方法和普通函数一样，只不过是放在类里，要通过类或实例来调用，但是它不能访问类和实例的属性和方法</p>
<h4><span id="什么是装饰器">什么是装饰器?</span></h4>
<p>装饰器是一个接收函数作为参数的闭包函数</p>
<p>它可以在不修改函数内部源代码的情况下，给函数添加额外的功能</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calc_time</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner</span>():</span><br><span class="line">        t1 = time.time()</span><br><span class="line">        func()</span><br><span class="line">        t2 = time.time()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;cost time: &#123;&#125;s&#x27;</span>.<span class="built_in">format</span>(t2-t1))</span><br><span class="line">    <span class="keyword">return</span> inner</span><br></pre></td></tr></table></figure>
<h4><span id="什么是元类-使用场景">什么是元类? 使用场景</span></h4>
<p><strong>元类是创建类的类</strong>，<strong>type还有继承自type的类都是元类</strong></p>
<p><strong>作用</strong>: 在类定义时（new, init）和 类实例化时(call)
可以添加自定义的功能</p>
<p><strong>使用场景</strong>:
ORM框架中创建一个类就代表数据库中的一个表，但是定义这个类时为了统一需要把里面的类属性全部改为小写，这个时候就要用元类重写new方法，把attrs字典里的key转为小写</p>
<h4><span id="python局部变量">Python局部变量</span></h4>
<p>python中list作为全局变量无需global声明的原因，则不会有歧义。它是“明确的”，因为如果把b当作是局部变量的话，它会报KeyError，所以它只能是引用全局的b,故不需要多此一举显式声明global。</p>
<h4><span id="python-读取大文件">Python 读取大文件？</span></h4>
<p>最近无论是面试还是笔试，有一个高频问题始终阴魂不散，那就是给一个大文件，至少超过10g,在内存有限的情况下（低于2g），该以什么姿势读它？</p>
<p><strong>一般：</strong></p>
<ul>
<li>with 上下文管理器会自动关闭打开的文件描述符</li>
<li>在迭代文件对象时，内容是一行一行返回的，不会占用太多内存</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">retrun_count</span>(<span class="params">fname</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算文件有多少行</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(fname) <span class="keyword">as</span> file: </span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> file:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br></pre></td></tr></table></figure>
<p><strong>更底层：</strong> fp.read()
<code>iter(partial(file.read, block_size), '')</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">chunked_file_reader</span>(<span class="params">fp, block_size=<span class="number">1024</span> * <span class="number">8</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;生成器函数：分块读取文件内容</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        chunk = fp.read(block_size)</span><br><span class="line">        <span class="comment"># 当文件没有更多内容时，read 调用将会返回空字符串 &#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> chunk:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">yield</span> chunk</span><br><span class="line"><span class="comment"># iter()优化</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chunked_file_reader</span>(<span class="params">file, block_size=<span class="number">1024</span> * <span class="number">8</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;生成器函数：分块读取文件内容，使用 iter 函数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 首先使用 partial(fp.read, block_size) 构造一个新的无需参数的函数</span></span><br><span class="line">    <span class="comment"># 循环将不断返回 fp.read(block_size) 调用结果，直到其为 &#x27;&#x27; 时终止</span></span><br><span class="line">    <span class="keyword">for</span> chunk <span class="keyword">in</span> <span class="built_in">iter</span>(partial(file.read, block_size), <span class="string">&#x27;&#x27;</span>):</span><br><span class="line">        <span class="keyword">yield</span> chunk</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">return_count_v3</span>(<span class="params">fname</span>):</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(fname) <span class="keyword">as</span> fp:</span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> chunked_file_reader(fp):</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br></pre></td></tr></table></figure>
<h4><span id="pandas分批读取大数据集">pandas分批读取大数据集?</span></h4>
<p>pandas 的 chunksize 读取</p>
<h4><span id="python可变数据类型-不可变数据类型">Python可变数据类型 不可变数据类型？</span></h4>
<p><strong>不可变类型</strong>：数值型、字符串型string和元组tuple；不允许变量的值发生变化，如果改变了变量的值，相当于是新建了一个对象。</p>
<p><strong>可变数据类型</strong>：列表list和字典dict，Set集合</p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>流程的Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>算法长征（14）位运算</title>
    <url>/posts/2KRNTN0/</url>
    <content><![CDATA[<h3><span id="位运算">位运算</span></h3>
<ul>
<li>https://www.runoob.com/python/python-operators.html</li>
</ul>
<p>a 为 60，b 为 13</p>
<figure class="highlight abnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">a</span> <span class="operator">=</span> <span class="number">0011</span> <span class="number">1100</span></span><br><span class="line"><span class="attribute">b</span> <span class="operator">=</span> <span class="number">0000</span> <span class="number">1101</span></span><br></pre></td></tr></table></figure>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220603165450958.png" alt="image-20220603165450958" style="zoom:50%;"></p>
<h4><span id="一-位运算技巧">一、位运算技巧</span></h4>
<ul>
<li><code>n &amp;= n - 1</code>: 把 n 的二进制位中的最低位的 1 变为
0.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">countOnes</span>(<span class="params">x: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">		ones = <span class="number">0</span></span><br><span class="line">  	<span class="keyword">while</span> x &gt; <span class="number">0</span>:</span><br><span class="line">				x &amp;= (x - <span class="number">1</span>)</span><br><span class="line">        ones += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> ones</span><br></pre></td></tr></table></figure>
<hr>
<h4><span id="剑指offer-16-数值的整数次方"></span></h4>
<p>实现 <a href="https://www.cplusplus.com/reference/valarray/pow/">pow(<em>x</em>,
<em>n</em>)</a> ，即计算 x 的 n
次幂函数（即，xn）。不得使用库函数，同时不需要考虑大数问题。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">myPow</span>(<span class="params">self, x: <span class="built_in">float</span>, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="comment"># 快速幂</span></span><br><span class="line">        <span class="keyword">if</span> x== <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        res = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> n &lt; <span class="number">0</span>:</span><br><span class="line">            x, n = <span class="number">1</span> / x, -n</span><br><span class="line">        <span class="keyword">while</span> n:</span><br><span class="line">            <span class="keyword">if</span> n &amp; <span class="number">1</span>:</span><br><span class="line">                res *= x</span><br><span class="line">            x *= x</span><br><span class="line">            n &gt;&gt;= <span class="number">1</span> <span class="comment"># n // 2</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-15-二进制中1的个数"></span></h4>
<p>编写一个函数，输入是一个无符号整数（以二进制串的形式），<strong>返回其二进制表达式中数字位数为
'1' 的个数</strong>（也被称为 <a href="http://en.wikipedia.org/wiki/Hamming_weight">汉明重量</a>)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hammingWeight</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> n:</span><br><span class="line">            res += <span class="number">1</span></span><br><span class="line">            n &amp;= n - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">hammingWeight</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> n:</span><br><span class="line">            <span class="keyword">if</span> n&amp;<span class="number">1</span> == <span class="number">1</span>:</span><br><span class="line">                res += <span class="number">1</span></span><br><span class="line">            n &gt;&gt;= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-65-不用加减乘除做加法"></span></h4>
<p>写一个函数，求<strong>两个整数之和</strong>，要求在函数体内不得使用
“+”、“-”、“*”、“/” 四则运算符号。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, a: <span class="built_in">int</span>, b: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 无进位和: 异或运算^ 规律相同</span></span><br><span class="line">        <span class="comment"># 进位: 与运算&amp; 规律相同（并需左移一位）</span></span><br><span class="line">        <span class="keyword">if</span> b == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> a</span><br><span class="line">        <span class="keyword">return</span> add(a ^ b, (a &amp; b) &lt;&lt; <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-56-i-数组中数字出现的次数"></span></h4>
<p>一个整型数组 <code>nums</code>
里除两个数字之外，其他数字都出现了两次。请写程序找出这两个只出现一次的数字。要求时间复杂度是O(n)，空间复杂度是O(1)。</p>
<p><font color="red">
如果除了<strong>一个</strong>数字以外，其他数字都出现了两次，那么如何找到出现一次的数字？</font></p>
<p>全员进行异或操作即可。考虑异或操作的性质：对于两个操作数的每一位，相同结果为
0，不同结果为 1。那么在计算过程中，成对出现的数字的所有位会两两抵消为
0，最终得到的结果就是那个出现了一次的数字。</p>
<p><font color="red">那么这一方法如何扩展到找出<strong>两个</strong>出现一次的数字呢？
</font></p>
<p>如果我们可以把<strong>所有数字分成两组</strong>，使得：</p>
<ul>
<li><p>两个只出现一次的数字在不同的组中；</p></li>
<li><p>相同的数字会被分到相同的组中</p></li>
</ul>
<p>那么对两个组分别进行异或操作，即可得到答案的两个数字。<strong>这是解决这个问题的关键。</strong></p>
<p><font color="red"> 那么如何实现这样的分组呢？</font></p>
<ul>
<li>在异或结果中找到任意为 11 的位。</li>
</ul>
<h5><span id="算法">算法：</span></h5>
<ul>
<li>先对所有数字进行一次异或，得到两个出现一次的数字的异或值。</li>
<li>在异或结果中找到任意为 1 的位。</li>
<li>根据这一位对所有的数字进行分组。</li>
<li>在每个组内进行异或操作，得到两个数字。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">singleNumbers</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        ret = functools.reduce(<span class="keyword">lambda</span> x, y: x ^ y, nums)</span><br><span class="line">        div = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> div &amp; ret == <span class="number">0</span>:</span><br><span class="line">            div &lt;&lt;= <span class="number">1</span></span><br><span class="line">        a, b = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> n &amp; div:</span><br><span class="line">                a ^= n</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                b ^= n</span><br><span class="line">        <span class="keyword">return</span> [a, b]</span><br></pre></td></tr></table></figure>
<h4><span id="剑指offer-56-ii-数组中数字出现的次数-ii"></span></h4>
<p>在一个数组 <code>nums</code>
中除一个数字只出现一次之外，其他数字都出现了三次。请找出那个只出现一次的数字。</p>
<ul>
<li>有限状态机、遍历统计</li>
</ul>
<h5><span id="算法">算法：</span></h5>
<ul>
<li>首先，将所有数字都看成
<font color="#aa5bfb"><strong>32位</strong></font> 的二进制数；</li>
<li>接着，将数组中的所有数字相加。那么，对于"某一位"来说，数值一定是
<font color="#fb5b9b"><strong>3N或3N+1</strong></font> ；</li>
<li>为什么？<font color="red">所有出现3次的数字对该位置的贡献，和一定是0或3，出现一次的数字对该位置的贡献，一定是0或1</font></li>
<li>所以，对该位置的和，用3取余，结果就是出现一次的数字在该位置的值。</li>
</ul>
<p><img src="https://pic.leetcode-cn.com/1628505479-dhBiYM-file_1628505479864" alt="在这里插入图片描述" style="zoom:50%;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">singleNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        counts = [<span class="number">0</span>] * <span class="number">32</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">32</span>):</span><br><span class="line">                counts[j] += num &amp; <span class="number">1</span></span><br><span class="line">                num &gt;&gt;= <span class="number">1</span></span><br><span class="line">        res, m = <span class="number">0</span>, <span class="number">3</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">32</span>):</span><br><span class="line">            res &lt;&lt;= <span class="number">1</span></span><br><span class="line">            res |= counts[<span class="number">31</span> - i] % m</span><br><span class="line">        <span class="keyword">return</span> res <span class="keyword">if</span> counts[<span class="number">31</span>] % m == <span class="number">0</span> <span class="keyword">else</span> ~(res ^ <span class="number">0xffffffff</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="剑指-offer-ii-003-前-n个数字二进制中-1-的个数"></span></h4>
<p>给定一个非负整数 <code>n</code> ，请计算 <code>0</code> 到
<code>n</code> 之间的每个数字的二进制表示中 1
的个数，并输出一个数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">countBits</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># o(nlogn)</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">countbits</span>(<span class="params">x: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">            ones = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> x &gt; <span class="number">0</span>:</span><br><span class="line">                x &amp;= (x - <span class="number">1</span>)</span><br><span class="line">                ones += <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> ones</span><br><span class="line">        <span class="keyword">return</span> [countbits(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n + <span class="number">1</span>)]</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">countBits</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        bits, high = [<span class="number">0</span>], <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> i&amp;(i - <span class="number">1</span>) == <span class="number">0</span>:</span><br><span class="line">                high = i</span><br><span class="line">            bits.append(bits[i - high] + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> bits</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title>模型部署（2）【TODO】在线部署</title>
    <url>/posts/CDA58R/</url>
    <content><![CDATA[<h3><span id="模型在线部署-tensorflowserving">模型在线部署-TensorFlow
Serving</span></h3>
<p>TensorFlow Serving 是 TensorFlow
提供的一个高性能、灵活、可扩展的模型服务框架，用于部署和扩展 TensorFlow
模型服务。它支持多种模型格式和多种协议，能够快速部署和扩展模型服务，适用于各种规模和复杂度的深度学习模型。TensorFlow
Serving 的主要特点包括：</p>
<ol type="1">
<li>支持多种模型格式：TensorFlow Serving 支持多种常见的模型格式，包括
TensorFlow SavedModel 格式、TensorFlow Hub 格式、Session Bundle
格式等，能够适应不同类型和规模的深度学习模型。</li>
<li>支持多种协议：TensorFlow Serving 支持多种常见的网络协议，包括
gRPC、RESTful API、Apache Kafka、Apache Pulsar
等，能够方便地与其他系统集成，实现模型服务的高效和灵活。</li>
<li>高性能和高可用性：TensorFlow Serving
提供了多种性能优化和扩展机制，包括模型预热、预加载、多线程和多进程等，能够快速响应请求并保证高可用性。</li>
<li>易于部署和管理：TensorFlow Serving 提供了多种部署和管理工具，包括
Docker 容器、Kubernetes、Triton Inference Server
等，能够快速部署和管理模型服务，并支持自动化部署和扩展。</li>
</ol>
<p>通过使用 TensorFlow Serving，用户可以方便地将训练好的 TensorFlow
模型部署到云端或本地服务器上，提供高效、灵活、可扩展的模型服务。TensorFlow
Serving
已广泛应用于各种领域，包括计算机视觉、自然语言处理、语音识别等，是深度学习模型部署和推断的重要基础框架之一。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型名称和路径</span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;mnist&quot;</span></span><br><span class="line">MODEL_BASE_PATH = <span class="string">&quot;./models/mnist&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 TensorFlow Serving</span></span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line">subprocess.Popen([<span class="string">&quot;tensorflow_model_server&quot;</span>, </span><br><span class="line">                  <span class="string">&quot;--port=8500&quot;</span>, </span><br><span class="line">                  <span class="string">&quot;--rest_api_port=8501&quot;</span>, </span><br><span class="line">                  <span class="string">f&quot;--model_name=<span class="subst">&#123;MODEL_NAME&#125;</span>&quot;</span>, </span><br><span class="line">                  <span class="string">f&quot;--model_base_path=<span class="subst">&#123;MODEL_BASE_PATH&#125;</span>&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送推断请求</span></span><br><span class="line">data = np.random.rand(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).tolist()</span><br><span class="line">json_data = &#123;<span class="string">&quot;instances&quot;</span>: data&#125;</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">&quot;content-type&quot;</span>: <span class="string">&quot;application/json&quot;</span>&#125;</span><br><span class="line">url = <span class="string">f&quot;http://localhost:8501/v1/models/<span class="subst">&#123;MODEL_NAME&#125;</span>:predict&quot;</span></span><br><span class="line"></span><br><span class="line">response = requests.post(url, json=json_data, headers=headers)</span><br><span class="line"><span class="built_in">print</span>(response.json())</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
        <category>模型部署</category>
      </categories>
  </entry>
  <entry>
    <title>模型部署（3）部署优化</title>
    <url>/posts/367YBF3/</url>
    <content><![CDATA[<h3><span id="模型部署优化的学习路线是什么">模型部署优化的学习路线是什么？</span></h3>
<ul>
<li>https://segmentfault.com/a/1190000040491572</li>
</ul>
<p>模型部署优化这个方向其实比较宽泛。从模型完成训练，到最终将模型部署到实际硬件上，整个流程中会涉及到很多不同层面的工作，每一个环节对技术点的要求也不尽相同。</p>
<p><strong>部署的流程大致可以分为以下几个环节：</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211425187.png" alt="模型部署流程" style="zoom: 67%;"></p>
<h3><span id="一-模型转换">一、模型转换</span></h3>
<p>从训练框架得到模型后，根据需求转换到相应的模型格式。模型格式的选择通常是根据公司业务端
SDK 的需求，通常为 caffe 模型或 onnx
模型，以方便模型在不同的框架之间适配。该环节的工作需要对相应的训练框架以及
caffe/onnx 等模型格式有所了解。常用的 Pytorch 和 TensorFlow
等框架都有十分成熟的社区和对应的博客或教程；caffe 和 onnx
模型格式也有很多可参考和学习的公开文档。</p>
<p>即使没找到有可参考的文章时，好在二者都是开源的，依然可以通过对源码和样例代码的阅读来寻找答案。</p>
<h3><span id="二-模型优化">二、模型优化</span></h3>
<p>此处的模型优化是指与后端无关的通用优化，比如<strong>常量折叠</strong>、<strong>算数优化</strong>、<strong>依赖优化</strong>、<strong>函数优化</strong>、<strong>算子融合</strong>以及<strong>模型信息简化</strong>等等。</p>
<p>部分训练框架会在训练模型导出时就包含部分上述优化过程，同时如果模型格式进行了转换操作，不同
IR
表示之间的差异可能会引入一些冗余或可优化的计算，因此在模型转换后通常也会进行一部分的模型优化操作。</p>
<p><strong>该环节的工作需要对计算图的执行流程、各个 op
的计算定义、程序运行性能模型有一定了解，才能知道如果进行模型优化，如何保证优化后的模型具有更好的性能。</strong></p>
<p>了解得越深入，越可以挖掘到更多的模型潜在性能。</p>
<h3><span id="三-模型压缩">三、模型压缩</span></h3>
<p>广义上来讲，模型压缩也属于模型优化的一部分。模型压缩本身也包括很多种方法，比如剪枝、蒸馏、量化等等。模型压缩的根本目的是希望获得一个较小的模型，减少存储需求的同时降低计算量，从而达到加速的目的。</p>
<p><strong>该环节的工作需要对压缩算法本身、模型涉及到的算法任务及模型结构设计、硬件平台计算流程三个方面都有一定的了解。</strong></p>
<p>当因模型压缩操作导致模型精度下降时，对模型算法的了解，和该模型在硬件上的计算细节有足够的了解，才能分析出精度下降的原因，并给出针对性的解决方案。</p>
<p><strong>对于模型压缩更重要的往往是工程经验，</strong>
因为在不同的硬件后端上部署相同的模型时，由于硬件计算的差异性，对精度的影响往往也不尽相同，这方面只有通过积累工程经验来不断提升。</p>
<p>OpenPPL也在逐步开源自己的模型压缩工具链，并对上述提到的模型算法、压缩算法和硬件平台适配等方面的知识进行介绍。</p>
<h3><span id="四-模型部署">四、模型部署</span></h3>
<p>模型部署是整个过程中最复杂的环节。从工程上讲，主要的核心任务是<strong>模型打包</strong>、<strong>模型加密</strong>，并进行SDK封装。</p>
<p><strong>在一个实际的产品中，往往会用到多个模型。模型打包是指将模型涉及到的前后处理，以及多个模型整合到一起，并加入一些其他描述性文件。</strong>模型打包的格式和模型加密的方法与具体的
SDK 相关。<strong>在该环节中主要涉及到的技能与 SDK
开发更为紧密。</strong></p>
<p>从功能上讲，对部署最后的性能影响最大的肯定是SDK中包含的后端库，即实际运行模型的推理库。开发一个高性能推理库所需要的技能点就要更为广泛，并且专业。</p>
<p>并行计算的编程思想在不同的平台上是通用的，但不同的硬件架构的有着各自的特点，推理库的开发思路也不尽相同，这也就要求对开发后端的架构体系有着一定的了解。</p>
<p>具体到不同架构的编程学习，建议参考当前各大厂开源的推理库来进一步学习。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>模型部署</category>
      </categories>
  </entry>
  <entry>
    <title>模型部署（5）Treelite加速</title>
    <url>/posts/2SGD3Q6/</url>
    <content><![CDATA[<h2><span id="treelite树模型部署加速工具支持xgboost-lightgbm和sklearn">Treelite：树模型部署加速工具（支持XGBoost、LightGBM和Sklearn）</span></h2>
<h3><span id="一-treelite介绍"><strong>一、TreeLite介绍</strong></span></h3>
<p>TreeLite能够树模型编译优化为单独库，可以很方便的用于模型部署。经过优化后可以将XGBoost模型的预测速度提高2-6倍。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261551831.jpg"></p>
<p>如上图，黑色曲线为XGBoost在不同batch
size下的吞吐量，红色曲线为XGBoost经过TreeLite编译后的吞吐量。</p>
<p>Treelite支持众多的树模型，特别是随机森林和GBDT。同时Treelite可以很好的支持XGBoost,
LightGBM和 scikit-learn，也可以将自定义模型根据要求完成编译。</p>
<h3><span id="二-treelite原理"><strong>二、TreeLite原理</strong></span></h3>
<p><strong>TreeLite主要在两方面完成了改进。</strong></p>
<ul>
<li><p><strong>逻辑分支</strong></p>
<ul>
<li><p>这个指令是<strong>gcc引入</strong>的，作用是<strong>允许程序员将最有可能执行的分支告诉编译器</strong>。这个指令的写法为：<code>__builtin_expect(EXP, N)</code>。意思是：EXP==N的概率很大。【<strong>减少重新取跳转地址</strong>】__builtin_expect
说明: https://www.jianshu.com/p/2684613a300f</p></li>
<li><p><strong>构建树模型+
计算好每个分支下面样本的个数+提前预知哪一个叶子节点被执行的可能性更大，进而可以提前执行子节点逻辑。</strong></p></li>
</ul></li>
<li><p><strong>逻辑比较</strong></p>
<ul>
<li><strong>浮点数比较，转化为整数型比较</strong>。</li>
</ul></li>
</ul>
<h4><span id="21-逻辑分支"><strong>2.1 逻辑分支</strong></span></h4>
<p>对于树模型而言，节点的分类本质使用if语句完成，而CPU在执行if语句时会等待条件逻辑的计算。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> ( [conditional expression] ) &#123;</span><br><span class="line">  <span class="built_in">foo</span>();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="built_in">bar</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>如果在构建树模型时候，提前计算好每个分支下面样本的个数，则可以提前预知哪一个叶子节点被执行的可能性更大，进而可以提前执行子节点逻辑。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211426056.jpg" alt="img" style="zoom: 67%;"></p>
<p>借助于编译命令，可以完成逻辑计算加速。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* expected to be false */</span></span><br><span class="line"><span class="keyword">if</span>( __builtin_expect([condition],<span class="number">0</span>))&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="22-逻辑比较">2.2 逻辑比较</span></h4>
<p>原始的分支比较可能会有浮点数比较逻辑，可以量化为数值比较逻辑。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (data[<span class="number">3</span>].fvalue &lt; <span class="number">1.5</span>) &#123;  </span><br><span class="line"><span class="comment">/* floating-point comparison */</span></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (data[<span class="number">3</span>].qvalue &lt; <span class="number">3</span>) &#123;     </span><br><span class="line"><span class="comment">/* integer comparison */</span></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><p>项目链接：<a href="https://link.zhihu.com/?target=https%3A//treelite.readthedocs.io/">https://treelite.readthedocs.io/</a></p></li>
<li><p>项目论文：<a href="https://link.zhihu.com/?target=https%3A//mlsys.org/Conferences/doc/2018/196.pdf">https://mlsys.org/Conferences/doc/2018/196.pdf</a></p></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>模型部署</category>
      </categories>
  </entry>
  <entry>
    <title>模型部署（1）【draft】概述</title>
    <url>/posts/32RS544/</url>
    <content><![CDATA[<h3><span id="机器学习一模型训练及线上部署相关笔记">机器学习（一）：模型训练及线上部署相关笔记</span></h3>
<p>https://www.shangmayuan.com/a/2331a95928b344d782ac08ac.html</p>
<ul>
<li>GBDT+LR模型训练及线上部署</li>
<li>Java调用jpmml类</li>
</ul>
<h3><span id="一-离线模型offline">一、离线模型(Offline)</span></h3>
<p>离线模型存在于很多业务场景中，其中最常见的业务场景就是用在推荐系统的召回阶段，由于在推荐系统中，<strong>召回并不要求是实时的</strong>，可以根据业务的需要，调整成每天一次，或者每几个小时跑一次即可，因此，这类的模型，一般我们只需要使用<strong>Linux下的crontab定时任务脚本</strong>，每隔一段时间来启动一次就可以，然后将log文件输出到指定的文件下即可。这种方式一般来讲仅限离线模型的部署，其本质上就是一段定时任务的代码。</p>
<h3><span id="二-在线online近似在线nearline模型">二、在线(Online)/近似在线(NearLine)模型</span></h3>
<p>在生产系统中，实时推理和预测是最常见的需求，也是对于很多深度学习模型来说所必须达到的点。下面简介一些深度学习模型在实时预测时常见的几种部署方法：</p>
<h4><span id="21将模型预测直接打包成http接口">2.1
将模型预测直接打包成http接口</span></h4>
<p>将模型直接打包成一个http接口的形式是在企业中比较常见的模型上线的方式，<strong>所谓的将预测直接打包成http接口实际上一般是指将我们训练好的模型直接在线上进行预测</strong>。我们来试想一个场景，当一个模型训练好之后，我们如果想要验证这个模型的好坏，我们首先能想到的办法就是找一批数据来测试一下。实际上，将模型预测直接打包成http接口也是利用了这样的思路。</p>
<p>在这里，我们可以<strong>将训练好的模型提前进行加载，并初始化若干个消息队列和worker，当有新的待预测数据进入的时候，我们直接将数据通过消息队列传入到模型中进行推理和预测，最终得到结果。</strong></p>
<p>而<strong>对于外层接收输入，我们一般可以将接收的地方使用flask打包成一个http接口，等待传入即可。</strong></p>
<p>使用这种方式直接打包成http接口的好处在于打包和部署相对比较方便，对于一些相对比较<strong>轻量级且对并发量要求不是很高的情况下相对还是比较好用的。使用值得注意的是，如果对于一个相对比较大的模型来讲，这种方式推理的时间相对就会比较长，从用户输入到结果返回可能需要200ms左右。</strong></p>
<h4><span id="22-pmml">2.2 PMML</span></h4>
<blockquote>
<p>使用PMML部署机器学习模型 : https://zhuanlan.zhihu.com/p/79197337</p>
</blockquote>
<p>PMML (Predictive Model Markup Language)
是一套通用的且与平台和环境无关的模型表示语言，<strong>机器学习在模型部署方面的一种标准部署方案，其形式是采用XML语言标记形式</strong>。我们可以将自己训练的机器学习模型打包成PMML模型文件的形式，然后使用目标环境的解析PMML模型的库来完成模型的加载并做预测。PMML是一套基于XML的标准，通过
XML Schema 定义了使用的元素和属性，主要由以下核心部分组成：</p>
<p><strong>数据字典（Data Dictionary）</strong>，描述输入数据。</p>
<p><strong>数据转换（Transformation Dictionary和Local
Transformations）</strong>，应用在输入数据字段上生成新的派生字段。</p>
<p><strong>模型定义 （Model）</strong>，每种模型类型有自己的定义。</p>
<p><strong>输出（Output）</strong>，指定模型输出结果。</p>
<p>目前，大部分机器学习库都支持直接打包成PMML模型文件的相关函数，例如在Python中的LightGBM库，XGBoost库，Keras库等，都有对PMML的支持，直接使用相应的命令就可以生成，而在Java、R等语言中，也有相关的库可以进行PMML文件生成的命令。一般来讲，使用PMML文件进行预测的过程如下：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261553349.jpg" alt="img" style="zoom: 50%;"></p>
<p><strong>由于其平台无关性，导致PMML可以实现跨平台部署，是企业中部署机器学习模型的常见解决方案。</strong></p>
<h4><span id="23-tensorflow-serving">2.3 TensorFlow Serving</span></h4>
<p>使用TensorFlow Serving进行服务部署，一般需要2台以上机器。</p>
<ul>
<li>其中一台作为TensorFlow
Serving的服务器，这台服务器是专门来做模型部署和预测用，对于这台服务器，一般建议使用GPU服务器，这样会使整个推理预测的过程变得很快；</li>
<li>另外一台服务器是业务服务器，也就是接收用户的输入以及其他业务处理的服务器。我们可以把模型部署到TensorFlow
Serving的服务器上，而一般我们只需要先在服务器上使用docker创建一个TensorFlow
Serving服务，然后将模型文件上传上去，当有请求进来的时候，业务服务会直接对模型所在的服务器发起服务调用，并得到模型预测的结果。</li>
</ul>
<h3><span id="三-实际用时的一些部署方法组合">三、实际用时的一些部署方法组合</span></h3>
<h4><span id="31-rpmmlsparkairflow调度">3.1 R+pmml+spark+airflow调度</span></h4>
<p>用R语言训练模型并转为pmml文件，然后使用spark将这个pmml文件封装为jar，使用airflow提交到yarn。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">val is: InputStream = fs.open(path)</span><br><span class="line"></span><br><span class="line">val pmml: PMML = PMMLUtil.unmarshal(is)</span><br><span class="line"></span><br><span class="line">modelEvaluator = ModelEvaluatorFactory.newInstance.newModelEvaluator(pmml)</span><br></pre></td></tr></table></figure>
<h4><span id="32-pythonsklearnairflow调度">3.2 python+sklearn+airflow调度</span></h4>
<p>使用python训练好sklearn模型，并joblib.dumps()保存，然后在python文件中joblib.load()加载改文件，使用airflow离线调度。</p>
<h4><span id="33-xgboostsparkxgb4j">3.3 xgboost+spark+xgb4j</span></h4>
<ul>
<li>使用分布式的<strong>spark版的xgboost</strong>，训练好的模型直接保存为model.booster.saveModel(hdfsOutStream)二进制文件.然后<strong>xgboost4j加载该文件XGBoost.loadModel(is)实现线上实时预测</strong>。</li>
</ul>
<h4><span id="34tensorflowtensorflow的java库">3.4
tensorflow+tensorflow的java库</span></h4>
<h3><span id="四-不同需求对应的不同平台部署方案">四、不同需求对应的不同平台部署方案</span></h3>
<h5><span id="1-放到服务器上跑要求吞吐和时延重点是吞吐这种应用在互联网企业居多一般是互联网产品的后端ai计算例如人脸验证-语音服务-应用了深度学习的智能推荐等">1、放到服务器上跑，要求吞吐和时延（重点是吞吐）这种应用在互联网企业居多，一般是互联网产品的后端AI计算，例如人脸验证、语音服务、应用了深度学习的智能推荐等。</span></h5>
<p>由于一般是大规模部署，这时不仅仅要考虑吞吐和时延，还要考虑功耗和成本。所以除了软件外，硬件也会下功夫，比如使用推理专用的NVIDIA
P4、寒武纪MLU100等。这些推理卡比桌面级显卡功耗低，单位能耗下计算效率更高，且硬件结构更适合高吞吐量的情况软件上，一般都不会直接上深度学习框架。对于NVIDIA的产品，一般都会使用TensorRT来加速（不仅可以加速前传，还包含调度功能）。TensorRT用了CUDA、CUDNN，而且还有<strong>图优化、fp16、int8量化</strong>等。</p>
<h3><span id="五-模型部署时一些常用的trick">五、模型部署时一些常用的trick</span></h3>
<h4><span id="51-模型压缩">5.1 模型压缩</span></h4>
<p>基于参数修剪和共享的方法针对模型参数的冗余性，试图去除冗余和不重要的项。基于低秩因子分解的技术使用矩阵/张量分解来估计深度学习模型的信息参数。基于传输/紧凑卷积滤波器的方法设计了特殊的结构卷积滤波器来降低存储和计算复杂度。知识蒸馏方法通过学习一个蒸馏模型，训练一个更紧凑的神经网络来重现一个更大的网络的输出。</p>
<p>一般来说，参数修剪和共享，低秩分解和知识蒸馏方法可以用于全连接层和卷积层的CNN，但另一方面，使用转移/紧凑型卷积核的方法仅支持卷积层。低秩因子分解和基于转换/紧凑型卷积核的方法提供了一个端到端的流水线，可以很容易地在CPU/GPU环境中实现。相反参数修剪和共享使用不同的方法，如矢量量化，二进制编码和稀疏约束来执行任务，这导致常需要几个步骤才能达到目标。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>模型部署</category>
      </categories>
  </entry>
  <entry>
    <title>模型部署（4）DaaS-Client</title>
    <url>/posts/3FG16R6/</url>
    <content><![CDATA[<h2><span id="how自动部署开源ai模型到生产环境">HOW
自动部署开源AI模型到生产环境？</span></h2>
<h3><span id="一-背景介绍">一、背景介绍</span></h3>
<p>AI的广泛应用是由AI在开源技术的进步推动的，利用功能强大的开源模型库，数据科学家们可以很容易的训练一个性能不错的模型。但是因为模型生产环境和开发环境的不同，涉及到不同角色人员：模型训练是数据科学家和数据分析师的工作，但是模型部署是开发和运维工程师的事情，导致模型上线部署却不是那么容易。</p>
<p><strong>DaaS（Deployment-as-a-Service）是AutoDeployAI公司推出的基于Kubernetes的AI模型自动部署系统，提供一键式自动部署开源AI模型生成REST
API，以方便在生产环境中调用</strong>。下面，我们主要演示在DaaS中如何部署经典机器学习模型，包括<strong>Scikit-learn、XGBoost、LightGBM、和PySpark
ML Pipelines</strong>。关于深度学习模型的部署，会在下一章中介绍。</p>
<p><strong>DMatrix 格式</strong>
在xgboost当中运行速度更快，性能更好。</p>
<h3><span id="二-部署准备">二、部署准备</span></h3>
<p>我们使用DaaS提供的Python客户端（DaaS-Client）来部署模型，对于XGBoost和LightGBM，我们同样使用它们的Python
API来作模型训练。在训练和部署模型之前，我们需要完成以下操作。</p>
<ul>
<li><strong>安装Python DaaS-Client</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install --upgrade git+https://github.com/autodeployai/daas-client.git</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>初始化DaasClient</strong>。使用DaaS系统的URL、账户、密码登陆系统，文本使用的DaaS演示系统安装在本地的Minikube上。完整Jupyter
Notebook，请参考：<a href="https://github.com/aipredict/ai-deployment/blob/master/deploy-ai-models-in-daas/deploy-sklearn-xgboost-lightgbm-pyspark.ipynb">deploy-sklearn-xgboost-lightgbm-pyspark.ipynb</a></li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">from daas_client import DaasClient</span><br><span class="line"></span><br><span class="line">client = DaasClient(&#x27;https://192.168.64.3:30931&#x27;, &#x27;username&#x27;, &#x27;password&#x27;)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>创建项目</strong>。DaaS使用项目管理用户不同的分析任务，一个项目中可以包含用户的各种分析资产：模型、部署、程序脚本、数据、数据源等。项目创建成功后，设置为当前活动项目，发布的模型和创建的部署都会存储在该项目下。<code>create_project</code>函数接受三个参数：
<ul>
<li><strong>项目名称</strong>：可以是任意有效的Linux文件目录名。</li>
<li><strong>项目路由</strong>：使用在部署的REST
URL中来唯一表示当前项目，只能是小写英文字符(a-z)，数字(0-9)和中横线<code>-</code>，并且<code>-</code>不能在开头和结尾处。</li>
<li><strong>项目说明</strong>（可选）：可以是任意字符。</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">project = <span class="string">&#x27;部署测试&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> client.project_exists(project):</span><br><span class="line">    client.create_project(project, <span class="string">&#x27;deployment-test&#x27;</span>, <span class="string">&#x27;部署测试项目&#x27;</span>)</span><br><span class="line">client.set_project(project)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>初始化数据</strong>。我们使用流行的分类数据集<code>iris</code>来训练不同的模型，并且把数据分割为训练数据集和测试数据集以方便后续使用。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">seed = <span class="number">123456</span></span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris_target_name = <span class="string">&#x27;Species&#x27;</span></span><br><span class="line">iris_feature_names = iris.feature_names</span><br><span class="line">iris_df = pd.DataFrame(iris.data, columns=iris_feature_names)</span><br><span class="line">iris_df[iris_target_name] = iris.target</span><br><span class="line"></span><br><span class="line">X, y = iris_df[iris_feature_names], iris_df[iris_target_name]</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=seed)    </span><br></pre></td></tr></table></figure>
<ul>
<li><strong>模型部署流程。主要包含以下几步</strong>：
<ul>
<li><strong>训练模型</strong>。使用模型库提供的API，在<code>iris</code>数据集上训练模型。</li>
<li><strong>发布模型</strong>。调用<code>publish</code>函数发布模型到DaaS系统。</li>
<li><strong>测试模型</strong>（可选）。调用<code>test</code>函数获取测试API信息，可以使用任意的REST客户端程序测试模型在DaaS中是否工作正常，使用的是DaaS系统模型测试API。第一次执行<code>test</code>会比较慢，因为DaaS系统需要启动测试运行时环境。</li>
<li><strong>部署模型</strong>。发布成功后，调用<code>deploy</code>函数部署部署模型。可以使用任意的REST客户端程序测试模型部署，使用的是DaaS系统正式部署API。</li>
</ul></li>
</ul>
<h3><span id="三-部署scikit-learn模型">三、部署Scikit-learn模型</span></h3>
<ul>
<li><strong>训练一个Scikit-learn分类模型</strong>：SVC</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line">model = SVC(probability=<span class="literal">True</span>, random_state=seed)</span><br><span class="line">model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>发布Scikit-learn模型</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">publish_resp = client.publish(model,</span><br><span class="line">                            name=<span class="string">&#x27;iris&#x27;</span>,</span><br><span class="line">                            mining_function=<span class="string">&#x27;classification&#x27;</span>,</span><br><span class="line">                            X_test=X_test,</span><br><span class="line">                            y_test=y_test,</span><br><span class="line">                            description=<span class="string">&#x27;A SVC model&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>test</strong>函数必须要指定前两个参数，第一个<strong>model</strong>是训练的模型对象，第二个是模型名称，其余是可选参数：</p>
<ul>
<li><strong>mining_function</strong>：指定挖掘功能，可以指定为<code>regression</code>（回归）、<code>classification</code>（分类）、和<code>clustering</code>（聚类）。</li>
<li><strong>X_test和y_test</strong>：指定测试训练集，发布时计算模型评估指标，比如针对分类模型，计算正确率（Accuracy），对于回归模型，计算可释方差（explained
Variance）。</li>
<li><strong>data_test</strong>：
同样是指定测试训练集，但是该参数用在Spark模型上，非Spark模型通过<code>X_test</code>和<code>y_test</code>指定。</li>
<li><strong>description</strong>：模型描述。</li>
<li><strong>params</strong>：记录模型参数设置。</li>
</ul>
<p><strong>publish_resp</strong>是一个字典类型的结果，记录了模型名称，和发布的模型版本。该模型是<code>iris</code>模型的第一个版本。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;model_name&#x27;<span class="punctuation">:</span> &#x27;iris&#x27;<span class="punctuation">,</span> &#x27;model_version&#x27;<span class="punctuation">:</span> &#x27;<span class="number">1</span>&#x27;<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>测试Scikit-learn模型</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_resp = client.test(publish_resp[<span class="string">&#x27;model_name&#x27;</span>],</span><br><span class="line">                        model_version=publish_resp[<span class="string">&#x27;model_version&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p><code>test_resp</code>是一个字典类型的结果，记录了测试REST
API信息。如下，其中<code>access_token</code>是访问令牌，一个长字符串，这里没有显示出来。<code>endpoint_url</code>指定测试REST
API地址，<code>payload</code>提供了测试当前模型需要输入的请求正文格式。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">      &#x27;access_token&#x27;<span class="punctuation">:</span> &#x27;A-LONG-STRING-OF-BEARER-TOKEN-USED-IN-HTTP-HEADER-AUTHORIZATION&#x27;<span class="punctuation">,</span></span><br><span class="line">			&#x27;endpoint_url&#x27;<span class="punctuation">:</span> &#x27;https<span class="punctuation">:</span><span class="comment">//192.168.64.3:30931/api/v1/test/deployment-test/daas-python37-faas/test&#x27;,</span></span><br><span class="line">			&#x27;payload&#x27;<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      				&#x27;args&#x27;<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">              			&#x27;X&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span> &#x27;petal length (cm)&#x27;<span class="punctuation">:</span> <span class="number">1.5</span><span class="punctuation">,</span></span><br><span class="line">                            &#x27;petal width (cm)&#x27;<span class="punctuation">:</span> <span class="number">0.4</span><span class="punctuation">,</span></span><br><span class="line">                            &#x27;sepal length (cm)&#x27;<span class="punctuation">:</span> <span class="number">5.7</span><span class="punctuation">,</span></span><br><span class="line">                            &#x27;sepal width (cm)&#x27;<span class="punctuation">:</span> <span class="number">4.4</span></span><br><span class="line">                          <span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">               &#x27;model_name&#x27;<span class="punctuation">:</span> &#x27;iris&#x27;<span class="punctuation">,</span></span><br><span class="line">               &#x27;model_version&#x27;<span class="punctuation">:</span> &#x27;<span class="number">1</span>&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>使用requests调用测试API，这里我们直接使用<strong>test_resp</strong>返回的测试payload，您也可以使用自定义的数据<code>X</code>，但是参数<code>model_name</code>和<code>model_version</code>必须使用上面输出的值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">response = requests.post(test_resp[<span class="string">&#x27;endpoint_url&#x27;</span>],</span><br><span class="line">                        headers=&#123;</span><br><span class="line">      <span class="string">&#x27;Authorization&#x27;</span>: <span class="string">&#x27;Bearer &#123;token&#125;&#x27;</span>.<span class="built_in">format</span>(token=test_resp[<span class="string">&#x27;access_token&#x27;</span>])&#125;,</span><br><span class="line">                        json=test_resp[<span class="string">&#x27;payload&#x27;</span>],</span><br><span class="line">                        verify=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>返回结果，不同于正式部署API，除了预测结果，测试API会同时返回标准控制台输出和标准错误输出内容，以方便用户碰到错误时，查看相关信息。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"># response.json()</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">      &#x27;result&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span></span><br><span class="line">      &#x27;PredictedValue&#x27;<span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">            &#x27;Probabilities&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span><span class="number">0.8977133931668801</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="number">0.05476023239878367</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="number">0.047526374434336216</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">			&#x27;stderr&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">			&#x27;stdout&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h3><span id="四-部署pyspark模型">四、部署PySpark模型</span></h3>
<p><strong>训练一个PySpark分类模型</strong>：RandomForestClassifier。PySpark模型必须是一个<code>PipelineModel</code>，也就是说必须使用Pipeline来建立模型，哪怕只有一个Pipeline节点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.getOrCreate()</span><br><span class="line">df = spark.createDataFrame(iris_df)</span><br><span class="line"></span><br><span class="line">df_train, df_test = df.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>], seed=seed)</span><br><span class="line">assembler = VectorAssembler(inputCols=iris_feature_names,</span><br><span class="line">                            outputCol=<span class="string">&#x27;features&#x27;</span>)</span><br><span class="line"></span><br><span class="line">rf = RandomForestClassifier(seed=seed).setLabelCol(iris_target_name)</span><br><span class="line">pipe = Pipeline(stages=[assembler, rf])</span><br><span class="line">model = pipe.fit(df_train)</span><br></pre></td></tr></table></figure>
<p><strong>发布PySpark模型</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">publish_resp = client.publish(model,</span><br><span class="line">                            name=<span class="string">&#x27;iris&#x27;</span>,</span><br><span class="line">                            mining_function=<span class="string">&#x27;classification&#x27;</span>,</span><br><span class="line">                            data_test=df_test,</span><br><span class="line">                            description=<span class="string">&#x27;A RandomForestClassifier of Spark model&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3><span id="五-模型部署管理">五、模型部署管理</span></h3>
<p>打开浏览器，登陆DaaS管理系统。进入项目<code>部署测试</code>，切换到<code>模型</code>标签页，有一个<code>iris</code>模型，最新版本是<code>v4</code>，类型是<code>Spark</code>即我们最后发布的模型。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261549637.jpeg" alt="Daas-models" style="zoom: 33%;"></p>
<p>点击模型，进入模型主页（概述）。当前<code>v4</code>是一个Spark
Pipeline模型，正确率是94.23%，并且显示了<code>iris</code>不同版本正确率历史图。下面罗列了模型的输入和输出变量，以及评估结果，当前为空，因为还没有在DaaS中执行任何的模型评估任务。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261549145.jpeg" alt="Daas-model-overview-v4" style="zoom: 50%;"></p>
<p>点击<code>v4</code>，可以自由切换到其他版本。比如，切换到<code>v1</code>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261549781.png" alt="DaaS-model-versions" style="zoom:50%;"></p>
<p><code>v1</code>版本是一个Scikit-learn
SVM分类模型，正确率是98.00%。其他信息与<code>v4</code>类似。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261549645.jpeg" alt="DaaS-model-overview-v1" style="zoom:50%;"></p>
<p>切换到模型<code>部署</code>标签页，有一个我们刚才创建的部署<code>iris-svc</code>，鼠标移动到操作菜单，选择<code>修改设置</code>。可以看到，当前部署服务关联的是模型<code>v1</code>，就是我们刚才通过<code>deploy</code>函数部署的<code>iris</code>第一个版本Scikit-learn模型。选择最新的<code>v4</code>，点击命令<code>保存并且重新部署</code>，该部署就会切换到<code>v4</code>版本。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>DaaS-Client、Sklearn、XGBoost、LightGBM、和PySpark_关注 AI/ML
模型上线、模型部署-程序员宅基地_</li>
<li>DaaS-Client：https://github.com/autodeployai/daas-client</li>
<li>3万字长文
PySpark入门级学习教程，框架思维:https://zhuanlan.zhihu.com/p/395431025</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>模型部署</category>
      </categories>
  </entry>
  <entry>
    <title>模型部署（6）XGBoost4J</title>
    <url>/posts/1EHVYXP/</url>
    <content><![CDATA[<h3><span id="分布式-xgboost4j-spark基本原理">分布式 XGBoost4J - Spark
基本原理</span></h3>
<p><strong>XGBoost4J-Spark</strong>是一个项目，旨在通过使XGBoost适应Apache
Spark的MLLIB框架，无缝集成XGBoost和Apache
Spark。通过集成，用户不仅可以使用XGBoost的高性能算法实现，还可以利用Spark强大的数据处理引擎实现以下功能：</p>
<ul>
<li>特征工程：特征提取，变换，降维和选择等。</li>
<li>管道：构造，评估和调整ML管道</li>
<li>持久性：持久化并加载机器学习模型，甚至整个管道</li>
</ul>
<p>本文将介绍使用XGBoost4J-Spark构建机器学习管道的端到端过程。讨论</p>
<ul>
<li>使用Spark预处理数据以适合XGBoost / XGBoost4J-Spark的数据接口</li>
<li>使用XGBoost4J-Spark训练XGBoost模型</li>
<li>使用Spark服务XGBoost模型（预测）</li>
<li>使用XGBoost4J-Spark构建机器学习管道</li>
<li>在生产中运行XGBoost4J-Spark</li>
</ul>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/390643240">模型上线之模型即服务（三）自动上线框架</a></p></li>
<li><p><a href="https://zhuanlan.zhihu.com/p/351495832">机器学习中的并行计算</a></p></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>模型部署</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（1）【draft】数据清洗</title>
    <url>/posts/P9Y8FT/</url>
    <content><![CDATA[<h3><span id="一-特征工程-数据清洗">一、特征工程-数据清洗</span></h3>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261223770.jpg" alt="img" style="zoom: 67%;"></p>
<p>数据格式内容错误数据来源有多种，有些是传感器采集，然后算法提取的特征数据；有些是采集的控制器的数据；还有一些应用场合，则是用户/访客产生的，数据肯定存在格式和内容上不一致的情况，所以在进行模型构建之前需要先进行数据的格式内容清洗操作。逻辑错误清洗主要是通过简单的逻辑推理发现数据中的问题数据，防止分析结果走偏，主要包含以下几个步骤：</p>
<p><strong><em>1.数据去重，去除或替换不合理的值；</em></strong></p>
<p><strong><em>2.去除或重构不可靠的字段值（修改矛盾的内容）；</em></strong></p>
<p><strong><em>3.去除异常点数据。</em></strong></p>
<h3><span id="二-采样">二、采样</span></h3>
<p>随机采样方法整理与讲解（MCMC、Gibbs Sampling等） - 向阳树的文章 -
知乎 https://zhuanlan.zhihu.com/p/109978580</p>
<h3><span id="三-参考文献">三、参考文献</span></h3>
<ul>
<li><p>特征工程 - 未来达摩大师的文章 - 知乎
https://zhuanlan.zhihu.com/p/476659737</p></li>
<li><p>这9个特征工程使用技巧，解决90%机器学习问题！ -
Python与数据挖掘的文章 - 知乎
https://zhuanlan.zhihu.com/p/462744763</p></li>
<li><p>有哪些精彩的特征工程案例？ - 京东科技风险算法与技术的回答 - 知乎
https://www.zhihu.com/question/400064722/answer/1308358333</p></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（2）特征预处理</title>
    <url>/posts/XGJYS5/</url>
    <content><![CDATA[<h3><span id="特征工程-特征处理">特征工程-特征处理</span></h3>
<h3><span id="一-数值类型处理">一、 数值类型处理</span></h3>
<blockquote>
<p><strong>pandas 显示所有列：</strong></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#显示所有列</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment">#显示所有行</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_rows&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment">#设置value的显示长度为100，默认为50</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;max_colwidth&#x27;</span>,<span class="number">100</span>)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p><strong>pandas 查看缺失特征:</strong></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train.isnull().<span class="built_in">sum</span>().sort_values(ascending = <span class="literal">False</span>) / train.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p>
<p><strong>pandas 查看某一列的分布:</strong></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.loc[:,col_name].value_counts()</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p><strong>特征提取方式是可以深挖隐藏在数据背后更深层次的信息的</strong>。其次，数值类型数据也并不是直观看上去那么简单易用，因为不同的数值类型的计量单位不一样，比如个数、公里、千克、DB、百分比之类，同样数值的大小也可能横跨好几个量级，比如小到头发丝直径约为0.00004米，
大到热门视频播放次数成千上万次。</p>
<h4><span id="11-数据归一化">1.1 数据归一化</span></h4>
<blockquote>
<p><strong>为什么要数据归一化？</strong></p>
<p><a href="../../AI深度学习/深度学习（3）Normalization*.md">深度学习（3）Normalization*.md</a></p>
<ul>
<li><strong>可解释性</strong>：<strong>回归模型【无正则化】</strong>中自变量X的量纲不一致导致了<strong>回归系数无法直接解读</strong>或者错误解读；需要将X都处理到统一量纲下，这样才可比【可解释性】；<strong>取决于我们的逻辑回归是不是用了正则化</strong>。如果你不用正则，标准化并不是必须的，如果用正则，那么标准化是必须的。</li>
<li><strong>距离计算</strong>：机器学习任务和统计学任务中有很多地方要用到<strong>“距离”的计算</strong>，比如<strong>PCA、KNN，kmeans和SVM</strong>等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果；</li>
<li><strong>加速收敛</strong>：参数估计时使用<strong>梯度下降</strong>，在使用梯度下降的方法求解最优化问题时，
归一化/标准化后可以加快梯度下降的求解速度，即<strong>提升模型的收敛速度</strong>。</li>
</ul>
<p><strong>需要归一化的模型：</strong>利用梯度下降法求解的模型一般需要归一化，<strong>线性回归、LR、SVM、KNN、神经网络</strong></p>
</blockquote>
<p><span class="math display">\[
\tilde{x}=\frac{x-\min (x)}{\max (x)-\min (x)}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># define data </span></span><br><span class="line">data = np.asarray([[<span class="number">100</span>, <span class="number">0.001</span>], </span><br><span class="line">                   [<span class="number">8</span>, <span class="number">0.05</span>], </span><br><span class="line">                   [<span class="number">50</span>, <span class="number">0.005</span>], </span><br><span class="line">                   [<span class="number">88</span>, <span class="number">0.07</span>], </span><br><span class="line">                   [<span class="number">4</span>, <span class="number">0.1</span>]])</span><br><span class="line"><span class="comment"># define min max scaler</span></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line"><span class="comment"># transform data</span></span><br><span class="line">scaled = scaler.fit_transform(data) </span><br></pre></td></tr></table></figure>
<h4><span id="12-数据标准化">1.2 数据标准化</span></h4>
<p>数据标准化是指通过改变数据的分布得到均值为0，标准差为1的服从标准正态分布的数据。主要目的是为了让不同特征之间具有相同的尺度（Scale），这样更有理化模型训练收敛。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="comment"># define standard scaler</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line"><span class="comment"># transform data</span></span><br><span class="line">scaled = scaler.fit_transform(data) </span><br><span class="line"><span class="built_in">print</span>(scaled)</span><br></pre></td></tr></table></figure>
<h4><span id="13-对数转换">1.3 对数转换</span></h4>
<p><span class="math inline">\(\log\)</span> 函数的定义为 <span class="math inline">\(\log _a\left(\alpha^x\right)=x\)</span>, 其中
<span class="math inline">\(\mathrm{a}\)</span> 是 <span class="math inline">\(\log\)</span> 函数的底数, <span class="math inline">\(\alpha\)</span> 是一个正常数, <span class="math inline">\(x\)</span> 可以是任何正数。由于 <span class="math inline">\(\alpha^0=1\)</span> <span class="math inline">\(a=10\)</span> 时, 函数 <span class="math inline">\(\log _{10}(x)\)</span> 可以将 <span class="math inline">\([1,10]\)</span> 映射到[ <span class="math inline">\([0,1]\)</span>, 将 <span class="math inline">\([1,100]\)</span> 映射到 <span class="math inline">\([1,2]\)</span> 。换句话说,
<strong>log函数压缩了大数的范 围, 扩大了小数的范围</strong>。 <span class="math inline">\(\mathrm{x}\)</span> 越大, <span class="math inline">\(\log (\mathrm{x})\)</span> 增量越慢。 <span class="math inline">\(\log (\mathrm{x})\)</span> 函数的图像如下:</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261226003.png" alt="image-20220426154119370" style="zoom: 25%;"></p>
<p><strong>Log函数可以极大压缩数值的范围，相对而言就扩展了小数字的范围。该转换方法适用于长尾分布且值域范围很大的特征，变换后的特征趋向于正态分布。</strong>对数值类型使用对数转换一般有以下几种好处：</p>
<ul>
<li>缩小数据的绝对数值</li>
<li>取对数后，可以将乘法计算转换成加法计算</li>
<li>在数据的整个值域中不同区间的差异带来的影响不同</li>
<li>取对数后不会改变数据的性质和相关关系，但压缩了变量的尺度。</li>
<li>得到的数据易消除异方差问题</li>
</ul>
<h3><span id="二-序数和类别特征处理">二、序数和类别特征处理</span></h3>
<p>本文主要说明特征工程中关于<strong>序数特征</strong>和<strong>类别特征</strong>的常用处理方法。主要包含<strong>LabelEncoder</strong>、<strong>One-Hot编码</strong>、<strong>DummyCoding</strong>、<strong>FeatureHasher</strong>以及要重点介绍的<strong>WOE编码</strong>。</p>
<h4><span id="21-序数特征处理">2.1 序数特征处理</span></h4>
<p><strong>序数特征指的是有序但无尺度的特征</strong>。比如表示‘学历’的特征，'高中'、'本科'、'硕士'，这些特征彼此之间是有顺序关系的，但是特征本身无尺度，并且也可能不是数值类型。在实际应用中，一般是字符类型居多，为了将其转换成模型能处理的形式，通常需要先进行编码，比如LabelEncoding。如果序数特征本身就是数值类型变量，则可不进行该步骤。下面依次介绍序数特征相关的处理方式。</p>
<ul>
<li><h4><span id="label-encoding">Label Encoding</span></h4></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">x = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">encoder = LabelEncoder()</span><br><span class="line">x1 = encoder.fit_transform(x)</span><br><span class="line"></span><br><span class="line">x2 = pd.Series(x).astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">x2.cat.codes.values</span><br><span class="line"><span class="comment"># pandas 因子化</span></span><br><span class="line">x2, uniques = pd.factorize(x)</span><br><span class="line"><span class="comment"># pandas 二值化</span></span><br><span class="line">x2 = pd.Series(x)</span><br><span class="line">x2 = (x2 &gt;= <span class="string">&#x27;b&#x27;</span>).astype(<span class="built_in">int</span>) <span class="comment">#令大于等于&#x27;b&#x27;的都为1</span></span><br></pre></td></tr></table></figure>
<h4><span id="22-类别特征处理">2.2 类别特征处理</span></h4>
<p><strong>类别特征由于没有顺序也没有尺度</strong>，因此处理较为麻烦，但是在CTR等领域却是非常常见的特征。比如<strong>商品的类型，颜色，用户的职业，兴趣</strong>等等。类别变量编码方法中最常使用的就是<strong>One-Hot编码</strong>，接下来结合具体实例来介绍。</p>
<ul>
<li><h4><span id="one-hot编码">One-Hot编码</span></h4></li>
</ul>
<p>One-Hot编码，又称为'独热编码'，其变换后的单列特征值只有一位是1。如下例所示，一个特征中包含3个不同的特征值(a,b,c)，编码转换后变成3个子特征，其中每个特征值中只有一位是有效位1。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, OneHotEncoder</span><br><span class="line"></span><br><span class="line">one_feature = [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">feature = label_encoder.fit_transform(one_feature)</span><br><span class="line">onehot_encoder = OneHotEncoder(sparse=<span class="literal">False</span>)</span><br><span class="line">onehot_encoder.fit_transform(feature.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<ul>
<li><h4><span id="labelbinarizer">LabelBinarizer</span></h4></li>
</ul>
<p>sklearn中的LabelBinarizer也具有同样的作用，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line">feature = np.array([<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">LabelBinarizer().fit_transform(feature)</span><br></pre></td></tr></table></figure>
<ul>
<li><h4><span id="虚拟编码dummy-coding">虚拟编码Dummy Coding</span></h4></li>
</ul>
<p>同样，<strong>pandas中也内置了对应的处理方式,使用起来比Sklearn更加方便</strong>，产生n-1个特征。实例如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">one_feature = [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">pd.get_dummies(one_feature, prefix=<span class="string">&#x27;test&#x27;</span>) <span class="comment"># 设置前缀test</span></span><br></pre></td></tr></table></figure>
<ul>
<li><h4><span id="特征哈希feature-hashing"><strong><font color="red">
特征哈希（feature hashing）</font></strong></span></h4></li>
</ul>
<p>按照上述编码方式，如果某个特征具有100个类别值，那么经过编码后将产生100个或99个新特征，这极大地增加了特征维度和特征的稀疏度，同时还可能会出现内存不足的情况。<strong>sklearn中的FeatureHasher接口采用了hash的方法，将不同的值映射到用户指定长度的数组中，使得输出特征的维度是固定的，该方法占用内存少，效率高，可以在多类别变量值中使用，但是由于采用了Hash函数的方式，所以具有冲突的可能，即不同的类别值可能映射到同一个特征变量值中。</strong></p>
<blockquote>
<p>Feature hashing(特征哈希):
https://blog.csdn.net/laolu1573/article/details/79410187</p>
<p>https://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing</p>
<p><a href="https://www.zhihu.com/question/264165760/answer/277634591">如何用通俗的语言解释CTR和推荐系统中常用的<em>Feature</em>
<em>Hashing</em>技术以及其对应的优缺点？</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> FeatureHasher</span><br><span class="line"></span><br><span class="line">h = FeatureHasher(n_features=<span class="number">5</span>, input_type=<span class="string">&#x27;string&#x27;</span>)</span><br><span class="line">test_cat = [<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;e&#x27;</span>,<span class="string">&#x27;f&#x27;</span>,<span class="string">&#x27;g&#x27;</span>,<span class="string">&#x27;h&#x27;</span>,<span class="string">&#x27;i&#x27;</span>,<span class="string">&#x27;j&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">f = h.transform(test_cat)</span><br><span class="line">f.toarray()</span><br></pre></td></tr></table></figure>
<p><strong>如果hash的目标空间足够大，并且hash函数本身足够散列，不会损失什么特征信息。</strong></p>
<p>feature
hashing简单来说和<strong>kernal的思想</strong>是类似的，就是把输入的特征映射到一个具有一些我们期望的较好性质的空间上去。在feature
hasing这个情况下我们希望目标的空间具有如下的性质：</p>
<ol type="1">
<li><strong>样本无关的维度大小，因为当在线学习，或者数据量非常大，提前对数据观察开销非常大的时候，这可以使得我们能够提前给算法分配存储和切分pattern。大大提高算法的工程友好性</strong>。</li>
<li>这个空间一般来说比输入的特征空间维度小很多。</li>
<li>另外我们假设在原始的特征空间里，样本的分布是非常稀疏的，只有很少一部分子空间是被取值的。</li>
<li><strong>保持内积的无偏</strong>（不变肯定是不可能的，因为空间变小了），否则很多机器学习方法就没法用了。</li>
</ol>
<p><strong>原理</strong>：假设输入特征是一个 <span class="math inline">\(\mathrm{N}\)</span> 维的0/1取值的向量 <span class="math inline">\(\mathrm{x}_{\circ} 一 个
\mathrm{~N}-&gt;\mathrm{M}\)</span> 的哈希函数 <span class="math inline">\(\mathrm{h}\)</span> 。那么 <span class="math inline">\(\phi_j=\sum_{h(i)=j} x_i\)</span></p>
<p><strong>好处：</strong></p>
<ul>
<li>从某种程度上来讲，使得训练样本的特征在对应空间里的<strong>分布更均匀</strong>了。这个好处对于实际训练过程是非常大的，某种程度上起到了<strong>shuffle的作用</strong>。</li>
<li>特征的空间变小了，而且是一个可以预测的大小。比如说加入输入特征里有个东西叫做user_id，那么显然你也不知道到底有多少<a href="https://www.zhihu.com/search?q=userid&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A%22277634591%22%7D">userid</a>的话，你需要先扫描一遍并且分配足够的空间给到它不然学着学着oom了。你也不能很好地提前优化<a href="https://www.zhihu.com/search?q=分片&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A%22277634591%22%7D">分片</a>。</li>
<li>对在线学习非常友好。</li>
</ul>
<p><strong>坏处：</strong></p>
<ul>
<li>会给debug增加困难，为了debug你要保存记录h计算的过程数据，否则如果某个特征有毛病，你怎么知道到底是哪个原始特征呢？</li>
<li>没选好哈希函数的话，<strong>可能会造成碰撞</strong>，如果原始特征很稠密并且碰撞很严重，那可能会带来坏的训练效果。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">hashing_vectorizer</span>(<span class="params">features, N</span>):</span><br><span class="line">  	x = [<span class="number">0</span>] * N</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> features:</span><br><span class="line">      	h = <span class="built_in">hash</span>(f)</span><br><span class="line">        idx = h % N</span><br><span class="line">        <span class="keyword">if</span> xt(f)  <span class="number">1</span>: <span class="comment"># xt 2值hash函数减少hash冲突</span></span><br><span class="line">          	x[idx] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">         		x[idx] -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<ul>
<li><h4><span id="多类别值处理方式-基于统计的编码方法">多类别值处理方式 --
基于统计的编码方法</span></h4></li>
</ul>
<p>当类别值过多时，<strong>One-Hot 编码或者Dummy
Coding都可能导致编码出来的特征过于稀疏</strong>，其次也会占用过多内存。<strong>如果使用FeatureHasher，n_features的设置不好把握，可能会造成过多冲突，造成信息损失</strong>。这里提供一种基于统计的编码方法，包括<strong>基于特征值的统计</strong>或者<strong>基于标签值的统计</strong>——基于标签的编码。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line"></span><br><span class="line"><span class="built_in">test</span> = [<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;e&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;c&#x27;</span>]</span><br><span class="line"><span class="built_in">df</span> = pd.DataFrame(<span class="built_in">test</span>, columns=[<span class="string">&#x27;alpha&#x27;</span>])</span><br><span class="line">sns.countplot(<span class="built_in">df</span>[<span class="string">&#x27;alpha&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261226350.png" alt="image-20220426130800412" style="zoom:50%;"></p>
<p>首先我们将每个类别值出现的频数计算出来，比如我们设置阈值为1，那么所有小于阈值1的类别值都会被编码为同一类，大于1的类别值会分别编码，如果出现频数一样的类别值，既可以都统一分为一个类，也可以按照某种顺序进行编码，这个可以根据业务需要自行决定。那么根据上图，可以得到其编码值为：</p>
<p><span class="math display">\[
\left\{a^{\prime}: 0, &#39; c^{\prime}: 1, &#39; e^{\prime}: 2, &#39;
b^{\prime}: 2, &#39; d &#39;: 2\right\}
\]</span>
<strong>即（a,c）分别编码为一个不同的类别，（e,b,d）编码为同一个类别。</strong></p>
<h4><span id="23-二阶">2.3 二阶</span></h4>
<blockquote>
<p>w * h = s</p>
</blockquote>
<h3><span id="三-特征离散化处理方法">三、 特征离散化处理方法</span></h3>
<p><strong>特征离散化指的是将连续特征划分离散的过程</strong>：将原始定量特征的一个区间一一映射到单一的值。离散化过程也被表述成分箱（Binning）的过程。特征离散化常应用于<strong>逻辑回归</strong>和金融领域的评分卡中，同时在规则提取，特征分类中也有对应的应用价值。本文主要介绍几种常见的分箱方法，包括<strong>等宽分箱、等频分箱、信息熵分箱</strong>、<strong>基于决策树分箱、卡方分箱</strong>等。</p>
<p><strong>可以看到在分箱之后，数据被规约和简化，有利于理解和解</strong>释。总来说特征离散化，即
分箱之后会带来如下优势：</p>
<ul>
<li>有助于模型部署和应用，加快模型迭代</li>
<li>增强模型鲁棒性</li>
<li>增加非线性表达能力：连续特征不同区间对模型贡献或者重要程度不一样时，分箱后不同的权重能直接体现这种差异，离散化后的特征再进行特征
交叉衍生能力会进一步加强。</li>
<li>提升模型的泛化能力</li>
<li><strong>扩展数据在不同各类型算法中的应用范围</strong></li>
</ul>
<p>当然特征离散化也有其缺点，总结如下：</p>
<ul>
<li>分箱操作必定会导致一定程度的信息损失</li>
<li>增加流程：建模过程中加入了额外的的离散化步骤</li>
<li>影响模型稳定性：
当一个特征值处于分箱点的边缘时，此时微小的偏差会造成该特征值的归属从一箱跃迁到另外一箱，影响模型的稳定性。</li>
</ul>
<h4><span id="31-等宽分箱equal-widthbinning">3.1 等宽分箱（Equal-Width
Binning)</span></h4>
<p><strong>等宽分箱指的是每个分隔点或者划分点的距离一样，即等宽</strong>。实践中一般指定分隔的箱数，等分计算后得到每个分隔点。例如将数据序列分为n份，则
分隔点的宽度计算公式为： <span class="math display">\[
w=\frac{\max -\min }{n}
\]</span>
这样就将原始数据划分成了n个等宽的子区间，一般情况下，分箱后每个箱内的样本数量是不一致的。使用pandas中的cut函数来实现等宽分箱，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">value, cutoff = pd.cut(df[<span class="string">&#x27;mean radius&#x27;</span>], bins=<span class="number">4</span>, retbins=<span class="literal">True</span>, precision=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p><strong>等宽分箱计算简单，但是当数值方差较大时，即数据离散程度很大，那么很可能出现没有任何数据的分箱</strong>，这个问题可以通过自适应数据分布的分箱方法--等频分箱来避免</p>
<h4><span id="32-等频分箱equal-frequencybinning">3.2 等频分箱（Equal-Frequency
Binning）</span></h4>
<p><strong>等频分箱理论上分隔后的每个箱内得到数据量大小一致</strong>，但是当某个值出现次数较多时，会出现等<strong>分边界是同一个值</strong>，导致同一数值分到不同的箱内，这是不正确的。具体的实现可以<strong>去除分界处的重复值</strong>，但这也导致每箱的数量不一致。如下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s1 = pd.Series([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">value, cutoff = pd.qcut(s1, <span class="number">3</span>, retbins=<span class="literal">True</span>)</span><br><span class="line">sns.countplot(value)</span><br></pre></td></tr></table></figure>
<p><strong>上述的等宽和等频分箱容易出现的问题是每箱中信息量变化不大</strong>。例如，等宽分箱不太适合分布不均匀的数据集、离群值；等频方法不太适合特定的值占比过多的数据集，如<strong>长尾分布</strong>。</p>
<h4><span id="33-信息熵分箱有监督">3.3 信息熵分箱【有监督】</span></h4>
<p><strong>如果分箱后箱内样本对y的区分度好，那么这是一个好的分箱</strong>。通过信息论理论，我们可知信息熵衡量了这种区分能力。当特征按照某个分隔点划分为上下两部分后能达到最大的信息增益，那么这就是一个好的分隔点。由上可知，信息熵分箱是有监督的分箱方法。<strong><font color="red">
其实决策树的节点分裂原理也是基于信息熵。</font></strong></p>
<p>首先我们需要明确信息熵和信息增益的计算方式, 分别如下: <span class="math display">\[
\begin{gathered}
\operatorname{Entropy}(y)=-\sum_{i=1}^m p_i \log _2 p_i \\
\operatorname{Gain}(x)=\operatorname{Entropy}(y)-\operatorname{Infos}_{\text
{split }}(x)
\end{gathered}
\]</span> 在二分类问题中, <span class="math inline">\(m=2\)</span>
。信息增益的物理含义表达为： <span class="math inline">\(x\)</span>
的分隔带来的信息对 <span class="math inline">\(y\)</span>
的不确定性带来的增益。 对于二值化的单点分隔,
如果我们找到一个分隔点将数据一分为二, 分成 <span class="math inline">\(P_1\)</span> 和 <span class="math inline">\(P_2\)</span> 两部分, 那么划分后的信息熵
的计算方式为: <span class="math display">\[
\operatorname{Info}_{\text {split }}(x)=P 1_{\text {ratio }}
\operatorname{Entropy}\left(x_{p 1}\right)+P 2_{\text {ratio }}
\operatorname{Entropy}\left(x_{p 2}\right)
\]</span>
同时也可以看出，当分箱后，某个箱中的标签y的类别（0或者1）的比例相等时，其熵值最大，表明此特征划分几
乎没有区分度。而当某个箱中的数据的标签 <span class="math inline">\(y\)</span> 为单个类别时, 那么该箱的熵值达到最小的
0 , 即纯度最纯, 最具区 分度。从结果上来看,
最大信息增益对应分箱后的总熵值最小。</p>
<h4><span id="34-决策树分箱有监督">3.4 决策树分箱【有监督】</span></h4>
<p><strong>由于决策树的结点选择和划分也是根据信息熵来计算的，因此我们其实可以利用决策树算法来进行特征分箱</strong>，具体做法如下：</p>
<p>还是以乳腺癌数据为例，首先取其中‘mean
radius’字段，和标签字段‘target’来拟合一棵决策树，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>, max_depth=<span class="number">3</span>) <span class="comment"># 树最大深度为3</span></span><br><span class="line">dt.fit(df[<span class="string">&#x27;mean radius&#x27;</span>].values.reshape(-<span class="number">1</span>, <span class="number">1</span>), df[<span class="string">&#x27;target&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>接着我们取出这课决策树的所有叶节点的分割点的阈值，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">qts = dt.tree_.threshold[np.where(dt.tree_.children_left &gt; -<span class="number">1</span>)]</span><br><span class="line">qts = np.sort(qts)</span><br><span class="line">res = [np.<span class="built_in">round</span>(x, <span class="number">3</span>) <span class="keyword">for</span> x <span class="keyword">in</span> qts.tolist()]</span><br></pre></td></tr></table></figure>
<h4><span id="35-卡方分箱-有监督">3.5 卡方分箱 【有监督】</span></h4>
<blockquote>
<p><strong>特征选择之卡方分箱、WOE/IV</strong> - 云水僧的文章 - 知乎
https://zhuanlan.zhihu.com/p/101771771</p>
</blockquote>
<p><strong><font color="red">
卡方检验可以用来评估两个分布的相似性，因此可以将这个特性用到数据分箱的过程中。卡方分箱认为：理想的分箱是在同一个区间内标签的分布是相同的</font>;</strong>
<strong>卡方分布是概率统计常见的一种概率分布，是卡方检验的基础。</strong></p>
<p>布定义为: 若n个独立的随机变量 <span class="math inline">\(Z_1, Z_2,
\ldots, Z_k\)</span> 满足标准正态分布 <span class="math inline">\(N(0,1)\)</span>, 则 <span class="math inline">\(\mathrm{n}\)</span> 个随机变量的平方和 <span class="math inline">\(X=\sum_{i=0}^k Z_i^2\)</span> 为服从自由度为 <span class="math inline">\(\mathrm{k}\)</span> 的卡方分布, 记为 <span class="math inline">\(X \sim \chi^2\)</span> 。参数 <span class="math inline">\(\mathrm{n}\)</span>
称为自由度（样本中独立或能自由变化的自变 量的个数),
不同的自由度是不同的分布。</p>
<p>卡方检验：卡方检验属于非参数假设检验的一种，其本质都是度量频数之间的差异。其假设为：观察频数与期望
频数无差异或者两组变量相互独立不相关。 <span class="math display">\[
\chi^2=\sum \frac{(O-E)^2}{E}
\]</span></p>
<ul>
<li>卡方拟合优度检验：用于检验样本是否来自于某一个分布，比如检验某样本是否为正态分布</li>
<li>独立性卡方检验，查看两组类别变量分布是否有差异或者相关，以列联表的形式比较。以列联表形式的卡方检验中，卡方统计量由上式给出。</li>
</ul>
<h4><span id="步骤">步骤：</span></h4>
<p>卡方分箱是自底向上的(即基于合并的)数据离散化方法。它依赖于卡方检验:具有最小卡方值的相邻区间合并在一起,直到满足确定的停止准则。基本思想:
对于精确的离散化，相对类频率在一个区间内应当完全一致。因此,如果两个相邻的区间具有非常类似的类分布，则这两个区间可以合并；否则，它们应当保持分开。而低卡方值表明它们具有相似的类分布。</p>
<p><strong>理想的分箱是在同一个区间内标签的分布是相同的</strong>。卡方分箱就是不断的计算相邻区间的卡方值（卡方值越小表示分布越相似），将分布相似的区间（卡方值最小的）进行合并，直到相邻区间的分布不同，达到一个理想的分箱结果。下面用一个例子来解释：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261231284.png" alt="image-20220708173638301" style="zoom: 33%;"></p>
<p>由上图，第一轮中初始化是5个区间，分别计算相邻区间的卡方值。找到1.2是最小的，合并2、3区间，为了方便，将合并后的记为第2区间，因此得到4个区间。第二轮中，由于合并了区间，影响该区间与前面的和后面的区间的卡方值，因此重新计算1和2,2和4的卡方值，由于4和5区间没有影响，因此不需要重新计算，这样就得到了新的卡方值列表，找到最小的取值2.5，因此该轮会合并2、4区间，并重复这样的步骤，一直到满足终止条件。</p>
<h4><span id="36-woe编码有监督"><strong><font color="red"> 3.6 WOE编码
【有监督】</font></strong></span></h4>
<blockquote>
<p><strong><font color="red">
风控模型—WOE与IV指标的深入理解应用</font></strong>:
https://zhuanlan.zhihu.com/p/80134853</p>
</blockquote>
<p><strong>WOE (Weight of Evidence, 证据权重）编码利用了标签信息,
属于有监督的编码方式</strong>。该方式广泛用于金融领 域信用风险模型中,
是该领域的经验做法。下面先给出WOE的计算公式: <span class="math display">\[
W O E_i=\ln \left\{\frac{P_{y 1}}{P_{y 0}}\right\}=\ln \left\{\frac{B_i
/ B}{G_i / G}\right\}
\]</span> <span class="math inline">\(W O E_i\)</span> 值可解释为第
<span class="math inline">\(i\)</span>
类别中好坏样本分布比值的对数。其中各个分量的解释如下: - <span class="math inline">\(P_{y 1}\)</span> 表示该类别中坏样本的分布 - <span class="math inline">\(P_{y 0}\)</span> 表示该类别中好样本的分布 - <span class="math inline">\(B_i / B\)</span>
表示该类别中坏样本的数量在总体坏样本中的占比 - <span class="math inline">\(G_i / G\)</span>
表示该类别中好样本的数量在总体好样本中的占比</p>
<p>很明显，如果整个分数的值大于1，那么WOE值为正，否则为负，所以WOE值的取值范围为正负无穷。
<strong>WOE值直观上表示的实际上是“当前分组中坏客户占所有坏客户的比例”和“当前分组中好客户占所有坏客户的比例”的差异。</strong>转化公式以后，也可以理解为：当前这个组中坏客户和好客户的比值，和所有样本中这个比值的差异。这个差异为这两个比值的比值，再取对数来表示的。
WOE越大，这种差异越大，这个分组里的样本坏样本可能性就越大，WOE越小，差异越小，这个分组里的坏样本可能性就越小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 随机生成1000行数据</span></span><br><span class="line">df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;x&#x27;</span>: np.random.choice([<span class="string">&#x27;R&#x27;</span>,<span class="string">&#x27;G&#x27;</span>,<span class="string">&#x27;B&#x27;</span>], <span class="number">1000</span>),</span><br><span class="line">    <span class="string">&#x27;y&#x27;</span>: np.random.randint(<span class="number">2</span>, size=<span class="number">1000</span>)</span><br><span class="line">&#125;)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<h3><span id="四-缺失值处理解析">四、缺失值处理解析</span></h3>
<blockquote>
<p>看不懂你打我，史上最全的缺失值解析:
https://zhuanlan.zhihu.com/p/379707046</p>
<p>https://zhuanlan.zhihu.com/p/137175585</p>
</blockquote>
<table>
<thead>
<tr class="header">
<th>机器学习模型</th>
<th>是否支持缺失值</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>XGBoost</strong></td>
<td>是</td>
</tr>
<tr class="even">
<td><strong>LightGBM</strong></td>
<td>是</td>
</tr>
<tr class="odd">
<td>线性回归</td>
<td>否</td>
</tr>
<tr class="even">
<td>逻辑回归（LR）</td>
<td>否</td>
</tr>
<tr class="odd">
<td>随机森林（RF）</td>
<td>否</td>
</tr>
<tr class="even">
<td>SVM</td>
<td>否</td>
</tr>
<tr class="odd">
<td>因子分解机(FM)</td>
<td>否</td>
</tr>
<tr class="even">
<td>朴实贝叶斯（NB）</td>
<td>否</td>
</tr>
</tbody>
</table>
<h4><span id="41-缺失值的替换">4.1 <strong>缺失值的替换</strong></span></h4>
<p><strong>scikit-learn中填充缺失值的API是Imputer类，使用方法如下：</strong></p>
<p>参数strategy有三个值可选：mean(平均值)，median(中位数)，most_frequent(众数)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rom sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 缺失值填补的时候必须得是float类型</span></span><br><span class="line"><span class="comment"># 缺失值要填充为np.nan，它是浮点型，strategy是填充的缺失值类型，这里填充平均数，axis代表轴，这里第0轴是列</span></span><br><span class="line">im = Imputer(missing_values=<span class="string">&#x27;NaN&#x27;</span>,strategy=<span class="string">&#x27;mean&#x27;</span>,axis=<span class="number">0</span>)</span><br><span class="line">data = im.fit_transform([[<span class="number">1</span>, <span class="number">2</span>], </span><br><span class="line">                         [np.nan, <span class="number">3</span>], </span><br><span class="line">                         [<span class="number">7</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure>
<h4><span id="42-缺失值的删除">4.2 缺失值的删除</span></h4>
<h3><span id="五-异常值处理">五、异常值处理</span></h3>
<h3><span id="数据预处理qampa">数据预处理Q&amp;A</span></h3>
<h4><span id="1-lr为什么要离散化"><strong><font color="red"> 1、LR为什么要离散化？</font></strong></span></h4>
<p>[<a href="https://zhuanlan.zhihu.com/p/122387176">学习]
连续<em>特征的离散化</em>：在什么情况<em>下</em>将连续的<em>特征离散化</em>之后可以获得更好的效果？</a></p>
<p><strong>问题描述：</strong>发现CTR预估一般都是用LR，而且特征都是离散的，为什么一定要用离散特征呢？这样做的好处在哪里？求大拿们解答。</p>
<h5><span id="答案一严林"><strong>答案一（<a href="https://www.zhihu.com/search?q=严林&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22122387176%22%7D">严林</a>）：</strong></span></h5>
<p>在工业界，很少直接将连续值作为逻辑回归模型的特征输入，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：</p>
<ol type="1">
<li>离散特征的增加和减少都很容易，易于模型的快速迭代；</li>
<li>稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；</li>
<li>【鲁棒性】离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则为0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；</li>
<li>【模型假设】<strong>逻辑回归属于广义线性模型，表达能力受限</strong>；单变量离散化为N个后，每个变量有独立的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合；</li>
<li>【特征交叉】离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力；</li>
<li>特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻的样本会刚好相反，所以怎么划分区间是门学问；</li>
<li>特征离散化以后，起到了简化逻辑回归模型的作用，降低了模型过拟合的风险；</li>
</ol>
<h5><span id="李沐曾经说过模型是使用离散特征还是连续特征其实是一个海量离散特征简单模型同少量连续特征复杂模型的权衡"><strong><font color="red">
<a href="https://www.zhihu.com/search?q=李沐&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22122387176%22%7D">李沐</a>曾经说过：模型是使用离散特征还是连续特征，其实是一个“海量离散特征+简单模型”同“少量连续特征+复杂模型”的权衡。</font></strong></span></h5>
<blockquote>
<p>这里我写下我关于上面某些点的理解，有问题的欢迎指出：</p>
<ol start="0" type="1">
<li>假设目前有两个连续的特征：『年龄』和『收入』，预测用户的『魅力指数』；</li>
</ol>
<p>第三点:
<strong>LR是广义线性模型</strong>，因此如果特征『年龄』不做离散化直接输入，那么只能得到『年龄』和魅力指数的一个线性关系。但是这种线性关系是不准确的，并非年龄越大魅力指一定越大；如果将年龄划分为M段，则可以针对每段有一个对应的权重；这种分段的能力为模型带来类似『折线』的能力，也就是所谓的非线性
<strong>连续变量的划分，naive的可以通过人为先验知识划分，也可以通过训练单特征的决策树桩，根据Information
Gain/Gini系数等来有监督的划分。</strong>
假如『年龄』离散化后，共有N段，『收入』离散化后有M段；此时这两个离散化后的特征类似于<strong>CategoryFeature</strong>，对他们进行<strong>OneHotEncode</strong>，即可以得到
M + N的 01向量；例如： 0 1 0 0， 1 0 0 0 0； 第四点:
<strong>特征交叉</strong>，可以理解为上述两个向量的互相作用，作用的方式可以例如是
&amp;和|操作（这种交叉方式可以产生一个 M * N的01向量；）
上面特征交叉，可以类比于决策树的决策过程。例如进行&amp;操作后，得到一个1，则可以认为产生一个特征
（a &lt; age &lt; b &amp;&amp; c &lt; income &lt;
d）;将特征空间进行的非线性划分，也就是所谓的引入非线性；</p>
</blockquote>
<h5><span id="答案二周开拓"><strong>答案二（周开拓）：</strong></span></h5>
<p><strong><font color="red"> 机器学习里当然并没有free
lunch，一个方法能work，必定是有假设的。如果这个假设和真实的问题及数据比较吻合，就能work。</font></strong></p>
<p>对于LR这类的模型来说，假设基本如下：</p>
<ul>
<li><strong>局部<a href="https://www.zhihu.com/search?q=平坦性&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22122387176%22%7D">平坦性</a>，或者说连续性</strong>。对于连续特征x来说，在任何一个取值x0的邻域附近，这个特征对预估目标y的影响也在一个足够小的邻域内变化。比如，人年龄对点击率的影响，x0=30岁假设会产生一定的影响，那么x=31或者29岁，这个影响和x0=30岁的影响差距不会太大；</li>
<li><strong>x对y的影响，这个函数虽然局部比较平坦，但是不太规律，如果你知道这个影响是个严格的直线</strong>（或者你有先验知识知道这个影响一定可以近似于一个参数不太多的函数），<strong>显然也没必要去做离散化</strong>。当然这条基本对于绝大多数问题都是成立的，因为基本没有这种好事情。</li>
</ul>
<p>假设一个最简单的问题，binary
classification，y=0/1，x是个连续值。你希望学到一个logloss足够小的y=f(x)。</p>
<p>那么有一种做法就是，在数据轴上切若干段，每一段观察训练样本里y为1的比例，以这个比例作为该段上y=f(x)的值。这个当然不是LR训练的过程，但是就是离散化的思想。你可以发现：</p>
<ul>
<li><strong>如果每一段里面都有足够多的样本，那么在这一段里的y=f(x)值的点估计就比较可信</strong>；</li>
<li><font color="red">如果x在数轴上分布不太均匀，比如是<strong>指数分布或者周期分布</strong>的，这么做可能会有问题，因而你要先<strong>对x取个log，或者去掉周期性</strong></font>；</li>
</ul>
<p>这就告诉了你应该怎么做离散化：<strong><font color="red">
尽可能保证每个分段里面有足够多的样本，尽量让样本的分布在数轴上均匀一些。</font></strong></p>
<p>结语：<strong>本质上连续特征离散化，可以理解为连续信号怎么转化为数字信号，好比我们计算机画一条曲线，也是变成了画一系列线段的问题。</strong>用分段函数来表达一个连续的函数在大多数情况下，都是work的。想取得好的效果需要：</p>
<ul>
<li>你的分段足够小，以使得在每个分段内x对y的影响基本在一个不大的邻域内，或者你可以忍受这个变化的幅度；</li>
<li>你的分段足够大，以使得在每个分段内有足够的样本，以获得可信的f(x)也就是权重；</li>
<li>你的分段策略使得在每个x的分段中，样本的分布尽量均匀（当然这很难），一般会根据先验知识先对x做一些变化以使得变得均匀一些；</li>
<li>如果你有非常强的x对y的先验知识，比如严格线性之类的，也未必做离散化，但是这种先验在计算广告或者推荐系统里一般是不存在的，也许其他领域比如CV之类的里面是可能存在的；</li>
</ul>
<p>最后还有个特别大的<strong>LR用离散特征的好处就是LR的特征是并行的，每个特征是并行同权的</strong>，如果有异常值的情况下，如果这个异常值没见过，那么LR里因为没有这个值的权重，最后对<a href="https://www.zhihu.com/search?q=score&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22122387176%22%7D">score</a>的贡献为0，最多效果不够好，但是不会错的太离谱。另外，如果你debug，很容易查出来是哪个段上的权重有问题，比较好定位和解决。</p>
<h4><span id="2-树模型为什么离散化"><strong><font color="red">2、树模型为什么离散化？</font></strong></span></h4>
<h5><span id="cart树的离散化">Cart树的离散化：</span></h5>
<p><strong>分类：</strong></p>
<ul>
<li><p><strong><font color="red">如果特征值是连续值：CART的处理思想与C4.5是相同的，即将连续特征值离散化。唯一不同的地方是度量的标准不一样，</font></strong>
<strong>CART采用基尼指数，而C4.5采用信息增益比</strong>。</p></li>
<li><p>如果当前节点为连续属性，<strong>CART树中该属性（剩余的属性值）后面还可以参与子节点的产生选择过程</strong>。</p></li>
</ul>
<p><strong>回归：</strong></p>
<p><strong>对于连续值的处理, CART
分类树采用基尼系数的大小来度量特征的各个划分点</strong>。在回归模型中,
我们使用常见的和方差度量方式, 对于任意划分特征 <span class="math inline">\(\mathrm{A}\)</span>, 对应的任意划分点 <span class="math inline">\(\mathrm{s}\)</span> 两边划分成的数据集 <span class="math inline">\(D_1\)</span> 和 <span class="math inline">\(D_2\)</span>, 求出使 <span class="math inline">\(D_1\)</span> 和 <span class="math inline">\(D_2\)</span> 各自集合的均方差最小, 同时 <span class="math inline">\(D_1\)</span> 和 <span class="math inline">\(D_2\)</span>
的均方差之和最小所对应的特征和特征值划分点。表达式为: <span class="math display">\[
\min _{a, s}\left[\min _{c_1} \sum_{x_i \in
D_1}\left(y_i-c_1\right)^2+\min _{c_2} \sum_{x_i \in
D_2}\left(y_i-c_2\right)^2\right]
\]</span> 其中, <span class="math inline">\(c_1\)</span> 为 <span class="math inline">\(D_1\)</span> 数据集的样本输出均值, <span class="math inline">\(c_2\)</span> 为 <span class="math inline">\(D_2\)</span> 数据集的样本输出均值。</p>
<h5><span id="lgb直方图算法优点">LGB直方图算法优点：</span></h5>
<p><strong>内存小、复杂度降低、直方图加速【分裂、并行通信、缓存优化】</strong></p>
<ul>
<li><p><strong>内存消耗降低</strong>。预排序算法需要的内存约是训练数据的两倍（2x样本数x维度x4Bytes），它需要用32位浮点来保存特征值，并且对每一列特征，都需要一个额外的排好序的索引，这也需要32位的存储空间。对于
直方图算法，则只需要(1x样本数x维
度x1Bytes)的内存消耗，仅为预排序算法的1/8。因为直方图算法仅需要存储特征的
bin
值(离散化后的数值)，不需要原始的特征值，也不用排序，而bin值用8位整型存储就足够了。</p></li>
<li><p><strong>算法时间复杂度大大降低</strong>。决策树算法在节点分裂时有两个主要操作组成，一个是“寻找分割点”，另一个是“数据分割”。从算法时间复杂度来看，在“寻找分割点”时，预排序算法对于深度为<span class="math inline">\(k\)</span>的树的时间复杂度：对特征所有取值的排序为<span class="math inline">\(O(NlogN)\)</span>，<span class="math inline">\(N\)</span>为样本点数目，若有<span class="math inline">\(D\)</span>维特征，则<span class="math inline">\(O(kDNlogN)\)</span>，而直方图算法需要<span class="math inline">\(O(kD \times bin)\)</span> (bin是histogram
的横轴的数量，一般远小于样本数量<span class="math inline">\(N\)</span>)。</p></li>
<li><p><strong>直方图算法还可以进一步加速</strong>【<strong>两个维度</strong>】。一个容易观察到的现象：<strong>一个叶子节点的直方图可以直接由父节点的直方图和兄弟节点的直方图做差得到（分裂时左右集合）</strong>。通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的<span class="math inline">\(k\)</span>个bin。利用这个方法，LightGBM可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。</p></li>
<li><p><strong>数据并行优化</strong>，用 histgoram
可以大幅降低通信代价。用 pre-sorted
算法的话，通信代价是非常大的（几乎是没办法用的）。所以 xgoobst
在并行的时候也使用 histogram 进行通信。</p></li>
<li><p><strong>缓存优化</strong>：上边说到 XGBoost
的预排序后的特征是通过索引给出的样本梯度的统计值，因其索引访问的结果并不连续，XGBoost
提出缓存访问优化算法进行改进。<strong><font color="red"> LightGBM
所使用直方图算法对 Cache
天生友好所有的特征都采用相同的方法获得梯度，构建直方图时bins字典同步记录一阶导、二阶导和个数，大大提高了缓存命中</font></strong>；因为<strong>不需要存储特征到样本的索引</strong>，降低了存储消耗，而且也不存在
Cache Miss的问题。</p></li>
</ul>
<h4><span id="3-归一化">3、归一化？</span></h4>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><p><strong>机器学习中的特征工程（四）----
特征离散化处理方法：</strong>https://www.jianshu.com/p/918649ce379a</p></li>
<li><p><strong>机器学习中的特征工程（三）----
序数和类别特征处理方法</strong>：https://www.jianshu.com/p/3d828de72cd4</p></li>
<li><p><strong>机器学习中的特征工程（二）----
数值类型数据处理</strong>：https://www.jianshu.com/p/b0cc0710ef55</p></li>
<li><p>机器学习中的特征工程（一）----
概览：https://www.jianshu.com/p/172677f4ea4c</p></li>
<li><p>特征工程完全手册 -
从预处理、构造、选择、降维、不平衡处理，到放弃：https://zhuanlan.zhihu.com/p/94994902</p></li>
<li><p><strong>这9个特征工程使用技巧，解决90%机器学习问题！</strong> -
Python与数据挖掘的文章 - 知乎
https://zhuanlan.zhihu.com/p/462744763</p></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（0）特征工程 vs 表示学习</title>
    <url>/posts/3RNPESE/</url>
    <content><![CDATA[<h2><span id="特征工程与表示学习"></span></h2>
<h3><span id="1-表示学习"><strong>1. 表示学习</strong></span></h3>
<p>当我们学习一个复杂概念时，总想有一条捷径可以化繁为简。机器学习模型也不例外，如果有经过提炼的对于原始数据的更好表达，往往可以使得后续任务事倍功半。<strong>这也是表示学习的基本思路，即找到对于原始数据更好的表达，以方便后续任务（比如分类）</strong>。</p>
<p>举个简单的例子, 假设我们有 <span class="math inline">\(\{x,
y\}\)</span>, 想要寻找 <span class="math inline">\(x\)</span> 与 <span class="math inline">\(y\)</span> 之间的关系。 <span class="math display">\[
x=\left[\begin{array}{cccc}
1 &amp; 2 &amp; 1 &amp; 0 \\
2 &amp; 3 &amp; 2 &amp; 1 \\
1 &amp; 6 &amp; 1 &amp; 4 \\
0 &amp; 0 &amp; 0 &amp; 1 \\
1 &amp; 1 &amp; 1 &amp; 17
\end{array}\right], \quad y=\left[\begin{array}{c}
6 \\
10 \\
14 \\
18 \\
22
\end{array}\right]
\]</span> 如果单用肉眼看的话, <span class="math inline">\(x\)</span>
这个矩阵其实还是比较复杂的, 无法直接发现与 <span class="math inline">\(y\)</span> 间的关系。但如果我们非常幸运, 发现
<span class="math inline">\(x\)</span> 每行相加后的结果 <span class="math inline">\([4,8,12,16,20]^T\)</span>, 就可以直接看出 <span class="math inline">\(x\)</span> 与 <span class="math inline">\(y\)</span> 之间的关系是 <span class="math inline">\(y=x+2\)</span> 。这个例子是为了说明:
<strong>同样的数据的不同表达, 会直接决定后续任务的难易程度,
因此找到好的数据表示往往是机器学习的核心任务</strong>。值得注意的是,
在现实情况中我们所提炼的到表示往往是很复杂的,
往往对于高维矩阵提取到特征也是高维矩阵。这个例 子仅供抛砖引玉之用,
表示学习不等于维度压缩或者特征选择。</p>
<h3><span id="2特征工程与表示学习人工-vs-自动"><strong>2.
特征工程与表示学习：人工 vs. 自动</strong></span></h3>
<p><strong>正因为数据表示的重要性，机器学习一般有两种思路来提升原始数据的表达</strong>：</p>
<ol type="1">
<li>特征<strong>学习</strong>(feature
<strong>learning</strong>)，又叫<strong>表示学习</strong>(representation
learning)或者表征学习，一般指的是<strong>自动</strong>学习有用的数据特征。<strong>深度学习的最终目标，就是完全自动化的广义数据处理。</strong></li>
<li>特征<strong>工程</strong>(feature
<strong>engineering</strong>)，主要指对于数据的<strong>人为</strong>处理提取，有时候也代指“洗数据”。</li>
</ol>
<p>不难看出，两者的主要区别在于前者是“<strong>学习的过程</strong>”，而后者被认为是一门“<strong>人为的工程</strong>”。用更加白话的方式来说，<strong>特征学习是</strong>从数据中自动抽取特征或者表示的方法，这个学习过程是<strong>模型自主的</strong>。而<strong>特征工程</strong>的过程是<strong>人为的</strong>对数据进行处理，<strong>得到我们认为的、适合后续模型使用的样式</strong>。根据这个思路，机器学习模型对于数据的处理可以被大致归类到两个方向：</p>
<ul>
<li>表示学习：<strong>模型自动</strong>对输入数据进行学习，得到更有利于使用的特征(*可能同时做出了预测)。代表的算法大致包括：
<ul>
<li>深度学习，包括大部分常见的模型如CNN/RNN/DBN等。</li>
<li>某些无监督学习算法，如<strong>主成分分析(PCA) </strong>及
<strong>自编码器（autoencoder）</strong>通过对数据转化而使得输入数据更有意义。</li>
<li>某些树模型可以自动的学习到数据中的特征并同时作出预测。</li>
</ul></li>
<li>特征工程：模型依赖<strong>人为处理</strong>的数据特征，而模型的主要任务是预测，比如简单的线性回归期待良好的输入数据(如离散化后的数据)</li>
</ul>
<h3><span id="3-模型选择"><strong>3. 模型选择</strong></span></h3>
<p>回归到问题的本质，就要谈谈什么时候用「手工提取」什么时候用「表示学习」。一种简单的看法是，<strong>要想自动学习到数据的良好表达，就需要大量的数据。这个现象也解释了为什么「特征工程」往往在中小数据集上表现良好，而「表示学习」在大量复杂数据上更有用武之地。</strong></p>
<p>而一切的根本，其实在于<strong>假设</strong>。比如我们会假设数据分布，会假设映射函数的性质，也会假设预测值与输入值间的关系。<strong>这一切假设其实并非凭空猜想，而是基于我们对于问题的理解，从某种角度来看，这是一种先验，是贝叶斯模型</strong>。在中小数据集上的机器学习往往使用的就是强假设模型（人类知识先验）+一个简单线性分类器。当数据愈发复杂，数据量逐渐加大后，我们对于数据的理解越来越肤浅，做出的假设也越来越倾向于随机，那么此时人工特征工程往往是有害的，而需要使用摆脱了人类先验的模型，比如深度学习或者集成模型。</p>
<p><strong>换句话说，模型选择的过程其实也是在衡量我们对于问题及数据的理解是否深刻，是在人类先验与数据量之间的一场博弈。</strong>从这个角度来看，深度学习首先革的是传统机器学习模型的命：最先被淘汰的不是工人，而是特定场景下的传统机器学习模型。</p>
<p>但话说回来，在很多领域数据依然是稀缺的，我们依然需要人工的手段来提炼数据。而这样的尝试其实并不罕见，我也写过一篇<a href="https://zhuanlan.zhihu.com/p/32896968">「Stacking」与「神经网络」</a>介绍如何模拟神经网络在中小数据集上无监督的抽取特征，并最终提升数据的表示。另一个相关的问题是，到底多少数据才算多？可以参考这篇文章：<a href="https://zhuanlan.zhihu.com/p/34523880">「机器学习」到底需要多少数据？</a>。</p>
<p>然而，<strong>相同的数据对于不同的任务也要求不同的数据表达，最优的数据表示并非是绝对的</strong>。类比来看，人类是由细胞组成的，器官也是由细胞组成的。在器官层面来看，细胞是很好的表达。而从人类角度来看，器官是比较好的表达，因为我们可以通过身高体重来区分人，而无法直观地通过细胞来区分人。然而再往前看一步，每个人的细胞携带不同的遗传信息，因此也可以被认为是一种很强的数据表达。讲这个故事的目的是说明，<strong>什么是好的数据表达，其实是非常模棱两可的问题，在不同语境下可能大不相同</strong>。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（5）特征融合</title>
    <url>/posts/2TRK228/</url>
    <content><![CDATA[<h3><span id="特征工程数据清洗预处理-特征生成-特征拼接">特征工程｜数据清洗（预处理）、特征生成、特征拼接</span></h3>
<p>这或许是全网最全机器学习模型融合方法总结！：https://zhuanlan.zhihu.com/p/511246278</p>
<p>特征工程的完整流程是：特征设计 -&gt; 特征获取 -&gt; 特征处理 -&gt;
特征存储 -&gt;
特征监控。前边介绍了那么多，相当于是对特征设计、特征获取、特征存储进行了说明，而特征工程中最重要的环节则是特征处理。特征处理中还包括：数据清洗、特征生成、特征拼接、特征处理、特征转换、特征选择。本篇主要介绍<strong>数据清洗、特征生成、特征拼接</strong>。</p>
<h3><span id="一-数据清洗">一、数据清洗</span></h3>
<p>从特征工程角度讲，数据清洗是特征工程的前置阶段（但是也会贯穿整个数据应用过程），其本义是对数据进行重新的<strong>审查和校验</strong>，目的在于<strong>删除重复信息</strong>、纠正存在的错误数据，并保证数据的一致性。数据清洗是整个数据分析过程中不可缺少的一个环节，其结果质量直接关系到模型效果和最终结论。</p>
<p>一个特征处理的完整流程可以表示为：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261411937.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>因此基础数据的准确性、完备性、一致性决定了后续特征数据的有效性。在我们日常使用的公开数据集中，很多都是已经被处理后的了，比如学术界中使用很广泛的MovieLens数据集，但是在真实的业务场景中，我们拿到的数据其实直接是没有办法使用的，可能包含了<strong>大量的缺失值</strong>，可能包含<strong>大量的噪音</strong>，也可能因为人工录入错误导致有异常点存在，对我们挖据出有效信息造成了一定的困扰，所以我们需要通过一些方法，尽量提高数据的质量。</p>
<p><strong>初期数据清洗更多的是针对单条样本数据的清洗和检测</strong>，包括：</p>
<ul>
<li>数据表示一致性处理</li>
<li>逻辑错误值处理</li>
<li>缺失值处理</li>
<li>非必要性数据剔除</li>
</ul>
<p>在实际的业务场景中，数据是由系统收集或用户填写而来，有很大可能性在格式和内容上存在一些问题，同样类型的数据在不同的团队上报过程中产出的内容或格式会不一致，同样不同数据源采集而来的数据内容和格式也会不一致。</p>
<blockquote>
<p>数据格式的一致性。比如<strong>时间信息</strong>（以2020年6月18日，11点11分12秒为例），有的用毫秒时间戳表示（1592449872000），有的用秒时间戳表示（1592449872），有的用带横线的时间表示（2020-06-18
11:11:12），有的则用不带横线的时间表示（20200618 11:11:12）。</p>
<p>数据类型的一致性。比如不同的数据表中，同样表示用户ID的字段，有的可能是string类型，有的是int类型。如果用string类型表示，如果用户id缺失的话，正常可以留空，但是不同团队，不同人对于缺失的id处理方式也会不一致，比如有的用None，有的用Null，有的则用0表示，可谓是千奇百怪。小编在日常工作中也会经常遇到这种情况，被折磨的体无完肤。</p>
</blockquote>
<h3><span id="二-特征生成">二、特征生成</span></h3>
<p>对基础数据进行清理之后需要做的就是生成我们需要的特征，在特征设计部分提到特征主要分为四大维度，根据小编的经验特征又可以根据其值的属性划分为：</p>
<ul>
<li><strong>类别特征</strong>：即特征的属性值是一个有限的集合，比如用户性别、事物的类别、事物的ID编码类特征等</li>
<li><strong>连续特征</strong>：即用户行为、类别、组合特征之类的统计值，比如用户观看的视频部数、某类别下事物的个数等</li>
<li><strong>时间序列特征</strong>：即和时间相关的特征，比如用户来访时间、用户停留时长、当前时间等。</li>
<li>组合特征：即多种类别的组合特征，比如用户在某个类别下的行为统计特征、当天内事物被访问次数特征等</li>
<li><strong>文本特征</strong>：即和文本相关的特征，比如评论数据、商品描述、新闻内容等。</li>
<li><strong>Embedding特征</strong>：即一些基础特征的高层次表示，比如用户ID编码的Embedding表示、事物ID编码的Embedding表示、<strong>用户访问事物序列的Embedding编码</strong>等。</li>
</ul>
<h3><span id="三-特征融合">三、特征融合</span></h3>
<blockquote>
<p>多模态特征融合三部曲: https://zhuanlan.zhihu.com/p/390668652</p>
<p>推荐系统（六）—— 特征融合 :
https://zhuanlan.zhihu.com/p/459012483</p>
</blockquote>
<h4><span id="31-特征处理">3.1 特征处理</span></h4>
<p>假设你有三种类型数据，或者说可以是三个不同维度的向量.</p>
<p><span class="math display">\[
x_1 \in \mathbb{R}^{n_1}, x_2 \in \mathbb{R}^{n_2}, x_3 \in
\mathbb{R}^{n_3}
\]</span></p>
<p>第一种融合手段就是在训练前进行的</p>
<ol type="1">
<li><strong>三个向量直接concat，可能维度会比较高，再进行个PCA</strong></li>
<li><strong>自编码器结构</strong>：三个向量通过MLP映射成一个维度后相加，用还原回去；融合特征再用来做后续的模型设计和训练就好了。</li>
</ol>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261411138.png" alt="image-20220519212856682" style="zoom: 33%;"></p>
<h4><span id="32-模型结构">3.2 模型结构</span></h4>
<p>一种直接的思想就是分而治之，多分支网络；还有一种比较出名的在中间层进行融合的方法，多模态双线性矩阵分解池化方法（MFB），本质上就是对不同模态数据进行双线性融合，借助矩阵分解的思想，再对原始特征进行高维映射，然后element-wise相乘后再做pooling操作。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261411043.png" alt="image-20220519220722481" style="zoom: 33%;"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261411033.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="33-后处理">3.3 后处理</span></h4>
<p>后处理其实也是分而治之的思想，多模态数据分别训练不同的模型，再将不同模型的预测输出进行融合，比如平均、加权，或者fix住原来的多个网络，后面再加一层进行微调。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261411915.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="34特征融合是什么和特征交叉有什么区别呢">3.4
特征融合是什么？和特征交叉有什么区别呢？</span></h4>
<p>在上一篇文章（<a href="https://zhuanlan.zhihu.com/p/457853657">yu-lzn：推荐系统（五）——
特征交叉</a>）中，我们讨论了特征交叉，特征交叉也称为特征组合，旨在提高模型对非线性的建模能力，从而提高模型的性能。<strong>特征融合</strong>和特征交叉有相同的目的，都是为了提高模型的性能。特征融合是想更好地利用不同特性的特征。</p>
<blockquote>
<p>随着信息时代的发展，<strong>在推荐系统中，多模态信息的融合也变得越来越重要</strong>。以淘宝购物为例，用户在决策是否购买物品时，会考虑<strong>物品的属性</strong>、<strong>物品图片的展示</strong>、其他<strong>用户的评论信息</strong>、甚至是观看<strong>物品的介绍视频</strong>等等。换句话说，这些<strong>多模态信息（文本、图片、视频）会影响用户的行为</strong>。所以如何利用这些多模态信息来建模，是提高推荐系统准确度的一个途径。那么如何去融合这些不同来源的信息便是一个关键的问题。</p>
</blockquote>
]]></content>
      <categories>
        <category>算法</category>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（7）【draft】特征重要性</title>
    <url>/posts/9TPJKB/</url>
    <content><![CDATA[<h2><span id="特征重要性-模型的可解释性">特征重要性 - 模型的可解释性</span></h2>
<blockquote>
<p>机器学习模型可解释性进行到底 —— <strong>SHAP值理论</strong>（一） -
悟乙己的文章 - 知乎 https://zhuanlan.zhihu.com/p/364919024</p>
<p><strong>Permutation Importance</strong></p>
<p>机器学习模型可解释性进行到底——特征重要性（四） - 悟乙己的文章 - 知乎
https://zhuanlan.zhihu.com/p/364922142</p>
</blockquote>
]]></content>
      <categories>
        <category>算法</category>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（4）不平衡数据集*</title>
    <url>/posts/16MJEZ4/</url>
    <content><![CDATA[<h2><span id="不平衡数据问题">不平衡数据问题</span></h2>
<p><strong>实际上，很多时候，数据不平衡并没有啥负面影响，并不是数据不平衡了，就一定要处理。如果你只是为了做而做，我有99%的自信告诉你，你做了也是白做，啥收益都没有。</strong></p>
<h4><span id="为什么很多模型在训练数据不均衡时会出问题">为什么很多模型在训练数据不均衡时会出问题？</span></h4>
<p><strong>本质原因是</strong>：<strong>模型在训练时优化的目标函数和在测试时使用的评价标准不一致。</strong>这种”不一致“可能是训练数据的样本分布与测试数据分布不一致；</p>
<h3><span id="一-不平衡数据集的主要处理方式"><strong>一、不平衡数据集的主要处理方式？</strong></span></h3>
<h4><span id="11-数据的角度">1.1 <strong>数据的角度</strong></span></h4>
<p>主要方法为采样，分为<strong>欠采样</strong>和<strong>过采样</strong>以及对应的一些改进方法。[<strong>python
imblearn库</strong>]<strong><font color="red">尊重真实样本分布，人为主观引入样本权重，反而可能得出错误的结论。</font></strong></p>
<h5><span id="业务角度"><strong><font color="red">
业务角度</font></strong>：</span></h5>
<ul>
<li><strong>时间因素</strong>，对近期样本提高权重，较远样本降低权重。这是考虑近期样本与未来样本之间的“相似度”更高，希望模型学到更多近期样本的模式。</li>
<li><strong>贷款类型</strong>，不同额度、利率、期限的样本赋予不同权重，这需要结合业务未来的发展方向。例如，未来业务模式希望是小额、短期、低利率，那就提高这批样本的权重。</li>
<li><strong>样本分群</strong>，不同群体赋予不同权重。例如，按流量获客渠道，如果未来流量渠道主要来自平台A，那么就提高这批样本权重。</li>
</ul>
<h5><span id="技术角度"><strong><font color="red">
技术角度：</font></strong></span></h5>
<ul>
<li><p><strong>欠采样</strong>：</p>
<ul>
<li><p><strong>EasyEnsemble</strong>：从多数类<span class="math inline">\(S_{max}\)</span>上随机抽取一个子集，与其他类训练一个分类器；重复若干次，多个分类器融合。</p></li>
<li><p><font color="red"><strong>BalanceCascade</strong></font>：从多数类<span class="math inline">\(S_{max}\)</span>上随机抽取一个子集，与其他类训练一个分类器；<strong>剔除能被分类正确的分类器</strong>，重复若干次，多个分类器融合。</p></li>
<li><p><strong>NearMIss</strong>：利用K邻近信息挑选具有代表性的样本。</p></li>
<li><p><strong>one-side Selection</strong>：采用数据清洗技术。</p></li>
</ul></li>
<li><p><strong>过采样</strong>：</p>
<ul>
<li><p><strong>随机采样</strong></p></li>
<li><p><strong>SMOTE算法</strong>：对少数类<span class="math inline">\(S_{min}\)</span>中每个样本x的K近邻随机选取一个样本y，在x，y的连线上随机选取一个点作为新的样本点。</p></li>
<li><p><strong>Borderline-SMOTE、ADASYN改进算法等</strong></p></li>
</ul></li>
<li><h5><span id="分层抽样技术批量训练分类器的分层抽样技术-当面对不平衡类问题时这种技术通过消除批次内的比例差异可使训练过程更加稳定">分层抽样技术：批量训练分类器的「分层抽样」技术。当面对不平衡类问题时，这种技术（通过消除批次内的比例差异）可使训练过程更加稳定。</span></h5></li>
</ul>
<h4><span id="12-算法的角度"><strong>1.2 算法的角度</strong></span></h4>
<p>考虑<strong>不同误分类情况代价的差异性</strong>对算法进行优化，主要是基于<strong>代价敏感学习算法</strong>(Cost-Sensitive
Learning)，代表的算法有<strong>adacost</strong>。<a href="实现基于代价敏感的AdaCost算法">实现基于代价敏感的AdaCost算法</a></p>
<ul>
<li><p><strong>代价函数</strong>：可以增加小类样本的权值，降低大类样本的权值（这种方法其实是产生了新的数据分布，即产生了新的数据集），从而使得分类器将重点集中在小类样本身上。刚开始，可以设置每个类别的权值与样本个数比例的倒数，然后可以使用过采样进行调优。</p>
<blockquote>
<p>这种方法的难点在于设置合理的权重，实际应用中一般让各个分类间的加权损失值近似相等。当然这并不是通用法则，还是需要具体问题具体分析。</p>
</blockquote></li>
<li><h5><span id="xgb自定义损失函数jhwjhw0123imbalance-xgboostfocalloss">XGB自定义损失函数
/<strong><a href="https://github.com/jhwjhw0123/Imbalance-XGBoost">Imbalance-XGBoost</a></strong>【Focal
Loss】：</span></h5></li>
</ul>
<p><span class="math display">\[
L_w=-\sum_{i=1}^m \hat{y}_i\left(1-y_i\right)^\gamma \log
\left(y_i\right)+\left(1-\hat{y}_i\right) y_i^\gamma \log
\left(1-y_i\right)
\]</span></p>
<h4><span id="13-分类方式">1.3 <strong>分类方式</strong></span></h4>
<p>可以把小类样本作为<strong>异常点</strong>(outliers)，把问题转化为<strong>异常点检测问题(anomaly
detection)</strong>。此时分类器需要学习到大类的决策分界面，即分类器是一个<strong>单个类分类器（One
Class Classifier）</strong>。代表的算法有<font color="red">
<strong>One-class SVM</strong></font>。</p>
<h5><span id="一类分类算法">一类分类算法：</span></h5>
<p>不平衡数据集的一类分类算法:https://machinelearningmastery.com/one-class-classification-algorithms/</p>
<p>一类分类是机器学习的一个领域，它提供了异常值和异常检测的技术,如何使一类分类算法适应具有严重偏斜类分布的不平衡分类,如何拟合和评估
SVM、隔离森林、椭圆包络、局部异常因子等一类分类算法。</p>
<h5><span id="不平数据集的划分方法">不平数据集的划分方法？</span></h5>
<ul>
<li><p>K折交叉验证？</p></li>
<li><p>自助法？</p></li>
</ul>
<h5><span id="不平数据集的评价方法">不平数据集的评价方法？</span></h5>
<p>G-Mean和ROC曲线和AUC。Topk@P</p>
<ul>
<li><strong>AP衡量的是学出来的模型在每个类别上的好坏，mAP衡量的是学出的模型在所有类别上的好坏，得到AP后mAP的计算就变得很简单了，就是取所有AP的平均值。</strong></li>
</ul>
<h3><span id="二-类别不平衡如何得到一个不错的分类器">二、「类别不平衡」如何得到一个不错的分类器？</span></h3>
<blockquote>
<p><strong>微调</strong>：<a href="https://zhuanlan.zhihu.com/p/32940093">如何处理数据中的「类别不平衡」？</a></p>
</blockquote>
<p>机器学习中常常会遇到数据的<strong>类别不平衡（class
imbalance）</strong>，也叫数据偏斜（class
skew）。以常见的二分类问题为例，我们希望预测病人是否得了某种罕见疾病。但在历史数据中，阳性的比例可能很低（如百分之0.1）。在这种情况下，学习出好的分类器是很难的，而且在这种情况下得到结论往往也是很具迷惑性的。</p>
<p>以上面提到的场景来说，如果我们的分类器<strong>总是</strong>预测一个人未患病，即预测为反例，那么我们依然有高达99.9%的预测准确率。然而这种结果是没有意义的，这提出了今天的第一个问题，如何有效在类别不平衡的情况下评估分类器？</p>
<p><strong>当然，本文最终希望解决的问题是：在数据偏斜的情况下，如何得到一个不错的分类器？如果可能，是否可以找到一个较为简单的解决方法，而规避复杂的模型、数据处理，降低我们的工作量。</strong></p>
<h4><span id="21类别不平衡下的评估问题"><strong>2.1
类别不平衡下的评估问题</strong>?</span></h4>
<p>而<strong>当类别不平衡时，准确率就非常具有迷惑性</strong>，而且意义不大。给出几种主流的评估方法：</p>
<ul>
<li><strong>ROC</strong>是一种常见的替代方法，全名receiver operating
curve，计算ROC曲线下的面积是一种主流方法</li>
<li><strong>Precision-recall
curve</strong>和ROC有相似的地方，但定义不同，计算此曲线下的面积也是一种方法</li>
<li><strong>Precision@n</strong>是另一种方法，特制将分类阈值设定得到恰好n个正例时分类器的precision</li>
<li>Average
precision也叫做平均精度，主要描述了precision的一般表现，在异常检测中有时候会用</li>
<li>直接使用Precision也是一种想法，但此时的假设是分类器的阈值是0.5，因此意义不大</li>
</ul>
<blockquote>
<p>本文的目的不是介绍一般的分类评估标准，简单的科普可以参看：<a href="https://www.zhihu.com/question/19645541">如何解释召回率与准确率？</a></p>
</blockquote>
<h4><span id="22解决类别不平衡中的奇淫巧技有什么"><strong>2.2
解决类别不平衡中的“奇淫巧技”有什么？</strong></span></h4>
<p>对于类别不平衡的研究已经有很多年了，在资料[1]中就介绍了很多比较复杂的技巧。结合我的了解举几个简单的例子：</p>
<blockquote>
<p>[1] He, H. and Garcia, E.A., 2009. Learning from imbalanced data.
<em>IEEE Transactions on knowledge and data engineering</em>,
<em>21</em>(9), pp.1263-1284.</p>
</blockquote>
<ul>
<li>对数据进行采用的过程中通过相似性同时生成并插样“少数类别数据”，叫做SMOTE算法</li>
<li>对数据先进行聚类，再将大的簇进行随机欠采样或者小的簇进行数据生成</li>
<li>把监督学习变为无监督学习，舍弃掉标签把问题转化为一个无监督问题，如异常检测</li>
<li><strong>先对多数类别进行随机的欠采样，并结合boosting算法进行集成学习</strong></li>
</ul>
<h4><span id="23简单通用的算法有哪些"><strong>2.3
简单通用的算法有哪些？</strong></span></h4>
<ul>
<li>对较多的那个类别进行欠采样(under-sampling)，舍弃一部分数据，使其与较少类别的数据相当</li>
<li>对较少的类别进行过采样(over-sampling)，重复使用一部分数据，使其与较多类别的数据相当</li>
<li><strong>阈值调整（threshold
moving）</strong>，将原本默认为0.5的阈值调整到
较少类别/（较少类别+较多类别）即可</li>
</ul>
<p>当然很明显我们可以看出，<strong>第一种和第二种方法都会明显的改变数据分布，我们的训练数据假设不再是真实数据的无偏表述</strong>。在第一种方法中，我们<strong>浪费了很多数据</strong>。而第二类方法中有无中生有或者重复使用了数据，会导致过拟合的发生。</p>
<p><strong>因此欠采样的逻辑中往往会结合集成学习来有效的使用数据，假设正例数据n，而反例数据m个。我们可以通过欠采样，随机无重复的生成（k=n/m）个反例子集，并将每个子集都与相同正例数据合并生成k个新的训练样本。我们在k个训练样本上分别训练一个分类器，最终将k个分类器的结果结合起来，比如求平均值。这就是一个简单的思路，也就是Easy
Ensemble [5]。</strong></p>
<p>但不难看出，其实这样的过程是需要花时间处理数据和编程的，对于很多知识和能力有限的人来说难度比较大。特此推荐两个简单易行且效果中上的做法：</p>
<ul>
<li>简单的调整阈值，不对数据进行任何处理。此处特指将分类阈值从0.5调整到正例比例</li>
<li>使用现有的集成学习分类器，如随机森林或者xgboost，<strong>并调整分类阈值</strong></li>
</ul>
<p><strong>提出这样建议的原因有很多。首先，简单的阈值调整从经验上看往往比过采样和欠采样有效</strong>
[6]。其次，如果你对统计学知识掌握有限，而且编程能力一般，在集成过程中更容易出错，还不如使用现有的集成学习并调整分类阈值。</p>
<h4><span id="24一个简单但有效的方案"><strong>2.4
一个简单但有效的方案</strong></span></h4>
<p>经过了上文的分析，我认为一个比较靠谱的解决方案是：</p>
<ul>
<li>不对数据进行过采样和欠采样，但使用现有的集成学习模型，如随机森林</li>
<li>输出随机森林的预测概率，<strong>调整阈值得到最终结果</strong></li>
<li><strong>选择合适的评估标准，如precision@n</strong></li>
</ul>
<h3><span id="三-脉脉数据集不平衡应该思考什么">三、脉脉：数据集不平衡应该思考什么</span></h3>
<p>首先, 猜测一下, 你研究的数据存在着较 大的不平衡,
你还是比较关注正类(少数类) 样本的, 比如【想要识别出 有信用风险 的
人】那么就要谈一下你所说的【模型指标还行】这个问题。<strong>auc这种复合指标先不提,
precision代表的是, 你预测的信用风险人群,
其中有多少是真的信用风险人群。recall 代表的是,
"真的信用风险人群"有多少被你识别出来了</strong>；</p>
<ul>
<li>所以, 倘若你比较关注的是【我想要找出
所有"可能有违约风险的人"】宁可错杀也不
放过。那么你应该重点关注的就是召回率 recall。在此基础上,
尽量提高precision。</li>
<li>你把训练集的正负样本控制在64左右, 那 么你是怎么控制的呢,
是单纯用了数据清理技术, 还是单纯生成了一些新的样本, 还是怎么做的？</li>
<li><font color="red"><strong>如果条件允许, 可以查看一下你被错分的 样本,
看看被错分的原因可能是什么, 是因为类重叠,
还是有少数类的分离还是单纯的因为不平衡比太夸张所以使分类器产生偏倚?</strong>
</font></li>
<li><font color="red">不知道你用的什么模型,
但是现在有一些把重采样和分类器结合在一起的集成学习方法,
可以试试看。</font></li>
<li>维度太高的时候, <strong>特征的提取很重要</strong>呀！</li>
<li>当做异常检测问题可能会好一些?</li>
</ul>
<h3><span id="四-样本准备与权重指标">四、样本准备与权重指标</span></h3>
<blockquote>
<p>样本权重对逻辑回归评分卡的影响探讨:
https://zhuanlan.zhihu.com/p/110982479</p>
</blockquote>
<h4><span id="风控业务背景"><strong>风控业务背景</strong></span></h4>
<p><strong>在统计学习建模分析中，样本非常重要，它是我们洞察世界的窗口</strong>。在建立逻辑回归评分卡时，我们也会考虑对样本赋予不同的权重weight，希望模型学习更有侧重点。</p>
<p>诚然，我们可以通过实际数据测试来检验赋权前后的差异，但我们更希望从理论上分析其合理性。毕竟理论可以指导实践。本文尝试探讨样本权重对逻辑回归评分卡的影响，以及从业务和技术角度分析样本权重调整的操作方法。</p>
<h4><span id="part-1样本加权对woe的影响"><strong>Part 1.
样本加权对WOE的影响</strong></span></h4>
<p>在<strong>《</strong><a href="https://zhuanlan.zhihu.com/p/80134853">WOE与IV指标的深入理解应用</a><strong>》</strong>一文中,
我们介绍了WOE的概念和计算方法。在逻辑回归评分卡中, 其具有
重要意义。其公式定义如下:</p>
<p><span class="math display">\[
W_O=\ln \left(\frac{\text { Good }_i}{\text { Good }_T} / \frac{\text {
Bad }_i}{\operatorname{Bad}_T}\right)=\ln \left(\frac{\text { Good
}_i}{\text { Bad }_i}\right)-\ln \left(\frac{\text { Good
}_T}{\operatorname{Bad}_T}\right)
\]</span>
<strong>现在，我们思考在计算WOE时，是否要考虑样本权重呢?</strong></p>
<p>如图1所示的样本, 我们希望对某些样本加强学习,
因此对年龄在46岁以下的样本赋予权重1.5, 而对46岁以上的样本赋予权重1.0,
也就是加上权重列weight。此时再计算WOE值,
我们发现数值发生变化。这是因为权重的改 变, 既影响了局部bucket中的
odds，也影响了整体的 odds 。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261249252.jpg" alt="img">我们有2种对样本赋权后的模型训练方案，如图2所示。</p>
<ul>
<li>方案1: WOE变换利用原训练集，LR模型训练时利用加权后的样本。</li>
<li>方案2: WOE变换和LR模型训练时，均使用加权后的样本。</li>
</ul>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261249494.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>个人更倾向于第一种方案，原因在于：<strong>WOE变换侧重变量的可解释性，引入样本权重会引起不可解释的困扰。</strong></p>
<h4><span id="part-2采样对lr系数的影响"><strong>Part 2.
采样对LR系数的影响</strong></span></h4>
<p>我们定义特征向量 <span class="math inline">\(\mathbf{x}=x_1, x_2,
\ldots, x_n\)</span> 。记 <span class="math inline">\(G=\operatorname{Good}, B=B a d\)</span>,
那么逻辑回归的公式组成便是: <span class="math display">\[
\begin{aligned}
&amp; \operatorname{Ln}(\text { odds }(G \mid
\mathbf{x}))=\operatorname{Ln}\left(\frac{p_G f(\mathbf{x} \mid G)}{p_B
f(\mathbf{x} \mid
B)}\right)=\operatorname{Ln}\left(\frac{p_G}{p_B}\right)+\operatorname{Ln}\left(\frac{f(\mathbf{x}
\mid G)}{f(\mathbf{x} \mid B)}\right) \\
&amp;
=\operatorname{Ln}\left(\frac{p_G}{p_B}\right)+\operatorname{Ln}\left(\frac{f\left(x_1,
x_2, \ldots, x_n \mid G\right)}{f\left(x_1, x_2, \ldots, x_n \mid
B\right)}\right) \\
&amp;
=\operatorname{Ln}\left(\frac{p_G}{p_B}\right)+\operatorname{Ln}\left(\frac{f\left(x_1
\mid G\right)}{f\left(x_1 \mid
B\right)}\right)+\operatorname{Ln}\left(\frac{f\left(x_2 \mid
G\right)}{f\left(x_2 \mid
B\right)}\right)+\ldots+\operatorname{Ln}\left(\frac{f\left(x_n \mid
G\right)}{f\left(x_n \mid B\right)}\right) \\
&amp; =L n\left(\text { odd } s_{\text {pop
}}\right)+\operatorname{Ln}\left(\text { odd } s_{i n f
o}(\mathbf{x})\right) \\
&amp;
\end{aligned}
\]</span> 其中, 第2行到第3行的变换是基于朴素贝叶斯假设, 即自变量 <span class="math inline">\(x_i\)</span> 之间相互独立。</p>
<ul>
<li><span class="math inline">\(o d d s_{p o p}\)</span> 是指总体
(训练集) 的 <span class="math inline">\(o d d s\)</span>, 指先验信息
<span class="math inline">\(o d d s\)</span> 。</li>
<li><span class="math inline">\(o d d s_{i n f o}(\mathbf{x})\)</span>
是指自变量引起的 <span class="math inline">\(o d d s\)</span> 变化,
我们称为后验信息 <span class="math inline">\(o d d s 。\)</span></li>
</ul>
<p><font color="red">因此，随着观察信息的不断加入，对群体的好坏 <span class="math inline">\(o d d s\)</span> 判断将越来越趋于客观。</font></p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-0021358b05ebb5fea25073cceea1da2d_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h5><span id="样本权重调整直接影响先验项也就是截距-那对系数的影响呢">样本权重调整直接影响先验项，也就是截距。那对系数的影响呢？</span></h5>
<p>接下来，我们以过采样（Oversampling）和欠采样（Undersampling）为例，分析采样对LR系数的影响。如图4所示，对于不平衡数据集，过采样是指对正样本简单复制很多份；欠采样是指对负样本随机抽样。最终，正负样本的比例将达到1:1平衡状态。</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-c49197fdd37023e75daabd7e74feb11b_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>我们同样从贝叶斯角度进行解释:</strong> <span class="math display">\[
\begin{gathered}
P(B \mid \mathbf{x})=\frac{P(\mathbf{x} \mid B)
P(B)}{P(\mathbf{x})}=\frac{P(\mathbf{x} \mid B) P(B)}{P(\mathbf{x} \mid
B) P(B)+P(\mathbf{x} \mid G) P(G)} \\
\Leftrightarrow \frac{1}{P(B \mid \mathbf{x})}=1+\frac{P(\mathbf{x} \mid
G) P(G)}{P(\mathbf{x} \mid B) P(B)} \\
\Leftrightarrow \operatorname{Ln}\left(\frac{P(\mathbf{x} \mid
G)}{P(\mathbf{x} \mid B)}\right)=\operatorname{Ln}\left(\frac{1}{P(B
\mid
\mathbf{x})}-1\right)-\operatorname{Ln}\left(\frac{P(G)}{P(B)}\right) \\
\Leftrightarrow \operatorname{Ln}\left(\frac{P(G \mid \mathbf{x})}{P(B
\mid \mathbf{x})}\right)=\operatorname{Ln}\left(\frac{P(\mathbf{x} \mid
G)}{P(\mathbf{x} \mid
B)}\right)+\operatorname{Ln}\left(\frac{P(G)}{P(B)}\right)
\end{gathered}
\]</span> 假设采样处理后的训练集为 <span class="math inline">\(\mathbf{x}^{\prime}\)</span> 。记 <span class="math inline">\(\# B\)</span> 和 <span class="math inline">\(\#
G\)</span> 分别表示正负样本数, 那么显然: <span class="math display">\[
o d d s=\frac{\# G}{\# B} \neq \frac{\# G^{\prime}}{\# B^{\prime}}=o d d
s^{\prime}
\]</span> 由于 <span class="math inline">\(\operatorname{Ln}\left(\frac{P(G)}{P(B)}\right)=\operatorname{Ln}\left(\frac{\#
G}{\# B}\right)\)</span> ，因此对应截距将发生变化。</p>
<p><font color="red">无论是过采样, 还是欠采样,
处理后的新样本都和原样本服从同样的分布, 即满足</font>: <span class="math display">\[
\begin{aligned}
&amp; P(\mathbf{x} \mid G)=P\left(\mathbf{x}^{\prime} \mid
G^{\prime}\right) \\
&amp; P(\mathbf{x} \mid B)=P\left(\mathbf{x}^{\prime} \mid
B^{\prime}\right)
\end{aligned}
\]</span> 因此, <span class="math inline">\(\operatorname{Ln}\left(\frac{P(\mathbf{x} \mid
G)}{P(\mathbf{x} \mid
B)}\right)=\operatorname{Ln}\left(\frac{P\left(\mathbf{x}^{\prime} \mid
G^{\prime}\right)}{P\left(\mathbf{x}^{\prime} \mid
B^{\prime}\right)}\right)\)</span>, 即系数不发生变化。</p>
<p><strong>实践证明，按照做评分卡的方式，做WOE变换，然后跑LR，单变量下确实只有截距影响。而对于多变量，理想情况下，当各自变量相互独立时，LR的系数是不变的，但实际自变量之间多少存在一定的相关性，所以还是会有一定的变化。</strong></p>
<h4><span id="part-3样本准备与权重指标"><strong><font color="red"> Part 3.
样本准备与权重指标</font></strong></span></h4>
<p><strong>风控建模的基本假设是末来样本和历史样本的分布是一致的</strong>。模型从历史样本中拟合
<span class="math inline">\(X_{\text {old }}\)</span> 和 <span class="math inline">\(y\)</span> 之间的关系，并 根据末来样本的 <span class="math inline">\(X_{\text {new }}\)</span>
进行预测。<font color="red">因此, 我们总是在思考,
如何选择能代表末来样本的训练样本。</font></p>
<p>如图5所示，不同时间段、不同批次的样本总是存在差异，即<strong>服从不同的总体分布</strong>。因此，我们需要<strong>从多个维度来衡量两个样本集之间的相似性。</strong></p>
<p>从迁移学习的角度看，这是一个从源域（source
domain）中学习模式，并应用到目标域（target
domain）的过程。在这里，源域是训练集，目标域指测试集，或者未来样本。</p>
<p>这就会涉及到一些难点：</p>
<ul>
<li>假设测试集OOT与未来总体分布样本基本一致，但未来样本是不可知且总是在发生变化。</li>
<li>面向测试集效果作为评估指标，会出现在测试集上过拟合现象。 <img src="https://pic4.zhimg.com/80/v2-b40bd56da51ab37d01fbffbdb8bc91f7_1440w.jpg" alt="img"></li>
</ul>
<p><strong>那么，建模中是否可以考虑建立一个权重指标体系，即综合多方面因素进行样本赋权？我们采取2种思路来分析如何开展。</strong></p>
<p><strong><font color="red"> 业务角度</font></strong>：</p>
<ol type="1">
<li><strong>时间因素</strong>，对近期样本提高权重，较远样本降低权重。这是考虑近期样本与未来样本之间的“相似度”更高，希望模型学到更多近期样本的模式。</li>
<li><strong>贷款类型</strong>，不同额度、利率、期限的样本赋予不同权重，这需要结合业务未来的发展方向。例如，未来业务模式希望是小额、短期、低利率，那就提高这批样本的权重。</li>
<li><strong>样本分群</strong>，不同群体赋予不同权重。例如，按流量获客渠道，如果未来流量渠道主要来自平台A，那么就提高这批样本权重。</li>
</ol>
<p>结合以上各维度，可得到总体采样权重的一种融合方式为： <span class="math display">\[
w=w_1 * w_2 * w_3
\]</span>
<strong>这种业务角度的方案虽然解释性强，但实际拍定多大的权重显得非常主观，实践中往往需要不断尝试，缺少一些理论指导。</strong></p>
<p><strong><font color="red"> 技术角度：</font></strong></p>
<ol type="1">
<li><strong>过采样、欠采样等，从样本组成上调整正负不平衡</strong>。</li>
<li><strong>代价敏感学习，在损失函数对好坏样本加上不同的代价。比如，坏样本少，分错代价更高。</strong></li>
<li><strong>借鉴Adaboost的做法，对误判样本在下一轮训练时提高权重。</strong></li>
</ol>
<p>在机器学习中，有一个常见的现象——<strong>Covariate
Shift</strong>，是指当训练集的样本分布和测试集的样本分布不一致的时候，训练得到的模型无法具有很好的泛化
(Generalization) 能力。</p>
<p>其中一种做法，既然是希望让训练集尽可能像测试集，那就让模型帮助我们做这件事。如图6所示，将测试集标记为1，训练集标记为0，训练一个LR模型，在训练集上预测，概率越高，说明这个样例属于测试集的可能性越大。以此达到样本权重调整的目的。</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-6a218af9de452a4c58e36a9e8e6d4bb0_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="part-4常见工具包的样本赋权"><strong>Part 4.
常见工具包的样本赋权</strong></span></h4>
<p>现有Logistic
Regression模块主要来自sklearn和scipy两个包。很不幸，scipy包并不支持直接赋予权重列。这是为什么呢？有统计学家认为，<strong><font color="red">
尊重真实样本分布，人为主观引入样本权重，反而可能得出错误的结论。</font></strong></p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-4942078e60d225438f77362c675bec20_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>因此，我们只能选择用scikit-learn。样本权重是如何体现在模型训练过程呢？查看源码后，发现目前主要是体现在<strong>损失函数</strong>中，即<strong>代价敏感学习。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Logistic loss is the negative of the log of the logistic function.</span></span><br><span class="line"><span class="comment"># 添加L2正则项的逻辑回归对数损失函数</span></span><br><span class="line">out = -np.<span class="built_in">sum</span>(sample_weight * log_logistic(yz)) + <span class="number">.5</span> * alpha * np.dot(w, w)</span><br></pre></td></tr></table></figure>
<p><strong><font color="red">
样本权重对决策分割面的影响:</font></strong></p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-699ad7ac670c27a5b0963b8b104ad7fc_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>以下是scikit-learn包中的逻辑回归参数列表说明，可以发现调节样本权重的方法有两种：</p>
<ul>
<li>在class_weight参数中使用balanced</li>
<li>在调用fit函数时，通过sample_weight调节每个样本权重。</li>
</ul>
<p>如果同时设置上述2个参数，<strong>那么样本的真正权重是class_weight *
sample_weight.</strong></p>
<p><strong>那么，在评估模型的指标时，是否需要考虑抽样权重，即还原真实场景下的模型评价指标？</strong>笔者认为，最终评估还是需要还原到真实场景下。例如，训练集正负比例被调节为1:1，但这并不是真实的<span class="math inline">\(odds\)</span>，在预测时将会偏高。因此，仍需要进行模型校准。</p>
<h4><span id="part-5-总结"><strong>Part 5. 总结</strong></span></h4>
<p>本文系统整理了样本权重的一些观点，但目前仍然没有统一的答案。据笔者所知，目前在实践中还是采取以下几种方案：</p>
<ol type="1">
<li>尊重原样本分布，不予处理，LR模型训练后即为真实概率估计。</li>
<li>结合权重指标综合确定权重，训练完毕模型后再进行校准，还原至真实概率估计。</li>
</ol>
<p>值得指出的是，大环境总是在发生变化，造成样本分布总在偏移。因此，尽可能增强模型的鲁棒性，以及策略使用时根据实际情况灵活调整，两者相辅相成，可能是最佳的使用方法。欢迎大家一起讨论业界的一些做法。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>机器学习中不平衡数据的预处理：https://capallen.gitee.io/2019/Deal-with-imbalanced-data-in-ML.html</li>
<li>如何处理数据中的「类别不平衡」？：https://zhuanlan.zhihu.com/p/32940093</li>
<li><strong><font color="blue">不平衡数据集处理方法</font></strong>：https://blog.csdn.net/asialee_bird/article/details/83714612</li>
<li><strong><font color="blue">不平衡数据究竟出了什么问题？</font></strong>：https://www.zhihu.com/column/jiqizhixin</li>
<li>数据挖掘时，当正负样本不均，代码如何实现改变正负样本权重? -
十三的回答 - 知乎
https://www.zhihu.com/question/356640889/answer/2299286791</li>
<li><strong>样本权重对逻辑回归评分卡的影响探讨</strong> -
求是汪在路上的文章 - 知乎 https://zhuanlan.zhihu.com/p/110982479</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（3）特征选择</title>
    <url>/posts/2DEZT90/</url>
    <content><![CDATA[<h3><span id="特征选择">特征选择</span></h3>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/74198735">【机器学习】特征选择(Feature
Selection)方法汇总</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/306057603"><em>特征选择方法</em>全面总结</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/479948993"><em>特征选择</em>的基本<em>方法</em>总结</a></p>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261231076.jpg" style="zoom: 67%;"></p>
<p>训练数据包含许多冗余或无用的特征，移除这些特征并不会导致丢失信息。其中冗余是指一个本身很有用的特征与另外一个有用的特征强相关，或它包含的信息能从其它特征推演出来;
特征很多但样本相对较少。</p>
<ul>
<li><p><strong>产生过程</strong>：产生特征或特征子集候选集合；</p></li>
<li><p><strong>评价函数</strong>：衡量特征或特征子集的重要性或者好坏程度，即量化特征变量和目标变量之间的联系以及特征之间的相互联系。为了避免过拟合，可用交叉验证的方式来评估特征的好坏；</p></li>
<li><p><strong>停止准则</strong>：为了减少计算复杂度，需设定一个阈值，当评价函数值达到阈值后搜索停止</p></li>
<li><p><strong>验证过程</strong>：在验证数据集上验证选出来的特征子集的有效性</p></li>
</ul>
<h3><span id="一-特征选择的目的"><strong>一、特征选择的目的</strong></span></h3>
<p>1.<strong>简化模型</strong>，使模型更易于理解：去除不相关的特征会降低学习任务的难度。并且可解释性能对模型效果的稳定性有更多的把握</p>
<p>2.<strong>改善性能</strong>：节省存储和计算开销</p>
<p>3.<strong>改善通用性、降低过拟合风险</strong>：减轻维数灾难，特征的增多会大大增加模型的搜索空间，大多数模型所需要的训练样本随着特征数量的增加而显著增加。特征的增加虽然能更好地拟合训练数据，但也可能增加方差</p>
<h3><span id="二-特征选择常见方法">二、特征选择常见方法</span></h3>
<ul>
<li><strong>Filter(过滤法)</strong>
<ul>
<li><strong>覆盖率</strong></li>
<li><strong>方差选择</strong></li>
<li><strong>Pearson(皮尔森)相关系数</strong></li>
<li><strong>卡方检验</strong></li>
<li><strong>互信息法(KL散度、相对熵)和最大信息系数</strong></li>
<li>Fisher得分</li>
<li>相关特征选择</li>
<li>最小冗余最大相关性</li>
</ul></li>
<li><strong>Wrapper(包装法)</strong>
<ul>
<li>完全搜索</li>
<li>启发搜索</li>
<li>随机搜索</li>
</ul></li>
<li><strong>Embedded(嵌入法)</strong>
<ul>
<li>L1 正则项</li>
<li>树模型选择</li>
<li>不重要性特征选择</li>
</ul></li>
</ul>
<h3><span id="三-filter过滤法特征集">三、<strong>Filter(过滤法)</strong>
【特征集】</span></h3>
<h3><span id></span></h3>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261231951.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h5><span id="定义"><strong>定义</strong></span></h5>
<ul>
<li><strong>过滤法的思想就是不依赖模型，仅从特征的角度来做特征的筛选</strong>，具体又可以分为两种方法，一种是根据特征里面包含的信息量，如方差选择法，如果一列特征的方差很小，每个样本的取值都一样的话，说明这个特征的作用不大，可以直接剔除。另一种是对每一个特征，都计算关于目标特征的<a href="https://www.zhihu.com/search?q=相关度&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22479948993%22%7D">相关度</a>，然后根据这个相关度来筛选特征，只保留高于某个阈值的特征，这里根据相关度的计算方式不同就可以衍生出一下很多种方法。</li>
</ul>
<h5><span id="分类"><strong>分类</strong></span></h5>
<ul>
<li><strong>单变量过滤方法</strong>：不需要考虑特征之间的相互关系，按照特征变量和目标变量之间的相关性或互信息对特征进行排序，过滤掉最不相关的特征变量。优点是计算效率高、不易过拟合。</li>
<li><strong>多变量过滤方法</strong>：考虑特征之间的相互关系，常用方法有基于相关性和一致性的特征选择</li>
</ul>
<h5><span id="覆盖率">覆盖率</span></h5>
<ul>
<li>即特征在训练集中出现的比例。若覆盖率很小，如有10000个样本，但某个特征只出现了5次，则次覆盖率对模型的预测作用不大，可删除</li>
</ul>
<h5><span id="1方差选择法">（1）<strong>方差选择法</strong></span></h5>
<ul>
<li>先计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"><span class="comment"># 方差选择法，返回值为特征选择后的数据</span></span><br><span class="line"><span class="comment"># 参数threshold为方差的阈值</span></span><br><span class="line">VarianceThreshold(threshold=<span class="number">3</span>).fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<h5><span id="2pearson皮尔森相关系数">（2）Pearson皮尔森相关系数</span></h5>
<p><font color="red"><strong>用于度量两个变量X和Y之间的线性相关性</strong></font></p>
<ul>
<li><strong>用于度量两个变量X和Y之间的线性相关性</strong>，结果的取值区间为[-1,
1]，
-1表示完全的负相关(这个变量下降，那个就会上升)，+1表示完全的正相关，0表示没有线性相关性</li>
<li>计算方法为两个变量之间的<strong>协方差</strong>和<strong>标准差</strong>的商</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line">  <span class="comment"># 选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line">  <span class="comment"># 第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，</span></span><br><span class="line">  <span class="comment"># 输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。</span></span><br><span class="line">  <span class="comment"># 在此为计算相关系数</span></span><br><span class="line">  <span class="comment"># 其中参数k为选择的特征个数</span></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(<span class="built_in">map</span>(<span class="keyword">lambda</span> x:pearsonr(x, Y), X.T)).T, </span><br><span class="line">              k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<h5><span id="3卡方检验">（3）<strong>卡方检验</strong></span></h5>
<p><font color="red">自变量对因变量的相关性</font></p>
<p><strong>检验定性自变量对定性因变量的相关性</strong>。假设自变量有N种取值，因变量有M种取值，考虑自变量等于i且因变量等于j的样本频数的观察值与期望的差距，构建统计量:
<span class="math display">\[
\chi^2=\sum \frac{(A-E)^2}{E}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line"><span class="comment">#选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line">SelectKBest(chi2, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<h5><span id="4psi互信息法kl散度-相对熵和最大信息系数mutual-information-and-maximal-information-coefficient-mic">（4）PSI互信息法(KL散度、相对熵)和最大信息系数
Mutual information and maximal information coefficient (MIC)</span></h5>
<blockquote>
<p><strong><font color="red">
风控模型—群体稳定性指标(PSI)深入理解应用</font></strong>:https://zhuanlan.zhihu.com/p/79682292</p>
</blockquote>
<p>评价定性自变量对定性因变量的相关性，评价类别型变量对类别型变量的相关性，互信息越大表明两个变量相关性越高，互信息为0时，两个变量相互独立。互信息的计算公式为
<span class="math display">\[
I(X ; Y)=\sum_{x \in X} \sum_{y \in Y} p(x, y) \log \frac{p(x, y)}{p(x)
p(y)}=D_{K L}(p(x, y) \| p(x) p(y))
\]</span></p>
<h5><span id="5fisher得分">（5）<strong>Fisher得分</strong></span></h5>
<p>对于分类问题, <strong>好的特征应该是在同一个类别中的取值比较相似,
而在不同类别之间的取值差异比较大</strong>。因此特征 <span class="math inline">\(\mathrm{i}\)</span> 的重要性可用Fiser得分 <span class="math inline">\(S_i\)</span> 来表示 <span class="math display">\[
S_i=\frac{\sum_{j=1}^K n_j\left(\mu_{i j}-\mu_i\right)^2}{\sum_{j=1}^K
n_j \rho_{i j}^2}
\]</span> 其中, <span class="math inline">\(u_{i j}\)</span> 和 <span class="math inline">\(\rho_{i j}\)</span> 分别是特征i在类别 <span class="math inline">\(j\)</span> 中均值和方差, <span class="math inline">\(\mu_i\)</span> 为特征i的均值, <span class="math inline">\(n_j\)</span>
为类别中中的样本数。<strong>Fisher得分越高,
特征在不同类别之间的差异性越大、在同一类别中的差异性越小，则特征越重要;</strong></p>
<h5><span id="6相关特征选择">（6）<strong>相关特征选择</strong></span></h5>
<p>该方法基于的假设是，好的特征集合包含跟目标变量非常相关的特征，但这些特征之间彼此不相关</p>
<h5><span id="7最小冗余最大相关性mrmr">（7）<strong>最小冗余最大相关性(
mRMR)</strong></span></h5>
<p>由于单变量过滤法只考虑了单特征变量和目标变量之间的相关性，因此选择的特征子集可能过于冗余。mRMR在进行特征时考虑到了特征之间的冗余性，具体做法是对跟已选择特征相关性较高的冗余特征进行惩罚;</p>
<h4><span id="四-wrapper包装法特征集模型">四、Wrapper(包装法)
【特征集+模型】</span></h4>
<p><img src="https://pic4.zhimg.com/v2-bd321ff1e16c011d1a2bce86a5939a17_b.jpg"></p>
<p><strong>定义</strong></p>
<ul>
<li><p>使用<strong>机器学习算法评估特征子集</strong>的效果，可以检测两个或多个特征之间的交互关系，而且选择的特征子集让模型的效果达到最优。</p></li>
<li><p>这是<strong>特征子集搜索</strong>和<strong>评估指标相结合</strong>的方法。前者提供候选的新特征子集，后者基于新特征子集训练一个模型，并用验证集进行评估，为每一组特征子集进行打分。</p></li>
<li><p>最简单的方法是在<strong>每一个特征子集上训练并评估模型</strong>，从而找出最优的特征子集</p></li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>需要对每一组特征子集训练一个模型，<strong>计算量很大</strong></li>
<li>样本不够充分的情况下<strong>容易过拟合</strong></li>
<li>特征变量较多时计算复杂度太高</li>
</ul>
<h5><span id="1完全搜索">（1）完全搜索</span></h5>
<p>即穷举法, 遍历所有可能的组合达到全局最优, 时间复杂度 <span class="math inline">\(2^n\)</span></p>
<h5><span id="2启发式搜索">（2）启发式搜索</span></h5>
<p>序列向前选择: 特征子集从空集开始, 每次只加入一个特征, 时间复杂度为
<span class="math inline">\(O(n+(n-1)+(n-2)+\ldots+1)=O\left(n^2\right)\)</span></p>
<p>序列向后选择: 特征子集从全集开始, 每次删除一个特征, 时间复杂度为
<span class="math inline">\(O\left(n^2\right)\)</span></p>
<h5><span id="3随机搜索">（3）<strong>随机搜索</strong></span></h5>
<p>执行序列向前或向后选择时，随机选择特征子集</p>
<h5><span id="4递归特征消除法">（4）<strong>递归特征消除法</strong></span></h5>
<p>使用一个基模型进行多轮训练，每轮训练后通过学习器返回的<strong>coef</strong>_或者<strong>feature_importances</strong>_消除若干权重较低的特征，再基于新的特征集进行下一轮训练。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment">#递归特征消除法，返回特征选择后的数据</span></span><br><span class="line"><span class="comment">#参数estimator为基模型</span></span><br><span class="line"><span class="comment">#参数n_features_to_select为选择的特征个数</span></span><br><span class="line">RFE(estimator=LogisticRegression(), </span><br><span class="line">    n_features_to_select=<span class="number">2</span>).fit_transform(iris.data, </span><br><span class="line">                                          iris.target)</span><br></pre></td></tr></table></figure>
<h3><span id="五-embedded嵌入法">五、Embedded（嵌入法）</span></h3>
<p>将特征选择嵌入到模型的构建过程中，具有包装法与机器学习算法相结合的优点，也具有过滤法计算效率高的优点</p>
<h5><span id="1lasso方法-l1正则项">（1）LASSO方法 L1正则项</span></h5>
<p>通过对回归系数添加惩罚项来防止过拟合，可以让特定的回归系数变为0，从而可以选择一个不包含那些系数的更简单的模型；实际上，L1惩罚项降维的原理是，在多个对实际上，L1惩罚项降维的原理是，在多个对目标值具有同等相关性的特征中，只保留一个，所以没保留的特征并不代表不重要具有同等相关性的特征中，只保留一个，所以没保留的特征并不代表不重要。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment">#带L1惩罚项的逻辑回归作为基模型的特征选择</span></span><br><span class="line">SelectFromModel(LogisticRegression(</span><br><span class="line">          penalty=<span class="string">&quot;l1&quot;</span>, C=<span class="number">0.1</span>)).fit_transform(</span><br><span class="line">               iris.data,iris.target)</span><br></pre></td></tr></table></figure>
<h5><span id="2基于树模型的特征选择方法">（2）基于树模型的特征选择方法</span></h5>
<ul>
<li>在决策树中，深度较浅的节点一般对应的特征分类能力更强(可以将更多的样本区分开)</li>
<li>对于基于决策树的算法，如随机森林，重要的特征更有可能出现在深度较浅的节点，而且出现的次数可能越多</li>
<li>即可基于树模型中特征出现次数等指标对特征进行重要性排序</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="comment">#GBDT作为基模型的特征选择</span></span><br><span class="line">SelectFromModel(</span><br><span class="line">    GradientBoostingClassifier()).fit_transform(</span><br><span class="line">      iris.data,iris.target)</span><br></pre></td></tr></table></figure>
<h5><span id="3使用特征重要性来筛选特征的缺陷">（3）使用特征重要性来筛选特征的缺陷？</span></h5>
<ul>
<li>特征重要性只能说明哪些特征在训练时起到作用了，并不能说明特征和目标变量之间一定存在依赖关系。举例来说，随机生成一大堆没用的特征，然后用这些特征来训练模型，一样可以得到特征重要性，但是这个特征重要性并不会全是0，这是完全没有意义的。</li>
<li>特征重要性容易高估数值特征和基数高的类别特征的重要性。这个道理很简单，特征重要度是根据决策树分裂前后节点的不纯度的减少量（基尼系数或者MSE）来算的，那么对于数值特征或者基础高的类别特征，不纯度较少相对来说会比较多。</li>
<li>特征重要度在选择特征时需要决定阈值，要保留多少特征、删去多少特征，这些需要人为决定，并且删掉这些特征后模型的效果也不一定会提升。</li>
</ul>
<h5><span id="4non-importance-选择">（4）Non importance 选择</span></h5>
]]></content>
      <categories>
        <category>算法</category>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（6）Auto工具</title>
    <url>/posts/30CKG49/</url>
    <content><![CDATA[<h3><span id="一-autoeda-工具">一、AutoEDA 工具</span></h3>
<blockquote>
<p>盘点Kaggle中常见的AutoEDA工具库：
https://zhuanlan.zhihu.com/p/444405236</p>
</blockquote>
<h4><span id="41-pandas-profiling">4.1 <strong>Pandas Profiling</strong></span></h4>
<ul>
<li><a href="http://link.zhihu.com/?target=https%3A//pandas-profiling.github.io/pandas-profiling/docs/master/index.html">https://pandas-profiling.github.io/pandas-profiling/docs/master/index.html</a></li>
</ul>
<p><strong>Pandas
Profiling</strong>是款比较成熟的工具，可以直接传入DataFrame即可完成分析过程，将结果展示为HTML格式，同时分析功能也比较强大。</p>
<ul>
<li>功能：<strong>字段类型分析、变量分布分析、相关性分析、缺失值分析、重复行分析</strong></li>
<li>耗时：较少</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261406349.jpg" alt="img" style="zoom: 67%;"></p>
<h4><span id="42-autoviz"><strong>4.2 AutoViz</strong></span></h4>
<ul>
<li><a href="http://link.zhihu.com/?target=https%3A//github.com/AutoViML/AutoViz">https://github.com/AutoViML/AutoViz</a></li>
</ul>
<p><strong>AutoViz是款美观的数据分析工具</strong>，在进行可视化的同时将结果保存为图片格式。</p>
<ul>
<li>功能：<strong>相关性分析、数值变量箱线图、数值变量分布图</strong></li>
<li>耗时：较多</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261406304.jpg" alt="img" style="zoom: 67%;"></p>
<h4><span id="43-dataprep">4.3 <strong>Dataprep</strong></span></h4>
<ul>
<li><a href="http://link.zhihu.com/?target=https%3A//dataprep.ai/">https://dataprep.ai/</a></li>
</ul>
<p><strong>Dataprep是款比较灵活也比较强大的工具，也是笔者最喜欢的。它可以指定列进行分析，同时也可以在Notebook中进行交互式分析。</strong></p>
<ul>
<li>功能：<strong>字段类型分析、变量分布分析、相关性分析、缺失值分析、交互式分析</strong>。</li>
<li>耗时：较多</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261406891.jpg" alt="img" style="zoom: 67%;"></p>
<h4><span id="44-sweetviz"><strong>4.4 SweetViz</strong></span></h4>
<ul>
<li><a href="http://link.zhihu.com/?target=https%3A//github.com/fbdesignpro/sweetviz">https://github.com/fbdesignpro/sweetviz</a></li>
</ul>
<p><strong>SweetViz是款强大的数据分析工具，可以很好的分析训练集和测试集，以及目标标签与特征之间的关系</strong>。</p>
<ul>
<li>功能：数据集对比分析、字段类型分析、变量分布分析、目标变量分析</li>
<li>耗时：中等<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261406924.jpg" alt="img" style="zoom:67%;"></li>
</ul>
<h4><span id="45-d-tale">4.5 D-Tale</span></h4>
<ul>
<li><a href="http://link.zhihu.com/?target=https%3A//github.com/man-group/dtale">https://github.com/man-group/dtale</a></li>
</ul>
<p><code>D-Tale</code>是款功能最为强大的数据分析工具，对单变量的分析过程支持比较好。</p>
<ul>
<li>功能：字段类型分析、变量分布分析、相关性分析、缺失值分析、交互式分析。</li>
<li>耗时：中等</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261406335.jpg" alt="img" style="zoom:67%;"></p>
<h3><span id="二-警惕特征工程中的陷阱">二、警惕「特征工程」中的陷阱</span></h3>
<ul>
<li>https://zhuanlan.zhihu.com/p/33651227</li>
</ul>
<p>特征工程(Feature
Engineering)是机器学习中的重要环节。在传统的项目中，百分之七十以上的时间都花在了预处理数据上(Data
Preprocessing)，其中特征工程消耗了很多时间。</p>
<p><strong>一般来说, 特征工程涵盖的内容非常广泛,
包括从缺失值补全、特征选择、维度压缩, 到对输入数据的范围进行变 换 (Data
Scaling) 等</strong>。举个简单的例子, 一个K-近邻算法的输入数据有两个特征
<span class="math inline">\(X_1, X_2\)</span>, 但 <span class="math inline">\(X_1\)</span> 这个特征的 取值范围在 <span class="math inline">\([0,1]\)</span> 而 <span class="math inline">\(X_2\)</span> 的范围在 <span class="math inline">\([-1000,1000]\)</span> 。不可避免的,
K-近邻的结果取决于距离, 那么很容易被取值范 围大的特征, 也就是此处的
<span class="math inline">\(X_2\)</span> 所“垄断”。在这种情况下, 把
<span class="math inline">\(X_1, X_2\)</span>
的取值调整到可比较的范围上就成了必须。 常见的做法有归一化或者标准化,
此处不再赘述, 可以参考[1]。为了简化内容, 本文中的例子仅以归一化作为唯
一的特征工程。今天主要说的是: 特征工程中的面临的进退两难。</p>
<h4><span id="21-如何保证训练集-测试集-预测数据-有相同的输入">2.1 <strong>如何保证
训练集、测试集、预测数据 有相同的输入？</strong></span></h4>
<p>以刚才的例子为基础，我们把所有数据按照70:30的比例分为训练集和测试集，并打算使用K-近邻进行训练。那么一个令人困扰的问题是，对训练集的特征做归一化后，测试集的特征怎么办？这是一个非常关键的问题，因为训练集<strong>特征归一化</strong>后，测试集的特征范围可能就不同了，因此模型失效。一般有几种思路：</p>
<ul>
<li><strong>方法1：把训练集和测试集合在一起做归一化</strong>，这样特征范围就统一了。之后用训练集做训练，那测试集做测试。<strong>但很明显的，在训练模型时，不应该包括任何测试集的信息</strong>。这种做法会导致存在人为偏差的模型，不能用。</li>
<li><strong>方法2：对训练集单独做归一化，之后对测试集单独做归一化</strong>。这种看法看似也可以，重点在于数据量以及数据的排列顺序。<strong>在数据量大且数据被充分打乱的前提下，这种做法是可行的</strong>。但换句话说，如果有这样的前提假设，那么方法1的结论也是可行的。</li>
<li><strong>方法3：对训练集先做归一化，并保留其归一化参数（如最大、最小值），之后用训练集的归一化参数对测试集做处理。</strong>这种做法看似是可以的。<strong>但风险在于数据量有限的前提下，训练集的参数会导致测试集的结果异常，如产生极大或者极小的数值</strong>。</li>
</ul>
<blockquote>
<p>其实不难看出，从某种意义上说，三种做法是等价的。在数据量大且充分打乱的前提下，训练集和验证集有相同的分布假设，因此用任意一种其实差别不大。然而这样的假设过于乐观，<strong>且我们在真实情况下应该只有{训练集+1个测试数据}，因此方法2是明显不行的</strong>。</p>
<p>方法1常常被认为是错误的操作，原因是在训练阶段引入了测试数据，这属于未知数据。即使仅仅引入了1个测试数据，如果取值非常极端，依然会导致输出范围有较大的波动。其次，如果对于每一个测试数据都需要用整个训练集来归一的话，那么运算开销会非常大。</p>
<p>那么似乎备选的只有方案3，即保<strong>留验证集上的归一化参数</strong>，并运用于测试集。这样的做法看似可以，但有不少风险：</p>
<ul>
<li><strong>不是每种特征工程都可以保存参数，很多特征工程是非常繁复的</strong>。</li>
<li>如果测试集数据和训练集数据有很大的差别，那么用测试集的参数会产生异常数据。</li>
</ul>
</blockquote>
<h4><span id="22-可能的解决方案">2.2 可能的解决方案</span></h4>
<p>在<strong>模型评估阶段</strong>，如果我们假设拥有大量数据，且充分打乱其顺序。那么在划分训练集和测试集前，可以对整体数据进行统一的特征工程。不难看出，这和统计学的大数定理有异曲同工之妙。这种做法是最为高效的，需要的运算量最小。而将“测试数据”暴露给训练模型的风险也并不大，因为大数据量使得分布比较稳定，可以忽略。换个角度来看，当数据量非常大的时候，使用其他方法进行特征工程的开销会过大，不利于模型评估。因此，在<strong>模型评估阶段</strong>，如果符合以上假设，可以用这种方法（也就是上文的方法1）。但退一步说，如果满足这个条件，那么方法3也是等价的。</p>
<p>在<strong>预测阶段</strong>，每次假设我们只有1个测试点，那么最佳方案还是保存训练集上特征工程的参数或者模型，并直接用于未知数据的特征工程（也就是上文的方法3）。</p>
<p>但在<strong>预测阶段</strong>，一个一个数据的预测是非常昂贵的，我们一般会做<strong>“批处理”(batch
operation)</strong>。换句话说，就是攒够一定量的预测数据后统一进行预测。在这种情况下，我们：</p>
<ul>
<li>利用方法3，按照顺序对每个训练数据进行处理</li>
<li>利用方法1，风险在于（方法1）会影响训练数据且需要重新训模型</li>
<li><strong>利用方法2，此时较为稳妥</strong>。在批的尺寸较大，且与训练数据分布相同（接近）时，效果应该与方法3一致，但效率可以得到提升</li>
</ul>
<h4><span id="23-总结"><strong>2.3 总结</strong></span></h4>
<p>这篇文章的重点是：“特征工程虽然重要，但极容易在使用中带来风险。”比如在训练时同时误用了测试数据进行特征工程，也叫做数据泄露(data
leakage)。但数据泄露其实也是个伪命题，<strong>当数据量大且分布相同时，使用哪一种方法得到结果应该都近似等价，而更重要的是运行效率</strong>。分类讨论的话，方法1、2、3都有可能是适合的方法。</p>
<p>但我们依然希望能避免类似的风险，因此尽量避免不必要的特征工程，有以下建议：</p>
<ul>
<li><strong>选择对于特征学习能力强的模型，在数据量允许的情况下可以选择深度学习</strong></li>
<li><strong>避免不必要的特征工程，数据范围比较良好的情况下省略某些特征工程</strong></li>
<li><strong>优先选择对于特征工程要求低的模型，如xgboost等</strong></li>
</ul>
<h3><span id="三-业务角度看特征工程">三、业务角度看特征工程</span></h3>
<p><a href="https://zhuanlan.zhihu.com/p/505480353">如何从业务角度看特征工程</a></p>
<p>前两天刷某知名社交软件的时候看到有人问特征工程现在还重要吗？觉得是个很有意思的事情。其实工业界能够支持的起大规模稀疏向量的场景大概并不是想象中的那么多，大多数场景面对极为稀疏的行为数据下都很难在ID层面得到很好的emb表达。在这个前提下，没有好的特征工程，其余的模型结构优化或者各种花里胡哨的模型结构都是纸上谈兵。真正被小场景捶打过的朋友，比如我，绝对会在一次又一次的生活毒打中明白，抛弃那些ppt上的高级多塔多注意力，直面特征工程的人生吧！</p>
<p>有竞赛经验的小伙伴都明白，一个强特能一飞冲天，一个灵机一动能直上top榜。但是，长久的可持续的特征工程决不能够靠简单的灵机一动来实现，特别是当手上有无数的芝麻大小的场景时，一个系统的特征工程思维就尤为重要了。本文将从以下几个方面来阐述特征工程中的方方面面。提前说明的是，一般的特征工程常用方法，例如one-hot，hash-encoding，分桶等等不会作为本文的重点，因为这是器的维度，文末有一篇非常全面的文章供参考，本文主要聚焦在术的维度，也就是怎么去思考和选用方法的层面。<strong>首先，我会给出一个特征工程树，这个属于一个主流版本，希望在屏蔽场景特殊性的情况下，给出一般场景的思考方法</strong>。接下来，我会介绍上文提到的特征树的细节，包括涉及到的具体特征例子。第三部分，则包括特征之间可能存在的相互作用和不同特征适合的模型类型。最后，我给出了一个具体场景的具体例子，并说明这个场景的一般性和特殊性，给出针对具体业务场景的特征工程思路。</p>
<p>此外，一个基础认知是，这里的特征是指输入模型的信息，包括偏置或者先验，这些特征的使用方式除了作为模型的输入，也可以通过其他的方式引入，例如样本工程或者损失函数，这个就不在本文讨论范围之内了。当然还是那句老话，个人的认知是有限的，欢迎有经验的小伙伴交流和指正。</p>
<h4><span id="31-基础特征树">3.1 基础特征树</span></h4>
<p>不管是基于已有的模型迭代优化，又或者是从0到1构建一个场景的全部特征，都需要自己梳理一个完整的基础特征树。这是了解一个场景的开始。做这件事情我推荐的方法是<strong>先体验这个场景，然后分类列出所有可能影响你优化目标决策的因素以及优化目标的历史信息</strong>。</p>
<p>对于绝大多数业务来讲，基础的特征树都可以分为以下3大部分。</p>
<ul>
<li><strong>供给侧</strong>：对于大部分to
c的互联网应用，供给侧都是item，可能是音乐，doc或者一条推送消息。</li>
<li><strong>消费侧</strong>：有关用户的一切描述，其中比较特殊的是序列特征。</li>
<li><strong>上下文</strong>：场景测的因素，包括特定的时刻，特定的展现形式等。</li>
<li><strong>交叉特征</strong>：以上三个部分任意两部分或全部的交叉特征。</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（9）TF-IDF</title>
    <url>/posts/4YNH5E/</url>
    <content><![CDATA[<h3><span id="一-tf-idf">一、TF-IDF</span></h3>
<blockquote>
<p>https://blog.csdn.net/u010417185/article/details/87905899</p>
</blockquote>
<p><strong>TF-IDF(Term Frequency-Inverse Document Frequency,
词频-逆文件频率)</strong>是一种用于资讯检索与资讯探勘的常用<a href="https://www.zhihu.com/search?q=加权技术&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%2297273457%22%7D">加权技术</a>。TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。</p>
<p>上述引用总结就是, <strong>一个词语在一篇文章中出现次数越多,
同时在所有文档中出现次数越少,
越能够代表该文章。</strong>这也就是TF-IDF的含义。</p>
<h4><span id="11-tf"><strong>1.1 TF</strong></span></h4>
<p><strong>TF(Term
Frequency，词频)</strong>表示词条在文本中出现的频率，这个数字通常会被归一化(一般是词频除以文章总词
数),
以防止它偏向长的文件（同一个词语在长文件里可能会比短文件有更高的词频,
而不管该词语重要与否）。TF 用公式表示如下: <span class="math display">\[
T F_{i, j}=\frac{n_{i, j}}{\sum_k n_{k, j}}
\]</span> 其中, <span class="math inline">\(n_{i, j}\)</span> 表示词条
<span class="math inline">\(t_i\)</span> 在文档 <span class="math inline">\(d_j\)</span> 中出现的次数, <span class="math inline">\(T F_{i, j}\)</span> 就是表示词条 <span class="math inline">\(t_i\)</span> 在文档 <span class="math inline">\(d_j\)</span> 中出现的频率。</p>
<p><strong>但是, 需要注意, 一些通用的词语对于主题并没有太大的作用,
反倒是一些出现频率较少的词才能够表达文章的主题,
所以单纯使用是TF不合适的</strong>。权重的设计必须满足：一个词预测主题的能力越强,
权重越大, 反之, 权重 越小。所有统计的文章中,
一些词只是在其中很少几篇文章中出现, 那么这样的词对文章的主题的作用很大,
这些 词的权重应该设计的较大。IDF就是在完成这样的工作。</p>
<h4><span id="12-idf"><strong>1.2 IDF</strong></span></h4>
<p><strong>IDF(Inverse Document
Frequency，逆文件频率)</strong>表示关键词的普遍程度。如果包含词条 <span class="math inline">\(i\)</span> 的文档越少, IDF越 大,
则说明该词条具有很好的类别区分能力。某一特定词语的IDF,
可以由总文件数目除以包含该词语之文件的数 目, 再将得到的商取对数得到:
<span class="math display">\[
I D F_i=\log \frac{|D|}{1+\left|j: t_i \in d_j\right|}
\]</span> 其中, <span class="math inline">\(|D|\)</span>
表示所有<strong>文档的数量, <span class="math inline">\(\left|j: t_i \in
d_j\right|\)</span> 表示包含词条 <span class="math inline">\(t_i\)</span> 的文档数量</strong>, 为什么这里要加 1
呢? 主要是<strong>防止包含词条 <span class="math inline">\(t_i\)</span>
的数量为 0 从而导致运算出错的现象发生</strong>。</p>
<p>某一特定文件内的高词语频率, 以及该词语在整个文件集合中的低文件频率,
可以产生出高权重的TF-IDF。因此, TF-IDF倾向于<strong>过滤淖常见的词语,
保留重要的词语,</strong> 表达为 <span class="math display">\[
T F-I D F=T F \cdot I D F
\]</span> 最后在计算完文档中每个字符的tfidf之后, 对其进行归一化,
将值保留在0-1之间, 并保存成稀疏矩阵。</p>
<h3><span id="二-tf-idf-qampa">二、TF-IDF Q&amp;A</span></h3>
<h4><span id="1-究竟应该是对整个语料库进行tf-idf呢还是先对训练集进行tf-idf然后再对xtest进行tf-idf呢两者有什么区别"><strong>1、究竟应该是对整个语料库进行tf-idf呢？还是先对训练集进行tf-idf，然后再对xtest进行tf-idf呢？两者有什么区别？</strong></span></h4>
<h5><span id="fit">fit</span></h5>
<ul>
<li>学习输入的数据有多少个不同的单词，以及每个单词的idf</li>
</ul>
<h5><span id="transform-训练集">transform 训练集</span></h5>
<ul>
<li>回我们一个document-term matrix.</li>
</ul>
<h5><span id="transform-测试集">transform 测试集</span></h5>
<p>transform的过程也很让人好奇。要知道，他是将测试集的数据中的文档数量纳入进来，重新计算每个词的idf呢，还是<strong>直接用训练集学习到的idf去计算测试集里面每一个tf-idf</strong>呢？</p>
<p><strong>如果纳入了测试集新词，就等于预先知道测试集中有什么词，影响了idf的权重。这样预知未来的行为，会导致算法丧失了泛化性。</strong></p>
<h4><span id="2-tf-idf模型加载太慢"><font color="red">2、TF-IDF
模型加载太慢</font></span></h4>
<blockquote>
<p>https://thiagomarzagao.com/2015/12/08/saving-TfidfVectorizer-without-pickles/</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> idfs <span class="keyword">import</span> idfs <span class="comment"># numpy array with our pre-computed idfs</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># subclass TfidfVectorizer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyVectorizer</span>(<span class="title class_ inherited__">TfidfVectorizer</span>):</span><br><span class="line">    <span class="comment"># plug our pre-computed IDFs</span></span><br><span class="line">    TfidfVectorizer.idf_ = idfs</span><br><span class="line"></span><br><span class="line"><span class="comment"># instantiate vectorizer</span></span><br><span class="line">vectorizer = MyVectorizer(lowercase = <span class="literal">False</span>,</span><br><span class="line">                          min_df = <span class="number">2</span>,</span><br><span class="line">                          norm = <span class="string">&#x27;l2&#x27;</span>,</span><br><span class="line">                          smooth_idf = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plug _tfidf._idf_diag</span></span><br><span class="line">vectorizer._tfidf._idf_diag = sp.spdiags(idfs,</span><br><span class="line">                                         diags = <span class="number">0</span>,</span><br><span class="line">                                         m = <span class="built_in">len</span>(idfs),</span><br><span class="line">                                         n = <span class="built_in">len</span>(idfs))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>算法</category>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（8）【draft】时间序列处理</title>
    <url>/posts/TYS9XF/</url>
    <content><![CDATA[<h2><span id="时间序列数据的预处理">时间序列数据的预处理</span></h2>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/466086665"><em>时间序列</em>数据的预<em>处理</em></a></li>
<li><a href="https://mp.weixin.qq.com/s/vyDZfDdaH2Y7k75NNsMNJA">如何在实际场景中使用异常检测？阿里云Prometheus智能检测算子来了</a></li>
</ul>
<blockquote>
<p>在本文中，我们将主要讨论以下几点：</p>
<ul>
<li>时间序列数据的定义及其重要性。</li>
<li>时间序列数据的预处理步骤。</li>
<li>构建时间序列数据，查找缺失值，对特征进行去噪，并查找数据集中存在的异常值。</li>
</ul>
</blockquote>
<h3><span id="时间序列的定义">时间序列的定义</span></h3>
<p><strong>时间序列是在特定时间间隔内记录的一系列均匀分布的观测值</strong>。时间序列的一个例子是黄金价格。在这种情况下，我们的观察是在固定时间间隔后一段时间内收集的黄金价格。时间单位可以是分钟、小时、天、年等。但是任何两个连续样本之间的时间差是相同的。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（10）模型训练-损失函数</title>
    <url>/posts/1TPZG47/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记-损失函数">[PyTorch 学习笔记] 损失函数</span></h2>
<h3><span id="一-损失函数">一、损失函数</span></h3>
<p><strong>损失函数是衡量模型输出与真实标签之间的差异</strong>。我们还经常听到<strong>代价函数</strong>和<strong>目标函数</strong>，它们之间差异如下：</p>
<ul>
<li><p><strong>损失函数</strong>(Loss
Function)是计算<strong>一个样本</strong>的模型输出与真实标签的差异 Loss
<img src="https://www.zhihu.com/equation?tex=%3Df%5Cleft%28y%5E%7B%5Cwedge%7D%2C+y%5Cright%29" alt="[公式]"></p></li>
<li><p><strong>代价函数</strong>(Cost
Function)是计算整个<strong>样本集</strong>的模型输出与真实标签的差异，是所有样本损失函数的平均值
<img src="https://www.zhihu.com/equation?tex=%5Ccos+t%3D%5Cfrac%7B1%7D%7BN%7D+%5Csum_%7Bi%7D%5E%7BN%7D+f%5Cleft%28y_%7Bi%7D%5E%7B%5Cwedge%7D%2C+y_%7Bi%7D%5Cright%29" alt="[公式]"></p></li>
<li><p><strong>目标函数</strong>(Objective
Function)就是代价函数加上正则项</p></li>
</ul>
<p><strong>在 PyTorch
中的损失函数也是继承于<code>nn.Module</code>，所以损失函数也可以看作网络层。</strong></p>
<p>在逻辑回归的实验中，我使用了交叉熵损失函数<code>loss_fn = nn.BCELoss()</code>，<img src="https://www.zhihu.com/equation?tex=BCELoss" alt="[公式]">
的继承关系：<code>nn.BCELoss() -&gt; _WeightedLoss -&gt; _Loss -&gt; Module</code>。在计算具体的损失时<code>loss = loss_fn(y_pred.squeeze(), train_y)</code>，这里实际上在
Loss
中进行一次前向传播，<strong>最终调用<code>BCELoss()</code>的<code>forward()</code>函数<code>F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)</code>。</strong></p>
<h4><span id="11nncrossentropyloss-softmaxxlogxnnnllloss">1.1
<strong>nn.CrossEntropyLoss</strong> = softmax(x)+log(x)+nn.NLLLoss</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.CrossEntropyLoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, ignore_index=-<span class="number">100</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：把<code>nn.LogSoftmax()</code>和<code>nn.NLLLoss()</code>结合，计算交叉熵。<code>nn.LogSoftmax()</code>的作用是把输出值归一化到了
[0,1] 之间。</p>
<ul>
<li>weight：各类别的 loss 设置权值</li>
<li>ignore_index：忽略某个类别的 loss 计算</li>
<li><strong>reduction：计算模式</strong>，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<blockquote>
<p><strong>==下面介绍熵的一些基本概念==</strong></p>
<ul>
<li><strong>自信息</strong>：<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BI%7D%28x%29%3D-%5Clog+%5Bp%28x%29%5D" alt="[公式]"></li>
<li>信息熵就是求自信息的期望：<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BH%7D%28%5Cmathrm%7BP%7D%29%3DE_%7Bx+%5Csim+p%7D%5BI%28x%29%5D%3D-%5Csum_%7Bi%7D%5E%7BN%7D+P%5Cleft%28x_%7Bi%7D%5Cright%29+%5Clog+P%5Cleft%28x_%7Bi%7D%5Cright%29" alt="[公式]"></li>
<li><strong>相对熵</strong>，也被称为 KL
散度，用于衡量两个分布的相似性(距离)：<img src="https://www.zhihu.com/equation?tex=%5Cboldsymbol%7BD%7D_%7BK+L%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29%3D%5Cboldsymbol%7BE%7D_%7B%5Cboldsymbol%7Bx%7D+%5Csim+p%7D%5Cleft%5B%5Clog+%5Cfrac%7B%5Cboldsymbol%7BP%7D%28%5Cboldsymbol%7Bx%7D%29%7D%7BQ%28%5Cboldsymbol%7Bx%7D%29%7D%5Cright%5D" alt="[公式]">。其中 <img src="https://www.zhihu.com/equation?tex=P%28X%29" alt="[公式]">
是真实分布，<img src="https://www.zhihu.com/equation?tex=Q%28X%29" alt="[公式]"> 是拟合的分布</li>
<li><strong>交叉熵</strong>：<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BH%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29%3D-%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%5Cboldsymbol%7BP%7D%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29+%5Clog+%5Cboldsymbol%7BQ%7D%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29" alt="[公式]"></li>
</ul>
<p>相对熵展开可得：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Cboldsymbol%7BD%7D_%7BK+L%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29+%26%3D%5Cboldsymbol%7BE%7D_%7B%5Cboldsymbol%7Bx%7D+%5Csim+p%7D%5Cleft%5B%5Clog+%5Cfrac%7BP%28x%29%7D%7BQ%28%5Cboldsymbol%7Bx%7D%29%7D%5Cright%5D+%5C%5C+%26%3D%5Cboldsymbol%7BE%7D_%7B%5Cboldsymbol%7Bx%7D+%5Csim+p%7D%5B%5Clog+P%28%5Cboldsymbol%7Bx%7D%29-%5Clog+Q%28%5Cboldsymbol%7Bx%7D%29%5D+%5C%5C+%26%3D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+P%5Cleft%28x_%7Bi%7D%5Cright%29%5Cleft%5B%5Clog+P%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29-%5Clog+Q%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29%5Cright%5D+%5C%5C+%26%3D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+P%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29+%5Clog+P%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29-%5Csum_%7Bi%3D1%7D%5E%7BN%7D+P%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29+%5Clog+%5Cboldsymbol%7BQ%7D%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29+%5C%5C+%26%3D+H%28P%2CQ%29+-H%28P%29+%5Cend%7Baligned%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>所以<strong>交叉熵 = 信息熵 + 相对熵</strong>，即 <img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BH%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29%3D%5Cboldsymbol%7BD%7D_%7BK+%5Cboldsymbol%7BL%7D%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29%2B%5Cmathrm%7BH%7D%28%5Cboldsymbol%7BP%7D%29" alt="[公式]">，又由于信息熵 <img src="https://www.zhihu.com/equation?tex=H%28P%29" alt="[公式]">
是固定的，因此<strong>==优化交叉熵 <img src="https://www.zhihu.com/equation?tex=H%28P%2CQ%29" alt="[公式]">
等价于优化相对熵==</strong> <img src="https://www.zhihu.com/equation?tex=D_%7BKL%7D%28P%2CQ%29" alt="[公式]">。</p>
</blockquote>
<p>所以对于<strong>每一个样本</strong>的 Loss 计算公式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BH%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29%3D-%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%5Cboldsymbol%7BP%7D%5Cleft%28%5Cboldsymbol%7Bx%7D_%7B%5Cboldsymbol%7Bi%7D%7D%5Cright%29+%5Clog+Q%5Cleft%28%5Cboldsymbol%7Bx%7D_%7B%5Cboldsymbol%7Bi%7D%7D%5Cright%29+%3D+logQ%28x_%7Bi%7D%29" alt="[公式]">，因为 <img src="https://www.zhihu.com/equation?tex=N%3D1" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=P%28x_%7Bi%7D%29%3D1" alt="[公式]">。</p>
<p>所以 <img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+%5Ctext+%7B+class+%7D%29%3D-%5Clog+%5Cleft%28%5Cfrac%7B%5Cexp+%28x%5B%5Ctext+%7B+class+%7D%5D%29%7D%7B%5Csum_%7Bj%7D+%5Cexp+%28x%5Bj%5D%29%7D%5Cright%29%3D-x%5B%5Ctext+%7B+class+%7D%5D%2B%5Clog+%5Cleft%28%5Csum_%7Bj%7D+%5Cexp+%28x%5Bj%5D%29%5Cright%29" alt="[公式]">。</p>
<p>如果了类别的权重，则 <img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+%5Ctext+%7B+class+%7D%29%3D%5Coperatorname%7Bweight%7D%5B%5Ctext+%7B+class+%7D%5D%5Cleft%28-x%5B%5Ctext+%7B+class+%7D%5D%2B%5Clog+%5Cleft%28%5Csum_%7Bj%7D+%5Cexp+%28x%5Bj%5D%29%5Cright%29%5Cright%29" alt="[公式]">。</p>
<p>下面设有 3 个样本做 2 分类。inputs 的形状为 <img src="https://www.zhihu.com/equation?tex=3+%5Ctimes+2" alt="[公式]">，表示每个样本有两个神经元输出两个分类。target 的形状为
<img src="https://www.zhihu.com/equation?tex=3+%5Ctimes+1" alt="[公式]">，注意类别从 0 开始，类型为<code>torch.long</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># fake data</span></span><br><span class="line">inputs = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">3</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">target = torch.tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>], dtype=torch.long)</span><br><span class="line"></span><br><span class="line"><span class="comment"># def loss function</span></span><br><span class="line">loss_f_none = nn.CrossEntropyLoss(weight=<span class="literal">None</span>, reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">loss_f_sum = nn.CrossEntropyLoss(weight=<span class="literal">None</span>, reduction=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">loss_f_mean = nn.CrossEntropyLoss(weight=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># forward</span></span><br><span class="line">loss_none = loss_f_none(inputs, target)</span><br><span class="line">loss_sum = loss_f_sum(inputs, target)</span><br><span class="line">loss_mean = loss_f_mean(inputs, target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># view</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Cross Entropy Loss:&quot;</span>, loss_none, loss_sum, loss_mean)</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Cross Entropy Loss: tensor([<span class="number">1.3133</span>, <span class="number">0.1269</span>, <span class="number">0.1269</span>]) tensor(<span class="number">1.5671</span>) tensor(<span class="number">0.5224</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="12-nnnllloss">1.2 <strong>nn.NLLLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.NLLLoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, ignore_index=-<span class="number">100</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：实现<strong>负对数似然函数</strong>中的符号功能</p>
<p>主要参数：</p>
<ul>
<li><strong>weight</strong>：各类别的 loss 权值设置</li>
<li><strong>ignore_index</strong>：忽略某个类别</li>
<li><strong>reduction：计算模式</strong>，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p><strong>每个样本的 loss 公式为：</strong><img src="https://www.zhihu.com/equation?tex=l_%7Bn%7D%3D-w_%7By_%7Bn%7D%7D+x_%7Bn%2C+y_%7Bn%7D%7D" alt="[公式]">。还是使用上面的例子，第一个样本的输出为 [1,2]，类别为
0，则第一个样本的 loss 为 -1；第一个样本的输出为 [1,3]，类别为
1，则第一个样本的 loss 为 -3。</p>
<h4><span id="13-nnbceloss"><strong>1.3 nn.BCELoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.BCELoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>计算二分类的交叉熵</strong>。需要注意的是：输出值区间为
[0,1]。</p>
<p>主要参数：</p>
<ul>
<li>weight：各类别的 loss 权值设置</li>
<li>ignore_index：忽略某个类别</li>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p><strong>计算公式</strong>为：<img src="https://www.zhihu.com/equation?tex=l_%7Bn%7D%3D-w_%7Bn%7D%5Cleft%5By_%7Bn%7D+%5Ccdot+%5Clog+x_%7Bn%7D%2B%5Cleft%281-y_%7Bn%7D%5Cright%29+%5Ccdot+%5Clog+%5Cleft%281-x_%7Bn%7D%5Cright%29%5Cright%5D" alt="[公式]"></p>
<p>使用这个函数有两个不同的地方：</p>
<ul>
<li><strong>预测的标签需要经过 sigmoid 变换到 [0,1] 之间</strong>。</li>
<li><strong>真实的标签需要转换为 one hot
向量，类型为<code>torch.float</code>。</strong></li>
</ul>
<h4><span id="14nnbcewithlogitsloss">1.4
<strong>nn.BCEWithLogitsLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.BCEWithLogitsLoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>, pos_weight=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>结合 sigmoid
与二分类交叉熵</strong>。需要注意的是，网络最后的输出不用经过 sigmoid
函数。这个 loss 出现的原因是有时网络模型最后一层输出不希望是归一化到
[0,1] 之间，但是在计算 loss 时又需要归一化到 [0,1] 之间。</p>
<p>主要参数：</p>
<ul>
<li><strong>weight</strong>：<strong>各输出类别的 loss
权值设置</strong></li>
<li><strong>pos_weight</strong>：<strong>==设置输入样本类别对应的神经元的输出的
loss 权值==</strong></li>
<li>ignore_index：忽略某个类别</li>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<h4><span id="15-nnl1loss">1.5 <strong>nn.L1Loss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.L1Loss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>计算 inputs 与 target 之差的绝对值</strong></p>
<p>主要参数：</p>
<ul>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p>公式：<img src="https://www.zhihu.com/equation?tex=l_%7Bn%7D%3D%5Cleft%7Cx_%7Bn%7D-y_%7Bn%7D%5Cright%7C" alt="[公式]"></p>
<h4><span id="16-nnmseloss">1.6 <strong>nn.MSELoss</strong></span></h4>
<p>功能：计算 inputs 与 target 之差的平方</p>
<p>公式：<img src="https://www.zhihu.com/equation?tex=l_%7Bn%7D%3D%5Cleft%28x_%7Bn%7D-y_%7Bn%7D%5Cright%29%5E%7B2%7D" alt="[公式]"></p>
<p>主要参数：</p>
<ul>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<h4><span id="17-nnsmoothl1loss"><strong>1.7 nn.SmoothL1Loss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.SmoothL1Loss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：平滑的 L1Loss</p>
<p>公式：<img src="https://www.zhihu.com/equation?tex=z_%7Bi%7D%3D%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bll%7D0.5%5Cleft%28x_%7Bi%7D-y_%7Bi%7D%5Cright%29%5E%7B2%7D%2C+%26+%5Ctext+%7B+if+%7D%5Cleft%7Cx_%7Bi%7D-y_%7Bi%7D%5Cright%7C%3C1+%5C%5C+%5Cleft%7Cx_%7Bi%7D-y_%7Bi%7D%5Cright%7C-0.5%2C+%26+%5Ctext+%7B+otherwise+%7D%5Cend%7Barray%7D%5Cright." alt="[公式]"></p>
<p>下图中橙色曲线是 L1Loss，蓝色曲线是 Smooth L1Loss</p>
<p><img src="https://pic3.zhimg.com/80/v2-59bedd97c18dff6fe2bf9fd96494cac2_1440w.jpg" alt="img" style="zoom: 50%;"></p>
<p>主要参数：</p>
<ul>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<h4><span id="18-nnpoissonnllloss">1.8 <strong>nn.PoissonNLLLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.PoissonNLLLoss(log_input=<span class="literal">True</span>, full=<span class="literal">False</span>, size_average=<span class="literal">None</span>, eps=<span class="number">1e-08</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>泊松分布的负对数似然损失函数</strong></p>
<p>主要参数：</p>
<ul>
<li><p>log_input：输入是否为对数形式，决定计算公式</p></li>
<li><ul>
<li>当 log_input =
True，表示输入数据已经是经过对数运算之后的，loss(input, target) =
exp(input) - target * input</li>
<li>当 log_input = False，，表示输入数据还没有取对数，loss(input,
target) = input - target * log(input+eps)</li>
</ul></li>
<li><p>full：计算所有 loss，默认为 loss</p></li>
<li><p>eps：修正项，避免 log(input) 为 nan</p></li>
</ul>
<h4><span id="19-nnkldivloss">1.9 <strong>nn.KLDivLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.KLDivLoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>计算 KLD(divergence)，KL 散度，相对熵</strong></p>
<p>注意事项：需要提前将输入计算
log-probabilities，如通过<code>nn.logsoftmax()</code></p>
<p>主要参数：</p>
<ul>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)，batchmean(batchsize
维度求平均值)</li>
</ul>
<p>公式：<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+D_%7BK+L%7D%28P+%5C%7C+Q%29%3DE_%7Bx-p%7D%5Cleft%5B%5Clog+%5Cfrac%7BP%28x%29%7D%7BQ%28x%29%7D%5Cright%5D+%26%3DE_%7Bx-p%7D%5B%5Clog+P%28x%29-%5Clog+Q%28x%29%5D+%3D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+P%5Cleft%28x_%7Bi%7D%5Cright%29%5Cleft%28%5Clog+P%5Cleft%28x_%7Bi%7D%5Cright%29-%5Clog+Q%5Cleft%28x_%7Bi%7D%5Cright%29%5Cright%29+%5Cend%7Baligned%7D" alt="[公式]"></p>
<p>对于每个样本来说，计算公式如下，其中 <img src="https://www.zhihu.com/equation?tex=y_%7Bn%7D" alt="[公式]">
是真实值 <img src="https://www.zhihu.com/equation?tex=P%28x%29" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=x_%7Bn%7D" alt="[公式]"> 是经过对数运算之后的预测值 <img src="https://www.zhihu.com/equation?tex=logQ%28x%29" alt="[公式]">。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=l_%7Bn%7D%3Dy_%7Bn%7D+%5Ccdot%5Cleft%28%5Clog+y_%7Bn%7D-x_%7Bn%7D%5Cright%29" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h4><span id="110nnmarginrankingloss">1.10
<strong>nn.MarginRankingLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.MarginRankingLoss(margin=<span class="number">0.0</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>计算两个向量之间的相似度，用于排序任务</strong></p>
<p>特别说明：<strong>该方法计算 两组数据之间的差异，返回一个 <img src="https://www.zhihu.com/equation?tex=n+%5Ctimes+n" alt="[公式]"> 的
loss 矩阵</strong></p>
<p>主要参数：</p>
<ul>
<li>margin：边界值，<img src="https://www.zhihu.com/equation?tex=x_%7B1%7D" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=x_%7B2%7D" alt="[公式]">
之间的差异值</li>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p>计算公式：<img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+y%29%3D%5Cmax+%280%2C-y+%2A%28x+1-x+2%29%2B%5Coperatorname%7Bmargin%7D%29" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 的取值有 +1 和 -1。</p>
<ul>
<li>当 <img src="https://www.zhihu.com/equation?tex=y%3D1" alt="[公式]"> 时，希望 <img src="https://www.zhihu.com/equation?tex=x_%7B1%7D+%3E+x_%7B2%7D" alt="[公式]">，当 <img src="https://www.zhihu.com/equation?tex=x_%7B1%7D+%3E+x_%7B2%7D" alt="[公式]">，不产生 loss</li>
<li>当 <img src="https://www.zhihu.com/equation?tex=y%3D-1" alt="[公式]"> 时，希望 <img src="https://www.zhihu.com/equation?tex=x_%7B1%7D+%3C+x_%7B2%7D" alt="[公式]">，当 <img src="https://www.zhihu.com/equation?tex=x_%7B1%7D+%3C+x_%7B2%7D" alt="[公式]">，不产生 loss</li>
</ul>
<h4><span id="111-nnsoftmarginloss">1.11 <strong>nn.SoftMarginLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.SoftMarginLoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>计算二分类的 logistic 损失</strong></p>
<p>主要参数：</p>
<ul>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p>计算公式：<img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+y%29%3D%5Csum_%7Bi%7D+%5Cfrac%7B%5Clog+%281%2B%5Cexp+%28-y%5Bi%5D+%2A+x%5Bi%5D%29%29%7D%7B%5Ctext+%7B+x.nelement+%7D+0%7D" alt="[公式]"></p>
<h4><span id="112nnmultimarginloss">1.12
<strong>nn.MultiMarginLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.MultiMarginLoss(p=<span class="number">1</span>, margin=<span class="number">1.0</span>, weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：计算多分类的折页损失</p>
<p>主要参数：</p>
<ul>
<li>p：可以选择 1 或 2</li>
<li>weight：各类别的 loss 权值设置</li>
<li>margin：边界值</li>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p>计算公式：<img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+y%29%3D%5Cfrac%7B%5Cleft.%5Csum_%7Bi%7D+%5Cmax+%280%2C+%5Coperatorname%7Bmargin%7D-x%5By%5D%2Bx%5Bi%5D%29%5Cright%29%5E%7Bp%7D%7D%7B%5Cquad+%5Ctext+%7B+x.size+%7D%280%29%7D" alt="[公式]">，其中 y 表示真实标签对应的神经元输出，x
表示其他神经元的输出。</p>
<h4><span id="113nncosineembeddingloss">1.13
<strong>nn.CosineEmbeddingLoss</strong></span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.nn.CosineEmbeddingLoss(margin=0.0, size_average=None, reduce=None, reduction=&#x27;mean&#x27;)</span><br></pre></td></tr></table></figure>
<p>功能：采用余弦相似度计算两个输入的相似性</p>
<p>主要参数：</p>
<ul>
<li>margin：边界值，可取值 [-1, 1]，推荐为 [0, 0.5]</li>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p>计算公式：<img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+y%29%3D%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bll%7D1-%5Ccos+%5Cleft%28x_%7B1%7D%2C+x_%7B2%7D%5Cright%29%2C+%26+%5Ctext+%7B+if+%7D+y%3D1+%5C%5C+%5Cmax+%5Cleft%280%2C+%5Ccos+%5Cleft%28x_%7B1%7D%2C+x_%7B2%7D%5Cright%29-%5Coperatorname%7Bmargin%7D%5Cright%29%2C+%26+%5Ctext+%7B+if+%7D+y%3D-1%5Cend%7Barray%7D%5Cright." alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%5Ccos+%28%5Ctheta%29%3D%5Cfrac%7BA+%5Ccdot+B%7D%7B%5C%7CA%5C%7C%5C%7CB%5C%7C%7D%3D%5Cfrac%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+A_%7Bi%7D+%5Ctimes+B_%7Bi%7D%7D%7B%5Csqrt%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cleft%28A_%7Bi%7D%5Cright%29%5E%7B2%7D%7D+%5Ctimes+%5Csqrt%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cleft%28B_%7Bi%7D%5Cright%29%5E%7B2%7D%7D%7D" alt="[公式]"></p>
<h2><span id="二-损失函数qampa">二、损失函数Q&amp;A</span></h2>
<h4><span id="21nncrossentropyloss-softmaxxlogxnnnllloss">2.1
nn.CrossEntropyLoss = softmax(x)+log(x)+nn.NLLLoss?</span></h4>
<p>在各种深度学习框架中，我们最常用的损失函数就是交叉熵（torch.nn.CrossEntropyLoss），<strong>熵是用来描述一个系统的混乱程度,通过交叉熵我们就能够确定预测数据与真是数据之间的相近程度</strong>。交叉熵越小，表示数据越接近真实样本。</p>
<p><strong>交叉熵计算公式：</strong></p>
<p><img src="https://img-blog.csdnimg.cn/20191024155805924.png" alt="img" style="zoom:50%;"></p>
<p><strong>softmax函数</strong>又称为归一化指数函数，它可以把一个多维向量压缩在（0，1）之间，并且它们的和为1.</p>
<p><strong>计算公式：</strong></p>
<p><img src="https://img-blog.csdnimg.cn/20191024162238579.png" alt="1" style="zoom:50%;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line">z = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">z_exp = [math.exp(i) <span class="keyword">for</span> i <span class="keyword">in</span> z]  </span><br><span class="line"><span class="built_in">print</span>(z_exp)  <span class="comment"># Result: [2.72, 7.39, 20.09, 54.6, 2.72, 7.39, 20.09] </span></span><br><span class="line">sum_z_exp = <span class="built_in">sum</span>(z_exp)  </span><br><span class="line"><span class="built_in">print</span>(sum_z_exp)  <span class="comment"># Result: 114.98 </span></span><br><span class="line">softmax = [<span class="built_in">round</span>(i / sum_z_exp, <span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> z_exp]</span><br><span class="line"><span class="built_in">print</span>(softmax)  <span class="comment"># Result: [0.024, 0.064, 0.175, 0.475, 0.024, 0.064, 0.175]</span></span><br></pre></td></tr></table></figure>
<p><strong>log_softmax</strong>是指在softmax函数的基础上，再进行一次log运算，此时结果有正有负，<strong>log函数的值域是负无穷到正无穷，当x在0—1之间的时候，log(x)值在负无穷到0之间</strong>。</p>
<p><strong>nn.NLLLoss</strong>的结果就是把上面的<strong>输出与Label对应的那个值拿出来，再去掉负号，再求均值</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">input</span>=torch.randn(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">soft_input = torch.nn.Softmax(dim=<span class="number">0</span>)</span><br><span class="line">soft_input(<span class="built_in">input</span>)</span><br><span class="line">Out[<span class="number">20</span>]: </span><br><span class="line">tensor([[<span class="number">0.7284</span>, <span class="number">0.7364</span>, <span class="number">0.3343</span>],</span><br><span class="line">        [<span class="number">0.1565</span>, <span class="number">0.0365</span>, <span class="number">0.0408</span>],</span><br><span class="line">        [<span class="number">0.1150</span>, <span class="number">0.2270</span>, <span class="number">0.6250</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment">#对softmax结果取log</span></span><br><span class="line">torch.log(soft_input(<span class="built_in">input</span>))</span><br><span class="line">Out[<span class="number">21</span>]: </span><br><span class="line">tensor([[-<span class="number">0.3168</span>, -<span class="number">0.3059</span>, -<span class="number">1.0958</span>],</span><br><span class="line">        [-<span class="number">1.8546</span>, -<span class="number">3.3093</span>, -<span class="number">3.1995</span>],</span><br><span class="line">        [-<span class="number">2.1625</span>, -<span class="number">1.4827</span>, -<span class="number">0.4701</span>]])</span><br></pre></td></tr></table></figure>
<p>假设标签是[0,1,2]，第一行取第0个元素，第二行取第1个，第三行取第2个，去掉负号，即[0.3168,3.3093,0.4701],求平均值，就可以得到损失值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(<span class="number">0.3168</span>+<span class="number">3.3093</span>+<span class="number">0.4701</span>)/<span class="number">3</span></span><br><span class="line">Out[<span class="number">22</span>]: <span class="number">1.3654000000000002</span></span><br><span class="line"><span class="comment">#验证一下</span></span><br><span class="line">loss=torch.nn.NLLLoss()</span><br><span class="line">target=torch.tensor([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">loss(<span class="built_in">input</span>,target)</span><br><span class="line">Out[<span class="number">26</span>]: tensor(<span class="number">0.1365</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="nncrossentropyloss"><strong>nn.CrossEntropyLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss=torch.nn.NLLLoss()</span><br><span class="line">target=torch.tensor([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">loss(<span class="built_in">input</span>,target)</span><br><span class="line">Out[<span class="number">26</span>]: tensor(-<span class="number">0.1399</span>)</span><br><span class="line">loss =torch.nn.CrossEntropyLoss()</span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[ <span class="number">1.1879</span>,  <span class="number">1.0780</span>,  <span class="number">0.5312</span>],</span><br><span class="line">        [-<span class="number">0.3499</span>, -<span class="number">1.9253</span>, -<span class="number">1.5725</span>],</span><br><span class="line">        [-<span class="number">0.6578</span>, -<span class="number">0.0987</span>,  <span class="number">1.1570</span>]])</span><br><span class="line">target = torch.tensor([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">loss(<span class="built_in">input</span>,target)</span><br><span class="line">Out[<span class="number">30</span>]: tensor(<span class="number">0.1365</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（11）模型训练-优化器</title>
    <url>/posts/K3Z6CF/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记-优化器">[PyTorch 学习笔记] 优化器</span></h2>
<blockquote>
<p>torch.optim.lr_scheduler：调整学习率：https://blog.csdn.net/qyhaill/article/details/103043637</p>
</blockquote>
<p>这篇文章主要介绍了 PyTorch 中的优化器，包括 3
个部分：优化器的概念、optimizer 的属性、optimizer 的方法。</p>
<h3><span id="一-优化器">一、<strong>优化器</strong></span></h3>
<h4><span id="11-优化器的概念"><strong>1.1 优化器的概念</strong></span></h4>
<p><strong>PyTorch
中的优化器是用于管理并更新模型中可学习参数的值，使得模型输出更加接近真实标签。</strong></p>
<h4><span id="12-optimizer-的属性">1.2 <strong>optimizer 的属性</strong></span></h4>
<p>PyTorch 中提供了 Optimizer 类，定义如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Optimizer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"> <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, params, defaults</span>):</span><br><span class="line">        self.defaults = defaults</span><br><span class="line">        self.state = defaultdict(<span class="built_in">dict</span>)</span><br><span class="line">        self.param_groups = [] <span class="comment"># momentum、lr、weight_decay、params 等。</span></span><br></pre></td></tr></table></figure>
<p>主要有 3 个属性</p>
<ul>
<li>defaults：优化器的超参数，如 weight_decay，momentum</li>
<li>state：参数的缓存，如 momentum
中需要用到前几次的梯度，就缓存在这个变量中</li>
<li>param_groups：管理的参数组，是一个 list，其中每个元素是字典，包括
momentum、lr、weight_decay、params 等。</li>
<li>_step_count：记录更新 次数，在学习率调整中使用</li>
</ul>
<h4><span id="13-optimizer-的方法">1.3 <strong>optimizer 的方法</strong></span></h4>
<ul>
<li><strong>zero_grad()</strong>：<strong>清空所管理参数的梯度</strong>。由于
PyTorch
的特性是张量的梯度不自动清零，因此每次反向传播之后都需要清空梯度。</li>
<li><strong>step()</strong>：执行一步梯度更新</li>
<li><strong>add_param_group()</strong>：添加参数组</li>
<li><strong>state_dict()</strong>：获取优化器当前状态信息字典</li>
<li><strong>load_state_dict()</strong>：<strong>加载状态信息字典</strong>，包括
state 、momentum_buffer 和
param_groups。主要用于模型的断点续训练。我们可以在每隔 50 个 epoch
就保存模型的 state_dict
到硬盘，在意外终止训练时，可以继续加载上次保存的状态，继续训练。</li>
</ul>
<h4><span id="14-学习率">1.4 <strong>学习率</strong></span></h4>
<p><strong>学习率是影响损失函数收敛的重要因素，控制了梯度下降更新的步伐</strong>。下面构造一个损失函数
<img src="https://www.zhihu.com/equation?tex=y%3D%282x%29%5E%7B2%7D" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 的初始值为 2，学习率设置为 1。</p>
<h4><span id="15-momentum-动量">1.5 <strong>momentum 动量</strong></span></h4>
<blockquote>
<p><strong>在 PyTroch 中，momentum 的更新公式是：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=v_%7Bi%7D%3Dm+%2A+v_%7Bi-1%7D%2Bg%5Cleft%28w_%7Bi%7D%5Cright%29" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=w_%7Bi%2B1%7D%3Dw_%7Bi%7D-l+r+%2A+v_%7Bi%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
</blockquote>
<p><strong>==momentum
动量的更新方法，不仅考虑当前的梯度，还会结合前面的梯度。==</strong></p>
<p>momentum 来源于指数加权平均：<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7Bv%7D_%7Bt%7D%3D%5Cboldsymbol%7B%5Cbeta%7D+%2A+%5Cboldsymbol%7Bv%7D_%7Bt-1%7D%2B%28%5Cmathbf%7B1%7D-%5Cboldsymbol%7B%5Cbeta%7D%29+%2A+%5Cboldsymbol%7B%5Ctheta%7D_%7Bt%7D" alt="[公式]">，其中 <img src="https://www.zhihu.com/equation?tex=v_%7Bt-1%7D" alt="[公式]">
是上一个时刻的指数加权平均，<img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%7D" alt="[公式]"> 表示当前时刻的值，<img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]">
是系数，一般小于 1。指数加权平均常用于时间序列求平均值。假设现在求得是
100 个时刻的指数加权平均，那么</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7Bv%7D_%7B100%7D%3D%5Cboldsymbol%7B%5Cbeta%7D+%2A+%5Cboldsymbol%7Bv%7D_%7B99%7D%2B%28%5Cmathbf%7B1%7D-%5Cboldsymbol%7B%5Cbeta%7D%29+%2A+%5Cboldsymbol%7B%5Ctheta%7D_%7B100%7D" alt="[公式]"> <img src="https://www.zhihu.com/equation?tex=%3D%28%5Cmathbf%7B1%7D-%5Cboldsymbol%7B%5Cbeta%7D%29+%2A+%5Cboldsymbol%7B%5Ctheta%7D_%7B100%7D%2B%5Cboldsymbol%7B%5Cbeta%7D+%2A%5Cleft%28%5Cboldsymbol%7B%5Cbeta%7D+%2A+%5Cboldsymbol%7Bv%7D_%7B98%7D%2B%28%5Cmathbf%7B1%7D-%5Cboldsymbol%7B%5Cbeta%7D%29+%2A+%5Cboldsymbol%7B%5Ctheta%7D_%7B99%7D%5Cright%29" alt="[公式]"> <img src="https://www.zhihu.com/equation?tex=%3D%28%5Cmathbf%7B1%7D-%5Cboldsymbol%7B%5Cbeta%7D%29+%2A+%5Cboldsymbol%7B%5Ctheta%7D_%7B100%7D%2B%28%5Cmathbf%7B1%7D-%5Cboldsymbol%7B%5Cbeta%7D%29+%2A+%5Cboldsymbol%7B%5Cbeta%7D+%2A+%5Cboldsymbol%7B%5Ctheta%7D_%7B99%7D%2B%5Cleft%28%5Cboldsymbol%7B%5Cbeta%7D%5E%7B2%7D+%2A+%5Cboldsymbol%7Bv%7D_%7B98%7D+%5Cright%29" alt="[公式]"></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%3D%5Csum_%7Bi%7D%5E%7BN%7D%28%5Cmathbf%7B1%7D-%5Cboldsymbol%7B%5Cbeta%7D%29+%2A+%5Cboldsymbol%7B%5Cbeta%7D%5E%7Bi%7D+%2A+%5Cboldsymbol%7B%5Ctheta%7D_%7BN-i%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>从上式可以看到，由于 <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]"> 小于
1，越前面时刻的 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]"> 的次方就越大，系数就越小。</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]">
<strong>==可以理解为记忆周期，<img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]">
越小，记忆周期越短，<img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]">
越大，记忆周期越长==</strong>。通常 <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]"> 设置为
0.9，那么 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7B1-%5Cbeta%7D%3D%5Cfrac%7B1%7D%7B1-0.9%7D%3D10" alt="[公式]">，表示更关注最近 10 天的数据。</p>
<p>下面代码展示了 <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3D0.9" alt="[公式]">
的情况</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">weights = exp_w_func(beta, time_list)</span><br><span class="line"></span><br><span class="line">    plt.plot(time_list, weights, <span class="string">&#x27;-ro&#x27;</span>, label=<span class="string">&quot;Beta: &#123;&#125;\ny = B^t * (1-B)&quot;</span>.<span class="built_in">format</span>(beta))</span><br><span class="line">    plt.xlabel(<span class="string">&quot;time&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;weight&quot;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.title(<span class="string">&quot;exponentially weighted average&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(np.<span class="built_in">sum</span>(weights))</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="https://pic1.zhimg.com/80/v2-50afec65f47b962e5ad3982e5665e484_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>下面代码展示了不同的 <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]">
取值情况</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">beta_list = [<span class="number">0.98</span>, <span class="number">0.95</span>, <span class="number">0.9</span>, <span class="number">0.8</span>]</span><br><span class="line">w_list = [exp_w_func(beta, time_list) <span class="keyword">for</span> beta <span class="keyword">in</span> beta_list]</span><br><span class="line"><span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(w_list):</span><br><span class="line">    plt.plot(time_list, w, label=<span class="string">&quot;Beta: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(beta_list[i]))</span><br><span class="line">    plt.xlabel(<span class="string">&quot;time&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;weight&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<p><img src="https://pic3.zhimg.com/80/v2-6359f031b0b42379be3575e4554e56e2_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]">
==的值越大，记忆周期越长，就会更多考虑前面时刻的数值，因此越平缓。==</p>
<h3><span id="二-常用优化器">二、常用优化器</span></h3>
<h4><span id="21optimsgd随机梯度下降法">2.1
<strong>==optim.SGD==</strong>：随机梯度下降法</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optim.SGD(params, lr=&lt;required parameter&gt;, momentum=<span class="number">0</span>, dampening=<span class="number">0</span>, weight_decay=<span class="number">0</span>, nesterov=<span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>主要参数：</p>
<ul>
<li>params：管理的参数组</li>
<li>lr：初始学习率</li>
<li>momentum：动量系数 <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]"></li>
<li>weight_decay：L2 正则化系数</li>
<li>nesterov：是否采用 NAG</li>
</ul>
<h4><span id="22optimadagrad自适应学习率梯度下降法">2.2
==<strong>optim.Adagrad</strong>==：自适应学习率梯度下降法</span></h4>
<h4><span id="23-optimrmspropadagrad-的改进">2.3 <strong>optim.RMSprop</strong>
：Adagrad 的改进</span></h4>
<h4><span id="24-optimadadelta">2.4 <strong>optim.Adadelta</strong></span></h4>
<h4><span id="25optimadamrmsprop-集合momentum这个是目前最常用的优化器因为它可以使用较大的初始学习率">2.5
<strong>==optim.Adam==</strong>：RMSProp 集合
Momentum，这个是目前最常用的优化器，因为它可以使用较大的初始学习率。</span></h4>
<h4><span id="26optimadamaxadam-增加学习率上限">2.6
<strong>optim.Adamax</strong>：Adam 增加学习率上限</span></h4>
<blockquote>
<p>#### <strong>optim.SparseAdam</strong>：稀疏版的 Adam</p>
<p>#### <strong>optim.ASGD</strong>：随机平均梯度下降</p>
<p>####
<strong>optim.Rprop</strong>：弹性反向传播，这种优化器通常是在所有样本都一起训练，也就是
batchsize 为全部样本时使用。</p>
<p>#### <strong>optim.LBFGS</strong>：BFGS 在内存上的改进</p>
</blockquote>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（12）可视化</title>
    <url>/posts/3W41PJ7/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记-可视化">[PyTorch 学习笔记] 可视化</span></h2>
<blockquote>
<p>在 PyTorch 中也可以使用 <strong>TensorBoard</strong>，具体是使用
TensorboardX 来调用 TensorBoard。除了安装 TensorboardX，还要安装
TensorFlow 和 TensorBoard，其中 TensorFlow 和 TensorBoard 需要一致。</p>
<ul>
<li><strong>Captum</strong> 【可解释性】:
https://captum.ai/docs/introduction</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（13）正则化</title>
    <url>/posts/2BXVQ4T/</url>
    <content><![CDATA[<h2><span id="pytorch学习笔记-weight-decay-dropout和normalization">[PyTorch
学习笔记] weight decay、 dropout和Normalization</span></h2>
<p>这篇文章主要介绍了正则化与偏差-方差分解，以及 PyTorch 中的 L2
正则项--weight decay</p>
<h2><span id="一-regularization-weight-decay"><strong>一、Regularization</strong>
-weight decay</span></h2>
<p>Regularization 中文是正则化，可以理解为一种减少方差的策略。</p>
<p><strong>在机器学习中，误差可以分解为：偏差，方差与噪声之和。即误差=偏差+方差+噪声</strong></p>
<ul>
<li><strong>偏差</strong>：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。</li>
<li><strong>方差</strong>：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。</li>
<li><strong>噪声</strong>：表达了在当前任务上学习任何算法所能达到的期望泛化误差的下界。</li>
</ul>
<figure>
<img src="https://pic1.zhimg.com/80/v2-c874ad0d236cbbf304637c612ae722b8_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h5><span id="正则化方式有l1-和-l2-正则项两种-其中-l2-正则项又被称为权值衰减weight-decay">正则化方式有
L1 和 L2 正则项两种。其中 L2 正则项又被称为权值衰减(weight decay)。</span></h5>
<p>当没有正则项时：<img src="https://www.zhihu.com/equation?tex=%5Cboldsymbol%7BO%7D+%5Cboldsymbol%7Bb%7D+%5Cboldsymbol%7Bj%7D%3D%5Cboldsymbol%7BL%7D+%5Cboldsymbol%7Bo%7D+%5Cboldsymbol%7Bs%7D+%5Cboldsymbol%7Bs%7D" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=w_%7Bi%2B1%7D%3Dw_%7Bi%7D-%5Cfrac%7B%5Cpartial+o+b+j%7D%7B%5Cpartial+w_%7Bi%7D%7D%3Dw_%7Bi%7D-%5Cfrac%7B%5Cpartial+L+o+s+s%7D%7B%5Cpartial+w_%7Bi%7D%7D" alt="[公式]"></p>
<p>当使用 L2 正则项时，<img src="https://www.zhihu.com/equation?tex=%5Cboldsymbol%7BO%7D+%5Cboldsymbol%7Bb%7D+%5Cboldsymbol%7Bj%7D%3D%5Cboldsymbol%7BL%7D+%5Cboldsymbol%7Bo%7D+%5Cboldsymbol%7Bs%7D+%5Cboldsymbol%7Bs%7D%2B%5Cfrac%7B%5Clambda%7D%7B2%7D+%2A+%5Csum_%7Bi%7D%5E%7BN%7D+%5Cboldsymbol%7Bw%7D_%7Bi%7D%5E%7B2%7D" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+w_%7Bi%2B1%7D%3Dw_%7Bi%7D-%5Cfrac%7B%5Cpartial+o+b+j%7D%7B%5Cpartial+w_%7Bi%7D%7D+%26%3Dw_%7Bi%7D-%5Cleft%28%5Cfrac%7B%5Cpartial+L+o+s+s%7D%7B%5Cpartial+w_%7Bi%7D%7D%2B%5Clambda+%2A+w_%7Bi%7D%5Cright%29+%3Dw_%7Bi%7D%281-%5Clambda%29-%5Cfrac%7B%5Cpartial+L+o+s+s%7D%7B%5Cpartial+w_%7Bi%7D%7D+%5Cend%7Baligned%7D" alt="[公式]">，其中 <img src="https://www.zhihu.com/equation?tex=0+%3C+%5Clambda+%3C+1" alt="[公式]">，所以具<strong>有权值衰减的作用</strong>。</p>
<h2><span id="二-dropout"><strong>二、Dropout</strong></span></h2>
<blockquote>
<p>深度学习中Dropout原理解析 - Microstrong的文章 - 知乎
https://zhuanlan.zhihu.com/p/38200980</p>
</blockquote>
<p><strong>Dropout 是另一种抑制过拟合的方法</strong>。在使用 dropout
时，数据尺度会发生变化，如果设置 dropout_prob
=0.3，那么在训练时，数据尺度会变为原来的
70%；<strong>==而在测试时，执行了 model.eval() 后，dropout
是关闭的，因此所有权重需要乘以 (1-dropout_prob)，把数据尺度也缩放到
70%==</strong>。<strong>加了 dropout 之后，权值更加集中在 0
附近，使得神经元之间的依赖性不至于过大。</strong></p>
<p>PyTorch 中 Dropout 层如下，通常放在每个网路层的最前面：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.Dropout(p=0.5, inplace=False)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>p：主力需要注意的是，p
是被舍弃的概率，也叫失活概率；<strong>代码层面实现让某个神经元以概率p停止工作，其实就是让它的激活函数值以概率p变为0</strong></li>
</ul>
<h4><span id="21dropout具体工作流程"><strong>2.1
Dropout具体工作流程</strong></span></h4>
<ul>
<li>首先随机（临时）删掉网络中一部分的隐藏神经元，输入输出神经元保持不变（图3中虚线为部分临时被删除的神经元）</li>
<li>然后把输入x通过修改后的网络前向传播，然后把得到的损失结果通过修改的网络反向传播。一小批训练样本执行完这个过程后，<strong>在没有被删除的神经元上按照随机梯度下降法更新对应的参数</strong>（w，b）。</li>
<li>恢复被删掉的神经元（此时被删除的神经元保持原样，而没有被删除的神经元已经有所更新）</li>
<li>重复上述过程</li>
</ul>
<h4><span id="22为什么dropout-可以解决过拟合共享隐藏单元的bagging集成模型">2.2
==为什么dropout 可以解决过拟合？==
【共享隐藏单元的bagging集成模型】</span></h4>
<ul>
<li><strong>取平均的作用：</strong>
整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</li>
<li><strong>减少神经元之间复杂的共适应关系：</strong>
因为dropout程序导致两个神经元不一定每次都在一个dropout网络中出现。这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况
。<strong>从这个角度看dropout就有点像L1，L2正则，减少权重使得网络对丢失特定神经元连接的鲁棒性提高。</strong></li>
<li><strong>Dropout纯粹作为一种高效近似Bagging的方法。</strong>然而,有
比这更进一步的Dropout观点。<strong>==Dropout不仅仅是训练一个Bagging的集成模型,并且是共享隐藏单元的集成模型==</strong>。这意味着无论其他隐藏单元是否在模型中,每个隐藏单元必须都能够表现良好。</li>
</ul>
<h4><span id="modeleval-和modeltrian"><strong>model.eval() 和
model.trian()</strong></span></h4>
<p>有些网络层在训练状态和测试状态是不一样的，如 dropout 层，在训练时
dropout
层是有效的，但是数据尺度会缩放，为了保持数据尺度不变，所有的权重需要除以
1-p。而在测试时 dropout
层是关闭的。因此在测试时需要先调用<code>model.eval()</code>设置各个网络层的的<code>training</code>属性为
False，在训练时需要先调用<code>model.train()</code>设置各个网络层的的<code>training</code>属性为
True。</p>
<h2><span id="三-normalization">三、Normalization</span></h2>
<blockquote>
<p>深度学习基础 之 ---- BN、LN、IN、GN、SN - 琪小钧的文章 - 知乎
https://zhuanlan.zhihu.com/p/524829507</p>
</blockquote>
<p>这篇文章主要介绍了 Batch Normalization 的概念，以及 PyTorch 中的
1d/2d/3d Batch Normalization 实现。</p>
<h4><span id="31-batchnormalization"><strong>3.1 Batch
Normalization</strong></span></h4>
<blockquote>
<p>BN层的作用是把一个batch内的所有数据，从不规范的分布拉到正态分布。<strong>这样做的好处是使得数据能够分布在激活函数的敏感区域，敏感区域即为梯度较大的区域，因此在反向传播的时候能够较快反馈误差传播</strong>。</p>
</blockquote>
<p>称为批标准化。批是指一批数据，通常为
mini-batch；经过处理后的数据符合均值为0，标准差为1的分布，<strong>如果原始的分布是<a href="https://www.zhihu.com/search?q=正态分布&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A607815171%7D">正态分布</a>，那么z-score标准化就将原始的正态分布转换为标准正态分布</strong>，机器学习中的很多问题都是基于正态分布的假设，这是更加常用的归一化方法。<strong>Batch
Normalization 层一般在激活函数前一层。</strong></p>
<h4><span id="批标准化的优点有如下"><strong>批标准化的优点有如下：</strong></span></h4>
<ul>
<li><strong>可以使用更大的学习率，==加速模型收敛==</strong></li>
<li><strong>可以不用精心设计权值初始化</strong></li>
<li><strong>可以不用 dropout 或者较小的 dropout</strong></li>
<li><strong>可以不用 L2 或者较小的 weight decay</strong></li>
<li>可以不用 LRN (local response normalization)</li>
</ul>
<blockquote>
<p>假设输入的 mini-batch 数据是 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BB%7D%3D%5Cleft%5C%7Bx_%7B1+%5Cdots+m%7D%5Cright%5C%7D" alt="[公式]">，Batch Normalization 的可学习参数是 <img src="https://www.zhihu.com/equation?tex=%5Cgamma%2C+%5Cbeta" alt="[公式]">，步骤如下：</p>
<ul>
<li>求 mini-batch 的均值：<img src="https://www.zhihu.com/equation?tex=%5Cmu_%7B%5Cmathcal%7BB%7D%7D+%5Cleftarrow+%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi%3D1%7D%5E%7Bm%7D+x_%7Bi%7D" alt="[公式]"></li>
<li>求 mini-batch 的方差：<img src="https://www.zhihu.com/equation?tex=%5Csigma_%7B%5Cmathcal%7BB%7D%7D%5E%7B2%7D+%5Cleftarrow+%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi%3D1%7D%5Cleft%28x_%7Bi%7D-%5Cmu_%7B%5Cmathcal%7BB%7D%7D%5Cright%29%5E%7B2%7D" alt="[公式]"></li>
<li>标准化：<img src="https://www.zhihu.com/equation?tex=%5Cwidehat%7Bx%7D_%7Bi%7D+%5Cleftarrow+%5Cfrac%7Bx_%7Bi%7D-%5Cmu_%7B%5Cmathcal%7BB%7D%7D%7D%7B%5Csqrt%7B%5Csigma_%7BB%7D%5E%7B2%7D%2B%5Cepsilon%7D%7D" alt="[公式]">，其中 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="[公式]">
是放置分母为 0 的一个数</li>
<li><strong>affine transform(缩放和平移)</strong>：<img src="https://www.zhihu.com/equation?tex=y_%7Bi%7D+%5Cleftarrow+%5Cgamma+%5Cwidehat%7Bx%7D_%7Bi%7D%2B%5Cbeta+%5Cequiv+%5Cmathrm%7BB%7D+%5Cmathrm%7BN%7D_%7B%5Cgamma%2C+%5Cbeta%7D%5Cleft%28x_%7Bi%7D%5Cright%29" alt="[公式]">，这个操作可以增强模型的
capacity，也就是让模型自己判断是否要对数据进行标准化，进行多大程度的标准化。如果
<img src="https://www.zhihu.com/equation?tex=%5Cgamma%3D+%5Csqrt%7B%5Csigma_%7BB%7D%5E%7B2%7D%7D" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=%5Cbeta%3D%5Cmu_%7B%5Cmathcal%7BB%7D%7D" alt="[公式]">，那么就实现了恒等映射。</li>
</ul>
</blockquote>
<p><strong>Batch Normalization</strong> 的提出主要是为了<strong>解决
Internal Covariate Shift
(ICS)</strong>。在训练过程中，数据需要经过多层的网络，如果数据在前向传播的过程中，尺度发生了变化，可能会导致梯度爆炸或者梯度消失，从而导致模型难以收敛。</p>
<p><strong>带有 bn 层的 LeNet 定义如下：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet_bn</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet_bn, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(num_features=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(num_features=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm1d(num_features=<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = F.relu(out)</span><br><span class="line"></span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = F.relu(out)</span><br><span class="line"></span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        out = self.fc1(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line">        out = F.relu(out)</span><br><span class="line"></span><br><span class="line">        out = F.relu(self.fc2(out))</span><br><span class="line">        out = self.fc3(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>带 bn 层的网络，并且不使用 kaiming 初始化权值，训练过程如下：</p>
<p><img src="https://pic4.zhimg.com/80/v2-2f7ed3c6b9158750a643d99e42ec07bf_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>虽然训练过程中，训练集的 loss 也有激增，但只是增加到
0.4，非常稳定。</p>
<h4><span id="32-batch-normalizationin-pytorch">3.2 <strong>Batch Normalization
in PyTorch</strong></span></h4>
<p>在 PyTorch 中，有 3 个 Batch Normalization 类</p>
<ul>
<li>nn.BatchNorm1d()，输入数据的形状是 <img src="https://www.zhihu.com/equation?tex=B+%5Ctimes+C+%5Ctimes+1D%5C_feature" alt="[公式]"></li>
<li>nn.BatchNorm2d()，输入数据的形状是 <img src="https://www.zhihu.com/equation?tex=B+%5Ctimes+C+%5Ctimes+2D%5C_feature" alt="[公式]"></li>
<li>nn.BatchNorm3d()，输入数据的形状是 <img src="https://www.zhihu.com/equation?tex=B+%5Ctimes+C+%5Ctimes+3D%5C_feature" alt="[公式]"></li>
</ul>
<h4><span id="以nnbatchnorm1d为例如下"><strong>以nn.BatchNorm1d()为例，如下：</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.nn.BatchNorm1d(num_features, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li><strong>num_features：一个样本的特征数量</strong>，这个参数最重要</li>
<li>eps：在进行标准化操作时的分布修正项</li>
<li><strong>momentum</strong>：<strong>指数加权平均估计当前的均值和方差</strong>,在训练时，均值和方差采用指数加权平均计算，也就是不仅考虑当前
mini-batch 的值均值和方差还考虑前面的 mini-batch 的均值和方差。</li>
<li>affine：是否需要 affine transform，默认为 True</li>
<li>track_running_stats：True 为训练状态，此时均值和方差会根据每个
mini-batch 改变。False 为测试状态，此时均值和方差会固定</li>
</ul>
<p><strong>主要属性</strong>：</p>
<ul>
<li><strong>runninng_mean：均值</strong></li>
<li><strong>running_var：方差</strong></li>
<li>weight：affine transform 中的 <img src="https://www.zhihu.com/equation?tex=%5Cgamma" alt="[公式]"></li>
<li>bias：affine transform 中的 <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]"></li>
</ul>
<h4><span id="33-layernormalization">3.3 <strong>Layer
Normalization</strong></span></h4>
<blockquote>
<p>batch是“竖”着来的，各个维度做归一化，所以与batch size有关系。
layer是“横”着来的，对一个样本，不同的神经元neuron间做归一化。</p>
</blockquote>
<p><font color="red"> <strong>提出的原因</strong>：<strong>Batch
Normalization 不适用于变长的网络，如
RNN</strong></font>。如下显示了同一层的神经元的情况。假设这个mini-batch一共有N个样本，则Batch
Normalization是对每一个维度进行归一。而Layer
Normalization对于单个的样本就可以处理。<strong>bn和ln都可以比较好的抑制梯度消失和梯度爆炸的情况</strong>。<strong>思路</strong>：每个网络层计算均值和方差。</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-2d3f611065de9070fced5b5abd4d032d_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>注意事项</strong>：</p>
<ul>
<li>不再有 running_mean 和 running_var</li>
<li><img src="https://www.zhihu.com/equation?tex=%5Cgamma" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]"> 为逐样本的</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.nn.LayerNorm(normalized_shape, eps=<span class="number">1e-05</span>, elementwise_affine=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="34-instancenormalization"><strong>3.4 Instance
Normalization</strong></span></h4>
<p><strong>提出的原因：Batch Normalization 不适用于图像生成。因为在一个
mini-batch 中的图像有不同的风格，不能把这个 batch
里的数据都看作是同一类取标准化</strong>。</p>
<p>思路：逐个 instance 的 channel 计算均值和方差。也就是<strong>每个
feature map 计算一个均值和方差</strong>。</p>
<p>包括 InstanceNorm1d、InstanceNorm2d、InstanceNorm3d。</p>
<p>以<code>InstanceNorm1d</code>为例，定义如下：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.nn.InstanceNorm1d(num_features, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>num_features：一个样本的特征数，这个参数最重要</li>
<li>eps：分母修正项</li>
<li>momentum：指数加权平均估计当前的的均值和方差</li>
<li>affine：是否需要 affine transform</li>
<li>track_running_stats：True 为训练状态，此时均值和方差会根据每个
mini-batch 改变。False 为测试状态，此时均值和方差会固定</li>
</ul>
<h4><span id="35-groupnormalization"><strong>3.5 Group
Normalization</strong></span></h4>
<p><strong>提出的原因：在小 batch 的样本中，Batch Normalization
估计的值不准。一般用在很大的模型中，这时 batch size
就很小。</strong></p>
<p><strong>思路：数据不够，通道来凑。
每个样本的特征分为几组，每组特征分别计算均值和方差。可以看作是 Layer
Normalization 的基础上添加了特征分组。</strong></p>
<h3><span id="4-相关问题">4、相关问题</span></h3>
<h4><span id="为啥用ln而不用bn在transformer里">为啥用LN而不用BN在Transformer里？</span></h4>
<p>BN是对一批数据进行归一化，一批里有不同的样本，bn对不同样本的同一个通道的特征（channel）进行均值方差操作；而LN对同一个样本内部的不同特征进行均值方差操作。</p>
<p>BN在batch
size（N)和WH上进行缩放,保留C,而LN是在C和HW上进行缩放，保留bitch
size,在NLP中就对应句子长度，通常来说文本词句的长度是不一样的，如果使用BN则会导致靠前的bitch
size里的数据可以做相同的均值方差操作，而靠后的多余的数据的方差和均值难以估计，如下图</p>
<p><img src="https://pic3.zhimg.com/v2-b54729909bce975857608382ef4cac2a_b.jpg" alt="img" style="zoom:50%;"></p>
<p>第一个样本里有5个数据通道（可看作特征），第二个样本空间里有3个数据通道（特征），则在提取特征时前三个的均值方差满足同一个norm操作公式，而后面两个由于第二个样本没有数据，所以均值方差不满足其公式，导致误差产生。</p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（14）模型保存与加载</title>
    <url>/posts/2DF1D1/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记模型保存与加载">[PyTorch 学习笔记]
模型保存与加载</span></h2>
<p>这篇文章主要介绍了序列化与反序列化，以及 PyTorch
中的模型保存于加载的两种方式，模型的断点续训练。</p>
<h3><span id="一-序列化与反序列化">一、<strong>序列化与反序列化</strong></span></h3>
<p>模型在内存中是以对象的逻辑结构保存的，但是在硬盘中是以二进制流的方式保存的。</p>
<ul>
<li>序列化是指将内存中的数据以二进制序列的方式保存到硬盘中。PyTorch
的模型保存就是序列化。</li>
<li>反序列化是指将硬盘中的二进制序列加载到内存中，得到模型的对象。PyTorch
的模型加载就是反序列化。</li>
</ul>
<h3><span id="二-pytorch中的模型保存与加载"><strong>二、PyTorch
中的模型保存与加载</strong></span></h3>
<h4><span id="21-torchsave"><strong>2.1 torch.save</strong></span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.save(obj, f, pickle_module, pickle_protocol=2, _use_new_zipfile_serialization=False)</span><br></pre></td></tr></table></figure>
<p>主要参数：</p>
<ul>
<li>obj：保存的对象，可以是模型。也可以是
dict。因为一般在保存模型时，不仅要保存模型，还需要保存优化器、此时对应的
epoch 等参数。这时就可以用 dict 包装起来。</li>
<li>f：输出路径</li>
</ul>
<h4><span id="22-torchsave">2.2 torch.save</span></h4>
<p>其中模型保存还有两种方式：</p>
<h5><span id="221-保存整个-module"><strong>2.2.1 保存整个 Module</strong></span></h5>
<p>这种方法比较耗时，保存的文件大</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.savev(net, path)</span><br></pre></td></tr></table></figure>
<h5><span id="222-只保存模型的参数"><strong>2.2.2 只保存模型的参数</strong></span></h5>
<p>推荐这种方法，运行比较快，保存的文件比较小</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">state_sict = net.state_dict()</span><br><span class="line">torch.savev(state_sict, path)</span><br></pre></td></tr></table></figure>
<p>下面是保存 LeNet 的例子。在网络初始化中，把权值都设置为
2020，然后保存模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net = LeNet2(classes=<span class="number">2019</span>)</span><br><span class="line"><span class="comment"># &quot;训练&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练前: &quot;</span>, net.features[<span class="number">0</span>].weight[<span class="number">0</span>, ...])</span><br><span class="line">net.initialize()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练后: &quot;</span>, net.features[<span class="number">0</span>].weight[<span class="number">0</span>, ...])</span><br><span class="line"></span><br><span class="line">path_model = <span class="string">&quot;./model.pkl&quot;</span></span><br><span class="line">path_state_dict = <span class="string">&quot;./model_state_dict.pkl&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存整个模型</span></span><br><span class="line">torch.save(net, path_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型参数</span></span><br><span class="line">net_state_dict = net.state_dict()</span><br><span class="line">torch.save(net_state_dict, path_state_dict)</span><br></pre></td></tr></table></figure>
<p>运行完之后，文件夹中生成了<code>model.pkl</code>和<code>model_state_dict.pkl</code>，分别保存了整个网络和网络的参数</p>
<h4><span id="23-torchload"><strong>2.3 torch.load</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.load(f, map_location=<span class="literal">None</span>, pickle_module, **pickle_load_args)</span><br></pre></td></tr></table></figure>
<p>主要参数：</p>
<ul>
<li>f：文件路径</li>
<li><strong>map_location：指定存在 CPU 或者 GPU。</strong></li>
</ul>
<h3><span id="三-模型的断点续训练">三、<strong>模型的断点续训练</strong></span></h3>
<p>在训练过程中，可能由于某种意外原因如断点等导致训练终止，这时需要重新开始训练。断点续练是在训练过程中每隔一定次数的
epoch
就保存<strong>模型的参数和优化器的参数</strong>，这样如果意外终止训练了，下次就可以重新加载最新的<strong>模型参数和优化器的参数</strong>，在这个基础上继续训练。</p>
<p>下面的代码中，每隔 5 个 epoch 就保存一次，保存的是一个
<strong>dict，包括模型参数、优化器的参数、epoch</strong>。然后在 epoch
大于 5 时，就<code>break</code>模拟训练意外终止。关键代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (epoch+<span class="number">1</span>) % checkpoint_interval == <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">    checkpoint = &#123;<span class="string">&quot;model_state_dict&quot;</span>: net.state_dict(),</span><br><span class="line">                  <span class="string">&quot;optimizer_state_dict&quot;</span>: optimizer.state_dict(),</span><br><span class="line">                  <span class="string">&quot;epoch&quot;</span>: epoch&#125;</span><br><span class="line">    path_checkpoint = <span class="string">&quot;./checkpoint_&#123;&#125;_epoch.pkl&quot;</span>.<span class="built_in">format</span>(epoch)</span><br><span class="line">    torch.save(checkpoint, path_checkpoint)</span><br></pre></td></tr></table></figure>
<p>在 epoch 大于 5 时，就<code>break</code>模拟训练意外终止</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> epoch &gt; <span class="number">5</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;训练意外中断...&quot;</span>)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>断点续训练的恢复代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">path_checkpoint = <span class="string">&quot;./checkpoint_4_epoch.pkl&quot;</span></span><br><span class="line">checkpoint = torch.load(path_checkpoint)</span><br><span class="line"></span><br><span class="line">net.load_state_dict(checkpoint[<span class="string">&#x27;model_state_dict&#x27;</span>])</span><br><span class="line"></span><br><span class="line">optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optimizer_state_dict&#x27;</span>])</span><br><span class="line"></span><br><span class="line">start_epoch = checkpoint[<span class="string">&#x27;epoch&#x27;</span>]</span><br><span class="line"></span><br><span class="line">scheduler.last_epoch = start_epoch</span><br></pre></td></tr></table></figure>
<p><strong>需要注意的是，还要设置<code>scheduler.last_epoch</code>参数为保存的
epoch。模型训练的起始 epoch 也要修改为保存的 epoch。</strong></p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（15）模型Finetune</title>
    <url>/posts/1R22EKT/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记-模型finetune微调">[PyTorch 学习笔记] 模型
Finetune【微调】</span></h2>
<p><strong>迁移学习</strong>：把在 source domain
任务上的学习到的模型应用到 target domain 的任务。</p>
<p><strong>Finetune
就是一种迁移学习的方法</strong>。比如做人脸识别，可以把 ImageNet 看作
source domain，人脸数据集看作 target domain。通常来说 source domain 要比
target domain 大得多。可以利用 ImageNet
训练好的网络应用到人脸识别中。</p>
<p>对于一个模型，通常可以分为前面的 feature extractor (卷积层)和后面的
classifier，在 Finetune 时，通常不改变 feature extractor
的权值，也就是冻结卷积层；并且改变最后一个全连接层的输出来适应目标任务，训练后面
classifier 的权值，这就是 Finetune。<strong>通常 target domain
的数据比较小，不足以训练全部参数，容易导致过拟合，因此不改变 feature
extractor 的权值</strong>。</p>
<h4><span id="finetune-步骤如下">Finetune 步骤如下：</span></h4>
<ol type="1">
<li><p><strong>获取预训练模型的参数</strong></p></li>
<li><p><strong>使用<code>load_state_dict()</code>把参数加载到模型中</strong></p></li>
<li><p><strong>修改输出层</strong></p></li>
<li><p><strong>固定 feature extractor 的参数</strong>。这部分通常有 2
种做法：</p></li>
<li><ul>
<li>==<strong>固定卷积层的预训练参数。可以设置<code>requires_grad=False</code>或者<code>lr=0</code></strong>==</li>
</ul></li>
<li><ul>
<li><strong>可以通过<code>params_group</code>给 feature extractor
==设置一个较小的学习率==</strong></li>
</ul></li>
</ol>
<h4><span id="不使用-finetune"><strong>不使用 Finetune</strong></span></h4>
<p>第一次我们首先不使用
Finetune，而是从零开始训练模型，这时只需要修改全连接层即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先拿到 fc 层的输入个数</span></span><br><span class="line">num_ftrs = resnet18_ft.fc.in_features</span><br><span class="line"><span class="comment"># 然后构造新的 fc 层替换原来的 fc 层</span></span><br><span class="line">resnet18_ft.fc = nn.Linear(num_ftrs, classes)</span><br></pre></td></tr></table></figure>
<p>训练了 25 个 epoch 后的准确率为：70.59%。<strong>训练的 loss
曲线如下：</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-5ee8d34af79f9efccef5131c24dcaee2_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<h4><span id="使用-finetune不冻结卷积层">使用 Finetune，
<strong>不冻结卷积层</strong></span></h4>
<p>然后我们把下载的模型参数加载到模型中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">path_pretrained_model = enviroments.resnet18_path</span><br><span class="line">state_dict_load = torch.load(path_pretrained_model)</span><br><span class="line">resnet18_ft.load_state_dict(state_dict_load)</span><br></pre></td></tr></table></figure>
<p>训练了 25 个 epoch 后的准确率为：96.08%。训练的 loss 曲线如下：</p>
<p><img src="https://pic2.zhimg.com/80/v2-f12709c02275380983b1518935b56d21_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<h4><span id="使用-finetune-冻结卷积层">使用 Finetune、
<strong>冻结卷积层</strong></span></h4>
<h5><span id="设置requires_gradfalse这里先冻结所有参数然后再替换全连接层相当于冻结了卷积层的参数"><strong>设置<code>requires_grad=False</code></strong>这里先冻结所有参数，然后再替换全连接层，相当于冻结了卷积层的参数：</span></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> resnet18_ft.parameters():</span><br><span class="line">		param.requires_grad = <span class="literal">False</span></span><br><span class="line"> 		<span class="comment"># 首先拿到 fc 层的输入个数</span></span><br><span class="line">		num_ftrs = resnet18_ft.fc.in_features</span><br><span class="line">		<span class="comment"># 然后构造新的 fc 层替换原来的 fc 层</span></span><br><span class="line">		resnet18_ft.fc = nn.Linear(num_ftrs, classes)</span><br></pre></td></tr></table></figure>
<h4><span id="使用-finetune-设置学习率为0">使用 Finetune、<strong>设置学习率为
0</strong></span></h4>
<p><strong>这里把卷积层的学习率设置为
0，需要在优化器里设置不同的学习率</strong>。首先获取全连接层参数的地址，然后使用
filter
过滤不属于全连接层的参数，也就是保留卷积层的参数；接着设置优化器的分组学习率，传入一个
list，包含 2 个元素，每个元素是字典，对应 2
个参数组。其中卷积层的学习率设置为 全连接层的 0.1 倍。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先获取全连接层参数的地址</span></span><br><span class="line">fc_params_id = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">id</span>, resnet18_ft.fc.parameters()))   </span><br><span class="line"><span class="comment"># 返回的是parameters的 内存地址</span></span><br><span class="line"><span class="comment"># 然后使用 filter 过滤不属于全连接层的参数，也就是保留卷积层的参数</span></span><br><span class="line">base_params = <span class="built_in">filter</span>(<span class="keyword">lambda</span> p: <span class="built_in">id</span>(p) <span class="keyword">not</span> <span class="keyword">in</span> fc_params_id, resnet18_ft.parameters())</span><br><span class="line"><span class="comment"># 设置优化器的分组学习率，传入一个 list，包含 2 个元素，每个元素是字典，对应 2 个参数组</span></span><br><span class="line">optimizer = optim.SGD([&#123;<span class="string">&#x27;params&#x27;</span>: base_params, <span class="string">&#x27;lr&#x27;</span>: <span class="number">0</span>&#125;, &#123;<span class="string">&#x27;params&#x27;</span>: resnet18_ft.fc.parameters(), <span class="string">&#x27;lr&#x27;</span>: LR&#125;], momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="使用分组学习率-对卷积层使用较小的学习率">使用分组学习率、对卷积层使用较小的学习率</span></h4>
<p><strong>这里不冻结卷积层，而是对卷积层使用较小的学习率，对全连接层使用较大的学习率，需要在优化器里设置不同的学习率</strong>。首先获取全连接层参数的地址，然后使用
filter
过滤不属于全连接层的参数，也就是保留卷积层的参数；接着设置优化器的分组学习率，传入一个
list，包含 2 个元素，每个元素是字典，对应 2
个参数组。其中卷积层的学习率设置为 全连接层的 0.1 倍。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 首先获取全连接层参数的地址</span></span><br><span class="line">fc_params_id = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">id</span>, resnet18_ft.fc.parameters()))     </span><br><span class="line"><span class="comment"># 返回的是parameters的 内存地址</span></span><br><span class="line"><span class="comment"># 然后使用 filter 过滤不属于全连接层的参数，也就是保留卷积层的参数</span></span><br><span class="line">base_params = <span class="built_in">filter</span>(<span class="keyword">lambda</span> p: <span class="built_in">id</span>(p) <span class="keyword">not</span> <span class="keyword">in</span> fc_params_id, resnet18_ft.parameters())</span><br><span class="line"><span class="comment"># 设置优化器的分组学习率，传入一个 list，包含 2 个元素，每个元素是字典，对应 2 个参数组</span></span><br><span class="line">optimizer = optim.SGD([&#123;<span class="string">&#x27;params&#x27;</span>: base_params, <span class="string">&#x27;lr&#x27;</span>: LR*<span class="number">0</span>&#125;, &#123;<span class="string">&#x27;params&#x27;</span>: resnet18_ft.fc.parameters(), <span class="string">&#x27;lr&#x27;</span>: LR&#125;], momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（16）模型GPU训练</title>
    <url>/posts/3GGS5GD/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记-模型应用">[PyTorch 学习笔记] 模型应用</span></h2>
<ul>
<li>Neural Network Malware Binary
Classification：https://github.com/jaketae/deep-malware-detection</li>
</ul>
<p>下面的代码是使用 Generator 来生成人脸图像，Generator 已经训练好保存在
pkl 文件中，只需要加载参数即可。<strong>由于模型是在多 GPU
的机器上训练的，因此加载参数后需要使用<code>remove_module()</code>函数来修改<code>state_dict</code>中的<code>key</code>。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 多 GPU 的机器上训练模型参数修改</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">remove_module</span>(<span class="params">state_dict_g</span>):</span><br><span class="line">    <span class="comment"># remove module.</span></span><br><span class="line">    <span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"></span><br><span class="line">    new_state_dict = OrderedDict()</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> state_dict_g.items():</span><br><span class="line">        namekey = k[<span class="number">7</span>:] <span class="keyword">if</span> k.startswith(<span class="string">&#x27;module.&#x27;</span>) <span class="keyword">else</span> k</span><br><span class="line">        new_state_dict[namekey] = v</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> new_state_dict</span><br></pre></td></tr></table></figure>
<p><strong>在 GAN 的训练模式中</strong>，Generator
接收随机数得到输出值，目标是让输出值的分布与训练数据的分布接近，但是这里<strong>==不是使用人为定义的损失函数来计算输出值与训练数据分布之间的差异，而是使用
Discriminator
来计算这个差异==</strong>。需要注意的是这个差异不是单个数字上的差异，而是分布上的差异。</p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（1）张量操作</title>
    <url>/posts/A5MDD8/</url>
    <content><![CDATA[<h2><span id="pytorch-资料">PyTorch 资料</span></h2>
<ul>
<li><p><a href="https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss">PyTorch
1.7.0 文档</a></p></li>
<li><p>https://www.w3cschool.cn/pytorch/pytorch-mrni3btn.html</p></li>
<li><p>https://handbook.pytorch.wiki/chapter1/1.1-pytorch-introduction.html</p></li>
<li><p>LSTM细节分析理解（pytorch版）：https://zhuanlan.zhihu.com/p/79064602</p></li>
<li><p>OLD：https://www.pytorch123.com/SixthSection/Dcgan/</p></li>
<li><p>PyTorch 学习笔记汇总（完结撒花） - 张贤同学的文章 - 知乎
https://zhuanlan.zhihu.com/p/265394674</p></li>
</ul>
<h1><span id="pytorch-学习笔记"><strong>PyTorch 学习笔记</strong></span></h1>
<p>在线电子书：<a href="https://link.zhihu.com/?target=https%3A//pytorch.zhangxiann.com/">https://pytorch.zhangxiann.com/</a></p>
<p>配套代码：<strong><a href="https://link.zhihu.com/?target=https%3A//github.com/zhangxiann/PyTorch_Practice">https://github.com/zhangxiann/PyTorch_Practice</a></strong></p>
<h2><span id="一-基本概念">一、基本概念</span></h2>
<h3><span id="11-pytorch-简介与安装">1.1 Pytorch 简介与安装</span></h3>
<h3><span id="12-tensor-张量介绍">1.2 Tensor 张量介绍</span></h3>
<p><img src="https://image.zhangxiann.com/20200515145801.png" alt="img" style="zoom:75%;"></p>
<h4><span id="121-直接创建-tensor">1.2.1 直接创建 Tensor</span></h4>
<h4><span id="torchtensor">torch.tensor()</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.tensor(data, dtype=<span class="literal">None</span>, device=<span class="literal">None</span>, requires_grad=<span class="literal">False</span>, pin_memory=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>data: 数据，可以是 list，numpy</li>
<li>dtype: 数据类型，默认与 data 的一致</li>
<li>device: 所在设备，cuda/cpu</li>
<li>requires_grad: 是否需要梯度</li>
<li>pin_memory: 是否存于锁页内存</li>
</ul>
<h4><span id="torchfrom_numpyndarray">torch.from_numpy(ndarray)</span></h4>
<p><strong>从 numpy 创建 tensor。利用这个方法创建的 tensor 和原来的
ndarray 共享内存，当修改其中一个数据，另外一个也会被改动。</strong></p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-3c43ca0bec07c933d07de270730e8ba2_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="122-根据数值创建-tensor">1.2.2 根据数值创建 Tensor</span></h4>
<h4><span id="torchzeros根据-size创建全-0-张量">torch.zeros()：根据 size
创建全 0 张量</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.zeros(*size, out=<span class="literal">None</span>, dtype=<span class="literal">None</span>, layout=torch.strided, device=<span class="literal">None</span>, requires_grad=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>size: 张量的形状</li>
<li>out: 输出的张量，如果指定了
out，那么<code>torch.zeros()</code>返回的张量和 out
指向的是同一个地址</li>
<li>layout: 内存中布局形式，有 strided，sparse_coo
等。当是稀疏矩阵时，设置为 sparse_coo 可以减少内存占用。</li>
<li>device: 所在设备，cuda/cpu</li>
<li>requires_grad: 是否需要梯度</li>
</ul>
<h4><span id="torchfulltorchfull_like创建自定义数值的张量">torch.full()，torch.full_like()：创建自定义数值的张量</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)</span><br></pre></td></tr></table></figure>
<ul>
<li>size: 张量的形状，如 (3,3)</li>
<li>fill_value: 张量中每一个元素的值</li>
</ul>
<h4><span id="torcharange创建等差的1-维张量-注意区间为start-end">torch.arange()：创建等差的
1 维张量。注意区间为[start, end)。</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)</span><br></pre></td></tr></table></figure>
<ul>
<li>start: 数列起始值</li>
<li>end: 数列结束值，开区间，取不到结束值</li>
<li>step: 数列公差，默认为 1</li>
</ul>
<h4><span id="torchlinspace创建均分的1-维张量-数值区间为-start-end">torch.linspace()：创建均分的
1 维张量。数值区间为 [start, end]</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)</span><br></pre></td></tr></table></figure>
<ul>
<li>start: 数列起始值</li>
<li>end: 数列结束值</li>
<li>steps: 数列长度 (元素个数)</li>
</ul>
<h4><span id="123-根据概率创建-tensor">1.2.3 根据概率创建 Tensor</span></h4>
<h4><span id="torchnormal">torch.normal()</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.normal(mean, std, *, generator=None, out=None)</span><br></pre></td></tr></table></figure>
<p><strong>功能：生成正态分布 (高斯分布)</strong></p>
<ul>
<li>mean: 均值</li>
<li>std: 标准差</li>
</ul>
<h3><span id="13-张量操作与线性回归">==1.3 张量操作与线性回归==</span></h3>
<h3><span id="131-拼接cat-stack"><strong>==1.3.1 拼接==</strong>：cat、stack</span></h3>
<h4><span id="torchcat将张量按照dim-维度进行拼接">torch.cat()：将张量按照
dim 维度进行拼接</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.cat(tensors, dim=0, out=None)</span><br></pre></td></tr></table></figure>
<ul>
<li>tensors: 张量序列 <strong>[t, t]</strong></li>
<li>dim: 要拼接的维度</li>
</ul>
<h4><span id="torchstack将张量在新创建的dim-维度上进行拼接已有维度后移">torch.stack()：将张量在==新创建的
dim 维度==上进行拼接，已有维度后移</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.stack(tensors, dim=0, out=None)</span><br></pre></td></tr></table></figure>
<ul>
<li>tensors: 张量序列</li>
<li>dim: 要拼接的维度</li>
</ul>
<h3><span id="132-切分chunk-split">==1.3.2 切分==：chunk、split</span></h3>
<h4><span id="torchchunk将张量按照维度dim-进行平均切分-若不能整除则最后一份张量小于其他张量">torch.chunk()：将张量按照维度
dim 进行平均切分。若不能整除，则最后一份张量小于其他张量。</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.chunk(input, chunks, dim=0)</span><br><span class="line">torch.chunk(a, dim=1, chunks=3)</span><br></pre></td></tr></table></figure>
<ul>
<li>input: 要切分的张量</li>
<li>chunks: 要切分的份数</li>
<li>dim: 要切分的维度</li>
</ul>
<h4><span id="torchsplit将张量按照维度dim-进行平均切分-可以指定每一个分量的切分长度">torch.split()：将张量按照维度
dim 进行平均切分。可以指定每一个==分量的切分长度==。</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.split(tensor, split_size_or_sections, dim=<span class="number">0</span>)</span><br><span class="line">torch.split(t, [<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>], dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>tensor: 要切分的张量</li>
<li>split_size_or_sections: 为 int
时，表示每一份的长度，如果不能被整除，则最后一份张量小于其他张量；为
list 时，按照 list 元素作为每一个分量的长度切分。如果 list
元素之和不等于切分维度 (dim) 的值，就会报错。</li>
<li>dim: 要切分的维度</li>
</ul>
<h3><span id="133-索引">==1.3.3 索引==</span></h3>
<h4><span id="torchindex_select在维度dim-上按照-index-索引取出数据拼接为张量返回">torch.index_select()：在维度
dim 上，按照 index 索引取出数据拼接为张量返回。</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.index_select(input, dim, index, out=None)</span><br></pre></td></tr></table></figure>
<p>功能：在维度 dim 上，按照 index
索引取出数据拼接为张量返回。<code>torch.tensor([0, 2], dtype=torch.long)</code></p>
<ul>
<li>input: 要索引的张量</li>
<li>dim: 要索引的维度</li>
<li>index: 要索引数据的序号</li>
</ul>
<h4><span id="torchmask_select按照mask-中的-true-进行索引拼接得到一维张量返回">torch.mask_select()：按照
mask 中的 True 进行索引拼接得到一维张量返回。</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.masked_select(input, mask, out=None)</span><br></pre></td></tr></table></figure>
<ul>
<li>要索引的张量</li>
<li>mask: 与 input 同形状的布尔类型张量</li>
</ul>
<h3><span id="134-变换">==1.3.4 变换==</span></h3>
<h4><span id="torchreshape变换张量的形状-当张量在内存中是连续时返回的张量和原来的张量共享数据内存改变一个变量时另一个变量也会被改变">torch.reshape()：变换张量的形状。当张量在内存中是连续时，返回的张量和原来的张量共享数据内存，改变一个变量时，另一个变量也会被改变。</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.reshape(input, shape)</span><br><span class="line">torch.reshape(t, (-1, 2, 2))</span><br></pre></td></tr></table></figure>
<ul>
<li>input: 要变换的张量</li>
<li>shape: 新张量的形状</li>
</ul>
<h4><span id="torchtranspose交换张量的两个维度-常用于图像的变换比如把chw变换为hwc">torch.transpose()：交换张量的两个维度。常用于图像的变换，比如把<code>c*h*w</code>变换为<code>h*w*c</code>。</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.transpose(input, dim0, dim1)</span><br></pre></td></tr></table></figure>
<ul>
<li>input: 要交换的变量</li>
<li>dim0: 要交换的第一个维度</li>
<li>dim1: 要交换的第二个维度</li>
</ul>
<h4><span id="torcht2维张量转置对于-2维矩阵而言等价于torchtransposeinput-0-1">torch.t()：2
维张量转置，对于 2
维矩阵而言，等价于<code>torch.transpose(input, 0, 1)</code>。</span></h4>
<h4><span id="torchsqueeze压缩长度为-1的维度">torch.squeeze()：压缩长度为 1
的维度</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.squeeze(input, dim=None, out=None)</span><br></pre></td></tr></table></figure>
<ul>
<li>dim: 若为 None，则移除所有长度为 1
的维度；若指定维度，则当且仅当该维度长度为 1 时可以移除。</li>
</ul>
<h4><span id="torchunsqueeze根据dim-扩展维度长度为-1">torch.unsqueeze()：根据
dim 扩展维度，长度为 1。</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.unsqueeze(input, dim)</span><br></pre></td></tr></table></figure>
<h3><span id="135-张量的数学运算">==1.3.5 张量的数学运算==</span></h3>
<h4><span id="加减乘除对数指数幂函数和三角函数">加减乘除，对数，指数，幂函数
和三角函数。</span></h4>
<h4><span id="torchadd逐元素计算-input-alpha-other-因为在深度学习中经常用到先乘后加的操作">torch.add():
逐元素计算 input + alpha *
other。因为在深度学习中经常用到先乘后加的操作。</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.add(input, other, out=None)</span><br><span class="line">torch.add(input, other, *, alpha=1, out=None)</span><br></pre></td></tr></table></figure>
<ul>
<li>input: 第一个张量</li>
<li>alpha: 乘项因子</li>
<li>other: 第二个张量</li>
</ul>
<h4><span id="torchaddcdiv">torch.addcdiv()</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.addcdiv(input, tensor1, tensor2, *, value=1, out=None)</span><br></pre></td></tr></table></figure>
<p>计算公式为：out <img src="https://www.zhihu.com/equation?tex=_%7Bi%7D%3D%5Coperatorname%7Binput%7D_%7Bi%7D%2B" alt="[公式]"> value <img src="https://www.zhihu.com/equation?tex=%5Ctimes+%5Cfrac%7B%5Ctext+%7B+tensor+%7D+1_%7Bi%7D%7D%7B%5Ctext+%7B+tensor+%7D+2_%7Bi%7D%7D" alt="[公式]"></p>
<h4><span id="torchaddcmul">torch.addcmul()</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">torch.addcmul(input, tensor1, tensor2, *, value=1, out=None)</span><br></pre></td></tr></table></figure>
<p>计算公式为：out <img src="https://www.zhihu.com/equation?tex=_%7Bi%7D%3D" alt="[公式]">
input <img src="https://www.zhihu.com/equation?tex=_%7Bi%7D%2B" alt="[公式]"> value <img src="https://www.zhihu.com/equation?tex=%5Ctimes" alt="[公式]"> tensor
<img src="https://www.zhihu.com/equation?tex=1_%7Bi%7D+%5Ctimes" alt="[公式]"> tensor <img src="https://www.zhihu.com/equation?tex=2_%7Bi%7D" alt="[公式]"></p>
<h4><span id="pytorch-线性回归">==Pytorch 线性回归==</span></h4>
<p>线性回归是分析一个变量 (<img src="https://www.zhihu.com/equation?tex=y" alt="[公式]">) 与另外一
(多) 个变量 (<img src="https://www.zhihu.com/equation?tex=x" alt="[公式]">) 之间的关系的方法。一般可以写成 <img src="https://www.zhihu.com/equation?tex=y%3Dwx%2Bb" alt="[公式]">。线性回归的目的就是求解参数 <img src="https://www.zhihu.com/equation?tex=w%2C+b" alt="[公式]">。</p>
<p>线性回归的求解可以分为 3 步：</p>
<ol type="1">
<li>确定模型：<img src="https://www.zhihu.com/equation?tex=y%3Dwx%2Bb" alt="[公式]"></li>
<li>选择损失函数，一般使用均方误差 MSE：<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%5Cleft%28y_%7Bi%7D-%5Chat%7By%7D_%7Bi%7D%5Cright%29%5E%7B2%7D" alt="[公式]">。其中 <img src="https://www.zhihu.com/equation?tex=+%5Chat%7By%7D_%7Bi%7D+" alt="[公式]"> 是预测值，<img src="https://www.zhihu.com/equation?tex=y" alt="[公式]">
是真实值。</li>
<li>使用梯度下降法求解梯度 (其中 <img src="https://www.zhihu.com/equation?tex=lr" alt="[公式]">
是学习率)，并更新参数：</li>
</ol>
<ul>
<li><figure>
<img src="https://www.zhihu.com/equation?tex=w+%3D+w+-+lr+%2A+w.grad" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure></li>
<li><figure>
<img src="https://www.zhihu.com/equation?tex=b+%3D+b+-+lr+%2A+b.grad" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">代码如下：</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">torch.manual_seed(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.05</span>  <span class="comment"># 学习率</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建训练数据</span></span><br><span class="line">x = torch.rand(<span class="number">20</span>, <span class="number">1</span>) * <span class="number">10</span>  <span class="comment"># x data (tensor), shape=(20, 1)</span></span><br><span class="line"><span class="comment"># torch.randn(20, 1) 用于添加噪声</span></span><br><span class="line">y = <span class="number">2</span>*x + (<span class="number">5</span> + torch.randn(<span class="number">20</span>, <span class="number">1</span>))  <span class="comment"># y data (tensor), shape=(20, 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建线性回归参数</span></span><br><span class="line">w = torch.randn((<span class="number">1</span>), requires_grad=<span class="literal">True</span>) <span class="comment"># 设置梯度求解为 true</span></span><br><span class="line">b = torch.zeros((<span class="number">1</span>), requires_grad=<span class="literal">True</span>) <span class="comment"># 设置梯度求解为 true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代训练 1000 次</span></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前向传播，计算预测值</span></span><br><span class="line">    wx = torch.mul(w, x)</span><br><span class="line">    y_pred = torch.add(wx, b)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算 MSE loss</span></span><br><span class="line">    loss = (<span class="number">0.5</span> * (y - y_pred) ** <span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    b.data.sub_(lr * b.grad)</span><br><span class="line">    w.data.sub_(lr * w.grad)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每次更新参数之后，都要清零张量的梯度</span></span><br><span class="line">    w.grad.zero_()</span><br><span class="line">    b.grad.zero_()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘图，每隔 20 次重新绘制直线</span></span><br><span class="line">    <span class="keyword">if</span> iteration % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">        plt.scatter(x.data.numpy(), y.data.numpy())</span><br><span class="line">        plt.plot(x.data.numpy(), y_pred.data.numpy(), <span class="string">&#x27;r-&#x27;</span>, lw=<span class="number">5</span>)</span><br><span class="line">        plt.text(<span class="number">2</span>, <span class="number">20</span>, <span class="string">&#x27;Loss=%.4f&#x27;</span> % loss.data.numpy(), fontdict=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">20</span>, <span class="string">&#x27;color&#x27;</span>:  <span class="string">&#x27;red&#x27;</span>&#125;)</span><br><span class="line">        plt.xlim(<span class="number">1.5</span>, <span class="number">10</span>)</span><br><span class="line">        plt.ylim(<span class="number">8</span>, <span class="number">28</span>)</span><br><span class="line">        plt.title(<span class="string">&quot;Iteration: &#123;&#125;\nw: &#123;&#125; b: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(iteration, w.data.numpy(), b.data.numpy()))</span><br><span class="line">        plt.pause(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果 MSE 小于 1，则停止训练</span></span><br><span class="line">        <span class="keyword">if</span> loss.data.numpy() &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（2）静态图与动态图机制</title>
    <url>/posts/2DYJWRV/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记静态图与动态图机制">[PyTorch 学习笔记]
静态图与动态图机制</span></h2>
<h3><span id="计算图">计算图</span></h3>
<p>深度学习就是对张量进行一系列的操作，随着操作种类和数量的增多，会出现各种值得思考的问题。比如<strong>多个操作之间是否可以并行</strong>，<strong>如何协同底层的不同设备</strong>，如<strong>何避免冗余</strong>的操作，以实现最<strong>高效的计算效率</strong>，同时避免一些
bug。因此产生了<strong>计算图 (Computational Graph)</strong>。</p>
<p>计算图是用来描述运算的有向无环图，有两个主要元素：<strong>节点
(Node)</strong> 和<strong>边
(Edge)</strong>。节点表示数据，如向量、矩阵、张量。边表示运算，如加减乘除卷积等。</p>
<p>用计算图表示：<img src="https://www.zhihu.com/equation?tex=y%3D%28x%2Bw%29%2A%28w%2B1%29" alt="[公式]">，如下所示：</p>
<p><img src="https://pic2.zhimg.com/80/v2-464ea7ee4475f3c7f08c389f65fd3e89_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>可以看作， <img src="https://www.zhihu.com/equation?tex=y%3Da+%5Ctimes+b" alt="[公式]"> ，其中 <img src="https://www.zhihu.com/equation?tex=a%3Dx%2Bw" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=b%3Dw%2B1" alt="[公式]">。</p>
<h3><span id="计算图与梯度求导">计算图与梯度求导</span></h3>
<p>这里求 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 对 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> 的导数。根复合函数的求导法则，可以得到如下过程。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+w%7D+%26%3D%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+a%7D+%5Cfrac%7B%5Cpartial+a%7D%7B%5Cpartial+w%7D%2B%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+b%7D+%5Cfrac%7B%5Cpartial+b%7D%7B%5Cpartial+w%7D+%5C%5C+%26%3Db+%2A+1%2Ba+%2A+1+%5C%5C+%26%3Db%2Ba+%5C%5C+%26%3D%28w%2B1%29%2B%28x%2Bw%29+%5C%5C+%26%3D2+%2A+w%2Bx%2B1+%5C%5C+%26%3D2+%2A+1%2B2%2B1%3D5%5Cend%7Baligned%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>体现到计算图中，就是根节点 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 到叶子节点
<img src="https://www.zhihu.com/equation?tex=w" alt="[公式]">
有两条路径
<code>y -&gt; a -&gt; w</code>和<code>y -&gt;b -&gt; w</code>。根节点依次对每条路径的孩子节点求导，一直到叶子节点<code>w</code>，最后把每条路径的导数相加即可。</p>
<p><img src="https://pic2.zhimg.com/80/v2-d4c05b194d2e123cb246115e90ec917d_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">w = torch.tensor([<span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">x = torch.tensor([<span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># y=(x+w)*(w+1)</span></span><br><span class="line">a = torch.add(w, x)     <span class="comment"># retain_grad()</span></span><br><span class="line">b = torch.add(w, <span class="number">1</span>)</span><br><span class="line">y = torch.mul(a, b)</span><br><span class="line"><span class="comment"># y 求导</span></span><br><span class="line">y.backward()</span><br><span class="line"><span class="comment"># 打印 w 的梯度，就是 y 对 w 的导数</span></span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br></pre></td></tr></table></figure>
<p>结果为<code>tensor([5.])</code>，我们回顾前面说过的 Tensor
中有一个属性<code>is_leaf</code>标记是否为叶子节点。</p>
<p><img src="https://pic2.zhimg.com/80/v2-3bc1ff0ab920582a3491111b81a32fe5_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>在上面的例子中，<img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]">
是叶子节点，其他所有节点都依赖于叶子节点。<strong>叶子节点的概念主要是为了节省内存，在计算图中的一轮反向传播结束之后，非叶子节点的梯度是会被释放的</strong>。</p>
<h3><span id="pytorch-的动态图机制">PyTorch 的动态图机制</span></h3>
<p><strong>PyTorch 采用的是动态图机制 (Dynamic Computational Graph)，而
Tensorflow 采用的是静态图机制 (Static Computational
Graph)。</strong></p>
<p><strong>动态图是运算和搭建同时进行，也就是可以先计算前面的节点的值，再根据这些值搭建后面的计算图</strong>。优点是<strong>灵活，易调节，易调试</strong>。PyTorch
里的很多写法跟其他 Python
库的代码的使用方法是完全一致的，没有任何额外的学习成本。</p>
<p><strong>静态图是先搭建图，然后再输入数据进行运算</strong>。优点是<strong>高效</strong>，因为静态计算是通过先定义后运行的方式，之后再次运行的时候就不再需要重新构建计算图，所以速度会比动态图更快。但是不灵活。<strong>TensorFlow
每次运行的时候图都是一样的，是不能够改变的，所以不能直接使用 Python 的
while 循环语句，需要使用辅助函数 tf.while_loop 写成 TensorFlow
内部的形式。</strong></p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（17）模型应用</title>
    <url>/posts/3ACJRH6/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记-使用-gpu训练模型">[PyTorch 学习笔记] 使用 GPU
训练模型</span></h2>
<p>https://zhuanlan.zhihu.com/p/254738836</p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（3）Autograd 与逻辑回归</title>
    <url>/posts/15HX48P/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记autograd-与逻辑回归">[PyTorch 学习笔记]
Autograd 与逻辑回归</span></h2>
<h3><span id="自动求导-autograd"><strong>自动求导 (autograd)</strong></span></h3>
<p>在深度学习中，权值的更新是依赖于梯度的计算，因此梯度的计算是至关重要的。<strong>在
PyTorch
中，只需要搭建好前向计算图，然后利用<code>torch.autograd</code>自动求导得到所有张量的梯度。</strong></p>
<h4><span id="torchautogradbackward自动求取梯度"><strong>torch.autograd.backward()</strong>：自动求取梯度</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.autograd.backward(tensors, grad_tensors=<span class="literal">None</span>, retain_graph=<span class="literal">None</span>, create_graph=<span class="literal">False</span>, grad_variables=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>tensors</strong>: 用于求导的张量，如 loss</li>
<li><strong>retain_graph</strong>: <strong>保存计算图</strong>。PyTorch
采用动态图机制，默认每次反向传播之后都会释放计算图。这里设置为 True
可以不释放计算图。</li>
<li>create_graph: 创建导数计算图，用于高阶求导</li>
<li><strong>grad_tensors:</strong> <strong>多梯度权重</strong>。当有多个
loss 混合需要计算梯度时，设置每个 loss 的权重。</li>
</ul>
<h3><span id="逻辑回归-logisticregression">==<strong>逻辑回归 (Logistic
Regression)</strong>==</span></h3>
<p><strong>逻辑回归是线性的二分类模型</strong>。模型表达式 <img src="https://www.zhihu.com/equation?tex=y%3Df%28z%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D" alt="[公式]">，其中 <img src="https://www.zhihu.com/equation?tex=z%3DWX%2Bb" alt="[公式]">。<img src="https://www.zhihu.com/equation?tex=f%28z%29" alt="[公式]"> 称为 sigmoid 函数，也被称为 Logistic
函数。函数曲线如下：(横坐标是 <img src="https://www.zhihu.com/equation?tex=z" alt="[公式]">，而 <img src="https://www.zhihu.com/equation?tex=z%3DWX%2Bb" alt="[公式]">，纵坐标是 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]">)</p>
<p><img src="https://pic3.zhimg.com/80/v2-9606554d12be479e930976e852a1b7b6_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>分类原则如下：class <img src="https://www.zhihu.com/equation?tex=%3D%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bll%7D0%2C+%26+0.5%3Ey+%5C%5C+1+%26+0.5+%5Cleq+y%5Cend%7Barray%7D%5Cright." alt="[公式]">。当 <img src="https://www.zhihu.com/equation?tex=y%3C0.5" alt="[公式]">
时，类别为 0；当 <img src="https://www.zhihu.com/equation?tex=0.5+%5Cleq+y" alt="[公式]">
时，类别为 1。</p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=z%3DWX%2Bb" alt="[公式]"> 就是原来的线性回归的模型。从横坐标来看，当 <img src="https://www.zhihu.com/equation?tex=z%3C0" alt="[公式]">
时，类别为 0；当 <img src="https://www.zhihu.com/equation?tex=0+%5Cleq+z" alt="[公式]">
时，类别为
1，直接使用线性回归也可以进行分类。逻辑回归是在线性回归的基础上加入了一个
sigmoid 函数，这是为了更好地描述置信度，把输入映射到 (0,1)
区间中，符合概率取值。</p>
<p>逻辑回归也被称为<strong>对数几率回归</strong> <img src="https://www.zhihu.com/equation?tex=%5Cln+%5Cfrac%7By%7D%7B1-y%7D%3DW+X%2Bb" alt="[公式]">，几率的表达式为：<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7By%7D%7B1-y%7D" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 表示正类别的概率，<img src="https://www.zhihu.com/equation?tex=1-y" alt="[公式]">
表示另一个类别的概率。根据对数几率回归可以推导出逻辑回归表达式：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cln+%5Cfrac%7By%7D%7B1-y%7D%3DW+X%2Bb" alt="[公式]"> <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7By%7D%7B1-y%7D%3De%5E%7BW+X%2Bb%7D" alt="[公式]"> <img src="https://www.zhihu.com/equation?tex=y%3De%5E%7BW+X%2Bb%7D-y+%2A+e%5E%7BW+X%2Bb%7D" alt="[公式]"> <img src="https://www.zhihu.com/equation?tex=y%5Cleft%281%2Be%5E%7BW+X%2Bb%7D%5Cright%29%3De%5E%7BW+X%2Bb%7D" alt="[公式]"> <img src="https://www.zhihu.com/equation?tex=y%3D%5Cfrac%7Be%5E%7BW+X%2Bb%7D%7D%7B1%2Be%5E%7BW+X%2Bb%7D%7D%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%28W+X%2Bb%29%7D%7D" alt="[公式]"></p>
<h3><span id="pytorch实现逻辑回归">==<strong>PyTorch
实现逻辑回归</strong>==</span></h3>
<p><img src="https://pic3.zhimg.com/80/v2-9ff73ed5e7babaec8c73d420386f02b2_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p><strong>PyTorch 构建模型需要 5 大步骤：</strong></p>
<ul>
<li><strong>数据</strong>：包括数据读取，数据清洗，进行数据划分和数据预处理，比如读取图片如何预处理及数据增强。</li>
<li><strong>模型</strong>：包括构建模型模块，组织复杂网络，初始化网络参数，定义网络层。</li>
<li><strong>损失函数</strong>：包括创建损失函数，设置损失函数超参数，根据不同任务选择合适的损失函数。</li>
<li><strong>优化器</strong>：包括根据梯度使用某种优化器更新参数，管理模型参数，管理多个参数组实现不同学习率，调整学习率。</li>
<li><strong>迭代训练</strong>：组织上面 4
个模块进行反复训练。包括观察训练效果，绘制 Loss/ Accuracy 曲线，用
TensorBoard 进行可视化分析。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">torch.manual_seed(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ============================ step 1/5 生成数据 ============================</span></span><br><span class="line">sample_nums = <span class="number">100</span></span><br><span class="line">mean_value = <span class="number">1.7</span></span><br><span class="line">bias = <span class="number">1</span></span><br><span class="line">n_data = torch.ones(sample_nums, <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 使用正态分布随机生成样本，均值为张量，方差为标量</span></span><br><span class="line">x0 = torch.normal(mean_value * n_data, <span class="number">1</span>) + bias      <span class="comment"># 类别0 数据 shape=(100, 2)</span></span><br><span class="line"><span class="comment"># 生成对应标签</span></span><br><span class="line">y0 = torch.zeros(sample_nums)                         <span class="comment"># 类别0 标签 shape=(100, 1)</span></span><br><span class="line"><span class="comment"># 使用正态分布随机生成样本，均值为张量，方差为标量</span></span><br><span class="line">x1 = torch.normal(-mean_value * n_data, <span class="number">1</span>) + bias     <span class="comment"># 类别1 数据 shape=(100, 2)</span></span><br><span class="line"><span class="comment"># 生成对应标签</span></span><br><span class="line">y1 = torch.ones(sample_nums)                          <span class="comment"># 类别1 标签 shape=(100, 1)</span></span><br><span class="line">train_x = torch.cat((x0, x1), <span class="number">0</span>)</span><br><span class="line">train_y = torch.cat((y0, y1), <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ============================ step 2/5 选择模型 ============================</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LR</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LR, self).__init__()</span><br><span class="line">        self.features = nn.Linear(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = self.sigmoid(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">lr_net = LR()   <span class="comment"># 实例化逻辑回归模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ============================ step 3/5 选择损失函数 ============================</span></span><br><span class="line">loss_fn = nn.BCELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ============================ step 4/5 选择优化器   ============================</span></span><br><span class="line">lr = <span class="number">0.01</span>  <span class="comment"># 学习率</span></span><br><span class="line">optimizer = torch.optim.SGD(lr_net.parameters(), lr=lr, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ============================ step 5/5 模型训练 ============================</span></span><br><span class="line"><span class="keyword">for</span> iteration <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    y_pred = lr_net(train_x)</span><br><span class="line">    <span class="comment"># 计算 loss</span></span><br><span class="line">    loss = loss_fn(y_pred.squeeze(), train_y)</span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="comment"># 清空梯度</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># 绘图</span></span><br><span class="line">    <span class="keyword">if</span> iteration % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        mask = y_pred.ge(<span class="number">0.5</span>).<span class="built_in">float</span>().squeeze()  <span class="comment"># 以0.5为阈值进行分类</span></span><br><span class="line">        correct = (mask == train_y).<span class="built_in">sum</span>()  <span class="comment"># 计算正确预测的样本个数</span></span><br><span class="line">        acc = correct.item() / train_y.size(<span class="number">0</span>)  <span class="comment"># 计算分类准确率</span></span><br><span class="line"></span><br><span class="line">        plt.scatter(x0.data.numpy()[:, <span class="number">0</span>], x0.data.numpy()[:, <span class="number">1</span>], c=<span class="string">&#x27;r&#x27;</span>, label=<span class="string">&#x27;class 0&#x27;</span>)</span><br><span class="line">        plt.scatter(x1.data.numpy()[:, <span class="number">0</span>], x1.data.numpy()[:, <span class="number">1</span>], c=<span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;class 1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        w0, w1 = lr_net.features.weight[<span class="number">0</span>]</span><br><span class="line">        w0, w1 = <span class="built_in">float</span>(w0.item()), <span class="built_in">float</span>(w1.item())</span><br><span class="line">        plot_b = <span class="built_in">float</span>(lr_net.features.bias[<span class="number">0</span>].item())</span><br><span class="line">        plot_x = np.arange(-<span class="number">6</span>, <span class="number">6</span>, <span class="number">0.1</span>)</span><br><span class="line">        plot_y = (-w0 * plot_x - plot_b) / w1</span><br><span class="line"></span><br><span class="line">        plt.xlim(-<span class="number">5</span>, <span class="number">7</span>)</span><br><span class="line">        plt.ylim(-<span class="number">7</span>, <span class="number">7</span>)</span><br><span class="line">        plt.plot(plot_x, plot_y)</span><br><span class="line"></span><br><span class="line">        plt.text(-<span class="number">5</span>, <span class="number">5</span>, <span class="string">&#x27;Loss=%.4f&#x27;</span> % loss.data.numpy(), fontdict=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">20</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;red&#x27;</span>&#125;)</span><br><span class="line">        plt.title(<span class="string">&quot;Iteration: &#123;&#125;\nw0:&#123;:.2f&#125; w1:&#123;:.2f&#125; b: &#123;:.2f&#125; accuracy:&#123;:.2%&#125;&quot;</span>.<span class="built_in">format</span>(iteration, w0, w1, plot_b, acc))</span><br><span class="line">        plt.legend()</span><br><span class="line">        <span class="comment"># plt.savefig(str(iteration / 20)+&quot;.png&quot;)</span></span><br><span class="line">        plt.show()</span><br><span class="line">        plt.pause(<span class="number">0.5</span>)</span><br><span class="line">        <span class="comment"># 如果准确率大于 99%，则停止训练</span></span><br><span class="line">        <span class="keyword">if</span> acc &gt; <span class="number">0.99</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>训练的分类直线的可视化如下：</p>
<figure>
<img src="https://pic1.zhimg.com/v2-0bd46429c86896a40fc31587ce1e5eb8_b.webp" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（6）模型构建-nn</title>
    <url>/posts/27GTTPQ/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记模型创建步骤-与-nnmodule">[PyTorch 学习笔记]
模型创建步骤 与 nn.Module</span></h2>
<p>这篇文章来看下 PyTorch
中网络模型的创建步骤。网络模型的内容如下，包括模型创建和权值初始化，这些内容都在<code>nn.Module</code>中有实现。</p>
<p><img src="https://pic1.zhimg.com/80/v2-73f524c24074752262f174e286cd06c8_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<h3><span id="一-网络模型的创建步骤">一、<strong>网络模型的创建步骤</strong></span></h3>
<p>创建模型有 2
个要素：<strong>构建子模块</strong>和<strong>拼接子模块</strong>。如
LeNet
里包含很多卷积层、池化层、全连接层，当我们构建好所有的子模块之后，按照一定的顺序拼接起来。</p>
<p><img src="https://pic2.zhimg.com/80/v2-c49991252ebd1a0a1697e87249d1335d_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>这里以上一篇文章中 <code>lenet.py</code>的 LeNet
为例，继承<code>nn.Module</code>，必须实现<code>__init__()</code>
方法和<code>forward()</code>方法。其中<code>__init__()</code>
方法里创建子模块，在<code>forward()</code>方法里拼接子模块。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet</span>(nn.Module):</span><br><span class="line"> <span class="comment"># 子模块创建</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, classes)</span><br><span class="line"> <span class="comment"># 子模块拼接</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = F.relu(self.conv1(x))</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = F.relu(self.conv2(out))</span><br><span class="line">        out = F.max_pool2d(out, <span class="number">2</span>)</span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        out = F.relu(self.fc1(out))</span><br><span class="line">        out = F.relu(self.fc2(out))</span><br><span class="line">        out = self.fc3(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<ul>
<li><p>调用<code>net = LeNet(classes=2)</code>创建模型时，会调用<code>__init__()</code>方法创建模型的子模块。</p></li>
<li><p>在训练时<strong>调用<code>outputs = net(inputs)</code>时，会进入<code>module.py</code>的<code>call()</code>函数中</strong>：</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, *<span class="built_in">input</span>, **kwargs</span>):</span><br><span class="line">    <span class="keyword">for</span> hook <span class="keyword">in</span> self._forward_pre_hooks.values():</span><br><span class="line">        result = hook(self, <span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">if</span> result <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(result, <span class="built_in">tuple</span>):</span><br><span class="line">                result = (result,)</span><br><span class="line">            <span class="built_in">input</span> = result</span><br><span class="line">    <span class="keyword">if</span> torch._C._get_tracing_state():</span><br><span class="line">        result = self._slow_forward(*<span class="built_in">input</span>, **kwargs)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result = self.forward(*<span class="built_in">input</span>, **kwargs)</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<ul>
<li>最终会<strong>调用<code>result = self.forward(*input, **kwargs)</code>函数，该函数会进入模型的<code>forward()</code>函数中，进行前向传播。</strong></li>
</ul>
<p>在 <code>torch.nn</code>中包含 4 个模块，如下图所示。</p>
<p><img src="https://pic4.zhimg.com/80/v2-286125e2e4b7bec2a5b632db6e690c7b_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h3><span id="二-nnmodule">二、nn.Module</span></h3>
<p><strong><code>nn.Module</code> 有 8
个属性，都是<code>OrderDict</code>(有序字典)。在 LeNet
的<code>__init__()</code>方法中会调用父类<code>nn.Module</code>的<code>__init__()</code>方法，创建这
8 个属性。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Initializes internal Module state, shared by both nn.Module and ScriptModule.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    torch._C._log_api_usage_once(<span class="string">&quot;python.nn_module&quot;</span>)</span><br><span class="line"></span><br><span class="line">    self.training = <span class="literal">True</span></span><br><span class="line">    self._parameters = OrderedDict()</span><br><span class="line">    self._buffers = OrderedDict()</span><br><span class="line">    self._backward_hooks = OrderedDict()</span><br><span class="line">    self._forward_hooks = OrderedDict()</span><br><span class="line">    self._forward_pre_hooks = OrderedDict()</span><br><span class="line">    self._state_dict_hooks = OrderedDict()</span><br><span class="line">    self._load_state_dict_pre_hooks = OrderedDict()</span><br><span class="line">    self._modules = OrderedDict()</span><br></pre></td></tr></table></figure>
<ul>
<li>**_parameters 属性**：存储管理 nn.Parameter 类型的参数</li>
<li>**_modules 属性**：存储管理 nn.Module 类型的参数</li>
<li>_buffers 属性：存储管理缓冲属性，如 BN 层中的 running_mean</li>
<li>5 个 ***_hooks 属性：存储管理钩子函数</li>
</ul>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（5）【Nan】图像处理</title>
    <url>/posts/3FXX4X4/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（4）DataLoader</title>
    <url>/posts/38401RR/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记dataloader-与-dataset">[PyTorch 学习笔记]
DataLoader 与 DataSet</span></h2>
<h4><span id="人民币-二分类"><strong>人民币 二分类</strong></span></h4>
<p>实现 1 元人民币和 100 元人民币的图片二分类。前面讲过 PyTorch
的五大模块：数据、模型、损失函数、优化器和迭代训练。</p>
<p>数据模块又可以细分为 4 个部分：</p>
<ul>
<li>数据收集：样本和标签。</li>
<li>数据划分：训练集、验证集和测试集</li>
<li>数据读取：对应于 PyTorch 的 DataLoader。其中 DataLoader 包括 Sampler
和 DataSet。Sampler 的功能是生成索引， DataSet
是根据生成的索引读取样本以及标签。</li>
<li>数据预处理：对应于 PyTorch 的 transforms</li>
</ul>
<p><img src="https://pic1.zhimg.com/80/v2-11280c55c7d6f98b4ddb6fffe9c3645c_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h3><span id="一-dataloader-与-dataset">一、DataLoader 与 DataSet</span></h3>
<h4><span id="11torchutilsdatadataloader"><strong>1.1
torch.utils.data.DataLoader()</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.utils.data.DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">False</span>, sampler=<span class="literal">None</span>, batch_sampler=<span class="literal">None</span>, num_workers=<span class="number">0</span>, collate_fn=<span class="literal">None</span>, pin_memory=<span class="literal">False</span>, drop_last=<span class="literal">False</span>, timeout=<span class="number">0</span>, worker_init_fn=<span class="literal">None</span>, multiprocessing_context=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>功能：构建可迭代的数据装载器</p>
<ul>
<li><strong>dataset</strong>: Dataset
类，决定数据从哪里读取以及如何读取</li>
<li><strong>batchsize</strong>: 批大小</li>
<li><strong>num_works</strong>:num_works: 是否多进程读取数据</li>
<li><strong>sheuffle</strong>: 每个 epoch 是否乱序</li>
<li>drop_last: 当样本数不能被 batchsize
整除时，是否舍弃最后一批数据</li>
</ul>
<h4><span id="12-epoch-iterationbatchsize"><strong>1.2 Epoch, Iteration,
Batchsize</strong></span></h4>
<ul>
<li><strong>Epoch</strong>: 所有训练样本都已经输入到模型中，称为一个
Epoch</li>
<li><strong>Iteration</strong>: 一批样本输入到模型中，称为一个
Iteration</li>
<li><strong>Batchsize</strong>: 批大小，决定一个 iteration
有多少样本，也决定了一个 Epoch 有多少个 Iteration</li>
</ul>
<h4><span id="13torchutilsdatadataset">1.3
<strong>torch.utils.data.Dataset</strong></span></h4>
<p><strong>功能</strong>：Dataset 是抽象类，所有自定义的 Dataset
都需要继承该类，<strong>并且重写<code>__getitem()__</code>方法和<code>__len__()</code>方法</strong>
。<code>__getitem()__</code>方法的作用是接收一个索引，返回索引对应的样本和标签，这是我们自己需要实现的逻辑。<code>__len__()</code>方法是返回所有样本的数量。</p>
<p>数据读取包含 3 个方面：</p>
<ul>
<li><strong>读取哪些数据</strong>：每个 Iteration 读取一个
<strong>Batchsize 大小</strong>的数据，每个 Iteration
应该读取哪些数据。</li>
<li><strong>从哪里读取数据</strong>：如何找到硬盘中的数据，应该在哪里设置<strong>文件路径参数</strong></li>
<li><strong>如何读取数据</strong>：不同的文件需要使用不同的读取方法和库。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RMBDataset</span>(<span class="title class_ inherited__">Dataset</span>):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_dir, transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        rmb面额分类任务的Dataset</span></span><br><span class="line"><span class="string">        :param data_dir: str, 数据集所在路径</span></span><br><span class="line"><span class="string">        :param transform: torch.transform，数据预处理</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># data_info存储所有图片路径和标签，在DataLoader中通过index读取样本</span></span><br><span class="line">        self.data_info = self.get_img_info(data_dir)</span><br><span class="line">        self.transform = transform</span><br><span class="line">        </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_img_info</span>(<span class="params">data_dir</span>):</span><br><span class="line">        data_info = <span class="built_in">list</span>()</span><br><span class="line">        <span class="comment"># data_dir 是训练集、验证集或者测试集的路径</span></span><br><span class="line">        <span class="keyword">for</span> root, dirs, _ <span class="keyword">in</span> os.walk(data_dir):</span><br><span class="line">            <span class="comment"># 遍历类别</span></span><br><span class="line">            <span class="comment"># dirs [&#x27;1&#x27;, &#x27;100&#x27;]</span></span><br><span class="line">            <span class="keyword">for</span> sub_dir <span class="keyword">in</span> dirs:</span><br><span class="line">                <span class="comment"># 文件列表</span></span><br><span class="line">                img_names = os.listdir(os.path.join(root, sub_dir))</span><br><span class="line">                <span class="comment"># 取出 jpg 结尾的文件</span></span><br><span class="line">                img_names = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x.endswith(<span class="string">&#x27;.jpg&#x27;</span>), img_names))</span><br><span class="line">                <span class="comment"># 遍历图片</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(img_names)):</span><br><span class="line">                    img_name = img_names[i]</span><br><span class="line">                    <span class="comment"># 图片的绝对路径</span></span><br><span class="line">                    path_img = os.path.join(root, sub_dir, img_name)</span><br><span class="line">                    <span class="comment"># 标签，这里需要映射为 0、1 两个类别</span></span><br><span class="line">                    label = rmb_label[sub_dir]</span><br><span class="line">                    <span class="comment"># 保存在 data_info 变量中</span></span><br><span class="line">                    data_info.append((path_img, <span class="built_in">int</span>(label)))</span><br><span class="line">        <span class="keyword">return</span> data_info</span><br><span class="line">      </span><br><span class="line">		<span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># 通过 index 读取样本</span></span><br><span class="line">        path_img, label = self.data_info[index]</span><br><span class="line">        <span class="comment"># 注意这里需要 convert(&#x27;RGB&#x27;)</span></span><br><span class="line">        img = Image.<span class="built_in">open</span>(path_img).convert(<span class="string">&#x27;RGB&#x27;</span>)     <span class="comment"># 0~255</span></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(img)   <span class="comment"># 在这里做transform，转为tensor等等</span></span><br><span class="line">        <span class="comment"># 返回是样本和标签</span></span><br><span class="line">        <span class="keyword">return</span> img, label   </span><br><span class="line">      </span><br><span class="line">		<span class="comment"># 返回所有样本的数量</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data_info)      </span><br></pre></td></tr></table></figure>
<ul>
<li><strong>图片的路径和对应的标签</strong>：实现读取数据的
Dataset，编写一个<code>get_img_info()</code>方法，<strong>读取每一个图片的路径和对应的标签，组成一个元组，再把所有的元组作为
list
存放到<code>self.data_info</code>变量中</strong>，这里需要注意的是标签需要映射到
0 开始的整数: <code>rmb_label = &#123;"1": 0, "100": 1&#125;</code>。</li>
<li>然后在<code>Dataset</code>
的初始化函数中调用<code>get_img_info()</code>方法。</li>
<li><strong>索引</strong>：然后在<code>__getitem__()</code>方法中根据<code>index</code>
读取<code>self.data_info</code>中路径对应的数据，并在这里做 transform
操作，返回的是样本和标签。</li>
<li><strong>长度</strong>：在<code>__len__()</code>方法中返回<code>self.data_info</code>的长度，即为所有样本的数量。</li>
</ul>
<p>在<code>train_lenet.py</code>中，分 5 步构建模型。</p>
<ul>
<li>首先定义训练集、验证集、测试集的路径，定义训练集和测试集的<code>transforms</code>。然后构建训练集和验证集的<code>RMBDataset</code>对象，把对应的路径和<code>transforms</code>传进去。再构建<code>DataLoder</code>，设置
batch_size，其中训练集设置<code>shuffle=True</code>，表示每个 Epoch
都打乱样本。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 构建MyDataset实例train_data = RMBDataset(data_dir=train_dir, transform=train_transform)valid_data = RMBDataset(data_dir=valid_dir, transform=valid_transform)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建DataLoder</span></span><br><span class="line"><span class="comment"># 其中训练集设置 shuffle=True，表示每个 Epoch 都打乱样本</span></span><br><span class="line">train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>)</span><br><span class="line">valid_loader = DataLoader(dataset=valid_data, batch_size=BATCH_SIZE)</span><br></pre></td></tr></table></figure>
<ul>
<li>第 2 步构建模型，这里采用经典的 Lenet 图片分类网络。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net = LeNet(classes=<span class="number">2</span>)</span><br><span class="line">net.initialize_weights()</span><br></pre></td></tr></table></figure>
<ul>
<li>第 3 步设置损失函数，这里使用<strong>交叉熵损失函数</strong>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>
<ul>
<li>第 4 步设置优化器。这里采用 <strong>SGD 优化器</strong>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer = optim.SGD(net.parameters(), lr=LR, momentum=<span class="number">0.9</span>) <span class="comment"># 选择优化器</span></span><br><span class="line">scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=<span class="number">10</span>, gamma=<span class="number">0.1</span>) </span><br><span class="line"><span class="comment"># 设置学习率下降策略</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>第 5 步<strong>迭代训练模型</strong>，在每一个 epoch
里面，<strong>需要遍历 train_loader 取出数据，每次取得数据是一个
batchsize 大小</strong>。这里又分为 4 步。</p>
<ul>
<li><p><strong>前向传播</strong></p></li>
<li><p><strong>反向传播求导</strong></p></li>
<li><p><strong>使用<code>optimizer</code>更新权重</strong></p></li>
<li><p><strong>统计训练情况</strong>。每一个 epoch
完成时都需要使用<code>scheduler</code>更新学习率，和计算验证集的准确率、</p>
<p>loss。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(MAX_EPOCH):</span><br><span class="line"></span><br><span class="line">    loss_mean = <span class="number">0.</span></span><br><span class="line">    correct = <span class="number">0.</span></span><br><span class="line">    total = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line">    net.train()</span><br><span class="line">    <span class="comment"># 遍历 train_loader 取数据</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line">        outputs = net(inputs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># backward</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update weights</span></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 统计分类情况</span></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).squeeze().<span class="built_in">sum</span>().numpy()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印训练信息</span></span><br><span class="line">        loss_mean += loss.item()</span><br><span class="line">        train_curve.append(loss.item())</span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % log_interval == <span class="number">0</span>:</span><br><span class="line">            loss_mean = loss_mean / log_interval</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Training:Epoch[&#123;:0&gt;3&#125;/&#123;:0&gt;3&#125;] Iteration[&#123;:0&gt;3&#125;/&#123;:0&gt;3&#125;] Loss: &#123;:.4f&#125; Acc:&#123;:.2%&#125;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch, MAX_EPOCH, i+<span class="number">1</span>, <span class="built_in">len</span>(train_loader), loss_mean, correct / total))</span><br><span class="line">            loss_mean = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line">    scheduler.step()  <span class="comment"># 更新学习率</span></span><br><span class="line">    <span class="comment"># 每个 epoch 计算验证集得准确率和loss</span></span><br></pre></td></tr></table></figure></li>
</ul></li>
</ul>
<p>我们可以看到每个
iteration，我们是从<strong>train_loader</strong>中取出数据的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">if</span> self.num_workers == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> _SingleProcessDataLoaderIter(self)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> _MultiProcessingDataLoaderIter(self)</span><br></pre></td></tr></table></figure>
<p>这里我们没有设置多进程，会执行<code>_SingleProcessDataLoaderIter</code>的方法。我们以<code>_SingleProcessDataLoaderIter</code>为例。在<code>_SingleProcessDataLoaderIter</code>里只有一个方法<code>_next_data()</code>，如下：</p>
<h4><span id="14_singleprocessdataloaderiter单进程">==1.4
<code>_SingleProcessDataLoaderIter</code>单进程==</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_next_data</span>(<span class="params">self</span>):</span><br><span class="line">		index = self._next_index()  <span class="comment"># may raise StopIteration</span></span><br><span class="line"> 		data = self._dataset_fetcher.fetch(index)  <span class="comment"># may raise StopIteration</span></span><br><span class="line"> 		<span class="keyword">if</span> self._pin_memory:</span><br><span class="line">  			data = _utils.pin_memory.pin_memory(data)</span><br><span class="line"> 		<span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<p>在该方法中，<strong>self._next_index()</strong>是<strong>获取一个
batchsize 大小的 index 列表</strong>，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_next_index</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">next</span>(self._sampler_iter)  <span class="comment"># may raise StopIteration</span></span><br></pre></td></tr></table></figure>
<p>其中调用的<strong>sample类</strong>的<code>__iter__()</code>方法<strong>返回
batch_size 大小的随机 index 列表</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">		batch = []</span><br><span class="line"> 		<span class="keyword">for</span> idx <span class="keyword">in</span> self.sampler:</span><br><span class="line">  			batch.append(idx)</span><br><span class="line">  			<span class="keyword">if</span> <span class="built_in">len</span>(batch) == self.batch_size:</span><br><span class="line">   					<span class="keyword">yield</span> batch</span><br><span class="line">   					batch = []</span><br><span class="line"> 		<span class="keyword">if</span> <span class="built_in">len</span>(batch) &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> self.drop_last:</span><br><span class="line">  			<span class="keyword">yield</span> batch</span><br></pre></td></tr></table></figure>
<p>然后再返回看
<code>dataloader</code>的<code>_next_data()</code>方法，在第二行中调用了<strong>self._dataset_fetcher.fetch(index)</strong>获取数据。这里会调用<code>_MapDatasetFetcher</code>中的<code>fetch()</code>函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fetch</span>(<span class="params">self, possibly_batched_index</span>):</span><br><span class="line">		<span class="keyword">if</span> self.auto_collation:</span><br><span class="line">  			data = [self.dataset[idx] <span class="keyword">for</span> idx <span class="keyword">in</span> possibly_batched_index]</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">  			data = self.dataset[possibly_batched_index]</span><br><span class="line"> 		<span class="keyword">return</span> self.collate_fn(data)</span><br></pre></td></tr></table></figure>
<p>这里调用了<strong>self.dataset[idx]</strong>，这个函数会<strong>调用<code>dataset.__getitem__()</code>方法获取具体的数据</strong>，所以<code>__getitem__()</code>方法是我们必须实现的。我们拿到的<code>data</code>是一个
list，每个元素是一个 tuple，<strong>每个 tuple
包括样本和标签</strong>。所以最后要使用<code>self.collate_fn(data)</code>把
data 转换为两个 list，<strong>第一个 元素 是样本的 batch 形式，形状为
[16, 3, 32, 32] (16 是 batch size，[3, 32, 32]
是图片像素)；第二个元素是标签的 batch 形式，形状为 [16]。</strong></p>
<p>所以在代码中，我们使用<code>inputs, labels = data</code>来接收数据。</p>
<h4><span id="pytorch单进程数据读取流程图">==PyTorch
单进程数据读取流程图==</span></h4>
<figure>
<img src="https://pic2.zhimg.com/80/v2-7604c8f5e0df531b9127d81736b1da91_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="15_multiprocessingdataloaderiterself多进程">==1.5
_MultiProcessingDataLoaderIter(self)多进程==</span></h4>
<blockquote>
<p>[源码解析] PyTorch 分布式(2) ---
数据加载之DataLoader:https://www.cnblogs.com/rossiXYZ/p/15150504.html</p>
</blockquote>
<p>总体逻辑如下：</p>
<ul>
<li>主进程把需要获取的数据 index 放入index_queue。</li>
<li>子进程从 index_queue 之中读取
index，进行数据读取，然后把读取数据的index放入worker_result_queue。</li>
<li>主进程的 pin_memory_thread 会从 worker_result_queue
读取数据index，依据这个index进行读取数据，进行处理，把结果放入
data_queue。</li>
</ul>
<figure>
<img src="https://img2020.cnblogs.com/blog/1850883/202108/1850883-20210811215147352-1780778189.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（8）模型构建-池化-线性-激活</title>
    <url>/posts/26PZZ5C/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记池化层-线性层和激活函数层">[PyTorch 学习笔记]
池化层、线性层和激活函数层</span></h2>
<h3><span id="一-池化层"><strong>一、池化层</strong></span></h3>
<p><strong>池化的作用则体现在降采样：保留显著特征、降低特征维度，增大
kernel 的感受野</strong>。 另外一点值得注意：pooling
也可以提供一些<strong>旋转不变性</strong>。
池化层可对提取到的特征信息进行降维，一方面使特征图变小，简化网络计算复杂度并在一定程度上避免过拟合的出现；一方面进行<strong>特征压缩</strong>，提取<strong>主要特征</strong>。</p>
<h4><span id="11-nnmaxpool2d-最大池化">1.1 nn.MaxPool2d() 最大池化</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.MaxPool2d(kernel_size, stride=<span class="literal">None</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, return_indices=<span class="literal">False</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">maxpool_layer = nn.MaxPool2d((<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">2</span>)) </span><br><span class="line"><span class="comment"># input:(i, o, size) weights:(o, i , h, w)</span></span><br></pre></td></tr></table></figure>
<p>这个函数的功能是进行 2 维的最大池化，主要参数如下：</p>
<ul>
<li><strong>kernel_size</strong>：池化核尺寸</li>
<li><strong>stride</strong>：步长，通常与 kernel_size 一致</li>
<li><strong>padding</strong>：填充宽度，主要是为了调整输出的特征图大小，一般把
padding 设置合适的值后，保持输入和输出的图像尺寸不变。</li>
<li>dilation：池化间隔大小，默认为
1。常用于图像分割任务中，主要是为了提升感受野</li>
<li>ceil_mode：默认为 False，尺寸向下取整。为 True 时，尺寸向上取整</li>
<li>return_indices：为 True
时，返回最大池化所使用的像素的索引，这些记录的索引通常在反最大池化时使用，把小的特征图反池化到大的特征图时，每一个像素放在哪个位置。</li>
</ul>
<h5><span id="下图-a表示反池化b-表示上采样c-表示反卷积">下图 (a)
表示反池化，(b) 表示上采样，(c) 表示反卷积。</span></h5>
<p><img src="https://pic2.zhimg.com/80/v2-cfb9340c4d4b0406d61271ffce30ff6d_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h3><span id="12-nnavgpool2d-平均池化">1.2 nn.AvgPool2d() 平均池化</span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.nn.AvgPool2d(kernel_size, stride=<span class="literal">None</span>, padding=<span class="number">0</span>, ceil_mode=<span class="literal">False</span>, count_include_pad=<span class="literal">True</span>, divisor_override=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>这个函数的功能是进行 2 维的平均池化，主要参数如下：</p>
<ul>
<li><strong>kernel_size</strong>：池化核尺寸</li>
<li><strong>stride</strong>：步长，通常与 kernel_size 一致</li>
<li><strong>padding</strong>：填充宽度，主要是为了调整输出的特征图大小，一般把
padding 设置合适的值后，保持输入和输出的图像尺寸不变。</li>
<li>dilation：池化间隔大小，默认为
1。常用于图像分割任务中，主要是为了提升感受野</li>
<li>ceil_mode：默认为 False，尺寸向下取整。为 True 时，尺寸向上取整</li>
<li>count_include_pad：在计算平均值时，是否把填充值考虑在内计算</li>
<li>divisor_override：除法因子。在计算平均值时，分子是像素值的总和，分母默认是像素值的个数。如果设置了
divisor_override，把分母改为 divisor_override。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img_tensor = torch.ones((<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">avgpool_layer = nn.AvgPool2d((<span class="number">2</span>, <span class="number">2</span>), stride=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">img_pool = avgpool_layer(img_tensor)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;raw_img:\n&#123;&#125;\npooling_img:\n&#123;&#125;&quot;</span>.<span class="built_in">format</span>(img_tensor, img_pool))</span><br></pre></td></tr></table></figure>
<h4><span id="13-nnmaxunpool2d最大值反池化">1.3 nn.MaxUnpool2d()
最大值反池化</span></h4>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">nn.MaxUnpool2d(kernel_size, stride=None, padding=0)</span><br></pre></td></tr></table></figure>
<p>功能是对二维信号（图像）进行最大值反池化，主要参数如下：</p>
<ul>
<li>kernel_size：池化核尺寸</li>
<li>stride：步长，通常与 kernel_size 一致</li>
<li>padding：填充宽度</li>
</ul>
<h3><span id="二-线性层">二、 <strong>线性层</strong></span></h3>
<p>线性层又称为全连接层，其每个神经元与上一个层所有神经元相连，实现对前一层的线性组合或线性变换。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">1.</span>, <span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">linear_layer = nn.Linear(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">linear_layer.weight.data = torch.tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">[<span class="number">2.</span>, <span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">[<span class="number">3.</span>, <span class="number">3.</span>, <span class="number">3.</span>],</span><br><span class="line">[<span class="number">4.</span>, <span class="number">4.</span>, <span class="number">4.</span>]])</span><br><span class="line"></span><br><span class="line">linear_layer.bias.data.fill_(<span class="number">0.5</span>)</span><br><span class="line">output = linear_layer(inputs)</span><br><span class="line"><span class="built_in">print</span>(inputs, inputs.shape)</span><br><span class="line"><span class="built_in">print</span>(linear_layer.weight.data, linear_layer.weight.data.shape)</span><br><span class="line"><span class="built_in">print</span>(output, output.shape)</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">tensor([[1., 2., 3.]]) torch.Size([1, 3])</span><br><span class="line">tensor([[1., 1., 1.],</span><br><span class="line">        [2., 2., 2.],</span><br><span class="line">        [3., 3., 3.],</span><br><span class="line">        [4., 4., 4.]]) torch.Size([4, 3])</span><br><span class="line">tensor([[ 6.5000, 12.5000, 18.5000, 24.5000]], grad_fn=&lt;AddmmBackward&gt;) torch.Size([1, 4])</span><br></pre></td></tr></table></figure>
<h3><span id="三-激活函数层">三、<strong>激活函数层</strong></span></h3>
<p>假设第一个隐藏层为：<img src="https://www.zhihu.com/equation?tex=H_%7B1%7D%3DX+%5Ctimes+W_%7B1%7D" alt="[公式]">，第二个隐藏层为：<img src="https://www.zhihu.com/equation?tex=H_%7B2%7D%3DH_%7B1%7D+%5Ctimes+W_%7B2%7D" alt="[公式]">，输出层为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Ctext+%7B+Out+%7D+%5Cboldsymbol%7Bp%7D+%5Cboldsymbol%7Bu%7D+%5Cboldsymbol%7Bt%7D+%26%3D%5Cboldsymbol%7BH%7D_%7B2%7D+%2A+%5Cboldsymbol%7BW%7D_%7B3%7D+%5C%5C+%26%3D%5Cboldsymbol%7BH%7D_%7B1%7D+%2A+%5Cboldsymbol%7BW%7D_%7B2%7D+%2A+%5Cboldsymbol%7BW%7D_%7B3%7D+%5C%5C+%26%3D%5Cboldsymbol%7BX%7D+%2A+%28%5Cboldsymbol%7BW%7D_%7B1%7D+%2A%5Cboldsymbol%7BW%7D_%7B2%7D+%2A+%5Cboldsymbol%7BW%7D_%7B3%7D%29+%5C%5C+%26%3D%5Cboldsymbol%7BX%7D+%2A+%7BW%7D+%5Cend%7Baligned%7D++%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><strong>如果没有非线性变换，由于矩阵乘法的结合性，多个线性层的组合等价于一个线性层。激活函数对特征进行非线性变换，赋予了多层神经网络具有深度的意义。下面介绍一些激活函数层。</strong></p>
<h4><span id="31-nnsigmoid">3.1 <strong>nn.Sigmoid</strong></span></h4>
<ul>
<li><p><strong>计算公式</strong>：<img src="https://www.zhihu.com/equation?tex=y%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-x%7D%7D" alt="[公式]"></p></li>
<li><p><strong>梯度公式</strong>：<img src="https://www.zhihu.com/equation?tex=y%5E%7B%5Cprime%7D%3Dy+%2A%281-y%29" alt="[公式]"></p></li>
<li><p><strong>特性</strong>：</p></li>
<li><ul>
<li>输出值在(0,1)，符合<strong>概率</strong></li>
<li>导数范围是 [0, 0.25]，容易导致<strong>梯度消失</strong></li>
<li><strong>输出为非 0 均值，破坏数据分布</strong></li>
</ul></li>
</ul>
<p><img src="https://pic2.zhimg.com/80/v2-92f08b1ea82087c553dfec9c18d1b3a9_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<h4><span id="32-nntanh">3.2 <strong>nn.tanh</strong></span></h4>
<ul>
<li><p><strong>计算公式</strong>：<img src="https://www.zhihu.com/equation?tex=y%3D%5Cfrac%7B%5Csin+x%7D%7B%5Ccos+x%7D%3D%5Cfrac%7Be%5E%7Bx%7D-e%5E%7B-x%7D%7D%7Be%5E%7B-%7D%2Be%5E%7B-x%7D%7D%3D%5Cfrac%7B2%7D%7B1%2Be%5E%7B-2+x%7D%7D%2B1" alt="[公式]"></p></li>
<li><p><strong>梯度公式</strong>：<img src="https://www.zhihu.com/equation?tex=y%5E%7B%5Cprime%7D%3D1-y%5E%7B2%7D" alt="[公式]"></p></li>
<li><p><strong>特性</strong>：</p></li>
<li><ul>
<li>输出值在(-1, 1)，数据符合 0 均值</li>
<li>导数范围是 (0,1)，容易导致梯度消失</li>
</ul></li>
<li><p><img src="https://pic3.zhimg.com/80/v2-1187e5593fcd1c9b3f4deaeeb45d1a0e_1440w.jpg" alt="img" style="zoom: 33%;"></p></li>
</ul>
<h4><span id="33nnrelu修正线性单元">3.3
<strong>nn.ReLU(修正线性单元)</strong></span></h4>
<ul>
<li><p>计算公式：<img src="https://www.zhihu.com/equation?tex=y%3Dmax%280%2C+x%29" alt="[公式]"></p></li>
<li><p>梯度公式：<img src="https://www.zhihu.com/equation?tex=y%5E%7B%5Cprime%7D%3D%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bll%7D1%2C+%26+x%3E0+%5C%5C+u+n+d+%5Ctext+%7B+ef+ined%2C+%7D+%26+x%3D0+%5C%5C+0%2C+%26+x%3C0%5Cend%7Barray%7D%5Cright." alt="[公式]"></p></li>
<li><p>特性：</p></li>
<li><ul>
<li>输出值均为正数，负半轴的导数为
0，容易导致<strong>死神经元</strong></li>
<li>导数是 1，缓解梯度消失，但容易引发梯度爆炸</li>
</ul></li>
</ul>
<p><img src="https://pic3.zhimg.com/80/v2-aa6efbe0e0fd4900cb60d9df516986ca_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p><strong>针对 RuLU 会导致==死神经元==的缺点，出现了下面 3
种改进的激活函数。</strong></p>
<h4><span id="nnleakyrelu"><strong>nn.LeakyReLU</strong></span></h4>
<ul>
<li>有一个参数<code>negative_slope</code>：设置负半轴斜率</li>
</ul>
<h4><span id="nnprelu"><strong>nn.PReLU</strong></span></h4>
<ul>
<li>有一个参数<code>init</code>：设置初始斜率，这个斜率是可学习的</li>
</ul>
<h4><span id="nnrrelu"><strong>nn.RReLU</strong></span></h4>
<p>R 是 random 的意思，负半轴每次斜率都是随机取 [lower, upper]
之间的一个数</p>
<ul>
<li>lower：均匀分布下限</li>
<li>upper：均匀分布上限</li>
</ul>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（7）模型构建-nn</title>
    <url>/posts/1CEZTMF/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记卷积层与nnconv">[PyTorch 学习笔记]
卷积层与nn.Conv</span></h2>
<h3><span id="一-1d2d3d-卷积"><strong>一、1D/2D/3D 卷积</strong></span></h3>
<p>卷积有一维卷积、二维卷积、三维卷积。一般情况下，卷积核在几个维度上滑动，就是几维卷积。比如在图片上的卷积就是二维卷积。</p>
<h4><span id="一维卷积"><strong>一维卷积</strong>：</span></h4>
<p><img src="https://pic3.zhimg.com/v2-00ab31bd2533a6368ea01a09d2f3c0d6_b.webp" alt="img" style="zoom:50%;"></p>
<h4><span id="二维卷积"><strong>二维卷积</strong>：</span></h4>
<p><img src="https://pic4.zhimg.com/v2-15fea61b768f7561648dbea164fcb75f_b.webp" alt="img" style="zoom:50%;"></p>
<h4><span id="三维卷积"><strong>三维卷积</strong>：</span></h4>
<p><img src="https://pic2.zhimg.com/v2-0083d388fd6739d22ac67d35940a9025_b.webp" alt="img" style="zoom:50%;"></p>
<h3><span id="二-nnconv2d二维卷积"><strong>二、nn.Conv2d()
二维卷积</strong></span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.Conv2d(self, in_channels, out_channels, kernel_size, stride=<span class="number">1</span>,</span><br><span class="line">                 padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>,</span><br><span class="line">                 bias=<span class="literal">True</span>, padding_mode=<span class="string">&#x27;zeros&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这个函数的功能是对多个二维信号进行二维卷积，主要参数如下：</p>
<ul>
<li><strong>in_channels</strong>：<strong>输入通道数</strong></li>
<li><strong>out_channels</strong>：<strong>输出通道数，等价于卷积核个数</strong></li>
<li><strong>kernel_size</strong>：<strong>卷积核尺寸</strong></li>
<li><strong>stride</strong>：<strong>步长</strong></li>
<li><strong>padding</strong>：填充宽度，主要是为了调整输出的特征图大小，一般把
padding 设置合适的值后，保持输入和输出的图像尺寸不变。</li>
<li>dilation：空洞卷积大小，默认为
1，这时是标准卷积，常用于图像分割任务中，主要是为了提升感受野</li>
<li>groups：分组卷积设置，主要是为了模型的轻量化，如在
ShuffleNet、MobileNet、SqueezeNet 中用到</li>
<li>bias：偏置</li>
</ul>
<h4><span id="21卷积尺寸计算简化版"><strong>2.1
卷积尺寸计算（简化版）</strong></span></h4>
<p>这里不考虑空洞卷积，假设输入图片大小为 <img src="https://www.zhihu.com/equation?tex=+I+%5Ctimes+I" alt="[公式]">，卷积核大小为 <img src="https://www.zhihu.com/equation?tex=k+%5Ctimes+k" alt="[公式]">，stride 为 <img src="https://www.zhihu.com/equation?tex=s" alt="[公式]">，padding
的像素数为 <img src="https://www.zhihu.com/equation?tex=p" alt="[公式]">，图片经过卷积之后的尺寸 <img src="https://www.zhihu.com/equation?tex=+O+" alt="[公式]"> 如下：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=O+%3D+%5Cdisplaystyle%5Cfrac%7BI+-k+%2B+2+%5Ctimes+p%7D%7Bs%7D+%2B1" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>下面例子的输入图片大小为 <img src="https://www.zhihu.com/equation?tex=5+%5Ctimes+5" alt="[公式]">，卷积大小为 <img src="https://www.zhihu.com/equation?tex=3+%5Ctimes+3" alt="[公式]">，stride 为 1，padding 为 0，所以输出图片大小为 <img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle%5Cfrac%7B5+-3+%2B+2+%5Ctimes+0%7D%7B1%7D+%2B1+%3D+3" alt="[公式]">。</p>
<h4><span id="22-卷积网络示例"><strong>2.2 卷积网络示例</strong></span></h4>
<p>这里使用 input * channel 为 3，output_channel 为 1 ，卷积核大小为
<img src="https://www.zhihu.com/equation?tex=3+%5Ctimes+3" alt="[公式]"> 的卷积核 <strong>nn.Conv2d(3, 1, 3)</strong>，使用
<strong>nn.init.xavier_normal_()</strong>
方法初始化网络的权值。代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv_layer = nn.Conv2d(<span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>)   </span><br><span class="line"><span class="comment"># 初始化卷积层权值</span></span><br><span class="line">nn.init.xavier_normal_(conv_layer.weight.data)</span><br><span class="line">img_conv = conv_layer(img_tensor)</span><br></pre></td></tr></table></figure>
<p>我们通过<code>conv_layer.weight.shape</code>查看卷积核的 shape
是<code>(1, 3, 3, 3)</code>，对应是<code>(output_channel, input_channel, kernel_size, kernel_size)</code>。所以第一个维度对应的是<strong>卷积核的个数</strong>，每个卷积核都是<code>(3,3,3)</code>。虽然每个卷积核都是
3 维的，执行的却是 2 维卷积。下面这个图展示了这个过程。</p>
<p><img src="https://pic4.zhimg.com/80/v2-b34951f3454a10c6a9eb343f3822aee3_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>也就是每个卷积核在 input_channel 维度再划分，这里 input_channel 为
3，那么这时每个卷积核的 shape 是<code>(3, 3)</code>。<strong>3
个卷积核在输入图像的每个 channel 上卷积后得到 3 个数，把这 3
个数相加，再加上 bias</strong>，得到最后的一个输出。</p>
<p><img src="https://pic3.zhimg.com/80/v2-bcf2370e45db4607f99b6af57f1974fa_1440w.jpg" alt="img" style="zoom:67%;"></p>
<h3><span id="三-nnconvtranspose转置卷积">三、nn.ConvTranspose()
转置卷积</span></h3>
<h4><span id="31-转置卷积原理">3.1 转置卷积原理</span></h4>
<p>转置卷积又称为反卷积 (Deconvolution) 和部分跨越卷积 (Fractionally
strided Convolution)，用于对图像进行<strong>上采样</strong>。</p>
<p><strong>正常卷积如下：</strong></p>
<figure>
<img src="https://pic3.zhimg.com/v2-705305fee5a050575544c64067405fce_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>原始的图片尺寸为 <img src="https://www.zhihu.com/equation?tex=4+%5Ctimes+4" alt="[公式]">，卷积核大小为 <img src="https://www.zhihu.com/equation?tex=3+%5Ctimes+3" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=padding+%3D0" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=stride+%3D+1" alt="[公式]">。由于卷积操作可以通过矩阵运算来解决，因此原始图片可以看作
<img src="https://www.zhihu.com/equation?tex=16+%5Ctimes+1" alt="[公式]"> 的矩阵 <img src="https://www.zhihu.com/equation?tex=I_%7B16+%5Ctimes+1%7D" alt="[公式]">，卷积核可以看作 <img src="https://www.zhihu.com/equation?tex=4+%5Ctimes+16" alt="[公式]">
的矩阵 <img src="https://www.zhihu.com/equation?tex=K_%7B4+%5Ctimes+16%7D" alt="[公式]">，那么输出是 <img src="https://www.zhihu.com/equation?tex=K_%7B4+%5Ctimes+16%7D+%5Ctimes+I_%7B16+%5Ctimes+1%7D+%3D+O_%7B4+%5Ctimes+1%7D" alt="[公式]"> 。</p>
<p><strong>转置卷积如下：</strong></p>
<p><img src="https://pic4.zhimg.com/v2-286ac2cfb69abf4d8aa06b8eeb39ced3_b.jpg" alt="img" style="zoom: 67%;"></p>
<p>原始的<strong>图片尺寸</strong>为 <img src="https://www.zhihu.com/equation?tex=2+%5Ctimes+2" alt="[公式]">，<strong>卷积核大小</strong>为 <img src="https://www.zhihu.com/equation?tex=3+%5Ctimes+3" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=padding+%3D0" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=stride+%3D+1" alt="[公式]">。由于卷积操作可以通过矩阵运算来解决，因此原始图片可以看作
<img src="https://www.zhihu.com/equation?tex=4+%5Ctimes+1" alt="[公式]"> 的矩阵 <img src="https://www.zhihu.com/equation?tex=I_%7B4+%5Ctimes+1%7D" alt="[公式]">，卷积核可以看作 <img src="https://www.zhihu.com/equation?tex=4+%5Ctimes+16" alt="[公式]">
的矩阵 <img src="https://www.zhihu.com/equation?tex=K_%7B16+%5Ctimes+4%7D" alt="[公式]">，那么输出是 <img src="https://www.zhihu.com/equation?tex=K_%7B16+%5Ctimes+4%7D+%5Ctimes+I_%7B4+%5Ctimes+1%7D+%3D+O_%7B16+%5Ctimes+1%7D" alt="[公式]"> 。</p>
<p>正常卷积核转置卷积矩阵的形状刚好是转置关系，因此称为转置卷积，但里面的权值不是一样的，<strong>卷积操作也是不可逆的</strong>。</p>
<p>PyTorch 中的转置卷积函数如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nn.ConvTranspose2d(self, in_channels, out_channels, kernel_size, stride=<span class="number">1</span>,</span><br><span class="line">                 padding=<span class="number">0</span>, output_padding=<span class="number">0</span>, groups=<span class="number">1</span>, bias=<span class="literal">True</span>,</span><br><span class="line">                 dilation=<span class="number">1</span>, padding_mode=<span class="string">&#x27;zeros&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>和普通卷积的参数基本相同，不再赘述。</p>
<h4><span id="32-转置卷积尺寸计算">3.2 <strong>转置卷积尺寸计算</strong></span></h4>
<h5><span id="简化版转置卷积尺寸计算"><strong>简化版转置卷积尺寸计算</strong></span></h5>
<p>这里不考虑空洞卷积，假设输入图片大小为 <img src="https://www.zhihu.com/equation?tex=+I+%5Ctimes+I" alt="[公式]">，卷积核大小为 <img src="https://www.zhihu.com/equation?tex=k+%5Ctimes+k" alt="[公式]">，stride 为 <img src="https://www.zhihu.com/equation?tex=s" alt="[公式]">，padding
的像素数为 <img src="https://www.zhihu.com/equation?tex=p" alt="[公式]">，图片经过卷积之后的尺寸 <img src="https://www.zhihu.com/equation?tex=+O+" alt="[公式]">
如下，刚好和普通卷积的计算是相反的：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=O+%3D+%28I-1%29+%5Ctimes+s+%2B+k" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>转置卷积代码示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> common_tools <span class="keyword">import</span> transform_invert, set_seed</span><br><span class="line"></span><br><span class="line">set_seed(<span class="number">3</span>)  <span class="comment"># 设置随机种子</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># load img </span></span><br><span class="line">path_img = os.path.join(os.path.dirname(os.path.abspath(__file__)), <span class="string">&quot;imgs&quot;</span>, <span class="string">&quot;lena.png&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(path_img)</span><br><span class="line">img = Image.<span class="built_in">open</span>(path_img).convert(<span class="string">&#x27;RGB&#x27;</span>)  <span class="comment"># 0~255</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># convert to tensor</span></span><br><span class="line">img_transform = transforms.Compose([transforms.ToTensor()])</span><br><span class="line">img_tensor = img_transform(img)</span><br><span class="line"><span class="comment"># 添加 batch 维度</span></span><br><span class="line">img_tensor.unsqueeze_(dim=<span class="number">0</span>)    <span class="comment"># C*H*W to B*C*H*W</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create convolution layer </span></span><br><span class="line"><span class="comment"># flag = 1</span></span><br><span class="line">flag = <span class="number">0</span></span><br><span class="line"><span class="keyword">if</span> flag:</span><br><span class="line">    conv_layer = nn.Conv2d(<span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>)   <span class="comment"># input:(i, o, size) weights:(o, i , h, w)</span></span><br><span class="line">    <span class="comment"># 初始化卷积层权值</span></span><br><span class="line">    nn.init.xavier_normal_(conv_layer.weight.data)</span><br><span class="line">    <span class="comment"># nn.init.xavier_uniform_(conv_layer.weight.data)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculation</span></span><br><span class="line">    img_conv = conv_layer(img_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment">#  transposed</span></span><br><span class="line">flag = <span class="number">1</span></span><br><span class="line"><span class="comment"># flag = 0</span></span><br><span class="line"><span class="keyword">if</span> flag:</span><br><span class="line">    conv_layer = nn.ConvTranspose2d(<span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>, stride=<span class="number">2</span>)   <span class="comment"># input:(input_channel, output_channel, size)</span></span><br><span class="line">    <span class="comment"># 初始化网络层的权值</span></span><br><span class="line">    nn.init.xavier_normal_(conv_layer.weight.data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculation</span></span><br><span class="line">    img_conv = conv_layer(img_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================================= visualization ==================================</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;卷积前尺寸:&#123;&#125;\n卷积后尺寸:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(img_tensor.shape, img_conv.shape))</span><br><span class="line">img_conv = transform_invert(img_conv[<span class="number">0</span>, <span class="number">0</span>:<span class="number">1</span>, ...], img_transform)</span><br><span class="line">img_raw = transform_invert(img_tensor.squeeze(), img_transform)</span><br><span class="line">plt.subplot(<span class="number">122</span>).imshow(img_conv, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">121</span>).imshow(img_raw)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>转置卷积前后图片显示如下，左边原图片的尺寸是 (512,
512)，右边转置卷积后的图片尺寸是 (1025, 1025)。</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-3dd1bd7f3e487b1837b51bed00ebf546_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>转置卷积后的图片一般都会有棋盘效应，像一格一格的棋盘，这是转置卷积的通病。</p>
<p>关于棋盘效应的解释以及解决方法，推荐阅读<strong>Deconvolution And
Checkerboard Artifacts[1]</strong>。</p>
<h4><span id="33-dcgan">3.3 DCGAN</span></h4>
<ul>
<li><strong>生成器</strong>
<ul>
<li>nz = 100 : 潜在向量 z 的大小</li>
<li>ngf = 64 : 生成器中特征图的大小</li>
<li>ndf = 64 : 判别器中的特征映射的大小</li>
</ul></li>
</ul>
<figure>
<img src="https://pytorch.org/tutorials/_images/dcgan_generator.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成器代码</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ngpu</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.ngpu = ngpu</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># 输入是Z，进入卷积</span></span><br><span class="line">            nn.ConvTranspose2d(nz, ngf * <span class="number">8</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">8</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ngf*8) x 4 x 4</span></span><br><span class="line">            nn.ConvTranspose2d(ngf * <span class="number">8</span>, ngf * <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">4</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ngf*4) x 8 x 8</span></span><br><span class="line">            nn.ConvTranspose2d( ngf * <span class="number">4</span>, ngf * <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf * <span class="number">2</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ngf*2) x 16 x 16</span></span><br><span class="line">            nn.ConvTranspose2d( ngf * <span class="number">2</span>, ngf, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ngf),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ngf) x 32 x 32</span></span><br><span class="line">            nn.ConvTranspose2d( ngf, nc, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Tanh()</span><br><span class="line">            <span class="comment"># state size. (nc) x 64 x 64</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="keyword">return</span> self.main(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>判别器代码</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ngpu</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.ngpu = ngpu</span><br><span class="line">        self.main = nn.Sequential(</span><br><span class="line">            <span class="comment"># input is (nc) x 64 x 64</span></span><br><span class="line">            nn.Conv2d(nc, ndf, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ndf) x 32 x 32</span></span><br><span class="line">            nn.Conv2d(ndf, ndf * <span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">2</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ndf*2) x 16 x 16</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">2</span>, ndf * <span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">4</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ndf*4) x 8 x 8</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">4</span>, ndf * <span class="number">8</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(ndf * <span class="number">8</span>),</span><br><span class="line">            nn.LeakyReLU(<span class="number">0.2</span>, inplace=<span class="literal">True</span>),</span><br><span class="line">            <span class="comment"># state size. (ndf*8) x 4 x 4</span></span><br><span class="line">            nn.Conv2d(ndf * <span class="number">8</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="keyword">return</span> self.main(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>
<h3><span id="三-卷积参数更新">三、卷积参数更新</span></h3>
<p><img src="https://pic1.zhimg.com/80/v2-f73cc6d82689ff3239cd7954913eb81b_1440w.jpg" alt="img"></p>
<p>与全连接<a href="https://so.csdn.net/so/search?q=神经网络&amp;spm=1001.2101.3001.7020">神经网络</a>不同，卷积神经网络每一层中的节点并不是与前一层的所有神经元节点相连，而是只与前一层的部分节点相连。并且和每一个节点相连的那些通路的权重都是相同的。举例来说，<strong>对于二维卷积神经网络，其权重就是卷积核里面的那些值，这些值从上而下，从左到右要将图像中每个对应区域卷积一遍然后将积求和输入到下一层节点中激活，得到下一层的特征图</strong>。因此其权重和偏置更新公式与全连接神经网络不通。</p>
<ul>
<li>降低的计算量</li>
<li>权重得到共享，降低了参数量</li>
</ul>
<p>根据《Deep learning》这本书的描述，<a href="https://so.csdn.net/so/search?q=卷积神经网络&amp;spm=1001.2101.3001.7020">卷积神经网络</a>有3个核心思想：</p>
<ul>
<li><strong>稀疏交互</strong>（sparse
interactions），即每个节点通过固定个（一般等于卷积核元素的数目，远小于前一层节点数）连接与下一层的神经元节点相连;
尽管是稀疏连接，但是在更深层的神经单元中，其可以间接地连接到全部或大部分输入图像。如果采用了步幅卷积或者池化操作，那么这种间接连接全部图像的可能性将会增加。</li>
<li><strong>参数共享</strong>（parameter
sharing），以2D卷积为例，每一层都通过固定的卷积核产生下一层的特征图，而这个卷积核将从上到下、从左到右遍历图像每一个对应区域；</li>
<li><strong>等变表示</strong>（equivariant
representations），卷积和参数共享的形式使得神经网络具有平移等变形，即f(g(x))=g(f(x))。另外，pooling操作也可以使网络具有局部平移不变形。局部平移不变形是一个很有用的性质，尤其是当我们只关心某个特征是否出现而不关心它出现的具体位置时。池化可以看作增加了一个无线强的先验，这一层学的函数必须具有对少量平移的不变形。</li>
</ul>
<h4><span id="31-正向传播">3.1 正向传播</span></h4>
<h4><span id="如何对卷积核数量和卷积步长进行选择">如何对卷积核数量和卷积步长进行选择?</span></h4>
<ul>
<li>卷积核的数量越多，意味着提取的特征种类越多，通常会取2^n个;</li>
<li>步长通常不会超过卷积核宽度或长度，步长大于1的时候有下采样的效果，比如步长为2时，可以让feature
map的尺寸缩小一半。</li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch（9）模型训练-权重初始化</title>
    <url>/posts/2VVSRFN/</url>
    <content><![CDATA[<h2><span id="pytorch-学习笔记-权值初始化">[PyTorch 学习笔记] 权值初始化</span></h2>
<p><strong>在搭建好网络模型之后，一个重要的步骤就是对网络模型中的权值进行初始化</strong>。<strong>==适当的权值初始化可以加快模型的收敛，而不恰当的权值初始化可能引发梯度消失或者梯度爆炸，最终导致模型无法收敛==</strong>。下面分
3
部分介绍。第一部分介绍不恰当的权值初始化是如何引发梯度消失与梯度爆炸的，第二部分介绍常用的
Xavier 方法与 Kaiming 方法，第三部分介绍 PyTorch 中的 10
种初始化方法。</p>
<h3><span id="一-梯度消失与梯度爆炸">一、<strong>梯度消失与梯度爆炸</strong></span></h3>
<p>考虑一个 3 层的全连接网络。</p>
<p><img src="https://www.zhihu.com/equation?tex=H_%7B1%7D%3DX+%5Ctimes+W_%7B1%7D" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=H_%7B2%7D%3DH_%7B1%7D+%5Ctimes+W_%7B2%7D" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=Out%3DH_%7B2%7D+%5Ctimes+W_%7B3%7D" alt="[公式]"></p>
<p><img src="https://pic3.zhimg.com/80/v2-bd64028adc3d3efd6e7df4ebdfc5b51a_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>其中第 2 层的权重梯度如下：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5CDelta+%5Cmathrm%7BW%7D_%7B2%7D+%26%3D%5Cfrac%7B%5Cpartial+%5Cmathrm%7BLoss%7D%7D%7B%5Cpartial+%5Cmathrm%7BW%7D_%7B2%7D%7D%3D%5Cfrac%7B%5Cpartial+%5Cmathrm%7BLoss%7D%7D%7B%5Cpartial+%5Cmathrm%7Bout%7D%7D+%2A+%5Cfrac%7B%5Cpartial+%5Cmathrm%7Bout%7D%7D%7B%5Cpartial+%5Cmathrm%7BH%7D_%7B2%7D%7D+%2A+%5Cfrac%7B%5Cpartial+%5Cmathrm%7BH%7D_%7B2%7D%7D%7B%5Cpartial+%5Cmathrm%7Bw%7D_%7B2%7D%7D+%5C%5C+%26%3D%5Cfrac%7B%5Cpartial+%5Cmathrm%7BLoss%7D%7D%7B%5Cpartial+%5Cmathrm%7Bout%7D%7D+%2A+%5Cfrac%7B%5Cpartial+%5Cmathrm%7Bout%7D%7D%7B%5Cpartial+%5Cmathrm%7BH%7D_%7B2%7D%7D+%2A+%5Cmathrm%7BH%7D_%7B1%7D+%5Cend%7Baligned%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>所以 <img src="https://www.zhihu.com/equation?tex=%5CDelta+%5Cmathrm%7BW%7D_%7B2%7D" alt="[公式]"> 依赖于前一层的输出 <img src="https://www.zhihu.com/equation?tex=H_%7B1%7D" alt="[公式]">。如果
<img src="https://www.zhihu.com/equation?tex=H_%7B1%7D" alt="[公式]">
趋近于零，那么 <img src="https://www.zhihu.com/equation?tex=%5CDelta+%5Cmathrm%7BW%7D_%7B2%7D" alt="[公式]"> 也<strong>接近于 0，造成梯度消失</strong>。如果 <img src="https://www.zhihu.com/equation?tex=H_%7B1%7D" alt="[公式]">
趋近于无穷大，那么 <img src="https://www.zhihu.com/equation?tex=%5CDelta+%5Cmathrm%7BW%7D_%7B2%7D" alt="[公式]">
也接近于<strong>无穷大，造成梯度爆炸</strong>。要避免梯度爆炸或者梯度消失，就要严格控制网络层输出的数值范围。</p>
<p>下面构建 100
层全连接网络，先不使用非线性激活函数，每层的权重初始化为服从 <img src="https://www.zhihu.com/equation?tex=N%280%2C1%29" alt="[公式]">
的正态分布，输出数据使用随机初始化的数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> common_tools <span class="keyword">import</span> set_seed</span><br><span class="line"></span><br><span class="line">set_seed(<span class="number">1</span>)  <span class="comment"># 设置随机种子</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, neural_num, layers</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line">        self.linears = nn.ModuleList([nn.Linear(neural_num, neural_num, bias=<span class="literal">False</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(layers)])</span><br><span class="line">        self.neural_num = neural_num</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">for</span> (i, linear) <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.linears):</span><br><span class="line">            x = linear(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">   </span><br><span class="line">		<span class="keyword">def</span> <span class="title function_">forward_new</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">for</span> (i, linear) <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.linears):</span><br><span class="line">            x = linear(x)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;layer:&#123;&#125;, std:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, x.std()))</span><br><span class="line">            <span class="keyword">if</span> torch.isnan(x.std()):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;output is nan in &#123;&#125; layers&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">initialize</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="comment"># 判断这一层是否为线性层，如果为线性层则初始化权值</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight.data)    <span class="comment"># normal: mean=0, std=1</span></span><br><span class="line"></span><br><span class="line">layer_nums = <span class="number">100</span></span><br><span class="line">neural_nums = <span class="number">256</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">net = MLP(neural_nums, layer_nums)</span><br><span class="line">net.initialize()</span><br><span class="line"></span><br><span class="line">inputs = torch.randn((batch_size, neural_nums))  <span class="comment"># normal: mean=0, std=1</span></span><br><span class="line">output = net(inputs)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">tensor([[nan, nan, nan,  ..., nan, nan, nan],</span><br><span class="line">        [nan, nan, nan,  ..., nan, nan, nan],</span><br><span class="line">        [nan, nan, nan,  ..., nan, nan, nan],</span><br><span class="line">        ...,</span><br><span class="line">        [nan, nan, nan,  ..., nan, nan, nan],</span><br><span class="line">        [nan, nan, nan,  ..., nan, nan, nan],</span><br><span class="line">        [nan, nan, nan,  ..., nan, nan, nan]], grad_fn=&lt;MmBackward&gt;)</span><br></pre></td></tr></table></figure>
<p>也就是<strong>==数据太大(梯度爆炸)或者太小(梯度消失)==</strong>了。接下来我们在<code>forward()</code>函数中判断每一次前向传播的输出的标准差是否为
nan，如果是 nan 则停止前向传播。</p>
<p>以输入层第一个神经元为例：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BH%7D_%7B11%7D%3D%5Csum_%7Bi%3D0%7D%5E%7Bn%7D+X_%7Bi%7D+%5Ctimes+W_%7B1+i%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中输入 X 和权值 W 都是服从 <img src="https://www.zhihu.com/equation?tex=N%280%2C1%29" alt="[公式]">
的正态分布，所以这个神经元的方差为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Cmathbf%7BD%7D%5Cleft%28%5Cmathrm%7BH%7D_%7B11%7D%5Cright%29+%26%3D%5Csum_%7Bi%3D0%7D%5E%7Bn%7D+%5Cboldsymbol%7BD%7D%5Cleft%28X_%7Bi%7D%5Cright%29+%2A+%5Cboldsymbol%7BD%7D%5Cleft%28W_%7B1+i%7D%5Cright%29+%5C%5C+%26%3Dn+%2A%281+%2A+1%29+%5C%5C+%26%3Dn+%5Cend%7Baligned%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<blockquote>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=E%28X+%5Ctimes+Y%29%3DE%28X%29+%5Ctimes+E%28Y%29" alt="[公式]">：两个相互独立的随机变量的乘积的期望等于它们的期望的乘积</li>
<li><img src="https://www.zhihu.com/equation?tex=D%28X%29%3DE%28X%5E%7B2%7D%29+-+%5BE%28X%29%5D%5E%7B2%7D" alt="[公式]">：一个随机变量的方差等于它的平方的期望减去期望的平方</li>
<li><img src="https://www.zhihu.com/equation?tex=D%28X%2BY%29%3DD%28X%29%2BD%28Y%29" alt="[公式]">：两个相互独立的随机变量之和的方差等于它们的方差的和</li>
</ul>
<p>可以推导出两个随机变量的乘积的方差如下：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=D%28X+%5Ctimes+Y%29%3DE%5B%28XY%29%5E%7B2%7D%5D+-+%5BE%28XY%29%5D%5E%7B2%7D%3DD%28X%29+%5Ctimes+D%28Y%29+%2B+D%28X%29+%5Ctimes+%5BE%28Y%29%5D%5E%7B2%7D+%2B+D%28Y%29+%5Ctimes+%5BE%28X%29%5D%5E%7B2%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>如果 <img src="https://www.zhihu.com/equation?tex=E%28X%29%3D0" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=E%28Y%29%3D0" alt="[公式]">，那么 <img src="https://www.zhihu.com/equation?tex=D%28X+%5Ctimes+Y%29%3DD%28X%29+%5Ctimes++D%28Y%29" alt="[公式]"></p>
</blockquote>
<p><strong>标准差</strong>为：<img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bstd%7D%5Cleft%28%5Cmathrm%7BH%7D_%7B11%7D%5Cright%29%3D%5Csqrt%7B%5Cmathbf%7BD%7D%5Cleft%28%5Cmathrm%7BH%7D_%7B11%7D%5Cright%29%7D%3D%5Csqrt%7Bn%7D" alt="[公式]">，所以每经过一个网络层，方差就会扩大 n 倍，标准差就会扩大
<img src="https://www.zhihu.com/equation?tex=%5Csqrt%7Bn%7D" alt="[公式]"> 倍，n
为每层神经元个数，直到超出数值表示范围。对比上面的代码可以看到，每层神经元个数为
256，输出数据的标准差为 1，所以第一个网络层输出的标准差为 16
左右，第二个网络层输出的标准差为 256 左右，以此类推，直到 31
层超出数据表示范围。可以把每层神经元个数改为 400，那么每层标准差扩大 20
倍左右。从 <img src="https://www.zhihu.com/equation?tex=D%28%5Cmathrm%7BH%7D_%7B11%7D%29%3D%5Csum_%7Bi%3D0%7D%5E%7Bn%7D+D%28X_%7Bi%7D%29+%5Ctimes+D%28W_%7B1+i%7D%29" alt="[公式]">，可以看出，<strong>每一层网络输出的方差与神经元个数、输入数据的方差、权值方差有关，其中比较好改变的是权值的方差
<img src="https://www.zhihu.com/equation?tex=D%28W%29" alt="[公式]">，所以 <img src="https://www.zhihu.com/equation?tex=D%28W%29%3D+%5Cfrac%7B1%7D%7Bn%7D" alt="[公式]">，标准差为</strong> <img src="https://www.zhihu.com/equation?tex=std%28W%29%3D%5Csqrt%5Cfrac%7B1%7D%7Bn%7D" alt="[公式]">。</p>
<p>因此修改权值初始化代码为<code>nn.init.normal_(m.weight.data, std=np.sqrt(1/self.neural_num))</code></p>
<p>上述是没有使用非线性变换的实验结果，如果在<code>forward()</code>中添加非线性变换<code>tanh</code>，每一层的输出方差还是会越来越小，会导致梯度消失。因此出现了
Xavier 初始化方法与 Kaiming 初始化方法。</p>
<h3><span id="二-xavier-方法与-kaiming方法">二、<strong>Xavier 方法与 Kaiming
方法</strong></span></h3>
<h4><span id="21-xavier-方法-sigmod-tanh">2.1 Xavier 方法 sigmod、tanh</span></h4>
<p>Xavier 是 2010
年提出的，针对有非线性激活函数时的权值初始化方法，目标是保持数据的方差维持在
1 左右，主要针对饱和激活函数如 sigmoid 和 tanh
等。同时考虑前向传播和反向传播，需要满足两个等式：<img src="https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bn%7D_%7B%5Cboldsymbol%7Bi%7D%7D+%2A+%5Cboldsymbol%7BD%7D%28%5Cboldsymbol%7BW%7D%29%3D%5Cmathbf%7B1%7D" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bn%7D_%7B%5Cboldsymbol%7Bi%2B1%7D%7D+%2A+%5Cboldsymbol%7BD%7D%28%5Cboldsymbol%7BW%7D%29%3D%5Cmathbf%7B1%7D" alt="[公式]">，可得：<img src="https://www.zhihu.com/equation?tex=D%28W%29%3D%5Cfrac%7B2%7D%7Bn_%7Bi%7D%2Bn_%7Bi%2B1%7D%7D" alt="[公式]">。为了使 Xavier 方法初始化的权值服从均匀分布，假设 <img src="https://www.zhihu.com/equation?tex=W" alt="[公式]"> 服从均匀分布
<img src="https://www.zhihu.com/equation?tex=U%5B-a%2C+a%5D" alt="[公式]">，那么方差 <img src="https://www.zhihu.com/equation?tex=D%28W%29%3D%5Cfrac%7B%28-a-a%29%5E%7B2%7D%7D%7B12%7D%3D%5Cfrac%7B%282+a%29%5E%7B2%7D%7D%7B12%7D%3D%5Cfrac%7Ba%5E%7B2%7D%7D%7B3%7D" alt="[公式]">，令 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B2%7D%7Bn_%7Bi%7D%2Bn_%7Bi%2B1%7D%7D%3D%5Cfrac%7Ba%5E%7B2%7D%7D%7B3%7D" alt="[公式]">，解得：<img src="https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Ba%7D%3D%5Cfrac%7B%5Csqrt%7B6%7D%7D%7B%5Csqrt%7Bn_%7Bi%7D%2Bn_%7Bi%2B1%7D%7D%7D" alt="[公式]">，所以 <img src="https://www.zhihu.com/equation?tex=W" alt="[公式]"> 服从分布 <img src="https://www.zhihu.com/equation?tex=U%5Cleft%5B-%5Cfrac%7B%5Csqrt%7B6%7D%7D%7B%5Csqrt%7Bn_%7Bi%7D%2Bn_%7Bi%2B1%7D%7D%7D%2C+%5Cfrac%7B%5Csqrt%7B6%7D%7D%7B%5Csqrt%7Bn_%7Bi%7D%2Bn_%7Bi%2B1%7D%7D%7D%5Cright%5D" alt="[公式]"></p>
<p>所以初始化方法改为：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">a = np.sqrt(6 / (self.neural_num + self.neural_num))</span><br><span class="line"># 把 a 变换到 tanh，计算增益</span><br><span class="line">tanh_gain = nn.init.calculate_gain(&#x27;tanh&#x27;)</span><br><span class="line">a *= tanh_gain</span><br><span class="line"></span><br><span class="line">nn.init.uniform_(m.weight.data, -a, a)</span><br></pre></td></tr></table></figure>
<p>并且每一层的激活函数都使用 tanh，输出如下：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">layer:0, std:0.7571136355400085</span><br><span class="line">layer:1, std:0.6924336552619934</span><br><span class="line">layer:2, std:0.6677976846694946</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">layer:97, std:0.6426210403442383</span><br><span class="line">layer:98, std:0.6407480835914612</span><br><span class="line">layer:99, std:0.6442216038703918</span><br></pre></td></tr></table></figure>
<p>可以看到每层输出的方差都维持在 0.6 左右。</p>
<p>PyTorch 也提供了 Xavier 初始化方法，可以直接调用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tanh_gain = nn.init.calculate_gain(<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">nn.init.xavier_uniform_(m.weight.data, gain=tanh_gain)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>#### <strong>nn.init.calculate_gain()</strong></p>
<p>上面的初始化方法都使用了<code>tanh_gain = nn.init.calculate_gain('tanh')</code>。</p>
<p><code>nn.init.calculate_gain(nonlinearity,param=**None**)</code>的<strong>==主要功能是经过一个分布的方差经过激活函数后的变化尺度==</strong>，主要有两个参数：</p>
<ul>
<li>nonlinearity：激活函数名称</li>
<li>param：激活函数的参数，如 Leaky ReLU 的 negative_slop。</li>
</ul>
<p>下面是计算标准差经过激活函数的变化尺度的代码。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.randn(<span class="number">10000</span>)</span><br><span class="line">out = torch.tanh(x)</span><br><span class="line"></span><br><span class="line">gain = x.std() / out.std()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;gain:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(gain))</span><br><span class="line"></span><br><span class="line">tanh_gain = nn.init.calculate_gain(<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;tanh_gain in PyTorch:&#x27;</span>, tanh_gain)</span><br></pre></td></tr></table></figure></p>
<p>输出如下：</p>
<p><figure class="highlight text"><table><tr><td class="code"><pre><span class="line">gain:1.5982500314712524</span><br><span class="line">tanh_gain in PyTorch: 1.6666666666666667</span><br></pre></td></tr></table></figure></p>
<p>结果表示，原有数据分布的方差经过 tanh 之后，标准差会变小 1.6
倍左右。</p>
</blockquote>
<h4><span id="22-kaiming-方法">2.2 Kaiming 方法</span></h4>
<p>虽然 Xavier 方法提出了针对饱和激活函数的权值初始化方法，但是 AlexNet
出现后，大量网络开始使用非饱和的激活函数如 ReLU 等，这时 Xavier
方法不再适用。2015 年针对 ReLU 及其变种等激活函数提出了 Kaiming
初始化方法。</p>
<p>针对 ReLU，方差应该满足：<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BD%7D%28W%29%3D%5Cfrac%7B2%7D%7Bn_%7Bi%7D%7D" alt="[公式]">；针对 ReLu 的变种，方差应该满足：<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BD%7D%28W%29%3D%5Cfrac%7B2%7D%7Bn_%7Bi%7D%7D" alt="[公式]">，a 表示负半轴的斜率，如 PReLU 方法，标准差满足 <img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bstd%7D%28W%29%3D%5Csqrt%7B%5Cfrac%7B2%7D%7B%5Cleft%281%2Ba%5E%7B2%7D%5Cright%29+%2A+n_%7Bi%7D%7D%7D" alt="[公式]">。代码如下：<code>nn.init.normal_(m.weight.data, std=np.sqrt(2 / self.neural_num))</code>，或者使用
PyTorch
提供的初始化方法：<code>nn.init.kaiming_normal_(m.weight.data)</code>，同时把激活函数改为
ReLU。</p>
<h4><span id="23-常用初始化方法">2.3 <strong>常用初始化方法</strong></span></h4>
<p><strong>PyTorch 中提供了 10 中初始化方法</strong></p>
<ol type="1">
<li>Xavier 均匀分布</li>
<li>Xavier 正态分布</li>
<li>Kaiming 均匀分布</li>
<li>Kaiming 正态分布</li>
<li>均匀分布</li>
<li>正态分布</li>
<li>常数分布</li>
<li>正交矩阵初始化</li>
<li>单位矩阵初始化</li>
<li>稀疏矩阵初始化</li>
</ol>
<p>每种初始化方法都有它自己适用的场景，原则是保持每一层输出的方差不能太大，也不能太小。</p>
]]></content>
      <categories>
        <category>【draft】工程</category>
        <category>开源工具</category>
        <category>Pytorch框架</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（1）业务风控常用算法归纳</title>
    <url>/posts/DMQR7N/</url>
    <content><![CDATA[<h2><span id="业务风控常用算法归纳">业务风控常用算法归纳</span></h2>
<blockquote>
<p><strong>风控碎碎念</strong>：https://www.zhihu.com/column/c_1483570023214510080</p>
<p><strong>求是汪在路上</strong>：https://www.zhihu.com/column/c_1156982447794233344</p>
</blockquote>
<h4><span id="前言">前言</span></h4>
<p>本篇文章在这里主要是做一个综述性的文章简单介绍一下，做一个归纳性质的文章：<strong>风控最核心的算法，按我的理解可以分解为以下几类</strong></p>
<ul>
<li><strong>有监督的去评价用户各个场景的风险层级</strong>：欺诈类风险，信用类风险等；给用户一个评分，作为用户后续策略的基础；【LR、XGB、LGB】</li>
<li><strong>无监督的去挖掘用户的社区关系</strong>：社区发现类算法，最主要的适用于数据标签的扩散，通过用户的相似性或者用户的关联性，达到增加覆盖的目的</li>
<li><strong>发现数据中的异常值</strong>：往往用于日常的风险感知和监控之中，可以有最简单的箱线图，也可以有单分类的孤立森林；</li>
<li><strong>行为序列的发现</strong>：最简单的可以是频繁项集，复杂的可以用各类用于序列挖掘的深度学习模型，可以作为模型的一个特征，也可以作为风险行为的发现；</li>
<li><strong>内容风控中</strong>：往往从正则和规则开始，有复杂的深度学习模型来cover，这一块了解较少；</li>
</ul>
<h3><span id="一-风控算法场景">一、风控算法场景</span></h3>
<h4><span id="11-用于用户风险评级的算法">1.1 用于用户风险评级的算法</span></h4>
<p>这里不考虑<strong>冷启动阶段</strong>所涉及的一些专家规则和头脑风暴，一般评级往往存在于项目运行了一段时间，有了比较可靠的数据积累之后，这时候往往需要我们更精确的根据场景进行用户的划分，最为人熟知的便是信贷中常用的信用分的那一套东西，这一块的知识，我常常是看这个博主
<strong>求是汪在路上</strong>；这一块的算法或者说这一类的算法，这位大佬讲的已经十分清楚了，有兴趣的可以翻出来看看；</p>
<p><strong><font color="red">
这一类的算法，主要是以有监督为准，难点主要集中在，正负样本不平衡，正负样本的选择，样本的观察期，表现期，观察点等的选择。</font></strong>一般涉及到的算法，主要以lr，xgb为主，那么在实际使用中，xgb和lightGBM因为其效果出色，特征工程的东西往往比较简单，往往在使用中用的更多一些。</p>
<p>这一类场景，往往目标相对明确，用途相对明确，做起来，工作量主要集中在特征工程上，一般来说特征工程做好了，这一类模型都可以做出还可以的效果；</p>
<h4><span id="12-用于社区挖掘的算法">1.2 用于社区挖掘的算法</span></h4>
<p><strong>社区挖掘，其实和聚类有点点像，也有点像推荐中的基于用户相似的推荐</strong>，本质就是将有关系，有联系的各类用户放到一起，用以达到用户分群的目的，这一块写的比较好的文章，我推荐：</p>
<ol type="1">
<li>怎么去找边与边之间的关联：</li>
</ol>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/471165448">小伍哥聊风控：风控中团伙挖掘的14大关系类型</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/33164335">今晚的风儿很喧嚣：推荐算法入门（1）相似度计算方法大全</a></li>
</ul>
<p>2、 社区挖掘的算法有哪些：</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/141401358">马东什么：社区发现算法综述</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/397573443">Shirley：基于深度学习的社区发现综述</a></li>
</ul>
<p>基本社区发现就是在于如何发现用户之间，边与边之间的关系，可以是直接关系可以是相似关系，然后将边连成图，进行图挖掘，一般来说一个庞大的图大多数会先选择做连通图，再到连通图下做二次挖掘，用以增速提效。<strong>前期的数据探索，我比较推荐gephi软件，如果你习惯用python，networkx也是很好的选择，你只需要定义好点和边，便可以大致看出数据的分布和图的密度，选择合适的算法进行愉快的聚类咯。</strong></p>
<p>其实这一块，我觉得和推荐场景有一点点像，推荐是猜你喜欢，风控是猜你会干坏事，只是标签不一样，要做的事情是一样的，所有用于推荐相关的算法，也可以类比的用于风控，往往会有<strong>出其不意的效果</strong>；</p>
<h4><span id="13-异常值相关的发现算法">1.3 异常值相关的发现算法</span></h4>
<p>异常值算法，其实和不平衡数据集(pu-learning)的解决方法类似，因为对于风控来讲，风控本身针对的用户在平台或者在用户群中，占比就非常非常低，部分场景可能连千分之一，万分之一都不到，对于大数据集来讲，本身就算是一种<strong>异常值</strong>了，所以往往异常值发现的算法，在实际使用当中，往往会有意想不到的好效果；</p>
<p>说到异常值发现，日常的监控可能是一个方面，比如同比环比，比例异常，用户群占比异常等；除此之外还有一些，xgbod，iforest的半监督或者单分类的模型可以用于此类场景，这类场景，推荐可以参考：</p>
<p><a href="https://zhuanlan.zhihu.com/p/368352445">xiaobo
Xie：异常检测用于不平衡数据的二分类</a></p>
<p>我个人觉得这是一类对于风控来讲非常好的思考方式，就<strong>是当我们很难刻画黑用户的特征的时候，我们能尽可能好的描述好白用户的特征</strong>，我们一样可以解决问题，这一类问题的模型解决也往往是朝着这个思路来做的；</p>
<h4><span id="14-行为序列相关的算法">1.4 行为序列相关的算法</span></h4>
<p>行为序列作为风控行为挖掘的重要组成部分，在部分场景往往有着意想不到的作用，举个例子，电商场景，正常人从搜索到下单，<strong>往往有着复杂的序列，至少大部分用户会有复杂的序列</strong>，而黑灰产往往会点击某些固定的链接直接进入商详，或者搜索固定的词进入商品，下单购买一气呵成，而如果一个非营销类商品大多数聚集着这样的序列，可能往往就存在一些问题，如果这个问题深入探讨下去，便是行为序列的挖掘；</p>
<p>从简入深，可以有<strong>频繁项集</strong>(前后无关联，只要频繁反复出现某类行为即为有问题)，往深了做，可以<strong>有rnn及其改进的lstm</strong>相关的算法，进行进一步的建模，可以更加准确。在业务前期，我们可以先用频繁项集提取一些有价值的规则，在满足前期需求之后，可以进一步使用模型对当前场景进行优化，已达到提升召回和准确的作用。</p>
<p>同样我也在这里推荐一篇知乎上的文章：</p>
<p><a href="https://zhuanlan.zhihu.com/p/420995638">没什么大不了：浅谈行为序列建模</a></p>
<h4><span id="15-内容风控相关算法">1.5 <strong>内容风控相关算法</strong></span></h4>
<p>这一部分是我的一个知识盲区，我自己大约只能做到正则，基于同义词的正则相关的策略，其余更深入的算法探索，我没有做过，也没有相关经验，也就不班门弄斧了，毕业以来做深度学习的东西比较少，理论大约停留在表面，不太深入，也没做过什么实践，就不赘述了；网上也没找到什么比较深入探讨的资料，如果有小伙伴推荐的话，我也希望可以评论或者私信告知，不甚荣幸。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（2）风控模型-开发流程标准化*</title>
    <url>/posts/29K9TF6/</url>
    <content><![CDATA[<h1><span id="风控模型">风控模型</span></h1>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/109649516">求是汪在路上：多头借贷风险分析与建模</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/252845718">求是汪在路上：抽样对Lift和KS指标的影响</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/161009991">求是汪在路上：客户级通用信用评分模型架构设计</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/90214329">求是汪在路上：大数据信贷风控模型架构</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/90251922">求是汪在路上：<strong><font color="red">
风控模型开发流程标准化</font></strong></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/92691256">求是汪在路上：风控模型上线部署流程</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/350616539">求是汪在路上：如何量化样本偏差对信贷风控模型的影响</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/110982479">求是汪在路上：<strong><font color="red">
样本权重对逻辑回归评分卡的影响探讨</font></strong></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/85976154">求是汪在路上：利用样本分群提升风控模型性能</a></p>
</blockquote>
<h2><span id="一-风控模型开发流程标准化">一、风控模型开发流程标准化</span></h2>
<h3><span id="风控业务背景"><strong>风控业务背景</strong></span></h3>
<p>在大型风控建模项目中，模型开发阶段实际上只占其中很小的一部分，我们常把大量精力投入在数据准备、特征工程、模型设计等阶段。同时，开发阶段所用方法重复性相对较高。如果将其模块化封装，可大大提高建模效率。Don‘t
repeat yourself！</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-ca4ae4880f0369cdfd03bfa3b97cba81_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>本文主要内容在于：</p>
<ol type="1">
<li>理论角度，系统阐述了风控模型开发流程，以及相应的理论依据。</li>
<li>实践角度，整理了目前一些开源工具包，可供大家自行选择使用。</li>
</ol>
<h3><span id="11风控模型开发流程标准化的意义"><strong>1.1
风控模型开发流程标准化的意义</strong></span></h3>
<p>在《<a href="https://zhuanlan.zhihu.com/p/90214329">大数据信贷风控模型架构</a>》一文中，我们系统探讨了大数据风控模型架构的优缺点。从该架构出发，基于历次大型模型开发项目实践，我们往往会发现存在以下问题：</p>
<ol type="1">
<li>各建模同学的工程能力存在差异，无法保证所有人都有代码优化及debug的能力。</li>
<li>整个流程不规范统一，某些同学不清楚基础指标函数的底层逻辑，出现问题难以定位。</li>
<li>浪费大量时间用于协调沟通，尤其是过程文档记录参差不齐，无法复现。</li>
<li><strong>建模脚本可能存在多个版本，模型版本管理困难</strong>。</li>
</ol>
<p>风控模型开发流程标准化的意义在于：</p>
<ol type="1">
<li>提高建模效率：可批量快速生产模型，保证项目按期完成，同时让建模同学更有精力关注模型优化分析等复杂工作。</li>
<li>理解计算逻辑：帮助团队更为深刻理解各类评估指标背后的业务含义，便于调试优化。</li>
<li><strong>统一建模流程</strong>：约定命名方式。保证在分工协作的情况下，模型开发文档更容易整合汇总，便于Review。</li>
<li>流程规范约束：减少建模同学（尤其是新手）出错的概率，降低返工可能，并记录必要的中间过程，便于问题回溯。</li>
</ol>
<p>由于经常需要跨时间窗来分析变量，我们约定以下名词：</p>
<ul>
<li><strong>样本集</strong>：训练集（In the Sample，INS）、验证集（Out
of Sample，OOS）、测试集（Out of Time，OOT）</li>
<li><strong>自然月</strong>：由于风控领域中样本相对较少，一般按月粒度来观察。对于某段时间内的样本，我们也称为cohort或vintage。通俗而言，就是一个批次（batch）。</li>
</ul>
<h3><span id="12-功能模块-探索性数据分析"><strong>1.2 功能模块 -
探索性数据分析</strong></span></h3>
<p><strong>探索性数据分析（Exploratory Data
Analysis，EDA）用于初步检验数据质量，因此需要计算各类数据特征指标。</strong></p>
<blockquote>
<ul>
<li>探索数据分布（Exploratory Data Distribution，EDD）</li>
<li>缺失率（Missing Rate）</li>
<li>重复值（Duplicate Value）</li>
<li>单一值（Unique Value）</li>
<li>其他数据质量检查（Quality Check）</li>
</ul>
</blockquote>
<h4><span id="121探索数据分布exploratory-data-distributionedd">1.2.1
探索数据分布（Exploratory Data Distribution，EDD）</span></h4>
<p><strong>功能</strong>：按自然月/样本集维度，统计变量的数据分布。</p>
<p><strong>指标</strong>：</p>
<ul>
<li>连续型变量，包括：数量(count)、均值(mean)、标准差(std)、最小值(min)、分位数P25、P50、P75、最大值(max)。其中，最大值和最小值可用来观察异常值（outlier）。</li>
<li>离散型变量，包括：取值及出现次数(cnt)、占比(ratio)。</li>
</ul>
<p><strong>示例</strong>：连续变量数据分布（月维度)、离散变量数据分布</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-8f7ad96d18789094dab9090cf551a81e_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic4.zhimg.com/80/v2-0b97ea436eb6156939e74bf5126ae3d3_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li><strong>业务含义</strong>：基于“<strong>历史与未来样本分布相同</strong>”的建模假设，我们才能基于历史数据拟合X和Y之间的关系来预测未来。因此，在变量分布上，首先需要保证这一点。</li>
</ul>
<p>从图1中，我们可以观察分位数的变化差异。例如，变量 <img src="https://www.zhihu.com/equation?tex=x_2" alt="[公式]">
在2018年1月时最大值异常，其余月份均正常。此时，我们就需要检查：数据源是否存在问题？变量回溯过程是否出错？</p>
<h4><span id="122-缺失率missingrate">1.2.2 <strong>缺失率（Missing
Rate）</strong></span></h4>
<p>功能：<strong>按自然月/样本集维度，统计变量的缺失率。</strong></p>
<p>指标：缺失率 = 未覆盖样本数 / 总样本数 × 100%</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-32d1ec1106b1e58cfcd2ecfe7b0040b5_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>业务：</p>
<ul>
<li>用于分析数据源的缺失率，以及未来的采集率趋势。如果缺失率持续升高，我们就认为这块数据不可用。</li>
<li>造成缺失的原因多种多样，可分为随机缺失和非随机缺失。例如，如果是用户自填信息，用户主观不愿意填写而导致数据缺失，属于非随机缺失。</li>
</ul>
<h4><span id="123-重复值duplicatevalue">1.2.3 <strong>重复值（Duplicate
Value）</strong></span></h4>
<p>功能：检验建模样本中是否有重复数据。</p>
<p>指标：按样本ID分组后，统计行数</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-2c3cd4f809b68e130f4d6edba31058b8_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>业务：观察相同订单的特征变量取值是否一致。取值相同，只需简单去重；否则，说明生成逻辑有误，需检查SQL逻辑。</p>
<h4><span id="124-单一值uniquevalue">1.2.4 <strong>单一值（Unique
Value）</strong></span></h4>
<p>功能：统计变量中某一固定值的占比。</p>
<p>指标：变量每个取值的出现次数。</p>
<p>示例：变量中0的取值占到70%.</p>
<p><strong>业务：如果变量取值中某一固定值占比很高，那么该变量区别度往往很低。通常，单一值比例超过90%以上，建议删除该变量。</strong></p>
<h4><span id="125其他数据质量检查qc"><strong>1.2.5
其他数据质量检查（QC）</strong></span></h4>
<p>变量取值本身具有某些业务含义，我们需要结合业务来检验，并记录归档。例如：</p>
<ul>
<li>特殊值归档说明：例如-9999999是代表缺失，还是其他含义，需给出描述说明。</li>
<li>0的业务逻辑确认：真实值为0？数据缺失？默认填充值？</li>
</ul>
<h3><span id="13-功能模块-特征选择">1.3 <strong>功能模块 -
特征选择</strong></span></h3>
<p>根据RFM特征体系，我们可以构造成千上万个特征变量（参考《<a href="https://zhuanlan.zhihu.com/p/85440355">风控特征—时间滑窗统计特征体系</a>》）。但是，这些变量并不都满足我们的要求，<strong><font color="red">
我们需要剔除不符合要求的变量，从输入上保证风控系统的鲁棒性。</font></strong></p>
<p>变量筛选（selection）是一个比较复杂的精细活，需要考虑很多因素，比如：<strong>预测能力、相关性、稳定性、合规性、业务可解释性</strong>等等。考虑不同维度，我们会依据一系列指标进行变量筛选。</p>
<p>从广义上，可分为业务指标和技术指标两大类。</p>
<h4><span id="131-业务指标包括">1.3.1 <strong>业务指标</strong>包括：</span></h4>
<ol type="1">
<li><strong>合规性(compliant)</strong>：用以加工变量的数据源是否符合国家法律法规？是否涉及用户隐私数据？例如，如果某块爬虫数据被监管，那么相关变量的区分度再好，我们也只能弃用。而在国外，种族、性别、宗教等变量被禁止用于信贷风控中，这会存在歧视性。</li>
<li><strong>可得性(available)</strong>：数据未来是否能继续采集？这就涉及产品流程设计、用户授权协议、合规需求、模型应用环节等诸多方面。例如，如果产品业务流程改动而导致某个埋点下线，那么相关埋点行为变量只能弃用。又比如，如果需要做额度授信模型，那么只能利用在额度阶段能采集到的实时数据，这就需要提前确认数据采集逻辑。</li>
<li><strong>稳定性(stable)</strong>：一方面，数据源采集稳定是变量稳定性的基本前提。例如，外部数据常会因为政策性、技术性等原因导致接入不稳定，这就需要做好数据缓存，或者模型降级机制。另一方面，变量取值分布变化是导致不稳定的直接原因。我们将会采取一些技术指标展开分析，下文将会介绍。</li>
<li><strong>可解释性(interpretable)</strong>：需要符合业务可解释性。如果变量的业务逻辑不清晰，那么我们宁可弃之。同时，这也是保证模型可解释性（参数
+ 变量）的前提。</li>
<li><strong>逻辑性(logical)</strong>：也就是因果逻辑，特征变量是因，风控决策是果。如果某个变量是风控系统决策给出的，那么我们就不能入模。例如，用户历史申贷订单的利率是基于上一次风控系统决策的结果，如果将“用户历史申贷订单的利率”作为变量，那么在实际使用时就会有问题。</li>
<li><strong>可实时上线</strong>：模型最终目的是为了上线使用。如果实时变量不支持加工，那么对应的离线变量就只能弃之。例如，某个离线变量在统计时限定观察期为180天，但线上只支持观察期为90天，那么就不可用。对于不熟悉线上变量加工逻辑的新手，往往容易踩坑而导致返工。</li>
</ol>
<h4><span id="132-技术指标包括">1.3.2 <strong>技术指标</strong>包括：</span></h4>
<blockquote>
<p>基于缺失率（Missing Rate） 基于变异系数（Coefficient of
Variation，CV） 基于稳定性（Population Stability Index，PSI）
基于信息量（Information Value，IV） 基于RF/XGBoost特征重要性（Feature
Importance） 变量聚类（Variable Cluster，VarClus）
基于线性相关性（Linear Correlation） 基于多重共线性（Multicollinearity）
基于逐步回归（stepwise) 基于P-Vaule显著性检验</p>
</blockquote>
<ul>
<li><strong>基于缺失率（Missing Rate）</strong></li>
</ul>
<p><strong>业务：</strong>变量缺失率越高，可利用价值越低。缺失率变化不稳定的变量，尤其是缺失率趋势在升高，代表未来数据源采集率下降，不建议采用。数据源是特征变量的基础，数据源不稳定，直接导致模型稳定性变差。</p>
<h5><span id="功能">功能：</span></h5>
<blockquote>
<p>step 1.
按自然月/样本集维度，统计变量缺失率，并计算缺失率的均值、标准差。 step
2. 根据实际场景，设置阈值（如50%、70%、90%）进行筛选。</p>
</blockquote>
<figure>
<img src="https://pic4.zhimg.com/80/v2-d432f6c6916a4e94b698d325ce9d32b7_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li><strong>基于变异系数（Coefficient of Variation，CV）</strong></li>
</ul>
<p><strong>业务</strong>：变异系数越小，代表波动越小，稳定性越好。缺点在于CV没有统一的经验标准。</p>
<p><strong>功能</strong>：</p>
<blockquote>
<p>step 1.
基于数据分布EDD，选择某个指标（如均值mean）计算变异系数CV，用来衡量变量分布的稳定性。
step 2. 设置阈值进行筛选。</p>
</blockquote>
<p><strong>指标</strong>：变异系数 C·V =（ 标准偏差 SD / 平均值Mean ）×
100%</p>
<ul>
<li><strong>基于稳定性（Population Stability Index，PSI）</strong></li>
</ul>
<p><strong>业务</strong>：需分申请层、放款层，分别评估变量稳定性。通常会选择0.1作为阈值，只要任意一个不满足稳定性要求就弃用。PSI无法反映很多细节原因，比如分布是右偏还是左偏。此时需要从EDD上进行分析。</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-330e33c4f93c5abef39854964f780d5a_1440w.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>功能</strong>：</p>
<blockquote>
<p>step 1. 以训练集（INS）分布为期望分布，计算变量的群体稳定性指标PSI。
step 2. 根据PSI的经验阈值进行筛选。</p>
</blockquote>
<p><strong>指标</strong>： <img src="https://www.zhihu.com/equation?tex=psi+%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7B%28A_i+-+E_i%29%7D+%2A+ln%28A_i+%2F+E_i%29" alt="[公式]"></p>
<p>上式含义为：PSI = SUM( (实际占比 - 预期占比）* ln(实际占比 /
预期占比)
);预期占比是指训练集上每个分箱里的样本占比，实际占比是待比较样本集的每个分箱里的样本占比。可参考《<a href="https://zhuanlan.zhihu.com/p/79682292">群体稳定性指标(PSI)深入理解应用</a>》。</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-c9cb1ae5f72f2f6c5dfcb54486f23182_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>==<strong>基于信息量（Information Value，IV）</strong>==</li>
</ul>
<p><strong>业务</strong>：<strong>用以评估变量的预测能力</strong>。通常情况下，IV越高，预测能力越强。但IV过高时，我们就要怀疑是否发生信息泄漏（leakage）问题，也就是在自变量X中引入了Y的信息。</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-1833a40731ac61e55a38bbd928dc7636_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>功能</strong>：</p>
<blockquote>
<p>step 1. 按自然月/样本集维度，统计变量的IV。 step 2.
根据IV的经验阈值来筛选。</p>
</blockquote>
<p><strong>指标</strong>：IV。可参考<strong>《</strong><a href="https://zhuanlan.zhihu.com/p/80134853">WOE与IV指标的深入理解应用</a><strong>》</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=IV+%3D++%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%28%5Cfrac%7BBad_i%7D%7BBad_T%7D++-+%5Cfrac%7BGood_i%7D%7BGood_T%7D%29+%2A+WOE_i+%5C%5C++++%3D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%28%5Cfrac%7BBad_i%7D%7BBad_T%7D++-+%5Cfrac%7BGood_i%7D%7BGood_T%7D%29+%2Aln%28%5Cfrac%7BBad_i%7D%7BBad_T%7D++%2F+%5Cfrac%7BGood_i%7D%7BGood_T%7D%29+%5C%5C+" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://pic3.zhimg.com/80/v2-2097685ef366bb9df0f6b8944c416aba_1440w.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>==<strong>基于RF/XGBoost特征重要性</strong>==</li>
</ul>
<p><strong>业务</strong>：在特征变量特别多的时候，可用于快速筛选特征。从机器学习可解释性角度而言，特征重要性只具有全局可解释性，无法对单个case给出解释。</p>
<p><strong>功能</strong>：</p>
<blockquote>
<p>step 1. 根据树模型训练后给出的特征重要性，一般选择累积重要性Top
95%的变量。 step 2.
为降低一次训练所导致的随机性影响，可综合多次结果来筛选。</p>
</blockquote>
<p>指标：特征重要性。XGBoost实现中Booster类get_score方法输出特征重要性，其中
importance_type参数支持三种特征重要性的计算方法：</p>
<blockquote>
<ol type="1">
<li><strong>weight（默认值）：使用特征在所有树中作为划分属性的次数。</strong></li>
<li><strong>gain：使用特征在作为划分属性时，OBj的平均降低量。</strong></li>
<li><strong>cover：使用特征在作为划分属性时对样本的覆盖度。</strong></li>
</ol>
</blockquote>
<p><strong>RF中计算特征重要度的主要思想：影响力分析</strong>。如果某个输入变量产生扰动，导致模型系统输出性能（利用袋外数据OOB的准确率来评估）产生明显影响，那么说明输入变量对系统具有较大的影响力，特征重要度比较高。</p>
<p>执行步骤为：</p>
<blockquote>
<p>step 1. 基准性能：对每一颗决策树，选择相应的袋外数据计算误差，记为
<img src="https://www.zhihu.com/equation?tex=err_%7BOOB1%7D" alt="[公式]"> ； step 2.
输入扰动：随机对袋外数据所有样本的特征加入噪声干扰(如白噪声)，再次计算袋外数据误差，记为
<img src="https://www.zhihu.com/equation?tex=err_%7BOOB2%7D" alt="[公式]"> ； step 3. 重要度计算： <img src="https://www.zhihu.com/equation?tex=+%5Cfrac%7B%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28err_%7BOOB2%7D-err_%7BOOB1%7D%29%7D%7BN%7D" alt="[公式]"> ，N为随机森林中决策树的棵数。</p>
</blockquote>
<figure>
<img src="https://pic4.zhimg.com/80/v2-7457883119e561b64bae7ef3d49340ff_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li><strong>变量聚类（Variable Cluster，VarClus）</strong></li>
</ul>
<p><strong>业务</strong>：在SAS中对应Proc VarClus方法。</p>
<p><strong>功能</strong>：</p>
<blockquote>
<p>step 1. 列聚类，将所有变量进行层次聚类。 step 2.
根据聚类结果，剔除IV相对较低的变量。</p>
</blockquote>
<p><strong>指标</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> FeatureAgglomeration</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line">    </span><br><span class="line">X_Scale = preprocessing.StandardScaler().fit_transform(input_df[var_list])</span><br><span class="line">ward = FeatureAgglomeration(n_clusters=n_clusters, linkage=<span class="string">&#x27;ward&#x27;</span>)</span><br><span class="line">ward.fit(X_Scale)</span><br><span class="line">clusters = <span class="built_in">list</span>(ward.labels_)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://pic3.zhimg.com/80/v2-f93b791196087e503a2da4b12a26b84a_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li><strong>基于线性相关性（Linear Correlation）</strong></li>
</ul>
<p><strong>业务</strong>：逻辑回归作为一种线性模型，其基础假设是：自变量
<img src="https://www.zhihu.com/equation?tex=%28X_1%EF%BC%8CX_2%29" alt="[公式]">
之间应相互独立。当两变量间的相关系数大于阈值时（一般阈值设为0.6)，剔除IV值较低的变量。</p>
<p><strong>功能</strong>：</p>
<blockquote>
<p>step 1. 计算变量的线性相关性。 step 2.
<strong>相关性较高的多个变量里，保留IV较高的变量。</strong></p>
</blockquote>
<p><strong>指标</strong>：<strong>皮尔逊相关系数（Pearson Correlation
Coefficient）</strong>，系数的取值为<img src="https://www.zhihu.com/equation?tex=%5B-1.0%2C1.0%5D" alt="[公式]">，两变量相关系数越接近0，说明线性相关性越弱；越接近1或-1，说明线性相关性越强。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Crho_%7BX%2CY%7D%3D%5Cfrac%7Bcov%28X%2CY%29%7D%7B%5Csigma_X%5Csigma_Y%7D%5C%5C%3D%5Cfrac%7BE%28%28X-%5Cbar+X%29%28Y-%5Cbar+Y%29%29%7D%7B%5Csqrt%7B%5Csum%5Climits_%7Bi%3D1%7D%5En%28X_i-%5Cbar+X%29%5E2%7D+%5Csqrt%7B+%5Csum%5Climits_%7Bi%3D1%7D%5En%28Y_i-%5Cbar+Y%29%5E2%7D%7D+%5C%5C%3D+%5Cfrac%7BE%28XY%29-E%28X%29%28Y%29%7D%7B%5Csqrt%7BE%28X%5E2%29-E%5E2%28X%29%7D%5Csqrt%7BE%28Y%5E2%29-E%5E2%28Y%29%7D%7D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://pic4.zhimg.com/80/v2-17f049f47e262d45614a016289def3eb_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li><strong>基于多重共线性（Multicollinearity）</strong></li>
</ul>
<p>对于自变量<img src="https://www.zhihu.com/equation?tex=X_1%2C+X_2%2C+%5Ccdots+%2C+X_n" alt="[公式]">，如果存在不全为0的系数<img src="https://www.zhihu.com/equation?tex=c_1%2Cc_2%2C+%5Ccdots%2C+c_n" alt="[公式]">，使得以下线性等式近似成立:</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=c_1X_1+%2B+c_2X_2+%2B+%5Ccdots+%2B+c_nX_n+%5Capprox+0%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>换言之，对于 <img src="https://www.zhihu.com/equation?tex=N" alt="[公式]"> 个变量，其中 <img src="https://www.zhihu.com/equation?tex=1" alt="[公式]">
个可以由剩下的 <img src="https://www.zhihu.com/equation?tex=N-1" alt="[公式]"> 个变量线性表示。此时，我们就称自变量<img src="https://www.zhihu.com/equation?tex=X_1%2C+X_2%2C+%5Ccdots+%2C+X_n" alt="[公式]">具有较强的多重共线性。</p>
<p><strong><font color="red">
当出现多重共线性时，变量之间的联动关系会导致估计标准差偏大，置信区间变宽。这就会产生一个常见的现象，LR中变量系数出现正负号不一致。</font></strong></p>
<p>业务：VIF取值的业务含义为：</p>
<blockquote>
<p>若VIF &lt; 3，说明基本不存在多重共线性问题 若VIF &gt;
10，说明问题比较严重。</p>
</blockquote>
<p>功能：</p>
<blockquote>
<p>step 1. <strong>计算变量的方差膨胀因子（Variance Inflation
Factor，VIF），适用于线性模型。</strong> step 2.
根据阈值剔除VIF较高的变量。</p>
</blockquote>
<p>指标：通常用VIF衡量一个变量和其他变量的多重共线性。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from statsmodels.stats.outliers_influence import variance_inflation_factor</span><br></pre></td></tr></table></figure>
<p>示例：</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-6b5e626a0af1ae9f595f25fb8fb9b10b_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li><p><strong>基于逐步回归（stepwise)</strong></p>
<ul>
<li><p>前向选择（forward
selection）：逐步加入变量，计算指标进行评估，若不合格则不加入，直到评估完所有变量。</p></li>
<li><p>后向选择（backward
selection）：初始时加入所有变量，根据指标逐渐剔除不合格的变量。</p></li>
<li><p>逐步选择（stepwise）：将向前选择和向后选择的结合，逐步放入最优的变量、移除最差的变量。</p></li>
</ul></li>
<li><p><strong>基于P-Vaule显著性检验</strong></p></li>
</ul>
<p>业务：根据逻辑回归参数估计表，剔除P值大于0.05的变量。</p>
<p>功能：</p>
<blockquote>
<p>step 1. 用于检验自变量X与因变量Y之间的相关性。 step 2.
剔除P值大于0.05的变量。</p>
</blockquote>
<p>指标：P-Vaule。在变量相关分析中，对相关系数进行假设检验时：</p>
<blockquote>
<p>原假设H0：自变量与因变量之间线性无关。
备择假设H1：自变量与因变量之间线性相关。</p>
</blockquote>
<p>或许不太恰当，但通常当P值大于0.05时，接受原假设，否则拒绝原假设。因此，我们需要剔除P值大于0.05的变量。</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-e08616047f86d2e6011528e45df62eb9_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="14-功能模块-模型训练">1.4 <strong>功能模块 -
模型训练</strong></span></h3>
<p>该模块主要包括<strong>变量变换（如分箱）</strong>、<strong>样本准备（包括样本赋权、拒绝推断等）</strong>、<strong>模型参数估计</strong>、<strong>模型分数校准</strong>、<strong>模型文件保存</strong>等功能。</p>
<h4><span id="141-woe转换weight-ofevidence">1.4.1 <strong>WOE转换（Weight of
Evidence）</strong></span></h4>
<p><strong>业务：训练集上的WOE曲线需满足单调性，并且经过跨时间窗验证WOE变换逻辑同样满足单调性。如果不满足，那就需要再次调整。</strong></p>
<p><strong>功能：在评分卡模型中用于变量WOE变换，支持等频、等距、自定义间距等分箱操作。</strong></p>
<p>原理：可参考<strong>《</strong><a href="https://zhuanlan.zhihu.com/p/80134853">WOE与IV指标的深入理解应用</a><strong>》</strong></p>
<p>示例：</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-3f95842ee9ac7568cfd1147552471481_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="142-样本权重sampleweight">1.4.2 <strong>样本权重（Sample
Weight）</strong></span></h4>
<p><strong>功能：给建模样本赋予权重列，以逼近总体样本。</strong></p>
<p><strong>原理：建模本质在于从历史样本中学习未来样本的数理统计规律。</strong></p>
<h4><span id="不同的样本权重主要有几个目的"><strong>不同的样本权重主要有几个目的：</strong></span></h4>
<ul>
<li>为了让模型更稳健，一般都是拿近期样本refit模型，但上线后没几个月很快就衰减了，说明训练样本有偏程度比较高，不够代表总体。</li>
<li>早期的历史样本都是拿钱换来的，如何把这部分样本利用起来，不浪费。</li>
</ul>
<h4><span id="业务角度主观性强操作性高"><strong>==业务角度（主观性强，操作性高）：==</strong></span></h4>
<ul>
<li>按时间因素，近期样本提高权重，较远样本降低权重</li>
<li>按贷款类型，不同额度、利率、期限的样本赋予不同权重</li>
<li>按样本分群，不同群体赋予不同权重</li>
</ul>
<h4><span id="技术角度操作性复杂可解释性弱"><strong>技术角度（操作性复杂，可解释性弱）：</strong></span></h4>
<ul>
<li>借鉴Adaboost思想，对误判样本提高权重</li>
<li>过采样、欠采样、SMOTE等</li>
</ul>
<h4><span id="拒绝演绎rejectinference"><strong>拒绝演绎（Reject
Inference）</strong></span></h4>
<p>功能：样本偏差将会导致模型估计过于乐观。通过推断拒绝样本的贷后表现，加入建模样本，可降低放贷建模样本与申请作用样本之间的偏差。</p>
<p>原理：参考《<a href="https://zhuanlan.zhihu.com/p/88624987">风控建模中的样本偏差与拒绝推断</a>》</p>
<h4><span id="参数估计parameterestimation"><strong>参数估计（Parameter
Estimation）</strong></span></h4>
<p><strong>功能：支持机器学习模型（如随机森林、GBDT、XGBoost、LightGBM等）调参、评分卡模型逐步回归（stepwise）。</strong></p>
<p>原理：LR采用最大似然估计进行参数估计。而机器学习模型的超参数较多，通常需要借助网格搜索（grid
search）、贝叶斯调参等技术，降低对人工经验的依赖。</p>
<h4><span id="分数校准calibration"><strong>分数校准（Calibration）</strong></span></h4>
<p>功能：其一，一致性校准，将模型预测概率校准到真实概率。其二，尺度变换，将风险概率转换为平时所见的整数分数。</p>
<p>原理：参考《<a href="https://zhuanlan.zhihu.com/p/82670834">信用评分卡模型分数校准</a>》</p>
<h4><span id="模型保存save-model"><strong>模型保存（Save Model）</strong></span></h4>
<p>功能：将模型（参数+结构）保存为pkl和pmml文件，用以最终上线部署。注意需要给不同版本的模型赋予易于辨识、含义清晰的命名。一般建议至少包含以下内容：</p>
<blockquote>
<p>命名 = 生成日期+责任人+业务线+应用环节+版本号
例如：20190101_小王_有钱花_额度授信_V1.pmml</p>
</blockquote>
<p>原理：参考《<a href="https://zhuanlan.zhihu.com/p/92691256">风控模型上线部署流程</a>》</p>
<h3><span id="15-功能模块-模型评估">1.5 <strong>功能模块 -
模型评估</strong></span></h3>
<p>在实际业务实践中，我们对风控模型的衡量维度主要包括以下几个方面：</p>
<blockquote>
<ul>
<li>稳定性（Stability）</li>
<li>区分度（Discrimination）</li>
<li>排序性（Ranking）</li>
<li>拟合度（Goodness of Fit）</li>
</ul>
</blockquote>
<h4><span id="151-稳定性stability">1.5.1 <strong>稳定性（Stability）</strong></span></h4>
<p>业务：在风控中，稳定性压倒一切。PSI取值所对应的业务含义如图8所示。我们需在申请层和放贷层上评估稳定性。原因在于：</p>
<ul>
<li>虽然模型是基于放贷订单训练，但最终应用在申请层。</li>
<li>申请层和放贷层客群存在差异。</li>
</ul>
<p>当PSI曲线的趋势一直在上升时，我们就要分析原因，消除不稳定因素。排查方向可参考《<a href="https://zhuanlan.zhihu.com/p/86559671">特征稳定性指标(CSI)深入理解应用</a>》中的Part
4。</p>
<p>指标：PSI。可参考《<a href="https://zhuanlan.zhihu.com/p/79682292">群体稳定性指标(PSI)深入理解应用</a>》</p>
<p>示例：</p>
<p><img src="https://pic2.zhimg.com/80/v2-ed926c29a728c4e8f42b881af25c319d_1440w.png" alt="img">模型分数PSI计算结果表（申请+放贷）</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-b5e5d64f96906eeaa78e8ac6ebf80098_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="152区分度discrimination">1.5.2
<strong>区分度（Discrimination）</strong></span></h4>
<p>业务：KS指标是风控建模同学最为追求的指标之一。通常情况下，KS越大，模型性能越好。但更需要分析KS不佳的原因，可结合ROC曲线进行辅助分析。</p>
<p>指标：Gini、AUC、KS。可参考《<a href="https://zhuanlan.zhihu.com/p/79934510">区分度评估指标(KS)深入理解应用</a>》
<img src="https://pic2.zhimg.com/80/v2-952042e2835b7a3b4458d3fd763b6e15_1440w.png" alt="img"></p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-649ad86e09b8f5fc09dc224a6a1fb6ea_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="153-排序性ranking">1.5.3 <strong>排序性（Ranking）</strong></span></h4>
<p><strong>业务</strong>：大部分模型在最终应用时只是利用到排序性，其主要是为了观察曲线的斜率。如图21所示的模型，排序性非常好，前5个分箱就能抓住大约77%的坏客户。</p>
<p><strong>指标：按自然月/样本集维度，统计包含bad_rate、lift、odds等指标的Gain
Table。</strong></p>
<blockquote>
<p><strong>lift = 召回样本的bad rate / 全部样本的bad rate</strong>
<strong>odds = bads / good</strong></p>
</blockquote>
<p>示例：模型分数Gain-Table</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-169d5023b834416495810435e8c9b11b_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="154-拟合度goodness-offit">1.5.4 <strong>拟合度（Goodness of
Fit）</strong></span></h4>
<p><strong>业务</strong>：我们以训练集为基准，将模型分数划分成10个(或20个)分箱后，查看每个分箱里的reject
rate等指标是否一致。理论上，如果按每个Vintage绘制多条曲线，这些曲线会几乎重合，也就是围绕在训练集附近波动。此时，我们就可以相信模型在每一档的坏账估计比较准确。</p>
<p>指标：按自然月/样本集，评估每个分箱里lift、reject rate、bad
rate的点估计</p>
<p>示例：</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-32f4f004276a03f1adb5046d4ea40d91_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="16-开源的风控建模工具包简介">1.6 开源的风控建模工具包简介</span></h3>
<p>前文主要介绍一些理论，接下来介绍目前一些开源的风控建模工具包。</p>
<blockquote>
<p>feature-selector scorecardpy toad</p>
</blockquote>
<h4><span id="161-feature-selector">1.6.1 <strong>feature-selector</strong></span></h4>
<ul>
<li>https://github.com/WillKoehrsen/feature-selector</li>
</ul>
<p><strong>主要功能：包括缺失率、单一值、相关性、特征重要性等。</strong></p>
<ol type="1">
<li>Missing Values</li>
<li>Single Unique Values</li>
<li>Collinear Features</li>
<li>Zero Importance Features</li>
<li>Low Importance Features</li>
</ol>
<h4><span id="162-scorecardpy">1.6.2 <strong>scorecardpy</strong></span></h4>
<ul>
<li>https://github.com/shichenxie/scorecardpy</li>
</ul>
<p><strong>主要功能：包括数据集划分、变量筛选、WOE分箱变换、评分卡尺度变换、模型性能评估。</strong></p>
<ol type="1">
<li>data partition (split_df)</li>
<li>variable selection (iv, var_filter)</li>
<li>weight of evidence (woe) binning (woebin, woebin_plot, woebin_adj,
woebin_ply)</li>
<li>scorecard scaling (scorecard, scorecard_ply)</li>
<li>performance evaluation (perf_eva, perf_psi)</li>
</ol>
<h4><span id="163-toad">1.6.3 <strong>toad</strong></span></h4>
<ul>
<li>https://toad.readthedocs.io/en/stable/tutorial_chinese.html</li>
</ul>
<p><strong>主要功能：包括数据分析处理、特征筛选、模型筛选、模型评估、评分卡尺度变换等。</strong></p>
<ol type="1">
<li>data handling</li>
<li>feature selection and WOE binning</li>
<li>model selection</li>
<li>results evaluation and model validation</li>
<li>scorecard transformation.</li>
</ol>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（2）风控模型-抽样对Lift和KS指标的影响</title>
    <url>/posts/ADDHH0/</url>
    <content><![CDATA[<h1><span id="风控模型">风控模型</span></h1>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/109649516">多头借贷风险分析与建模</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/252845718">抽样对Lift和KS指标的影响</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/161009991">客户级通用信用评分模型架构设计</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/90214329">大数据信贷风控模型架构</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/90251922"><strong><font color="red">
风控模型开发流程标准化</font></strong></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/92691256">风控模型上线部署流程</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/350616539">如何量化样本偏差对信贷风控模型的影响</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/110982479"><strong><font color="red">
样本权重对逻辑回归评分卡的影响探讨</font></strong></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/85976154"><strong><font color="red">
利用样本分群提升风控模型性能</font></strong></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/252845718">抽样对Lift和KS指标的影响</a></p>
</blockquote>
<h3><span id="风控业务背景"><strong>风控业务背景</strong></span></h3>
<p>在测试外部三方数据时，数据服务商只允许我们抛出有限一定量样本（例如5w、10w、20w）来匹配三方数据。这就要求我们对样本抽样。在对外部数据建模测算后，我们如何将结果还原到原始样本上评估呢？针对这种常见场景，本文将探索抽样对lift指标和KS指标的影响。</p>
<h3><span id="一-样本抽样方法">一、样本抽样方法</span></h3>
<p>在《<a href="https://zhuanlan.zhihu.com/p/104872477">外部数据风控建模评估分析</a>》中，我们介绍过外部数据的一些基本知识，其测算流程大致如图1所示。</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-df9f69bec553a3a250bfe6e381c5f116_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>在测算外部数据前，第一步非常重要，样本是我们一切分析的载体。<strong>由于三方数据服务商一般只能提供有限的测试量（比如10w）</strong>，那么我们只能从业务样本中进行抽样。那么可以采取哪些抽样方法呢？一般有以下几种：</p>
<h4><span id="11简单随机抽样保持内部真实好坏比例">1.1
<strong>简单随机抽样，保持内部真实好坏比例。</strong></span></h4>
<ul>
<li>好处：建模时可以直接评估模型效果，而不需要考虑<strong>==bad
rate==</strong>失真。</li>
<li>坏处：好坏样本严重不均衡，坏样本总是极少量的，我们可能需要逐月评估单变量和模型KS，以此观察区分度的稳定性。<strong>此时，坏样本较少，导致结果失去统计意义，波动较大</strong></li>
</ul>
<figure>
<img src="https://pic1.zhimg.com/80/v2-0a9b3fd0245488edde868b0e3da6fb6c_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="12好坏分层抽样好样本n1抽样坏样本11抽样">1.2
<strong><font color="red">
好坏分层抽样，好样本N:1抽样，坏样本1:1抽样。</font></strong></span></h4>
<p>比如，<strong>假设内部bad
rate是5%</strong>，也就是好坏比例约为20:1，那么从20个好样本中随机抽1个，坏样本则全部保留。<strong>由此，我们在评估真实bad
rate捕捉率时，也可以按此权重进行还原。即，1个好样本代表20个原始好样本。</strong></p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-ab77a0e880b5a0c4436af3162be4802e_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="13按资质对客群分层再分层随机抽样">1.3
<strong>按资质对客群分层，再分层随机抽样。</strong></span></h4>
<p>具体操作方法为：</p>
<ol type="1">
<li>以某段时间窗的样本训练一个排序模型，例如风险模型（PD），或过退模型（AR）。</li>
<li>对这个时间窗外待抽样的样本进行排序，将人群分为若干个分层。</li>
<li>分层抽样，每组中相同比例。</li>
</ol>
<p>这样就可以用来建立适应不同客群的信用分。</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-d7b8e0930bde34c4703d2794e6d76c87_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>这三种方案里，我们最常采用方案二。因此，本文以该方案为例进行探讨。</p>
<h3><span id="二-lift和ks指标介绍"><strong>二、Lift和KS指标介绍</strong></span></h3>
<p>Lift, 名称为提升度, 其含义为：经过某种排序后圈出来的坏人浓度,
相对于随机抽样的坏人浓度的提升, 即: <span class="math display">\[
L i f t=\frac{cover-bad-rate}{total-bad-rate}
\]</span> 举例说明, 如图5所示, 现在有 50 个人, 其中 5 个坏人,
那么整体坏人占比为 <span class="math inline">\(10 \%\)</span>
。我们将其随机分为 5 组, 每组 10 人，则理想情况下，每组中有 1
个坏人。</p>
<p>现在我们拥有一个排序模型, 对这 50 个人排序后, 我们笑选出分数最低的 10
个人, 也就是第一组, 此时能抓住 2 个 坏人, 坏人浓度为 <span class="math inline">\(20 \%\)</span> 。那么 lift <span class="math inline">\(=20 \% / 10 \%=2\)</span> 。</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-79b9b1a9ce8a45b1cd3fb70d69da0b63_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>在反欺诈场景中，我们常会用到Lift这个指标来判断规则的有效性</strong>。在测试外部数据时，我们会发现有些变量的区分度虽然很低，或者查得率很低，但是其查得人群的坏人捕捉率却很高。这对我们如何进行规则发现也是一个启发。</p>
<p>KS指标的含义详见：《<a href="https://zhuanlan.zhihu.com/p/79934510">区分度评估指标(KS)深入理解应用</a>》</p>
<h3><span id="三-抽样对lift指标的影响">三、抽样对Lift指标的影响</span></h3>
<p>现在我们有这样一个场景，在抽样样本上我们制定一个阈值cutoff，高于这个阈值则通过(PS)，低于这个阈值则拒绝(RJ)。在抽样样本上，我们测算拒绝部分的坏人lift，那么在原始样本上，相应的lift是多少呢？</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-8fe85db67a0419fc8e0877a85e254cb4_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>我们按照lift的定义来推导所带来的影响。 <span class="math display">\[
\begin{aligned}
&amp; L i f t=\frac{B a d_{r j} / R J}{\left(B a d_{r j}+B a d_{p
s}\right) /(R J+P S)} \\
&amp; =\frac{B a d_{r j}}{R J} \times \frac{R J+P S}{B a d_{r j}+B a
d_{p s}} \\
&amp; =\frac{B a d_{r j}}{\operatorname{Bad}_{r j}+\operatorname{Bad}_{p
s}} \times \frac{R J+P S}{R J} \\
&amp; =\frac{B a d_{r j}}{B a d_{r j}+B a d_{p s}} \times\left(1+\frac{P
S}{R J}\right) \\
&amp;
\end{aligned}
\]</span> 其中: - <span class="math inline">\(B a d_{r j}\)</span> :
拒绝部分的真实坏样本数 - <span class="math inline">\(\operatorname{Good}_{r j}\)</span> :
拒绝部分的真实好样本数 - <span class="math inline">\(B_{p s}\)</span>
：通过部分的真实坏样本数 - <span class="math inline">\(\operatorname{Good}_{p s}\)</span> :
通过部分的真实好样本数</p>
<p>由于全部保留 <span class="math inline">\(B a d\)</span> 样本,
同时采用相同的cutoff, 那么 <span class="math inline">\(B a d_{r
j}\)</span> 和 <span class="math inline">\(B a d_{p s}\)</span>
在抽样前后保持不变。同时, 不可能有 完美的模型, 因此无论是 <span class="math inline">\(R J\)</span> 还是 <span class="math inline">\(P
S\)</span> 中都有好坏样本，即: <span class="math display">\[
\begin{aligned}
&amp; R J=B_{a d_{r j}}+\operatorname{Good}_{r j} \\
&amp; P S=\operatorname{Bad}_{p s}+\operatorname{Good}_{p s}
\end{aligned}
\]</span> 由于简单随机抽样, 假设抽样比例为 rate，那么: <span class="math display">\[
\text { Good }_{\text {sample }}=\text { Good }_{\text {origin }} \times
\text { rate }
\]</span>
同时，在相同的cutoff下，也就是相同的标准下，抽样和原始样本中的好样本比例应该相同，即：
<span class="math display">\[
\begin{aligned}
&amp; \text { Good }_{r j \_} \_ \text {sample }=\text { Good }_{r j \_}
\_ \text {origin } \times \text { rate } \\
&amp; \text { Good }_{p s \_} \text {sample }=\text { Good }_{p s \_} \_
\text {origin } \times \text { rate } \\
&amp;
\end{aligned}在抽样样本上：
\]</span> 在抽样样本上: <span class="math display">\[
\begin{aligned}
&amp; L i f t_{s a m p l e}=\frac{B a d_{r j}}{B a d_{r j}+B a d_{p s}}
\times\left(1+\frac{P S_s}{R J_s}\right) \\
&amp; =\frac{B a d_{r j}}{B a d_{r j}+B a d_{p s}} \times\left(1+\frac{B
a d_{p s}+\operatorname{Good}_{p s}}{B a d_{r j}+\operatorname{Good}_{r
j}}\right)
\end{aligned}
\]</span> 在原始样本上: <span class="math display">\[
\begin{aligned}
&amp; =\frac{B a d_{r j}}{\operatorname{Bad}_{r j}+\text { Bad }_{p s}}
\times\left(1+\frac{\text { Bad }_{p s}+\text { Good }_{p s} / \text {
rate }}{\operatorname{Bad}_{r j}+\text { Good }_{r j} / \text { rate
}}\right) \\
&amp; =\frac{B a d_{r j}}{\operatorname{Bad}_{r j}+\operatorname{Bad}_{p
s}} \times\left(1+\frac{\text { rate } \times \operatorname{Bad}_{p
s}+\operatorname{Good}_{p s}}{\text { rate } \times
\operatorname{Bad}_{r j}+\operatorname{Good}_{r j}}\right) \\
&amp;
\end{aligned}
\]</span> <strong><font color="red"> 对比公式（6）和
（7），我们发现，原始样本上的lift完全可以通过抽样分布上的值进行计算。我们再以实验佐证理论，发现几乎是一样的。</font></strong>造成些许差异的原因可能是样本量。</p>
<h3><span id="四-抽样对ks指标的影响">四、抽样对KS指标的影响</span></h3>
<p>在《<a href="https://zhuanlan.zhihu.com/p/79934510">区分度评估指标(KS)深入理解应用</a>》中，我们认识了KS的计算原理。那么对于随机抽样而言，好人分布和坏人分布是相互独立的，那么在计算累积好样本分布和累积坏样本分布时，理论上KS不应该发生变化。</p>
<p><strong>数据胜于雄辩。首先对好样本5:1抽样，坏样本则保持1:1不变</strong>，由此组成新样本集。</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-b6e2797c944acffa0209c745afcbc03e_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>接下来，我们对比抽样前后的KS差异，如图8所示。结果并无明显区别。</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-6cad55ad53f392de06b951e151f87f6d_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>因此，结论为：<strong>分层抽样不会改变KS</strong>，抽样样本与原始样本上计算的KS相同。在实践中，我们可能因为坏样本过少等原因会影响一些差异，但整体无明显差异。</p>
<h3><span id="五-总结">五、<strong>总结</strong></span></h3>
<p>在匹配外部数据后，我们在抽样样本上会进行一些测算，同时希望能还原在真实原始样本上的结果。针对一些模型指标（Lift、KS）的在抽样前后变化情况，结论为：</p>
<ul>
<li><strong>lift指标数值将会发生变化，但可以换算得到。</strong></li>
<li><strong>ks指标不会发生变化，但需要保证样本量足够。</strong></li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（3）技术算法-PU Learning</title>
    <url>/posts/387JGHJ/</url>
    <content><![CDATA[<h2><span id="pulearning在风控中的应用理论篇">PU
Learning在风控中的应用（理论篇）</span></h2>
<h4><span id="一-风控业务背景">一、风控业务背景</span></h4>
<p>在实际分类场景中，我们经常会遇到类似这样的问题：<strong>只有已标记的正样本，以及未标记的样本</strong>。比如金融风控场景，只有部分用户被标记为欺诈用户，剩下的大量用户未被标记。虽然这其中大多数信用良好，但仍有少量可能为欺诈用户。</p>
<p>为了方便操作，我们可以将未标记的样本都作为负样本进行训练，但存在几个缺陷：</p>
<ol type="1">
<li>正负样本极度不平衡，负样本数量远远超过正样本，效果很差。</li>
<li>某些关键样本会干扰分类器的最优分隔面的选择，尤其是SVM。</li>
</ol>
<p>如何辨别未标记样本中的正负样本，提升模型准确度，就成为一个值得思考的问题。PU
Learning就是解决这种场景的一种学习方法。</p>
<p>本文尝试回答以下几个问题：</p>
<ul>
<li>我们如何将从PU数据中学习的问题形式化？</li>
<li><strong>通常对PU数据进行哪些假设以便于学习算法的设计？</strong></li>
<li><strong>我们可以从PU数据估计类先验吗？为什么这很有用？</strong></li>
<li><strong>我们如何从PU数据中学习模型？</strong></li>
<li><strong>我们如何在PU环境中评估模型？</strong></li>
<li>PU数据何时以及为什么出现在实际应用中？</li>
<li>PU学习与机器学习的其他领域有什么关系？</li>
</ul>
<p><strong>数学符号含义速查</strong>： <span class="math inline">\(x\)</span> ：某样例的特征向量, <span class="math inline">\(x \in \boldsymbol{x}\)</span></p>
<p><span class="math inline">\(y\)</span> : 某样例的标签变量, <span class="math inline">\(y \in \boldsymbol{y}=\{0,1\}\)</span></p>
<p><span class="math inline">\((\boldsymbol{x}, \boldsymbol{y})\)</span>
: 某样本二元组</p>
<p><span class="math inline">\(s\)</span> : 某样例是否被标注的指示变量,
<span class="math inline">\(s \in s=\{0,1\}\)</span></p>
<p><span class="math inline">\(\alpha\)</span> ：先验类别（Class
Prior)， <span class="math inline">\(\alpha=\operatorname{Pr}(y=1)\)</span>
，指正类别先验比例</p>
<p><span class="math inline">\(c\)</span> : 标签频率（Label Frequency)，
<span class="math inline">\(c=\operatorname{Pr}(s=1 \mid y=1)\)</span>,
指L集合占总体P集的比例 <span class="math inline">\(e\)</span> :
倾向评分函数 (Propensity Score) , <span class="math inline">\(e(x)=\operatorname{Pr}(s=1 \mid y=1,
x)\)</span></p>
<p><span class="math inline">\(f(x)\)</span> :
总体样本的概率密度分布函数, <span class="math inline">\(\quad
f(x)=\operatorname{Pr}(x \mid y \in\{0,1\})\)</span></p>
<p><span class="math inline">\(f_{+}(x)\)</span> :
正样本的概率密度分布函数, <span class="math inline">\(\quad
f_{+}(x)=\operatorname{Pr}(x \mid y=1)\)</span></p>
<p><span class="math inline">\(f_{-}(x)\)</span> :
负样本的概率密度分布函数, <span class="math inline">\(\quad
f_{-}(x)=\operatorname{Pr}(x \mid y=0)\)</span></p>
<p><span class="math inline">\(f_l(x)\)</span> : 有标签 (labeled)
样本的概率密度分布函数, <span class="math inline">\(\quad
f_l(x)=\operatorname{Pr}(x \mid s=1) \subset f_{+}(x)\)</span></p>
<p><span class="math inline">\(f_u(x)\)</span> : 无标签 (unlabeled)
样本的概率密度分布函数， <span class="math inline">\(\quad
f_u(x)=\operatorname{Pr}(x \mid s=0)\)</span></p>
<p><span class="math inline">\(\hat{\theta}\)</span> : 对参数 <span class="math inline">\(\theta\)</span> 的估计值</p>
<p><span class="math inline">\(P:\)</span> 正样本集, Positive,
已标注的正样本</p>
<p><span class="math inline">\(N\)</span> : 负样本集, Negative,
实际末知</p>
<p><span class="math inline">\(L\)</span> : 有标签样本集, Labeled,
只有正样本</p>
<p><span class="math inline">\(U\)</span> : 无标签样本集, Unlabeled,
包括末知的正负样本</p>
<p><span class="math inline">\(P U:\)</span>
正样本和无标签样本组成的集合</p>
<p><span class="math inline">\(R N\)</span> : 可靠的负样本</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（3）技术算法-评分卡基础</title>
    <url>/posts/1EHB2HT/</url>
    <content><![CDATA[<h2><span id="评分卡基础逻辑回归算法理解">评分卡基础—逻辑回归算法理解</span></h2>
<h4><span id="风控业务背景"><strong>风控业务背景</strong></span></h4>
<p>逻辑回归（Logistic
Regression，LR）是建立信贷金融评分卡的重要模型，其具有形式简单、易于解释、鲁棒性强等优点。然而，很多建模同学并不是很清楚其原理。本文尝试对逻辑回归基础加以分析理解。</p>
<blockquote>
<p>目录 Part 1. 从线性回归到逻辑回归 Part 2. 为什么采用sigmoid函数 Part
3. 利用极大似然估计法估计参数 Part 4. 最优化问题求解之梯度下降法 Part 5.
正则项的作用和种类 Part 6. 总结 致谢 版权声明 参考资料</p>
</blockquote>
<h3><span id="一-从线性回归到逻辑回归">一、从线性回归到逻辑回归</span></h3>
<p>线性模型是指对各种属性进行<strong>线性加权</strong>组合的函数：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=f%28%5Cpmb+%7Bx%7D%29+%3D+w_%7B1%7Dx_%7B1%7D+%2B+w_%7B2%7Dx_%7B2%7D+%2B+...+%2B+w_%7Bn%7D+x_%7Bn%7D+%2B+b+%5C%5C+%3D+%5Cpmb%7Bw%7D%5ET%5Cpmb%7Bx%7D+%2B+b++%5Ctag%7B1%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>这一过程将信息进行整合；不同的权重(weight)反映了自变量对因变量不同的贡献程度
。线性回归（Liner
Regression）具有广泛应用，例如：预测房价、天气等等。</p>
<p><strong><font color="red">
但在实际应用中，很多人会忽略线性回归的几大假设：</font></strong></p>
<ul>
<li><strong>零均值假设</strong>：随机误差项均值为0。</li>
<li><strong>同方差假设</strong>：随机误差项方差相同。若满足这一特性，称模型具有<strong>同方差性</strong></li>
<li><strong>残差 <img src="https://www.zhihu.com/equation?tex=%5Cvarepsilon" alt="[公式]">
服从正态分布 <img src="https://www.zhihu.com/equation?tex=N%28%5Cmu%2C+%5Csigma%5E2%29" alt="[公式]"></strong></li>
<li><strong>无自相关假设</strong>：若不满足这一特性，称模型具有<strong>自相关性</strong>（Autocorrelation）。</li>
<li>...</li>
</ul>
<p>显然，线性回归的输出结果 <img src="https://www.zhihu.com/equation?tex=f%28%5Ctextbf%7Bx%7D%29+%5Cin+%28-%5Cinfty%2C+%5Cinfty%29" alt="[公式]">
。那如果要做分类呢？我们就考虑将线性回归的输出与分类任务的真实标签 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]">联系起来，即再找一个映射函数。</p>
<p>我们采用一个 <img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]"> 函数（也叫对数几率）：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=+f%28z%29+%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D++%5Ctag%7B2%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其函数图像如图2所示，直观感受其优美的姿态，对称、平滑，且输出 <img src="https://www.zhihu.com/equation?tex=+f%28z%29+%5Cin+%280%2C1%29" alt="[公式]"> .</p>
<p><img src="https://pic2.zhimg.com/80/v2-4b114919fe629cb80abcdfd949e73869_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>我们尝试把 <img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]"> 函数模块拼接到线性回归的输出后面，如图3所示。</p>
<p><img src="https://pic4.zhimg.com/80/v2-d48c12be1ae99fd3008ea54e242be983_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>把图3用公式表达，也就是在 <img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]">
函数内嵌套一个线性回归：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=f%28%5Cpmb%7Bx%7D%29%3D+%5Cfrac%7B1%7D%7B1+%2B+e%5E-%7B%28%5Cpmb%7Bw%7D%5ET%5Cpmb%7Bx%7D+%2B+b%29%7D%7D+%5Ctag%7B3%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>我们再将其变换得到逻辑回归的另一种常见形式：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=+ln+%5Cfrac%7Bp%28y%3D1%7C%5Cpmb%7Bx%7D%29%7D%7B1%E2%88%92p%28y%3D1%7C%5Cpmb%7Bx%7D%29%7D+%3D+%7B%5Cpmb%7Bw%7D%5ET%5Cpmb%7Bx%7D+%2B+b%7D+%5Ctag%7B4%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>为什么要这样做呢？这是因为右边就是线性回归，而左边则引入了 <img src="https://www.zhihu.com/equation?tex=odds" alt="[公式]"> (几率)
的概念，即<strong>事件发生概率相对于不发生概率的比值。</strong></p>
<p>显然可以得到正负样例的概率表达式：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=p%28y%3D1%7C%5Cpmb%7Bx%7D%29+%3D++%5Cfrac%7Be%5E%7B%5Cpmb%7Bw%7D%5ET%5Cpmb%7Bx%7D+%2B+b%7D%7D%7B1+%2B+e%5E%7B%5Cpmb%7Bw%7D%5ET%5Cpmb%7Bx%7D+%2B+b%7D%7D+%5C%5C+p%28y%3D0%7C%5Cpmb%7Bx%7D%29+%3D++%5Cfrac%7B1%7D%7B1+%2B+e%5E%7B%5Cpmb%7Bw%7D%5ET%5Cpmb%7Bx%7D+%2B+b%7D%7D+%5Ctag%7B5%7D+" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h3><span id="二-为什么采用sigmoid函数">二、为什么采用sigmoid函数</span></h3>
<blockquote>
<p>根本原因：</p>
<p>函数优点：</p>
</blockquote>
<p>至此，你可能会有疑问：为什么这里就直接选择了<img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]">
函数？如果只是为了将输出结果从 <img src="https://www.zhihu.com/equation?tex=%28-%5Cinfty%2C+%5Cinfty%29" alt="[公式]"> 映射到 <img src="https://www.zhihu.com/equation?tex=%280%2C+1%29" alt="[公式]">
，完全可以选择其他函数，比如单位阶跃函数：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=p%28y%3D1+%7C+x%29%3D%5Cbegin%7Bcases%7D+0%2C%26+z%5Clt+0+%5C%5C+0.5%2C%26+z+%3D+0%5C%5C+1%2C%26+z%5Cgt+0%5C+%5Cend%7Bcases%7D+%2C%5Cquad+z%3Dw%5ET+x%2Bb++%5Ctag%7B6%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>若预测值 <img src="https://www.zhihu.com/equation?tex=z+%3E0" alt="[公式]"> 则判为正例， <img src="https://www.zhihu.com/equation?tex=z+%3C+0" alt="[公式]">
则判为负例， <img src="https://www.zhihu.com/equation?tex=z+%3D+0" alt="[公式]">
则可任意判别。你可能会说，这个阶跃函数不可微，也无法像<img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]">
函数那样输出概率。这就冒出两个问题：</p>
<ol type="1">
<li><strong>为什么这个映射函数一定要求可微？</strong></li>
<li><strong>为什么 <img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]"> 函数输出值可以代表概率？</strong></li>
</ol>
<p>首先，我们先分析 <img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]">
函数的基本性质：</p>
<ol type="1">
<li>定义域：<img src="https://www.zhihu.com/equation?tex=%28-%5Cinfty%2C+%5Cinfty%29" alt="[公式]"></li>
<li>值域：<img src="https://www.zhihu.com/equation?tex=%280%2C1%29" alt="[公式]"></li>
<li>函数在定义域内为连续和光滑函数</li>
<li>处处可导，导数为 <img src="https://www.zhihu.com/equation?tex=f%E2%80%B2%28x%29%3Df%28x%29%281%E2%88%92f%28x%29%29" alt="[公式]"> ，以下是推导过程：</li>
</ol>
<figure>
<img src="https://www.zhihu.com/equation?tex=f%27%28x%29%3D%5B%5Cfrac%7B1%7D%7B1%2Be%5E%7B-x%7D%7D%5D%27+%3D%5Cfrac%7B1%27%C2%B7%281%2Be%5E%7B-x%7D%29-1%C2%B7%281%2Be%5E%7B-x%7D%29%27%7D%7B%281%2Be%5E%7B-x%7D%29%5E%7B2%7D%7D+%5C%5C+%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-x%7D%7D-%5Cfrac%7B1%7D%7B%281%2Be%5E%7B-x%7D%29%5E%7B2%7D%7D++%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-x%7D%7D+%281-%5Cfrac%7B1%7D%7B1%2Be%5E%7B-x%7D%7D%29+%5C%5C+%3Df%28x%29%5B1-f%28x%29%5D+%5Ctag%7B7%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>可以看到，<img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]">
函数确实具有很多优点，但这仍不是我们选择它的<strong>根本原因</strong>。这是因为，我们仍可以找到一些与之类似性质的函数。</p>
<h4><span id="根本原因">根本原因：</span></h4>
<p>由于逻辑回归本质上属于线性模型，我们尝试<strong>从广义线性模型（Generalized
Linear
Model，GLM）角度入手解释</strong>。前文提到，<strong>线性回归存在诸多假设，实际应用中往往无法满足</strong>。这就会有以下问题：</p>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=y" alt="[公式]">
的取值范围 <img src="https://www.zhihu.com/equation?tex=%28-%5Cinfty%2C+%5Cinfty%29" alt="[公式]"> 与某些场景矛盾。例如，要求 <img src="https://www.zhihu.com/equation?tex=y+%5Cin+%280%2C%5Cinfty%29" alt="[公式]">
。假设一个线性回归模型预测当温度下降10摄氏度，沙滩上的游客将减少1000人。那么，如果当前20摄氏度时，沙滩上只有50人，按此模型预测，当温度为10摄氏度时，沙滩上便有-950人。这显然不符合常理，因为人数不能为负数。</li>
<li>残差 <img src="https://www.zhihu.com/equation?tex=%5Cvarepsilon" alt="[公式]"> 服从正态分布 <img src="https://www.zhihu.com/equation?tex=N%28%5Cmu%2C+%5Csigma%5E2%29" alt="[公式]"> ，且要求方差 <img src="https://www.zhihu.com/equation?tex=%5Csigma%5E2" alt="[公式]">
是常数。但有时，均值 <img src="https://www.zhihu.com/equation?tex=%5Cmu" alt="[公式]"> 越大，我们越预测不准确（方差 <img src="https://www.zhihu.com/equation?tex=%5Csigma%5E2" alt="[公式]">
越大）。</li>
</ul>
<p><strong>为了解决这些局限性，后人发展了GLM，用以提高线性模型的普适性。</strong></p>
<blockquote>
<p>GLM允许因变量 <span class="math inline">\(y\)</span>
的分布<strong>并不一定要服从正态分布</strong>，而可以服从其它分布。</p>
</blockquote>
<p><strong>广义线性模型GLM由三要素组成, 即：</strong></p>
<ul>
<li><p><strong>概率分布</strong> (Probability distribution) : 指因变量
<span class="math inline">\(y\)</span> 的分布假设,
来自指数分布族。</p></li>
<li><p><strong>线性预测</strong> (Linear predictor) : 自变量的线性组合,
即 <span class="math inline">\(\eta=\boldsymbol{X}
\boldsymbol{\beta}\)</span></p></li>
<li><p><strong>链接函数</strong> (Link function) : 通过均值 <span class="math inline">\(\mu\)</span> 来链接前两者, 即 <span class="math inline">\(E(Y)=\mu=g^{-1}(\eta)\)</span>
<img src="/Users/apple/Library/Application Support/typora-user-images/image-20220708133222814.png" alt="image-20220708133222814" style="zoom:50%;"></p>
<p><strong>首先分析概率分布。对于只有单个参数 <span class="math inline">\(\theta\)</span> 的指数分布族的通用形式为:</strong>
<span class="math display">\[
f(x \mid \theta)=h(x) \exp (\eta(\theta) \cdot T(x)-A(\theta))
\]</span> 其中, <span class="math inline">\(h(x)\)</span> 和 <span class="math inline">\(T(x)\)</span> 只是关于自变量 <span class="math inline">\(x\)</span> 的函数； <span class="math inline">\(\eta(\theta)\)</span> 和 <span class="math inline">\(A(\theta)\)</span> 只是关于末知参数 <span class="math inline">\(\theta\)</span> 的函数。
不同的线性模型具有不同的分布假设。比如：</p></li>
<li><p><strong><font color="red"> 线性回归假设 <span class="math inline">\(y\)</span> 的残差 <span class="math inline">\(\varepsilon\)</span> 服从正态分布 <span class="math inline">\(N\left(\mu,
\sigma^{2}\right)\)</span></font></strong></p></li>
<li><p><strong><font color="red"> 逻辑回归假设 <span class="math inline">\(y\)</span> 服从伯努利分布
(Bernoulli)</font></strong></p></li>
</ul>
<p>接下来，我们尝试：</p>
<ol type="1">
<li>将逻辑回归因变量 <span class="math inline">\(y\)</span> 变换到式
<img src="https://www.zhihu.com/equation?tex=%288%29" alt="[公式]">
的形式，确定以上几个函数，验证其属于指数分布族。</li>
<li>求解出逻辑回归对应的链接函数。注意，此时我们<strong>还没有认可sigmoid函数</strong>。⚠️</li>
</ol>
<p><strong>由于逻辑回归假设 <span class="math inline">\(y\)</span>
服从伯努利分布（<a href="https://link.zhihu.com/?target=https%3A//encyclopedia.thefreedictionary.com/Bernoulli%2Bdistribution">Bernoulli</a>），即：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Beqnarray%2A%7D++%26%26+f%28x%7Cp%29+%3D+p%5Ex+%281-p%29%5E%7B1-x%7D+%5C%5C++%26%26+%3D++%5Cexp%28x%2Alnp+%2B+%281-x%29%2Aln%281-p%29%29+%5C%5C+%26%26+%3D%5Cexp%28ln%28%5Cfrac%7Bp%7D%7B1-p%7D%29+%2A+x+%2B+ln%281-p%29%29+%5C%5C++%26%26%3D%5Cexp%28%CE%B7%2Ax+%2B+ln%281%2Be%5E%CE%B7%29%29+%5C%5C+%26%26+Let%3A+%CE%B7%3Dln%28%5Cfrac%7Bp%7D%7B1-p%7D%29++%5Cend%7Beqnarray%2A%7D+%5Ctag%7B9%7D+" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>对比式 <img src="https://www.zhihu.com/equation?tex=%288%29" alt="[公式]"> 指数函数族的通用形式，我们发现：</p>
<ul>
<li><figure>
<img src="https://www.zhihu.com/equation?tex=h%28x%29+%3D+1%EF%BC%8CT%28x%29%3Dx" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure></li>
<li><figure>
<img src="https://www.zhihu.com/equation?tex=%5Ceta%28p%29%3Dln%28%7Bp%7D%2F%281-p%29%29%2C+A%28p%29+%3D+-ln%281%2Be%5E%CE%B7%29" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure></li>
</ul>
<p><strong>这说明伯努利分布也是指数分布族（<a href="https://link.zhihu.com/?target=https%3A//encyclopedia.thefreedictionary.com/Exponential%2Bfamily">exponential
family</a>）的成员。按GLM的第二要素定义：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Ceta+%3D+%5Cpmb%7BX%7D+%5Cpmb%7B%5Cbeta%7D+%5C%5C+%5CRightarrow+ln%28%5Cfrac%7Bp%7D%7B1-p%7D%29+%3D+%5Cpmb%7BX%7D+%5Cpmb%7B%5Cbeta%7D+%5Ctag%7B10%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>我们再计算 <img src="https://www.zhihu.com/equation?tex=%5Ceta%28p%29%3Dln%28%7Bp%7D%2F%281-p%29%29" alt="[公式]"> 的反函数，就得到了<img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]">
函数：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=f%28x%29+%3D+%5Cfrac%7B1%7D%7B1%2B+e%5E%7B-x%7D%7D+%5Ctag%7B11%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>按类似方法，我们可以推导出各分布函数及其链接函数，如图5所示。</p>
<p><img src="https://pic1.zhimg.com/80/v2-ffe75b45239773e6245b00b78c65d908_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p><strong>从广义线性模型角度，我们确实推导出 <img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]">函数与逻辑回归之间密不可分的联系。但是，sigmoid函数输出值为什么可以代表概率？</strong></p>
<p><strong><font color="red"> 上文提到，逻辑回归中因变量 <span class="math inline">\(y\)</span> 服从伯努利分布，而伯努利分布的参数 <img src="https://www.zhihu.com/equation?tex=p" alt="[公式]">
的含义就是样例属于 <img src="https://www.zhihu.com/equation?tex=y+%3D+1" alt="[公式]"> 的概率。</font></strong></p>
<h3><span id="三-利用极大似然估计法估计参数">三、利用极大似然估计法估计参数</span></h3>
<p>在模型参数估计问题上，两大主流学派持有不同观点：</p>
<ul>
<li><strong>频率主义学派（Frequentist）：</strong>
<strong>认为参数虽然未知，但却是客观存在的固定值</strong>。因此，可通过优化似然函数等准则估计参数值。</li>
<li><strong>贝叶斯学派（Bayesian）： </strong>
<strong>认为参数是未观察到的随机变量，其本身也可有分布</strong>。因此，可假定参数服从一个先验分布，再基于观察到的数据来计算参数的后验分布。</li>
</ul>
<p><strong>极大似然估计法（Maximum Likelihood
Estimation，MLE）属于频率主义学派方法，其蕴含的朴素思想在于：</strong></p>
<p>我们已经确定了一个模型种类 <img src="https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D%28x%7C%5Ctheta%29" alt="[公式]"> ，但还不清楚其真实参数 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]">
。既然目前观察样本已经出现，那么就<strong>由果溯因</strong>，估计出一组参数
<img src="https://www.zhihu.com/equation?tex=%5Chat+%7B%5Ctheta%7D" alt="[公式]">
，使得出现目前结果的可能性<strong>最大</strong>（优化目标)，如图6所示。</p>
<p>由于一组样本中的所有样例是一个整体，因此我们<strong>将各样例的概率相乘</strong>（排列组合中的乘法原理）来得到我们的目标函数。</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-13bed4bb32c44c57bdde2cc772a34184_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>我们把第 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]"> 个样例的类别属于 <img src="https://www.zhihu.com/equation?tex=y%3D1" alt="[公式]">
的概率记为： <img src="https://www.zhihu.com/equation?tex=P%28y%3D1%7C+%5Cpmb%7Bx%7D_i%29+%3D+p%28+%5Cpmb%7Bx%7D_i%7C+%5Cpmb%7Bw%7D+%29" alt="[公式]"> .</p>
<p>现在，我们有观测样本 <img src="https://www.zhihu.com/equation?tex=+D%3D%5C%7B%28+%5Cpmb%7Bx%7D_1%2C+y_%7B1%7D%29%2C+%28+%5Cpmb%7Bx%7D_2%2C+y_%7B2%7D%29%2C...%2C%28+%5Cpmb%7Bx%7D_m%2C+y_%7Bm%7D%29%5C%7D%2C+%5Cpmb+x_%7Bi%7D+%5Cin+R%5En" alt="[公式]"> ，那么似然函数为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=L%28%5Cpmb%7Bw%7D%29%3D+%5Cprod_%7Bi%3D1%7D%5E%7Bm%7Dp%28+%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29++%3D+%5Cprod_%7Bi%3D1%7D%5Em+%5Bp%28+%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%5D%5E%7By_%7Bi%7D%7D%5B1-p%28+%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%5D%5E%7B1-y_%7Bi%7D%7D++%5Ctag%7B12%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中，样例 <img src="https://www.zhihu.com/equation?tex=+%5Cpmb%7Bx%7D_i" alt="[公式]"> 具有标签 <img src="https://www.zhihu.com/equation?tex=y_%7Bi%7D+%5Cin+%5C%7B0%2C1%5C%7D" alt="[公式]">
。右边为什么要写成这种形式呢？主要原因在于这是<strong>伯努利分布的常见形式</strong>。按正负样例分析，可以帮助你理解这个形式：</p>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=y_i+%3D+1" alt="[公式]"> 时，<img src="https://www.zhihu.com/equation?tex=%5Bp%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%5D%5E%7By_%7Bi%7D%7D%5B1-p%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%5D%5E%7B1-y_%7Bi%7D%7D+%3D+p%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%5E%7B1%7D%5B1-p%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%5D%5E%7B0%7D+%3D+p%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29" alt="[公式]"></li>
<li><img src="https://www.zhihu.com/equation?tex=y_i+%3D+0" alt="[公式]"> 时，<img src="https://www.zhihu.com/equation?tex=%5Bp%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%5D%5E%7By_%7Bi%7D%7D%5B1-p%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%5D%5E%7B1-y_%7Bi%7D%7D+%3D+p%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%5E%7B0%7D%5B1-p%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%5D%5E%7B1%7D+%3D+1-p%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29" alt="[公式]"></li>
</ul>
<p>为便于求解，将连乘 <img src="https://www.zhihu.com/equation?tex=%5Cprod" alt="[公式]"> 转为
<img src="https://www.zhihu.com/equation?tex=%5Csum" alt="[公式]">
，我们对等式 <img src="https://www.zhihu.com/equation?tex=%2812%29" alt="[公式]"> 两边同取对数 <img src="https://www.zhihu.com/equation?tex=ln" alt="[公式]">
，写成对数似然函数：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=+%5Cbegin%7Baligned%7D+L%28%5Cpmb%7Bw%7D%29%26%3D%5Csum_%7Bi%3D1%7D%5Em%5By_%7Bi%7Dlnp%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%2B%281-y_%7Bi%7D%29ln%281-p%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%29%5D+%5C%5C+%26%3D%5Csum_%7Bi%3D1%7D%5Em%5By_%7Bi%7Dln%5Cfrac%7Bp%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%7D%7B1-p%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%7D%2Bln%281-p%28%5Cpmb%7Bx%7D_i%7C%5Cpmb%7Bw%7D%29%29%5D++%5C%5C++%26%3D%5Csum_%7Bi%3D1%7D%5Em%5By_%7Bi%7D%5Cpmb%7Bw%7D%5ET%5Cpmb%7Bx%7D_i+-+ln%281%2Be%5E%7B%5Cpmb%7Bw%7D%5ET+%5Ccdot+%5Cpmb%7Bx%7D_%7Bi%7D%7D%29%5D+%5C%5C+%26%3D%5Csum_%7Bi%3D1%7D%5Em%5By_%7Bi%7D%5Csum_%7Bj%3D1%7D%5En%28w_i%5Ccdot+x_%7Bi%7D%5E%7B%28j%29%7D%29+-+ln%281%2Be%5E%7B%5Cpmb%7Bw%7D%5ET+%5Ccdot+%5Cpmb%7Bx%7D_%7Bi%7D%7D%29%5D+%5Cend%7Baligned%7D+%5Ctag%7B13%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>我们的优化目标是：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmax+L%28%5Cpmb%7Bw%7D%29+%5C%5C+%5CLeftrightarrow+%5Cmax+J%28%5Cpmb%7Bw%7D%29+%3D++%5Cfrac%7B1%7D%7Bm%7D%28%5Csum_%7Bi%3D1%7D%5Em%28y_%7Bi%7Dln+p%28x_i%7C%5Cpmb%7Bw%7D%29%2B%281-y_i%29+ln%281-p%28x_i%7C%5Cpmb%7Bw%7D%29%29%29+%5C%5C+%5CLeftrightarrow++%5Cmin+J%28%5Cpmb%7Bw%7D%29+%3D+-+%5Cfrac%7B1%7D%7Bm%7D%28%5Csum_%7Bi%3D1%7D%5Em%28y_%7Bi%7Dln+p%28x_i%7C%5Cpmb%7Bw%7D%29%2B%281-y_i%29+ln%281-p%28x_i%7C%5Cpmb%7Bw%7D%29%29%29+%5Ctag%7B14%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>认真考虑后，我们发现并没有其他<strong>约束项。</strong>(事实上，这里将蕴含正则项的思想)</p>
<h3><span id="四-最优化问题求解之梯度下降法">四、最优化问题求解之梯度下降法</span></h3>
<p>回到式 <img src="https://www.zhihu.com/equation?tex=%2814%29" alt="[公式]"> 这个问题中：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmin+J%28%5Cpmb%7Bw%7D%29+%3D+-%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%5By_%7Bi%7D%5Csum_%7Bj%3D1%7D%5Enw_i%5Ccdot+x_%7Bi%7D%5E%7B%28j%29%7D+-+ln%281%2B%5Cexp%28%5Csum_%7Bj%3D1%7D%5Enw_i%5Ccdot+x_%7Bi%7D%5E%7B%28j%29%7D%29%5D+%5Ctag%7B17%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>我们不断重复这一过程：达到某个点 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]">
后，继续计算下一个点 <img src="https://www.zhihu.com/equation?tex=%7Bk%2B1%7D" alt="[公式]">
：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=+w%5E%7Bk%2B1%7D_i+%3Dw%5Ek_i-%5Clambda++%5Cfrac%7B%5Cpartial+J%28%5Ctextbf%7Bw%7D%29%7D+%7B%5Cpartial+w_i%7D+%5Ctag%7B18%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>那么，这个迭代过程何时才能停止呢？一般满足以下任意条件即可：</p>
<ul>
<li>达到迭代次数上限： <img src="https://www.zhihu.com/equation?tex=k+%3D+k_%7Bmax%7D" alt="[公式]"></li>
<li>学习曲线变化很小：<img src="https://www.zhihu.com/equation?tex=+%7C%7CJ%28w%5E%7Bk%2B1%7D%29%E2%88%92J%28w%5Ek%29%7C%7C+" alt="[公式]"> 小于阈值。</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（4）特征工程-时序数据与特征工程</title>
    <url>/posts/2ZK2C8F/</url>
    <content><![CDATA[<h2><span id="特征工程-时序数据与特征工程">特征工程-时序数据与特征工程</span></h2>
<blockquote>
<p>信贷时序数据与特征工程介绍 - 求是汪在路上的文章 - 知乎
https://zhuanlan.zhihu.com/p/397614923</p>
</blockquote>
<h3><span id="引言">引言</span></h3>
<p><strong>无论是模型还是策略，其遵循的方法论都是“发现问题-&gt;确定目标-&gt;分析原因-&gt;寻找抓手-&gt;上线应对”这样一个闭环</strong>。对于模型岗而言，<strong><font color="red">
其核心KPI是提供具有良好排序能力的模型。而特征工程是提高模型区分度的最有效途径，决定了模型拟合的上限。</font></strong></p>
<p>信贷业务流程中积累了很多时间序列数据。因此，<strong>本文将介绍如何利用时序数据来构建常见的特征</strong>。同时，为兼顾实践性，本文附上了一些特征的SQL实现逻辑，供参考。</p>
<h3><span id="一-信贷时序行为数据">一、<strong>信贷时序行为数据</strong></span></h3>
<p>信贷业务经营中会积累很多时间序列数据。例如，<strong>客户的APP登录行为埋点数据、借款申请行为记录数据、还款行为数据、调额记录数据等</strong>。根据是否在平台内部沉淀，这些数据又可分为内部和外部数据。</p>
<h4><span id="11-内部数据">1.1 <strong>内部数据</strong></span></h4>
<p>以借款、还款行为数据为例，需要明确几个最细的时间粒度，包括：</p>
<ul>
<li>借款时点（draw_date）：客户借款申请时点。</li>
<li>应还时点（due_date）：约定还款时间，固定不变。</li>
<li>实还时点（settle_date）：客户实际还款时间，若早于应还日，称提前还款；若晚于应还时点，则成为逾期（overdue）；若在应还日当天还款，则为正常还款。</li>
</ul>
<p>独立来看，每个时点的数据都具有不同的信息。对于借据而已，具有以下属性：</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-bd57625dec1cdc547dc81c05796912d3_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>因此，从借款订单数据入手，其可反映客户的额度使用率、借款金额变化、借款时间集中度等信息。</p>
<p>如图2所示，当把这些时点线索交叉在一起，就会衍生出大量信息。例如：</p>
<ul>
<li><strong>结合应还时点和实还时点，可刻画客户历史上的还款行为，包括逾期、提前还款、正常还款</strong>。——由此可构建“过去一段时间内，<strong>逾期/提前还款/正常还款次数</strong>”这类特征。</li>
<li>结合应还时点和借款时点，如果客户在某个应还时点前多次发起借款申请，那么很可能是在“借新还旧”。——由此可构建“过去一段时间内，应还日前借款次数”这类特征。</li>
<li>结合逾期时点和借款时点，如果客户当前处于逾期状态，则新申请借款则可直接拒绝，或者提前管制客户。</li>
</ul>
<figure>
<img src="https://pic4.zhimg.com/80/v2-45b5c68a863deaf80abafc882e3c3703_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="12-外部数据">1.2 外部数据</span></h4>
<p>客户不仅会在本平台内借款，当无法满足其借款需求时，其也会在其他平台借款，由此形成了多头借款行为数据。这是一块非常宝贵的数据。</p>
<p>在《<a href="https://zhuanlan.zhihu.com/p/109649516">求是汪在路上：多头借贷风险分析与建模</a>》一文中，我们介绍过多头数据的相关知识。整合目前市场上数据商提供的多头数据，我们可分解为以下结构：</p>
<p><img src="https://pic3.zhimg.com/80/v2-bf2f245a96e5f359e82901341f3cae2e_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>在本文中，先构造一些假数据用以后续衍生特征。可通过以下SQL语句建表，并插入数据。</p>
<h3><span id="二-行为特征衍生思路">二、<strong>行为特征衍生思路</strong></span></h3>
<p>如果拥有这样的数据，你会如何构建特征？通常做法是取最近一段时间窗口（比如最近12个月），在这段时间内，我们可以从以下维度来统计出可累加的指标：</p>
<ul>
<li><strong>指标维度</strong>：金额、次数、笔数、天数、机构数、人数</li>
<li><strong>时间粒度</strong>：日、周、月</li>
<li><strong>聚合函数</strong>：计数（count），求和（sum）</li>
</ul>
<p>为什么要是可累加的呢？这是因为我们可以再次聚合，并且后续计算<strong>比例类特征</strong>时方便。由此，可得到如图5所示的时序数据：</p>
<p><img src="https://pic3.zhimg.com/80/v2-68035afb016202fe873d761ce4ecd3ee_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>在《<a href="https://zhuanlan.zhihu.com/p/85440355">求是汪在路上：风控特征—时间滑窗统计特征体系</a>》中，介绍过RFM特征体系的概念。</p>
<ul>
<li><strong>R（Recency）</strong>：<strong>客户最近一次交易消费时间的间隔</strong>。R值越大，表示客户交易发生的日期越久，反之则表示客户交易发生的日期越近。</li>
<li><strong>F（Frequency）</strong>：<strong>客户在最近一段时间内交易消费的次数</strong>。F值越大，表示客户交易越频繁，反之则表示客户交易不够活跃。</li>
<li><strong>M（Monetary）</strong>：<strong>客户在最近一段时间内交易消费的金额</strong>。M值越大，表示客户价值越高，反之则表示客户价值越低。</li>
</ul>
<p><strong>在RFM特征体系的基础上，我们进一步扩展维度</strong>。至少能从图5中捕捉到以下信息：</p>
<p><strong>1）常规统计特征</strong></p>
<p>把客户行为按最小时间粒度统计完毕后，我们就会得到一个分布。接下来则是利用统计函数<strong>最大值（MAX）、最小值（MIN）、平均值（AVG）、标准差（STD）</strong>来描述以上分布特征。</p>
<p>但是，这些指标在统计时只能对给定的数据集合计算，没有考虑到时间序列变化信息。换言之，什么时间段在持续上升，什么时间段在持续下降，什么时间段断档形成空窗期，这些信息都被掩盖了。</p>
<p><strong>2）时间距离特征</strong></p>
<p>用以刻画客户最远一次、最近一次或者某个特殊事件发生的时点。例如：</p>
<ul>
<li>最近一次申请日距离观察点的日期差（天数）</li>
<li>最近一次取到最大值、最小值的事件时点距离观察点的日期差（天数）</li>
<li>最近一次逾期距离观察点的日期差（天数）</li>
</ul>
<p><strong>3）行为波动特征</strong></p>
<p>用以刻画客户某段连续时间内的行为变化特征。例如：</p>
<ul>
<li>最长持续上升（或下降）的时间跨度（天数）。</li>
<li>最长睡眠期（天数）。即，客户多久没有活跃了？</li>
<li>连续行为窗口出现次数。</li>
</ul>
<p><strong>在信贷风控中，变化趋势是衡量风险非常重要的维度。我们喜欢稳定，但是风险天生具有易变性，当有变化的趋势就意味着风险，也意味着机遇。</strong>例如，当客户近期在行业内借款申请次数在上升时，我们就可以判断客户资金紧张，故而在到处借钱。那么，我们需要思考：</p>
<ol type="1">
<li>业务侧：客户是否因为我们的额度不够，无法满足其资金需求而跑到其他平台借款？出于余额增长的目标，我们能不能给客户提额呢？</li>
<li>风险侧：该客户的还款能力是否出现问题？我们给他放开额度后，我们能否承受风险？那么我们就需要给客户打一下风险分，判断客户风险。</li>
</ol>
<p>为捕捉客户行为变化趋势，我们可以用一种简单的方法：<strong>最近N个月次数
/ 最近M个月次数（N &lt;
M）</strong>。例如，多头变量中，该值越高，说明借款申请记录更为集中在近期。一般来说，近期行为对于识别短期欺诈风险更有用，远期行为对于识别长期信用风险更有用。</p>
<p><strong>4）集中度特征</strong></p>
<p><strong>用以刻画客户行为的偏好程度</strong>。如果说时间维度是纵向视角，那么集中度特征则是横截面视角。通常以比例特征形式出现。例如：</p>
<ul>
<li>一天内集中于哪个时间段活动？</li>
<li>借款机构中集中于哪些机构？</li>
<li>借款金额倾向于什么数目（例如1K以内，1K-5K，5K以上）？</li>
<li>购买的商品内集中于买什么品类？</li>
</ul>
<h3><span id="四-其他算法实现思路">四、<strong>其他算法实现思路</strong></span></h3>
<p>前面都是从业务领域知识先入手，分析潜在有用的变量逻辑，再去实现。这是平时大部分模型师所做的事情。但目前也有一些尝试用LSTM、RNN来处理时序数据的技术方案。这是后续可尝试探索和对比的方向。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191712092.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（4）特征工程-变量加工实践经验</title>
    <url>/posts/29H4DXP/</url>
    <content><![CDATA[<h2><span id="特征工程-风控变量加工实践经验">特征工程-风控变量加工实践经验</span></h2>
<blockquote>
<p>风控变量加工实践经验 - 求是汪在路上的文章 - 知乎
https://zhuanlan.zhihu.com/p/479784293</p>
<p>本文总结了风控变量开发过程中的一些实践经验。包括：</p>
<ol type="1">
<li><strong>检查数据一致性，确保数据质量</strong>。</li>
<li><strong>设计好整体架构，提高计算效率</strong>。</li>
</ol>
</blockquote>
<p>我们总在说，<strong>数据决定特征的上限，特征决定模型的上限。</strong>风控决策过程中依托大量变量，这些变量从开发到上线的研发流程如下:</p>
<ol type="1">
<li>风控模型同学先基于离线数据源使用Hive
SQL挖掘一系列变量，经过建模筛选后将变量需求提给开发同学。</li>
<li>开发同学与模型同学一起核对数据源以及变量实现逻辑，将每个变量用Java代码实现。</li>
<li>在线灰度运行，与离线Hive
T+1产出的变量以及模型分数做一致性比对，满足较高的一致性和稳定性后才最终发布。</li>
</ol>
<h3><span id="一-线上线下底层数据一致">一、线上线下底层数据一致</span></h3>
<p>底层数据一致是最根本的要求，其内涵包括两点：</p>
<ul>
<li>线上数据落快照，确保可回溯、不穿越。</li>
<li>线上数据经清洗到线下数据后确保一致。</li>
</ul>
<p><strong>1. 线上数据落快照，确保可回溯、不穿越。</strong></p>
<p>数据资产非常宝贵，一些内部数据早点落快照积累，后期才能进行回溯。在这个过程中，数据穿越问题是最为常见的，其导致的结果是离线分析效果可能很棒，但真正上线后效果一塌糊涂。因此，在做特征变量时都要限制数据采集时间在回溯时点之前。</p>
<p><strong>2. 线上数据经清洗到线下数据后确保一致。</strong></p>
<p><strong>线上数据一般是json这类的半结构化数据，为了离线分析时使用方便，我们通常将其解析为结构化的数据表</strong>。因此，在此转换过程中，有可能会出现字段取值错列、错误等情况，需要进行一致性检查。</p>
<h3><span id="二-离线变量加工注意事项">二、离线变量加工注意事项</span></h3>
<p>在平时业务实践中，我们习惯利用SQL来衍生特征变量，原因在于：</p>
<ul>
<li>SQL可分布式计算，对于海量数据处理上效率更高。</li>
<li>SQL语法较为固定，容易阅读理解；而Python语法灵活，每个人写的代码风格差异很大，较难维护理解。</li>
<li>SQL有大量内置函数（聚合函数、窗口函数等），可省去很多自定义函数的时间。</li>
</ul>
<p>但是，在开发过程中需要注意以下几点：</p>
<p><strong>1.
检查原始字段的取值类型。</strong>对于字符型变量，直接比较时容易出错，如下所示。例如，字符串类型的1000会比800小。因此，在聚合计算风控变量"最近N个月的最大借款金额"时就会出错。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="string">&#x27;1000&#x27;</span> <span class="operator">&gt;</span> <span class="string">&#x27;800&#x27;</span>;</span><br><span class="line"><span class="literal">false</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">3.679</span> seconds, Fetched <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="number">1000</span> <span class="operator">&gt;</span> <span class="number">800</span>;</span><br><span class="line"><span class="literal">true</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.16</span> seconds, Fetched <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">cast</span>(<span class="string">&#x27;1000&#x27;</span> <span class="keyword">as</span> <span class="type">int</span>) <span class="operator">&gt;</span> <span class="built_in">cast</span>(<span class="string">&#x27;800&#x27;</span> <span class="keyword">as</span> <span class="type">int</span>);</span><br><span class="line"><span class="literal">true</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.198</span> seconds, Fetched <span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>
<p><strong>2.
检查原始字段的取值范围。</strong>避免想当然地认为，该变量什么含义就"<strong>应该</strong>"是什么取值，或者完全按照编码文档来写逻辑，一切以实际数据为准。包括但不限于：</p>
<ul>
<li>确认字段正常不应该缺失的情况，确认是否实时数据落库过程中清洗所引起的。</li>
<li>从业务上检查字段含义对应的取值范围，确认脏数据该如何清洗。例如，对于日期类变量，其取值可能有如下格式：</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">datetime.datetime.strptime(<span class="type">date</span>, &quot;%Y-%m-%d %H:%M:%S&quot;)</span><br><span class="line">datetime.datetime.strptime(<span class="type">date</span>, &quot;%Y-%m-%d&quot;)</span><br><span class="line">datetime.datetime.strptime(<span class="type">date</span>, &quot;%Y/%m/%d&quot;)</span><br><span class="line">datetime.datetime.strptime(<span class="type">date</span>, &quot;%Y%m%d&quot;)</span><br><span class="line"></span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span><span class="operator">&gt;</span> <span class="keyword">select</span> to_date(<span class="string">&#x27;2022.03.20&#x27;</span>,<span class="string">&#x27;yyyy.MM.dd&#x27;</span>);</span><br><span class="line"><span class="number">2022</span><span class="number">-03</span><span class="number">-20</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.18</span> seconds, Fetched <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span><span class="operator">&gt;</span> <span class="keyword">select</span> to_date(<span class="string">&#x27;2022/03/20&#x27;</span>,<span class="string">&#x27;yyyy/MM/dd&#x27;</span>);</span><br><span class="line"><span class="number">2022</span><span class="number">-03</span><span class="number">-20</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.119</span> seconds, Fetched <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span><span class="operator">&gt;</span> <span class="keyword">select</span> to_date(<span class="string">&#x27;20220320&#x27;</span>,<span class="string">&#x27;yyyyMMdd&#x27;</span>);</span><br><span class="line"><span class="number">2022</span><span class="number">-03</span><span class="number">-20</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.365</span> seconds, Fetched <span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>
<p><strong>3. 适当定义一些中间变量。</strong>其好处在于：</p>
<ul>
<li>统一维护映射关系，便于维护修改变量口径；</li>
<li><strong>提高计算效率，一次计算可复用，不必多次重复运算</strong>；</li>
<li>便于代码review，结构层次上更为清晰易懂。</li>
</ul>
<p>中间变量适合需要利用多个字段来定义的场景，或者一个字段需要进行较为复杂的计算。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> when recall_date &gt; due_date <span class="keyword">and</span> repay_date = due_date then <span class="string">&quot;已到期,正常还款&quot;</span></span><br><span class="line">     when recall_date &gt; due_date <span class="keyword">and</span> repay_date &lt; due_date then <span class="string">&quot;已到期,提前还款&quot;</span></span><br><span class="line">     when recall_date &gt; due_date <span class="keyword">and</span> (repay_date &gt; due_date <span class="keyword">or</span> repay_date <span class="keyword">is</span> null) then <span class="string">&quot;已到期,逾期还款&quot;</span></span><br><span class="line"><span class="keyword">else</span> <span class="string">&quot;未到期&quot;</span> end <span class="keyword">as</span> repay_state -- 还款状态</span><br></pre></td></tr></table></figure>
<p>对于多人协作的项目，需要大家约定好中间变量口径，避免后续整理文档时出现类似的变量多种口径，引起IT同学混淆。</p>
<p><strong>4. 适当制作一些中间表</strong></p>
<p>其作用在于，采取最小可用数据范围原则，减少计算成本。例如：计算借据层面的字段"最近3个月内的借款次数"，只需要用到借据表的信息，并不需要还款计划表的信息。</p>
<p><strong>5. 确认每张表的主键，保证唯一</strong></p>
<p>SQL中常见的聚合函数包括最大值（max）、最小值（min）、平均值（avg）、计数（count）、标准差（std）、累加（sum）。如果数据记录出现重复，虽然不会影响max、min这些操作，但是会影响其他聚合计算的值。因此，在做中间表的过程中需要明确主键，确保group
by分组的时候是唯一的。</p>
<p><strong>6. 优化SQL代码，提高运行效率。</strong></p>
<p>例如，count(distinct case when 条件 then xxx else xxx
end)操作需要消耗大量资源，可以考虑将when中的条件提前到表的where中，过滤减少数据量，但要注意影响范围，避免误伤到其他变量的计算。</p>
<p><strong>同时，还可以将SQL代码做成工作流（workflow），某些任务可实现并行化运行。</strong></p>
<h3><span id="三-实时变量上线比对验证">三、实时变量上线比对验证</span></h3>
<p>实时变量计算有时效性要求，比如500毫秒内计算出数据。因此，实时变量一般将由IT同学根据文档通过Java开发，在此过程中由于以下原因可能引起变量不一致。</p>
<ul>
<li>离线变量开发口径逻辑，在文档整理过程中的表述歧义。</li>
<li>模型同学和IT同学沟通过程中的理解差异。</li>
<li>Java代码编写过程中存在的Bug。</li>
<li>计算引擎不同所引起的精度差异。</li>
<li>脏数据引起的不一致。</li>
</ul>
<p>为解决SQL离线变量到在线变量之间的翻译工作，目前有相关的实时SQL计算引擎技术，可参考下面这篇：</p>
<p>https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/Rx43XfhgdwerQWLn1eI3Ww</p>
<p>线上线下变量确保一致是非常重要的。其能保证基于离线批量数据所建立的风控模型和策略规则，在上线后能按照预期的效果生效。如果不一致，将会导致风控系统不可控。例如，离线评估得到的模型分数阈值为低于600分则拒绝，但线上模型总是和离线有偏差，600这个阈值将拒绝更多的用户，导致通过率下降。</p>
<p>模型同学需要和IT同学协调来定位变量问题，整个工作流程图如下所示。可以看到这是一个闭环迭代的过程，如何加快迭代速度成为关键。</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-ed93dffab2b80d4711f7a330bada6e59_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>变量一致性比对的逻辑很直接，其依赖于测试数据来归纳排查，当两者出现不一致则必有问题。当然，变量的逻辑正确性和取值一致性是两回事，<strong>逻辑正确性需要业务知识来确认，取值一致性需要技术工具来解决</strong>。</p>
<p><strong>为了尽可能提高比对效率，笔者有以下几点建议：</strong></p>
<p>1）<strong>准备足量测试原始数据，以及离线变量取值结果</strong>。在开发过程中准备一批（如1000条）原始数据json，这批数据必须保证和解析到数据库中的表数据是完全一致的。这样可以确保IT同学在写Java的时候，就可自己测试来消除一部分bug，减少后续工作量。</p>
<p>2）<strong>提前准备好相关不一致案例，预约时间集中排查。</strong>定位问题是一个非常耗时的工作，因此和IT同学约定好大片段的时间，提前准备好一些案例来沟通。案例准备过程可以将变量划分类别，聚类治之可极大提高效率。</p>
<p>3）<strong>整理比对所需要的代码脚本，缩短数据准备时间</strong>。比对过程是迭代中完善的，必然需要多轮数据拉取、计算、整理的工作，把这个流程打通形成工作流可加快速度。</p>
<p>在取数得到线上线下数据集后，可根据附录代码计算得到以下比对报告，如图2所示。我们将比对结果分为以下4种情况：</p>
<ul>
<li>有值且一致：有值并且满足精度一致要求</li>
<li><strong>有值不一致：有值但不满足精度一致要求</strong></li>
<li><strong>缺失不一致：其中有一个为nul</strong>l</li>
<li>缺失且一致：两者取值都为null</li>
</ul>
<p>对于情况1）和情况3）则需要查相应案例来定位原因。<strong>小细节往往能发现大问题</strong>，所以不要轻视。</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-1328321434f790cffff65d6988cbc29c_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="附录a">附录A</span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> multiprocessing.dummy <span class="keyword">import</span> Pool <span class="keyword">as</span> ThreadPool</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compare_online_offline</span>(<span class="params">data_offline,  </span></span><br><span class="line"><span class="params">                           data_online,</span></span><br><span class="line"><span class="params">                           remove_list=[<span class="string">&#x27;order_id&#x27;</span>],</span></span><br><span class="line"><span class="params">                           key_var=<span class="string">&#x27;order_id&#x27;</span>,</span></span><br><span class="line"><span class="params">                           spec_value=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                           filename=<span class="string">&#x27;report.xlsx&#x27;</span>,</span></span><br><span class="line"><span class="params">                           need_detail=<span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line">    t0 = time.time()</span><br><span class="line">    data_online_new  = data_online.copy()</span><br><span class="line">    data_offline_new = data_offline.copy()</span><br><span class="line">    data_offline_new.columns = [i.lower() <span class="keyword">for</span> i <span class="keyword">in</span> data_offline_new.columns]</span><br><span class="line">    data_online_new.columns  = [i.lower() <span class="keyword">for</span> i <span class="keyword">in</span> data_online_new.columns]</span><br><span class="line">    comp_list = <span class="built_in">list</span>(<span class="built_in">set</span>(data_online_new.columns) &amp; <span class="built_in">set</span>(data_offline_new.columns))  <span class="comment"># 取交集</span></span><br><span class="line">    comp_list = <span class="built_in">sorted</span>(<span class="built_in">list</span>(<span class="built_in">set</span>(comp_list).difference(remove_list)))   <span class="comment"># 比较列</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;比较特征数量为: &#x27;</span> + <span class="built_in">str</span>(<span class="built_in">len</span>(comp_list)))</span><br><span class="line">    num_varlist = <span class="built_in">list</span>(<span class="built_in">set</span>(data_online_new[comp_list].select_dtypes(exclude=[<span class="string">&#x27;object&#x27;</span>,<span class="string">&#x27;datetime&#x27;</span>]).columns))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compare</span>(<span class="params">x1, x2, vartype</span>):</span><br><span class="line">        <span class="keyword">if</span> pd.notna(x1) <span class="keyword">and</span> pd.notna(x2):</span><br><span class="line">            <span class="keyword">if</span> vartype == <span class="string">&#x27;numeric&#x27;</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> <span class="built_in">abs</span>(x1 - x2) &lt; <span class="number">0.001</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span> <span class="keyword">if</span> x1 == x2 <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">        <span class="keyword">else</span>:  </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> pd.notna(x1) <span class="keyword">and</span> <span class="keyword">not</span> pd.notna(x2):</span><br><span class="line">                <span class="keyword">return</span> <span class="number">3</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> np.nan</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">stat</span>(<span class="params">var</span>):</span><br><span class="line">        df = pd.merge(data_offline_new[[key_var,var]], data_online_new[[key_var,var]], on=key_var, how=<span class="string">&#x27;inner&#x27;</span>)</span><br><span class="line">        df.columns = [key_var, var+<span class="string">&#x27;_offline&#x27;</span>, var+<span class="string">&#x27;_online&#x27;</span>] </span><br><span class="line">        total = df.shape[<span class="number">0</span>]</span><br><span class="line">        miss_offline = df[var+<span class="string">&#x27;_offline&#x27;</span>].isnull().<span class="built_in">sum</span>()</span><br><span class="line">        miss_online  = df[var+<span class="string">&#x27;_online&#x27;</span>].isnull().<span class="built_in">sum</span>()</span><br><span class="line">        spec_offline = <span class="built_in">sum</span>(df[var+<span class="string">&#x27;_offline&#x27;</span>] == spec_value)</span><br><span class="line">        spec_online  = <span class="built_in">sum</span>(df[var+<span class="string">&#x27;_online&#x27;</span>] == spec_value)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>  var <span class="keyword">in</span> num_varlist:   </span><br><span class="line">            mean_offline = df[var+<span class="string">&#x27;_offline&#x27;</span>].mean()</span><br><span class="line">            mean_online  = df[var+<span class="string">&#x27;_online&#x27;</span>].mean()</span><br><span class="line">            df[var+<span class="string">&#x27;_same&#x27;</span>] = df.apply(<span class="keyword">lambda</span> row: compare(row[var+<span class="string">&#x27;_offline&#x27;</span>], row[var+<span class="string">&#x27;_online&#x27;</span>], <span class="string">&#x27;numeric&#x27;</span>), axis=<span class="number">1</span>) </span><br><span class="line">            value_same = df[df[var+<span class="string">&#x27;_same&#x27;</span>]==<span class="number">1</span>].shape[<span class="number">0</span>] <span class="comment"># 有值并且满足精度一致要求</span></span><br><span class="line">            value_diff = df[df[var+<span class="string">&#x27;_same&#x27;</span>]==<span class="number">2</span>].shape[<span class="number">0</span>] <span class="comment"># 有值但不满足精度一致要求</span></span><br><span class="line">        <span class="keyword">else</span>: </span><br><span class="line">            mean_offline = np.nan</span><br><span class="line">            mean_online = np.nan</span><br><span class="line">            df[var+<span class="string">&#x27;_same&#x27;</span>] = df.apply(<span class="keyword">lambda</span> row: compare(row[var+<span class="string">&#x27;_offline&#x27;</span>], row[var+<span class="string">&#x27;_online&#x27;</span>], <span class="string">&#x27;string&#x27;</span>), axis=<span class="number">1</span>)</span><br><span class="line">            value_same = df[df[var+<span class="string">&#x27;_same&#x27;</span>]==<span class="number">1</span>].shape[<span class="number">0</span>] <span class="comment"># 有值并且相同</span></span><br><span class="line">            value_diff = df[df[var+<span class="string">&#x27;_same&#x27;</span>]==<span class="number">2</span>].shape[<span class="number">0</span>] <span class="comment"># 有值但是不同</span></span><br><span class="line"></span><br><span class="line">        miss_same = df[df[var+<span class="string">&#x27;_same&#x27;</span>]==<span class="number">3</span>].shape[<span class="number">0</span>] <span class="comment"># 两者取值都为null</span></span><br><span class="line">        miss_diff = df[var+<span class="string">&#x27;_same&#x27;</span>].isnull().<span class="built_in">sum</span>()  <span class="comment"># 其中有一个为null</span></span><br><span class="line">        total_same = value_same + miss_same         <span class="comment"># 两者完全相同   </span></span><br><span class="line">        df[var+<span class="string">&#x27;_same&#x27;</span>] = df[var+<span class="string">&#x27;_same&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x <span class="keyword">in</span> [<span class="number">1</span>,<span class="number">3</span>] <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> [var, total, miss_offline, miss_online, mean_offline, mean_online, </span><br><span class="line">                value_diff, value_same, miss_diff, miss_same, total_same, spec_offline, spec_online, df]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 启动多线程</span></span><br><span class="line">    pool = ThreadPool(<span class="number">10</span>)</span><br><span class="line">    stat_list = pool.<span class="built_in">map</span>(stat, comp_list)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line"></span><br><span class="line">    final_cols = [<span class="string">&#x27;var&#x27;</span>,<span class="string">&#x27;total&#x27;</span>,<span class="string">&#x27;miss_offline&#x27;</span>,<span class="string">&#x27;miss_online&#x27;</span>,<span class="string">&#x27;mean_offline&#x27;</span>,<span class="string">&#x27;mean_online&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;value_diff&#x27;</span>,<span class="string">&#x27;value_same&#x27;</span>,<span class="string">&#x27;miss_diff&#x27;</span>,<span class="string">&#x27;miss_same&#x27;</span>,<span class="string">&#x27;total_same&#x27;</span>,<span class="string">&#x27;spec_offline&#x27;</span>,<span class="string">&#x27;spec_online&#x27;</span>]</span><br><span class="line">    stat_arr = [x[:-<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> stat_list]</span><br><span class="line">    df_stat = pd.DataFrame(stat_arr, columns=final_cols)</span><br><span class="line">    df_stat[<span class="string">&#x27;miss_del&#x27;</span>] = df_stat[<span class="string">&#x27;miss_offline&#x27;</span>] - df_stat[<span class="string">&#x27;miss_online&#x27;</span>]</span><br><span class="line">    df_stat[<span class="string">&#x27;mean_del&#x27;</span>] = df_stat[<span class="string">&#x27;mean_offline&#x27;</span>] - df_stat[<span class="string">&#x27;mean_online&#x27;</span>]</span><br><span class="line">    df_stat[<span class="string">&#x27;same_rate&#x27;</span>] = df_stat[<span class="string">&#x27;total_same&#x27;</span>] / df_stat[<span class="string">&#x27;total&#x27;</span>]</span><br><span class="line">    df_report = df_stat[[<span class="string">&#x27;var&#x27;</span>,<span class="string">&#x27;total&#x27;</span>,<span class="string">&#x27;miss_offline&#x27;</span>,<span class="string">&#x27;miss_online&#x27;</span>,<span class="string">&#x27;miss_del&#x27;</span>,<span class="string">&#x27;mean_offline&#x27;</span>,<span class="string">&#x27;mean_online&#x27;</span>,<span class="string">&#x27;mean_del&#x27;</span>,</span><br><span class="line">                         <span class="string">&#x27;value_diff&#x27;</span>,<span class="string">&#x27;value_same&#x27;</span>,<span class="string">&#x27;miss_diff&#x27;</span>,<span class="string">&#x27;miss_same&#x27;</span>,<span class="string">&#x27;total_same&#x27;</span>,<span class="string">&#x27;same_rate&#x27;</span>,<span class="string">&#x27;spec_offline&#x27;</span>,<span class="string">&#x27;spec_online&#x27;</span>]]</span><br><span class="line">    df_report.columns = [<span class="string">&#x27;变量名&#x27;</span>,<span class="string">&#x27;比较数&#x27;</span>,<span class="string">&#x27;离线缺失&#x27;</span>,<span class="string">&#x27;在线缺失&#x27;</span>,<span class="string">&#x27;离线-在线缺失&#x27;</span>,<span class="string">&#x27;离线均值&#x27;</span>,<span class="string">&#x27;在线均值&#x27;</span>,<span class="string">&#x27;离线-在线均值&#x27;</span>,</span><br><span class="line">                         <span class="string">&#x27;有值不一致&#x27;</span>,<span class="string">&#x27;有值一致量&#x27;</span>,<span class="string">&#x27;缺失不一致&#x27;</span>,<span class="string">&#x27;缺失一致量&#x27;</span>,<span class="string">&#x27;一致量&#x27;</span>,<span class="string">&#x27;一致率&#x27;</span>,<span class="string">&#x27;离线特殊值数&#x27;</span>,<span class="string">&#x27;在线特殊值数&#x27;</span>]</span><br><span class="line">    df_report = df_report.sort_values(by=[<span class="string">&#x27;一致率&#x27;</span>], ascending=<span class="number">1</span>)</span><br><span class="line">    df_report.to_excel(filename, index=<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;对比报告保存在%s&#x27;</span> % filename)</span><br><span class="line">    t1 = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;耗时%s分钟&#x27;</span> % <span class="built_in">int</span>((t1-t0)/<span class="number">60</span>))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;拼接明细...&#x27;</span>)</span><br><span class="line">    df_detail = pd.DataFrame(data_offline_new[key_var], columns=[key_var])</span><br><span class="line">    <span class="keyword">if</span> need_detail:</span><br><span class="line">       df_list = [x[-<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> stat_list]</span><br><span class="line">       <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="built_in">len</span>(df_list))):</span><br><span class="line">           df_detail = pd.merge(df_detail, df_list[i], on=key_var)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> df_report, df_detail</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（4）特征工程-时间滑窗统计特征体系</title>
    <url>/posts/67Q9G2/</url>
    <content><![CDATA[<h2><span id="风控特征时间滑窗统计特征体系">风控特征—时间滑窗统计特征体系</span></h2>
<h4><span id="风控业务背景"><strong>风控业务背景</strong></span></h4>
<p>俗话说，路遥知马力，日久见人心。在风控中也是如此，我们常<strong>从时间维度提取借款人在不同时间点的特征</strong>，以此来判断借款人的风险。在实践中，这类特征通常会占到80%以上。由于是<strong>通过时间切片和聚合统计函数来构造，因此一般被称为时间滑窗统计特征。</strong></p>
<h3><span id="一-观察期-观察点及表现期">一、<strong>观察期、观察点及表现期</strong></span></h3>
<p>理解这三者的概念是风控建模前期样本准备的基础，在此简单介绍。</p>
<ul>
<li><strong>观察点（</strong>Observation
Point<strong>）</strong>：并非是一个具体的时间点，而是一个时间区间，表示的是客户申请贷款的时间。在该时间段申请的客户<strong>可能</strong>会是我们用来建模的样本
。（提示：为什么用“可能”这个描述，因为还需剔除一些强规则命中的异常样本，这部分样本将不会加入建模）</li>
<li><strong>观察期</strong>（Observation
Window）：用以<strong>构造特征X</strong>的时间窗口。相对于观察点而言，是<strong>历史</strong>时间。观察期的选择依赖于用户数据的厚薄程度。通常数据越厚，可提取的信息也就越全面、可靠。</li>
<li><strong>表现期</strong>（Performance
Window）：定义<strong>好坏标签Y</strong>的时间窗口。相对于观察点而言，是<strong>未来</strong>时间。由于风险需要有一定时间窗才能表现出来，因此信贷风险具有<strong>滞后性</strong>。表现期的长短可以通过Vintage分析和滚动率分析来确定，在此不做展开。
<img src="https://pic3.zhimg.com/80/v2-c47416a557f573a72acccb00ec5a37fe_1440w.jpg" alt="img"></li>
</ul>
<p>表现期越长，信用风险暴露将越彻底，但意味着观察期离当前将越远，用以提取样本特征的历史数据将越陈旧，建模样本和未来样本的差异也越大。反之，表现期越短，风险还未暴露完全，但好处是能用到更近的样本。</p>
<h3><span id="二-rfm模型介绍">二、<strong>RFM模型介绍</strong></span></h3>
<p><strong>RFM模型最早是用来衡量客户价值和客户创利能力</strong>。理解RFM框架的思想是构造统计类特征的基础，其含义为：</p>
<ul>
<li><strong>R（Recency）</strong>：客户最近一次交易消费时间的间隔。R值越大，表示客户交易发生的日期越久，反之则表示客户交易发生的日期越近。</li>
<li><strong>F（Frequency）</strong>：客户在最近一段时间内交易消费的次数。F值越大，表示客户交易越频繁，反之则表示客户交易不够活跃。</li>
<li><strong>M（Monetary）</strong>：客户在最近一段时间内交易消费的金额。M值越大，表示客户价值越高，反之则表示客户价值越低。</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（5）数据挖掘-手机App数据挖掘实现</title>
    <url>/posts/34HK4X9/</url>
    <content><![CDATA[<h2><span id="风控数据手机app数据挖掘实践思路">风控数据—手机App数据挖掘实践思路</span></h2>
<h3><span id="引言"><strong>引言</strong></span></h3>
<p>作为移动互联网时代的主要载体，智能手机逐渐成为人们日常生活中不可或缺的一部分，改变着人们的生活习惯。比如，可以用“饿了么”点外卖，“支付宝”可以用来种树，“抖音”可以用来上厕所......强大的App给我们的生活带来了巨大的便利。</p>
<p><img src="https://pic3.zhimg.com/80/v2-87f00e7e18438ad4bf65c09feb5f38e6_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p>正因为如此，App与用户之间存在着密不可分的联系，用户在频繁使用这些App过程中也积累了大量的个人历史数据。<strong><font color="red">
这些App数据能帮助我们更好地去理解用户，推测用户的性别、职业、收入、兴趣、偏好等属性</font></strong>，也就是所谓的<strong>KYC（Know
your customer）</strong>。</p>
<p>在风控中，App数据也有其重要价值，常用于反欺诈、风控建模特征工程等。本文将分享App数据的一些挖掘思路，以及实践建议。</p>
<p><strong>首先，让我们思考下几个问题：</strong></p>
<ul>
<li>如何获取数据？</li>
<li>数据长啥样？</li>
<li>数据如何和业务相结合去理解？</li>
<li>可以采用什么算法实现高效提取信息？</li>
<li>如何利用这块数据服务业务？</li>
</ul>
<h3><span id="一-app数据长啥样">一、 App数据长啥样？</span></h3>
<p>根据资料显示，当前手机App数据主要包括：<strong>App安装包名称、App中文名、App安装列表、App安装序列。</strong></p>
<p><strong>为便于区分，常把App中文名记为app_name，App包名称（package）记为pkg_name。其中pkg_name是App的唯一ID</strong>，app_name则因为下载渠道、版本更新、数据采集等因素影响导致不唯一。例如，"企业微信"的pkg_name为“com.tencent.wework”，而app_name可能会有“企业微信”、“微信企业版”、“微信（企业版）”等多个值。</p>
<p>至于如何获取手机App package？可以参考这里：<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/gufenchen/article/details/91410667">实现获取appPackage和appActivity的方法</a></p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-e7c62877c3193cec175852170ee3eae2_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ol type="1">
<li><strong>App安装集合（App
List</strong>）：指手机上安装的所有App的集合，一般用逗号隔开，如：“com.alibaba.android.rimet,com.tencent.mm,com.citiccard.mobilebank,com.icbc,com.hongxin1.rm”。可以认为是一个集合，因此是<strong>无序</strong>的。</li>
<li><strong>App安装序列（App
Seq）</strong>：指手机上包含安装时间的App序列。如：["
信","1558014854044","<a href="https://link.zhihu.com/?target=http%3A//com.tencent.mm/">com.tencent.mm</a>",,"7.0.4"]，分别代表App中文名、App安装时间戳、App包名称和版本号。由于可根据安装时间戳得到安装顺序，因此是<strong>有序</strong>的。</li>
</ol>
<p>我们拿“微信”的package在腾讯应用宝中检索，那么就可以找到以下<strong>App描述数据</strong>：</p>
<ol type="1">
<li><strong>分类标签</strong>：标签精确表达了App的核心功能。但可能是开发者在发布App时从可选项中主观选择了一个标签，也有可能腾讯会在后期维护标签。标签不一定准确，但可作为一个重要的参考维度。</li>
<li><strong>下载量</strong>：可作为判断App是否小众的一个参考维度。然而，能在应用宝上架的App一般是合规的；对于一些质量较差无法上架的app就无法获取到下载量。</li>
<li><strong>应用描述</strong>：开发者对App的主要功能给出的描述性文本，可提取关键词、主题等内容。但如果只是根据关键词匹配，很容易出错。比如微信中藏有游戏中心入口，文本中出现“游戏”关键词，但这并不是一个游戏类App。</li>
</ol>
<h3><span id="二-app如何有效分类">二、App如何有效分类？</span></h3>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>安全场景-二进制文件SCA</title>
    <url>/posts/3SZGXMB/</url>
    <content><![CDATA[<ul>
<li>腾讯安全科恩实验室推出首款免费在线SCA平台：BinaryAI：https://www.freebuf.com/sectool/284239.html</li>
<li>源代码与二进制文件SCA检测原理：https://www.huaweicloud.com/zhishi/vss-010.html</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title>安全场景-软件供应链及物联网安全 </title>
    <url>/posts/DFA75A/</url>
    <content><![CDATA[<h3><span id="供应链及物理网安全">供应链及物理网安全</span></h3>
<blockquote>
<p>##### 1、<a href="https://developer.android.com/studio/build/apk-analyzer?hl=zh-cn">APK分析</a></p>
<p>考察点：逆向分析、文档收集、数据分析</p>
<p>##### 2、软件供应链安全分析</p>
<ul>
<li>MaMaDroid【13】</li>
<li><a href="https://github.com/MLDroid/drebin">Drebin</a> 【14】</li>
<li>AppContext【20】</li>
</ul>
<p>==考察点：二进制代码分析，二进制函数特征提取，补丁比较，源代码分析==</p>
<ul>
<li>如V. Livshits 等使用静态分析的方法在Java
源代码中进行脆弱性(vulnerability)检测的策略[47]。</li>
<li>G. Grieco 和G. Grinblat
等使用机器学习方法根据软件的内存错误信息训练测试模型,
检测软件漏洞的研究[49] <strong><em>Toward Large-Scale Vulnerability
Discovery Using Machine Learning</em></strong></li>
<li>彭小详等人的研究针对加壳技术,
提出了对恶意程序进行自动脱壳的方法[59]。<strong><em>Research of
Malicious Code in Automatic Unpacking</em></strong></li>
<li><a href="https://blog.csdn.net/weixin_34168880/article/details/86753392">「功守道」软件供应链安全大赛·C源代码赛季启示录</a></li>
</ul>
</blockquote>
<blockquote>
<p>##### 3、<a href="https://www.freebuf.com/sectool/219057.html">PowerShell反混淆</a></p>
<p>考察点：代码分析， 混淆语句定位、还原</p>
</blockquote>
<ul>
<li>XShell污染</li>
<li>CCleaner投毒</li>
</ul>
<h5><span id="混淆原理">混淆原理</span></h5>
<p>网上帖子太多了，可以参考下看雪论坛用户发的翻译贴：
https://bbs.pediy.com/thread-248034.htm</p>
<h5><span id="自动化反混淆工具">自动化反混淆工具</span></h5>
<p>Unit42安全团队编写的PowerShellProfiler.py： github地址：
https://github.com/pan-unit42/public_tools/tree/master/powershellprofiler
用法及原理参考： https://www.freebuf.com/sectool/219057.html</p>
<blockquote>
<p>##### 4、物联网漏洞挖掘</p>
<p>考察点：<a href="https://cloud.tencent.com/developer/article/1543779">常见漏洞原理</a>，二进制逆向工程，自动化程序分析</p>
</blockquote>
<h4><span id="相关论文">相关论文</span></h4>
<blockquote>
<p>DroidMD: an efficient and scalable Android malware detection approach
at source code level (2021 C&amp;S)</p>
<p>Detection of Repackaged Android Malware with Code-Heterogeneity
Features.(2020 TDSC)</p>
</blockquote>
<h5><span id="11-软件供应链">1.1 软件供应链</span></h5>
<p><a href="https://www.freebuf.com/sectool/276951.html">软件供应链安全工具DependencyTrack的使用</a></p>
<p>https://www.cnblogs.com/bonelee/p/13768901.html</p>
<h5><span id="12-物联网安全">1.2 物联网安全</span></h5>
<h3><span id="常见恶意行为">常见恶意行为</span></h3>
<blockquote>
<p>*标注为单点确定性恶意行为，**标注为二阶段恶意行为中的上游或下游行为，#标注为复合恶意行为</p>
</blockquote>
<p>*
<strong>敏感信息异常采集</strong>:针对生产环境，最大的威胁不是造成应用执行异常，而是在无形中泄漏关键敏感数据，包括可能造成机器控制权丧失的系统相关配置数据，关键的应用存储的用户数据等。</p>
<ul>
<li>口令与秘钥类型文件直接操作 *</li>
<li>系统敏感配置文件绕过API直接读取 *</li>
<li>典型服务端应用敏感配置文件直接读取 *</li>
<li>系统账户操作历史相关信息读取 **</li>
<li>典型服务端应用管理账户和用户数据读取 **</li>
<li>系统一般描述性信息采集 **</li>
<li>软件供应链上游特定资源数据探测、获取和泄漏（如源码遍历泄漏） #</li>
</ul>
<p>*
<strong>关键数据篡改</strong>:任何需要在生产环境上，修改、写入数据或代码从而实现恶意打击的行为，我们统一归纳到这一类里面，较为泛化。</p>
<ul>
<li>覆盖、篡改或插入口令秘钥类型文件用以账户植入 *</li>
<li>系统、用户环境变量和关键配置文件修改 **</li>
<li>自动执行脚本/用户操作历史篡改 **</li>
<li>典型服务端应用配置文件和关键数据文件绕过API方式篡改 *</li>
<li>系统/典型应用重要位置的脚本/可执行文件置换 **</li>
<li>开发、测试等环境系统默认工具链篡改替换 *</li>
<li>开发、测试等环境特定类型源文件/资源文件篡改污染 #</li>
</ul>
<p>*<strong>不可信数据传入渠道</strong>：以上两者重点考察了隐形的软件供应链本地恶意行为。在涉及到网络和交互的场景下，通过从供应链上进行污染，一种比较直接且有持续后效的恶意行为就是撕开一个口子，供后续入侵进场。</p>
<ul>
<li>下载敏感类型文件到临时目录 **</li>
<li>关键可执行文件（系统应用/关键服务端应用/关键库）下载/释放 **</li>
<li>网络传入指令/地址类型数据且无校验执行/访问 *</li>
</ul>
<p>*
<strong>不可信信息外传渠道</strong>。对应于上面的传入。敏感数据的采集后，需要搭配对应的下游传出才能形成完整恶意行为链路，常规可能的渠道形式分为两类。</p>
<ul>
<li>上游数据未脱敏形式的网络传出（TCP/UDP/ICMP） **</li>
<li>上游数据未脱敏形式的本地确定位置落盘 **</li>
</ul>
<p>*
<strong>其它典型木马后门行为</strong>。在上述行为框架之外，在生产环境上具有非单纯破坏效果的恶意行为，划分为此类，包括但不限于：</p>
<ul>
<li><p>键盘hook等输入监控行为 *</p></li>
<li><p>网络劫持行为 *</p></li>
<li><p>全局挂钩注入行为 **</p></li>
<li><p>远程控制 #</p></li>
</ul>
<h3><span id="经典赛题事例">经典赛题事例</span></h3>
<p><strong>#1：thttpd后门陷阱</strong></p>
<p>从基础软件或应用上面入手，稳定可控的后门是最佳选择。而在一个无关应用中突兀地出现网络连接，隐蔽性总归很差；在thttpd当中，以很袖珍的代码实现稳定的后门，是这里首先要呈现的一个题目。</p>
<p>在thttpd项目，恶意代码嵌入到libhttpd.c文件中，上下游恶意代码相关上下文：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">*** /thttpd/libhttpd.c</span><br><span class="line"></span><br><span class="line">--- malware/libhttpd.c</span><br><span class="line"></span><br><span class="line">*************** <span class="title function_">httpd_parse_request</span><span class="params">( httpd_conn* hc )</span></span><br><span class="line"></span><br><span class="line">*** 2102,2107 ****</span><br><span class="line"></span><br><span class="line">--- 2102,2113 ----</span><br><span class="line"></span><br><span class="line">cp += <span class="built_in">strspn</span>( cp, <span class="string">&quot; \t&quot;</span> );</span><br><span class="line"></span><br><span class="line">hc-&gt;useragent = cp;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">+ <span class="keyword">else</span> <span class="keyword">if</span> ( strncasecmp( buf, <span class="string">&quot;TE:&quot;</span>, <span class="number">3</span> ) == <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">+ &#123;</span><br><span class="line"></span><br><span class="line">+ cp = &amp;buf[<span class="number">3</span>];</span><br><span class="line"></span><br><span class="line">+ cp += <span class="built_in">strspn</span>( cp, <span class="string">&quot; \t&quot;</span>);</span><br><span class="line"></span><br><span class="line">+ hc-&gt;hs-&gt;cgi_pattern = cp;</span><br><span class="line"></span><br><span class="line">+ &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> ( strncasecmp( buf, <span class="string">&quot;Host:&quot;</span>, <span class="number">5</span> ) == <span class="number">0</span> )</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">cp = &amp;buf[<span class="number">5</span>];</span><br><span class="line"></span><br><span class="line">*************** cgi_child( httpd_conn* hc )</span><br><span class="line"></span><br><span class="line">*** <span class="number">3560</span>,<span class="number">3565</span> ****</span><br><span class="line"></span><br><span class="line">--- <span class="number">3566</span>,<span class="number">3576</span> ----</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* HAVE_SIGSET */</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Run the program. */</span></span><br><span class="line"></span><br><span class="line">+ <span class="keyword">if</span> ( <span class="built_in">strstr</span>( hc-&gt;acceptl, <span class="string">&quot;en;q=1.1&quot;</span>) != (<span class="type">char</span>*)<span class="number">0</span> )</span><br><span class="line"></span><br><span class="line">+ &#123;</span><br><span class="line"></span><br><span class="line">+ binary = argp[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">+ argp++;</span><br><span class="line"></span><br><span class="line">+ &#125;</span><br><span class="line"></span><br><span class="line">(<span class="type">void</span>) execve( binary, argp, envp );</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Something went wrong. */</span></span><br></pre></td></tr></table></figure>
<p>后门会根据http头判断是否开启cgi功能，并根据http头Accept-Language决定解析执行文件的路径。上述代码段中，首先通过http头TE:设置开启cgi功能（对应上述代码中，httpd_parse_request函数中插入的else
if ( strncasecmp( buf, "TE:", 3 ) == 0)
{...}代码块）。而下游代码同样巧妙，指定特殊的Accept-Language:
en;q=1.1决定是否执行指定的系统命令（即cgi_child函数插入的if ( strstr(
hc-&gt;acceptl, "en;q=1.1") != (char*)0 ) {...}代码块）。</p>
<p>本例恶意行为的主要特点：</p>
<ul>
<li>该后门的嵌入，新增代码量极小（共7行），巧妙借用了thttpd处理用户请求、cgi的原本逻辑，借用了execve的调用，没有任何新增的API调用等行为，可以躲避有意识的行为特征匹配检测。</li>
<li>该后门在代码中的插入，分布在了存在逻辑关联的上下游两个位置，在源代码分析领域，属于过程间代码扫描问题，对于基于语义的源代码静态扫描方案也提出了很高的要求。</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title>安全场景-客户端安全</title>
    <url>/posts/23JEMKQ/</url>
    <content><![CDATA[<blockquote>
<p><strong>AI安全实习生（日常/寒假实习）</strong></p>
<p><strong>岗位职责：</strong></p>
<ul>
<li>AI与软件安全相结合的前沿研究；</li>
</ul>
<p><strong>岗位需求（满足其一即可）：</strong></p>
<ul>
<li>对机器学习、深度学习等有较好的理解和掌握。在自然语言处理、大数据分析等人工智能领域有较丰富的项目或科研经验。能独立开展研究工作；</li>
<li><strong>有扎实的计算机学科基础知识储备</strong>，有<strong>程序语言分析</strong>，<strong>逆向分析</strong>等软件安全相关技术知识或项目经验。同时了解机器学习等相关知识，对算法研究感兴趣；</li>
</ul>
</blockquote>
<p><strong>4月15日</strong></p>
<figure>
<img src="../../../../../Library/Containers/com.tencent.xinWeChat/Data/Library/Application%20Support/com.tencent.xinWeChat/2.0b4.0.9/076b7987d1501ed1ebeee6aecab0dccc/Message/MessageTemp/d94f2f3724071aa466f759517f6fd464/Image/4001647676481_.pic.jpg" alt="4001647676481_.pic">
<figcaption aria-hidden="true">4001647676481_.pic</figcaption>
</figure>
<p>【<strong>岗位职责</strong>】
负责腾讯安全产品的研发工作，负责云主机安全的研究工作，负责数据分析及后台研发工作，对实验室海量的复杂恶意样本进行分析，提取恶意样本特征，设计恶意样本查杀方法，<strong>研发恶意代码分析领域的自动化工具</strong>，<strong>利用数据分析算法进行样本行为分析自动化以及特征提取自动化</strong>，研究前沿的程序安全和代码安全技术。</p>
<p>【<strong>岗位要求</strong>】</p>
<ul>
<li>掌握C/C++/Go中至少一门开发语言</li>
<li>掌握Python脚本开发</li>
<li>拥有安全研究/安全开发/攻防经验者优先</li>
<li>了解PE/Webshell等常见恶意程序的基本结构优先</li>
</ul>
<h2><span id="客户端安全qampa">客户端安全Q&amp;A</span></h2>
<h3><span id="1-pe文件结构">1、PE文件结构？</span></h3>
<p>https://bbs.pediy.com/user-home-825190.htm</p>
<blockquote>
<p>PE文件被称之为：“可执行文件，可以在Windows操作系统中进行加载和执行的文件”</p>
</blockquote>
<ul>
<li>Windows平台：PE（Portable
Executable）文件结构，其中Portable也就是Windows系统中能够跨平台运行</li>
<li>Linux平台：ELF（Executable and Linking Format）文件结构</li>
</ul>
<h4><span id="pe文件结构">PE文件结构：</span></h4>
<figure>
<img src="https://pic1.zhimg.com/v2-092acf1b67886791643b26b34ac669ec_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li><h4><span id="dos部分">Dos部分</span></h4></li>
</ul>
<p><strong>Dos分为两个部分，一个是DOS MZ文件头和DOS块</strong></p>
<h5><span id="mz文件头"><strong>MZ文件头</strong></span></h5>
<blockquote>
<p><strong>IMAGE_DOS_HEADER结构体</strong>：其大小占<strong>64个字节「重点」</strong>，并且该结构中的<strong>最后一个LONG类型e_lfanew成员指向PE文件头的位置为中的PE文件头标志的地址</strong></p>
</blockquote>
<h5><span id="dos-stub"><strong>Dos Stub</strong></span></h5>
<blockquote>
<p>属于链接器进行填充的，大小不一定，属于DOS部分的DOS块，无实际作用，但是可以作为注入手段进行利用！</p>
</blockquote>
<ul>
<li><h4><span id="pe文件头">PE文件头</span></h4></li>
</ul>
<blockquote>
<p>##### <strong>PE文件头标志（PE标识）</strong>z [4 字节] +
<strong>PE文件表头</strong>（<strong>标准PE头</strong>）[20 字节] +
扩展文件表头（<strong>扩展PE头</strong>）</p>
</blockquote>
<ul>
<li><h4><span id="节表">节表</span></h4></li>
</ul>
<p>IMAGE_SECTION_HEADER结构体（40字节） *
节的数量（大小取决于节的数量）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> _<span class="title">IMAGE_SECTION_HEADER</span> &#123;</span></span><br><span class="line">    BYTE    Name[IMAGE_SIZEOF_SHORT_NAME];<span class="comment">// 节表名称,如“.text” </span></span><br><span class="line">  <span class="comment">//IMAGE_SIZEOF_SHORT_NAME=8</span></span><br><span class="line">    <span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">      <span class="comment">//　共用体，也叫联合体，在一个“联合”内可以定义多种不同的数据类型， </span></span><br><span class="line"><span class="comment">//一个被说明为该“联合”类型的变量中，允许装入该“联合”所定义的任何一种数据，这些数据共享同一段内存，</span></span><br><span class="line"><span class="comment">//以达到节省空间的目的。union变量所占用的内存长度等于最长的成员的内存长度。</span></span><br><span class="line">            DWORD   PhysicalAddress; <span class="comment">//当前节的名称 ， 占8字节</span></span><br><span class="line">            DWORD   VirtualSize; <span class="comment">//内存中文件对齐大小</span></span><br><span class="line">    &#125; Misc;</span><br><span class="line">    DWORD   VirtualAddress; <span class="comment">//在内存中的偏移地址 +imageOfBase=真正的位置</span></span><br><span class="line">    DWORD   SizeOfRawData; <span class="comment">//当前节在文件中对齐后的大小 也就是节点的大小 [内存和文件中是一样的]</span></span><br><span class="line">    DWORD   PointerToRawData; <span class="comment">//当前节在文件中的偏移 也就是文件的开始位置</span></span><br><span class="line">    DWORD   PointerToRelocations; <span class="comment">// 调试相关</span></span><br><span class="line">    DWORD   PointerToLinenumbers;<span class="comment">// 调试相关</span></span><br><span class="line">    WORD    NumberOfRelocations;<span class="comment">// 调试相关</span></span><br><span class="line">    WORD    NumberOfLinenumbers;<span class="comment">// 调试相关</span></span><br><span class="line">    DWORD   Characteristics; <span class="comment">//文件属性，比如该节数据属性是否为可执行属性，都在这里面</span></span><br><span class="line">&#125; IMAGE_SECTION_HEADER, *PIMAGE_SECTION_HEADER;</span><br></pre></td></tr></table></figure>
<p>pc客户端安全业务有什么了解？</p>
<p>对windows汇编有什么了解？</p>
<p>ollydbg调试原理？</p>
<h3><span id="2-用过什么样的ollydbg的断点">2、用过什么样的OllyDBG的断点？</span></h3>
<ul>
<li>寻常断点</li>
<li>API断点</li>
<li>内存断点</li>
<li>硬件断点</li>
</ul>
<h3><span id="3-win下进程间通信">3、win下进程间通信？</span></h3>
<ul>
<li>文件映射</li>
<li>共享内纯</li>
<li>匿名管道</li>
<li>命名管道</li>
</ul>
<h3><span id="3-call-和jump指令的区别和相同">3、call 和
jump指令的区别和相同？</span></h3>
<p>https://www.nhooo.com/note/qa0ucr.html</p>
<ol type="1">
<li><p>传送指令（4个）：mov、push、pop、lea。</p></li>
<li><p>转移指令（8个）：call、jmp、je、jne、jb、jnb、ja、jna。</p></li>
<li><p>运算指令（7个）：add、sub、mul、div、adc、sbb、cmp。</p></li>
<li><p>处理机控制指令（1个）：nop。</p></li>
</ol>
<p><strong>CALL指令用于调用子例程（不是主程序的一部分），但是JUMP指令更新程序计数器值并指向程序内部的另一个位置。</strong></p>
<h3><span id="4-cuckoo-inline-hook">4、Cuckoo inline hook ？</span></h3>
<blockquote>
<p>Cuckoo对ntdll.dll, kernel32.dll,
advapi32.dll，shell32.dll，msvcrt.dll，user32.dll，wininet.dll，ws2_32.dll，mswsock.dll中的170+API进行hook</p>
</blockquote>
<p>Cuckoo对样本行为的捕获依靠<strong>API Inline
Hook</strong>，被测样本会被注入加载一个监控模块，当样本调用某个API函数时会被劫持到Cuckoo的模块内，这个模块除了常规的做log操作然后返回原函数外还会对某些API的上下文进行篡改，目的在于劫持某些API的执行逻辑。</p>
<p><strong>inline
hook是一种通过修改机器码的方式来实现hook的技术。</strong></p>
<p>对于正常执行的程序，它的函数调用流程大概是这样的：</p>
<p><a href="https://images.cnblogs.com/cnblogs_com/luoyesiqiu/1643996/o_200208152801正常流程.png"><img src="https://images.cnblogs.com/cnblogs_com/luoyesiqiu/1643996/o_200208152801%E6%AD%A3%E5%B8%B8%E6%B5%81%E7%A8%8B.png" alt="img" style="zoom: 67%;"></a></p>
<p>0x1000地址的call指令执行后跳转到0x3000地址处执行，执行完毕后再返回执行call指令的下一条指令。</p>
<p>我们在hook的时候，可能会读取或者修改call指令执行之前所压入栈的内容。那么，我们可以将call指令<strong>替换</strong>成jmp指令，jmp到我们自己编写的函数，在函数里call原来的函数，函数结束后再jmp回到原先call指令的下一条指令。如图：</p>
<p><a href="https://images.cnblogs.com/cnblogs_com/luoyesiqiu/1643996/o_200213062347inlinehook.png"><img src="https://images.cnblogs.com/cnblogs_com/luoyesiqiu/1643996/o_200213062347inlinehook.png" alt="img" style="zoom:67%;"></a></p>
<p>通过修改机器码实现的inline
hook，不仅不会破坏原本的程序逻辑，而且还能执行我们的代码，读写被hook的函数的数据。</p>
<h3><span id="5-cuckoo-windows-dll-注入">5、cuckoo windows DLL 注入</span></h3>
<blockquote>
<p>Cuckoo
sandbox在样本启动的时候,注入了相关的监控代码。在process.py文件中，通过Process调用，调用inject-x86.exe或inject-x64.exe完成注入。</p>
<p>https://www.cnblogs.com/luoyesiqiu/p/12173609.html</p>
</blockquote>
<p><strong>DLL注入（英语：DLL
injection）是一种计算机编程技术，它可以强行使另一个进程加载一个动态链接库以在其地址空间内运行指定代码[1]。</strong>在Windows操作系统上，每个进程都有独立的进程空间，即一个进程是无法直接操作另一个进程的数据的（事实上，不仅Windows，许多操作系统也是如此）。但是DLL注入是用一种不直接的方式，来实现操作其他进程的数据。假设我们有一个DLL文件，里面有操作目标进程数据的程序代码逻辑，DLL注入就是使目标进程加载这个DLL，加载后，这个DLL就成为目标进程的一部分，目标进程的数据也就可以直接操作了。</p>
<h4><span id="51-apc注入">5.1 APC注入</span></h4>
<blockquote>
<p>APC 队列（Asynchronous Procedure Call 异步过程调用）是一种可以在
Windows 中使用的机制，用于将要在特定线程上下文中完成的作业排队。</p>
</blockquote>
<p>APC注入，<strong>通过write_data向远程进程中写入DLL路径、Loadlibrary()执行函数指针、执行加载函数的指针</strong>,然后利用QueueUserAPC()在软中断时向线程的APC队列插入Loadlibrary()执行函数指针，达到注入DLL的目的。当线程再次被唤醒时，此线程会首先执行APC队列中被注册的函数。</p>
<h4><span id="52-crt注入">5.2 CRT注入</span></h4>
<p>同样通过write_data向远程进程中写入DLL路径、Loadlibrary()执行函数指针、执行加载函数的指针，之后在create_thread_and_wait中调用CreateRemoteThrea。当目标进程中执行load_library_woker（已事先写入进程空间）加载DLL，之后调用free_data清理现场，释放空间。</p>
<h3><span id="6-脱壳缓冲区溢出有什么经验">6、脱壳，缓冲区溢出有什么经验？</span></h3>
<h3><span id="7-沙箱如何获得动态样本信息">7、沙箱如何获得动态样本信息？</span></h3>
<h3><span id="8-沙箱反调试">8、沙箱反调试？</span></h3>
<h4><span id="样本对抗沙箱irc-bot">==样本对抗沙箱？IRC Bot==</span></h4>
<blockquote>
<p><a href="https://www.52pojie.cn/thread-377352-1-1.html"><strong>针对沙箱检测的逃逸技术</strong></a></p>
<p>https://www.anquanke.com/post/id/152631:当通过<code>CreateProcess</code>创建进程时，命令行中的路径的大小写会被沙箱的hook替换掉。</p>
</blockquote>
<p>因为反病毒沙箱大多都是基于虚拟机的，所以如果能保证样本在虚拟机环境中不执行那么就能大概率保证其在沙箱中不执行，针对沙箱的检测主要有如下几类：</p>
<h5><span id="针对虚拟机">针对虚拟机</span></h5>
<ul>
<li>虚拟机的特殊进程/注册表信息，比如像VBoxTray.exe、VMwareTray.exe等；</li>
<li>特殊的驱动程序，比如Virtualbox或VMware在Guest机器里面安装的驱动；</li>
<li>硬件信息，比如网卡的mac地址，特定品牌虚拟机的网卡mac地址默认情况下大多都在一个特定范围内；</li>
<li>指令执行环境，比如像LDT、GDT的地址范围等等；</li>
</ul>
<h5><span id="针对检测时间">针对检测时间</span></h5>
<p>沙箱每一轮分析一个样本的时间是有限的，通常就3分钟（默认），所以如果能让样本在这几分钟内不进入任何核心逻辑那么就可以避免被检测到。通常采取的做法有：</p>
<ul>
<li>利用Sleep函数，或和Sleep同等功能的延时函数；</li>
<li>检测系统时间，通过系统的时间来延时；</li>
<li>运行一些非常耗时的操作，比如一些特殊的数学算法以达到消耗时间的目的。</li>
</ul>
<h5><span id="针对交互">针对交互</span></h5>
<p>这种做法是为了确保样本是在有人操作的计算机中启动的，比如可以检测鼠标的移动、故意弹窗让用户点击等等。</p>
<h4><span id="ember-用了哪些特征">Ember 用了哪些特征？</span></h4>
<p>https://www.jianshu.com/p/cf96a701e899</p>
<p>头信息。从COFF报头中，我们报告报头中的时间戳、目标机器(字符串)和图像特征列表(字符串列表)。从可选的头文件中，我们提供了目标子系统(字符串)、DLL特征(字符串列表)、文件魔法作为字符串(例如“PE32”)、主映像版本和副映像版本、链接器版本、系统版本和子系统版本，以及代码、头文件和提交大小。在训练一个模型之前，使用特征哈希技巧总结模型特征、字符串描述符(如DLL特征、目标机器、子系统等)，每个带噪声的指标向量分配10个bin。</p>
<h4><span id="沙箱全局结果容器有哪些特征">沙箱全局结果容器有哪些特征？</span></h4>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title>安全场景（1）恶意软件检测*</title>
    <url>/posts/1W08D2X/</url>
    <content><![CDATA[<h2><span id="恶意软件检测">恶意软件检测</span></h2>
<h3><span id="一-论文">一、论文</span></h3>
<ul>
<li><strong>MALWARE综述</strong>
<ul>
<li><font color="red">论文分析</font>：https://powerlzy.github.io/posts/2GBZRTM/</li>
</ul></li>
<li>Deep Learning for Android Malware Defenses: a Systematic Literature
Review
<ul>
<li>项目地址：https://github.com/yueyueL/DL-based-Android-Malware-Defenses-review</li>
<li>项目概述：<strong>ACM Computing
Surveys</strong>.+安卓恶意软件检测；</li>
</ul></li>
</ul>
<h3><span id="二-开源项目">二、开源项目</span></h3>
<h4><span id="21-论文复现">2.1 论文复现</span></h4>
<ul>
<li>TrustCom2021：Malware Classification by Learning Semantic and
Structural Features of Control Flow Graphs
<ul>
<li>项目地址：https://github.com/Bowen-n/MCBG</li>
<li>项目概述：通过学习控制流图的语义和结构特征进行恶意软件分类的源代码</li>
</ul></li>
<li>Windows-malware-detection
<ul>
<li>项目地址：https://github.com/strugglingeagle/Windows-malware-detection</li>
<li>项目概述：基于HIN的Windows恶意软件检测模型</li>
</ul></li>
<li><strong>Learning from Context: Exploiting and Interpreting File Path
Information for Better Malware Detection</strong>
<ul>
<li>项目概述：Sophos公司：（ember+路径上下文）</li>
<li><font color="red">论文分析</font>：https://powerlzy.github.io/posts/2Z5SQWP/</li>
</ul></li>
<li><strong><font color="red">Quo Vadis: Hybrid Machine Learning
Meta-Model Based on Contextual and Behavioral Malware
Representations</font></strong>
<ul>
<li>项目地址：https://github.com/dtrizna/quo.vadis</li>
<li>项目概述：基于Windows内核仿真的混合机器学习恶意软件检测模型（动态分析+ember+路径上下文）</li>
<li><font color="red">论文分析</font>：https://powerlzy.github.io/posts/2Z5SQWP/</li>
</ul></li>
<li>Malware Detection based on API Sequence Intrinsic Features
<ul>
<li>项目地址：https://github.com/friendllcc/Malware-Detection-API-Sequence-Intrinsic-Features</li>
<li>项目概述：沙箱API序列特征</li>
</ul></li>
<li>Learning-Based-PE-Malware-Family-Classification-Methods
<ul>
<li>项目地址：https://github.com/nikeluobinxiaoma/Learning-Based-PE-Malware-Family-Classification-Methods</li>
<li>项目概述：天大同学实验代码，包含三类基于学习的PE恶意软件家族分类方法，分别是基于图像的、基于二进制的和基于反汇编的方法，还有一种检测恶意软件类间漂移的方法。</li>
</ul></li>
<li><strong><font color="red">MalConv-Pytorch</font></strong>
<ul>
<li>项目地址：https://github.com/PowerLZY/MalConv-Pytorch</li>
<li>项目概述：基于字节序列的恶意软件检测研究</li>
</ul></li>
<li>CADE: Detecting and Explaining Concept Drift Samples for Security
Applications
<ul>
<li>项目地址：https://github.com/whyisyoung/CADE</li>
<li>项目概述：Code for our USENIX Security 2021 paper</li>
</ul></li>
<li><strong>Ember：Elastic Malware Benchmark for Empowering
Researchers</strong>
<ul>
<li>项目地址：https://github.com/elastic/ember</li>
<li>项目概述：2038维,静态分析+LightGBM</li>
</ul></li>
<li>When Malware is Packin’ Heat; Limits of Machine Learning Classifiers
Based on Static Analysis Features
<ul>
<li>项目地址：https://github.com/ucsb-seclab/packware</li>
<li>项目概述：打包器对仅使用静态分析的基于机器学习的恶意软件分类器的影响</li>
</ul></li>
<li><strong><font color="red">Dynamic Malware Analysis with Feature
Engineering and Feature Learning</font></strong>
<ul>
<li>项目地址：https://github.com/joddiy/DynamicMalwareAnalysis</li>
<li>项目概述：<strong>服务器上有源码</strong></li>
</ul></li>
</ul>
<h4><span id="22-开源工具">2.2 开源工具</span></h4>
<ul>
<li><strong>DeepMalwareDetector</strong>
<ul>
<li>项目地址：https://github.com/islem-esi/DeepMalwareDetector</li>
<li>项目概述：一个深度学习框架，用于分析Windows
PE文件以检测恶意软件。</li>
</ul></li>
</ul>
<figure>
<img src="https://camo.githubusercontent.com/c63cf7a3679e1eabcf423278e77ca7aa709148bccfe8013d7a0cbeb16f86884a/68747470733a2f2f70726f322d6261722d73332d63646e2d6366362e6d79706f7274666f6c696f2e636f6d2f61643563643536382d633338662d343864662d613531302d3532643533326664303639342f61366133323334642d633730632d346135332d623639362d3265366236326264656633365f72775f313932302e706e673f683d3439646438353134643639636430643934393834363564643137623939353133" alt="image">
<figcaption aria-hidden="true">image</figcaption>
</figure>
<ul>
<li><strong>恶意软件沙箱</strong>
<ul>
<li>CAPE: Malware Configuration And Payload Extraction
<ul>
<li>项目地址：https://github.com/kevoreilly/CAPEv2</li>
</ul></li>
<li><font color="red">Bold-Falcon：</font>https://github.com/PowerLZY/Bold-Falcon
<ul>
<li><strong><code>说明文档</code></strong>
https://powerlzy.github.io/Bold-Falcon/</li>
<li><strong><code>开发文档</code></strong> <a href="https://boldfalcon.readthedocs.io/">https://boldfalcon.readthedocs.io</a></li>
</ul></li>
</ul></li>
</ul>
<h3><span id="三-算法比赛">三、算法比赛</span></h3>
<ul>
<li><strong>DataCon2019大数据安全分析比赛冠军思路分享 -
杨航锋的文章</strong>
<ul>
<li>知乎 https://zhuanlan.zhihu.com/p/64252076</li>
</ul></li>
<li><strong>DataCon2020大数据安全分析大赛，🏆【方向五】恶意代码分析冠军源码和方案。</strong>
<ul>
<li>项目地址：
<ul>
<li>https://github.com/yuriufo/DataCon2020；</li>
<li>https://datacon.qianxin.com/#integral</li>
</ul></li>
</ul></li>
<li><strong>2021 CCF BDCI 数字安全公开赛 -
基于人工智能的恶意软件家族分类</strong>
<ul>
<li>比赛官网：https://www.datafountain.cn/competitions/507</li>
<li>项目地址：https://github.com/PowerLZY/malware_classification_bdci</li>
</ul></li>
</ul>
<h3><span id="四-工业界应用">四、工业界应用</span></h3>
<ul>
<li><p>McAfee:
https://www.mcafee.com/enterprise/en-us/security-awareness/endpoint/what-is-next-gen-endpoint-protection.html</p></li>
<li><p>Vmware:https://www.carbonblack.com/resources/definitions/what-is-next-generation-antivirus/</p></li>
<li><p>CrowdStrike:https://www.crowdstrike.com/epp-101/next-generation-antivirus-ngav/</p></li>
<li><p>Avast:https://www.avast.com/technology/malware-detection-and-blocking</p></li>
<li><p><strong>卡巴斯基</strong>:https://media.kaspersky.com/en/enterprise-security/Kaspersky-Lab-Whitepaper-Machine-Learning.pdf</p>
<ul>
<li><font color="red">论文分析</font>：https://powerlzy.github.io/posts/3JVWT1D/</li>
</ul></li>
<li><p>火眼:https://www.fireeye.com/blog/threat-research/2019/03/clustering-and-associating-attacker-activity-at-scale.html</p></li>
<li><p>Linux沙箱 ｜
阿里云恶意文件检测平台开放Linux二进制文件检测：https://www.anquanke.com/post/id/276349#10006-weixin-1-52626-6b3bffd01fdde4900130bc5a2751b6d1</p></li>
</ul>
<h2><span id="恶意软件逃逸攻击">恶意软件逃逸攻击</span></h2>
<h3><span id="一-论文">一、论文</span></h3>
<ul>
<li>A survey on practical adversarial examples for malware classifiers
<ul>
<li><font color="red">论文分析</font>：https://powerlzy.github.io/posts/17HFC4S/</li>
<li>项目概述：恶意软件的对抗样本综述</li>
</ul></li>
<li><strong>Awesome Resources for Adversarial Attacks and Defenses for
Windows PE Malware Detection</strong>
<ul>
<li>项目地址：https://github.com/ryderling/adversarial-attacks-and-defenses-for-windows-pe-malware-detection</li>
<li>项目概述：针对Windows
PE恶意软件检测的对抗性攻击和防御的精心策划的资源列表。<strong>别人总结的到2021年之前。</strong></li>
</ul></li>
<li><font color="red">Adversarial Training for Raw-Binary Malware
Classifiers</font>
<ul>
<li>论文地址：https://www.usenix.org/conference/usenixsecurity23/presentation/lucas</li>
<li>项目概述：2023 USENIX
Security-原始二进制恶意软件分类器的对抗性训练</li>
</ul></li>
<li><strong>Adversarial Attacks and Defenses in Deep Learning: From a
Perspective of Cybersecurity</strong>
<ul>
<li>论文地址：https://dl.acm.org/doi/10.1145/3547330</li>
<li>项目概述：ACM Computing
Surveys-系统地理解对抗性攻击提供第一个分析框架</li>
</ul></li>
<li><strong><font color="red">Black-Box Adversarial Attacks Against Deep
Learning Based Malware Binaries Detection with GAN</font></strong>
<ul>
<li><font color="red">论文分析</font>：https://powerlzy.github.io/posts/35K4AXJ/</li>
<li>项目概述：GAPGAN</li>
</ul></li>
<li><strong>深度学习赋能的恶意代码攻防研究进展 （2021
计算机学报）</strong></li>
<li><strong>Intriguing Properties of Adversarial ML Attacks in the
Problem Space (2020 S&amp;P)</strong>
<ul>
<li>项目概述：重点理解问题空间定义和搜索策略</li>
</ul></li>
<li><strong>Functionality-Preserving Black-Box Optimization of
Adversarial Windows Malware （2021 TIFS）</strong>
<ul>
<li><font color="red">论文分析</font>：https://powerlzy.github.io/posts/3SMQYQP/</li>
<li>项目概述：<strong>攻击被形式化为一个有约束的最小化问题，这也使得规避检测的概率和注入的有效负载的大小之间的权衡得到优化</strong>。</li>
</ul></li>
<li><strong>Adversarial EXEmples: A Survey and Experimental Evaluation
of Practical Attacks on Machine Learning for Windows Malware
Detection</strong></li>
</ul>
<h3><span id="二-项目">二、项目</span></h3>
<h4><span id="21-开源论文">2.1 开源论文</span></h4>
<ul>
<li><strong>MALGAN: Generating Adversarial Malware Examples for
Black-Box Attacks Based on GAN</strong>
<ul>
<li>项目地址：https://github.com/PowerLZY/MalGAN</li>
<li>项目概述：动态分析+逃逸攻击</li>
</ul></li>
<li>Evading Machine Learning Malware Detection
<ul>
<li>项目地址：https://github.com/drhyrum/gym-malware</li>
<li>项目概述：blackhat 2017，强化学习</li>
</ul></li>
<li>MAB-Malware
<ul>
<li>项目地址：https://github.com/weisong-ucr/MAB-malware</li>
<li>项目概述：MAB恶意软件是一个开源的强化学习框架，用于生成PE恶意软件的AE。</li>
</ul></li>
<li>dversarial Deep Ensemble: Evasion Attacks and Defenses for Malware
Detection
<ul>
<li>项目地址：https://github.com/deqangss/adv-dnn-ens-malware</li>
<li>项目概述：对抗性深度集成；Android恶意软件变体</li>
</ul></li>
</ul>
<h4><span id="22-开源工具">2.2 开源工具</span></h4>
<ul>
<li><strong><font color="red">secml-malware</font></strong>
<ul>
<li>项目地址：https://github.com/pralab/secml_malware</li>
<li>项目概述：<strong>针对机器学习Windows恶意软件检测器创建对抗性攻击</strong></li>
</ul></li>
<li><strong>CleverHans</strong>
<ul>
<li>项目地址：https://github.com/cleverhans-lab/cleverhans</li>
<li>项目概述：用于构建攻击、构建防御和基准测试的对抗性示例库</li>
</ul></li>
</ul>
<h3><span id="三-比赛">三、比赛</span></h3>
<ul>
<li><strong>2021 Machine Learning Security Evasion Competition</strong>
<ul>
<li>比赛链接：
<ul>
<li>https://mlsec.io/；</li>
<li>https://cujo.com/announcing-the-winners-of-the-2021-machine-learning-security-evasion-competition/</li>
</ul></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>网络安全</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>恶意软件检测</tag>
        <tag>静态分析</tag>
        <tag>动态分析</tag>
      </tags>
  </entry>
  <entry>
    <title>安全场景（0）AI+安全概述</title>
    <url>/posts/27P0XPW/</url>
    <content><![CDATA[<h1><span id="ai-for-security-learning">AI-for-Security-Learning</span></h1>
<blockquote>
<p>##### <a href="https://github.com/404notf0und">404notf0und</a>/<strong><a href="https://github.com/404notf0und/AI-for-Security-Learning">AI-for-Security-Learning</a></strong></p>
<p><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzg5MTM5ODU2Mg==&amp;action=getalbum&amp;album_id=2041739478687416320&amp;scene=173&amp;from_msgid=2247493698&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect">杨秀章</a></p>
</blockquote>
<h3><span id="一-恶意加密流量数据">一 、恶意加密流量数据</span></h3>
<h4><span id="工具">工具：</span></h4>
<p><strong>cicflowmeter</strong>，一款流量特征提取工具，该工具输入pcap文件，输出pcap文件中包含的数据包的特征信息（80多维）</p>
<h4><span id="11-机器学习检测cobaltstrike木马初探">1.1 机器学习检测Cobalt
Strike木马初探</span></h4>
<h4><span id="httpswwwfreebufcomarticlesnetwork279190html">https://www.freebuf.com/articles/network/279190.html</span></h4>
<p>通过机器学习分析cobalt
strike的通信包，找出通信规律，然后用这个规律对新的通信包进行检测。</p>
<p><strong>数据集</strong>：</p>
<blockquote>
<p>cobalt strike恶意通信的心跳包，无需抓指令包</p>
<p><strong>TCP特征</strong>：每秒传输的数据包字节数、流包率，即每秒传输的数据包数、每秒前向包的数量、正向数据包的总大小、数据包在正向的平均大小、数据包正向标准偏差大小、流的最大长度、最小包到达间隔时间等等。</p>
</blockquote>
<p>Microsoft Network Monitor 3.4
https://www.microsoft.com/en-us/download/details.aspx?id=4865</p>
<h3><span id="二-恶意软件">二、恶意软件</span></h3>
<p><strong>==阿里云安全==：win32程序在沙箱中运行的API序列信息，训练集11w条程序记录，测试集5w条程序记录。6类程序中正常程序特别多，病毒程序偏少。</strong></p>
<p>如图所示赛题数据按照文件file_id进行组织：每个文件file_id对应一个文件标签，即文件的病毒标签；每个文件file_id可能由一个或者多个线程tid组成。每个线程tid由一个api或者多个api组成，每个api对应一个返回值，api的次序关系由index表示。</p>
<p><img src="https://pic4.zhimg.com/80/v2-4b1c1f507ffb4f88a673c3f661547043_1440w.jpg" alt="img" style="zoom:33%;"></p>
<ul>
<li><strong>统计特征</strong>：统计API的出现次数、类型统计以及API返回值的统计特征；</li>
<li><strong>图模型特征</strong>：将API序列转换成API图的边，统计有向图的相关的特征；</li>
<li><strong>时序特征</strong>：API序列的出现次数等时序特征，API返回值的时序特征；</li>
</ul>
<p><strong>==<a href="https://github.com/ocatak/lstm_malware_detection/blob/master/deep_learnin_lstm_malware_detection.ipynb">LSTM
+ API</a>==</strong>：</p>
<h4><span id="pdf-malware">PDF malware</span></h4>
<ul>
<li>Malware Analysis – Dissecting PDF
file：https://github.com/filipi86/MalwareAnalysis-in-PDF</li>
</ul>
<h5><span id="基于bert的恶意软件多分类"></span></h5>
<h3><span id="三-ddos">三 、DDOS</span></h3>
<p>在攻击感知方面，可从<strong>宏观攻击流感</strong>知与<strong>微观检测方法</strong>两个角度，分别<strong>基于IP流序列谱分析的泛洪攻击</strong>与<strong>低速率拒绝服务（Low-rate
Denial of
Service，LDoS）方法</strong>进行感知。在此基础上，将DDoS攻击检测转化为机器学习的二分类问题。</p>
<p><strong>基于多特征并行隐马尔科夫模型（Multi-FeatureParallel Hidden
Markov
Model，MFP-HMM）的DDoS攻击检测方法</strong>，利用HMM隐状态序列与特征观测序列的对应关系，将攻击引起的多维特征异常变化转化为离散型随机变量，通过概率计算来刻画当前滑动窗口序列与正常行为轮廓的偏离程度。</p>
<h3><span id="四-web安全">四、WEB安全</span></h3>
<p><strong>Web安全是指个人用户在Web相关操作时不因偶然或恶意的原因受到破坏、更改、泄露</strong>。除了现有的<strong>SQL注入检测、XSS攻击检测</strong>等
AI应用，本部分将列举“恶意URL检测”与“
Webshell检测”两例。后续实验部分，作者将详细描述Python实现该过程。</p>
<p><strong>恶意URL检测</strong></p>
<p>基于机器学习，从
URL特征、域名特征、Web特征的关联分析，使恶意URL识别具有高准确率</p>
<p>开源工具如Phinn：Phinn使用了机器学习领域中的卷积神经网络算法来生成和训练一个自定义的Chrome扩展，这个
Chrome扩展可以将用户浏览器中呈现的页面与真正的登录页面进行视觉相似度分析，以此来识别出恶意URL（钓鱼网站）。</p>
<p><strong>Webshell检测</strong></p>
<p><strong>Webshell常常被称为匿名用户（入侵者）通过网站端口对网站服务器的某种程度上操作的权限</strong>。由于Webshell其大多是以动态脚本的形式出现，也有人称之为网站的后门工具。在攻击链模型中，整个攻击过程分为：踩点、组装、投送、攻击、植入、控制、行动。在针对网站的攻击中，通常是利用上传漏洞，上传Webshell，然后通过Webshell进一步控制web服务器。</p>
<p>通过词袋&amp;TF-IDF模型、Opcode&amp;N-gram模型、Opcode调用序列模型等特征抽取方式，采用合适的模型，如朴素贝叶斯和深度学习的MLP、CNN等，实现Webshell的检测。类似地，也可进行SQL注入、
XSS攻击检测等。</p>
<h3><span id="五-入侵检测与防御">五、入侵检测与防御</span></h3>
<p>入侵检测与防御是指对入侵行为的发现并采取相应的防御行动。除了现有的内网入侵检测等AI应用，本部分将列举“APT检测与防范”与“C2链接分析”两例。</p>
<p><strong>5.1 APT检测与防范</strong></p>
<p>进行APT攻击的攻击者从侦查目标，制作攻击工具，传递攻击工具，利用漏洞或者弱点来进行突防，拿下全线运行工具，后期远端的维护这个工具，到最后达到了长期控制目标的目的。针对这种现在日益广泛的APT
攻击，威胁情报存在于整个攻击的各个环节。</p>
<p>威胁情报是基于证据的描述威胁的一组关联的信息，包括威胁相关的<strong>环境信息</strong>，如具体的<strong>攻击组织</strong>、<strong>恶意域名</strong>。恶意域名又包括<strong>远控的IOC</strong>、<strong>恶意文件的HASH</strong>和<strong>URL以及威胁指标之间的关联性</strong>，时间纬度上攻击手法的变化。这些信息汇总在一起形成高级威胁情报。除此之外，所关注的情报，还包括传统威胁种类的扩充，包括木马远控，僵尸网络，间谍软件，
Web后门等。利用机器学习来处理威胁情报，检测并识别出APT攻击中的恶意载荷，提高APT攻击威胁感知系统的效率与精确性，让安全研究人员能更快实现
APT攻击的发现和溯源。</p>
<p><strong>==5.1 DGA域名检测——C2链接分析==</strong>
<strong>DGA（域名生成算法）是一种利用随机字符来生成C2域名</strong>，从而逃避域名黑名单检测的技术手段。而有了DGA域名生成算法，攻击者就可以利用它来生成用作域名的伪随机字符串，这样就可以有效的避开黑名单列表的检测。伪随机意味着字符串序列似乎是随机的，但由于其结构可以预先确定，因此可以重复产生和复制。该算法常被运用于远程控制软件上。</p>
<h2><span id="安全-ai的问题和难点">安全 + AI的问题和难点</span></h2>
<h1><span id="fuzzing漏洞挖掘">Fuzzing漏洞挖掘</span></h1>
<p><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzg5MTM5ODU2Mg==&amp;action=getalbum&amp;album_id=2041739478687416320&amp;scene=173&amp;from_msgid=2247493698&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect">杨秀章</a></p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title>安全场景（2）恶意加密流量检测*</title>
    <url>/posts/368N99B/</url>
    <content><![CDATA[<h2><span id="基于机器学习的恶意加密流量检测">基于机器学习的恶意加密流量检测</span></h2>
<p>[1] Anderson B, McGrew D. Identifying encrypted malware traffic with
contextual flow data[C]//Proceedings of the 2016 ACM workshop on
artificial intelligence and security. 2016: 35-46.</p>
<figure>
<img src="image-20220516100235456.png" alt="image-20220516100235456">
<figcaption aria-hidden="true">image-20220516100235456</figcaption>
</figure>
<h4><span id="在进行tls握手时会进行如下几个步骤">在进行TLS握手时，会进行如下几个步骤：</span></h4>
<ol type="1">
<li><strong>Client Hello</strong>，客户端提供支持的加密套件数组（cipher
suites）；</li>
<li><strong>Server
Hello</strong>，由服务器端选择一个加密套件，传回服务器端公钥，并进行认证和签名授权（<strong>Certificate</strong>
+ Signature）；</li>
<li>客户端传回客户端公钥（<strong>Client Key
Exchange</strong>），客户端确立连接；</li>
<li>服务器端确立连接，开始 HTTP 通信。</li>
</ol>
<p><img src="https://pic4.zhimg.com/80/v2-a10c338f4c3e283b3b29d0e5752f1beb_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h3><span id="一-特征提取">一、特征提取</span></h3>
<h4><span id="11-可观察的数据元统计特征">1.1 可观察的数据元统计特征</span></h4>
<ul>
<li><strong>传统流数据</strong> (Flow Meta)
<ul>
<li>流入和流出的字节数和数据包数</li>
<li>源端口和目的端口</li>
</ul></li>
<li><strong>字节分布</strong> (BD, Byte Distribution)
<ul>
<li>数据包有效负载中遇到的每个字节值的计数</li>
<li>提供了大量<strong>数据编码</strong>和<strong>数据填充</strong>的信息</li>
<li>字节分布概率 ≈ 字节分布计数 / 分组有效载荷的总字节数</li>
<li>特征表示：1×256维字节分布概率序列</li>
</ul></li>
<li><strong>分组长度和分组到达间隔时间的序列 </strong>(SPLT, Sequence of
Packets Length and Times)
<ul>
<li><strong>==使用马尔可夫链模型建模==</strong></li>
</ul></li>
</ul>
<h4><span id="12-未加密的tls头部信息特征">1.2 未加密的TLS头部信息特征</span></h4>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220516101251514.png" alt="image-20220516101251514" style="zoom: 33%;"></p>
<blockquote>
<p><strong>TLS/SSL协议 过程</strong></p>
<ul>
<li>两层子协议：握手协议和记录协议</li>
<li>握手协议特点
<ul>
<li>加密明文但不加密握手过程</li>
<li>有多个版本但握手参数不变</li>
</ul></li>
</ul>
</blockquote>
<ul>
<li><strong>Client Hello</strong>
<ul>
<li>列出的密码套件列表(Cipher Suites)
<ul>
<li>密钥交换算法、加密算法</li>
<li>报文认证消息码(MAC)算法</li>
</ul></li>
<li>支持的扩展列表(Extensions)
<ul>
<li>提供额外功能或设定</li>
</ul></li>
</ul></li>
<li><strong>Server Hello</strong>：选定的密码套件和TLS扩展</li>
<li><strong>Certificate</strong>：服务器签发的证书信息</li>
<li><strong>Client Key Exchange</strong>：使用的密钥交换算法参数</li>
</ul>
<figure>
<img src="../../../../../../Library/Application%20Support/typora-user-images/image-20220516101639662.png" alt="image-20220516101639662">
<figcaption aria-hidden="true">image-20220516101639662</figcaption>
</figure>
<h4><span id="13-上下文数据">1.3 上下文数据</span></h4>
<ul>
<li><strong>DNS上下文流</strong>
<ul>
<li>基于目标IP地址与TLS相关的DNS响应
<ul>
<li>域名长度</li>
<li>DNS响应返回的IP地址数</li>
<li>DNS TTL值</li>
<li>域名在Alexa榜的排名</li>
</ul></li>
<li>补充了加密流中可能缺失的信息</li>
</ul></li>
<li><strong>HTTP上下文流</strong>
<ul>
<li>在TLS流5min窗口内的<strong>相同源IP地址的所有HTTP流</strong></li>
<li>恶意软件可能<strong>利用HTTP的头部字段</strong>来发起恶意活动
<ul>
<li>Content-Type、Server、Code</li>
</ul></li>
</ul></li>
</ul>
<h3><span id="二-工业落地">二、工业落地</span></h3>
<p>然而，AI技术如没有得到有效运用，也无法在实战中检测到加密的威胁行为。例如无监督学习可以定位未知威胁，但精准度待提升；有监督学习精确度高，却无法覆盖未知威胁。</p>
<h4><span id="21如何在实战中精准识别加密流量攻击">2.1
<strong>如何在实战中精准识别加密流量攻击？</strong></span></h4>
<p><strong>深信服安全团队经过7000+用户实践发现，只有将无监督学习和有监督学习智能化结合，才能最大限度提升加密流量攻击的识别率。</strong></p>
<figure>
<img src="https://mmbiz.qpic.cn/mmbiz_png/EJiaEo3Lq9kqe1fjo1Clib3ZyjiaxESYbUib3sYpbgKND3aB0b2gRURRDxECcT3mmFicMQdhdOaPDn2QVjyZ2rV8VrQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h4><span id="22有监督学习精准识别已知加密流量">2.2
<strong>有监督学习精准识别已知加密流量</strong></span></h4>
<p>有监督机器学习通过将已知、带标签的行为数据输入系统，学习分析数据行为，并根据数据标签来检测、识别特定的高级威胁。深信服NDR（全流量高级威胁检测系统）应用AI模型，基于有监督机器学习抓取所有上下行流量，<strong>提取1000+维度特征</strong>，同时增加了模型训练算法LightGBM学习特征的权重，对已知高级威胁的检测更为精准。传统的检测方式基于一个模型检测多个场景，不同场景的特征不尽相同，因此误报率很高。<strong><font color="red">
深信服NDR基于AI模型有监督学习进行场景化建模，一个模型对应一个场景，根据场景特征进行针对性检测</font></strong>，<strong>模型检测精准率能够达到98%</strong>。</p>
<h4><span id="23无监督学习提前发现未知加密流量">2.3
<strong>无监督学习提前发现未知加密流量</strong></span></h4>
<p>无监督的机器学习覆盖了聚类、神经网络等方法，不依赖任何标签值，通过自主学习，挖掘数据内在特征，实现自动化全面检测，更合理地利用资源，提升效率。</p>
<p>深信服NDR基于AI模型无监督学习方法，通过聚类学习、特征映射等智能分析技术建立设备加密流量动态行为基线，筛选出异常的、可疑的行为，同时结合行为聚合与关联分析，<strong>检测出未知威胁的早期迹象，最大程度地实现自动化检测</strong>，可以快速检测出如下异常，帮助网络安全团队主动预防威胁：</p>
<ul>
<li>异常的网络设备JA3</li>
<li>异常的访问时间和访问频率</li>
<li>异常的上下行数据包比率</li>
<li>异常的证书签发机构</li>
</ul>
<p><strong>以常见的“服务器权限获取手法webshell加密通信”为例</strong>，攻击者通过渗透系统或网络安装webshell
，在应用服务器上执行敏感命令、窃取数据、植入病毒，危害极大。‍webshell具有很强的隐蔽性，<strong>传统的、基于单向数据流的流量检测方案，无法实时更新数据，难以有效检测webshell</strong>。</p>
<p>深信服NDR基于AI模型无监督学习的<strong><font color="red">
孤立森林异常点</font></strong>检测算法，可以构建特征向量，精准检测“孤立离群”的webshell访问行为，<strong>具有更高检出率，更低误报率</strong>。除了webshell加密通信场景外，深信服NDR同样支持隧道检测、CS漏洞、加密挖矿、加密反弹shell等威胁检测，覆盖多种加密威胁场景。</p>
<h2><span id="三-算法比赛总结">三、算法比赛总结</span></h2>
<blockquote>
<p><a href="../算法比赛/恶意加密流量（1）DataCon2020-恶意加密流量检测.md">恶意加密流量（1）DataCon2020-恶意加密流量检测.md</a></p>
<p><a href="../算法比赛/恶意加密流量（2）Datacon2021恶意加密流量检测.md">恶意加密流量（2）Datacon2021恶意加密流量检测.md</a></p>
<p><a href="../算法比赛/恶意加密流量（3）西湖论剑AI大数据安全分析赛.md">恶意加密流量（3）西湖论剑AI大数据安全分析赛.md</a></p>
<p>#### 流量处理的工具</p>
<p>#### <strong>zeek</strong>:https://github.com/zeek/zeek</p>
<p><a href="https://darkdefender.medium.com/https-medium-com-melanijan93-analysing-pcaps-with-bro-zeek-33340e710012">使用
Bro/Zeek 分析 PCAP</a></p>
<p><a href="https://www.freebuf.com/sectool/235587.html">流量分析的瑞士军刀：Zeek</a></p>
<p>Zeek Analysis Tools (ZAT):</p>
<p>#### joy：</p>
</blockquote>
<blockquote>
<p><a href="https://github.com/ahlashkari/CICFlowMeter">CICFlowMeter</a>：</p>
</blockquote>
<h3><span id="21-数据包级">2.1 数据包级</span></h3>
<h4><span id="1长度分布">（1）长度分布</span></h4>
<p>根据Cisco的研究【17】，<strong>恶意软件和普通软件在正向流和反向流中的数据包长度分布不同</strong>。<strong><font color="red">
例如，当我们使用谷歌搜索时，客户端向服务器发送少量数据包，然后服务器返回大量数据包。然而，恶意软件的作用恰恰相反：恶意软件通常让客户端将数据传输到服务器，然后服务器定期返回调度命令。</font></strong>无论是否加密，数据包长度始终可见，因此它适合作为一种功能。我们将数据包长度和方向编码为一维独立特征。我们推测，感染恶意软件的客户端和服务器之间的一些控制消息的长度总是相似且频繁的，这具有很好的区分程度。<strong>我们考虑每个可能的数据包长度和方向元组。由于Internet上的最大传输单元（MTU）是1500字节，并且数据包的方向有两个发送或接收方向，因此我们的长度分布特征是3000维。</strong>为了提取这些特征，我们计算具有不同长度的所有数据包的数量，并进行规范化以确保概率分布。我们使用随机森林（RF）算法来处理这些特征。因为它能更好地处理高维特征，并且具有可解释性。</p>
<h4><span id="2长度序列">（2）长度序列</span></h4>
<p>第二部分，在不使用序列信息的情况下，我们只使用了数据包长度的统计特征，这可能会在时间上丢失一些信息，因此我们提取了数据包长度序列。<strong>我们在每个客户端的双向上取前1000个数据包长度</strong>，并将其放入TextCNN算法中以提取局部序列关系。因为该算法运行速度快，精度高。文本数据的卷积神经网络TextCNN【22】是一种用于句子分类任务的有用的深度学习算法。<strong>在这种情况下，我们将每个数据包的长度视为一个单词，长度序列相当于一个句子</strong>。</p>
<h4><span id="3服务器ip">（3）服务器IP</span></h4>
<p>在我们的数据集中，服务器IP地址是一个重要的标识符。<strong>我们假设，在同一地区，如果客户端感染了相同的恶意软件，则可能会导致其访问相同的服务器IP地址</strong>。因此，我们还考虑了对服务器IP地址的访问。<strong>值1或0表示是否访问了特定的服务器IP地址（一个热编码）</strong>。我们使用朴素贝叶斯（NB）算法来处理这些特征。由于朴素贝叶斯算法是一种非参数算法，其本质是寻找特征和标签之间的关系。因此，它可以被视为一个黑名单。</p>
<h4><span id="4词频分类器">（4）词频分类器</span></h4>
<p><strong>X509证书在Internet上广泛使用</strong>。它们用于验证实体之间的信任。证书颁发机构通常将X509证书链接在一起。如图2所示。[23]，<strong>X509证书提供URL、组织、签名等信息</strong>。我们从培训集中每个客户端的TLS流中提取X509证书链，并获取证书中<strong>主题</strong>和<strong>颁发者</strong>中包含的单词。我们将所有单词组合在一起，并将客户的流量视为由这些单词组成的句子。与B部分类似，我们计算每个单词的数量并将其用作特征。0我们使用朴素贝叶斯（NB）算法来处理这些特征。如果测试集样本证书中的所有单词从未出现在训练集中，我们将直接推断它是恶意的。因为训练集包含最流行的域名。</p>
<p><img src="image-20220621131035005.png" alt="image-20220621131035005" style="zoom: 67%;"></p>
<h4><span id="5tcp状态马尔可夫">==（5）TCP状态马尔可夫==</span></h4>
<p>我们发现<strong>恶意流量和正常流量之间TCP连接状态的分布是不同的</strong>。表一说明了可能的TCP连接状态[24]。我们按照流出现的时间对其进行排序，然后使用马尔可夫随机场转移矩阵（MRFTM）对该特征进行编码。MRFTM在建模连接状态序列时很有用。MRFTM[i，j]中的每个条目统计第i个和第j个状态之间的转换次数。最后，我们对MRFTM的行进行规范化，以确保适当的马尔可夫链。然后我们将其重塑为一维向量，也就是说，我们使用MRFTM的条目作为特征。我们使用随机森林（RF）算法来处理这些特征。</p>
<h3><span id="22-会话流级">2.2 会话流级</span></h3>
<h4><span id="6会话流量统计">（6）会话流量统计</span></h4>
<p>在加密流量中，上述5种分类器在主机级使用不同的特征提取方法和分类方法。此外，为了进一步提高准确率，防止恶意软件由于缺乏领域知识而欺骗分类器，我们还提取了TLS握手中的明文信息。在这个分类器中，我们首先考虑流级特征。我们仅选择TLS流，并分析每个流。一旦推断流是恶意的，就会推断相应的客户端被感染。我们对TCP和TLS协议进行了深入分析，<strong>提取了1000多个维度的流级特征</strong>，包括以下部分：</p>
<ul>
<li><strong>TCP连接状态特性</strong>：如F部分所述，我们对每个流的TCP连接状态进行一次热编码。</li>
<li><strong>统计特征</strong>：我们还提取常规统计特征，表II显示了相关特征名称和描述。</li>
</ul>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220621141516374.png" alt="image-20220621141516374" style="zoom: 33%;"></p>
<ul>
<li><strong>长度马尔可夫特征</strong>：数据包长度序列的操作类似于F部分中的TCP连接状态序列。长度值被离散为大小相等的容器。长度数据马尔可夫链有10个箱子，每个箱子150字节。假设一个1500字节的MTU，任何观察到的大小大于1350字节的数据包都被放入同一个bin中。</li>
<li><strong>TLS握手功能</strong>：我们发现客户端和服务器的TLS协议版本在恶意和良性TLS流之间有不同的分布，因此我们对客户端和服务器的TLS版本进行了一次热编码。此外，由于恶意软件可能使用旧的密码套件，我们在客户端和服务器上都对密码套件和扩展进行n-hot编码，即将所有密码套件和扩展扩展扩展为一维0向量，如果当前流使用某个密码套件或扩展，则相应的位置集值为1。</li>
<li><strong>TLS证书特性</strong>：我们发现，在恶意流中，很大一部分叶证书是自签名的，或者自签名证书出现在证书链中。恶意软件喜欢利用的自签名证书的成本很低。因此，我们分析从服务器发送的证书：<strong>证书链是否包含自签名证书、叶证书是否过期、证书版本、证书有效期、公钥长度、是否发生警报</strong>。同时，考虑到之前的词频分类器，我们发现一些词无法区分恶意和良性，因此我们还将流词频添加到流特征中。</li>
</ul>
<h3><span id="23-主机级特征">2.3 主机级特征</span></h3>
<h4><span id="7主机级荷载无关特征聚合流级统计信息">（7）<strong>主机级荷载无关特征聚合</strong>
(流级统计信息)</span></h4>
<p><strong>单独的看每条流可能漏掉了流之间的关联行为即主机级别的行为</strong>，比如恶意软件在发出正常的访问谷歌流量后可能就要开始进行恶意传输。再比如，有少量正常流也会出现自
签名，如果我们单独看流，可能就会误判，但是如果我们基于主机提取特征发现同一
IP
下有多条流都是自签名，则我们就会有很大的信心认为这是恶意的。因此，我们将上一小节中流级别
的特征进行聚合，并以流为基本单位提取主机级别特征。</p>
<p><strong>主机级特征聚合部分主要考虑了如下的特征:</strong></p>
<ul>
<li><strong>总包个数</strong>，<strong>每条流的平均包个数</strong>，<strong>时间间隔、包长的均值</strong>，以及上一个小节中证书部分的相关特
征，即<strong>自签名流数量，过期流数量，有效期过长（比如
100年）的流数量及其均值。</strong></li>
<li>TLS 半连接 和无连接</li>
</ul>
<h3><span id="24-上下文信息特征">2.4 上下文信息特征</span></h3>
<h4><span id="8其他应用协议">（8）其他应用协议</span></h4>
<p><strong><font color="red">HTTP头部信息</font></strong></p>
<ul>
<li><strong>Content-Type</strong>，正常流量 HTTP 头部信息汇总值多为
<code>image/*</code>，而恶意流量为
<code>text/*、text/html、charset=UTF-8</code> 或者
<code>text/html;charset=UTF-8</code>。</li>
<li><strong>User-Agent</strong></li>
<li><strong>Accept-Language</strong></li>
<li><strong>Server</strong></li>
<li><strong>HTTP响应码</strong></li>
</ul>
<p><strong><font color="red"> DNS响应信息</font></strong></p>
<ul>
<li><strong>==域名的长度==</strong>：正常流量的域名长度分布为均值为6或7的高斯分布（正态分布）；而恶意流量的域名（FQDN全称域名）长度多为6（10）。</li>
<li><strong>==数字字符及非字母数字(non-alphanumeric
character)的字符占比==</strong>：正常流量的DNS响应中全称域名的数字字符的占比和非字母数字字符的占比要大。</li>
<li><strong>DNS解析出的IP数量</strong>：大多数恶意流量和正常流量只返回一个IP地址；其它情况，大部分正常流量返回2-8个IP地址，恶意流量返回4或者11个IP地址。</li>
<li><strong>TTL值</strong>：正常流量的TTL值一般为60、300、20、30；而恶意流量多为300，大约22%的DNS响应汇总TTL为100，而这在正常流量中很罕见。</li>
<li><strong>域名是否收录在Alexa网站</strong>：恶意流量域名信息很少收录在Alexa
top-1,000,000中，而正常流量域名多收录在其中。</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title>安全场景（2）离地攻击检测</title>
    <url>/posts/KK562V/</url>
    <content><![CDATA[<h2><span id="living-off-the-land恶意软件系统分析">Living-Off-The-Land
恶意软件系统分析</span></h2>
<blockquote>
<p>[][AI安全论文] <a href="https://mp.weixin.qq.com/s?__biz=Mzg5MTM5ODU2Mg==&amp;mid=2247496069&amp;idx=1&amp;sn=f5aecaae5494b900b29f12078a2d632e&amp;chksm=cfcf4148f8b8c85ee56fbab09252bb4dc90f936cfb6decaa860b5e91457c9838cfb35179041a&amp;scene=178&amp;cur_album_id=1776483007625822210#rd">21.S&amp;P21
Survivalism经典离地攻击（Living-Off-The-Land）恶意软件系统分析</a>:S&amp;P21的离地攻击（Living-Off-The-Land）系统分析，这是一篇非常经典的论文，并且系统性分析文章是另一种讲故事的方式。</p>
</blockquote>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuMu3z61w35bGkJLmiaMzSMlbhFgicVxHG54dmR1ic5oqLlwSSzT28qicT2Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:67%;"></p>
<blockquote>
<p>原文作者：Frederick Barr-Smith, Xabier Ugarte-Pedrero, et al.
<strong>原文标题</strong>：Survivalism: Systematic Analysis of Windows
Malware Living-Off-The-Land
<strong>原文链接</strong>：https://ieeexplore.ieee.org/document/9519480
<strong>发表会议</strong>：2021 IEEE Symposium on Security and Privacy
(SP)</p>
</blockquote>
<p><strong>文章目录：</strong></p>
<ul>
<li><p><strong>摘要</strong></p></li>
<li><p><strong>一.引言</strong></p>
<p>1.什么是离地攻击</p>
<p>2.APT中的离地攻击</p>
<p>3.提出五个关键问题</p>
<p>4.贡献（Contribution）</p></li>
<li><p><strong>二.背景和相关工作</strong></p>
<p>A.LotL Binaries</p>
<p>B.Scope of our Study</p>
<p>C.Related Work</p></li>
<li><p><strong>三.MOTIVATION: 杀毒软件产品 vs
离地攻击技术</strong></p></li>
<li><p><strong>四.离地攻击流行性评估</strong></p>
<p>A.Dataset Composition</p>
<p>B.Analysis Pipeline</p>
<p>C.LotL Technique Identification</p>
<p>D.Parameter Analysis to Identify Execution Purpose</p></li>
<li><p><strong>五.评估结果</strong></p>
<p>A.商用恶意软件中LotL技术的流行性（Prevalence）</p>
<p>B.Comparison of Benign and Malicious Samples</p>
<p>C.Prevalence of LotL techniques in APT Malware</p></li>
<li><p><strong>六.案例分析</strong></p></li>
<li><p><strong>七.要点和讨论</strong></p></li>
<li><p><strong>八.局限性和未来工作</strong></p></li>
<li><p><strong>九.个人感受</strong></p></li>
</ul>
<h3><span id="摘要">摘要</span></h3>
<p>随着恶意软件检测算法和方法变得越来越复杂（sophisticated），恶意软件作者也采用（adopt）同样复杂的逃避机制（evasion
mechansims）来对抗（defeat）它们。<strong>民间证据表明离地攻击技术（Living-Off-The-Land，LotL）是许多恶意软件攻击中最主要的逃避技术之一。这些技术利用（leverage）系统中已经存在的二进制文件来执行（conduct）恶意操作。</strong>基于此，我们首次对Windows系统上使用这些技术的恶意软件进行大规模系统地调查。</p>
<p>在本文中，我们分析了这些本地系统的二进制文件在多个恶意软件数据集上的使用情况，这些数据集共包含31,805,549个样本。我们发现平均流行率（prevalence）为9.41%。实验结果表明，LotL技术被大量的使用，特别是在高级持久性威胁（Advanced
Persistent Threat
，APT）恶意软件样本中，离地攻击占比为26.26%，是社区恶意软件的两倍多。</p>
<p><strong>为了验证（illustrate）LotL技术的逃逸潜力，我们在本地沙箱环境（sandboxed
environment）中对几个完全打补丁的Windows系统进行了离地攻击技术的测试，其结果表明在10个最流行的反病毒产品（anti-virus）中存在明显的gap。</strong></p>
<h3><span id="一-引言">一、引言</span></h3>
<h4><span id="11-什么是离地攻击">1.1 什么是离地攻击</span></h4>
<p>恶意软件开发和检测是猫和老鼠的游戏，恶意软件作者不断开发新技术来绕过（bypass）检测系统。像AV杀毒软件（anti-virus）这样的安全产品通过静态和启发式分析（heuristic
analysis）技术，以检测、分类和防止恶意软件有效执行。</p>
<p>在过去，许多解决方案严重依赖于基于签名的检测，但不幸的是，由于使用了<strong>多态性（polymorphism）和加壳程序（packers）</strong>，这些方法变得不再那么有效。相反，许多产品开始开发启发式分析解决方案，包括检测恶意行为的算法。这些算法已成为AV引擎的重要组成部分。随着时间的推移，这些算法越来越复杂，因此需要更多创新性的逃避技术。</p>
<p>恶意软件作者和红队经常研究和发现新方法来绕过安全解决方案。虽然它们的潜在目标本质上可能有所不同，但这两种类型的攻击者通常都利用（leverage）最先进（state-of-the-art）的逃避技术来实现目标。<strong>从防守者的角度来看，为了及时作出响应，了解这些攻击和研究它们的趋势是至关重要的（crucial）</strong>。其中，在红队和恶意软件作者中都流行的规避策略就是使用离地攻击（LotL）技术。</p>
<p>==<strong>离地攻击（LotL）技术是指使用系统中已经存在或易于安装的二进制文件（如已签名的合法管理工具）来执行后渗透活动（post-exploitation
activity）。</strong>==</p>
<ul>
<li>通过利用这些工具，攻击者可以<strong>实现注册表修改、持久化、网络或系统侦察，或执行其他恶意代码</strong>。它们甚至可以用来减少由恶意活动产生的事件日志，而不需要将其他文件下载到本地的系统中。</li>
</ul>
<h4><span id="12-apt中的离地攻击">1.2 APT中的离地攻击</span></h4>
<p>离地攻击并不是隐蔽的技术，它们在互联网上公开记录着。许多开源的攻击安全工具利用了LotL技术，并且经常被攻击者所使用，从合法的红队到业余的网络攻击者，以及有组织的APT团队。</p>
<ul>
<li><code>PoshSpy[15]</code>：是一个俄罗斯APT29攻击模块，它是第一个被检测到的APT组织使用的LotL技术，特别是在PowerShell和Windows
Management中。</li>
<li>伊朗威胁组织[1]、APT33、APT34和其他组织也以使用本地Windows二进制文件和其它签名工具而闻名，特别是PowerShell[8]。</li>
</ul>
<p>尽管“离地攻击”在信息安全界是一个相对知名的术语，但有时很难找到一个精确的定义。此外，据我们所知，没有任何研究包含了对LotL技术在恶意软件样本中的流行程度的系统分析。关于LotL技术的文档大多以博客的形式出现，并记录着某些恶意软件家族的在野发现，或者攻击者在远程访问受损系统中所使用技术的描述。</p>
<ul>
<li>例如，<code>Emotet</code> 和
<code>Trickbot</code>，两个最常见的远程访问木马（Remote Access
Trojans，RAT），据称是使用链接的LotL二进制文件来实现持久化。</li>
<li>作为一种对策，微软描述了对抗使用LotL技术商用RAT的基本步骤。高度逃逸的远程访问木马
<code>Astaroth</code>，<code>TA505</code>
组织的一些恶意软件库，<code>Dexphot cryptominer</code> 和
<code>Nodersok</code> 同期使用的多个LotL二进制文件。</li>
</ul>
<h4><span id="13-提出5个关键性问题">1.3 提出5个关键性问题</span></h4>
<p>在本文中，我们分析了LotL现象，即商用恶意软件中与离地攻击二进制文件利用相关的文件。我们首先描述了什么是LotL
binary以及它如何被恶意软件利用来实施恶意行为的。</p>
<p>本文的研究重点是以Windows为主导的操作系统下流行且恶意软件最常针对的目标。<strong>许多基于离地攻击的AV逃逸行为已被记录下来。因此（As
a
consequence），安全界很大程度上认为，LotL技术（如代理执行恶意软件）实际上对安全解决方案是有效的。</strong></p>
<p>首先，我们提出了第一个假设以及第一个研究问题：</p>
<blockquote>
<p>#### <strong>问题1：Can LotL techniques effectively evade commercial
AV?</strong></p>
<p>#### ==LotL技术能有效地逃避目前大部分安全厂商的杀毒软件检测吗？==</p>
</blockquote>
<p>为了回答这个问题，我们评估了一组具有代表性的安全产品，并展示了其中的一些技术，虽然这是攻击者和防御者所熟知的，但仍然是绕过安全解决方案的有效方法，因此对安全行业来说这仍是一个开放的挑战。</p>
<p><strong>事实上，LotL二进制文件经常被系统管理员和高级计算机用户使用来执行（perform）系统管理任务，这使得即使是对于训练有素的分析人员来说，区分（distinguish）合法行为和恶意行为也非常困难</strong>。我们负责任地向受影响的供应商披露了我们的发现并进行跟进，因此提高了他们的检测能力。</p>
<p>尽管现有的文档提供了这些技术使用的可靠证据，但仍然不清楚这种现象在恶意软件样本中有多普遍。因此（In
this way），我们就提出了第二个研究问题：</p>
<blockquote>
<p>#### <strong>问题2：How prevalent is the use of LotL binaries in
malware?</strong></p>
<p>#### ==在恶意软件中使用LotL二进制文件的情况有多普遍？==</p>
</blockquote>
<p>在此基础上，我们试图阐明当前威胁情景中的一些趋势，以确定（identify）：</p>
<blockquote>
<p>#### <strong>问题3：What purposes do malware binaries use LotL
techniques for?</strong></p>
<p>#### ==恶意软件的二进制文件使用LotL技术的目的是什么？==</p>
<p>#### <strong>问题4：Which malware families and types use LotL
binaries most prolifically and how does their usage differ?</strong></p>
<p>####
==哪些恶意软件家族和类型使用LotL二进制文件最多，它们的使用情况又有何不同？==</p>
</blockquote>
<p>此外，我们还调查（investigate）了为什么这些技术难以检测。部分杀毒软件公司参与了我们的披露，即将恶意攻击与系统管理员执行完全合法的管理任务区分开来是困难的。这就给我们带来了另一个问题：</p>
<blockquote>
<p><strong>问题5：What are the overlaps and differences in the behavior
of legitimate and malicious binaries with respect to the usage of LotL
binaries? How would this affect detection by heuristic AV
engines?</strong></p>
<p>####
==在使用LotL二进制文件方面，合法和恶意二进制文件的行为有哪些重叠和差异呢？这将如何影响启发式AV引擎的检测呢？==</p>
</blockquote>
<p>虽然恶意样本和良性样本之间的LotL二进制使用频率（prevalence）有一些明显的差异，但我们也注意到一些类别存在某些相似性，如<strong>代理执行（proxied
execution）</strong>。</p>
<p>最后，<strong>我们将注意力集中在高逃逸和高级持续威胁的恶意软件上，我们发现它利用离地攻击技术是商用恶意软件的两倍</strong>。在表1中列出了一些使用LotL技术进行攻击的APT组织。</p>
<h4><span id="14-贡献">1.4 贡献</span></h4>
<p>据我们所知，本文提出了迄今为止对商用和APT恶意软件使用LotL技术最大规模的系统分析。本文的核心（core
）贡献：</p>
<ul>
<li>我们通过测试一组最流行的AV引擎来对抗基于LotL技术部署的恶意载荷，以评估LotL技术的可行性，并展示了离地攻击检测的复杂性对行业仍是一个挑战。<strong>即使在披露9个月后，这些技术仍没有被发现</strong>。</li>
<li>我们对代表现代商用恶意软件的几个数据集进行了大规模的评估，并确定了LotL技术的流行程度，以及在不同恶意软件家族和类型之间的差异。我们还评估了LotL技术由于假阳性风险可能对行业产生的影响。</li>
<li>我们评估了一个APT恶意软件数据集，并将其公开以促进（facilitate）后续的研究，并确定它执行LotL技术的频率是商用恶意软件的两倍。此外，我们还确定了哪些APT组织最多地使用LotL技术。</li>
</ul>
<h3><span id="二-背景和相关工作">二、背景和相关工作</span></h3>
<p>我们首先定义LotL二进制文件，并枚举恶意软件使用这些二进制文件的目的。</p>
<h4><span id="21-lotl-binaries">2.1 LotL Binaries</span></h4>
<p>近年来，“<code>Living-Off-The-Land binary（LOLbin）</code>”已经成为一个常用词，用来指在网络攻击中广泛使用的二进制文件。历史上，“Living-Off-The-Land”一直被用来表示可以为农业或狩猎提供喂养土地或离地的概念。<strong>转换为恶意软件和入侵领域，攻击者可能利用那些已经可以使用的文件（即系统上已经存在或易于安装的）来发起攻击并躲避检测。</strong></p>
<p>在本文中，我们将LotL二进制定义为：</p>
<ul>
<li>==<strong>任何具有公认合法用途的二进制文件，在攻击期间利用它直接执行恶意行为，或间接协助一系列恶意行动，从而达到恶意结果。</strong>==</li>
</ul>
<blockquote>
<p>In this paper, we define a LotL binary as any binary with a
recognised legitimate use, that is leveraged during an attack to
directly perform a malicious action; or to assist indirectly, in a
sequence of actions that have a final malicious outcome.</p>
</blockquote>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuuKVSBxwXyah6oA8o8y4YIcSszS9wu9wTcMpoVLldVNGWEmTcXX8Slw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<h4><span id="举例">举例：</span></h4>
<ul>
<li>在Windows系统上默认安装的二进制文件（binaries installed），如
<code>Reg.exe</code> 、<code>Sc.exe</code> 和 <code>Wmic.exe</code>
是最常被恶意软件执行的文件。</li>
<li>大多数默认安装的二进制文件都是由微软认证码签名的。认证码签名证明二进制文件没有在编译中被篡改或修改，这些二进制文件甚至可能被列为白名单。<strong>利用可信的LotL二进制文件的恶意软件可能因此避开杀毒软件</strong>。在Windows系统上使用系统二进制文件可以作为恶意软件操作的一部分，更重要的是，许多LotL技术使用系统二进制文件来实现这些二进制文件的目的。</li>
<li>此外，可以使用外部签名二进制文件（external signed binaries），如
<code>PsExec.exe</code>
或其他系统内部二进制文件。虽然它们使用频率不高，但本文的分析也囊括了这些文件。<strong>如APT组织在
<code>SoftCell</code> 和 <code>Havex</code> 中都使用
<code>PsExec.exe</code>
来秘密执行远程命令，从而实现网络中的横向移动。</strong></li>
<li>某些罕见情况，脆弱的（已签名）驱动程序被用来升级系统上的权限。这是
<code>RobbinHood</code> 勒索软件和各种 <code>APT wiper</code>
恶意软件样本所使用的一种技术，针对 <code>Saudi Arabian</code> 系统，包括
<code>Dustman</code> 、<code>Shamoon</code> 和
<code>Zerocleare</code>。</li>
</ul>
<h4><span id="可追溯性traceability"><strong>可追溯性（Traceability）：</strong></span></h4>
<ul>
<li>某些LotL二进制文件可能会比其他文件留下更多的系统日志，安全工具或取证分析人员可以利用这些日志来检测恶意操作。<strong>例如，可以将Powershell配置为具有全面的日志记录</strong>。</li>
<li>微软甚至建议<strong>阻止在系统上执行一些本机的二进制文件</strong>，除非有充分的理由。</li>
</ul>
<h4><span id="22-scope-of-our-study">2.2 Scope of our Study</span></h4>
<p>在本文中，我们关注的是Windows恶意软件执行系统二进制文件的目的。这些目的通常包括沿着
<strong>kill
chain</strong>的进展或逃避AV的检测。所有这些技术都被部署在系统的用户空间中。</p>
<p><code>hollowing</code> 和 <code>injection（注入）</code>
不在我们的研究范围内，尽管这是无文件恶意软件部署的常见技术。因为根据我们早期的定义，它们不是LotL技术。</p>
<h4><span id="23-related-work">2.3 Related Work</span></h4>
<blockquote>
<p>离地攻击相关工作较少，并且都非常经典，因此下面罗列了详细的相关研究，仅供自己后续深入，也希望对您有所帮助。</p>
</blockquote>
<ul>
<li>LotL恶意软件及其别名，“advanced volatile
threat”或“无文件”恶意软件在当前的学术文献中很少被提及。这主要受限于介绍分析少或描述为一个新兴的高逃逸恶意软件变体。</li>
<li>Li等[31]对恶意PowerShell脚本进行了分析，其中有一个小节专门描述了LotL攻击和无文件攻击作为近年来网络攻击的趋势。（<strong>作者第17篇博客详细介绍过PS经典</strong>）</li>
<li>Wang等[72]最近发表的一篇关于数据来源分析的论文指出，Living-Off-The-Land
是一种新兴的、突出的逃避型恶意软件子类（evasive malware
subtype）。（<strong>经典的You Are What You
Do后续即将分享</strong>）</li>
<li>先前的工作[64]进行了介绍性分析，然而LotL恶意软件还没有受到详细的学术分析。（An
emerging threat Fileless malware: a survey and research
challenges）</li>
<li>==<strong>赛门铁克</strong>[73,66]和<strong>思科Talos</strong>的[65]白皮书介绍了这个主题，并对多个数据集的流行性进行了分析。目前，没有论文对包含多个使用LotL技术的Windows恶意软件数据集进行大规模地系统分析。（<strong>经典</strong>）==
<ul>
<li>https://www.symantec.com/content/dam/symantec/docs/security-center/white-papers/istr-living-off-the-land-and-fileless-attack-techniques-en.pdf</li>
<li>https://www.symantec.com/content/dam/symantec/docs/white-papers/living-off-the-land-turning-your-infrastructure-against-you-en.pdf</li>
<li>https://blog.talosintelligence.com/2019/11/hunting-for-lolbins.html</li>
</ul></li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuo3I9Tc2Y5ic4biaG6jqMn0XNQbwVBw1LBM5ibErWYib2DDXc2avCPt2iaXQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<p>在一些论文中提到了LotL技术，强调了高隐蔽（stealthiness）和APT恶意软件曾使用。</p>
<ul>
<li><p>在一篇关于恶意软件分析工具Yara的论文中，Cohen[9]将LotL描述 “ LotL
as a trend that has been recently observed in the tactics used by elite
threat actors”，我们的分析结果进一步证实了该说法。</p></li>
<li><p>Hassan等[21]的研究表明，APT恶意软件使用LotL攻击策略来实现持续攻击并分析了两个活动，他们的工作还利用了MITRE
ATT&amp;CK框架[45]，通过MITRE定义了一个描述和分类知名攻击的分类方法。<strong>许多LotL技术在MITRE
ATT&amp;CK框架内被索引</strong>。Mitre公司及其常见CVE漏洞是安全领域的既定权威，他们囊括并描述许多LotL技术，这样表明离地攻击是一个值得深入分析的课题。</p></li>
<li><ul>
<li><strong>==W. U. Hassan, A. Bates, and D. Marino, “Tactical
Provenance Analysis for Endpoint Detection and Response Systems,” IEEE
Symposium on Security and Privacy, 2020.==</strong></li>
</ul></li>
</ul>
<p>==<strong>强烈推荐一个包含LotL二进制和ATT&amp;CK功能映射的资源</strong>：==</p>
<ul>
<li>https://github.com/LOLBAS-Project/LOLBAS</li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuicYc1hL2AJtlQRoibrRvWzTQjdOsicdTsl0q5kzawT3MibrOM71uREq5wQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<p>与我们研究相关的是对基于脚本的恶意软件分析和去混淆。使用LotL技术的恶意软件经常使用恶意脚本作为有效负载。（<strong>下列论文在作者第16篇PowerShell总结博客中详细介绍过</strong>）</p>
<ul>
<li>Ugarte等[67]通过识别可疑行为模式，测试了经
<code>Powershell.exe</code> 二进制调用的恶意脚本。</li>
<li><strong>Rubin等[61]将机器学习应用于检测PowerShell恶意软件（微软团队）</strong>。</li>
<li>Curtsinger[11]等人提出了恶意Javascript攻击的检测机制——ZOZZLE。</li>
</ul>
<p><strong>虽然这些论文提出了有效的检测方法，但是他们都是为狭隘的恶意载荷（payload）所用，他们没有分析更广泛的恶意软件生态系统和这些有效载荷是如何被LotL二进制文件触发的。</strong></p>
<h3><span id="三-动机">三、动机</span></h3>
<p><strong>安全研究人员已经记录了许多使用LotL技术成功躲避安全产品的案例</strong>。在许多情况下，这些<strong>LotL二进制文件被用来代理恶意载荷的执行，使其在一个合法的进程上下文中执行，或者作为一个合法系统进程的子进程生成一个新进程</strong>。在某些情况下，这些有效载荷作为LotL二进制调用的副作用被执行，而在其他情况下，它只是其主要记录行为的结果。此外，许多杀毒产品未能正确检测到这些技术。</p>
<figure>
<img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuqG91IHaTia5YXypwibNOxcZymPMV5Ku4TjBhzZlOv1icJx9VnwDhZfVfw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p><strong>为了回答第一个问题，我们首先分析了当前AV产品是否将LotL技术作为恶意行为的指标。</strong></p>
<p>为此，我们首先选择了10个具有代表性的AV产品（详见附录C），并利用常见<strong>基于LotL的代理执行技术来实施反弹Shell的模拟攻击</strong>。此外，本研究的目的不是测试任何特定AV产品的检测能力或将它们相互比较，而是确定是否存在普遍的检测差距。</p>
<ul>
<li>实验在联网的Windows
10虚拟机执行，并将最新的本地AV产品连接到它们的云组件。</li>
<li>利用一个反弹Shell来评估AV系统在部署LotL技术的恶意软件中有多脆弱。本文认为能够允许远程执行命令的reverse
shell是成功执行代码的证明，这与许多远程访问木马（RAT）功能相同。</li>
<li>通过从不同LotL二进制文件中运行这个反弹shell来进行实验，以测试AV产品是否检测到离地攻击技术是恶意的。</li>
<li>我们在必要时混淆了反弹shell的有效载荷，并使用各种有效载荷类型来测试AV检测传递机制本身的能力，而不是通过静态签名传递的特定有效载荷（详见附录D）。</li>
</ul>
<h4><span id="实验结果如表2所示">实验结果如表2所示：</span></h4>
<ul>
<li><strong>可以发现大部分的AV引擎允许我们建立一个反弹Shell并执行命令，它们并没有检测出利用LotL技术的恶意软件，60个中只检测出4个。</strong></li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuoBzOPNqhU9ce1SlxeLjb0e6mb3RUz0rkP2wrKGjKibMMUltIvMvbUeA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<h4><span id="负责任的披露和回应">负责任的披露和回应：</span></h4>
<p>此后，我们向相关的AV供应商发布了一份文件，包含我们检查的结果并协助补救。9个月后，我们在Windows
10机器上重复了类似的测试，这允许我们测试AV供应商是否在他们的产品中包含了新的启发式规则来检测LotL二进制的使用。其结果如下：</p>
<ul>
<li><strong>可以发现在60个相同的有效载荷中检测到了25个</strong></li>
<li>在检测到的反弹shell测试中，我们修改了载荷（利用混淆或运行不同的载荷），同时为LotL二进制文件保持了完全相同的命令行参数，通过利用这些混淆和修改的有效载荷，我们成功地在这25个被拦截的实例中的19个执行了一个反向shell。</li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuHRbN87ZFfsyVAYjqDAoDicE27vuhSBiaLf4zlGotKd2yrNfxA7Z3h2icw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<p>==<strong>实验结果表明，LotL技术仍然是杀毒软件供应商面临的一个重大挑战。合法用户通常以不可预知的方式使用这些工具，而安全公司很难在没有误报的情况下部署有效的检测策略。</strong>==</p>
<p>接下来将展示这些技术如何在商用恶意软件中是普遍存在的，以及离地攻击是不应该被安全社区忽视的问题。</p>
<h3><span id="四-离地攻击流行性评估">四、离地攻击流行性评估</span></h3>
<p>在本节中，我们测量了恶意软件中LotL技术的流行程度，并试图回答所提出的研究问题。</p>
<h4><span id="41-数据集描述">4.1 数据集描述</span></h4>
<p>评估工作是在9个独立的子数据集上进行的。我们总共收集了31,805,549个样本，其中我们从VirusTotal（VT）中获得了16,048,202份行为报告。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXulUhTGQG5b3yfdmTq4NIo8YaKGvb39A0WOwvqUft2aUEB7MwGebkjGw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<p>==<strong>Public Datasets</strong>==</p>
<p>公共恶意软件数据集，包括商用恶意软件、VirusShare语料库的二进制文件、窗口恶意PE文件、佐治亚理工学院发布的可执行文件、VX-Mumbal和MalShare共享的样本（两个重点的共有数据集）。</p>
<ul>
<li>https://impactcybertrust.org/dataset{ }view?idDataset=1143</li>
<li>https://vx-underground.org/samples.html</li>
<li>https://malshare.com</li>
</ul>
<p><strong>VirusTotal Balanced Dataset</strong></p>
<p>从VT中收集了237,288个hash值，利用 <code>AVClass</code>
预处理代码和打标签（家族分类），并平衡数据集中每个族。</p>
<p><strong>APT Malware</strong></p>
<p>我们根据一种类似于数据集论文dAPTaset[59]的方法收集了一个APT恶意软件的数据集。我们处理了HTML页面和pdf文件（<code>APTnotes</code>），并提取了这些文件中包含的所有恶意软件的hash值。</p>
<ul>
<li>https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-rezaeirad.pdf</li>
<li>https://github.com/aptnotes/data</li>
</ul>
<p>==<strong>Yara Rule Match Malware</strong>==</p>
<p>部署3个Yara规则来检测LotL二进制文件，并使用Livehunte来识别上传到VT的新的恶意软件hash，并使用LotL技术匹配恶意软件的行为特征。</p>
<h4><span id="42-analysis-pipeline">4.2 Analysis Pipeline</span></h4>
<p>当收集了由Windows
PE二进制文件组成的不同数据集，我们就分析样本的行为。包括三个阶段：</p>
<ul>
<li>data collection</li>
<li>data augmentation</li>
<li>data analysis</li>
</ul>
<blockquote>
<p>First Seen：首次发现病毒样本的时间戳 AVClass
Family：某恶意软件样本所属家族 <strong>Behavioural
Report：恶意行为报告，由特定恶意软件样本执行的进程和Shell命令的列表</strong></p>
</blockquote>
<h4><span id="43-lotl-techniqueidentification">4.3 LotL Technique
Identification</span></h4>
<p><strong>数据准备就绪，那么如何识别是否使用了LotL技术呢？</strong></p>
<p>我们使用<strong>模式匹配</strong>来识别恶意软件执行过程中对LotL二进制文件调用的情况，从而处理所有收集到的行为报告（<code>behavioural reports</code>）。行为报告包括两个指标：</p>
<ul>
<li><p><strong>Shell Commands（Shell命令）</strong></p>
<p><strong>恶意二进制文件在主机操作系统中执行的Shell命令</strong>，Shell命令日志可以通过引用系统二进制文件的绝对路径来显示它的执行情况。<strong>同时，Windows的命令提示符还包括许多别名，例如Reg.exe的reg</strong>。</p></li>
<li><p><strong>Processes（进程）</strong></p>
<p><strong>进程日志明确由恶意软件样本执行的系统二进制文件</strong>。执行的参数也包含在行为报告中的进程日志中。</p></li>
</ul>
<p>在我们的分析中，如果一个样本的行为报告包含至少一个LotL二进制文件的执行，那么它使用了LotL技术。<strong>我们记录了每一个LotL的执行及其参数细节，并将它们插入到数据库中。然后，我们分析了这些恶意软件样本的参数，以确定每个数据集中最==常见的参数类型和执行目的==。</strong></p>
<p>具体而言，我们确定了这两种独立类型的二进制文件：</p>
<ul>
<li><strong>Default System Binaries</strong></li>
<li><strong>Installed Signed Binaries</strong></li>
</ul>
<p>模式匹配优化：模式匹配方法在不断改进，直到所有识别的LotL命令被正确分类和映射到执行目的，并进行了数据清洗处理。</p>
<ul>
<li>不带参数的二进制执行移除</li>
<li>沙箱产物删除（如Explorer.exe和sha256），Web访问不处理</li>
<li>删除Verclsid.exe的实例</li>
</ul>
<h4><span id="44parameter-analysis-to-identify-execution-purpose">==4.4
Parameter Analysis to Identify Execution Purpose==</span></h4>
<p>==<strong>为了确定LotL技术的执行目的，我们观察了恶意软件样本提供的参数。</strong>==</p>
<p>图1说明了四个进程执行的映射。该映射通过识别单独的执行目的来在所有数据集上实施，<strong>例如执行Net.exe时使用stop参数表示任务停止。在将单个命令映射到执行目的之后，我们将为该二进制文件选择所有匹配的执行</strong>。我们在所有系统二进制执行中重复该步骤，直到每次执行被分类为属于特定的执行目的或被错误分类。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuHicN1aicniaStH5EZY1y22UBUzsMYXomMtNgYwuQYr1AZ8vWfRTPJOFPg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<p>按照这种方法，我们按目的将参数分为9个独立的类别。</p>
<p><strong>首先是三种与执行有关的类型：</strong></p>
<ul>
<li><strong>Proxied
Execution</strong>：代理执行，如Mshta.exe执行.hta文件，Rundll32.exe执行.dll文件</li>
<li><strong>Persistence</strong>：持久化：如果恶意代码配置或修改系统以在未来某个时间点执行命令或存储的作业，那么它就实现了持久性，比如Sc.exe带有创建参数的Bitsadmin.exe，或带有日期时间参数的Schtasks.exe/At.exe</li>
<li><strong>Delayed Execution</strong>：延迟执行，比如
Ping.exe执行-n</li>
</ul>
<p><strong>接着是三类与底层系统组件的修改有关。恶意软件通常从事这种行为，以便在机器上对目标进行==进一步的传播==或行动。</strong></p>
<ul>
<li><strong>Firewall Modification</strong>：防火墙修改，如Netsh.exe</li>
<li><strong>Registry Modification</strong>：注册表修改，如Reg.exe</li>
<li><strong>Permissions
Modification</strong>：权限修改，如Cacls.exe修改文件权限</li>
</ul>
<p><strong>最后是与执行或系统修改无关的三类。</strong></p>
<ul>
<li><strong>File Opening</strong>：打开文件，如Explorer.exe</li>
<li><strong>Reconnaissance</strong>：侦察，触发本地或远程配置的横向移动，如Net.exe</li>
<li><strong>Task
Stopping</strong>：使用LotL二进制文件秘密停止另一个进程或服务，如Taskkill.exe</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title>安全场景（3）高级威胁发现</title>
    <url>/posts/3J7GHQ3/</url>
    <content><![CDATA[<h2><span id="安全场景-高级威胁发现">安全场景 - 高级威胁发现</span></h2>
<blockquote>
<p>CSKB: A Cyber Security Knowledge Base Based on Knowledge Graph</p>
</blockquote>
<h3><span id="一-背景">一、背景</span></h3>
<p>APT
一般具有三个特性，即<strong>高级性</strong>、<strong>持续性</strong>和<strong>危害性</strong>。在
APT
的攻击模型方面，包括了<strong>杀伤链模型、钻石模型、TTP模型和ATT&amp;CK模型</strong>等。</p>
<h4><span id="11-威胁模型">1.1 威胁模型</span></h4>
<h5><span id="a-杀伤链模型">（a) 杀伤链模型</span></h5>
<p>杀伤链模型，最初起源于军事中的 C5KISR 系统中的
K（kill），后由洛克希德-马丁公司（全球最大的国防工程承包商，根据
Cybersecurity 500
名单，洛克希德-马丁公司在全球上市网络安全企业中位列前十）提出网络安全杀伤链七步模型，用来识别和防护网络入侵行为。<strong>网络安全杀伤链七步模型包括侦测、武器化、投递、漏洞利用、安装、控制和目标行动等</strong>。</p>
<figure>
<img src="https://pics2.baidu.com/feed/8694a4c27d1ed21b053dc6cebe6f05cc51da3f2a.jpeg?token=a84d479a7fc2e90987f1994b589690c8" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h5><span id="b-钻石模型">（b) 钻石模型</span></h5>
<p>钻石模型是由 Sergio Caltagirone、Andrew Pendergast、Christopher Betz
在 2013 年论文 The Diamond Model of Intrusion Analysis
中提出的一个针对网络入侵攻击的分析框架模型。该模型由四个核心特征组成，分别为：<strong>对手（adversary）、能力（capability）、基础设施（infrastructure）和受害者（victim）</strong>。四个核心特征间用连线表示相互间的基本关系，并按
照菱形排列，从而形成类似“钻石”形状的结构，因此得名为“钻石模型”。同时，模型还定义了社会-政治关系（对手和受害者之间的）和技术能力（用于确保能力和基础设施可操
作性的）两个重要的扩展元特征。该模型也认为，无论何种入侵活动，其基本的元素都是一个一个的事件，而每个事件都可以由上述四个基本核心特征组成。</p>
<h5><span id="c-ttp模型">（c) TTP模型</span></h5>
<p>TTP，该术语来自于三个英文词汇的首字母组合，即<strong>战术
Tactics、技术 Techniques 和过程
Procedures</strong>，是描述高级威胁组织网络攻击的重要指标，出自于《美国国防部军事及相关术语词典》，最早用于军事领域和反恐活动，后延伸到信息安全领域，并被用来描述相应
的过程。TTP
在网络情报中是核心信息，它与指标、事件、活动、攻击者、攻击目标有着密切的关联关系。</p>
<h5><span id="d-attampck模型">（d) ATT&amp;CK模型</span></h5>
<p>ATT&amp;CK 也就是 Adversarial Tactics, Techniques, and Common
Knowledge。顾名思义，这并不是一项技术，而是“对抗战术、技术和常识”框架，是更加底层“知识库”的基础框架，是由攻击者在攻击企业时会利用的
<strong>12 种战术和 244
种企业技术组成的精选知识库</strong>。它的着眼点不是单个的 IOC，而是
<strong>IOC
处于攻击过程中的上下文</strong>，也就是从点扩展到了面扩展到了链。当
ATT&amp;CK
把那些翻阅字典一样，轻易地找到相对应的常见战术动作，甚至做到杀伤链还原，更好地应对攻击。</p>
<p>APT
最经典的防护模型之一则是<strong>滑动标尺模型</strong>，它来源于美国系统网络安全协会（SANS），主要应对日益复杂的网络环境和不断变化的攻击手段。</p>
<p>滑动标尺模型分为五大类别，这五大类别之间具有连续关系，并有效展示了防御逐步提升的理念。这五大类别不是固定不变的，且重要程度不是均等的,
每个类别的某些措施与相邻类别密切相关,实现网络安全目标，组织应构建安全根基和文化，并不断完善，滑动标尺模型还能潜在促进组织的安全成熟进程。</p>
<figure>
<img src="https://pics0.baidu.com/feed/2e2eb9389b504fc2872cc4baffdc3f1990ef6d23.png?token=442ffe0f38a993cce0cb142181377fad" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title>安全场景（4）Webshell检测</title>
    <url>/posts/C7WFJN/</url>
    <content><![CDATA[<h2><span id="深度学习phpwebshell查杀引擎demo">深度学习PHP
webshell查杀引擎demo</span></h2>
<blockquote>
<ul>
<li>https://www.cdxy.me/?p=788</li>
<li><strong>==Webshell研究综述：检测与对抗技术的动态博弈进展==</strong>：https://zhuanlan.zhihu.com/p/259985000</li>
</ul>
</blockquote>
<h5><span id="传统webshell查杀思路">传统webshell查杀思路</span></h5>
<ul>
<li>规则系统</li>
<li>旁路执行</li>
<li>沙箱</li>
</ul>
<h5><span id="基于机器学习深度学习的webshell查杀引擎通过专家知识提取特征训练分类器其结果受样本-特征-结构等多种因素影响">基于机器学习/深度学习的webshell查杀引擎，通过专家知识提取特征训练分类器，其结果受样本、特征、结构等多种因素影响。</span></h5>
<h5><span id="特征维度">特征维度：</span></h5>
<ul>
<li><strong>统计特征</strong> (信息熵/重合指数/最长词/可压缩比)</li>
<li><strong>历史数据特征</strong>
(计算单个文件的落盘时间/文件创建进程/文件类型/代码风格/权限和同目录下其他文件的"距离")</li>
<li><strong>OP指令层特征</strong> (指令/调用链/参数文本特征)</li>
<li><strong>动态特征</strong>
(文件读写/网络连接，可依靠沙箱或旁路执行能力解决编码混淆类case)</li>
<li><strong>文本语义</strong> (n-gram/TF-IDF/word2vec/CNN/RNN)</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title>安全场景（5）恶意DNS检测</title>
    <url>/posts/30K2RMS/</url>
    <content><![CDATA[<h1><span id="datacon-2019-dns-analysis">DataCon 2019: DNS Analysis</span></h1>
<p>https://ixyzero.com/blog/archives/4473.html</p>
<ul>
<li>Datacon 2019：https://github.com/shyoshyo/DataCon-9102-DNS</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title>安全场景（6）PowerShell</title>
    <url>/posts/2MX2YPX/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>网络安全</category>
      </categories>
  </entry>
  <entry>
    <title>业务安全（1）API安全</title>
    <url>/posts/QTDMWG/</url>
    <content><![CDATA[<h2><span id="api安全">API安全</span></h2>
<h3><span id="一-背景简介">一、背景简介</span></h3>
<h4><span id="11-api">1.1 API</span></h4>
<p><strong>应用程序编程接口（API）是一组允许软件组件进行交互的协议</strong>。中间接口通常用于简化开发，使软件团队能够重复使用代码。API还通过将应用程序与它们所运行的基础设施脱钩来抽象系统之间的功能。尽管API在现代商业中的好处和用例不断增加，但固有的安全挑战带来了各种安全风险。</p>
<h4><span id="12-api安全">1.2 API安全</span></h4>
<p>一个API代表了一组服务，允许一个程序与另一个外部或内部程序进行通信。当我们谈论API安全时，我们通常指的是保护应用程序的后端服务，包括其数据库、用户管理系统或其他与数据存储交互的组件。API安全包括采用多种工具和做法来保护技术栈的完整性。一个强大的安全的API包括一个组织使用的API和使用这些API的服务。这包括防止恶意行为者访问敏感信息或代表你采取你不希望他们执行的行动。</p>
<p>不幸的是，虽然API是现代应用程序的一个重要组成部分，但它们是攻击者访问敏感信息的一个常见目标。在使用API时，了解第三方应用程序如何通过接口输送数据是至关重要的。此外，随着API日益成为一个攻击载体，API安全措施有助于安全团队评估安全风险，并有一个全面的计划来保护它们。</p>
<p><strong>由于API是公开访问的，它们是窃取敏感信息的常见目标，包括应用逻辑、用户凭证、信用卡号码等</strong>。此外，API端点的漏洞也会被恶意行为者利用，以获得对系统或网络的未授权访问，进行其他形式的攻击，如跨站脚本和代码注入。在线网络应用安全项目<a href="https://owasp.org/www-project-api-security/">（OWASP）发布了基于风险的十大漏洞建议</a>，以确保网络API的安全。这些包括:</p>
<h4><span id="13-最常见的api安全风险">1.3 最常见的API安全风险</span></h4>
<h5><span id="owasp-api安全-top-102032变化解读">OWASP API安全 top 10
2032变化解读</span></h5>
<ul>
<li>https://github.com/OWASP/API-Security</li>
<li>https://owasp.org/www-project-api-security/</li>
</ul>
<p>在开发过程中以及每当API更新时，应解决以下API安全风险:</p>
<ul>
<li><strong>破坏对象级授权</strong>。当请求可以访问或修改请求者不应该访问的数据时，例如能够通过篡改请求中的标识符访问另一个用户的帐户，就会发生BOLA。</li>
<li><strong>破坏函数级授权</strong>。当没有实现最小权限原则(POLP)时就会出现这种情况，通常是由于过于复杂的访问控制策略造成的。它导致攻击者能够执行敏感命令或访问针对特权帐户的端点。</li>
<li><strong>用户身份验证失败</strong>。与BOLA一样，如果身份验证过程被破坏，攻击者可以一次性甚至永久地冒充另一个用户。</li>
<li><strong>过多的数据暴露</strong>。API对请求的响应通常返回比相关或必要的数据更多的数据。尽管数据可能不会显示给用户，但可以很容易地检查这些数据，并可能导致敏感信息的潜在暴露。</li>
<li><strong>资产管理不当。</strong>API的开发和部署通常是快节奏的，在急于发布新的或更新的API时，经常会遗漏完整的文档。这将导致暴露的和幽灵端点，以及对旧api如何工作和需要实现的理解不足。</li>
<li><strong>缺乏资源和速率限制。</strong>API端点通常对互联网开放，如果对请求的数量或大小没有限制，则对DoS和暴力攻击开放。</li>
<li><strong>注入缺陷</strong>。如果没有正确地解析和验证请求数据，攻击者可能会发起命令或SQL注入攻击来访问它或在未经授权的情况下执行恶意命令。</li>
<li><strong>大规模作业。</strong>软件开发框架经常证明，只需一行代码就可以将从在线表单接收到的所有数据插入到数据库或对象中，这被称为批量赋值，从而无需编写重复的表单映射代码。如果没有指定哪些数据是可接受的，就会打开各种攻击向量。</li>
</ul>
<h3><span id="二-技术现状">二、技术现状</span></h3>
<h4><span id="api-安全性最佳实践">API 安全性最佳实践</span></h4>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><a href="https://owasp.org/www-project-api-security/">OWASP API
安全项目</a></li>
<li>API 安全性最佳实践：https://juejin.cn/post/7196653524204453947</li>
<li></li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>应用场景</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>【draft】算法优化（1）SliceLine- Fast, Linear-Algebra-based Slice Finding for ML Model Debugging</title>
    <url>/posts/ZP2YPE/</url>
    <content><![CDATA[<h2><span id="slicelinefast-linear-algebra-based-slice-finding-for-ml-model-debugging-sigmod21">SliceLine:
Fast, Linear-Algebra-based Slice Finding for ML Model Debugging （SIGMOD
’21）</span></h2>
<blockquote>
<ul>
<li>论文下载：https://mboehm7.github.io/resources/sigmod2021b_sliceline.pdf</li>
<li></li>
</ul>
</blockquote>
<h3><span id="摘要">摘要</span></h3>
<p>切片查找——最近一项关于调试机器学习（ML）模型的工作旨在查找前K个数据切片（例如，谓词的连接词，如性别女性和博士学位），其中经过训练的模型的表现明显不如整个训练/测试数据。这些切片可以用于为有问题的子集获取更多数据、添加规则或以其他方式改进模型。与决策树相比，一般的切片查找问题允许重叠的切片。由此产生的搜索空间是巨大的，因为它涵盖了特征的所有子集及其不同的值。因此，现有的工作主要依赖于启发式，并专注于适合单个节点内存的小型数据集。在本文中，我们从算法和系统的角度，以整体的方式解决了切片查找的这些可扩展性限制。我们利用切片大小、错误和结果分数的单调性财产来促进有效的修剪。<strong>此外，我们提出了一种优雅的基于线性代数的枚举算法，它允许在现有ML系统的基础上进行快速枚举和自动并行化。</strong>对不同真实世界回归和分类数据集的实验表明，有效的修剪和高效的稀疏线性代数使精确枚举变得可行，即使对于具有许多特征、相关性和数据大小超过单节点内存的数据集也是如此。</p>
<h3><span id="一-说明">一、说明</span></h3>
<p>机器学习（ML）和数据驱动的应用程序从根本上改变了IT格局的许多方面，从面向用户的应用程序到后端决策系统，再到软件和硬件堆栈的优化[21，36，56]。开发和部署用于生产的ML管道过程中的关键步骤是<strong>数据验证（分析输入数据特征）</strong>[56，59]和<strong>模型调试（分析有效的ML模型特征）</strong>[22，56，60]。需要考虑的方面包括数据误差（如异质性、人为误差、测量误差）、缺乏模型泛化（如过拟合、不平衡、域外预测）以及系统偏差和缺乏公平性。缺乏模型验证和调试可能会导致无声但严重的问题[56]。例如，种族偏见的监狱风险评估[6]、基于积雪的狼检测[58]和基于图像水印的马检测[38]。模型调试旨在识别此类问题。</p>
<p>模型调试技术：除了基本数据调试和验证[56，59]、服务期间的模型准确性监测和比较[56，60]，以及通过混淆矩阵进行手动模型误差分析（例如，正确标签与预测标签的矩阵可视化）外，还存在几种先进的模型调试技术。计算机视觉领域的例子有显著性图[30，63，70]、逐层相关性传播[8，38]和基于遮挡的解释[75]，它们都旨在找到对预测有重大影响的输入图像区域。数据管理界最近通过利用这种计算中固有的重叠，为基于遮挡的解释贡献了有效的增量计算方法[47，48]。然而，对于具有连续和分类特征的结构化数据和预测任务，文献相对较少。现有的工作包括解释表[25]（主要关注数据摘要）和切片查找器[18，19]，其目的是查找前K个数据切片（例如，谓词的连接词，如性别女性和博士学位），其中训练的模型的表现明显不如整个数据集。找到这样的有问题的切片对于理解缺乏训练数据或模型偏差非常有用，但也可以作为改进模型的途径</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（1）字节-色情导流用户识别</title>
    <url>/posts/1G5MF0A/</url>
    <content><![CDATA[<h1><span id="字节跳动安全ai挑战赛-大佬等等我">字节跳动安全AI挑战赛-大佬等等我</span></h1>
<ul>
<li><strong>比赛链接</strong>：https://security.bytedance.com/fe/ai-challenge#/challenge
<ul>
<li>基于文本和多模态数据的风险识别
<ul>
<li>电商黄牛地址识别</li>
<li><strong>色情导流用户识别</strong></li>
</ul></li>
<li>小样本半监督风险识别
<ul>
<li>人机识别</li>
<li>少样本作弊样本检测任务</li>
</ul></li>
</ul></li>
</ul>
<h2><span id="色情导流用户识别">色情导流用户识别</span></h2>
<blockquote>
<p>色情导流赛道 2ndSolution
https://github.com/rooki3ray/2021BytedanceSecurityAICompetition_track1</p>
</blockquote>
<h3><span id="一-赛题描述">一、赛题描述</span></h3>
<p>随着互联网的快速发展，网络黑产特别是色情导流也日益增多，给用户带来了极大的伤害。色情导流用户发布色情/低俗内容吸引用户，并且通过二维码、联系方式、短网址等完成导流。本赛题旨在通过提供用户相关数据，运用机器学习等方法对色情导流用户进行识别，提高模型检测的效果。</p>
<ul>
<li>输入：<strong>用户的特征，包括基础信息、投稿信息、行为信息</strong>。</li>
<li>输出：用户的标签（1表示色情导流用户，0表示正常用户）</li>
<li><strong>评价指标</strong>采用fβ（取β=0.3） <span class="math display">\[ f_{\beta} = (1 + \beta^2)\frac{p*r}{\beta^2*p+r}
\]</span></li>
</ul>
<h4><span id="基础信息">基础信息</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182038415.png" alt="image-20220629211352351" style="zoom:50%;"></p>
<h4><span id="投稿信息">投稿信息</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182038486.png" alt="image-20220629211559660" style="zoom:50%;"></p>
<h4><span id="行为信息">行为信息</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182038131.png" alt="image-20220629211703172" style="zoom:50%;"></p>
<h3><span id="二-数据构成">二、数据构成</span></h3>
<ul>
<li>用户基础信息
<ul>
<li>性别、粉丝数、个签、关注人数……</li>
</ul></li>
<li>用户投稿信息
<ul>
<li>视频标题、poi、省份、投稿时间</li>
</ul></li>
<li>用户行为信息
<ul>
<li>播放次数、点赞数、分享数……</li>
</ul></li>
</ul>
<h3><span id="三-方案说明">三、方案说明</span></h3>
<ul>
<li><strong>特征工程</strong>
<ul>
<li><strong>log1p 数据平滑</strong></li>
<li>类别特征（<strong>LabelEncoder</strong>）</li>
<li>时间特征（<strong>min-max 归一化</strong>）</li>
<li>文本特征（长度、WordVec）</li>
<li>交叉特征</li>
</ul></li>
<li><strong>模型训练</strong>
<ul>
<li>10折lgb交叉验证，均值作为预测结果</li>
<li>伪标签</li>
</ul></li>
<li>最终分数线上第二（0.9906）。</li>
</ul>
<h3><span id="四-代码结构">四、代码结构</span></h3>
<blockquote>
<p>from config import Config</p>
<p>import argparse</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── 1_word2vec.py</span><br><span class="line">├── 2_merge_data.py</span><br><span class="line">├── 3_5_train_kfold.py</span><br><span class="line">├── 4_pseudo_label.py</span><br><span class="line">├── config.py</span><br><span class="line">├── data</span><br><span class="line">│   ├── pseudo.csv</span><br><span class="line">│   ├── raw</span><br><span class="line">│   │   ├── 测试数据</span><br><span class="line">│   │   └── 训练数据</span><br><span class="line">│   ├── sentence</span><br><span class="line">│   │   └── signature</span><br><span class="line">│   ├── test.csv</span><br><span class="line">│   ├── train.csv</span><br><span class="line">│   └── ...</span><br><span class="line">├── evaluate_kfold.py</span><br><span class="line">├── __pycache__</span><br><span class="line">├── readme.md</span><br><span class="line">├── requirements.txt</span><br><span class="line">├── run.sh</span><br><span class="line">├── saved</span><br><span class="line">│   ├── <span class="number">1112_1315_0.985_0</span><span class="number">.9934</span></span><br><span class="line">│   │   └── ...</span><br><span class="line">│   ├── <span class="number">1112_1320_0.985</span>_pseudo_0<span class="number">.9934</span></span><br><span class="line">│   │   └── ...</span><br><span class="line">│   ├── 1112_1321_pseudo_0<span class="number">.985_0</span><span class="number">.9942</span></span><br><span class="line">│   │   ├── <span class="number">1112_1321_0.985</span>_results_kfold_0<span class="number">.9942</span>.csv</span><br><span class="line">│   │   ├── log.log</span><br><span class="line">│   │   └── ...</span><br><span class="line">└── utils.py</span><br></pre></td></tr></table></figure>
<h4><span id="41-runsh">4.1 run.sh</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> -x</span><br><span class="line">python 1_word2vec.py</span><br><span class="line">python 2_merge_data.py</span><br><span class="line">python 3_5_train_kfold.py</span><br><span class="line">python 4_pseudo_label.py</span><br><span class="line">python 3_5_train_kfold.py --pseudo</span><br></pre></td></tr></table></figure>
<h4><span id="42-1_word2vecpy">4.2 1_word2vec.py</span></h4>
<h4><span id="43-5_train_kfoldpy">4.3 <strong>5_train_kfold.py</strong></span></h4>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>算法比赛</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>文本分类（1）搜狐文本情感分类</title>
    <url>/posts/7C1A6K/</url>
    <content><![CDATA[<h2><span id="搜狐情感分析-推荐排序算法大赛-baseline">搜狐情感分析 ×
推荐排序算法大赛 baseline</span></h2>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzAxOTU5NTU4MQ==&amp;mid=2247490226&amp;idx=1&amp;sn=b080925450eb0fa2f8215a33e297214e&amp;chksm=9bc5f2e0acb27bf60296480678b8a8d20ddc0ca1e7e086fd7894fd70372cdd75d0260a915aa6&amp;mpshare=1&amp;scene=23&amp;srcid=0506hKi6p6tQeYmhSvBsgKQT&amp;sharer_sharetime=1651827176665&amp;sharer_shareid=984256fd6ff6c7f7ab7ae447f9006552%23rd">搜狐情感分析
× 推荐排序算法大赛 baseline</a></li>
<li><strong>比赛官网</strong>：https://www.biendata.xyz/competition/sohu_2022/</li>
</ul>
<h3><span id="赛题背景"><strong>赛题背景</strong></span></h3>
<p>在工业界，推荐算法和自然语言处理是结合非常紧密的两个技术环节。本次大赛我们推出创新赛制——NLP
和推荐算法双赛道：探究文本情感对推荐转化的影响。情感分析是NLP领域的经典任务，本次赛事在经典任务上再度加码，研究文本对指定对象的情感极性及色彩强度，难度升级，挑战加倍。同时拥有将算法成果研究落地实际场景的绝佳机会，接触在校园难以体验到的工业实践，体验与用户博弈的真实推荐场景。</p>
<h3><span id="比赛任务"><strong>比赛任务</strong></span></h3>
<p><strong>比赛分为两部分：</strong></p>
<ul>
<li><strong>第一部分：==面向实体对象的文本描述情感极性及色彩强度分析==。情感极性和强度分为五种情况：极正向、正向、中立、负向、极负向。选手需要针对给定的每一个实体对象，从文本描述的角度，分析出对该实体的情感极性和强度。</strong></li>
<li><strong>第二部分：利用给出的用户文章点击序列数据及用户相关特征，结合第一部分做出的情感分析模型，对给定的文章做出是否会形成点击转化的预测判别。用户点击序列中涉及的文章，及待预测的文章，我们都会给出其详细内容。</strong></li>
</ul>
<h3><span id="一-任务1面向实体对象的文本情感分类">一、
<strong>任务1：面向实体对象的文本情感分类</strong></span></h3>
<h4><span id="21-数据加载">2.1 <strong>数据加载</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_file = <span class="string">&#x27;data/Sohu2022_data/nlp_data/train.txt&#x27;</span></span><br><span class="line">test_file = <span class="string">&#x27;data/Sohu2022_data/nlp_data/test.txt&#x27;</span></span><br><span class="line">sub_file = <span class="string">&#x27;data/submission/section1.txt&#x27;</span></span><br><span class="line"></span><br><span class="line">train = pd.read_json(train_file, lines=<span class="literal">True</span>)</span><br><span class="line">test = pd.read_json(test_file, lines=<span class="literal">True</span>)</span><br><span class="line">sub= pd.read_table(sub_file)</span><br></pre></td></tr></table></figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040555.png" alt="图片"></p>
<h4><span id="22-文本长度统计">2.2 <strong>文本长度统计</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train[<span class="string">&#x27;text_len&#x27;</span>].quantile([<span class="number">0.5</span>,<span class="number">0.8</span>,<span class="number">0.9</span>,<span class="number">0.96</span>])</span><br></pre></td></tr></table></figure>
<p><strong>大部分文本长度在562以内</strong>，在迭代过程中发现，输入到模型的文本越完整效果越好，所以可以尝试<strong>文档级的模型</strong>，比如<strong>ernie-doc</strong>或者<strong>xlnet</strong>等。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040982.png" alt="图片" style="zoom:50%;"></p>
<h4><span id="23-实体情感标签统计">2.3 <strong>实体情感标签统计</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.countplot(sentiment_df.sentiment)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sentiment value count&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040704.png" alt="图片" style="zoom:50%;"></p>
<p>可以看出中性情感占到了绝大部分，极端情感最少。因为数据量比较大，大家可以使用一些<strong>采样策略</strong>：</p>
<ul>
<li><strong>中立情感负采样 ，但是有过拟合风险</strong></li>
<li><strong>保证情感比例采样：加快模型迭代速度</strong></li>
<li><strong>对同一个样本的重复情感可以负采样，ent1和ent2：1
text|ent1+ent2</strong></li>
</ul>
<h4><span id="24-数据预处理">2.4 <strong>数据预处理</strong></span></h4>
<p><strong>重复标签</strong>：同一样本的标签有多个，然后按照多个实体情感对样本进行复制，得到每个文本以及标签，处理代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lst_col = <span class="string">&#x27;sentiment&#x27;</span></span><br><span class="line">train = pd.DataFrame(&#123;</span><br><span class="line">    col: np.repeat(train[col].values, train[lst_col].<span class="built_in">str</span>.<span class="built_in">len</span>())</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> train.columns.difference([lst_col])</span><br><span class="line">&#125;).assign(**&#123;lst_col: np.concatenate(train[lst_col].values)&#125;)[train.columns.tolist()]</span><br></pre></td></tr></table></figure>
<h4><span id="模型定义"><strong>模型定义</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LastHiddenModel</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_name, n_classes</span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        config = AutoConfig.from_pretrained(model_name)</span><br><span class="line">        self.model = AutoModel.from_pretrained(model_name, config=config)</span><br><span class="line">        self.linear = nn.Linear(config.hidden_size, n_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_ids, attention_mask, token_type_ids</span>):</span><br><span class="line">        outputs = self.model(input_ids, attention_mask, token_type_ids)<span class="comment"># last_hidden_state和pooler out</span></span><br><span class="line">        last_hidden_state = outputs[<span class="number">0</span>] <span class="comment"># 所有字符最后一层hidden state # 32 400 768 ，但是PAD PAD</span></span><br><span class="line">        input_mask_expanded = attention_mask.unsqueeze(-<span class="number">1</span>).expand(last_hidden_state.size()).<span class="built_in">float</span>()</span><br><span class="line">        sum_embeddings = torch.<span class="built_in">sum</span>(last_hidden_state * input_mask_expanded, <span class="number">1</span>)</span><br><span class="line">        sum_mask = input_mask_expanded.<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line">        sum_mask = torch.clamp(sum_mask, <span class="built_in">min</span>=<span class="number">1e-9</span>)</span><br><span class="line">        mean_embeddings = sum_embeddings / sum_mask</span><br><span class="line">        logits = self.linear(mean_embeddings)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure>
<h4><span id="扩展思路"><strong>扩展思路：</strong></span></h4>
<ul>
<li><strong>长文本处理：模型输入/模型预测:TTA</strong></li>
<li><strong>doc级文本模型：longformer</strong></li>
</ul>
<blockquote>
<p>（<strong>xlnet</strong>）
https://huggingface.co/hfl/chinese-xlnet-base</p>
<p>(<strong>longformer_zh</strong>)
https://huggingface.co/ValkyriaLenneth/longformer_zh</p>
<p>(longformer-chinese-base-4096)
https://huggingface.co/schen/longformer-chinese-base-4096</p>
</blockquote>
<ul>
<li><strong>轻量级模型：LSTM、GRU/Transformer等网络 600 word
300</strong></li>
<li><strong>选择使用不同预训练模型进行微调，chinese-roberta-wwm/nezha/xlnet/ernie/ernie-gram,其中ernie或者ernie-gram效果可能会好些</strong></li>
<li><strong>预训练模型输出的利用：CLS/PoolerOut/LastHiddenState/+(Bi)LSTM/LastFourConcat/etc...</strong></li>
<li><strong>训练优化：对抗训练(FGM/PGD/AWP)/EMA/MultiDropout/Rdrop</strong></li>
<li><strong>文本分类上分微调技巧实战</strong>
<ul>
<li>改进1 Last 4 Layers Concatenating</li>
<li>改进2 模型层间差分学习率:
对不同的网络层数使用不同的学习率，这样可以防止过拟合，有利于加速学习。</li>
</ul></li>
<li>==<strong>BERT长文本处理：《CogLTX: Applying BERT to Long
Texts》</strong>==
<ul>
<li>https://github.com/Sleepychord/CogLTX</li>
<li><strong>分类实例</strong>：https://github.com/Sleepychord/CogLTX/blob/main/run_20news.py</li>
<li>COGLTX采用的策略是将每个子句从原句中移除判断其是否是必不可少的(t是一个阈值)：</li>
</ul></li>
</ul>
<p>​
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040195.png" alt="图片" style="zoom: 67%;"></p>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzkzOTI4ODc2Ng==&amp;mid=2247484174&amp;idx=1&amp;sn=cd2d5d51d9874bbc03d50b0bca9f17f3&amp;scene=21#wechat_redirect"><strong>CogLTX
: bert处理长文本代码解析</strong></a></p>
<ul>
<li><strong>XLNET分类模型</strong></li>
</ul>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> XLNetModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyXLNet</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">35</span>, alpha=<span class="number">0.5</span></span>):</span><br><span class="line"></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="built_in">super</span>(MyXLNet, self).__init__()</span><br><span class="line">        self.net = XLNetModel.from_pretrained(xlnet_cfg.xlnet_path).cuda()</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> self.net.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;layer.11&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;layer.10&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;layer.9&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;layer.8&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;pooler.dense&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">                param.requires_grad = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                param.requires_grad = <span class="literal">False</span></span><br><span class="line">        self.MLP = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">768</span>, num_classes, bias=<span class="literal">True</span>),</span><br><span class="line">        ).cuda()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line"></span><br><span class="line">        x = x.long()</span><br><span class="line">        x = self.net(x, output_all_encoded_layers=<span class="literal">False</span>).last_hidden_state</span><br><span class="line">        x = F.dropout(x, self.alpha, training=self.training)</span><br><span class="line">        x = torch.<span class="built_in">max</span>(x, dim=<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">        x = self.MLP(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(x)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<ul>
<li><strong>长文本理解模型 ERNIE-Doc</strong>
<ul>
<li>ERNIE-DOC，是一个基于Recurrence Transformers(Dai et al., 2019)
的文档级语言预训练模型。
本模型用了两种技术：<strong>回溯式feed机制和增强的循环机制</strong>，<strong>使模型具有更长的有效上下文长度，以获取整个文档的相关信息。</strong></li>
<li>https://github.com/PaddlePaddle/ERNIE</li>
</ul></li>
</ul>
<h3><span id="二-任务2文章点击预测"><strong>二、任务2：文章点击预测</strong></span></h3>
<p>第二部分：利用给出的<strong>用户文章点击序列数据</strong>及<strong>用户相关特征</strong>，结合第一部分做出的情感分析模型，对给定的文章做出是否会形成点击转化的预测判别。用户点击序列中涉及的文章，及待预测的文章，我们都会给出其详细内容。</p>
<h4><span id="21-数据加载">2.1 <strong>数据加载</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train = pd.read_csv(<span class="string">&#x27;data/Sohu2022_data/rec_data/train-dataset.csv&#x27;</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;data/Sohu2022_data/rec_data/test-dataset.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train_data.shape&quot;</span>,train.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test_data.shape&quot;</span>,test.shape)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040116.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>训练集中每条样本包含pvId，用户id，点击序列（序列中的每次点击都包含文章id和浏览时间），用户特征（包含但不限于操作系统、浏览器、设备、运营商、省份、城市等），待预测文章id和当前时间戳，以及用户的行为(1为有点击，0为未点击)。</p>
<blockquote>
<p><strong>smapleId:样本的唯一id</strong></p>
<p><strong>label：点击标签</strong></p>
<p><strong>pvId：将每次曝光给用户的展示结果列表称为一个Group(每个Group都有唯一的pvId)</strong></p>
<p><strong>suv:用户id</strong></p>
<p><strong>itemId：文章id</strong></p>
<p><strong>userSeq:点击序列</strong></p>
<p><strong>logTs：当前时间戳</strong></p>
<p><strong>operator：操作系统</strong></p>
<p><strong>browserType：浏览器</strong></p>
<p><strong>deviceType:设备</strong></p>
<p><strong>osType：运营商</strong></p>
<p><strong>province：省份</strong></p>
<p><strong>city：城市</strong></p>
</blockquote>
<h4><span id="22-数据分析">2.2 数据分析</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">statics</span>(<span class="params">data</span>):</span><br><span class="line">    stats = []</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> data.columns:</span><br><span class="line">        stats.append((col, data[col].nunique(), data[col].isnull().<span class="built_in">sum</span>() * <span class="number">100</span> / data.shape[<span class="number">0</span>],data[col].value_counts(normalize=<span class="literal">True</span>, dropna=<span class="literal">False</span>).values[<span class="number">0</span>] * <span class="number">100</span>, data[col].dtype))</span><br><span class="line">    stats_df = pd.DataFrame(stats, columns=[<span class="string">&#x27;Feature&#x27;</span>, <span class="string">&#x27;Unique_values&#x27;</span>, <span class="string">&#x27;Percentage_of_missing_values&#x27;</span>,<span class="string">&#x27;Percentage_of_values_in_the_biggest category&#x27;</span>, <span class="string">&#x27;type&#x27;</span>])</span><br><span class="line">    stats_df.sort_values(<span class="string">&#x27;Percentage_of_missing_values&#x27;</span>, ascending=<span class="literal">False</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> stats_df  </span><br><span class="line">stats_df=statics(train)</span><br><span class="line">stats_df</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040147.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h5><span id="标签分布如下">标签分布如下:</span></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.countplot(train.label)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;train label count&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182041629.png" alt="图片" style="zoom:67%;"></p>
<h4><span id="23-初步特征工程"><strong>2.3 初步特征工程</strong></span></h4>
<ul>
<li><strong>情感特征</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">amount_feas = [<span class="string">&#x27;prob_0&#x27;</span>, <span class="string">&#x27;prob_1&#x27;</span>, <span class="string">&#x27;prob_2&#x27;</span>, <span class="string">&#x27;prob_3&#x27;</span>,<span class="string">&#x27;prob_4&#x27;</span> ]</span><br><span class="line">category_fea = [<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> tqdm(amount_feas, desc=<span class="string">&quot;amount_feas 基本聚合特征&quot;</span>):</span><br><span class="line">    <span class="keyword">for</span> cate <span class="keyword">in</span> category_fea:</span><br><span class="line">        <span class="keyword">if</span> f != cate:</span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_medi&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;median&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_mean&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_max&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_min&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;min&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_std&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;std&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h5><span id="类别特征count特征">类别特征count特征：</span></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># count特征</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm(sparse_features):</span><br><span class="line">    data[col + <span class="string">&#x27;_count&#x27;</span>] = data.groupby(col)[<span class="string">&#x27;sampleId&#x27;</span>].transform(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">    dense_features.append(col + <span class="string">&#x27;_count&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h5><span id="用户特征">用户特征：</span></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># count特征</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm([<span class="string">&#x27;pvId&#x27;</span>,<span class="string">&#x27;itemId&#x27;</span> ]):</span><br><span class="line">    data[<span class="string">f&#x27;group_suv_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>] = data[[<span class="string">&#x27;suv&#x27;</span>, col]].groupby(<span class="string">&#x27;suv&#x27;</span>)[col].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">    dense_features.append(<span class="string">f&#x27;group_suv_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>)  </span><br></pre></td></tr></table></figure>
<h5><span id="物料特征">物料特征：</span></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pvId nunique特征</span></span><br><span class="line">select_cols = [<span class="string">&#x27;suv&#x27;</span>, <span class="string">&#x27;itemId&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm(select_cols):</span><br><span class="line"></span><br><span class="line">    data[<span class="string">f&#x27;group_pvId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>] = data[[<span class="string">&#x27;pvId&#x27;</span>, col]].groupby(<span class="string">&#x27;pvId&#x27;</span>)[col].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">    dense_features.append(<span class="string">f&#x27;group_pvId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>)      </span><br><span class="line"><span class="comment"># itemId nunique特征</span></span><br><span class="line">select_cols = [<span class="string">&#x27;pvId&#x27;</span>, <span class="string">&#x27;suv&#x27;</span>, <span class="string">&#x27;operator&#x27;</span>, <span class="string">&#x27;browserType&#x27;</span>, <span class="string">&#x27;deviceType&#x27;</span>, <span class="string">&#x27;osType&#x27;</span>, <span class="string">&#x27;province&#x27;</span>, <span class="string">&#x27;city&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm(select_cols):</span><br><span class="line">    data[<span class="string">f&#x27;group_itemId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>] = \</span><br><span class="line">        data[[<span class="string">&#x27;itemId&#x27;</span>, col]].groupby(<span class="string">&#x27;itemId&#x27;</span>)[col].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">    dense_features.append(<span class="string">f&#x27;group_itemId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>) </span><br></pre></td></tr></table></figure>
<h4><span id="nn模型-deepfm"><strong>NN模型-DeepFM</strong></span></h4>
<p>基于deepctr实现DeepFM训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_model_input = &#123;name: train[name] <span class="keyword">for</span> name <span class="keyword">in</span> feature_names&#125;</span><br><span class="line">valid_model_input = &#123;name: valid[name] <span class="keyword">for</span> name <span class="keyword">in</span> feature_names&#125;</span><br><span class="line">test_model_input = &#123;name: test[name] <span class="keyword">for</span> name <span class="keyword">in</span> feature_names&#125;</span><br><span class="line">model = DeepFM(linear_feature_columns, dnn_feature_columns, task=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(<span class="string">&quot;adam&quot;</span>, <span class="string">&quot;binary_crossentropy&quot;</span>, metrics=[<span class="string">&#x27;binary_crossentropy&#x27;</span>, <span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(train_model_input, train[target].values,</span><br><span class="line">                    batch_size=<span class="number">1024</span>, epochs=<span class="number">3</span>, verbose=<span class="number">1</span>, </span><br><span class="line">                    validation_data=(valid_model_input, valid[target].values))</span><br><span class="line"></span><br><span class="line">pred_ans = model.predict(valid_model_input, batch_size=<span class="number">1024</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;valid AUC&quot;</span>, <span class="built_in">round</span>(roc_auc_score(valid[target].values, pred_ans), <span class="number">4</span>))</span><br><span class="line">pred_ans = model.predict(test_model_input, batch_size=<span class="number">1024</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="树模型-catboost"><strong>树模型-Catboost</strong></span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_model = CatBoostClassifier(iterations=<span class="number">15000</span>, depth=<span class="number">5</span>, learning_rate=<span class="number">0.05</span>, loss_function=<span class="string">&#x27;Logloss&#x27;</span>, logging_level=<span class="string">&#x27;Verbose&#x27;</span>, eval_metric=<span class="string">&#x27;AUC&#x27;</span>, task_type=<span class="string">&quot;GPU&quot;</span>, devices=<span class="string">&#x27;0:1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">train_model.fit(train_dataset, eval_set=eval_dataset, early_stopping_rounds=<span class="number">30</span>, verbose=<span class="number">40</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="特征工程思路扩展"><strong>特征工程思路扩展</strong></span></h4>
<ul>
<li><strong>高阶特征：类别特征组合、高阶聚合特征，比例特征</strong></li>
<li><strong>点击序列统计特征：当前用户|全局： item
众数当做类别特征；统计量 count或者nunique</strong></li>
<li><strong>序列 Embedding特征：word2vec，tfidf(词袋)+SVD、graph
embedding(deepwalk)</strong></li>
<li><strong>点击转化率特征：itemid、pvId,类别组合 ..(提分)
Kfold</strong></li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>算法比赛</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（2）字节-小样本半监督风险识别</title>
    <url>/posts/1CE2BYX/</url>
    <content><![CDATA[<h2><span id="字节跳动安全ai挑战赛-大佬等等我">字节跳动安全AI挑战赛-大佬等等我</span></h2>
<ul>
<li><strong>比赛链接</strong>：https://security.bytedance.com/fe/ai-challenge#/challenge
<ul>
<li>基于文本和多模态数据的风险识别
<ul>
<li>电商黄牛地址识别</li>
<li><strong>色情导流用户识别</strong></li>
</ul></li>
<li>小样本半监督风险识别
<ul>
<li>人机识别</li>
<li>少样本作弊样本检测任务</li>
</ul></li>
</ul></li>
<li><strong>人工智能竞赛复盘：2021安全AI挑战赛</strong>
:https://www.bilibili.com/video/BV1PL4y1n7SN?spm_id_from=333.337.search-card.all.click&amp;vd_source=29387dc08d18f642078183a6816e93e8</li>
<li><strong>炼丹术士Zoro</strong>:https://www.zhihu.com/people/AIMuseum/posts</li>
<li><strong>字节跳动安全AI挑战赛直播笔记</strong> - 知乎
https://zhuanlan.zhihu.com/p/435018506</li>
</ul>
<h2><span id="小样本半监督风险识别">小样本半监督风险识别</span></h2>
<h3><span id="一-赛题描述">一、赛题描述</span></h3>
<p>在真实的社交网络中，存在的作弊用户会影响社交网络平台。在真实场景中，会受到多方面的约束，我们仅能获取到少部分的作弊样本和一部分正常用户样本，<strong>现需利用已有的少量带标签的样本，去挖掘大量未知样本中的剩余作弊样本</strong>。给定一段时间内的样本，其中包含少量作弊样本，部分正常样本以及标签未知的样本。参赛者应该利用这段时间内已有的数据，提出自己的解决方案，以预测标签未知的样本是否为作弊样本。数据处理方法和算法不限，但是参赛者需要综合考虑算法的效果和复杂度，从而构建合理的解决方案。</p>
<h4><span id="11-赛题数据与评价指标">1.1 赛题数据与评价指标</span></h4>
<p><strong>赛题数据</strong>：本次比赛给出的数据是T～T+N
时刻内点赞、关注事件下按比例抽样数据以及其对应账号的基础特征数据。</p>
<p><strong>评价指标</strong>：本赛题使用F1-score来评估模型的准召程度</p>
<h3><span id="二-解决方案一">二、 解决方案一</span></h3>
<p>首先明确本赛题实质上仍然是一个二分类的问题，我们也可以完全从此角度出来先构建出一个基础分类模型，然后再<strong>利用大量无标签的数据进行半监督学习来提升模型性能</strong>。</p>
<blockquote>
<p><strong>风险识别：第二名源代码</strong>
https://github.com/Ljwccc/ByteDanceSecurityAI</p>
<ul>
<li>用户侧特征：
<ul>
<li>账户本身的基础特征</li>
<li>账户本身的特征计数统计</li>
<li>粉丝量、关注量、发帖量、被点赞量、最后登陆时间-注册时间
乘除交叉</li>
<li>从请求数据中提取出来的device_type, app_version,
app_channel类别特征，直接作为静态画像使用</li>
<li>类别特征下的数值统计特征 min/sum/max/std</li>
</ul></li>
<li>请求侧特征：
<ul>
<li>用户请求的时间序列特征, 时间差序列特征 min/sum/max/std</li>
<li>w2v特征， 每个用户的请求ip序列建模</li>
</ul></li>
</ul>
</blockquote>
<h3><span id="21-特征工程">2.1 特征工程</span></h3>
<p>从序列特征中提取用户的设备信息、channel信息和app_version信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先 group</span></span><br><span class="line">user_request_cat_group = user_request.groupby([<span class="string">&#x27;request_user&#x27;</span>],as_index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">user_request_device_type = user_request_cat_group[<span class="string">&#x27;request_device_type&#x27;</span>].agg(&#123;<span class="string">&#x27;device_type_list&#x27;</span>:<span class="built_in">list</span>&#125;)</span><br><span class="line">user_request_channel = user_request_cat_group[<span class="string">&#x27;request_app_channel&#x27;</span>].agg(&#123;<span class="string">&#x27;channel_list&#x27;</span>:<span class="built_in">list</span>&#125;)</span><br><span class="line">user_request_app_version = user_request_cat_group[<span class="string">&#x27;request_app_version&#x27;</span>].agg(&#123;<span class="string">&#x27;app_version_list&#x27;</span>:<span class="built_in">list</span>&#125;)</span><br><span class="line"></span><br><span class="line">user_request_device_type[<span class="string">&#x27;device_type&#x27;</span>] = user_request_device_type[<span class="string">&#x27;device_type_list&#x27;</span>].apply(<span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line">user_request_channel[<span class="string">&#x27;channel&#x27;</span>] = user_request_channel[<span class="string">&#x27;channel_list&#x27;</span>].apply(<span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line">user_request_app_version[<span class="string">&#x27;app_version&#x27;</span>] = user_request_app_version[<span class="string">&#x27;app_version_list&#x27;</span>].apply(<span class="keyword">lambda</span> x:x[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">user_feat_from_action = pd.concat([user_request_device_type[[<span class="string">&#x27;request_user&#x27;</span>,<span class="string">&#x27;device_type&#x27;</span>]],user_request_channel[[<span class="string">&#x27;channel&#x27;</span>]], user_request_app_version[[<span class="string">&#x27;app_version&#x27;</span>]]],axis=<span class="number">1</span>).rename(columns=&#123;<span class="string">&#x27;request_user&#x27;</span>:<span class="string">&#x27;user&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>
<h4><span id="211-用户基础特征">2.1.1 用户基础特征</span></h4>
<p>类别特征</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 类别特征</span></span><br><span class="line">cat_cols = [<span class="string">&#x27;user_name&#x27;</span>,<span class="string">&#x27;user_profile&#x27;</span>,<span class="string">&#x27;user_register_type&#x27;</span>,<span class="string">&#x27;user_register_app&#x27;</span>,<span class="string">&#x27;user_least_login_app&#x27;</span>,<span class="string">&#x27;user_freq_ip&#x27;</span>,<span class="string">&#x27;user_freq_ip_3&#x27;</span>,<span class="string">&#x27;device_type&#x27;</span>,<span class="string">&#x27;channel&#x27;</span>,<span class="string">&#x27;app_version&#x27;</span>,<span class="string">&#x27;user_freq_ip_2&#x27;</span>,<span class="string">&#x27;user_freq_ip_1&#x27;</span>,]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手工类别特征</span></span><br><span class="line">user_info[<span class="string">&#x27;user_freq_ip_3&#x27;</span>] = user_info[<span class="string">&#x27;user_freq_ip&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="string">&#x27;.&#x27;</span>.join(<span class="built_in">str</span>(x).split(<span class="string">&#x27;.&#x27;</span>)[:<span class="number">3</span>])) <span class="comment"># 常用ip取前3位</span></span><br><span class="line">user_info[<span class="string">&#x27;user_freq_ip_2&#x27;</span>] = user_info[<span class="string">&#x27;user_freq_ip&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="string">&#x27;.&#x27;</span>.join(<span class="built_in">str</span>(x).split(<span class="string">&#x27;.&#x27;</span>)[:<span class="number">2</span>])) <span class="comment"># 常用ip取前2位</span></span><br><span class="line">user_info[<span class="string">&#x27;user_freq_ip_1&#x27;</span>] = user_info[<span class="string">&#x27;user_freq_ip&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="string">&#x27;.&#x27;</span>.join(<span class="built_in">str</span>(x).split(<span class="string">&#x27;.&#x27;</span>)[:<span class="number">1</span>])) <span class="comment"># 常用ip取前1位</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并从request中提取的基础特征</span></span><br><span class="line">user_info = user_info.merge(user_feat_from_action,on=<span class="string">&#x27;user&#x27;</span>,how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> user_feat_from_action</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类别特征的频次</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cat_cols:</span><br><span class="line">    user_info = freq_enc(user_info,col)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 对所有类别特征做label_encoder</span></span><br><span class="line">user_info = label_enc(user_info,cat_cols)</span><br></pre></td></tr></table></figure>
<p>点赞量，关注量等交叉特征，直接梭哈所有乘除法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_cols = [<span class="string">&#x27;user_fans_num&#x27;</span>,<span class="string">&#x27;user_follow_num&#x27;</span>,<span class="string">&#x27;user_post_num&#x27;</span>,<span class="string">&#x27;user_post_like_num&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col1 <span class="keyword">in</span> num_cols:</span><br><span class="line">    <span class="keyword">for</span> col2 <span class="keyword">in</span> [col <span class="keyword">for</span> col <span class="keyword">in</span> num_cols <span class="keyword">if</span> col!=col1]:</span><br><span class="line">        user_info[<span class="string">f&#x27;<span class="subst">&#123;col1&#125;</span>_<span class="subst">&#123;col2&#125;</span>_mul&#x27;</span>] = user_info[col1]*user_info[col2]</span><br><span class="line">        user_info[<span class="string">f&#x27;<span class="subst">&#123;col1&#125;</span>_<span class="subst">&#123;col2&#125;</span>_div&#x27;</span>] = user_info[col1]/(user_info[col2]+<span class="number">1e-3</span>)</span><br></pre></td></tr></table></figure>
<p>类别特征下粉丝量、关注量、发帖量、被点赞量、请求数量的统计值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_cols = [<span class="string">&#x27;user_fans_num&#x27;</span>,<span class="string">&#x27;user_follow_num&#x27;</span>,<span class="string">&#x27;user_post_num&#x27;</span>,<span class="string">&#x27;user_post_like_num&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> cat_col <span class="keyword">in</span> cat_cols:</span><br><span class="line">    cat_group = user_info.groupby(cat_col)[num_cols]</span><br><span class="line">    <span class="comment"># 平均值</span></span><br><span class="line">    cat_col_stat = cat_group.transform(np.mean)</span><br><span class="line">    cat_col_stat.rename(columns=&#123;name:<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span>_<span class="subst">&#123;cat_col&#125;</span>_mean&#x27;</span> <span class="keyword">for</span> name <span class="keyword">in</span> cat_col_stat.columns&#125;,inplace=<span class="literal">True</span>)</span><br><span class="line">    user_info = pd.concat([user_info,cat_col_stat],axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 和</span></span><br><span class="line">    cat_col_stat = cat_group.transform(np.<span class="built_in">sum</span>)</span><br><span class="line">    cat_col_stat.rename(columns=&#123;name:<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span>_<span class="subst">&#123;cat_col&#125;</span>_sum&#x27;</span> <span class="keyword">for</span> name <span class="keyword">in</span> cat_col_stat.columns&#125;,inplace=<span class="literal">True</span>)</span><br><span class="line">    user_info = pd.concat([user_info,cat_col_stat],axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 方差</span></span><br><span class="line">    cat_col_stat = cat_group.transform(np.std)</span><br><span class="line">    cat_col_stat.rename(columns=&#123;name:<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span>_<span class="subst">&#123;cat_col&#125;</span>_std&#x27;</span> <span class="keyword">for</span> name <span class="keyword">in</span> cat_col_stat.columns&#125;,inplace=<span class="literal">True</span>)</span><br><span class="line">    user_info = pd.concat([user_info,cat_col_stat],axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">del</span> cat_col_stat</span><br></pre></td></tr></table></figure>
<h4><span id="212-序列特征">2.1.2 序列特征</span></h4>
<p><strong>用户请求序列特征</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">user_request_list = user_request.groupby([<span class="string">&#x27;request_user&#x27;</span>],as_index=<span class="literal">False</span>)[<span class="string">&#x27;request_target&#x27;</span>].agg(&#123;<span class="string">&#x27;request_list&#x27;</span>:<span class="built_in">list</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 先按照时间进行排序</span></span><br><span class="line">user_request = user_request.sort_values(by=<span class="string">&#x27;request_time&#x27;</span>,)</span><br><span class="line"><span class="comment"># 请求的数量</span></span><br><span class="line">user_action_feat = user_request.groupby([<span class="string">&#x27;request_user&#x27;</span>],as_index=<span class="literal">False</span>)[<span class="string">&#x27;request_user&#x27;</span>].agg(&#123;<span class="string">&#x27;request_num&#x27;</span>:<span class="string">&#x27;count&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户请求的时间统计量，但是80%的用户只有一次请求行为</span></span><br><span class="line">user_action_feat_temp = user_request.groupby([<span class="string">&#x27;request_user&#x27;</span>],as_index=<span class="literal">False</span>)[<span class="string">&#x27;request_time&#x27;</span>].agg(&#123;<span class="string">&#x27;time_list&#x27;</span>:<span class="built_in">list</span>&#125;)</span><br><span class="line">user_action_feat = user_action_feat.merge(user_action_feat_temp,on=<span class="string">&#x27;request_user&#x27;</span>,how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">user_action_feat[<span class="string">&#x27;time_min&#x27;</span>] = user_action_feat[<span class="string">&#x27;time_list&#x27;</span>].apply(<span class="built_in">min</span>)</span><br><span class="line">user_action_feat[<span class="string">&#x27;time_max&#x27;</span>] = user_action_feat[<span class="string">&#x27;time_list&#x27;</span>].apply(<span class="built_in">max</span>)</span><br><span class="line">user_action_feat[<span class="string">&#x27;time_var&#x27;</span>] = user_action_feat[<span class="string">&#x27;time_list&#x27;</span>].apply(np.var)</span><br><span class="line">user_action_feat[<span class="string">&#x27;time_max-min&#x27;</span>] = user_action_feat[<span class="string">&#x27;time_list&#x27;</span>].apply(<span class="keyword">lambda</span> x:np.<span class="built_in">max</span>(x)-np.<span class="built_in">min</span>(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 时间间隔的平均值，最大值，最小值，方差</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">diff_value</span>(<span class="params">time</span>):</span><br><span class="line">    time_shift = <span class="built_in">list</span>(time[<span class="number">1</span>:])</span><br><span class="line">    time_shift.append(time[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    diff_time = time_shift-time</span><br><span class="line">    <span class="keyword">return</span> diff_time</span><br><span class="line">user_action_feat[<span class="string">&#x27;diff_time&#x27;</span>] = user_action_feat[<span class="string">&#x27;time_list&#x27;</span>].apply(<span class="keyword">lambda</span> x: diff_value(np.array(x)))</span><br><span class="line">user_action_feat[<span class="string">&#x27;diff_time_max&#x27;</span>] = user_action_feat[<span class="string">&#x27;diff_time&#x27;</span>].apply(<span class="built_in">max</span>)</span><br><span class="line">user_action_feat[<span class="string">&#x27;diff_time_var&#x27;</span>] = user_action_feat[<span class="string">&#x27;diff_time&#x27;</span>].apply(np.var)</span><br><span class="line">user_action_feat[<span class="string">&#x27;diff_time_mean&#x27;</span>] = user_action_feat[<span class="string">&#x27;diff_time&#x27;</span>].apply(np.mean)</span><br><span class="line">user_action_feat[<span class="string">&#x27;diff_time_min&#x27;</span>] = user_action_feat[<span class="string">&#x27;diff_time&#x27;</span>].apply(<span class="built_in">min</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>用户请求序列做一个embedding</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sentences = user_request_list[<span class="string">&#x27;request_list&#x27;</span>].values.tolist()</span><br><span class="line">emb_size = <span class="number">64</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sentences)):</span><br><span class="line">    sentences[i] = [<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> sentences[i]]  <span class="comment"># 数字转化为字符串用于训练w2v</span></span><br><span class="line"></span><br><span class="line">model = Word2Vec(sentences, size=emb_size, window=<span class="number">5</span>, min_count=<span class="number">5</span>, sg=<span class="number">0</span>, hs=<span class="number">0</span>, seed=<span class="number">1</span>, <span class="built_in">iter</span>=<span class="number">5</span>, workers=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">emb_matrix = []</span><br><span class="line"><span class="keyword">for</span> seq <span class="keyword">in</span> sentences:</span><br><span class="line">    vec = []</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> seq:</span><br><span class="line">        <span class="keyword">if</span> w <span class="keyword">in</span> model.wv.vocab:</span><br><span class="line">            vec.append(model.wv[w])</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(vec) &gt; <span class="number">0</span>:</span><br><span class="line">        emb_matrix.append(np.mean(vec, axis=<span class="number">0</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        emb_matrix.append([<span class="number">0</span>] * emb_size)</span><br><span class="line">emb_matrix = np.array(emb_matrix)</span><br><span class="line"></span><br><span class="line">emb_size = <span class="number">64</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(emb_size):</span><br><span class="line">    user_request_list[<span class="string">&#x27;action_emb_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i)] = emb_matrix[:, i]</span><br><span class="line"></span><br><span class="line">user_request_list = user_request_list.drop([<span class="string">&#x27;request_list&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">user_action_feat = user_action_feat.merge(user_request_list,how=<span class="string">&#x27;left&#x27;</span>,on=<span class="string">&#x27;request_user&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>合并基础特征和序列特征</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">user_info = user_info.merge(user_action_feat,how=<span class="string">&#x27;left&#x27;</span>,on=<span class="string">&#x27;user&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3><span id="22-模型训练">2.2 模型训练</span></h3>
<h4><span id="221-交叉验证">2.2.1 交叉验证</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">folds = KFold(n_splits=<span class="number">10</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">546789</span>)</span><br><span class="line">oof_preds, test_preds, importances = train_model_cat(train, test, y, folds, cat_cols)</span><br><span class="line"></span><br><span class="line">test_preds[<span class="string">&#x27;label&#x27;</span>] = test_preds[<span class="string">&#x27;label&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="number">0</span> <span class="keyword">if</span> x&lt;<span class="number">0.4</span> <span class="keyword">else</span> <span class="number">1</span>)</span><br><span class="line">test_preds = test_preds.drop_duplicates(subset=[<span class="string">&#x27;user&#x27;</span>])   <span class="comment"># 去除相同的user</span></span><br><span class="line"><span class="comment"># 生成结果</span></span><br><span class="line">test_preds[[<span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]].to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>, header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="222-模型训练">2.2.2 模型训练</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">useless_cols = [<span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;user_status&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model_cat</span>(<span class="params">data_, test_, y_, folds_, cat_cols, semi_data_=<span class="literal">None</span></span>):</span><br><span class="line">    oof_preds = np.zeros(data_.shape[<span class="number">0</span>])  <span class="comment"># 验证集预测结果</span></span><br><span class="line">    sub_preds = np.zeros(test_.shape[<span class="number">0</span>])  <span class="comment"># 测试集预测结果</span></span><br><span class="line">    feature_importance_df = pd.DataFrame()</span><br><span class="line">    feats = [f <span class="keyword">for</span> f <span class="keyword">in</span> data_.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> useless_cols]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 半监督每批训练数据</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> semi_data_ <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        semi_num = semi_data_.shape[<span class="number">0</span>]/<span class="number">5</span></span><br><span class="line">        semi_y = semi_data_[<span class="string">&#x27;user_status&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> n_fold, (trn_idx, val_idx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(folds_.split(data_)):</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> semi_data_ <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            semi_data_batch = semi_data_[feats].iloc[<span class="built_in">int</span>(n_fold*semi_num):<span class="built_in">int</span>((n_fold+<span class="number">1</span>)*semi_num)]</span><br><span class="line">            semi_y_batch = semi_y.iloc[<span class="built_in">int</span>(n_fold*semi_num):<span class="built_in">int</span>((n_fold+<span class="number">1</span>)*semi_num)]</span><br><span class="line">        </span><br><span class="line">            trn_x, trn_y = pd.concat([data_[feats].iloc[trn_idx],semi_data_batch]), pd.concat([y_.iloc[trn_idx],semi_y_batch])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]   <span class="comment"># 训练集数据</span></span><br><span class="line">            </span><br><span class="line">        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]   <span class="comment"># 验证集数据</span></span><br><span class="line">       </span><br><span class="line">        clf = CatBoostClassifier(</span><br><span class="line">            iterations=<span class="number">6000</span>,</span><br><span class="line">            learning_rate=<span class="number">0.08</span>,  <span class="comment"># 0.08</span></span><br><span class="line">            <span class="comment"># num_leaves=2**5,</span></span><br><span class="line">            eval_metric=<span class="string">&#x27;AUC&#x27;</span>,</span><br><span class="line">            task_type=<span class="string">&quot;CPU&quot;</span>,</span><br><span class="line">            loss_function=<span class="string">&#x27;Logloss&#x27;</span>,</span><br><span class="line">            colsample_bylevel = <span class="number">0.8</span>,</span><br><span class="line">            </span><br><span class="line">            subsample=<span class="number">0.9</span>,   <span class="comment"># 0.9</span></span><br><span class="line">            max_depth=<span class="number">7</span>,</span><br><span class="line">            reg_lambda = <span class="number">0.3</span>,</span><br><span class="line">            verbose=-<span class="number">1</span>,</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        clf.fit(trn_x, trn_y, </span><br><span class="line">                eval_set= [(trn_x, trn_y), (val_x, val_y)], </span><br><span class="line">                verbose_eval=<span class="number">300</span>, early_stopping_rounds=<span class="number">100</span>,  <span class="comment"># 这个参数有点小，可以再大一点</span></span><br><span class="line">                cat_features = cat_cols</span><br><span class="line">               )</span><br><span class="line">        oof_preds[val_idx] = clf.predict_proba(val_x)[:, <span class="number">1</span>]   <span class="comment"># 验证集结果</span></span><br><span class="line">        </span><br><span class="line">        sub_preds += clf.predict_proba(test_[feats])[:, <span class="number">1</span>] / folds_.n_splits  <span class="comment"># 测试集结果</span></span><br><span class="line">        </span><br><span class="line">        fold_importance_df = pd.DataFrame()</span><br><span class="line">        fold_importance_df[<span class="string">&quot;feature&quot;</span>] = feats</span><br><span class="line">        fold_importance_df[<span class="string">&quot;importance&quot;</span>] = clf.feature_importances_</span><br><span class="line">        fold_importance_df[<span class="string">&quot;fold&quot;</span>] = n_fold + <span class="number">1</span></span><br><span class="line">        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Fold %2d AUC : %.6f&#x27;</span> % (n_fold + <span class="number">1</span>, roc_auc_score(val_y, oof_preds[val_idx])))</span><br><span class="line">        <span class="keyword">del</span> clf, trn_x, trn_y, val_x, val_y</span><br><span class="line">        gc.collect()</span><br><span class="line">    </span><br><span class="line">    oof_preds = [<span class="number">1</span> <span class="keyword">if</span> i &gt;= <span class="number">0.4</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> oof_preds]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Full F1 score %.6f&#x27;</span> % f1_score(y_, oof_preds))</span><br><span class="line">    test_[<span class="string">&#x27;label&#x27;</span>] = sub_preds</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> oof_preds, test_[[<span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]], feature_importance_df</span><br></pre></td></tr></table></figure>
<h2><span id="三-解决方案二">三、<strong>解决方案二</strong></span></h2>
<ul>
<li><strong>基于账户本身基础特征</strong>，可以做这些类别特征的计数统计、对于粉丝量等数值特征可以做除法的交叉、登录时间和注册时间特征可以做减法交叉，基于请求行为，我们可以对机型、ip、app_version、app_channel做频数统计</li>
<li><strong>基于用户的请求行为序列</strong>，我们可以构建w2v特征(把用户请求行为序列看成句子，行为看作词，训练Word2Vec模型得到每个行为的表征</li>
<li><strong>基于用户的请求时间</strong>，我们可以计算请求时间的均值方差、请求时间间隔的统计特征等等。</li>
</ul>
<h2><span id="四-anovel-framework-for-social-bots-detection-in-online-social-networksbased-on-graph-embedding-and-community-detection">四、A
Novel Framework for Social Bots Detection in Online Social Networks
Based on Graph Embedding and Community Detection</span></h2>
<h3><span id="摘要">摘要</span></h3>
<p>随着在线社交网络的广泛普及，近年来用户数量也呈指数级增长。与此同时，社交机器人，即由程序控制的账户，也在上升。OSN的服务提供商经常使用它们来保持社交网络的活跃。与此同时，一些社交机器人也出于恶意目的注册。有必要检测这些恶意社交机器人，以呈现真实的舆论环境。我们提出了BotFinder，一个在OSN中检测恶意社交机器人的框架。具体来说，<strong>它将机器学习和图方法相结合</strong>，以便有效地提取社交机器人的潜在特征。关于特征工程，我们生成二阶特征，并使用编码方法对具有高基数的变量进行编码。这些特征充分利用了标记和未标记的样本。对于图，我们首先通过嵌入方法生成节点向量，然后进一步计算人类和机器人向量之间的相似性；然后，我们使用无监督的方法扩散标签，从而再次提高性能。为了验证该方法的性能，我们在由800多万条用户记录组成的人工竞赛提供的数据集上进行了广泛的实验。结果表明，我们的方法达到了0.8850的F1分数，这比最先进的方法要好得多</p>
<h3><span id="说明">说明</span></h3>
<p>与报纸等传统媒体相比。社交机器人，即由程序控制的帐户，可用于保持社交网络的活跃。虽然OSN中存在有益的社交机器人，但一些恶意社交机器人的出现会产生有害影响。例如，一些人可以出于各种目的注册大量帐户，例如增加粉丝数量或恶意喜欢。这些恶意行为已成为威胁社交网络平台健康发展的重要信息安全问题[1-2]。因此，有必要检测那些恶意的社交机器人，也称为社交机器人检测。特别是，当前的大多数研究涉及Twitter和其他国外平台，而很少有研究调查中国的OSN。因此，众多学者致力于研究社交机器人的检测问题。当前与社交机器人检测相关的工作主要分为两类，即机器学习方法和基于图的方法。然而，这一主题仍然存在一些挑战：</p>
<p>1）
一般来说，大多数方法依赖于单个算法来识别社交机器人，由于数据集的多样性，这可能不是理想的选择。</p>
<p>2）
实际上，大多数数据都是未标记的，这表明标签的数量通常很小。因此，<strong>有效利用未标记数据是一个巨大的挑战</strong>。</p>
<p>为了应对上述挑战，我们在此共同考虑用户的配置文件、行为以及它们之间的关系。此外，我们将特征工程和图方法相结合，提出了一种检测社交机器人的集成机制BotFinder。首先，在数据集上进行特征工程以提取全局信息。然后，通过嵌入方法生成节点向量。然后，我们计算人类和机器人的向量之间的相似性。最后，为了进一步提高性能，我们采用了无监督方法（这里考虑了社区检测算法）。使用所提出的算法，我们可以轻松地检测这些机器帐户。</p>
<p><strong>本文的贡献总结如下：</strong></p>
<p>1）
首先，在节点数较多、边数较少的情况下，在绘制过程中可能会忽略一些单个节点。然而，机器学习方法无法学习拓扑结构。因此，我们结合机器学习方法和图方法来克服这些问题。</p>
<p>2）
其次，在特征工程中，我们试图获得二阶特征，并采用编码方法对具有高基数的变量进行编码，或者换句话说，包含大量不同值的变量进行编码。对于图，我们通过嵌入方法生成节点向量。然后，我们利用无监督方法扩散标签以提高性能。这些方法充分利用了标记和未标记的样本。</p>
<p>本文的其余部分组织如下。在第二节中，我们回顾了一些相关的工作。在第3节中，我们介绍了拟议的框架BotFinder。然后，在第4节中，我们详细描述了所研究的数据集，并在充分分析的基础上进行了实验。最后，我们在第5节总结了我们的研究。</p>
<h3><span id="二-related-works"><strong>二、Related works</strong></span></h3>
<h4><span id="21-机器学习方法">2.1 机器学习方法</span></h4>
<p>在机器学习方法中，监督学习方法得到了广泛的研究。早期的反作弊算法仅利用用户配置文件或用户行为来构建模型。Breno等人[3]提出了一种使用人工神经网络进行数据预处理和挖掘的方法。Chang等人[4]提出了一种特征选择方法，然后使用决策树来检测机器人。Ganji等人[5]将K-最近邻（KNN）应用于信用卡欺诈检测。Ferrara等人[6-7]利用机器学习和认知行为建模技术分析了2017年法国总统选举和2017年加泰罗尼亚独立公投中的社交机器人。<strong>Denis等人[8]提出了一种用于检测Twitter上机器人的集成学习方法。</strong>
随着深度学习方法（LSTM、CNN等）的发展，研究人员也尝试开发新的方法来检测社交机器人，以进一步提高检测精度。通过将用户内容视为时间文本数据，Cai等人[9]提出了BeDM方法用于机器人检测。Kudugunta等人[10]提取了用户元数据和推文文本，这些数据被视为LSTM深度网络的输入。在实践中，大多数真实世界的数据都是未标记的，而无监督学习方法被广泛研究，这通常依赖于社交机器人的共同特征。Cresci等人[11-12]提出了一种基于DNA启发技术的改进方法，以模拟在线用户行为。陈等人[13]提出了一种无监督的方法来实时检测推特垃圾邮件活动。姜等人[14]提出了CATCHSYNC，仅使用没有标签的拓扑来检测可疑节点。Su等人[15]提出了物联网RU。Mazza等人[16]将转发的时间序列转换为特征向量，然后进行聚类。</p>
<h4><span id="22-图算法">2.2 图算法</span></h4>
<p>机器学习方法只考虑节点的特征。然而，节点之间的关系也包含有价值和有用的信息。随着深度学习和图算法的发展，需要考虑图的拓扑信息以进一步改进。<strong>社交机器人具有图形聚合的特点</strong>。而社区检测用于发现网络中的社区结构，也可以看作是一种广义聚类算法。因此，社区检测算法可能适用于检测社交机器人。许多研究者对这一课题进行了不懈的研究。Guillaume等人[17]提出了一种基于模块化优化的启发式方法。李等人[18]提出了基于深度稀疏自动编码器的WCD算法。对于特征丰富的样本，很难充分挖掘特征中存在的信息。然后，提出了新的方法，首先将节点的拓扑信息转换为特征向量，然后使用机器学习算法进行训练和推理。例如，Lerer等人[19]提出的Pytorch
BigGraph，<strong>Yu等人[20]提出的NetWalk</strong>，<strong>Grover等人[21]提出的Node2Vec</strong>，P<strong>ham等人[22]提出的Bot2Vec</strong>。此外，Kipf等人[23]提出了图卷积网络（GCN），对节点和网络拓扑的特征进行建模，<strong>Aljohani等人[24]将GCN应用于检测Twitter上的机器人</strong>。李等人[25]提出了用于网络免疫的BPD-DMP算法。聂等人[26]考虑了社交网络和发布内容；然后，他们提出了DCIM算法。高等人[27]对动态行为进行了表征，并提出了一种基于网络的模型。朱等人[28]研究了流行病在多层网络上的传播过程。Su等人[29]提出了检测车载网络中恶意节点的IDE。
大多数方法依赖于单个算法来识别社交机器人。在准确性和其他相关评估指标方面，以前的识别方法仍然有很大的局限性。</p>
<h3><span id="三-botfinder"><strong>三、BotFinder</strong></span></h3>
<p>在本节中，我们主要介绍BotFinder，它主要包括三个步骤：1）我们在表格数据上表示特征工程技术；2）
我们推导节点嵌入，然后测量人类和机器人之间的相似性；3）
我们应用社区检测算法来进一步提高性能</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182039206.png" alt="image-20220719205923660">
<figcaption aria-hidden="true">image-20220719205923660</figcaption>
</figure>
<p>图1详细说明了这些步骤。第一步，利用特征工程技术生成特征矩阵。第二步，我们使用图嵌入方法生成相似矩阵，然后合并这两个矩阵。然后，我们采用LightGBM[30]来训练合并矩阵并推断临时结果。第三步，我们应用社区检测方法生成部分结果，并使用这些结果校正LightGBM的结果。</p>
<h4><span id="31-featureengineering">3.1 <strong>Feature
Engineering</strong></span></h4>
<p>在这里，我们试图获得<strong>二阶特征、时间间隔特征、计数编码和k倍目标编码</strong>。然后，我们应用LightGBM来训练获得的特征并推断临时结果。</p>
<p><strong><font color="red">
二阶特征：为了表示表中分类变量的组合，我们假设二阶特征表示为
COUNT、NUNIQUE、RATIO</font></strong></p>
<ul>
<li><p><strong>COUNT 反映了活动程度。具体来说，我们选择一对变量（即 V1和
V2），并预计记录这对变量在数据集中出现的次数。我们将其缩写为 COUNT(v1,
v2)。</strong>例如，用户向使用设备类型（ V1）iPhone12,1和应用程序版本（
V2）126.7.0组合的人thump-up，这种组合在数据集中出现了k次。然后，使用iPhone12、1和126.7.0的用户将获得k的
COUNT值。【记录元组出现的次数】【并行化】</p></li>
<li><p><strong>UNIQUE表明了给定范围内的多样性。我们使用一个变量（
V1）作为主键，并在另一个变量（V2）中记录唯一类别的数量。我们将其缩写为
UNIQUE(V1)[V2] 。</strong>例如，对于使用device type（
V1）iPhone12,1的用户，数据集中有k个不同的应用程序版本。然后，使用iPhone12,1的用户将获得
UNIQUE 值k。</p></li>
<li><p><strong>RATIO描述计数比例。它计算为 COUNT(v1, v2) /
COUNT(v1)</strong>。例如，device type（V1）iPhone12,1 和 app version（
V2）126.7.0的组合在数据集中出现k次，device
type（V1）iPhone12在数据集中出现V次。然后，所有使用iPhone12、1和126.7.0的用户将获得
k/v 的 RATIO 值。</p></li>
</ul>
<p><strong>时间间隔特性：请求时间间隔因用户而异。这里，我们主要考虑时间间隔的最大值、最小值、中值和和。</strong></p>
<p><strong>计数编码：计数编码是通过将类别替换为在数据集上计算的类别计数来进行的</strong>。然而，某些变量的计数可能相同，这可能导致两个类别可能编码为相同值的冲突。这将导致模型性能下降。因此，我们在此介绍一种目标编码技术。</p>
<p><strong>K-折叠目标编码（或似然编码、影响编码、平均编码）</strong>：目标编码是通过目标（标签）对分类变量进行计数。在这里，我们用目标的相应概率替换分类变量的每一类。为了减少目标泄漏，我们采用k倍目标编码。具体实现如下：</p>
<ul>
<li>将训练数据分成10折。</li>
<li>将折#2-10<strong>目标的平均值</strong>作为折#1的编码值，并类似地计算#2-10的编码值。</li>
<li>使用训练数据的目标来确定测试数据的编码值。</li>
</ul>
<h4><span id="32-similaritycalculation"><strong>3.2 Similarity
Calculation</strong></span></h4>
<p><strong>在这里，我们采用Node2vec[21]来获得用户的节点嵌入（向量），然后计算用户和标记用户之间嵌入的余弦相似性</strong>。相似度值表示两个用户具有相同标签的概率；例如，如果user1和user2之间的余弦相似性相对较大，则它们很可能具有高概率的相同标签。</p>
<p>然后，对于训练集和测试集中的每个节点向量C，我们计算机器人和人类之间的最大和平均余弦相似度，该相似度表示为一个向量。【Smax1、Smean1，Smax0，Smean0】</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182039522.png" alt="image-20220719212846481" style="zoom:50%;"></p>
<h3><span id="33-communitydetection">3.3 <strong>community
detection</strong></span></h3>
<p><strong>对于社区检测，我们采用典型的Louvain方法</strong>[17]，将构建的图划分为社区。之后，我们将用以下规则标记社区：</p>
<blockquote>
<p>[1] Guillaume L. Fast unfolding of communities in large networks[J].
Journal Statistical Mechanics: Theory and Experiment, 2008, 10:
P1008.</p>
</blockquote>
<p>1）
如果具有标签的用户属于同一社区，则社区中的所有用户都应该具有相同的标签。</p>
<p>2）
如果社区中的用户没有任何标签，或者用户具有不同的标签，我们将不会进行预测。</p>
<p><strong>然而，预测可能不会覆盖所有用户。因此，该规则的性能是有限的。但该规则的结果比LightGBM更准确。通过将上述两个步骤结合起来，可以进一步提高性能。</strong></p>
<h3><span id="四-实验">四、实验</span></h3>
<p>为了评估该机制的性能，我们从一个大型社交网络平台的数据中心收集了一个数据集(https://security.bytedance.com/fe/ai-challenge#/sec-project?id=2&amp;active=1）。它包含超过800万条记录，包括<strong>用户配置文件</strong>和<strong>用户请求</strong>（关注或喜欢某人）。数据集的基本信息如表1和表2所示：表1显示了用户的个人信息（配置文件），而表2说明了用户的行为（请求），包括当时用于启动请求的设备和应用程序版本。</p>
<p><strong><font color="red">
任务描述如下：给定用户配置文件及其请求。只有一小部分用户被标记。因此，我们必须建立一个合理、解释性和有效的模型来检测来自用户的恶意机器人。</font></strong></p>
<h3><span id="五-结论">五、结论</span></h3>
<p>本文提出了一种社交机器人检测方法BotFinder。为了验证所开发方法的性能，我们收集了一个包含800多万条用户记录的数据集。同时，应用机器学习和图方法从此类数据集中提取社交机器人的潜在特征。<strong>特别是，对于特征工程，我们生成二阶特征，并使用编码方法对高基数变量进行编码。</strong>在图方面，我们为账户生成节点向量，然后利用无监督方法（这里我们利用社区检测）扩散标签，以进一步提高性能。通过在收集的数据集上进行的实验，所提出的集成机制的有效性得到了相对较大的F1分数0.8850的保证。与现有方法相比，该方法的性能优越。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>算法比赛</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（4）西湖论剑-告警误报检测</title>
    <url>/posts/3PV2CVF/</url>
    <content><![CDATA[<h2><span id="西湖论剑-告警误报检测">西湖论剑-告警误报检测</span></h2>
<blockquote>
<p>2020西湖论剑Ai大数据安全分析竞赛思路分享 - 杨航锋的文章 - 知乎
https://zhuanlan.zhihu.com/p/295179638</p>
</blockquote>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>算法比赛</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（1）图嵌入</title>
    <url>/posts/1D7JHF6/</url>
    <content><![CDATA[<h2><span id="graphembeddingdeepwalk算法原理实现和应用"></span></h2>
<blockquote>
<p><strong>图神经网络：从入门到放弃</strong>：https://www.zhihu.com/column/c_1322582255018184704</p>
<p>图卷积：从GCN到GAT、GraphSAGE</p>
</blockquote>
<figure>
<img src="https://pic2.zhimg.com/v2-4fa19e39f5a9690f6063e26102876c5f_1440w.jpg?source=172ae18b" alt="图卷积：从GCN到GAT、GraphSAGE">
<figcaption aria-hidden="true">图卷积：从GCN到GAT、GraphSAGE</figcaption>
</figure>
<figure>
<img src="image-20230311122935355.png" alt="image-20230311122935355">
<figcaption aria-hidden="true">image-20230311122935355</figcaption>
</figure>
<h2><span id="一-图卷积从gcn到gat-graphsage">一、图卷积：从GCN到GAT、GraphSAGE</span></h2>
<h4><span id="前言">前言</span></h4>
<p>图模型总体上可以分为两大类：一是<strong>random-walk游走类模型</strong>，另一类就是<strong>GCN、GAT等卷积模型了</strong>。</p>
<p>下面就自己学习卷积图模型过程的一些模型GCN、GAT、GraphSAGE
及疑问总结一下，欢迎交流学习。</p>
<h4><span id="11-为什么出现gcn来处理图结构">1.1 为什么出现GCN来处理图结构？</span></h4>
<p>在图像领域，CNN被拿来自动提取图像特征的结构，但是CNN处理的图像或者视频数据中像素点（pixel）是排列成成很整齐的矩阵，虽然图结构不整齐（不同点具有不同数目neighbors），但是不是可以用同样的方法去抽取图的的特征呢？</p>
<p><strong>于是就出现了两种方式来提取图的特征</strong>。<strong>一是空间域卷积（spatial
domain)</strong>，<strong>二是频域卷积（spectral
domain）</strong>。第一种方式由于每个顶点提取出来的neighbors不同，处理上比较麻烦，同时它的效果没有频域卷积效果好，没有做深究。因此，现在比较流行、工程上应用较多的为<strong>频域卷积</strong>。</p>
<h4><span id="12-gcn的计算原理">1.2 GCN的计算原理</span></h4>
<p>GCN的卷积核心公式： <img src="https://www.zhihu.com/equation?tex=H%5E%7Bl%2B1%7D%3D%5Csigma%28D%5E%7B-1%2F2%7DAD%5E%7B-1%2F2%7DH%5E%7Bl%7DW%5E%7Bl%7D%29" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=H%5E%7Bl%7D%E3%80%81H%5E%7Bl%2B1%7D" alt="[公式]">
分别是第l层、第l+1的节点，D为度矩阵，A为邻接矩阵,如下图。</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-ba5789828363879c84e577d6af49351a_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong><font color="red">
GCN计算方式上很好理解，本质上跟CNN卷积过程一样，是一个加权求和的过程，就是将邻居点通过度矩阵及其邻接矩阵，计算出各边的权重，然后加权求和。</font></strong>
<img src="https://pic2.zhimg.com/80/v2-3fe9d3277a19d431047d00b503e65145_1440w.jpg" alt="img"></p>
<p><strong>D负责提供权值的矩阵，邻接A矩阵控制应该融合哪些点,
H表示上一层的embedding参数</strong>。</p>
<p>结合上面两张图，动手算一算 <img src="https://www.zhihu.com/equation?tex=D%5E%7B-1%2F2%7DAD%5E%7B-1%2F2%7D" alt="[公式]"> ，能很清楚的看到，这个加权求和的卷积过程是怎么做的。</p>
<h4><span id="gcn-小结一下"><strong>GCN 小结一下：</strong></span></h4>
<p><strong>GCN首次提出了卷积的方式融合图结构特征，提供一个全新的视角</strong>。</p>
<p><strong>主要缺点</strong>：</p>
<ul>
<li>问题1：融合时边权值是固定的，不够灵活。</li>
<li>问题2：可扩展性差，因为它是全图卷积融合，全图做梯度更新，当图比较大时，这样的方式就太慢了，不合适。</li>
<li><strong>问题3：层数加深时，结果会极容易平滑，每个点的特征结果都十分相似</strong>。</li>
</ul>
<p>GAT就来解决问题1的，GraphSAGE就来解决这个问题2的，DeepGCN等一系列文章就来讨论问题3的。基本上，GCN提出之后，后续就是各路神仙打架了，都是针对GCN的各个不同点进行讨论改进了。</p>
<h4><span id="13-带attention的图注意网络gat">1.3 带attention的图注意网络GAT</span></h4>
<p>attention这么流行，看完GCN就容易想到，GCN每次做卷积时，边上的权重每次融合都是固定的，那能不能灵活一点，加个attention，让模型自己去学，那GAT就来干这个事了。</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-5e99445debc7a48e116323dea6d19c02_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>结合下面这两各公式，看看这个attention是怎么定义的。 <img src="https://www.zhihu.com/equation?tex=h_i%E3%80%81h_j%E3%80%81h_k" alt="[公式]"></p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-2b44cdbbdcd7cc82c8a4c61b63298acd_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><img src="https://www.zhihu.com/equation?tex=%5Calpha_%7Bi%2Cj%7D" alt="[公式]"> 表示第i个点与第j个点之间的attention系数，是node
feature，其他a、W的为模型参数。</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Calpha_%7Bi%2Cj%7D" alt="[公式]"> 就是通过计算 <img src="https://www.zhihu.com/equation?tex=LeakycReLU%28concat%5BWh_i%2CWh_j%5D%29" alt="[公式]"> ,在经过Normalize处理一下得到。</p>
<p>得到各条边的 <img src="https://www.zhihu.com/equation?tex=%5Calpha_%7Bi%2Cj%7D" alt="[公式]"> 之后，第i个点的融合attention过后的node
feature可以表示下面这个公式，实质上还是一个加权的feature求和过程，只是每次融合中的权重系数是随模型训练学习的，最后在经过一个非线性的激活函数去做对应的任务。</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-d94ac70352df632d330f452c102c55a8_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>在这个基础上，文中还提到了，为了使attention机制更具扩展性，定义multi-head
attention机制（K代表K个attention
head），去做attention权重的计算，然后concat起来，得到node feature。</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-f8a7e3911fa94bb8a023cee8bd14535f_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>当在网络最后一层时，concat输出的维度就node
feature太大，不太合理，就改用累加再平均，然后输出，做具体任务。</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-23302b1e31aeb633c80d0601a360654d_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>以上就是第一个图中右边示意的结构了。</p>
<h4><span id="gat-小结一下"><strong>GAT 小结一下</strong>：</span></h4>
<p>GAT中的attention机制还是很直观的，通过给每条边加了一个模型可学习的系数
<img src="https://www.zhihu.com/equation?tex=%5Calpha_%7Bi%2Cj%7D" alt="[公式]"> ，进行带attention系数的node
feature融合，使得在做卷积融合feature的过程，能够根据任务调整模型参数，变得自适应使得效果更好。</p>
<p>今年还出了一篇专门讨论GAT的工作的，讨论attention到底学到了的是什么，感兴趣的可以去看看<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2105.14491">How
Attentive are Graph Attention Networks?</a></p>
<h3><span id="14-可扩展的图网络graph-sage">1.4 可扩展的图网络Graph-SAGE</span></h3>
<p>前面说到，GCN中做卷积融合是全图的，梯度是基于全图更新，若是图比较大，每个点邻居节点也较多，这样的融合效率必然是很低的。于是GraphSAGE出现了。</p>
<p>在提GraphSAGE前，先解释下transductive learning、inductive
learning的概念，这也是GraphSAGE与其他图模型的区别。</p>
<ol type="1">
<li><strong>transductive是说要预测的数据在训练时模型也能看到。进一步解释一下，就是说训练前，构建的图结构已经是固定的，你要预测的点或边关系结构都应该已经在这个图里了，训练跟预测时的图结构都是一样的。</strong></li>
<li><strong>inductive是说要预测的数据在训练时模型不用看到，也就是我们平常做算法模型的样子，训练预测时的数据是分开的，也就是上面说的可以图结构不是固定的，加入新的节点。</strong></li>
</ol>
<p><strong>GraphSAGE</strong>就是inductive的模式，GraphSAGE提出随机采子图的方式去采样，通过子图更新node
embedding，
这样采出的子图结构本身就是变化，从而让模型学到的是一种采样及聚合的参数的方式，有效解决了unseen
nodes问题，同时避免了训练中需要把整个图的node
embedding一起更新的窘境，有效的增加了扩展性。</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-7b9fa5ba80bc9fe23c8846c313135124_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>具体的思想就是分三步：</p>
<ol type="1">
<li><strong>采子图</strong>：训练过程中，对于每一个节点采用切子图的方法，随机sample出部分的邻居点，作为聚合的feature点。如上图最左边，对于中心点，采两度，同时sample出部分邻居节点组成训练中的子图。</li>
<li><strong>聚合</strong>：采出子图后，做feature聚合。这里与GCN的方式是一致的，从最外层往里聚合，从而聚合得到中心点的node
embedding。聚合这里可操作的地方很多，比如你可以修改聚合函数（一般是用的mean、sum，pooling等），或增加边权值都是可以的。</li>
<li><strong>任务预测</strong>：<strong><font color="red"> 得到node
embedding后，就可以接下游任务了，比如做node classification，node
embedding后接一个linear层+softmax做分类即可。</font></strong></li>
</ol>
<p>具体到代码实现思路上，也是与上述思路高度一致。</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-e78146e4d6a7db2680e863abf3b709b1_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>也是针对每一个node采出子图，然后进行聚合，最后得到node
embedding。</p>
<p><strong>举例：假设中心点为v，采点v的K度子图</strong></p>
<ol type="1">
<li>采出中心点v的K层子图中邻居点u，然后一层层聚合，聚合得到邻居节点node
feature <img src="https://www.zhihu.com/equation?tex=h_%7BN%28V%29%7D%5Ek%3DAGGREGATEk%28%7Bh%5E%7Bk%E2%88%921%7D_u%2C+%E2%88%80u%E2%88%88N%28v%29%7D%29" alt="[公式]"></li>
<li>中心点与它的邻居点通过concat方式聚合， <img src="https://www.zhihu.com/equation?tex=h_v%5Ek%3DCONCAT%28h%5E%7Bk%E2%88%921%7D_v%2C+h%5Ek_%7BN%28v%29%7D%29" alt="[公式]"> ,在经过一个非线性函数处理。</li>
<li>最后再Normalize归一化处理一下，得到最后的node embedding</li>
<li>以上述这种方式，从最外层往里聚合,一直聚合到最初的中心点v，点v的node
embedding 就更新完成了。</li>
</ol>
<h4><span id="graphsage小结一下"><strong>GraphSAGE小结一下：</strong></span></h4>
<p>GraphSAGE主要解决了两个问题：</p>
<ol type="1">
<li><strong>解决了预测中unseen
nodes的问题，原来的GCN训练时，需要看到所有nodes的图数据。</strong></li>
<li><strong>解决了图规模较大，全图进行梯度更新，内存消耗大，计算慢的问题</strong></li>
</ol>
<p>以上两点都是通过一个方式解决的，也就是采子图的方式，由于采取的子图是局部图且是随机的，从而大大增加模型的可扩展性，但这也有一个问题可以思考一下，这个随机采子图的方式是合理的吗？这种方式会不会损失掉部分这个图的node信息，欢迎交流学习。</p>
<p>对以上感兴趣的还可以看看Cluster-GCN，它通过图聚类的方式去划分子图分区，从而，进一步提高了计算效率。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（2）DeepWalk</title>
    <url>/posts/13PH6XA/</url>
    <content><![CDATA[<h2><span id="graphembeddingdeepwalk算法原理实现和应用"></span></h2>
<ul>
<li><strong>DeepWalk【图神经网络论文精读】</strong>：https://www.bilibili.com/video/BV1o94y197vf/?spm_id_from=pageDriver&amp;vd_source=29387dc08d18f642078183a6816e93e8</li>
<li>https://www.zhihu.com/column/c_1322582255018184704</li>
<li>图神经网络—基于随机游走的早期研究（一）：DeepWalk &amp;
Node2Vec：https://zhuanlan.zhihu.com/p/343041065</li>
</ul>
<h3><span id="一-deepwalk">一、DeepWalk</span></h3>
<p><img src="image-20230311111100589.png" alt="image-20230311111100589" style="zoom:33%;"></p>
<p>DeepWalk[1]是一篇14年的文章，它极大的受到word2vec[4]的启发。</p>
<p>在图机器学习的早期研究中，人们主要希望模型能够捕捉到节点之间的连接关系。那在word2vec中人们希望模型学习的是什么呢？没错，就是token与token之间的"连接性"。word2vec的skip-gram
(with negative sampling)
模型本质上在回答：给定两个token，它们是否有在同一个context
window中出现过？<strong>从图的角度来说，word2vec的任务目标可以翻译为：给定两个节点，判断它们是否有任意k阶<em>内</em>的连接关系，其中k即为context
window的大小。</strong></p>
<p>因此，一个自然的想法就是，能不能利用word2vec训练模型，来捕捉图数据结构中节点之间的连接关系呢？出于此intuition，研究者们提出了DeepWalk。</p>
<h4><span id="11-overview-of-the-model">1.1 Overview of the Model</span></h4>
<p><strong>DeepWalk非常简单粗暴，它基本上就是以下两个模块的结合，甚至各个模块都没有太大的改动：</strong></p>
<ul>
<li>基于随机游走在图上进行<strong>游走采样</strong>，将节点邻接结构映射成序列结构。</li>
<li>利用采样得到的序列，训练Skip-gram模型，使习得的表达能够捕捉节点间的连接性。</li>
</ul>
<p><strong>第一部分：</strong>原论文提出在进行随机游走时，每次从给定起点出发，不停的利用uniform
sampling来采样邻居进行游走，直到该采样序列长度达到给定最大长度。因为每步游走仅需做一次uniform
sampling，所以DeepWalk可以在不需要额外存储计算的情况下，在O(1)的时间内采样一步随机游走。</p>
<p>假设给定模型l的walk
length，并且以每个节点为起点进行k次游走，那么总计会生成k|V|个长度为l的序列。最终完成整张图的随机游走的时间复杂度为O(lk|V|)。</p>
<p><strong>第二部分：</strong>原论文提出基于Hierarchical Softmax (HS)
来训练一个Skip-gram模型。但从今天的眼光来看，HS已经逐步退出历史的舞台。人们现在往往直接在GPU上计算softmax，并不再特别需要HS加速softmax计算。并且，若softmax计算量难以接受，人们也往往利用Noise
Contractive Estimation (NCE) or <strong>Negative Sampling</strong>
(NS)，来规避softmax的使用。<strong>因此，今天人们更常利用skip-gram with
negative sampling训练DeepWalk/Node2Vec模型。</strong></p>
<figure>
<img src="image-20230311113705926.png" alt="image-20230311113705926">
<figcaption aria-hidden="true">image-20230311113705926</figcaption>
</figure>
<figure>
<img src="image-20230311114014622.png" alt="image-20230311114014622">
<figcaption aria-hidden="true">image-20230311114014622</figcaption>
</figure>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（0）学习规划</title>
    <url>/posts/2WSVM9N/</url>
    <content><![CDATA[<h2><span id="图算法进阶规划">图算法进阶规划</span></h2>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/592333251"><em>图算法</em>在风控场景的应用</a></p>
<p>指纹挖掘：恶意样本IOC自动化提取（https://mp.weixin.qq.com/s/hoz6ihHJ5Wiv3wd4ECTopw）</p>
<p>而在现实世界中，<strong>大部分图是动态的，图的节点会随着时间增加，节点间的连接关系也会随着时间改变。</strong></p>
<p><strong>斯坦福大学CS224W图机器学习公开课-同济子豪兄中文精讲</strong>：https://github.com/TommyZihao/zihao_course/tree/main/CS224W</p>
<p><strong>[AI安全论文]
22.图神经网络及认知推理总结和普及-清华唐杰老师</strong>：https://mp.weixin.qq.com/s?__biz=Mzg5MTM5ODU2Mg==&amp;mid=2247496272&amp;idx=1&amp;sn=7eb79e3be42df3c8f002711a7bf1d410&amp;chksm=cfcf429df8b8cb8b557e22567f6054b2450b053ea0314d5c9f461d6c7f64b0d27c2440844167&amp;scene=178&amp;cur_album_id=1776483007625822210#rd</p>
</blockquote>
<h3><span id="一-图算法基础">一、图算法基础</span></h3>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191156743.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="二-图机器学习">二、图机器学习</span></h3>
<blockquote>
<p><strong>斯坦福大学CS224W图机器学习公开课-同济子豪兄中文精讲</strong>：https://github.com/TommyZihao/zihao_course/tree/main/CS224W</p>
</blockquote>
<h4><span id="21-图机器学习导论">2.1 图机器学习导论</span></h4>
<blockquote>
<p>3 月 8 日</p>
</blockquote>
<figure>
<img src="image-20230308175457512.png" alt="image-20230308175457512">
<figcaption aria-hidden="true">image-20230308175457512</figcaption>
</figure>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191157359.png" alt="image-20230309120614978">
<figcaption aria-hidden="true">image-20230309120614978</figcaption>
</figure>
<ul>
<li><strong>然而，我们只考虑将图结构（但不是节点的属性以及他们的邻居）</strong></li>
</ul>
<p><img src="image-20230311102049382.png" alt="image-20230311102049382"><img src="image-20230311111100589.png" alt="image-20230311111100589"></p>
<figure>
<img src="image-20230311111120651.png" alt="image-20230311111120651">
<figcaption aria-hidden="true">image-20230311111120651</figcaption>
</figure>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（3）node2vec</title>
    <url>/posts/2WXZF7X/</url>
    <content><![CDATA[<h2><span id="node2vec">Node2Vec</span></h2>
<blockquote>
<p>【Graph Embedding】node2vec：算法原理，实现和应用 - 浅梦的文章 - 知乎
https://zhuanlan.zhihu.com/p/56542707</p>
</blockquote>
<p><strong>DeepWalk的思路非常直接，就是结合随机游走和Skip-gram模型</strong>。尽管DeepWalk利用完全随机的游走，得到了<strong>相对小的游走时的时空复杂度，==但是这种游走的策略显然没有考虑到图中节点间的连接"强度"，同时也无法很好的考虑到图中节点的结构等价性(structural
equivalence)和同质性(homophily)，生成的游走序列完全"听天由命"==</strong>。</p>
<p>Node2Vec[2]是一篇16年文章，它修改了DeepWalk中的游走策略，<strong>使其能够更灵活的捕捉图中节点的结构等价性和同质性。</strong></p>
<h3><span id="21-overview-of-the-model">2.1 Overview of the Model</span></h3>
<p><strong>二阶随机游走（二阶马尔科夫）</strong></p>
<figure>
<img src="image-20230311144430446.png" alt="image-20230311144430446">
<figcaption aria-hidden="true">image-20230311144430446</figcaption>
</figure>
<figure>
<img src="image-20230311144607426.png" alt="image-20230311144607426">
<figcaption aria-hidden="true">image-20230311144607426</figcaption>
</figure>
<p>具体来说，如上图，我们可以说节点s1和节点u具有<strong>同质性</strong>，因为它们都属于图中同一个community/cluster；我们也会说节点u和节点s6具有<strong>结构等价性</strong>，因为它们在网络中扮演的角色十分类似，都是簇的中心。</p>
<p>Node2Vec的作者们宣称：</p>
<ul>
<li>倘若随机游走倾向于BFS，那么生成的序列会更倾向于在起点的附近进行探索，这样能够更好的捕捉节点间的同质性；</li>
<li>若随机游走倾向于DFS，那么生成的序列会探索图中更大的区域，使得模型有机会捕捉到节点间的结构相似性。</li>
</ul>
<p>以上陈述中，BFS能更好的捕捉同质性应该是比较直观的，毕竟它只会在起点附近震荡，也就意味着它能确保与起点近邻的节点均能习得近似的表达。但是DFS只是捕捉节点间结构等价性的必要条件而非充分条件。如果没有DFS，模型可能根本无法跳出起点的簇中，那么节点的结构等价性的捕捉也无从谈起。<strong>但是如果只是DFS，那么我们只能知道这两个距离很远的节点有某种依赖性，但我们无从得知这是怎样的依赖性，比如，它们都是簇的中心吗？还是它们都是各个簇的成员而已？</strong></p>
<p><strong>因此作者们提出了一个biased 2nd order random
walk，其引入了两个额外的参数p和q，以在游走中控制和融合BFS与DFS。</strong>这个游走被称作二阶随机游走的原因是：游走的下一步不仅取决于当前的节点，也取决于当前节点的上一步的节点。这和二阶马科夫假设是类似的。</p>
<p><img src="v2-8fae060cc9e639aa51b5034a57a9ccd3_720w.jpg" alt="img" style="zoom:50%;"></p>
<p>具体来说，上图为游走的一个例子。其中，节点v是当前节点，节点t是游走的上一步的节点，而我们现在要决定节点v的下一步x是哪一个节点。此时的游走概率由α决定，其公式为：</p>
<figure>
<img src="image-20220918150418927-3484660.png" alt="image-20220918150418927">
<figcaption aria-hidden="true">image-20220918150418927</figcaption>
</figure>
<ul>
<li>其中dtx指节点x与节点t之间的距离。有了α后，游走的（未经归一化的）转移概率可计算为<span class="math inline">\(π_{vx}=α_{pq}(t,x)⋅w_{vx}\)</span>，其中<span class="math inline">\(w_{vx}\)</span>是节点v与节点x之间的权重。</li>
<li>直观来说，若p越大，越不容易返回上一步游走到的节点，这能鼓励模型游走的更远，若p越小，则更容易返回上一步节点，使得模型倾向于在起点周围进行探索；若q越大，游走会更倾向于在上一步节点t的周围进行探索，若q越小，游走会更倾向于探索距离上一步节点t更远的节点。在p和q之间trade
off，可以控制随机游走的倾向性，从而达到更好的效果。特别的，当p=q=1时，Node2Vec等价于DeepWalk。</li>
</ul>
<p><strong>Node2Vec中提出的随机游走，若结合Alias
Sampling策略，在额外引入O(2|E|)的时空复杂度后，也可以在O(1)内完成一步游走的采样，因此整个游走的复杂度是
<span class="math inline">\(O(lk|V|+2|E|)\)</span>。</strong>基本上这就是Node2Vec这篇文章的核心了，后续同DeepWalk一样基于采样得到的序列训练Skip-gram模型即可。</p>
<h3><span id="22-alias-sampling">2.2 Alias Sampling</span></h3>
<h2><span id="4-summary">4. Summary</span></h2>
<p>DeepWalk和Node2Vec的思路都非常简单直接，也能取得可观的效果。它们与那些矩阵分解算法在同一时期被提出，但由于基于随机游走的算法有着更好的可扩展性，并且也能更好的泛化到新节点上，DeepWalk和Node2Vec远远比GraRep、HOPE这些模型流行的多。</p>
<p>但是，随着GCN的出现，无法共享参数的这些基于随机游走的模型也渐渐不再火热，如今的图机器学习领域已将重点放在了图神经网络的研究之中。</p>
<p>总体来说，DeepWalk和Node2Vec这类模型的优点有：</p>
<ul>
<li>相比于矩阵分解模型来说，可扩展性更强</li>
<li>虽然本身不是inductive的，但也能很容易的在训练中加入新的节点</li>
</ul>
<p>该类模型的局限性有：</p>
<ul>
<li>随机游走的代价事实上是极大的</li>
<li>Embedding
lookup矩阵后直接跟损失函数，模型表达能力有限、节点间无参数共享</li>
<li><strong>无法对k阶邻居进行区分，只能知道两两节点是否在同一个窗口中出现过，这样事实上丢失了图中部分拓扑信息，可能导致模型效果受限</strong>;</li>
<li>无法直接利用节点的特征</li>
<li>Transductive</li>
</ul>
<figure>
<img src="image-20230311111120651.png" alt="image-20230311111120651">
<figcaption aria-hidden="true">image-20230311111120651</figcaption>
</figure>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（4）PageRrank</title>
    <url>/posts/38C49BW/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（5）【Nan】GraphSAGE</title>
    <url>/posts/21SNDGZ/</url>
    <content><![CDATA[<h2><span id="graphsage">GraphSAGE</span></h2>
<blockquote>
<p>GraphSAGE：我寻思GCN也没我牛逼 - 蝈蝈的文章 - 知乎
https://zhuanlan.zhihu.com/p/74242097</p>
<p>【Graph Neural Network】GraphSAGE: 算法原理，实现和应用 - 浅梦的文章
- 知乎 https://zhuanlan.zhihu.com/p/79637787</p>
<p><strong>阿里开源的graphlearn</strong>：https://graph-learn.readthedocs.io/zh_CN/latest/</p>
<p><a href="../../AI算法应用/风控算法/风控反欺诈（2）GraphSAGE算法在网络黑产挖掘中的思考.md">风控反欺诈（2）GraphSAGE算法在网络黑产挖掘中的思考.md</a></p>
<p><strong>graphSAGE-pytorch</strong>：https://github.com/twjiang/graphSAGE-pytorch</p>
</blockquote>
<p>众所周知，2017年ICLR出产的GCN现在是多么地热门，仿佛自己就是图神经网络的名片。然而，在GCN的风头中，很多人忽略了GCN本身的巨大局限——Transductive
Learning——<strong>没法快速表示新节点</strong>，这限制了它在生产环境中应用。同年NIPS来了一篇使用Inductive
Learning的GraphSAGE，解决了这个问题。今天，让我们来一起琢磨琢磨这个GraphSAGE是个什么玩意儿。</p>
<h3><span id="一-回顾gcn及其问题">一、回顾GCN及其问题</span></h3>
<p>对GCN不熟悉的盆友，可以看看我的上一篇文章： <a href="https://zhuanlan.zhihu.com/p/71200936">蝈蝈：何时能懂你的心——图卷积神经网络（GCN）</a></p>
<ul>
<li><strong>GCN的基本思想：</strong>
把一个节点在图中的高纬度邻接信息降维到一个低维的向量表示。</li>
<li><strong>GCN的优点：</strong>
可以捕捉graph的全局信息，从而很好地表示node的特征。</li>
<li><strong>GCN的缺点：</strong> Transductive
learning的方式，需要把所有节点都参与训练才能得到node
embedding，无法快速得到新node的embedding。</li>
</ul>
<h3><span id="二-graphsage">二、GraphSAGE</span></h3>
<blockquote>

</blockquote>
<p>既然<strong>新增的节点，一定会改变原有节点的表示</strong>，那么我们<strong>干嘛一定要得到每个节点的一个固定的表示呢？</strong>我们何不直接<strong>学习一种节点的表示方法</strong>。这样不管graph怎么改变，都可以很容易地得到新的表示。</p>
<h4><span id="基本思想"><strong>基本思想：</strong></span></h4>
<p>去学习一个节点的信息是怎么通过其邻居节点的特征聚合而来的。
学习到了这样的“<strong>聚合函数</strong>”，而我们本身就已知各个节点的特征和邻居关系，我们就可以很方便地得到一个新节点的表示了。</p>
<p>GCN等transductive的方法，学到的是每个节点的一个唯一确定的embedding；
而<strong>GraphSAGE方法学到的node
embedding，是根据node的邻居关系的变化而变化的，也就是说，即使是旧的node，如果建立了一些新的link，那么其对应的embedding也会变化，而且也很方便地学到。</strong></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（5）标签传播</title>
    <url>/posts/1H66A43/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（4）【Nan】GCN</title>
    <url>/posts/28N4D7Y/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（6）【Nan】GAN</title>
    <url>/posts/JC8WRZ/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（7）【Nan】HetGNN</title>
    <url>/posts/1VGG9SJ/</url>
    <content><![CDATA[<h2><span id="hetgnn">HetGNN</span></h2>
<blockquote>
<p>HetGNN --异构图处理 - wlkq的文章 - 知乎
https://zhuanlan.zhihu.com/p/411528472</p>
<p>异构图embedding学习，舍HetGNN其谁？ - 李杰的文章 - 知乎
https://zhuanlan.zhihu.com/p/392367843</p>
</blockquote>
<p>图嵌入领域，同构图算法大行其道，如：DeepWalk、Node2vec、GCN、GraphSage、GAT。但实际业务场景中异构图居多，除了经典的MetaPath2vec、RGCN，貌似其他选项并不多，今天就为大家介绍一款异构图嵌入学习神器---HetGNN。</p>
<h3><span id="hetgnn简介">HetGNN简介</span></h3>
<p>提出的网络名称：<strong>HetGNN（Heterogeneous Graph Neural
Network），2019 SIGKDD</strong></p>
<p>核心理念：heterogeneous structural graph information + <a href="https://www.zhihu.com/search?q=heterogeneous&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22392367843%22%7D">heterogeneous</a>
attributes or contents for each node</p>
<h3><span id="异构图嵌入学习">异构图嵌入学习</span></h3>
<p>异构图算法相较同构图算法有如下三方面挑战：</p>
<ul>
<li>异质图中的大多数节点并不会连接所有类型的其他节点。如academic
graph中user节点不会直接连到venue（论文）节点上。另外说节点能够连接的邻居数也不一样。大部分GNN直接聚合邻居（一阶）节点信息，而远处传过来的节点信息会随着距离而减弱。hub节点会被弱关联的邻居节点扰乱信息，冷启动的节点会因为邻居不足而导致不能充分表示。<strong>那么问题1就是：如何对异质图上的每个节点采样到强相关的邻居节点呢？（这边我认为一般都是用了注意力机制了）</strong></li>
<li>每个节点都带有非结构化的属性特征，如text、image，常用的从concatenate或者linear
transformation不能建模节点属性间的deep
interaction。<strong>那么问题2就是：如何设计异质图上节点属性的encoder（编码器）来处理不同节点内容异质性问题。</strong></li>
<li>不同类型的邻居节点对生成节点embedding的贡献也不一样。例如在academic
graph，author和paper节点对author的embedding的影响会强如venue，venue节点包含不同的主题，具有更一般的嵌入，而大部分gnn集中在同质图的处理上，也没有考虑这种不同类型节点的影响。
<strong>挑战3是:如何通过考虑不同节点类型的影响来聚合异构邻居的特征信息。</strong>【<strong>自注意力机制</strong>】</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（8）【Nan】GAT</title>
    <url>/posts/3WJ8Z6E/</url>
    <content><![CDATA[<h2><span id="向往的gat图注意力网络的原理-实现及计算复杂度">向往的GAT(图注意力网络的原理、实现及计算复杂度)</span></h2>
<p>GAT原理：https://zhuanlan.zhihu.com/p/81350196；</p>
<p>GAT阿里的比赛；</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-GNN（7）【Nan】metapath2vec</title>
    <url>/posts/WCW1A3/</url>
    <content><![CDATA[<p>Metapath2vec是Yuxiao
Dong等于2017年提出的一种用于异构信息网络（Heterogeneous Information
Network, HIN）的顶点嵌入方法。metapath2vec使用基于meta-path的random
walks来构建每个顶点的异构邻域，然后用Skip-Gram模型来完成顶点的嵌入。在metapath2vec的基础上，作者还提出了metapath2vec++来同时实现异构网络中的结构和语义关联的建模。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习（4）CNN</title>
    <url>/posts/3MJS4P5/</url>
    <content><![CDATA[<h2><span id="cnn-门控卷积网络">CNN-门控卷积网络</span></h2>
<ul>
<li>https://zhuanlan.zhihu.com/p/59064623</li>
<li><a href="https://blog.csdn.net/FishPotatoChen/article/details/123389289?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-123389289-blog-108305491.pc_relevant_paycolumn_v3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-123389289-blog-108305491.pc_relevant_paycolumn_v3&amp;utm_relevant_index=2">参数估计</a></li>
<li>**<font color="red"> 卷积神经网络中用1*1
卷积有什么作用或者好处呢？</font>** - 初识CV的回答 - 知乎
https://www.zhihu.com/question/56024942/answer/1850649283</li>
</ul>
<h2><span id="一-参数估计">一、参数估计</span></h2>
<p>卷积操作的本质是<strong>稀疏交互</strong>和<strong>参数共享</strong>。</p>
<p><strong>稀疏交互</strong>：每个输出神经元仅与前一层特定局部区域内的神经元存在连接权重。<strong>物理意义</strong>：通常图像，文字、语音等现实世界中的数据都具有<strong>局部的特征结构</strong>。</p>
<p><strong>参数共享</strong>：卷积核中的每一个元素将作用于每一个局部输入的特定位置上。<strong>物理意义</strong>：平移等变性</p>
<p><strong>池化操作</strong>：针对非重叠区域，均值池化、最大池化。除了能显著降低参数外，还能够保持对平移、伸缩、旋转操作的不变性。</p>
<h4><span id="11-正向传播">1.1 正向传播</span></h4>
<p>这里用输入为 <span class="math inline">\(3 * 3\)</span> 矩阵 <span class="math inline">\(A^{l-1}\)</span>, 步长为 1 , 卷积核为 <span class="math inline">\(2 * 2\)</span> 矩阵 <span class="math inline">\(W^{l}\)</span>, 输出为 <span class="math inline">\(2 * 2\)</span> 矩阵 <span class="math inline">\(Z^{l}\)</span> 的卷积层为 例。矩阵 <span class="math inline">\(A^{l-1}\)</span> 可以是整个神经网络的输入,
也可以是池化层的输出。这个模型简化为输入层 <span class="math inline">\(A^{l-1}\)</span> 经 过卷积计算得到特征图 <span class="math inline">\(Z^{l}, Z^{l}\)</span> 经过激活函数 <span class="math inline">\(\sigma(x)\)</span> 得到输出层 <span class="math inline">\(A^{l}\)</span> (实际上在现实工程中很多时候不用激
活函数)。对于第 <span class="math inline">\(l\)</span> 层, 有下列表达式:
<span class="math display">\[
\left[\begin{array}{lll}
a_{1} &amp; a_{2} &amp; a_{3} \\
a_{4} &amp; a_{5} &amp; a_{6} \\
a_{7} &amp; a_{8} &amp; a_{9}
\end{array}\right]^{l-1} \Rightarrow\left[\begin{array}{cc}
\omega_{1} &amp; \omega_{2} \\
\omega_{3} &amp; \omega_{4}
\end{array}\right]^{l} \Rightarrow\left[\begin{array}{ll}
z_{1} &amp; z_{2} \\
z_{3} &amp; z_{4}
\end{array}\right]^{l} \Rightarrow\left[\begin{array}{ll}
a_{1} &amp; a_{2} \\
a_{3} &amp; a_{4}
\end{array}\right]^{l}
\]</span></p>
<p><span class="math display">\[
\left\{\begin{aligned}
a_{1}^{l} &amp;=\sum\left(\left[\begin{array}{ll}
a_{1} &amp; a_{2} \\
a_{4} &amp; a_{5}
\end{array}\right]^{l-1} \cdot\left[\begin{array}{ll}
\omega_{1} &amp; \omega_{2} \\
\omega_{3} &amp; \omega_{4}
\end{array}\right]^{l}\right)=\sigma\left(\omega_{1}
a_{1}^{l-1}+\omega_{2} a_{2}^{l-1}+\omega_{3} a_{3}^{l-1}+\omega_{4}
a_{4}^{l-1}+b^{l}\right) \\
a_{2}^{l} &amp;=\sum\left(\left[\begin{array}{ll}
a_{2} &amp; a_{3} \\
a_{5} &amp; a_{6}
\end{array}\right]^{l-1} \cdot\left[\begin{array}{ll}
\omega_{1} &amp; \omega_{2} \\
\omega_{3} &amp; \omega_{4}
\end{array}\right]^{l}\right)=\sigma\left(\omega_{1}
a_{2}^{l-1}+\omega_{2} a_{3}^{l-1}+\omega_{3} a_{5}^{l-1}+\omega_{4}
a_{6}^{l-1}+b^{l}\right) \\
a_{3}^{l} &amp;=\sum\left(\left[\begin{array}{ll}
a_{4} &amp; a_{5} \\
a_{7} &amp; a_{8}
\end{array}\right]^{l-1} \cdot\left[\begin{array}{ll}
\omega_{1} &amp; \omega_{2} \\
\omega_{3} &amp; \omega_{4}
\end{array}\right]^{l}\right)=\sigma\left(\omega_{1}
a_{4}^{l-1}+\omega_{2} a_{5}^{l-1}+\omega_{3} a_{7}^{l-1}+\omega_{4}
a_{8}^{l-1}+b^{l}\right) \\
a_{4}^{l} &amp;=\sum\left(\left[\begin{array}{ll}
a_{5} &amp; a_{6} \\
a_{8} &amp; a_{9}
\end{array}\right]^{l-1} \cdot\left[\begin{array}{ll}
\omega_{1} &amp; \omega_{2} \\
\omega_{3} &amp; \omega_{4}
\end{array}\right]^{l}\right)=\sigma\left(\omega_{1}
a_{5}^{l-1}+\omega_{2} a_{6}^{l-1}+\omega_{3} a_{8}^{l-1}+\omega_{4}
a_{9}^{l-1}+b^{l}\right)
\end{aligned}\right.
\]</span></p>
<p>简单来说, 卷积过程就是对应的位置代入函数之后相加求和,
不同的函数有不同的参数 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span>, 我们需 要训练的是卷积核参数,
所以这个公式还可以写做 <span class="math inline">\(Z^{l}=W^{l} *
A^{l-1}+b^{l}, \sigma(x)\)</span> 是激活函数,
<strong>我们假设是ReLU函数, 求导比较好求</strong>,
所以我们接下来的计算忽略了对激活层的求导。 <span class="math display">\[
\sigma(x)=\left\{\begin{array}{lc}
0 &amp; , \quad x&lt;0 \\
x &amp; , \quad x&gt;=0
\end{array}\right.
\]</span></p>
<h3><span id="12-反向传播">1.2 反向传播</span></h3>
<h2><span id="二-cnn-李宏毅">二、CNN - 李宏毅</span></h2>
<h2><span id="三-cnn-qampa">三、CNN Q&amp;A</span></h2>
<h4><span id="31卷积神经网络的卷积核大小-个数卷积层数如何确定呢">3.1
卷积神经网络的卷积核大小、个数，卷积层数如何确定呢？</span></h4>
<ul>
<li>https://cloud.tencent.com/developer/article/1462368</li>
</ul>
<p>每一层卷积有多少channel数，以及一共有多少层卷积，这些暂时没有理论支撑，一般都是靠感觉去设置几组候选值，然后通过实验挑选出其中的最佳值。这也是现在深度卷积神经网络虽然效果拔群，但是一直为人诟病的原因之一。</p>
<h4><span id="32卷积神经网络中用11-卷积有什么作用或者好处呢">3.2
卷积神经网络中用1*1 卷积有什么作用或者好处呢？</span></h4>
<ul>
<li>卷积神经网络中用1*1 卷积有什么作用或者好处呢？ - YJango的回答 - 知乎
https://www.zhihu.com/question/56024942/answer/194997553</li>
</ul>
<p><img src="image-20220627212030158.png" alt="image-20220627212030158" style="zoom: 50%;"></p>
<p><strong>降维</strong>：Inception结构可以看出，这些1X1的卷积的作用是为了让网络根据需要能够更灵活的控制数据的depth的。</p>
<p><strong>加入非线性</strong>。卷积层之后经过激励层，1*1的卷积在前一层的学习表示上添加了非线性激励（
non-linear activation ），提升网络的表达能力；</p>
<p><strong>1 * 1的卷积就是多个feature channels线性叠加，nothing
more!只不过这个组合系数恰好可以看成是一个1 *
1的卷积</strong>。这种表示的好处是，完全可以回到模型中其他常见N*N的框架下，不用定义新的层。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>CNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习（5）RNN</title>
    <url>/posts/19BYM1P/</url>
    <content><![CDATA[<h2><span id="rnn">RNN</span></h2>
<blockquote>
<p>史上最详细循环神经网络讲解（RNN/LSTM/GRU）:https://zhuanlan.zhihu.com/p/123211148</p>
</blockquote>
<h3><span id="一-什么是循环神经网络"><strong>一、什么是循环神经网络</strong></span></h3>
<p><strong>RNN对具有序列特性的数据非常有效，它能挖掘数据中的时序信息以及语义信息</strong>，利用了RNN的这种能力，使深度学习模型在解决语音识别、语言模型、机器翻译以及时序分析等NLP领域的问题时有所突破。</p>
<p>我们需要重点来了解一下RNN的特点这句话，什么是<strong>序列特性</strong>呢？我个人理解，就是<strong>符合时间顺序，逻辑顺序，或者其他顺序就叫序列特性</strong>，举几个例子：</p>
<ul>
<li>拿人类的某句话来说，也就是人类的自然语言，是不是符合某个逻辑或规则的字词拼凑排列起来的，这就是符合序列特性。</li>
<li>语音，我们发出的声音，每一帧每一帧的衔接起来，才凑成了我们听到的话，这也具有序列特性、</li>
<li>股票，随着时间的推移，会产生具有顺序的一系列数字，这些数字也是具有序列特性。</li>
</ul>
<h3><span id="二-为什么要发明循环神经网络"><strong>二、为什么要发明循环神经网络</strong></span></h3>
<p>我们先来看一个NLP很常见的问题，命名实体识别，举个例子，现在有两句话：</p>
<p>第一句话：I like eating apple！（我喜欢吃苹果！）</p>
<p>第二句话：The Apple is a great
company！（苹果真是一家很棒的公司！）</p>
<p>现在的任务是要给apple打Label，我们都知道第一个apple是一种水果，第二个apple是苹果公司，假设我们现在有大量的已经标记好的数据以供训练模型，当我们使用全连接的神经网络时，我们做法是把apple这个单词的特征向量输入到我们的模型中（如下图），在输出结果时，让我们的label里，正确的label概率最大，来训练模型，但我们的语料库中，有的apple的label是水果，有的label是公司，这将导致，模型在训练的过程中，预测的准确程度，取决于训练集中哪个label多一些，这样的模型对于我们来说完全没有作用。<strong>问题就出在了我们没有结合上下文去训练模型，而是单独的在训练apple这个单词的label，这也是全连接神经网络模型所不能做到的，于是就有了我们的循环神经网络。</strong></p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-9a86430ba17aa299ce5c44c7b75c5ece_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="三-循环神经网络的结构及原理"><strong>三、循环神经网络的结构及原理：</strong></span></h3>
<p><img src="https://pic1.zhimg.com/80/v2-8f534b5db1f3d8a5c4ccd029be4a15b4_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>上图就是RNN的结构，我第一次看到这图的第一反应是，不是说好的循环神经网络么，起码得是神经网络啊，神经网络不是有很多球球么，也就是神经元，这RNN咋就这几个球球，不科学啊，看不懂啊！！！！随着慢慢的了解RNN，才发现这图看着是真的清楚，因为RNN的特殊性，如果展开画成那种很多神经元的神经网络，会很麻烦。</p>
<p>我们先来讲解一下上面这幅图，首先不要管右边的W，只看X,U,S,V,O，这幅图就变成了，如下：</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-9a86430ba17aa299ce5c44c7b75c5ece_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>不看W的话，上面那幅图展开就是全连接神经网络，其中X是一个向量，也就是某个字或词的特征向量，作为输入层，如上图也就是3维向量，U是输入层到隐藏层的参数矩阵，在上图中其维度就是3X4，S是隐藏层的向量，如上图维度就是4，V是隐藏层到输出层的参数矩阵，在上图中就是4X2，O是输出层的向量，在上图中维度为2。</p>
<p><strong>弄懂了RNN结构的左边，那么右边这个W到底是什么啊？</strong>把上面那幅图打开之后，是这样的：
<img src="https://pic4.zhimg.com/80/v2-8abf977157000e6dad8589ec60ed6c3f_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>等等，这又是什么？？别慌，很容易看，举个例子，有一句话是，I love
you，那么在利用RNN做一些事情时，比如命名实体识别，上图中的 <img src="https://www.zhihu.com/equation?tex=X_%7Bt-1%7D" alt="[公式]">
代表的就是I这个单词的向量， <img src="https://www.zhihu.com/equation?tex=X" alt="[公式]">
代表的是love这个单词的向量， <img src="https://www.zhihu.com/equation?tex=X_%7Bt%2B1%7D" alt="[公式]">
代表的是you这个单词的向量，以此类推，我们注意到，上图展开后，W一直没有变，<strong>W其实是每个时间点之间的权重矩阵</strong>，我们注意到，RNN之所以可以解决序列问题，<strong>是因为它可以记住每一时刻的信息，==每一时刻的隐藏层不仅由该时刻的输入层决定，还由上一时刻的隐藏层决定==</strong>，公式如下，其中
<img src="https://www.zhihu.com/equation?tex=O_t" alt="[公式]">
代表t时刻的输出, <img src="https://www.zhihu.com/equation?tex=S_t" alt="[公式]"> 代表t时刻的隐藏层的值：</p>
<p><img src="https://pic4.zhimg.com/80/v2-9524a28210c98ed130644eb3c3002087_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p><strong>值得注意的一点是，在整个训练过程中，每一时刻所用的都是同样的W。</strong></p>
<h4><span id="四-举个例子方便理解"><strong>四、举个例子，方便理解：</strong></span></h4>
<p>假设现在我们已经训练好了一个RNN，如图，<strong>我们假设每个单词的特征向量是二维的，也就是输入层的维度是二维，且隐藏层也假设是二维，输出也假设是二维</strong>，所有权重的值都为1且没有偏差且所有激活函数都是线性函数，现在输入一个序列，到该模型中，我们来一步步求解出输出序列：</p>
<p><img src="https://pic4.zhimg.com/80/v2-09ce45f29378cb2695b3b4fcd2015047_1440w.png" alt="img" style="zoom:75%;"></p>
<p>你可能会好奇W去哪了？<strong>W在实际的计算中，在图像中表示非常困难
，所以我们可以想象上一时刻的隐藏层的值是被存起来，等下一时刻的隐藏层进来时，上一时刻的隐藏层的值通过与权重相乘，两者相加便得到了下一时刻真正的隐藏层</strong>，如图
<img src="https://www.zhihu.com/equation?tex=a_1" alt="[公式]"> , <img src="https://www.zhihu.com/equation?tex=a_2" alt="[公式]">
可以看做每一时刻存下来的值，当然初始时<img src="https://www.zhihu.com/equation?tex=a_1" alt="[公式]"> , <img src="https://www.zhihu.com/equation?tex=a_2" alt="[公式]">是没有存值的，因此初始值为0：</p>
<p><img src="https://pic2.zhimg.com/80/v2-2c3522b9d250a44cfaeddecbcd139275_1440w.jpg" alt="img" style="zoom:80%;"></p>
<p>当我们输入第一个序列，【1,1】，如下图，其中隐藏层的值，也就是绿色神经元，是通过公式
<img src="https://www.zhihu.com/equation?tex=S_%7Bt%7D%3Df%5Cleft%28U+%5Ccdot+X_%7Bt%7D%2BW+%5Ccdot+S_%7Bt-1%7D%5Cright%29" alt="[公式]"> 计算得到的，因为所有权重都是1，所以也就是 <img src="https://www.zhihu.com/equation?tex=1%2A1%2B1%2A1%2B1%2A0%2B1%2A0%3D2" alt="[公式]">
（我把向量X拆开计算的，由于篇幅关系，我只详细列了其中一个神经元的计算过程，希望大家可以看懂，看不懂的请留言），输出层的值4是通过公式
<img src="https://www.zhihu.com/equation?tex=O_%7Bt%7D%3Dg%5Cleft%28V+%5Ccdot+S_%7Bt%7D%5Cright%29" alt="[公式]"> 计算得到的，也就是 <img src="https://www.zhihu.com/equation?tex=2%2A1%2B2%2A1%3D4" alt="[公式]">
（同上，也是只举例其中一个神经元），得到输出向量【4,4】：</p>
<p><img src="https://pic2.zhimg.com/80/v2-c01a8a5c476aa2bd189965aa149d9e85_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>当【1,1】输入过后，我们的记忆里的 <img src="https://www.zhihu.com/equation?tex=a_1%2Ca_2" alt="[公式]">
已经不是0了，而是把这一时刻的隐藏状态放在里面，即变成了2，如图，输入下一个向量【1,1】，隐藏层的值通过公式<img src="https://www.zhihu.com/equation?tex=S_%7Bt%7D%3Df%5Cleft%28U+%5Ccdot+X_%7Bt%7D%2BW+%5Ccdot+S_%7Bt-1%7D%5Cright%29" alt="[公式]"> 得到， <img src="https://www.zhihu.com/equation?tex=1%2A1%2B1%2A1%2B1%2A2%2B1%2A2%3D6" alt="[公式]"> ，输出层的值通过公式<img src="https://www.zhihu.com/equation?tex=O_%7Bt%7D%3Dg%5Cleft%28V+%5Ccdot+S_%7Bt%7D%5Cright%29" alt="[公式]">，得到 <img src="https://www.zhihu.com/equation?tex=6%2A1%2B6%2A1%3D12" alt="[公式]"> ，最终得到输出向量【12,12】：</p>
<p><img src="https://pic2.zhimg.com/80/v2-5170c41f0285a718b890979e125832ed_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>同理，该时刻过后 <img src="https://www.zhihu.com/equation?tex=a_1%2Ca_2" alt="[公式]">
的值变成了6，也就是输入第二个【1,1】过后所存下来的值，同理，输入第三个向量【2,2】，如图，细节过程不再描述，得到输出向量【32,32】：</p>
<p><img src="https://pic3.zhimg.com/80/v2-7ba6fd916892a89211b5ee6a5940d2b2_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>由此，我们得到了最终的输出序列为：</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-e21cfad47c16012c38d2acd9c75039d7_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>至此，一个完整的RNN结构我们已经经历了一遍，我们注意到，每一时刻的输出结果都与上一时刻的输入有着非常大的关系，如果我们将输入序列换个顺序，那么我们得到的结果也将是截然不同，这就是RNN的特性，可以处理序列数据，同时对序列也很敏感。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>RNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-NLP-TextCNN</title>
    <url>/posts/HXBCSZ/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习（6）LSTM*</title>
    <url>/posts/1M5VH4X/</url>
    <content><![CDATA[<h2><span id="lstm和gru算法简单梳理">LSTM和GRU算法简单梳理🍭</span></h2>
<h3><span id="前言-从反向传播推导到梯度消失and爆炸的原因及解决方案"><font color="red">
前言 - 从反向传播推导到梯度消失and爆炸的原因及解决方案？</font></span></h3>
<blockquote>
<ul>
<li>从反向传播推导到梯度消失and爆炸的原因及解决方案（从DNN到RNN，内附详细反向传播公式推导）
- 韦伟的文章 - 知乎 https://zhuanlan.zhihu.com/p/76772734</li>
</ul>
<p><strong>本质上</strong>是因为神经网络的更新方法，梯度消失是因为反向传播过程中对梯度的求解会产生sigmoid导数和参数的连乘，sigmoid导数的最大值为0.25，权重一般初始都在0，1之间，乘积小于1，多层的话就会有多个小于1的值连乘，导致靠近输入层的梯度几乎为0，得不到更新。梯度爆炸是也是同样的原因，只是如果初始权重大于1，或者更大一些，多个大于1的值连乘，将会很大或溢出，导致梯度更新过大，模型无法收敛。其实<strong>梯度爆炸和梯度消失问题都是因为网络太深</strong>，网络权值更新不稳定造成的，本质上是因为<strong>梯度反向传播中的连乘效应</strong>。</p>
</blockquote>
<h3><span id="一-反向传播推导到梯度消失and爆炸的原因及解决方案">一、反向传播推导到梯度消失and爆炸的原因及解决方案</span></h3>
<h4><span id="11-反向传播推导">1.1 ==反向传播推导：==</span></h4>
<figure>
<img src="https://pic1.zhimg.com/80/v2-cbcb60d90cbd259a717cbe991aa93f5c_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>以上图为例开始推起来，先说明几点，i1，i2是输入节点，h1，h2为隐藏层节点，o1，o2为输出层节点，除了输入层，其他两层的节点结构为下图所示：</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-7c0b41fdbd084ed875480516967857ed_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>举例说明，<img src="https://www.zhihu.com/equation?tex=NET_%7Bo1%7D" alt="[公式]"> 为输出层的输入，也就是隐藏层的输出经过线性变换后的值，
<img src="https://www.zhihu.com/equation?tex=OUT_%7Bo1%7D" alt="[公式]"> 为经过激活函数sigmoid后的值；同理 <img src="https://www.zhihu.com/equation?tex=NET_%7Bh1%7D" alt="[公式]">
为隐藏层的输入，也就是输入层经过线性变换后的值， <img src="https://www.zhihu.com/equation?tex=OUT_%7Bh1%7D" alt="[公式]">
为经过激活函数sigmoid 的值。只有这两层有激活函数，输入层没有。</p>
<blockquote>
<p><strong>定义一下sigmoid的函数：</strong> <img src="https://www.zhihu.com/equation?tex=%5Csigma%28z%29+%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D" alt="[公式]"> <strong>说一下sigmoid的求导：</strong></p>
</blockquote>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Csigma%5E%7B%5Cprime%7D%28z%29+%26%3D%5Cleft%28%5Cfrac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D%5Cright%29%5E%7B%5Cprime%7D+%5C%5C+%26%3D%5Cfrac%7Be%5E%7B-z%7D%7D%7B%5Cleft%281%2Be%5E%7B-z%7D%5Cright%29%5E%7B2%7D%7D+%5C%5C+%26%3D%5Cfrac%7B1%2Be%5E%7B-z%7D-1%7D%7B%5Cleft%281%2Be%5E%7B-z%7D%5Cright%29%5E%7B2%7D%7D+%5C%5C+%26%3D%5Cfrac%7B%5Csigma%28z%29%7D%7B%5Cleft%281%2Be%5E%7B-z%7D%5Cright%29%5E%7B2%7D%7D+%5C%5C+%26%3D%5Csigma%28z%29%281-%5Csigma%28z%29%29+%5Cend%7Baligned%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>定义一下损失函数，这里的损失函数是均方误差函数，即：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=Loss_%7Bt+o+t+a+l%7D%3D%5Csum+%5Cfrac%7B1%7D%7B2%7D%28%5Ctext+%7Btarget+-+output%7D%29%5E%7B2%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>具体到上图，就是：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=Loss_%7Bt+o+t+a+l%7D%3D+%5Cfrac%7B1%7D%7B2%7D%28%5Ctext+%7Btarget1+-+out_o1%7D%29%5E%7B2%7D%2B+%5Cfrac%7B1%7D%7B2%7D%28%5Ctext+%7Btarget2+-+out_o2%7D%29%5E%7B2%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>到这里，所有前提就交代清楚了，前向传播就不推了，默认大家都会，下面推反向传播。</p>
<ul>
<li><strong>第一个反向传播（热身）</strong></li>
</ul>
<p>先来一个简单的热热身，求一下损失函数对W5的偏导，即： <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+w_5%7D" alt="[公式]"></p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-cbcb60d90cbd259a717cbe991aa93f5c_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><img src="https://pic2.zhimg.com/80/v2-7c0b41fdbd084ed875480516967857ed_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>首先根据链式求导法则写出对W5求偏导的总公式，再把图拿下来对照（如上），可以看出，需要计算三部分的求导【损失函数、激活函数、线性函数】，下面就一步一步来：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%E6%80%BB%E5%85%AC%E5%BC%8F%EF%BC%9A%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+w_5%7D+%3D+%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+out_%7Bo1%7D%7D+%5Cfrac%7B%5Cpartial+out_%7Bo1%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%5Cfrac%7B%5Cpartial+net_%7Bo1%7D%7D%7B%5Cpartial+w_%7B5%7D%7D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A+%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+out_%7Bo1%7D%7D+%3D+%5Cfrac%7B%5Cpartial%5Cfrac%7B1%7D%7B2%7D%28%7Btarget_1+-+out_%7Bo1%7D%7D%29%5E%7B2%7D%2B+%5Cfrac%7B1%7D%7B2%7D%28+%7Btarget_2+-+out_%7Bo2%7D%7D%29%5E%7B2%7D%7D%7B%5Cpartial+out_%7Bo1%7D%7D+%3D+out_%7Bo1%7D+-+target_1%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A+%5Cfrac%7B%5Cpartial+out_%7Bo1%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%3D+%5Cfrac%7B%5Cpartial%5Cfrac%7B1%7D%7B1%2Be%5E%7B-net_%7Bo1%7D%7D%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%3D%5Csigma%28net_%7Bo1%7D%29%281-%5Csigma%28net_%7Bo1%7D%29%29+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A+%5Cfrac%7B%5Cpartial+net_%7Bo1%7D%7D%7B%5Cpartial+w_5%7D+%3D+%5Cfrac%7B%5Cpartial+out_%7Bh1%7Dw_5%2Bout_%7Bh2%7Dw_6%7D%7B%5Cpartial+w_5%7D+%3Dout_%7Bh_1%7D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>综上三个步骤，得到总公式：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%E6%80%BB%E5%85%AC%E5%BC%8F%EF%BC%9A%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+w_5%7D+%3D+%28out_%7Bo1%7D+-+target_1%29+%5Ccdot+%28%5Csigma%28net_%7Bo1%7D%29%281-%5Csigma%28net_%7Bo1%7D%29%29%29%5Ccdot+out_%7Bh_1%7D++%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<ul>
<li><strong>第二个反向传播：</strong></li>
</ul>
<p>接下来，要求损失函数对w1的偏导，即： <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+w_1%7D" alt="[公式]"></p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-cbcb60d90cbd259a717cbe991aa93f5c_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><img src="https://pic2.zhimg.com/80/v2-7c0b41fdbd084ed875480516967857ed_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>还是把图摆在这，方便看，先写出总公式，对w1求导有个地方要注意，w1的影响不仅来自o1还来自o2，从图上可以一目了然，所以总公式为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%E6%80%BB%E5%85%AC%E5%BC%8F%EF%BC%9A%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+w_1%7D+%3D+%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+out_%7Bo1%7D%7D+%5Cfrac%7B%5Cpartial+out_%7Bo1%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%5Cfrac%7B%5Cpartial+net_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D++%5Cfrac%7B%5Cpartial+out_%7Bh1%7D%7D%7B%5Cpartial+net_%7Bh1%7D%7D+%5Cfrac%7B%5Cpartial+net_%7Bh1%7D%7D%7B%5Cpartial+w_1%7D%2B%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+out_%7Bo2%7D%7D+%5Cfrac%7B%5Cpartial+out_%7Bo2%7D%7D%7B%5Cpartial+net_%7Bo2%7D%7D+%5Cfrac%7B%5Cpartial+net_%7Bo2%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D++%5Cfrac%7B%5Cpartial+out_%7Bh1%7D%7D%7B%5Cpartial+net_%7Bh1%7D%7D+%5Cfrac%7B%5Cpartial+net_%7Bh1%7D%7D%7B%5Cpartial+w_1%7D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>所以总共分为左右两个式子，分别又对应5个步骤，详细写一下左边，右边同理：</p>
<p><img src="https://www.zhihu.com/equation?tex=%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A+%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+out_%7Bo1%7D%7D+%3D+out_%7Bo1%7D+-+target_1%5C%5C" alt="[公式]"> <img src="https://www.zhihu.com/equation?tex=%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A+%5Cfrac%7B%5Cpartial+out_%7Bo1%7D%7D%7B%5Cpartial+net_%7Bo1%7D%7D+%3D+%5Csigma%28net_%7Bo1%7D%29%281-%5Csigma%28net_%7Bo1%7D%29%29+%5C%5C" alt="[公式]"></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A+%5Cfrac%7B%5Cpartial+net_%7Bo1%7D%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%3D+%5Cfrac%7B%5Cpartial+out_%7Bh1%7Dw_5%2Bout_%7Bh2%7Dw_6%7D%7B%5Cpartial+out_%7Bh1%7D%7D+%3Dw_5%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9A+%5Cfrac%7B%5Cpartial+out_%7Bh1%7D%7D%7B%5Cpartial+net_%7Bh1%7D%7D+%3D+%5Csigma%28net_%7Bh1%7D%29%281-%5Csigma%28net_%7Bh1%7D%29%29+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A+%5Cfrac%7B%5Cpartial+net_%7Bh1%7D%7D%7B%5Cpartial+w_1%7D+%3D+%5Cfrac%7B%5Cpartial+i_1w_1%2Bi_2w_2%7D%7B%5Cpartial+w_1%7D+%3Di_1%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>右边也是同理，就不详细写了，写一下总的公式：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+w_1%7D++%26%3D%5Cleft%28%28out_%7Bo1%7D+-+target_1%29%5Ccdot+%28%5Csigma%28net_%7Bo1%7D%29%281-%5Csigma%28net_%7Bo1%7D%29%29%29%5Ccdot+w_5+%5Ccdot+%28%5Csigma%28net_%7Bh1%7D%29%281-%5Csigma%28net_%7Bh1%7D%29%29%29%5Ccdot+i_1+%5Cright%29+%5C%5C+%26%2B%7B%5Cleft%28%28out_%7Bo2%7D+-+target_2%29%5Ccdot+%28%5Csigma%28net_%7Bo2%7D%29%281-%5Csigma%28net_%7Bo2%7D%29%29%29%5Ccdot+w_7+%5Ccdot+%28%5Csigma%28net_%7Bh1%7D%29%281-%5Csigma%28net_%7Bh1%7D%29%29%29%5Ccdot+i_1+%5Cright%29%7D+%5C%5C+%5Cend%7Baligned%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>这个公式只是对如此简单的一个网络结构的一个节点的偏导，就这么复杂。。亲自推完才深深的意识到。。。</p>
<p>为了后面描述方便，把上面的公式化简一下， <img src="https://www.zhihu.com/equation?tex=out_%7Bo1%7D+-+target_1" alt="[公式]"> 记为 <img src="https://www.zhihu.com/equation?tex=C_%7Bo1%7D" alt="[公式]"> ，
<img src="https://www.zhihu.com/equation?tex=%5Csigma%28net_%7Bo1%7D%29%281-%5Csigma%28net_%7Bo1%7D%29%29" alt="[公式]"> 记为 <img src="https://www.zhihu.com/equation?tex=%5Csigma%28net_%7Bo1%7D%29%5E%7B%5Cprime%7D" alt="[公式]"> ，则：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+Loss_%7Bt+o+t+a+l%7D%7D%7B%5Cpartial+w_1%7D+%3D+C_%7Bo1%7D+%5Ccdot+%5Csigma%28net_%7Bo1%7D%29%5E%7B%5Cprime%7D+%5Ccdot+w_5+%5Ccdot+%5Csigma%28net_%7Bh1%7D%29%5E%7B%5Cprime%7D+%5Ccdot+i_1+%2B+C_%7Bo2%7D+%5Ccdot+%5Csigma%28net_%7Bo2%7D%29%5E%7B%5Cprime%7D+%5Ccdot+w_7+%5Ccdot+%5Csigma%28net_%7Bh1%7D%29%5E%7B%5Cprime%7D+%5Ccdot+i_1%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h4><span id="12梯度消失爆炸产生原因">1.2
<strong>==梯度消失，爆炸产生原因：==</strong></span></h4>
<p>从上式其实已经能看出来，求和操作其实不影响，主要是是看乘法操作就可以说明问题，可以看出，损失函数对w1的偏导，与
<img src="https://www.zhihu.com/equation?tex=C_%7Bo1%7D" alt="[公式]">
，权重w，sigmoid的导数有关，明明还有输入i为什么不提？因为如果是多层神经网络的中间某层的某个节点，那么就没有输入什么事了。所以产生影响的就是刚刚提的三个因素。</p>
<p>再详细点描述，如图，多层神经网络：</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-0f2ded75fbecc449a25bfd58b8c58d35_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>参考：</strong><a href="https://zhuanlan.zhihu.com/p/25631496">PENG：神经网络训练中的梯度消失与梯度爆炸282
赞同 · 26 评论文章</a></p>
<p>假设（假设每一层只有一个神经元且对于每一层 <img src="https://www.zhihu.com/equation?tex=y_i%3D%5Csigma%5Cleft%28z_i%5Cright%29%3D%5Csigma%5Cleft%28w_ix_i%2Bb_i%5Cright%29" alt="[公式]">，其中<img src="https://www.zhihu.com/equation?tex=%5Csigma" alt="[公式]">为sigmoid函数），如图：</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-ea9beb6c28c7d4e89be89dc5f4cbae2e_1440w.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>则：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Barray%7D%7Bl%7D%7B%5Cfrac%7B%5Cpartial+C%7D%7B%5Cpartial+b_%7B1%7D%7D%3D%5Cfrac%7B%5Cpartial+C%7D%7B%5Cpartial+y_%7B4%7D%7D+%5Cfrac%7B%5Cpartial+y_%7B4%7D%7D%7B%5Cpartial+z_%7B4%7D%7D+%5Cfrac%7B%5Cpartial+z_%7B4%7D%7D%7B%5Cpartial+x_%7B4%7D%7D+%5Cfrac%7B%5Cpartial+x_%7B4%7D%7D%7B%5Cpartial+z_%7B3%7D%7D+%5Cfrac%7B%5Cpartial+z_%7B3%7D%7D%7B%5Cpartial+x_%7B3%7D%7D+%5Cfrac%7B%5Cpartial+x_%7B3%7D%7D%7B%5Cpartial+z_%7B2%7D%7D+%5Cfrac%7B%5Cpartial+z_%7B2%7D%7D%7B%5Cpartial+x_%7B2%7D%7D+%5Cfrac%7B%5Cpartial+x_%7B2%7D%7D%7B%5Cpartial+z_%7B1%7D%7D+%5Cfrac%7B%5Cpartial+z_%7B1%7D%7D%7B%5Cpartial+b_%7B1%7D%7D%7D+%5C%5C+%7B%3DC_%7By4%7D+%5Csigma%5E%7B%5Cprime%7D%5Cleft%28z_%7B4%7D%5Cright%29+w_%7B4%7D+%5Csigma%5E%7B%5Cprime%7D%5Cleft%28z_%7B3%7D%5Cright%29+w_%7B3%7D+%5Csigma%5E%7B%5Cprime%7D%5Cleft%28z_%7B2%7D%5Cright%29+w_%7B2%7D+%5Csigma%5E%7B%5Cprime%7D%5Cleft%28z_%7B1%7D%5Cright%29%7D%5Cend%7Barray%7D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>看一下sigmoid函数的求导之后的样子：</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-208a4aa5dc657fe86919f3549d853793_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>发现sigmoid函数求导后最大最大也只能是0.25。</strong></p>
<p>再来看W，一般我们初始化权重参数W时，通常都小于1，用的最多的应该是0，1正态分布吧。</p>
<p><font color="red"><strong>所以 <img src="https://www.zhihu.com/equation?tex=%7C%5Csigma%27%5Cleft%28z%5Cright%29w%7C%5Cleq0.25" alt="[公式]">
，多个小于1的数连乘之后，那将会越来越小，导致靠近输入层的层的权重的偏导几乎为0，也就是说几乎不更新，这就是梯度消失的根本原因。</strong></font></p>
<p>再来看看<strong>梯度爆炸</strong>的原因，也就是说如果 <img src="https://www.zhihu.com/equation?tex=%7C%5Csigma%27%5Cleft%28z%5Cright%29w%7C%5Cgeq1" alt="[公式]">
时，连乘下来就会导致梯度过大，导致梯度更新幅度特别大，可能会溢出，导致模型无法收敛。sigmoid的函数是不可能大于1了，上图看的很清楚，那只能是w了，这也就是经常看到别人博客里的一句话，初始权重过大，一直不理解为啥。。现在明白了。</p>
<p>但梯度爆炸的情况一般不会发生，对于sigmoid函数来说， <img src="https://www.zhihu.com/equation?tex=%5Csigma%28z%29%5E%7B%5Cprime%7D" alt="[公式]"> 的大小也与w有关，因为 <img src="https://www.zhihu.com/equation?tex=z%3Dwx%2Bb" alt="[公式]">
，除非该层的输入值<img src="https://www.zhihu.com/equation?tex=x" alt="[公式]">在一直一个比较小的范围内。</p>
<p>其实<strong>梯度爆炸和梯度消失问题都是因为网络太深</strong>，网络权值更新不稳定造成的，本质上是因为<strong>梯度反向传播中的连乘效应</strong>。</p>
<p>==<strong>所以，总结一下，为什么会发生梯度爆炸和消失：</strong>==</p>
<blockquote>
<p>本质上是因为神经网络的更新方法，梯度消失是因为反向传播过程中对梯度的求解会产生sigmoid导数和参数的连乘，sigmoid导数的最大值为0.25，权重一般初始都在0，1之间，乘积小于1，多层的话就会有多个小于1的值连乘，导致靠近输入层的梯度几乎为0，得不到更新。梯度爆炸是也是同样的原因，只是如果初始权重大于1，或者更大一些，多个大于1的值连乘，将会很大或溢出，导致梯度更新过大，模型无法收敛。</p>
</blockquote>
<h3><span id="13-梯度消失-爆炸解决方案">1.3 梯度消失、爆炸解决方案？</span></h3>
<blockquote>
<p><strong>参考：</strong><a href="https://zhuanlan.zhihu.com/p/33006526">DoubleV：详解深度学习中的梯度消失、爆炸原因及其解决方法</a></p>
<ul>
<li>预训练加微调</li>
<li>梯度剪切、正则</li>
</ul>
</blockquote>
<h4><span id="解决方案一预训练加微调"><strong>解决方案一（预训练加微调）：</strong></span></h4>
<p>提出采取无监督逐层训练方法，其基本思想是每次训练一层隐节点，训练时将上一层隐节点的输出作为输入，而本层隐节点的输出作为下一层隐节点的输入，此过程就是逐层“预训练”（pre-training）；在预训练完成后，再对整个网络进行“微调”（<strong>fine-tunning</strong>）。</p>
<p>Hinton在训练深度信念网络（Deep Belief
Networks中，使用了这个方法，在各层预训练完成后，再利用BP算法对整个网络进行训练。此思想相当于是先寻找局部最优，然后整合起来寻找全局最优，此方法有一定的好处，但是目前应用的不是很多了。</p>
<h4><span id="解决方案二梯度剪切-正则"><strong>解决方案二（梯度剪切、正则）：</strong></span></h4>
<p><strong>梯度剪切</strong>这个方案主要是针对梯度爆炸提出的，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。</p>
<p><strong>正则化</strong>是通过对网络权重做正则限制过拟合，仔细看正则项在损失函数的形式：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=Loss%3D%28y-W%5ETx%29%5E2%2B+%5Calpha+%7C%7CW%7C%7C%5E2%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中， <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]">
是指正则项系数，因此，如果发生梯度爆炸，权值的范数就会变的非常大，通过正则化项，可以部分限制梯度爆炸的发生。</p>
<p>注：事实上，在深度神经网络中，往往是梯度消失出现的更多一些</p>
<h4><span id="解决方案三改变激活函数"><strong><font color="red">
解决方案三（改变激活函数）：</font></strong></span></h4>
<p>首先说明一点，<strong>tanh激活函数不能有效的改善这个问题</strong>，先来看tanh的形式：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Ctanh+%28x%29%3D%5Cfrac%7Be%5E%7Bx%7D-e%5E%7B-x%7D%7D%7Be%5E%7Bx%7D%2Be%5E%7B-x%7D%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>再来看tanh的导数图像：</p>
<p><img src="https://pic4.zhimg.com/80/v2-66a7e4fcf11a2d85c15e7bf7b88b2d1b_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p><strong>发现虽然比sigmoid的好一点，sigmoid的最大值小于0.25，tanh的最大值小于1，但仍是小于1的，所以并不能解决这个问题。</strong></p>
<p><strong>Relu</strong>:思想也很简单，如果激活函数的导数为1，那么就不存在梯度消失爆炸的问题了，每层的网络都可以得到相同的更新速度，relu就这样应运而生。先看一下relu的数学表达式：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7BRe%7D+%5Coperatorname%7Blu%7D%28%5Cmathrm%7Bx%7D%29%3D%5Cmax+%28%5Cmathrm%7Bx%7D%2C+0%29%3D%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bl%7D%7B0%2C+x%3C0%7D+%5C%5C+%7Bx%2C+x%3E0%7D%5Cend%7Barray%7D%5Cright%5C%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><img src="https://pic2.zhimg.com/80/v2-55475ee2d90cd7257a39f62549a65769_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>从上图中，我们可以很容易看出，<strong>relu函数的导数在正数部分是恒等于1的，因此在深层网络中使用relu激活函数就不会导致梯度消失和爆炸的问题。</strong></p>
<p><strong>relu</strong>的主要贡献在于：</p>
<ul>
<li>解决了梯度消失、爆炸的问题</li>
<li>计算方便，计算速度快</li>
<li>加速了网络的训练</li>
</ul>
<p>同时也存在一些<strong>缺点</strong>：</p>
<ul>
<li><strong>由于负数部分恒为0，会导致一些神经元无法激活（可通过设置小学习率部分解决）</strong></li>
<li>输出不是以0为中心的</li>
</ul>
<p><strong>leakrelu</strong></p>
<p>leakrelu就是为了解决relu的0区间带来的影响，其数学表达为： <img src="https://www.zhihu.com/equation?tex=leakrelu%3D%5Cbegin%7Bequation%7D+f%28x%29%3D+%5Cbegin%7Bcases%7D+x%2C+%26+%7Bx%5Cgt+0%7D+%5C%5C%5C%5C+x%2Ak%2C+%26+%7Bx%5Cleq+0%7D+%5Cend%7Bcases%7D+%5Cend%7Bequation%7D" alt="[公式]">
其中k是leak系数，一般选择0.1或者0.2，或者通过学习而来解决死神经元的问题。</p>
<p><img src="https://pic4.zhimg.com/80/v2-3ab1bd8fb85542a0c85eb907b73fa327_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>leakrelu解决了0区间带来的影响，而且包含了relu的所有优点</p>
<p><strong>elu</strong></p>
<p>elu激活函数也是为了解决relu的0区间带来的影响，其数学表达为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bcc%7D%7Bx%2C%7D+%26+%7B%5Ctext+%7B+if+%7D+x%3E0%7D+%5C%5C+%7B%5Calpha%5Cleft%28e%5E%7Bx%7D-1%5Cright%29%2C%7D+%26+%7B%5Ctext+%7B+otherwise+%7D%7D%5Cend%7Barray%7D%5Cright.%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其函数及其导数数学形式为：</p>
<p><img src="https://pic3.zhimg.com/80/v2-ec3c80e51129bd76d49cad6e52d449c2_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>但是elu相对于leakrelu来说，计算要更耗时间一些，因为有e。</p>
<h4><span id="解决方案四batchnorm梯度消失"><strong>解决方案四（batchnorm）：</strong>【梯度消失】</span></h4>
<p><strong>Batchnorm</strong>是深度学习发展以来提出的最重要的成果之一了，目前已经被广泛的应用到了各大网络中，具有加速网络收敛速度，提升训练稳定性的效果，Batchnorm本质上是解决反向传播过程中的梯度问题。batchnorm全名是batch
normalization，简称BN，即批规范化，通过规范化操作将输出信号x规范化到均值为0，方差为1保证网络的稳定性。</p>
<p>具体的batchnorm原理非常复杂，在这里不做详细展开，此部分大概讲一下batchnorm解决梯度的问题上。具体来说就是反向传播中，经过每一层的梯度会乘以该层的权重，举个简单例子：
正向传播中<img src="https://www.zhihu.com/equation?tex=f_3%3Df_2%28w%5ET%2Ax%2Bb%29" alt="[公式]">，那么反向传播中，<img src="https://www.zhihu.com/equation?tex=%5Cfrac+%7B%5Cpartial+f_2%7D%7B%5Cpartial+x%7D%3D%5Cfrac%7B%5Cpartial+f_2%7D%7B%5Cpartial+f_1%7Dw" alt="[公式]">，反向传播式子中有w的存在，所以<img src="https://www.zhihu.com/equation?tex=w" alt="[公式]">的大小影响了梯度的消失和爆炸，batchnorm就是通过对每一层的输出做scale和shift的方法，通过一定的规范化手段，<strong>把每层神经网络任意神经元这个输入值的分布【假设原始是正态分布】强行拉回到接近均值为0方差为1的标准正太分布，即严重偏离的分布强制拉回比较标准的分布，<font color="red">
这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，使得让梯度变大，避免梯度消失问题产生</font>，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。</strong></p>
<h4><span id="解决方案五残差结构"><strong><font color="red">
解决方案五（残差结构）：</font></strong></span></h4>
<p><img src="https://pic4.zhimg.com/80/v2-3134d24348c47ca2001d37fef1c3f8bf_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>如图，把输入加入到某层中，这样求导时，总会有个1在，这样就不会梯度消失了。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%5Coperatorname%7Bloss%7D%7D%7B%5Cpartial+x_%7Bl%7D%7D%3D%5Cfrac%7B%5Cpartial+%5Coperatorname%7Bloss%7D%7D%7B%5Cpartial+x_%7BL%7D%7D+%5Ccdot+%5Cfrac%7B%5Cpartial+x_%7BL%7D%7D%7B%5Cpartial+x_%7Bl%7D%7D%3D%5Cfrac%7B%5Cpartial+%5Coperatorname%7Bloss%7D%7D%7B%5Cpartial+x_%7BL%7D%7D+%5Ccdot%5Cleft%281%2B%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+x_%7BL%7D%7D+%5Csum_%7Bi%3Dl%7D%5E%7BL-1%7D+F%5Cleft%28x_%7Bi%7D%2C+W_%7Bi%7D%5Cright%29%5Cright%29%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>式子的第一个因子 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+loss%7D%7B%5Cpartial+%7B%7Bx%7D_%7BL%7D%7D%7D" alt="[公式]"> 表示的损失函数到达 L
的梯度，小括号中的1表明短路机制可以无损地传播梯度，而另外一项残差梯度则需要经过带有weights的层，梯度不是直接传递过来的。残差梯度不会那么巧全为-1，而且就算其比较小，有1的存在也不会导致梯度消失。所以残差学习会更容易。</p>
<p><code>注：上面的推导并不是严格的证</code>，只为帮助理解</p>
<p>==<strong>解决方案六（LSTM）：</strong>==</p>
<p>在介绍这个方案之前，有必要来推导一下RNN的反向传播，<strong>因为关于梯度消失的含义它跟DNN不一样！不一样！不一样！</strong></p>
<p>先推导再来说，从这copy的：<a href="https://zhuanlan.zhihu.com/p/28687529">沉默中的思索：RNN梯度消失和爆炸的原因565
赞同</a></p>
<p>RNN结构如图：</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-ab844e07a86f910d2852198c3117ddb7_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>假设我们的时间序列只有三段， <img src="https://www.zhihu.com/equation?tex=S_%7B0%7D" alt="[公式]">
为给定值，神经元没有激活函数，则RNN最简单的前向传播过程如下： <img src="https://www.zhihu.com/equation?tex=S_%7B1%7D%3DW_%7Bx%7DX_%7B1%7D%2BW_%7Bs%7DS_%7B0%7D%2Bb_%7B1%7D" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=O_%7B1%7D%3DW_%7Bo%7DS_%7B1%7D%2Bb_%7B2%7D" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=S_%7B2%7D%3DW_%7Bx%7DX_%7B2%7D%2BW_%7Bs%7DS_%7B1%7D%2Bb_%7B1%7D" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=O_%7B2%7D%3DW_%7Bo%7DS_%7B2%7D%2Bb_%7B2%7D" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=S_%7B3%7D%3DW_%7Bx%7DX_%7B3%7D%2BW_%7Bs%7DS_%7B2%7D%2Bb_%7B1%7D" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=O_%7B3%7D%3DW_%7Bo%7DS_%7B3%7D%2Bb_%7B2%7D" alt="[公式]"></p>
<p>假设在t=3时刻，损失函数为 <img src="https://www.zhihu.com/equation?tex=L_%7B3%7D%3D%5Cfrac%7B1%7D%7B2%7D%28Y_%7B3%7D-O_%7B3%7D%29%5E%7B2%7D" alt="[公式]"> 。</p>
<p>则对于一次训练任务的损失函数为 <img src="https://www.zhihu.com/equation?tex=L%3D%5Csum_%7Bt%3D0%7D%5E%7BT%7D%7BL_%7Bt%7D%7D" alt="[公式]"> ，即每一时刻损失值的累加。</p>
<p>使用随机梯度下降法训练RNN其实就是对 <img src="https://www.zhihu.com/equation?tex=W_%7Bx%7D+" alt="[公式]"> 、
<img src="https://www.zhihu.com/equation?tex=W_%7Bs%7D" alt="[公式]">
、 <img src="https://www.zhihu.com/equation?tex=W_%7Bo%7D" alt="[公式]"> 以及 <img src="https://www.zhihu.com/equation?tex=b_%7B1%7D" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=b_%7B2%7D" alt="[公式]">
求偏导，并不断调整它们以使L尽可能达到最小的过程。</p>
<p>现在假设我们我们的时间序列只有三段，t1，t2，t3。</p>
<p><strong>我们只对t3时刻的 <img src="https://www.zhihu.com/equation?tex=W_%7Bx%7D%E3%80%81W_%7Bs%7D%E3%80%81W_%7B0%7D" alt="[公式]"> 求偏导（其他时刻类似）：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%7BL_%7B3%7D%7D%7D%7B%5Cpartial%7BW_%7B0%7D%7D%7D%3D%5Cfrac%7B%5Cpartial%7BL_%7B3%7D%7D%7D%7B%5Cpartial%7BO_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BO_%7B3%7D%7D%7D%7B%5Cpartial%7BW_%7Bo%7D%7D%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%7BL_%7B3%7D%7D%7D%7B%5Cpartial%7BW_%7Bx%7D%7D%7D%3D%5Cfrac%7B%5Cpartial%7BL_%7B3%7D%7D%7D%7B%5Cpartial%7BO_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BO_%7B3%7D%7D%7D%7B%5Cpartial%7BS_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B3%7D%7D%7D%7B%5Cpartial%7BW_%7Bx%7D%7D%7D%2B%5Cfrac%7B%5Cpartial%7BL_%7B3%7D%7D%7D%7B%5Cpartial%7BO_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BO_%7B3%7D%7D%7D%7B%5Cpartial%7BS_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B3%7D%7D%7D%7B%5Cpartial%7BS_%7B2%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B2%7D%7D%7D%7B%5Cpartial%7BW_%7Bx%7D%7D%7D%2B%5Cfrac%7B%5Cpartial%7BL_%7B3%7D%7D%7D%7B%5Cpartial%7BO_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BO_%7B3%7D%7D%7D%7B%5Cpartial%7BS_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B3%7D%7D%7D%7B%5Cpartial%7BS_%7B2%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B2%7D%7D%7D%7B%5Cpartial%7BS_%7B1%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B1%7D%7D%7D%7B%5Cpartial%7BW_%7Bx%7D%7D%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%7BL_%7B3%7D%7D%7D%7B%5Cpartial%7BW_%7Bs%7D%7D%7D%3D%5Cfrac%7B%5Cpartial%7BL_%7B3%7D%7D%7D%7B%5Cpartial%7BO_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BO_%7B3%7D%7D%7D%7B%5Cpartial%7BS_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B3%7D%7D%7D%7B%5Cpartial%7BW_%7Bs%7D%7D%7D%2B%5Cfrac%7B%5Cpartial%7BL_%7B3%7D%7D%7D%7B%5Cpartial%7BO_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BO_%7B3%7D%7D%7D%7B%5Cpartial%7BS_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B3%7D%7D%7D%7B%5Cpartial%7BS_%7B2%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B2%7D%7D%7D%7B%5Cpartial%7BW_%7Bs%7D%7D%7D%2B%5Cfrac%7B%5Cpartial%7BL_%7B3%7D%7D%7D%7B%5Cpartial%7BO_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BO_%7B3%7D%7D%7D%7B%5Cpartial%7BS_%7B3%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B3%7D%7D%7D%7B%5Cpartial%7BS_%7B2%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B2%7D%7D%7D%7B%5Cpartial%7BS_%7B1%7D%7D%7D%5Cfrac%7B%5Cpartial%7BS_%7B1%7D%7D%7D%7B%5Cpartial%7BW_%7Bs%7D%7D%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><strong>可以看出对于 <img src="https://www.zhihu.com/equation?tex=W_%7B0%7D" alt="[公式]">
求偏导并没有长期依赖，但是对于 <img src="https://www.zhihu.com/equation?tex=W_%7Bx%7D%E3%80%81W_%7Bs%7D" alt="[公式]"> 求偏导，会随着时间序列产生长期依赖</strong>。因为 <img src="https://www.zhihu.com/equation?tex=S_%7Bt%7D" alt="[公式]">
随着时间序列向前传播，而 <img src="https://www.zhihu.com/equation?tex=S_%7Bt%7D" alt="[公式]"> 又是
<img src="https://www.zhihu.com/equation?tex=W_%7Bx%7D%E3%80%81W_%7Bs%7D" alt="[公式]">的函数。</p>
<p>根据上述求偏导的过程，我们可以得出任意时刻对 <img src="https://www.zhihu.com/equation?tex=W_%7Bx%7D%E3%80%81W_%7Bs%7D" alt="[公式]"> 求偏导的公式：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%7BL_%7Bt%7D%7D%7D%7B%5Cpartial%7BW_%7Bx%7D%7D%7D%3D%5Csum_%7Bk%3D0%7D%5E%7Bt%7D%7B%5Cfrac%7B%5Cpartial%7BL_%7Bt%7D%7D%7D%7B%5Cpartial%7BO_%7Bt%7D%7D%7D%5Cfrac%7B%5Cpartial%7BO_%7Bt%7D%7D%7D%7B%5Cpartial%7BS_%7Bt%7D%7D%7D%7D%28%5Cprod_%7Bj%3Dk%2B1%7D%5E%7Bt%7D%7B%5Cfrac%7B%5Cpartial%7BS_%7Bj%7D%7D%7D%7B%5Cpartial%7BS_%7Bj-1%7D%7D%7D%7D%29%5Cfrac%7B%5Cpartial%7BS_%7Bk%7D%7D%7D%7B%5Cpartial%7BW_%7Bx%7D%7D%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>任意时刻对<img src="https://www.zhihu.com/equation?tex=W_%7Bs%7D" alt="[公式]"> 求偏导的公式同上。</p>
<p><font color="red"> 如果加上激活函数， <img src="https://www.zhihu.com/equation?tex=S_%7Bj%7D%3Dtanh%28W_%7Bx%7DX_%7Bj%7D%2BW_%7Bs%7DS_%7Bj-1%7D%2Bb_%7B1%7D%29" alt="[公式]"> ，则 <img src="https://www.zhihu.com/equation?tex=%5Cprod_%7Bj%3Dk%2B1%7D%5E%7Bt%7D%7B%5Cfrac%7B%5Cpartial%7BS_%7Bj%7D%7D%7D%7B%5Cpartial%7BS_%7Bj-1%7D%7D%7D%7D" alt="[公式]"> = <img src="https://www.zhihu.com/equation?tex=%5Cprod_%7Bj%3Dk%2B1%7D%5E%7Bt%7D%7Btanh%5E%7B%27%7D%7DW_%7Bs%7D" alt="[公式]">激活函数tanh和它的导数图像在上面已经说过了，所以原因在这就不赘述了，还是一样的，激活函数导数小于1。</font></p>
<blockquote>
<p>==<strong>现在来解释一下，为什么说RNN和DNN的梯度消失问题含义不一样？</strong>==</p>
<ol type="1">
<li><strong>先来说DNN中的反向传播：</strong>在上文的DNN反向传播中，我推导了两个权重的梯度，第一个梯度是直接连接着输出层的梯度，求解起来并没有梯度消失或爆炸的问题，因为它没有连乘，只需要计算一步。第二个梯度出现了连乘，也就是说越靠近输入层的权重，梯度消失或爆炸的问题越严重，可能就会消失会爆炸。<strong>一句话总结一下，DNN中各个权重的梯度是独立的，该消失的就会消失，不会消失的就不会消失。</strong></li>
<li><strong>再来说RNN：</strong>RNN的特殊性在于，它的权重是共享的。抛开W_o不谈，因为它在某时刻的梯度不会出现问题（某时刻并不依赖于前面的时刻），但是W_s和W_x就不一样了，每一时刻都由前面所有时刻共同决定，是一个相加的过程，这样的话就有个问题，当距离长了，计算最前面的导数时，最前面的导数就会消失或爆炸，但当前时刻整体的梯度并不会消失，因为它是求和的过程，当下的梯度总会在，只是前面的梯度没了，但是更新时，由于权值共享，所以整体的梯度还是会更新，<strong>通常人们所说的梯度消失就是指的这个，指的是当下梯度更新时，用不到前面的信息了，因为距离长了，前面的梯度就会消失，也就是没有前面的信息了，但要知道，整体的梯度并不会消失，因为当下的梯度还在，并没有消失。</strong></li>
<li><strong>一句话概括：</strong>RNN的梯度不会消失，RNN的梯度消失指的是当下梯度用不到前面的梯度了，但DNN靠近输入的权重的梯度是真的会消失。</li>
</ol>
</blockquote>
<p>说完了RNN的反向传播及梯度消失的含义，终于该说<strong>为什么LSTM可以解决这个问题了</strong>，这里默认大家都懂LSTM的结构，对结构不做过多的描述。<strong>见第三节</strong>。【LSTM通过它的“门控装置”有效的缓解了这个问题，这也就是为什么我们现在都在使用LSTM而非普通RNN。】</p>
<h3><span id="二-lstm-框架结构">二、LSTM 框架结构</span></h3>
<h4><span id="前言">前言：</span></h4>
<blockquote>
<p>LSTM是RNN的一种变体，更高级的RNN，那么它的本质还是一样的，还记得RNN的特点吗，<strong>可以有效的处理序列数据，</strong>当然LSTM也可以，还记得RNN是如何处理有效数据的吗，是不是<strong>每个时刻都会把隐藏层的值存下来，到下一时刻的时候再拿出来用，这样就保证了，每一时刻含有上一时刻的信息</strong>，如图，我们把存每一时刻信息的地方叫做Memory
Cell，中文就是记忆细胞，可以这么理解。</p>
<p><img src="https://pic3.zhimg.com/80/v2-a5590a65bf7a93bbaafc1a6b03cf3862_1440w.png" alt="img" style="zoom:50%;"></p>
<p><strong>RNN什么信息它都存下来，因为它没有挑选的能力，而LSTM不一样，它会选择性的存储信息，因为它能力强，它有门控装置，它可以尽情的选择。</strong>如下图，普通RNN只有中间的Memory
Cell用来存所有的信息，而从下图我们可以看到，<strong>LSTM多了三个Gate</strong>。</p>
<p><img src="https://pic4.zhimg.com/80/v2-5602237fa98e90614cea748aa6a8b6d3_1440w.jpg" alt="img" style="zoom:50%;"></p>
<ul>
<li><strong>Input
Gate</strong>：输入门，在每一时刻从输入层输入的信息会首先经过输入门，输入门的开关会决定这一时刻是否会有信息输入到Memory
Cell。</li>
<li><strong>Output Gate</strong>：输出门，每一时刻是否有信息从Memory
Cell输出取决于这一道门。</li>
<li><strong>Forget Gate</strong>：遗忘门，每一时刻Memory
Cell里的值都会经历一个是否被遗忘的过程，就是由该门控制的，如果打卡，那么将会把Memory
Cell里的值清除，也就是遗忘掉。</li>
</ul>
<p>在了解LSTM的内部结构之前，我们需要先回顾一下普通RNN的结构，以免在这里很多读者被搞懵，如下：</p>
<p><img src="https://pic1.zhimg.com/80/v2-acee3e085ee62fe162bcac5cd135b54c_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>我们可以看到，左边是为了简便描述RNN的工作原理而画的缩略图，右边是展开之后，每个时间点之间的流程图，<strong>注意，我们接下来看到的LSTM的结构图，是一个时间点上的内部结构，就是整个工作流程中的其中一个时间点，也就是如下图：</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-ccf7b5baee04f3f24bd04637df9bcd3a_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>注意，<strong>上图是普通RNN的一个时间点的内部结构</strong>，上面已经讲过了公式和原理，<strong>LSTM的内部结构更为复杂，不过如果这么类比来学习，我认为也没有那么难</strong>。</p>
<p><img src="https://pic2.zhimg.com/80/v2-1428c54d3ae79cf12616e7051c07799d_1440w.jpg" alt="img" style="zoom:50%;"></p>
<ul>
<li>Cell：memory cell，也就是一个记忆存储的地方，这里就类似于普通RNN的
<img src="https://www.zhihu.com/equation?tex=S_t" alt="[公式]">
，都是用来存储信息的，这里面的信息都会保存到下一时刻，其实标准的叫法应该是
<img src="https://www.zhihu.com/equation?tex=h_t" alt="[公式]">
，因为这里对应神经网络里的隐藏层，所以是hidden的缩写，无论普通RNN还是LSTM其实t时刻的记忆细胞里存的信息，都应该被称为
<img src="https://www.zhihu.com/equation?tex=h_t" alt="[公式]"></li>
<li><img src="https://www.zhihu.com/equation?tex=a" alt="[公式]">
是这一时刻的输出，也就是类似于普通RNN里的 <img src="https://www.zhihu.com/equation?tex=O_t" alt="[公式]"></li>
<li>四个 <img src="https://www.zhihu.com/equation?tex=Z%EF%BC%8CZ_i%EF%BC%8CZ_f%EF%BC%8CZ_o" alt="[公式]"> ，这四个相辅相成，才造就了中间的Memory
Cell里的值，你肯恩要问普通RNN里有个 <img src="https://www.zhihu.com/equation?tex=X_t+" alt="[公式]">
作为输入，那LSTM的输入在哪？别着急，其实这四个 <img src="https://www.zhihu.com/equation?tex=Z%EF%BC%8CZ_i%EF%BC%8CZ_f%EF%BC%8CZ_o" alt="[公式]"> 都有输入向量 <img src="https://www.zhihu.com/equation?tex=X_t" alt="[公式]">
的参与。对了，在解释这四个分别是什么之前，我要先解释一下上图的所有这个符号：<img src="https://pic4.zhimg.com/80/v2-b74b5413f6897f2890b3ede634f60efb_1440w.png" alt="img" style="zoom:50%;">都代表一个激活函数，<strong>LSTM里常用的激活函数有两个，一个是tanh，一个是sigmoid</strong>。</li>
<li><figure>
<img src="https://www.zhihu.com/equation?tex=Z%3Dtanh%28W%5Bx_t%2Ch_%7Bt-1%7D%5D%29%5C%5CZ_i%3D%5Csigma%28W_i%5Bx_t%2Ch_%7Bt-1%7D%5D%29%5C%5CZ_f%3D%5Csigma%28W_f%5Bx_t%2Ch_%7Bt-1%7D%5D%29%5C%5CZ_o%3D%5Csigma%28W_o%5Bx_t%2Ch_%7Bt-1%7D%5D%29%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure></li>
<li><img src="https://www.zhihu.com/equation?tex=Z" alt="[公式]">
<strong>是最为普通的输入</strong>，可以从上图中看到， <img src="https://www.zhihu.com/equation?tex=Z" alt="[公式]">
是通过该时刻的输入 <img src="https://www.zhihu.com/equation?tex=X_t" alt="[公式]"> 和上一时刻存在memory cell里的隐藏层信息 <img src="https://www.zhihu.com/equation?tex=h_%7Bt-1%7D" alt="[公式]">
向量拼接，再与权重参数向量 <img src="https://www.zhihu.com/equation?tex=W" alt="[公式]">
点积，得到的值经过激活函数tanh最终会得到一个数值。</li>
<li><img src="https://www.zhihu.com/equation?tex=Z_i" alt="[公式]">
<strong>input gate的缩写i，所以也就是输入门的门控装置</strong>， <img src="https://www.zhihu.com/equation?tex=Z_i+" alt="[公式]">
同样也是通过该时刻的输入 <img src="https://www.zhihu.com/equation?tex=X_t" alt="[公式]">
和上一时刻隐藏状态，也就是上一时刻存下来的信息 <img src="https://www.zhihu.com/equation?tex=h_%7Bt-1%7D" alt="[公式]">
向量拼接，在与权重参数向量 <img src="https://www.zhihu.com/equation?tex=W_i" alt="[公式]">
点积（注意每个门的权重向量都不一样，这里的下标i代表input的意思，也就是输入门)。得到的值经过激活函数sigmoid的最终会得到一个0-1之间的一个数值，用来作为<strong>输入门的控制信号</strong>。</li>
<li>以此类推，就不详细讲解 <img src="https://www.zhihu.com/equation?tex=Z_f%EF%BC%8CZ_o" alt="[公式]">
了，分别是缩写forget和output的门控装置，原理与上述输入门的门控装置类似。上面说了，只有
<img src="https://www.zhihu.com/equation?tex=Z" alt="[公式]">
是输入，其他的三个都是门控装置，负责把控每一阶段的信息记录与遗忘，具体是怎样的呢？我们先来看公式：<strong>首先解释一下，经过这个sigmod激活函数后，得到的
<img src="https://www.zhihu.com/equation?tex=Z_i%EF%BC%8CZ_f%EF%BC%8CZ_o" alt="[公式]">
都是在0到1之间的数值，1表示该门完全打开，0表示该门完全关闭</strong>，</li>
</ul>
</blockquote>
<h4><span id="lstm迭代过程">==LSTM迭代过程==</span></h4>
<blockquote>
<p>LSTM和GRU算法简单梳理🍭: https://zhuanlan.zhihu.com/p/72500407</p>
</blockquote>
<p><img src="https://pic3.zhimg.com/80/v2-10f9ec56794c9f89ca2b6ce86c7693ee_1440w.jpg?source=d16d100b" alt="img" style="zoom: 33%;"></p>
<p><img src="https://pic2.zhimg.com/80/v2-867b66c85751aa3bfeeb4956054e0eb8_1440w.jpg?source=d16d100b" alt="img" style="zoom:67%;"></p>
<p><img src="https://www.zhihu.com/equation?tex=h_%7Bt%7D" alt="[公式]"> ：当前序列的隐藏状态、 <img src="https://www.zhihu.com/equation?tex=x_%7Bt%7D" alt="[公式]">
：当前序列的输入数据、 <img src="https://www.zhihu.com/equation?tex=C_%7Bt%7D" alt="[公式]">
：当前序列的细胞状态、 <img src="https://www.zhihu.com/equation?tex=%5Csigma" alt="[公式]"> ：
<img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]">
激活函数、 <img src="https://www.zhihu.com/equation?tex=%5Ctanh" alt="[公式]"> ： <img src="https://www.zhihu.com/equation?tex=+%5Ctanh" alt="[公式]">
激活函数。</p>
<p><strong>遗忘门：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D++f_%7Bt%7D%3D%5Csigma%5Cleft%28W_%7Bf%7D+%5Ccdot%5Cleft%5Bh_%7Bt-1%7D%2C+x_%7Bt%7D%5Cright%5D%2Bb_%7Bf%7D%5Cright%29++%5Cend%7Bequation%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><strong>输入门：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Cbegin%7Baligned%7D+i_%7Bt%7D+%26%3D%5Csigma%5Cleft%28W_%7Bi%7D+%5Ccdot%5Cleft%5Bh_%7Bt-1%7D%2C+x_%7Bt%7D%5Cright%5D%2Bb_%7Bi%7D%5Cright%29+%5C%5C+%5Ctilde%7BC%7D_%7Bt%7D+%26%3D%5Ctanh+%5Cleft%28W_%7BC%7D+%5Ccdot%5Cleft%5Bh_%7Bt-1%7D%2C+x_%7Bt%7D%5Cright%5D%2Bb_%7BC%7D%5Cright%29+%5Cend%7Baligned%7D+%5Cend%7Bequation%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><strong>细胞状态更新：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=C_%7Bt%7D%3DC_%7Bt-1%7D%5Codot+f_t%2Bi_t%5Codot+%5Ctilde%7BC_t%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><strong>输出门：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Cbegin%7Baligned%7D++o_t%26%3D%5Csigma%7B%28W_o%5Ccdot%5Bh_%7Bt-1%7D%2Cx_t%5D%2Bb_o%29%7D%5C%5C+h_t%26%3Do_t%5Codot+%5Ctanh%7B%28C_t%29%7D+%5Cend%7Baligned%7D+%5Cend%7Bequation%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h4><span id="21-lstm之遗忘门">2.1 LSTM之遗忘门</span></h4>
<p><img src="https://pic3.zhimg.com/80/v2-e616cbe445d60aee532ef3d9db0fb8f6_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p><strong>遗忘门是控制是否遗忘的</strong>，在 <img src="https://www.zhihu.com/equation?tex=LSTM" alt="[公式]">
中即以一定的概率控制是否遗忘上一层的细胞状态。图中输入的有前一序列的隐藏状态
<img src="https://www.zhihu.com/equation?tex=h_%7Bt-1%7D" alt="[公式]"> 和当前序列的输入数据 <img src="https://www.zhihu.com/equation?tex=x_t" alt="[公式]"> ，通过一个
<img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]">
激活函数得到遗忘门的输出 <img src="https://www.zhihu.com/equation?tex=f_t" alt="[公式]"> 。因为 <img src="https://www.zhihu.com/equation?tex=+sigmoid" alt="[公式]">
函数的取值在 <img src="https://www.zhihu.com/equation?tex=%5B0%2C+1%5D" alt="[公式]"> 之间，所以 <img src="https://www.zhihu.com/equation?tex=f_t" alt="[公式]">
表示的是遗忘前一序列细胞状态的概率，数学表达式为</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D++f_%7Bt%7D%3D%5Csigma%5Cleft%28W_%7Bf%7D+%5Ccdot%5Cleft%5Bh_%7Bt-1%7D%2C+x_%7Bt%7D%5Cright%5D%2Bb_%7Bf%7D%5Cright%29++%5Cend%7Bequation%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h4><span id="22-lstm之输入门">2.2 LSTM之输入门</span></h4>
<p><img src="https://pic2.zhimg.com/80/v2-1dbddd39ff6a039631b8ff1e4bc294a5_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p><strong>输入门是用来决定哪些数据是需要更新的</strong>，由 <img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]">
层决定；然后，一个 <img src="https://www.zhihu.com/equation?tex=%5Ctanh" alt="[公式]"> 层为新的候选值创建一个向量 <img src="https://www.zhihu.com/equation?tex=+%5Ctilde%7BC_t%7D" alt="[公式]"> ，这些值能够加入到当前细胞状态中，数学表达式为</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Cbegin%7Baligned%7D+i_%7Bt%7D+%26%3D%5Csigma%5Cleft%28W_%7Bi%7D+%5Ccdot%5Cleft%5Bh_%7Bt-1%7D%2C+x_%7Bt%7D%5Cright%5D%2Bb_%7Bi%7D%5Cright%29+%5C%5C+%5Ctilde%7BC%7D_%7Bt%7D+%26%3D%5Ctanh+%5Cleft%28W_%7BC%7D+%5Ccdot%5Cleft%5Bh_%7Bt-1%7D%2C+x_%7Bt%7D%5Cright%5D%2Bb_%7BC%7D%5Cright%29+%5Cend%7Baligned%7D+%5Cend%7Bequation%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h4><span id="23-lstm之细胞状态更新">2.3 LSTM之细胞状态更新</span></h4>
<p><img src="https://pic4.zhimg.com/80/v2-82f48ff07dd75ee4346ab44c573fe0b7_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p><strong>前面的遗忘门和输入门的结果都会作用于细胞状态</strong> <img src="https://www.zhihu.com/equation?tex=C_t" alt="[公式]">
，<strong>在决定需要遗忘和需要加入的记忆之后，就可以更新前一序列的细胞状态
<img src="https://www.zhihu.com/equation?tex=+C_%7Bt-1%7D" alt="[公式]"> 到当前细胞状态 <img src="https://www.zhihu.com/equation?tex=C_t" alt="[公式]">
了</strong>，前一序列的细胞状态 <img src="https://www.zhihu.com/equation?tex=C_%7Bt-1%7D" alt="[公式]">
乘以遗忘门的输出 <img src="https://www.zhihu.com/equation?tex=f_t" alt="[公式]"> 表示决定遗忘的信息， <img src="https://www.zhihu.com/equation?tex=+i_t%5Codot+%5Ctilde%7BC_t%7D" alt="[公式]"> 表示新的记忆信息，数学表达式为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=C_%7Bt%7D%3DC_%7Bt-1%7D%5Codot+f_t%2Bi_t%5Codot+%5Ctilde%7BC_t%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h4><span id="24-lstm之输出门">2.4 LSTM之输出门</span></h4>
<p><img src="https://pic3.zhimg.com/80/v2-6335c8e72a056eeb80970c88988f6bd2_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p><strong>在得到当前序列的细胞状态 <img src="https://www.zhihu.com/equation?tex=C_t" alt="[公式]">
后，就可以计算当前序列的输出隐藏状态 <img src="https://www.zhihu.com/equation?tex=h_t" alt="[公式]"></strong>
了，隐藏状态 <img src="https://www.zhihu.com/equation?tex=h_t" alt="[公式]"> 的更新由两部分组成，第一部分是 <img src="https://www.zhihu.com/equation?tex=o_t" alt="[公式]">
，它由前一序列的隐藏状态 <img src="https://www.zhihu.com/equation?tex=h_%7Bt-1%7D" alt="[公式]">
和当前序列的输入数据 <img src="https://www.zhihu.com/equation?tex=x_t" alt="[公式]"> 通过激活函数 <img src="https://www.zhihu.com/equation?tex=sigmoid" alt="[公式]">
得到，第二部分由当前序列的细胞状态 <img src="https://www.zhihu.com/equation?tex=C_t" alt="[公式]"> 经过 <img src="https://www.zhihu.com/equation?tex=%5Ctanh" alt="[公式]">
激活函数后的结果组成，数学表达式为</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Cbegin%7Baligned%7D++o_t%26%3D%5Csigma%7B%28W_o%5Ccdot%5Bh_%7Bt-1%7D%2Cx_t%5D%2Bb_o%29%7D%5C%5C+h_t%26%3Do_t%5Codot+%5Ctanh%7B%28C_t%29%7D+%5Cend%7Baligned%7D+%5Cend%7Bequation%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h3><span id="三-gru-框架结构">三、GRU 框架结构</span></h3>
<p><img src="https://pic3.zhimg.com/80/v2-7547e5c91e1590bf67e0641e9e29ec66_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p><strong>循环门单元( <img src="https://www.zhihu.com/equation?tex=Gated%5C+Recurrent%5C+Unit%2C%5C+GRU" alt="[公式]">
)，它组合了遗忘门和输入门到一个单独的更新门当中，也合并了细胞状态 <img src="https://www.zhihu.com/equation?tex=C" alt="[公式]">
和隐藏状态</strong> <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]">，并且还做了一些其他的改变使得其模型比标准 <img src="https://www.zhihu.com/equation?tex=LSTM" alt="[公式]">
模型更简单，其数学表达式式为： <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Cbegin%7Baligned%7D+z_%7Bt%7D+%26%3D%5Csigma%5Cleft%28W_%7Bz%7D+%5Ccdot%5Cleft%5Bh_%7Bt-1%7D%2C+x_%7Bt%7D%5Cright%5D%5Cright%29+%5C%5C+r_%7Bt%7D+%26%3D%5Csigma%5Cleft%28W_%7Br%7D+%5Ccdot%5Cleft%5Bh_%7Bt-1%7D%2C+x_%7Bt%7D%5Cright%5D%5Cright%29+%5C%5C+%5Ctilde%7Bh%7D_%7Bt%7D+%26%3D%5Ctanh+%5Cleft%28W+%5Ccdot%5Cleft%5Br_%7Bt%7D+%5Codot+h_%7Bt-1%7D%2C+x_%7Bt%7D%5Cright%5D%5Cright%29+%5C%5C+h_%7Bt%7D+%26%3D%5Cleft%281-z_%7Bt%7D%5Cright%29+%5Codot+h_%7Bt-1%7D%2Bz_%7Bt%7D+%5Codot+%5Ctilde%7Bh%7D_%7Bt%7D+%5Cend%7Baligned%7D+%5Cend%7Bequation%7D%5C%5C+" alt="[公式]"></p>
<p>首先介绍 <img src="https://www.zhihu.com/equation?tex=GRU" alt="[公式]"> 的两个门，它们分别是重置门 <img src="https://www.zhihu.com/equation?tex=r_t" alt="[公式]"> 和更新门
<img src="https://www.zhihu.com/equation?tex=z_t" alt="[公式]">
，计算方法与 <img src="https://www.zhihu.com/equation?tex=LSTM" alt="[公式]"> 中门的计算方法是一致的；然后是计算候选隐藏层 <img src="https://www.zhihu.com/equation?tex=%5Ctilde%7Bh%7D_t" alt="[公式]"> ，该候选隐藏层和 <img src="https://www.zhihu.com/equation?tex=LSTM" alt="[公式]"> 中的 <img src="https://www.zhihu.com/equation?tex=%5Ctilde%7BC%7D_t" alt="[公式]"> 类似，都可以看成是当前时刻的新信息，<strong>其中 <img src="https://www.zhihu.com/equation?tex=r_t" alt="[公式]">
用来控制需要保留多少之前的记忆，如果 <img src="https://www.zhihu.com/equation?tex=r_t" alt="[公式]"> 为 <img src="https://www.zhihu.com/equation?tex=0" alt="[公式]"> 则表示 <img src="https://www.zhihu.com/equation?tex=%5Ctilde%7Bh%7D_t" alt="[公式]"> 只保留当前序列的输入信息；最后 <img src="https://www.zhihu.com/equation?tex=+z_t" alt="[公式]">
控制需要从前一序列的隐藏层 <img src="https://www.zhihu.com/equation?tex=h_%7Bt-1%7D" alt="[公式]">
中遗忘多少信息和需要加入多少当前序列的隐藏层信息</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctilde%7Bh%7D_t" alt="[公式]"> ，从而得到当前序列的输出隐藏层信息 <img src="https://www.zhihu.com/equation?tex=h_t" alt="[公式]"> ，而 <img src="https://www.zhihu.com/equation?tex=GRU" alt="[公式]">
是没有输出门的。</p>
<p>GRU和LSTM的性能差不多，但GRU参数更少，更简单，所以训练效率更高。但是，如果数据的依赖特别长且数据量很大的话，LSTM的效果可能会稍微好一点，毕竟参数量更多。所以默认推荐使用LSTM。</p>
<h4><span id="参考资料️">参考资料⬇️</span></h4>
<p><a href="https://link.zhihu.com/?target=http%3A//colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding
LSTM Networks</a></p>
<h2><span id="lstm-qampa">LSTM Q&amp;A</span></h2>
<h3><span id="1-为什么lstm可以解决梯度消失和梯度爆炸">1、为什么LSTM可以解决梯度消失和梯度爆炸？</span></h3>
<p><img src="https://pic3.zhimg.com/80/v2-10f9ec56794c9f89ca2b6ce86c7693ee_1440w.jpg?source=d16d100b" alt="img" style="zoom: 33%;"></p>
<p><strong>参考（这个老哥说的是最好的）：</strong><a href="https://www.zhihu.com/question/34878706">LSTM如何来避免梯度弥散和梯度爆炸？</a></p>
<ul>
<li>==<strong>LSTM 中梯度的传播有很多条路径</strong>，<img src="https://www.zhihu.com/equation?tex=c_%7Bt-1%7D+%5Crightarrow+c_t+%3D+f_t%5Codot+c_%7Bt-1%7D+%2B+i_t+%5Codot+%5Chat%7Bc_t%7D" alt="[公式]">
这条路径上只有逐元素相乘和相加的操作，梯度流最稳定==；但是其他路径（例如
<img src="https://www.zhihu.com/equation?tex=c_%7Bt-1%7D+%5Crightarrow+h_%7Bt-1%7D+%5Crightarrow+i_t+%5Crightarrow+c_t" alt="[公式]"> )上梯度流与普通 RNN
类似，照样会发生相同的权重矩阵反复连乘。</li>
<li><strong>LSTM 刚提出时没有遗忘门</strong>，或者说相当于 <img src="https://www.zhihu.com/equation?tex=f_t%3D1" alt="[公式]">
，这时候在 <img src="https://www.zhihu.com/equation?tex=c_%7Bt-1%7D+%5Crightarrow+c_t" alt="[公式]"> 直接相连的短路路径上，<img src="https://www.zhihu.com/equation?tex=dl%2Fdc_t" alt="[公式]">
可以无损地传递给 <img src="https://www.zhihu.com/equation?tex=dl%2Fdc_%7Bt-1%7D" alt="[公式]">
，从而<strong>这条路径</strong>上的梯度畅通无阻，不会消失。类似于 ResNet
中的残差连接。</li>
<li>但是在<strong>其他路径</strong>上，LSTM 的梯度流和普通 RNN
没有太大区别，依然会爆炸或者消失。由于总的远距离梯度 =
各条路径的远距离梯度之和，即便其他远距离路径梯度消失了，只要保证有一条远距离路径（就是上面说的那条高速公路）梯度不消失，总的远距离梯度就不会消失（正常梯度
+ 消失梯度 = 正常梯度）。因此 LSTM
通过改善<strong>一条路径</strong>上的梯度问题拯救了<strong>总体的远距离梯度</strong>。</li>
<li>同样，因为总的远距离梯度 =
各条路径的远距离梯度之和，高速公路上梯度流比较稳定，但其他路径上梯度有可能爆炸，此时总的远距离梯度
= 正常梯度 + 爆炸梯度 = 爆炸梯度，因此 <strong>LSTM
仍然有可能发生梯度爆炸</strong>。不过，<strong>==由于 LSTM
的其他路径非常崎岖，和普通 RNN 相比多经过了很多次激活函数（导数都小于
1），因此 LSTM
发生梯度爆炸的频率要低得多==</strong>。实践中梯度爆炸一般通过梯度裁剪来解决。</li>
<li>对于现在常用的带遗忘门的 LSTM 来说，4 中的分析依然成立，而 3
分为两种情况：其一是遗忘门接近 1（例如模型初始化时会把 forget bias
设置成较大的正数，让遗忘门饱和），这时候远距离梯度不消失；其二是<strong>遗忘门接近
0，但这时模型是故意阻断梯度流的，这不是 bug 而是
feature</strong>（例如情感分析任务中有一条样本 “A，但是
B”，模型读到“但是”后选择把遗忘门设置成 0，遗忘掉内容
A，这是合理的）。当然，常常也存在 f 介于 [0, 1]
之间的情况，在这种情况下只能说 LSTM
改善（而非解决）了梯度消失的状况。</li>
</ul>
<h3><span id="2-为什么lstm模型中既存在sigmoid又存在tanh两种激活函数">2、为什么LSTM模型中既存在sigmoid又存在tanh两种激活函数？</span></h3>
<p>关于激活函数的选取，在LSTM中，遗忘门、输入门和输出门使用
Sigmoid函数作为激活函数;在<strong>生成候选记忆</strong>时，使用双曲正切函数<strong>tanh</strong>作为激活函数。值得注意的是，这两个激活函数都是<strong>饱和</strong>的也就是说在<strong>输入达到一定值的情况下，输出就不会发生明显变化</strong>了。如果是用非饱和的激活图数，例如ReLU，那么将<strong>难以实现门控的效果。</strong></p>
<ul>
<li><p>Sigmoid的输出在0-1之同，符合门控的物理定义，且当输入较大或较小时，其输出会非常接近1或0，从而保证该门开或关，在生成候选记亿时，</p></li>
<li><p><strong>tanh函数，是因为其输出在-1-1之间，这与大多数场景下特征分布是0中心的吻合</strong>。此外，<strong>tanh函数在输入为0近相比
Sigmoid函数有更大的梯度，通常使模型收敛更快。</strong></p></li>
</ul>
<p>激活函数的选择也不是一成不变的。<strong>例如在原始的LSTM中，使用的激活函数是
Sigmoid函数的变种，h(x)=2sigmoid(x)-1,g(x)＝4
sigmoid(x)-2，这两个函数的范国分别是[-1，1]和[-2，2]</strong>。并且在原始的LSTM中，只有输入门和输出门，没有遗忘门，其中输入经过输入门后是直接与记忆相加的，所以输入门控g(x)的值是0中心的。</p>
<p><strong>后来经过大量的研究和实验，人们发现增加遗忘门对LSTM的性能有很大的提升</strong>且<strong>h(x)使用tanh比2
sigmoid(x)-1要好</strong>，所以现代的LSTM采用
Sigmoid和tanh作为激活函数。<strong>事实上在门控中，使用
Sigmoid函数是几乎所有现代神经网络模块的共同选择</strong>。例如在<strong>门控循环单元和注意力机制</strong>中，也广泛使用
Sigmoid i函数作为门控的激活函数。</p>
<h4><span id="为什么">为什么？</span></h4>
<ol type="1">
<li>门是控制开闭的，全开时值为1，全闭值为０。用于遗忘和保留信息。</li>
<li>对于求值的激活函数无特殊要求。</li>
</ol>
<h4><span id="能更换吗">能更换吗？</span></h4>
<ol type="1">
<li>门是控制开闭的，全开时值为1，全闭值为０。用于遗忘和保留信息。门的激活函数只能是值域为０到１的，最常见的就是sigmoid。</li>
<li>对于求值的激活函数无特殊要求。</li>
</ol>
<h3><span id="3-能不能把tanh换成relu">3、能不能把tanh换成relu？</span></h3>
<p><strong>不行</strong>？对于梯度爆炸的问题用梯度裁剪解决就行了。</p>
<ol type="1">
<li><strong>会造成输出值爆炸</strong>。RNN共享参数矩阵，长程的话相当于多个相乘，最后输出类似于
<img src="https://www.zhihu.com/equation?tex=f%5Cleft%5BW+%5Cldots%5Cleft%5BW+f%5Cleft%5BW+f%5Cleft%5BW+f_%7Bi%7D%5Cright%5D%5Cright%5D%5Cright%5D%5Cright%5D" alt="[公式]"> ，其中是 <img src="https://www.zhihu.com/equation?tex=f" alt="[公式]"> 激活函数，如果 <img src="https://www.zhihu.com/equation?tex=W" alt="[公式]">
有一个大于1的特征值，且使用relu激活函数，那最后的输出值会爆炸。但是使用tanh激活函数，能够把输出值限制在-1和1之间。</li>
<li><strong>这里relu并不能解决梯度消失或梯度爆炸的问题</strong>。假设有t=3，最后一项输出反向传播对W求导，
<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f_%7B3%7D%7D%7B%5Cpartial+W_%7B1%7D%7D%3D%5Cfrac%7B%5Cpartial+f_%7B3%7D%7D%7B%5Cpartial+a_%7B3%7D%7D+f_%7B2%7D%2B%5Cfrac%7B%5Cpartial+f_%7B3%7D%7D%7B%5Cpartial+a_%7B3%7D%7D+W+%5Cfrac%7B%5Cpartial+f_%7B2%7D%7D%7B%5Cpartial+a_%7B2%7D%7D+f_%7B1%7D%2B%5Cfrac%7B%5Cpartial+f_%7B3%7D%7D%7B%5Cpartial+a_%7B3%7D%7D+W+%5Cfrac%7B%5Cpartial+f_%7B2%7D%7D%7B%5Cpartial+a_%7B2%7D%7D+W+%5Cfrac%7B%5Cpartial+f_%7B1%7D%7D%7B%5Cpartial+a_%7B1%7D%7D+%5Cfrac%7B%5Cpartial+a_%7B1%7D%7D%7B%5Cpartial+W_%7B1%7D%7D" alt="[公式]"> 。我们用最后一项做分析，即使使用了<a href="https://www.zhihu.com/search?q=relu&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22350613342%22%7D">relu</a>，
<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f_%7B3%7D%7D%7B%5Cpartial+a_%7B3%7D%7D%3D%5Cfrac%7B%5Cpartial+f_%7B2%7D%7D%7B%5Cpartial+a_%7B2%7D%7D%3D%5Cfrac%7B%5Cpartial+f_%7B3%7D%7D%7B%5Cpartial+a_%7B1%7D%7D%3D1" alt="[公式]"> ，还是会有两个 <img src="https://www.zhihu.com/equation?tex=W" alt="[公式]">
相乘，并不能解决梯度消失或梯度爆炸的问题。</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>RNN</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-NLP-命名实体识别</title>
    <url>/posts/2E809GM/</url>
    <content><![CDATA[<h2><span id="命名实体识别-bilstm-crf模型">命名实体识别-BiLSTM-CRF模型</span></h2>
<blockquote>
<p>最通俗易懂的BiLSTM-CRF模型中的CRF层介绍 - 孙孙的文章 - 知乎
https://zhuanlan.zhihu.com/p/44042528</p>
</blockquote>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-NLP（2）Word2vec*</title>
    <url>/posts/3BVGDDE/</url>
    <content><![CDATA[<h2><span id="一-word2vec">一、Word2Vec</span></h2>
<blockquote>
<ul>
<li><p><strong>nlp中的词向量对比：word2vec/glove/fastText/elmo/GPT/bert</strong>：https://zhuanlan.zhihu.com/p/56382372</p></li>
<li><p>Word2Vec算法梳理🔥 - 杨航锋的文章 - 知乎
https://zhuanlan.zhihu.com/p/58290018</p></li>
<li><p><a href="https://plushunter.github.io/2018/02/14/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%B3%BB%E5%88%97%EF%BC%882%EF%BC%89%EF%BC%9AWord2Vec/">Free
will：Word2Vec</a></p></li>
<li><p>[<a href="https://zhuanlan.zhihu.com/p/26306795">NLP]
秒懂词向量<em>Word2vec</em>的本质</a></p></li>
<li><p><a href="https://zhuanlan.zhihu.com/p/61635013"><em>Word2Vec</em>详解</a></p></li>
<li><p><strong><a href="https://zhuanlan.zhihu.com/p/53425736"><em>word2vec</em>详解（CBOW，skip-gram，负采样，分层Softmax）</a></strong></p></li>
<li><p><a href="https://zhuanlan.zhihu.com/p/89637281">快速入门词嵌入之<em>word2vec</em></a></p></li>
</ul>
<p><strong>word2vec 相比之前的 Word Embedding
方法好在什么地方？</strong></p>
<ul>
<li><strong>极快的训练速度</strong>。以前的语言模型优化的目标是MLE，只能说词向量是其副产品。Mikolov应该是第一个提出抛弃MLE（和困惑度）指标，就是要学习一个好的词嵌入。如果不追求MLE，模型就可以大幅简化，去除隐藏层。再利用HSoftmax以及负采样的加速方法，可以使得训练在小时级别完成。而原来的语言模型可能需要几周时间。</li>
<li><strong>一个很酷炫的man-woman=king-queen的示例</strong>。这个示例使得人们发现词嵌入还可以这么玩，并促使词嵌入学习成为了一个研究方向，而不再仅仅是神经网络中的一些参数。</li>
<li><strong>word2vec里有大量的tricks，比如噪声分布如何选？如何采样？如何负采样？</strong>等等。这些tricks虽然摆不上台面，但是对于得到一个好的词向量至关重要。</li>
</ul>
</blockquote>
<p>谷歌2013年提出的Word2Vec是目前最常用的词嵌入模型之一。Word2Vec实际是一种<strong>浅层的神经网络模型</strong>，它有两种网络结构，分别是<strong>连续词袋</strong>（CBOW）和<strong>跳字</strong>(Skip-Gram)模型。</p>
<blockquote>
<p>CBOW适合于数据集较小的情况，而Skip-Gram在大型语料中表现更好</p>
</blockquote>
<h3><span id="11-介绍cbow">1.1 介绍CBOW</span></h3>
<p>CBOW，全称Continuous
Bag-of-Word，中文叫做连续词袋模型：<strong>以上下文来预测当前词</strong>
<span class="math inline">\(w_t\)</span> 。CBOW模型的目的是预测 $P(w_t|
w_{t-k}, , w_{t-1}, w_{t+1}, , w_{t+k}) $</p>
<figure>
<img src="https://pic4.zhimg.com/v2-27f3e577618f84c0026968d273d823ef_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="前向传播过程">前向传播过程</span></h4>
<ul>
<li><p><strong>输入层</strong>: 输入C个单词<span class="math inline">\(x\)</span>： $x_{1k}, , x_{Ck} $，并且每个 <span class="math inline">\(x\)</span> 都是用 <strong>One-hot</strong>
编码表示，每一个 <span class="math inline">\(x\)</span> 的维度为
V（词表长度）。</p></li>
<li><p><strong>输入层到隐层</strong></p>
<ul>
<li>首先，共享矩阵为 <span class="math inline">\(W_{V \times N}\)</span>
，<strong>V表示词表长度</strong>，W的每一行表示的就是一个N维的向量（训练结束后，W的每一行就表示一个词的词向量）。</li>
<li>然后，我们把所有<strong>输入的词转<span class="math inline">\(x\)</span>化为对应词向量</strong>，然后<strong>取平均值</strong>，这样我们就得到了隐层输出值
( 注意，隐层中无激活函数，也就是说这里是线性组合)。 其中，隐层输出 <span class="math inline">\(h\)</span> 是一个N维的向量 。</li>
</ul>
<p><span class="math display">\[
  h = \frac{1}{C} W^T(x_1 + x_2 + \cdots + x_c)
  \]</span></p></li>
<li><p><strong>隐层到输出层</strong>：隐层的输出为N维向量 <span class="math inline">\(h\)</span> ， 隐层到输出层的权重矩阵为 <span class="math inline">\(W&#39;_{N \times V}\)</span>
。然后，通过矩阵运算我们得到一个 $V $ 维向量 <span class="math display">\[
  u = W&#39;^{T} * h
  \]</span></p></li>
</ul>
<p>其中，向量 <span class="math inline">\(u\)</span> 的第 <span class="math inline">\(i\)</span> 行表示词汇表中第 <span class="math inline">\(i\)</span>
个词的可能性，然后我们的目的就是取可能性最高的那个词。<strong>因此，在最后的输出层是一个softmax
层获取分数最高的词</strong>，那么就有我们的最终输出： <span class="math display">\[
P(w_j| context)  =y_i =  \frac{exp({u_j})}{\sum_{k \in V} exp({u_k})}
\]</span></p>
<h4><span id="损失函数">损失函数</span></h4>
<p>我们假定 <span class="math inline">\(j^*\)</span>
是真实单词在词汇表中的下标，那么根据极大似然法，则目标函数定义如下：
<span class="math display">\[
E = -log \, p(W_O |W_I) = -log \, \frac{exp({u_j})}{\sum_{k \in V}
exp({u_k})} =  log  \sum_{k \in V} exp(u_{k})  -u_j
\]</span></p>
<h3><span id="12-skip-gram模型">1.2 Skip-gram模型</span></h3>
<p>Skip-Gram的基本思想是：<strong>通过当前词 <span class="math inline">\(w_t\)</span> 预测其上下文 <span class="math inline">\(w_{t-i}, \cdots , w_{t+i}\)</span></strong>
，模型如下图所示：</p>
<figure>
<img src="https://pic2.zhimg.com/v2-42ef75691c18a03cfda4fa85a8409e19_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="前向传播过程">前向传播过程</span></h4>
<ul>
<li><p><strong>输入层</strong>： 输入的是一个单词，其表示形式为
<strong>One-hot</strong> ，我们将其表示为V维向量 <span class="math inline">\(x_k\)</span> ，其中 <span class="math inline">\(V\)</span> 为词表大小。然后，通过词向量矩阵 <span class="math inline">\(W_{V \times N}\)</span> 我们得到一个N维向量 <span class="math display">\[
  h = W^T * x_k = v^{T}_{w_I}
  \]</span></p></li>
<li><p><strong>隐层</strong>：
而隐层中没有激活函数，也就是说输入=输出，因此隐藏的输出也是 <span class="math inline">\(h\)</span> 。</p></li>
<li><p><strong>隐层到输出层</strong>：</p>
<ul>
<li><p><strong>首先</strong>，因为要输出C个单词，因此我们此时的输出有C个分布：
<strong>$y_1, y_C $，且每个分布都是独立的</strong>，我们需要单独计算，
其中 <span class="math inline">\(y_i\)</span> 表示窗口的第 <span class="math inline">\(i\)</span> 个单词的分布。
【<strong>独立性假设</strong>】</p></li>
<li><p><strong>其次</strong>， 因为矩阵 <span class="math inline">\(W&#39;_{N \times V}\)</span>
是共享的，因此我们得到的 <span class="math inline">\(V \times 1\)</span>
维向量 <span class="math inline">\(u\)</span> 其实是相同的，也就是有
<span class="math inline">\(u_{c,j} = u_j\)</span> ，这里 <span class="math inline">\(u\)</span> 的每一行同 CBOW
中一样，表示的也是评分。</p></li>
<li><p><strong>最后</strong>，每个分布都经过一个 softmax 层，不同于
CBOW，我们此处产生的是第 <span class="math inline">\(i\)</span>
个单词的分布（共有C个单词），如下：</p></li>
</ul>
<p><span class="math display">\[
  P(w_{i,j}| context)  =y_i =  \frac{exp({u_j})}{\sum_{k \in V}
exp({u_k})}
  \]</span></p></li>
</ul>
<h4><span id="损失函数">损失函数</span></h4>
<p>假设 <span class="math inline">\(j^*\)</span>
是真实单词在词汇表中的下标，那么根据<strong>极大似然法</strong>，则目标函数定义如下：
<span class="math display">\[
\begin{split} E &amp;= - log \, p(w_1, w_2, \cdots, w_C | w_I)   \\
&amp;= - log \prod_{c=1}^C P(w_c|w_i) \\ &amp;= - log  \prod_{c=1}^{C}
\frac{exp(u_{c, j})}{\sum_{k=1}^{V} exp(u_{c,k}) } \\ &amp;= -
\sum_{c=1}^C u_{j^*_c} + C \cdot log \sum_{k=1}^{V} exp(u_k) \end{split}
\]</span></p>
<h2><span id="二-word2vec-优化">二、Word2Vec 优化</span></h2>
<p>以上我们讨论的模型（二元模型，CBOW和skip-gram）都是他们的原始形式，没有加入任何优化技巧。对于这些模型，每个单词存在两类向量表达：<strong>输入向量</strong><img src="https://www.zhihu.com/equation?tex=v_%7Bw%7D%5E%7B%7D" alt="[公式]">，<strong>输出向量</strong><img src="https://www.zhihu.com/equation?tex=v_%7Bw%7D%5E%7B%27%7D" alt="[公式]">（这也是为什么word2vec的名称由来：1个单词对应2个向量表示)。学习得到输入向量比较简单；但<strong>要学习输出向量是很困难</strong>的。</p>
<h3><span id="21-hierarchical-softmax">==2.1 Hierarchical Softmax==</span></h3>
<blockquote>
<p>https://zhuanlan.zhihu.com/p/56139075</p>
</blockquote>
<p>Hierarchical
Softmax对原模型的改进主要有两点，第一点是从输入层到隐藏层的映射，没有采用原先的与矩阵W相乘然后相加求平均的方法，而是<strong>直接对所有输入的词向量求和</strong>。假设输入的词向量为（0，1，0，0）和（0,0,0,1），那么隐藏层的向量为（0,1,0,1）。</p>
<p><strong>Hierarchical Softmax</strong>的第二点改进是采用<a href="https://www.zhihu.com/search?q=哈夫曼树&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%2261635013%22%7D">哈夫曼树</a>来替换了原先的从隐藏层到输出层的矩阵W’。<strong>哈夫曼树的叶节点个数为词汇表的单词个数V</strong>，一个叶节点代表一个单词，而从根节点到该叶节点的路径确定了这个单词最终输出的词向量。</p>
<p><img src="https://pic4.zhimg.com/v2-3db7e66f36db0a9e6e6bc2f348dece47_b.jpg" alt="img" style="zoom:50%;"></p>
<p><strong>具体来说，这棵哈夫曼树除了根结点以外的所有非叶节点中都含有一个由参数θ确定的sigmoid函数，不同节点中的θ不一样</strong>。训练时==<strong>隐藏层的向量</strong>==与这个<strong>==sigmoid函数==</strong>进行运算，根据结果进行分类，若分类为负类则沿左子树向下传递，编码为0；若分类为正类则沿右子树向下传递，编码为1。</p>
<p><strong>每个叶子节点代表语料库中的一个词</strong>，<strong>于是每个词语都可以被01唯一的编码，并且其编码序列对应一个事件序列，于是我们可以计算条件概率
<img src="https://www.zhihu.com/equation?tex=p%28w+%7C+C+o+n+t+e+x+t%28w%29%29" alt="[公式]"></strong> 。</p>
<p><strong>在开始计算之前，还是得引入一些符号：</strong></p>
<ol type="1">
<li><p><img src="https://www.zhihu.com/equation?tex=p%5E%7Bw%7D" alt="[公式]"> :从根结点出发到达w对应叶子结点的路径</p></li>
<li><p><img src="https://www.zhihu.com/equation?tex=l%5E%7Bw%7D" alt="[公式]"> :路径中包含结点的个数</p></li>
<li><p><img src="https://www.zhihu.com/equation?tex=p_%7B1%7D%5E%7Bw%7D%2C+p_%7B2%7D%5E%7Bw%7D%2C+%5Ccdots%2C+p_%7Bl%5E%7Bw%7D%7D%5E%7Bw%7D" alt="[公式]"> :路径 <img src="https://www.zhihu.com/equation?tex=p%5E%7Bw%7D" alt="[公式]">
中的各个节点</p></li>
<li><p><img src="https://www.zhihu.com/equation?tex=d_%7B2%7D%5E%7Bw%7D%2C+d_%7B3%7D%5E%7Bw%7D%2C+%5Ccdots%2C+d_%7Bl+w%7D%5E%7Bw%7D+%5Cin%5C%7B0%2C1%5C%7D" alt="[公式]"> :词w的编码， <img src="https://www.zhihu.com/equation?tex=d_%7Bj%7D%5E%7Bw%7D" alt="[公式]"> 表示路径 <img src="https://www.zhihu.com/equation?tex=p%5E%7Bw%7D" alt="[公式]">
第j个节点对应的编码（根节点无编码）</p></li>
<li><p><img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7B1%7D%5E%7Bw%7D%2C+%5Ctheta_%7B2%7D%5E%7Bw%7D%2C+%5Ccdots%2C+%5Ctheta_%7Bl%5E%7Bw%7D-1%7D%5E%7Bw%7D+%5Cin+%5Cmathbb%7BR%7D%5E%7Bm%7D" alt="[公式]"> :路径 <img src="https://www.zhihu.com/equation?tex=p%5E%7Bw%7D" alt="[公式]">
中非叶节点对应的<strong>参数向量</strong></p></li>
</ol>
<p>于是可以给出w的条件概率：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=p%28w+%7C+C+o+n+t+e+x+t%28w%29%29%3D%5Cprod_%7Bj%3D2%7D%5E%7Bl%5E%7Bw%7D%7D+p%5Cleft%28d_%7Bj%7D%5E%7Bw%7D+%7C+%5Cmathbf%7Bx%7D_%7Bw%7D%2C+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><strong>这是个简单明了的式子，从根节点到叶节点经过了 <img src="https://www.zhihu.com/equation?tex=l%5E%7Bw%7D-1" alt="[公式]">
个节点，编码从下标2开始（根节点无编码），对应的参数向量下标从1开始（根节点为1)。</strong></p>
<p>其中，每一项是一个<strong>逻辑斯谛回归</strong>：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=p%5Cleft%28d_%7Bj%7D%5E%7Bw%7D+%7C+%5Cmathbf%7Bx%7D_%7Bw%7D%2C+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%3D%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bll%7D%7B%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%2C%7D+%26+%7Bd_%7Bj%7D%5E%7Bw%7D%3D0%7D+%5C%5C+%7B1-%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%2C%7D+%26+%7Bd_%7Bj%7D%5E%7Bw%7D%3D1%7D%5Cend%7Barray%7D%5Cright." alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>考虑到d只有0和1两种取值，我们可以用指数形式方便地将其写到一起：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=p%5Cleft%28d_%7Bj%7D%5E%7Bw%7D+%7C+%5Cmathbf%7Bx%7D_%7Bw%7D%2C+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%3D%5Cleft%5B%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D%5E%7B1-d_%7Bj%7D%5E%7Bw%7D%7D+%5Ccdot%5Cleft%5B1-%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D%5E%7Bd%5E%7Bw%7D%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><strong>我们的目标函数取对数似然</strong>：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%3D%5Csum_%7Bw+%5Cin+%5Cmathcal%7BC%7D%7D+%5Clog+p%28w+%7C+C+o+n+t+e+x+t%28w%29%29" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>将 <img src="https://www.zhihu.com/equation?tex=p%28w+%7C+C+o+n+t+e+x+t%28w%29%29" alt="[公式]"> 代入上式，有:</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%3D%5Csum_%7Bw+%5Cin+%5Cmathcal%7BC%7D%7D+%5Clog+%5Cprod_%7Bj%3D2%7D%5E%7Bl%5E%7Bw%7D%7D%5Cleft%5C%7B%5Cleft%5B%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D%5E%7B1-d_%7Bj%7D%5E%7Bw%7D%7D+%5Ccdot%5Cleft%5B1-%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D%5E%7Bd_%7Bj%7D%5E%7Bw%7D%7D%5Cright%5C%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=%3D%5Csum_%7Bw+%5Cin+%5Cmathcal%7BC%7D%7D+%5Csum_%7Bj%3D2%7D%5E%7Bl%5E%7Bw%7D%7D%5Cleft%5C%7B%5Cleft%281-d_%7Bj%7D%5E%7Bw%7D%5Cright%29+%5Ccdot+%5Clog+%5Cleft%5B%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D%2Bd_%7Bj%7D%5E%7Bw%7D+%5Ccdot+%5Clog+%5Cleft%5B1-%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D%5Cright%5C%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>这也很直白，连乘的对数换成求和。不过还是有点长，我们把每一项简记为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28w%2C+j%29%3D%5Cleft%281-d_%7Bj%7D%5E%7Bw%7D%5Cright%29+%5Ccdot+%5Clog+%5Cleft%5B%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D%2Bd_%7Bj%7D%5E%7Bw%7D+%5Ccdot+%5Clog+%5Cleft%5B1-%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h4><span id="wordvec极大化化目标函数使用的算法是是随机梯度上升法"><strong><font color="red">
<em>WordVec</em>
极大化化目标函数使用的算法是是随机梯度上升法</font></strong></span></h4>
<p>每一项有两个参数，一个是每个节点的参数向量 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bj-1%7D%5E%7Bw%7D" alt="[公式]"> ，另一个是输出层的输入 <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BX%7D_%7Bw%7D" alt="[公式]"> ，我们分别对其求偏导数：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%5Cmathcal%7BL%7D%28w%2C+j%29%7D%7B%5Cpartial+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%7D%3D%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%7D%5Cleft%5C%7B%5Cleft%281-d_%7Bj%7D%5E%7Bw%7D%5Cright%29+%5Ccdot+%5Clog+%5Cleft%5B%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D%2Bd_%7Bj%7D%5E%7Bw%7D+%5Ccdot+%5Clog+%5Cleft%5B1-%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D%5Cright%5C%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>因为sigmoid函数的导数有个很棒的形式：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Csigma%5E%7B%5Cprime%7D%28x%29%3D%5Csigma%28x%29%5B1-%5Csigma%28x%29%5D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>于是代入上上式得到：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cleft%281-d_%7Bj%7D%5E%7Bw%7D%5Cright%29%5Cleft%5B1-%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D+%5Cmathbf%7Bx%7D_%7Bw%7D-d_%7Bj%7D%5E%7Bw%7D+%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29+%5Cmathbf%7Bx%7D_%7Bw%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><strong>合并同类项得到：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cleft%5B1-d_%7Bj%7D%5E%7Bw%7D-%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D+%5Cmathbf%7Bx%7D_%7Bw%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>于是 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bj-1%7D%5E%7Bw%7D" alt="[公式]">的更新表达式就得到了：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bj-1%7D%5E%7Bw%7D+%3A%3D%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%2B%5Ceta%5Cleft%5B1-d_%7Bj%7D%5E%7Bw%7D-%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D+%5Cmathbf%7Bx%7D_%7Bw%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中， <img src="https://www.zhihu.com/equation?tex=%5Ceta" alt="[公式]">
是学习率，通常取0-1之间的一个值。学习率越大训练速度越快，但目标函数容易在局部区域来回抖动。</p>
<p><strong>再来 <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BX%7D_%7Bw%7D" alt="[公式]"> 的偏导数</strong>，注意到 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28w%2C+j%29%3D%5Cleft%281-d_%7Bj%7D%5E%7Bw%7D%5Cright%29+%5Ccdot+%5Clog+%5Cleft%5B%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D%2Bd_%7Bj%7D%5E%7Bw%7D+%5Ccdot+%5Clog+%5Cleft%5B1-%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D" alt="[公式]"> 中 <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BX%7D_%7Bw%7D" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bj-1%7D%5E%7Bw%7D" alt="[公式]"> 是对称的，所有直接将 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bj-1%7D%5E%7Bw%7D" alt="[公式]"> 的偏导数中的 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bj-1%7D%5E%7Bw%7D" alt="[公式]"> 替换为 <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BX%7D_%7Bw%7D" alt="[公式]"> ，得到关于 <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BX%7D_%7Bw%7D" alt="[公式]"> 的偏导数：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%5Cmathcal%7BL%7D%28w%2C+j%29%7D%7B%5Cpartial+%5Cmathbf%7Bx%7D_%7Bw%7D%7D%3D%5Cleft%5B1-d_%7Bj%7D%5E%7Bw%7D-%5Csigma%5Cleft%28%5Cmathbf%7Bx%7D_%7Bw%7D%5E%7B%5Ctop%7D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D%5Cright%29%5Cright%5D+%5Ctheta_%7Bj-1%7D%5E%7Bw%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><strong>不过 <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BX%7D_%7Bw%7D" alt="[公式]">
是上下文的词向量的和，不是上下文单个词的词向量。怎么把这个更新量应用到单个词的词向量上去呢？word2vec采取的是直接将
<img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BX%7D_%7Bw%7D" alt="[公式]"> 的更新量整个应用到每个单词的词向量上去</strong>：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7Bv%7D%28%5Cwidetilde%7Bw%7D%29+%3A%3D%5Cmathbf%7Bv%7D%28%5Cwidetilde%7Bw%7D%29%2B%5Ceta+%5Csum_%7Bj%3D2%7D%5E%7Bl%5E%7Bw%7D%7D+%5Cfrac%7B%5Cpartial+%5Cmathcal%7BL%7D%28w%2C+j%29%7D%7B%5Cpartial+%5Cmathbf%7Bx%7D_%7Bw%7D%7D%2C+%5Cquad+%5Cwidetilde%7Bw%7D+%5Cin+%5Ctext+%7B+Context+%7D%28w%29" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中， <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7Bv%7D%28%5Cwidetilde%7Bw%7D%29" alt="[公式]">
代表上下文中某一个单词的词向量。我认为应该也可以将其平均后更新到每个词向量上去，无非是学习率的不同，欢迎指正。</p>
<h3><span id="22-negative-sampling">2.2 Negative Sampling</span></h3>
<blockquote>
<p>Negative Sampling - 素轻的文章 - 知乎
https://zhuanlan.zhihu.com/p/56106590</p>
</blockquote>
<blockquote>
<p><strong>为了解决数量太过庞大的输出向量的更新问题，我们就不更新全部向量，而只更新他们的一个样本</strong>。</p>
<p>训练神经网络
意味着输入一个训练样本调整weight，让它预测这个训练样本更准。换句话说，每个训练样本将会影响网络中所有的weight。<strong>Negative
sampling
解决了这个问题，每次我们就修改了其中一小部分weight，而不是全部。</strong></p>
</blockquote>
<p><strong>负采样是另一种用来提高Word2Vec效率的方法</strong>，它是基于这样的观察：训练一个神经网络意味着使用一个训练样本就要稍微调整一下神经网络中所有的权重，这样才能够确保预测训练样本更加精确，如果能设计一种方法每次只更新一部分权重，那么计算复杂度将大大降低。</p>
<p>如果 vocabulary 大小为10000时， 当输入样本 ( "fox", "quick")
到神经网络时， <strong>“ fox” 经过 one-hot 编码，在输出层我们期望对应
“quick” 单词的那个神经元结点输出 1，其余 9999 个都应该输出
0</strong>。在这里，这9999个我们期望输出为0的神经元结点所对应的单词我们为
negative word. negative sampling 的想法也很直接
，<strong>将随机选择一小部分的 negative words，比如选 10个 negative
words 来更新对应的权重参数。</strong></p>
<p><strong>假设原来模型每次运行都需要300×10,000(其实没有减少数量，但是运行过程中，减少了需要载入的数量。)
现在只要300×(1+10)减少了好多。</strong></p>
<h4><span id="问题来了如何选择10个negativesample呢">==问题来了，如何选择10个negative
sample呢？==</span></h4>
<p><strong>negative
sample也是根据他们出现概率来选的，而这个概率又和他们出现的频率有关。更常出现的词，更容易被选为negative
sample。</strong></p>
<p>这个概率用一个公式表示，每个词给了一个和它频率相关的权重。这个概率公式为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=P%28w_i%29+%3D+%5Cfrac%7Bf%28w_i%29%5E%7B0.75%7D+%7D%7B+%5Csum_%7Bj%3D0%7D%5E%7Bn%7D%28f%28w_j%29%5E%7B0.75%7D%7D%29" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>在paper中说0.75这个超参是试出来的，这个函数performance比其他函数好。</p>
<p><strong><font color="red">
负采样算法实际上就是一个带权采样过程，负例的选择机制是和单词词频联系起来的。</font></strong>具体做法是以
<code>N+1</code> 个点对区间 <code>[0,1]</code>
做非等距切分，并引入的一个在区间 <code>[0,1]</code> 上的 <code>M</code>
等距切分，其中 <code>M &gt;&gt; N。</code>源码中取 M =
10^8。然后对两个切分做投影，得到映射关系：采样时，每次生成一个 [1, M-1]
之间的整数 i，则 Table(i)
就对应一个样本；当采样到正例时，跳过（<strong>拒绝采样</strong>）。</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-36547a4cd05365292830ad4b22ba4c93_1440w.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic3.zhimg.com/80/v2-a788595cc2611b0bfdac9e039a2e82fe_1440w.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic1.zhimg.com/80/v2-cfe67c913af37a9435f3331139abeab8_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h2><span id="三-word2vec-qampa">三、Word2vec Q&amp;A</span></h2>
<h3><span id="31-word2vec与lda的区别">3.1 Word2Vec与LDA的区别</span></h3>
<ol type="1">
<li><p>LDA是利用文档中<strong>单词的共现关系</strong>来对单词按<strong>主题聚类</strong>，也可以理解为对“<strong>文档-单词</strong>”矩阵进行<strong>分解</strong>，得到“<strong>文档-主题</strong>”和“<strong>主题-单词</strong>”两个<strong>概率分布</strong>。</p></li>
<li><p>Word2Vec是利用<strong>上下文-单词</strong>“矩阵进行学习，其中上下文由周围的几个单词组成，由此得到的词向量表示更多地融入了上下文共现的特征。也就是说，如果两个单词所对应的word2vec向量相似度较高，那么它们很可能经常在同样的上下文中出现。</p></li>
<li><p>LDA模型是一种基于<strong>概率图模型</strong>的<strong>生成式模型</strong>，其似然函数可以写成若干条件概率连乘的形式，其中包括需要推测的隐含变量（即主题）；</p></li>
<li><p>而Word2Vec模型一般表达为<strong>神经网络</strong>的形式，似然函数定义在网络的输出之上，需要通过学习网络的权重以得到单词的稠密向量表示。</p></li>
</ol>
<h3><span id="32-word2vec存在的问题是什么">3.2 Word2Vec存在的问题是什么？</span></h3>
<ul>
<li>对每个local context window单独训练，没有利用包 含在global
co-currence矩阵中的统计信息。</li>
<li>对多义词无法很好的表示和处理，因为使用了唯一的词向量</li>
</ul>
<h3><span id="32-ood-of-word2vec">3.2 OOD of word2vec</span></h3>
<p>其它单词认定其为Unknow，编号为0</p>
<h3><span id="34-项目中的word2vec">3.4 项目中的word2vec</span></h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">feature_asm2vec</span>(<span class="params">data_type, inter_path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Feature engineering for asm2vec feature.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> data_type == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">        <span class="comment"># TODO : 模型空判断</span></span><br><span class="line">        <span class="comment"># Train a Word2vec model by mixing traing set and test set</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;------------------------ 训练asm2vec模型 ------------------------&quot;</span>)</span><br><span class="line">        sentences = PathLineSentences(<span class="string">f&quot;<span class="subst">&#123;inter_path&#125;</span>/semantic/&quot;</span>)</span><br><span class="line">        model = Word2Vec(sentences=sentences, vector_size=<span class="number">1024</span>, window=<span class="number">5</span>, min_count=<span class="number">5</span>, workers=<span class="number">5</span>)</span><br><span class="line">        model.wv.save_word2vec_format(<span class="string">f&quot;<span class="subst">&#123;inter_path&#125;</span>/models/asm2vec.bin&quot;</span>, binary=<span class="literal">True</span>, sort_attr=<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load the trained Word2vec model</span></span><br><span class="line">    model_wv = KeyedVectors.load_word2vec_format(<span class="string">f&quot;<span class="subst">&#123;inter_path&#125;</span>/models/asm2vec.bin&quot;</span>, binary=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;------------------------ 生成asm2vec特征 ------------------------&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;<span class="subst">&#123;inter_path&#125;</span>/<span class="subst">&#123;data_type&#125;</span>_filename.txt&quot;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        filename = fp.read().split()</span><br><span class="line">    <span class="comment"># Feature engineering for generating string vector features</span></span><br><span class="line">    obj = StringVector()</span><br><span class="line">    arr = np.zeros((<span class="built_in">len</span>(filename), obj.dim))</span><br><span class="line">    <span class="keyword">with</span> tqdm(total=<span class="built_in">len</span>(filename), ncols=<span class="number">80</span>, desc=obj.name) <span class="keyword">as</span> pbar:</span><br><span class="line">        <span class="keyword">for</span> i, file <span class="keyword">in</span> <span class="built_in">enumerate</span>(filename):</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&quot;<span class="subst">&#123;inter_path&#125;</span>/semantic/<span class="subst">&#123;file&#125;</span>.txt&quot;</span>, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                stringz = f.read().decode(<span class="string">&#x27;utf-8&#x27;</span>, errors=<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">            lines = <span class="string">&#x27; &#x27;</span>.join(stringz.split(<span class="string">&#x27;\n&#x27;</span>))</span><br><span class="line">            raw_words = <span class="built_in">list</span>(<span class="built_in">set</span>(lines.split()))</span><br><span class="line">            arr[i, :] = obj.feature_vector((model_wv, raw_words))</span><br><span class="line">            pbar.update(<span class="number">1</span>)</span><br><span class="line">    arr[np.isnan(arr)] = <span class="number">0</span></span><br><span class="line">    np.save(<span class="string">f&quot;<span class="subst">&#123;inter_path&#125;</span>/feature/<span class="subst">&#123;data_type&#125;</span>_semantic.npy&quot;</span>, arr)</span><br></pre></td></tr></table></figure>
<h3><span id="35-tf-idf-word2vec和bert-比较">3.5 Tf-Idf、Word2Vec和BERT 比较</span></h3>
<blockquote>
<p>从算法本质来说 word2vec
一旦训练好了是<strong>没法处理未登录词（OOV）</strong>的，一般的做法是给OOV一个默认的向量，下面是一个类的封装（仅列出核心部分）</p>
</blockquote>
<p>https://www.leiphone.com/category/yanxishe/TbZAzc3CJAMs815p.html</p>
<ul>
<li><strong>词袋法</strong>：用scikit-learn进行特征工程、特征选择以及机器学习，测试和评估，用lime解释。</li>
<li><strong>词嵌入法</strong>：用gensim拟合Word2Vec，用tensorflow/keras进行特征工程和深度学习，测试和评估，用Attention机制解释。</li>
<li><strong>语言模型</strong>：用transformers进行特征工程，用transformers和tensorflow/keras进行预训练BERT的迁移学习，测试和评估。</li>
</ul>
<h4><span id="概要">概要</span></h4>
<p>在本文中，我将使用NLP和Python来解释3种不同的文本多分类策略：老式的词袋法（tf-ldf），著名的词嵌入法（Word2Vec）和最先进的语言模型（BERT）。</p>
<figure>
<img src="https://static.leiphone.com/uploads/new/images/20200930/5f73ddf75200f.png?imageView2/2/w/740" alt="NLP之文本分类：「Tf-Idf、Word2Vec和BERT」三种模型比较">
<figcaption aria-hidden="true">NLP之文本分类：「Tf-Idf、Word2Vec和BERT」三种模型比较</figcaption>
</figure>
<p>NLP（自然语言处理）是人工智能的一个领域，它研究计算机和人类语言之间的交互作用，特别是如何通过计算机编程来处理和分析大量的自然语言数据。NLP常用于文本数据的分类。文本分类是指根据文本数据内容对其进行分类的问题。</p>
<p>我们有多种技术从原始文本数据中提取信息，并用它来训练分类模型。本教程比较了传统的<strong>词袋法</strong>（与简单的机器学习算法一起使用）、流行的<strong>词嵌入模型</strong>（与深度学习神经网络一起使用）和最先进的语言模型（和基于<strong>attention</strong>的<strong>transformers</strong>模型中的<strong>迁移学习</strong>一起使用），语言模型彻底改变了NLP的格局。</p>
<p>我将介绍一些有用的Python代码，这些代码可以轻松地应用在其他类似的案例中（仅需复制、粘贴、运行），并对代码逐行添加注释，以便你能复现这个例子（下面是全部代码的链接）。</p>
<p><strong>词袋法</strong>：文件越多，词汇表越大，因此特征矩阵将是一个巨大的稀疏矩阵。</p>
<h4><span id="bert比之word2vec有哪些进步呢">Bert比之Word2Vec,有哪些进步呢？</span></h4>
<ul>
<li><p><strong>静态到动态：一词多义问题</strong></p></li>
<li><p><strong>词的多层特性</strong>：一个好的语言表示出了建模一词多义现象以外，还需要能够体现词的复杂特性，包括语法
(syntax)、语义 (semantics) 等。</p></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-NLP（1）词嵌入</title>
    <url>/posts/2ZDHNTC/</url>
    <content><![CDATA[<h2><span id="nlpword2vecglovefasttextelmogptbert">nlp：word2vec/glove/fastText/elmo/GPT/bert</span></h2>
<blockquote>
<p>本文以QA形式对自然语言处理中的词向量进行总结：包含word2vec/glove/fastText/elmo/bert。</p>
<ul>
<li>https://zhuanlan.zhihu.com/p/56382372</li>
<li><strong>Bert之后，RoBERTa、XLNET、ALBERT、ELECTRA改进对比</strong> -
虹膜小马甲的文章 - 知乎 https://zhuanlan.zhihu.com/p/486532878</li>
</ul>
</blockquote>
<h3><span id="一-文本表示和各词向量间的对比"><strong>一、文本表示和各词向量间的对比</strong></span></h3>
<h4><span id="1-文本表示和各词向量间的对比"><strong>1、文本表示和各词向量间的对比</strong></span></h4>
<ul>
<li><strong>词袋模型</strong>：<strong>one-hot、tf-idf</strong>、textrank等；</li>
<li>主题模型：LSA（SVD）、pLSA、LDA；</li>
<li><strong>基于词向量的固定表征</strong>：<strong>word2vec、fastText</strong>、glove</li>
<li><strong>基于词向量的动态表征</strong>：elmo、<strong>GPT、bert</strong></li>
</ul>
<h4><span id="2-怎么从语言模型理解词向量怎么理解分布式假设"><strong>2、怎么从语言模型理解词向量？怎么理解分布式假设？</strong></span></h4>
<p>上面给出的4个类型也是nlp领域最为常用的文本表示了，文本是由每个单词构成的，而谈起词向量，one-hot是可认为是最为简单的词向量，但存在维度灾难和语义鸿沟等问题；通过构建共现矩阵并利用<strong>SVD求解构建词向量</strong>，则计算复杂度高<strong>；而早期词向量的研究通常来源于语言模型，比如NNLM和RNNLM</strong>，其主要目的是语言模型，而词向量只是一个副产物。</p>
<p>所谓==分布式假设，用一句话可以表达：<strong>相同上下文语境的词有似含义</strong>==。而由此引申出了word2vec、fastText，在此类词向量中，虽然其本质仍然是语言模型，但是它的目标并不是语言模型本身，而是词向量，其所作的一系列优化，都是为了更快更好的得到词向量。<strong>glove则是基于全局语料库、并结合上下文语境构建词向量，结合了LSA和word2vec的优点。</strong></p>
<h4><span id="3-传统的词向量有什么问题怎么解决各种词向量的特点是什么"><strong>3、传统的词向量有什么问题？怎么解决？各种词向量的特点是什么？</strong></span></h4>
<p><strong>上述方法得到的词向量是固定表征的，无法解==决一词多义==等问题</strong>，如“川普”。为此引入基于语言模型的动态表征方法：elmo、GPT、bert。</p>
<p><img src="https://pic2.zhimg.com/80/v2-80e28f4375302454947c9c8431564ed9_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p><strong>各种词向量的特点：</strong></p>
<p>One-hot 表示 ：维度灾难、语义鸿沟；</p>
<p><strong>分布式表示 (distributed representation)</strong> ：</p>
<ul>
<li>矩阵分解（LSA）：利用全局语料特征，但SVD求解计算复杂度大；</li>
<li>基于NNLM/RNNLM的词向量：词向量为副产物，存在效率不高等问题；</li>
<li><strong>word2vec、fastText</strong>：优化效率高，但是基于局部语料；</li>
<li>glove：基于全局预料，结合了LSA和word2vec的优点；</li>
<li>elmo、GPT、bert：动态特征；</li>
</ul>
<h4><span id="4-word2vec和nnlm对比有什么区别word2vecvs-nnlm"><strong>4、word2vec和NNLM对比有什么区别？（word2vec
vs NNLM）</strong></span></h4>
<p>1）其本质都可以看作是语言模型；</p>
<p>2）词向量只不过NNLM一个产物，word2vec虽然其本质也是语言模型，但是其专注于词向量本身，因此做了许多优化来提高计算效率：</p>
<ul>
<li>与NNLM相比，词向量直接sum，不再拼接，并舍弃隐层；</li>
<li>考虑到sofmax归一化需要遍历整个词汇表，采用<strong>hierarchical
softmax</strong> 和<strong>negative
sampling</strong>进行优化，<strong>hierarchical softmax
实质上生成一颗带权路径最小的哈夫曼树，让高频词搜索路劲变小；negative
sampling更为直接，实质上对每一个样本中每一个词都进行负例采样；</strong></li>
</ul>
<h4><span id="5-word2vec和fasttext对比有什么区别word2vecvs-fasttext">5、<strong>word2vec和fastText对比有什么区别？（word2vec
vs fastText）</strong></span></h4>
<ul>
<li>都可以无监督学习词向量，
<strong>fastText训练词向量时会考虑subword</strong>；</li>
<li>fastText还可以进行==有监督学习==进行文本分类，其主要特点：
<ul>
<li>结构与<strong>CBOW类似</strong>，但学习目标是<strong>人工标注的分类结果</strong>；</li>
<li>采用hierarchical
softmax对输出的分类标签建立哈夫曼树，样本中标签多的类别被分配短的搜寻路径；</li>
<li><strong>引入N-gram，考虑词序特征</strong>；</li>
<li><strong>引入subword来处理长词，处理未登陆词问题</strong>；</li>
</ul></li>
</ul>
<h4><span id="6-glove和word2vec-lsa对比有什么区别word2vec-vs-glove-vs-lsa"><strong>6、glove和word2vec、
LSA对比有什么区别？（word2vec vs glove vs LSA）</strong></span></h4>
<ul>
<li><p><strong>glove vs LSA</strong></p>
<ul>
<li><p>LSA（Latent Semantic Analysis）可以基于co-occurance
matrix构建词向量，实质上是基于全局语料采用SVD进行矩阵分解，然而SVD计算复杂度高；</p></li>
<li><p>glove可看作是对LSA一种优化的高效矩阵分解算法，采用Adagrad对最小平方损失进行优化；</p></li>
</ul></li>
<li><p>==<strong>word2vec vs glove</strong>==</p>
<ul>
<li><p><strong>word2vec是局部语料库训练的，其特征提取是基于滑窗的</strong>；而glove的滑窗是为了构建co-occurance
matrix，是基于全局语料的，可见glove需要事先统计共现概率；因此，word2vec可以进行在线学习，glove则需要统计固定语料信息。</p></li>
<li><p>word2vec是无监督学习，同样由于不需要人工标注；glove通常被认为是无监督学习，但实际上glove还是有label的，即共现次数<img src="https://www.zhihu.com/equation?tex=log%28X_%7Bij%7D%29" alt="[公式]">。</p></li>
<li><p><strong>word2vec损失函数实质上是带权重的交叉熵，权重固定</strong>；<strong>glove的损失函数是最小平方损失函数，权重可以做映射变换。</strong></p></li>
<li><p>总体来看，<strong>==glove可以被看作是更换了目标函数和权重函数的全局word2vec==</strong>。</p></li>
</ul></li>
</ul>
<h4><span id="7-elmo-gpt-bert三者之间有什么区别elmo-vs-gpt-vsbert"><strong><font color="red">
7、 elmo、GPT、bert三者之间有什么区别？（elmo vs GPT vs
bert）</font></strong></span></h4>
<p>之前介绍词向量均是静态的词向量，无法解决一次多义等问题。下面介绍三种elmo、GPT、bert词向量，它们都是基于语言模型的动态词向量。下面从几个方面对这三者进行对比：</p>
<ul>
<li><strong>特征提取器</strong>：elmo采用<strong>LSTM</strong>进行提取，GPT和bert则采用<strong>Transformer</strong>进行提取。很多任务表明<strong>Transformer特征提取能力强于LSTM</strong>，elmo采用1层静态向量+2层LSTM，多层提取能力有限，而GPT和bert中的==Transformer==可采用多层，并行计算能力强。</li>
<li><strong>单/双向语言模型</strong>：GPT采用单向语言模型，elmo和bert采用双向语言模型。但是elmo实际上是两个单向语言模型（方向相反）的拼接，这种融合特征的能力比bert一体化融合特征方式弱。<strong>GPT和bert都采用Transformer，Transformer是encoder-decoder结构，GPT的单向语言模型采用decoder部分，decoder的部分见到的都是不完整的句子；bert的双向语言模型则采用encoder部分，采用了完整句子。</strong></li>
</ul>
<h3><span id="二-深入解剖word2vec"><strong>二、深入解剖word2vec</strong></span></h3>
<h4><span id="1-word2vec的两种模型分别是什么"><strong>1、word2vec的两种模型分别是什么？</strong></span></h4>
<p><strong>word2Vec</strong> 有两种模型：<strong>CBOW</strong> 和
<strong>Skip-Gram：</strong></p>
<ul>
<li><strong>CBOW 在已知 <code>context(w)</code> 的情况下，预测
<code>w</code>；在CBOW中，投射层将词向量直接相加而不是拼接起来，并舍弃了隐层，这些牺牲都是为了减少计算量</strong>。</li>
<li>Skip-Gram在已知 <code>w</code> 的情况下预测 <code>context(w)</code>
；</li>
</ul>
<p><img src="https://pic4.zhimg.com/80/v2-f1194171ee403f95c4131137ea1b52b3_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<h4><span id="2-word2vec的两种优化方法是什么它们的目标函数怎样确定的训练过程又是怎样的">2、<strong>word2vec的两种优化方法是什么？它们的目标函数怎样确定的？训练过程又是怎样的？</strong></span></h4>
<p><strong>不经过优化的CBOW和Skip-gram中
,在每个样本中每个词的训练过程都要遍历整个词汇表</strong>，也就是都需要经过softmax归一化，计算误差向量和梯度以更新两个词向量矩阵（这两个词向量矩阵实际上就是最终的词向量，可认为初始化不一样），当语料库规模变大、词汇表增长时，训练变得不切实际。为了解决这个问题，word2vec支持两种优化方法：<strong>hierarchical
softmax</strong> 和<strong>negative
sampling</strong>。此部分仅做关键介绍，数学推导请仔细阅读《<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/itplus/article/details/37969519">word2vec
中的数学原理详解</a>》。</p>
<ul>
<li><strong>hierarchical softmax</strong></li>
</ul>
<p><strong>hierarchical softmax</strong>
使用一颗二叉树表示词汇表中的单词，每个单词都作为二叉树的叶子节点。对于一个大小为V的词汇表，其对应的二叉树包含V-1非叶子节点。假如每个非叶子节点向左转标记为1，向右转标记为0，那么每个单词都具有唯一的从根节点到达该叶子节点的由｛0
1｝组成的代号（<strong>实际上为哈夫曼编码，为哈夫曼树，是带权路径长度最短的树，哈夫曼树保证了词频高的单词的路径短，词频相对低的单词的路径长，这种编码方式很大程度减少了计算量</strong>）。</p>
<ul>
<li><strong>negative sampling（拒绝采样）</strong></li>
</ul>
<p>negative sampling是一种不同于hierarchical
softmax的优化策略，相比于hierarchical softmax，negative
sampling的想法更直接——<strong>为每个训练实例都提供负例。</strong></p>
<p><strong><font color="red">
负采样算法实际上就是一个带权采样过程，负例的选择机制是和单词词频联系起来的。</font></strong>具体做法是以
<code>N+1</code> 个点对区间 <code>[0,1]</code>
做非等距切分，并引入的一个在区间 <code>[0,1]</code> 上的 <code>M</code>
等距切分，其中 <code>M &gt;&gt; N。</code>源码中取 M =
10^8。然后对两个切分做投影，得到映射关系：采样时，每次生成一个 [1, M-1]
之间的整数 i，则 Table(i)
就对应一个样本；当采样到正例时，跳过（<strong>拒绝采样</strong>）。</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-36547a4cd05365292830ad4b22ba4c93_1440w.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic3.zhimg.com/80/v2-a788595cc2611b0bfdac9e039a2e82fe_1440w.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic1.zhimg.com/80/v2-cfe67c913af37a9435f3331139abeab8_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="三-深入解剖glove详解"><strong>三、深入解剖Glove详解</strong></span></h3>
<p><strong>GloVe的全称叫Global Vectors for Word
Representation，它是一个基于全局词频统计（count-based &amp; overall
statistics）的词表征（word representation）工具。</strong></p>
<p><strong>1、GloVe构建过程是怎样的？</strong></p>
<p>（1）根据语料库构建一个共现矩阵，矩阵中的每一个元素 <img src="https://www.zhihu.com/equation?tex=X_%7Bij%7D" alt="[公式]">
代表单词 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]">
和上下文单词 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]"> 在特定大小的上下文窗口内共同出现的次数。</p>
<blockquote>
<p>共现矩阵:统计文本中两两词组之间共同出现的次数</p>
</blockquote>
<p>（2）构建词向量（Word
Vector）和共现矩阵之间的近似关系，其目标函数为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=J+%3D+%5Csum_%7Bi%2Cj%3D1%7D%5EV+f%5CBig%28X_%7Bij%7D%5CBig%29%5CBig%28w_i%5ET%5Ctilde%7Bw_j%7D+%2B+b_i+%2B+b_j+-%5Clog%7BX_%7Bij%7D%7D+%5CBig%29%5E2" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>这个loss function的基本形式就是最简单的mean square
loss，只不过在此基础上加了一个权重函数 <img src="https://www.zhihu.com/equation?tex=f%28x_%7Bij%7D%29" alt="[公式]"> :</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=f%28x%29+%3D++%5Cbegin%7Bcases%7D+%28x%2Fx_%7B%5Cmax%7D%29%5E%5Calpha+%26+%5Ctext%7Bif+%7D+x%3Cx_%7B%5Cmax%7D+%5C%5C+1+%26+%5Ctext%7Botherwise.%7D+%5Cend%7Bcases%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>根据实验发现 <img src="https://www.zhihu.com/equation?tex=x_%7B%5Cmax%7D" alt="[公式]">
的值对结果的影响并不是很大，原作者采用了 <img src="https://www.zhihu.com/equation?tex=x_%7B%5Cmax%7D%3D100" alt="[公式]"> 。而 <img src="https://www.zhihu.com/equation?tex=%5Calpha%3D3%2F4" alt="[公式]"> 时的结果要比 <img src="https://www.zhihu.com/equation?tex=%5Calpha%3D1" alt="[公式]">
时要更好。下面是 <img src="https://www.zhihu.com/equation?tex=%5Calpha%3D3%2F4" alt="[公式]"> 时 <img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]">
的函数图象，可以看出对于较小的 <img src="https://www.zhihu.com/equation?tex=X_%7Bij%7D" alt="[公式]">
，权值也较小。这个函数图像如下所示：</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-2e2b198b3b7a7c4ace45648ff18dd2ca_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<blockquote>
<ol type="1">
<li>实质上还是监督学习：虽然glove不需要人工标注为无监督学习，但实质还是有label就是
<img src="https://www.zhihu.com/equation?tex=log%28X_%7Bij%7D%29" alt="[公式]"> 。</li>
<li>向量 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]">
和 <img src="https://www.zhihu.com/equation?tex=%5Ctilde%7Bw%7D" alt="[公式]">为学习参数，本质上与监督学习的训练方法一样，采用了AdaGrad的梯度下降算法，对矩阵
<img src="https://www.zhihu.com/equation?tex=X" alt="[公式]">
中的所有非零元素进行随机采样，学习曲率（learning
rate）设为0.05，在vector
size小于300的情况下迭代了50次，其他大小的vectors上迭代了100次，直至收敛。</li>
<li>最终学习得到的是两个词向量是 <img src="https://www.zhihu.com/equation?tex=%5Ctilde%7Bw%7D" alt="[公式]">
和 <img src="https://www.zhihu.com/equation?tex=w+" alt="[公式]">
，因为 <img src="https://www.zhihu.com/equation?tex=X" alt="[公式]">
是对称的（symmetric），所以从原理上讲<img src="https://www.zhihu.com/equation?tex=%5Ctilde%7Bw%7D" alt="[公式]">
和 <img src="https://www.zhihu.com/equation?tex=w+" alt="[公式]">
，是也是对称的，他们唯一的区别是初始化的值不一样，而导致最终的值不一样。所以这两者其实是等价的，都可以当成最终的结果来使用。但是为了提高鲁棒性，我们最终会选择两者之和
<img src="https://www.zhihu.com/equation?tex=w%2B%5Ctilde%7Bw%7D" alt="[公式]">
作为最终的vector（两者的初始化不同相当于加了不同的随机噪声，所以能提高鲁棒性）。</li>
</ol>
</blockquote>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-NLP（3）doc2vec（PV-DM）</title>
    <url>/posts/2VH87R4/</url>
    <content><![CDATA[<h2><span id="doc2vec">Doc2Vec</span></h2>
<blockquote>
<p>论文｜Doc2vec的算法原理、代码实现及应用启发 - Thinkgamer的文章 - 知乎
https://zhuanlan.zhihu.com/p/336921474</p>
</blockquote>
<p>Doc2vec主要为了解决word2vec只包含局部窗口内的语义信息的问题，在进行词向量表示的时候融入了句子的语义表示。</p>
<p><strong>Doc2vec其实包含了两种算法：</strong></p>
<ul>
<li>PV-DM（Distributed Memory Model of Paragraph
Vector）:PV-DM类似于Word2vec中的CBOW模型</li>
<li>PV-DBOW（Distributed Bag of Words version of Paragraph Vector）</li>
</ul>
<h4><span id="原理">原理</span></h4>
<p><strong>doc2vec与word2vec的不同点</strong>：在输入层增加了Paragraph
id向量，来作为句子的表示向量，该向量在<strong>同一句子的不同词训练</strong>中是<strong>权值共享</strong>的</p>
<p><strong>原因</strong>：在word2vec训练中，<strong>每次只会选择句子中窗口内的词来进行训练学习当前词的向量表达，而忽略了窗口外的词，最终的句子向量也只是每个词的简单累加，</strong>加入Paragraph
id向量在同一个句子的若干次训练中是共享的，所以同一句话会有多次训练，每次训练中输入都包含Paragraph
vector，它可以被看作是句子的主旨，这样训练在获得词向量的同时也能获得准确的句子向量表示。</p>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20220712163125902.png" alt="image-20220712163125902" style="zoom:50%;"></p>
<p><strong>PV-DM模型的输入是固定长度的，其从段落的上下文的滑动窗口中进行采样，这一点和Word2vec是一致的，在基于同一段落构造好的样本中，
段落的向量是共享的，但是在基于不同段落构造好的样本中，段落的向量是不共享的。在所有的样本中，word的向量是一致的（共享的）。</strong></p>
<p>在整个训练过程中，paragraph vector能够记忆整个句子的意义，word
vector则能够基于全局部分学习到其具体的含义。</p>
<h4><span id="训练">训练</span></h4>
<p>每次从一句话中滑动采样固定长度的词，取其中一个词作预测词，其他的作输入词。<strong>输入词对应的词向量word
vector和本句话对应的句子向量Paragraph
vector作为输入层的输入</strong>，将本句话的向量和本次采样的词向量相加求平均或者累加构成一个新的向量X，进而使用这个向量X预测此次窗口内的预测词（softmax）。</p>
<h4><span id="预测">预测</span></h4>
<p>首先将新句子对应的Paragraph
vector随机初始化，<strong>固定词向量还有投影层到输出层的softmax
weights参数</strong>，对句子中的单词进行预测，根据结果<strong>进行Paragraph
vector更新</strong>，获得最终的Paragraph vector。利用最终Paragraph
vector进行词向量预测。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-NLP（4）BERT*-P1</title>
    <url>/posts/1ZBPFBF/</url>
    <content><![CDATA[<h2><span id="self-supervisedlearningbert-p1">Self - supervised
Learning（BERT-P1）</span></h2>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613162648282.png" alt="image-20220613162648282" style="zoom:50%;"></p>
<p>每个人都应该熟悉监督学习，当我们做监督学习时，我们只有一个模型，这个模型的输入是x，输出是y。假设你今天想做情感分析，你就是让机器阅读一篇文章，而机器需要对这篇文章进行分类，是正面的还是负面的，你必须先找到大量的文章，你需要对所有的文章进行label。我们需要<strong>有标签和文章数据来训练监督模型</strong>。</p>
<p>"Self-supervised
"是用另一种方式来监督，没有标签。假设我们只有一堆没有label的文章，但我们试图找到一种方法把它<strong>分成两部分</strong>。我们让其中一部分作为模型的输入数据，另一部分作为标签。</p>
<h3><span id="masking-input">Masking Input</span></h3>
<p>Self-supervised
Learning是什么意思呢，我们直接拿BERT模型来说。<font color="red">
<strong>BERT是一个transformer的Encoder</strong>，我们已经讲过<strong>transformer</strong>了，我们也花了很多时间来介绍<strong>Encoder</strong>和<strong>Decoder</strong>，transformer中的Encoder它实际上是BERT的架构，它和transformer的Encoder完全一样，里面有很多<strong>Self-Attention</strong>和<strong>Residual
connection</strong>，还有Normalization等等，那么，这就是<strong>BERT</strong>。</font></p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613164111945.png" alt="image-20220613164111945" style="zoom:50%;"></p>
<p>如果你已经忘记了Encoder里有哪些部件，你需要记住的关键点是，<font color="red"><strong>BERT可以输入一行向量，然后输出另一行向量，输出的长度与输入的长度相同</strong>
</font>。
BERT一般用于自然语言处理，用于文本场景，所以一般来说，它的输入是一串文本，也是一串数据。</p>
<p>当我们真正谈论Self-Attention的时候，我们也说<strong>不仅文本是一种序列，而且语音也可以看作是一种序列，甚至图像也可以看作是一堆向量</strong>。BERT同样的想法是，不仅用于NLP，或者用于文本，它也可以用于语音和视频。</p>
<p>接下来我们需要做的是，随机<strong>盖住</strong>一些输入的文字，<strong>被mask的部分是随机决定的</strong>，例如，我们输入100个token，什么是token？<strong>在中文文本中，我们通常把一个汉字看作是一个token</strong>，当我们输入一个句子时，其中的一些词会被随机mask。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613164315477.png" alt="image-20220613164315477" style="zoom:50%;"></p>
<h4><span id="mask的具体实现有两种方法">mask的具体实现有<strong>两种方法</strong>：</span></h4>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613164327649.png" alt="image-20220613164327649" style="zoom:50%;"></p>
<ul>
<li>第一种方法是，用一个<strong>特殊的符号替换句子中的一个词</strong>，我们用
"MASK
"标记来表示这个特殊符号，你可以把它看作一个新字，这个字完全是一个新词，它不在你的字典里，这意味着mask了原文。</li>
<li>另外一种方法，<strong>随机</strong>把某一个字<strong>换成另一个字</strong>。中文的
"湾"字被放在这里，然后你可以选择另一个中文字来替换它，它可以变成 "一
"字，变成 "天 "字，变成 "大 "字，或者变成 "小
"字，我们只是用随机选择的某个字来替换它</li>
</ul>
<p>所以有两种方法来做mask，一种是添加一个特殊的标记
"MASK"，另一种是用一个字来替换某个字。</p>
<p>两种方法都可以使用。<strong>使用哪种方法也是随机决定的</strong>。因此，当BERT进行训练时，向BERT输入一个句子，<strong>先随机决定哪一部分的汉字将被mask</strong>。mask后，一样是输入一个序列，我们把BERT的相应输出看作是另一个序列，接下来，我们在输入序列中寻找mask部分的相应输出，然后，这个向量将通过一个==Linear
transform==。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613164413322.png" alt="image-20220613164413322" style="zoom:50%;"></p>
<p>所谓的Linear
transform是指，输入向量将与一个<strong>矩阵相乘</strong>，然后做softmax，输出一个分布。这与我们在Seq2Seq模型中提到的使用transformer进行翻译时的输出分布相同。输出是一个很长的向量，包含我们想要处理的每个汉字，每一个字都对应到一个分数。</p>
<p>在训练过程中。我们知道被mask的字符是什么，而BERT不知道，我们可以用一个one-hot
vector来表示这个字符，并使输出和one-hot vector之间的交叉熵损失最小。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613164503646.png" alt="image-20220613164503646" style="zoom:50%;"></p>
<p>或者说得简单一点，我们实际上是在解决一个<strong>分类问题</strong>。现在，BERT要做的是，<strong>预测什么被盖住</strong>。被掩盖的字符，属于
"湾"类。在训练中，我们<strong>在BERT之后添加一个线性模型</strong>，并将它们<strong>一起训练</strong>。所以，BERT里面是一个transformer的Encoder，它有一堆参数。这两个需要共同训练，并试图<strong>预测被覆盖的字符是什么</strong>，这叫做mask。</p>
<h3><span id="next-sentence-prediction">Next Sentence Prediction</span></h3>
<p>事实上，当我们训练BERT时，除了mask之外，我们还会使用另一种方法，这种额外的方法叫做==Next
Sentence Prediction== 。</p>
<p>它的意思是，我们从数据库中拿出两个句子，这是我们通过在互联网上抓取和搜索文件得到的大量句子集合，我们在这<strong>两个句子之间</strong>添加一个<strong>特殊标记</strong>。这样，BERT就可以知道，这两个句子是不同的句子，因为这两个句子之间有一个分隔符。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613165146926.png" alt="image-20220613165146926" style="zoom:50%;"></p>
<p><font color="red">
<strong>我们还将在句子的开头添加一个特殊标记，这里我们用CLS来表示这个特殊标记。</strong></font></p>
<p>现在，我们有一个很长的序列，包括<strong>两个句子</strong>，由SEP标记和前面的CLS标记分开。如果我们把它传给BERT，它应该输出一个序列，因为输入也是一个序列，这毕竟是Encoder的目的。我们将<strong>只看CLS的输出</strong>，我们将把它乘以一个Linear
transform。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613165244059.png" alt="image-20220613165244059" style="zoom:50%;"></p>
<p>现在它必须做一个<strong>二分类问题</strong>，有两个可能的输出：是或不是。这个方法被称为Next
Sentence Prediction ，所以我们需要预测，第二句是否是第一句的后续句。</p>
<p>然而，后来的研究发现，对于BERT要做的任务来说，<strong>Next Sentence
Prediction 并没有真正的帮助</strong>。例如，有一篇论文叫 "Robustly
Optimized BERT
Approach"，简称RoBERTa。在这篇论文中，它明确指出，实施Next Sentence
Prediction ，几乎没有任何帮助。然后，这个概念不知不觉地成为主流。</p>
<p>在这之后，另一篇论文说下一句话预测没有用，所以在它之后的许多论文也开始说它没有用。例如，SCAN-BERT和XLNet都说Next
Sentence Prediction 方法是无用的。它可能是无用的原因之一是，<strong>Next
Sentence Prediction 太简单了</strong>，是一项容易的任务。</p>
<p>这个任务的典型方法是，首先随机选择一个句子，然后从数据库中或随机选择要与前一个句子相连的句子。通常，当我们随机选择一个句子时，它看起来与前一个句子有很大不同。对于BERT来说，预测两个句子是否相连并不是太难。因此，在训练BERT完成Next
Sentence Prediction
的任务时，<strong>没有学到什么太有用的东西</strong>。</p>
<p>还有一种类似于Next Sentence Prediction
的方法，它在纸面上看起来更有用，它被称为==<strong>Sentence order
prediction</strong>==，简称<strong>SOP</strong>。</p>
<p>这个方法的主要思想是，我们最初挑选的两个句子可能是相连的。可能有两种可能性：要么句子1在句子2后面相连，要么句子2在句子1后面相连。有两种可能性，我们问BERT是哪一种。</p>
<p>也许因为这个任务更难，它似乎更有效。它被用在一个叫ALBERT的模型中，这是BERT的高级版本。由于ALBERT这个名字与爱因斯坦相似，我在幻灯片中放了一张爱因斯坦的图片。</p>
<h4><span id="bert学了什么">BERT学了什么？</span></h4>
<p>当我们训练时，我们要求BERT学习两个任务。</p>
<ul>
<li><p>一个是掩盖一些字符，具体来说是汉字，然后要求它填补缺失的字符。</p></li>
<li><p>另一个任务表明它能够预测两个句子是否有顺序关系。</p></li>
</ul>
<p><strong><font color="red">
所以总的来说，BERT它学会了如何填空。BERT的神奇之处在于，在你训练了一个填空的模型之后，它还可以用于其他任务。这些任务不一定与填空有关</font></strong>，也可能是完全不同的任务，但BERT仍然可以用于这些任务，这些任务是BERT实际使用的任务，它们被称为==<strong>Downstream
Tasks</strong>==(下游任务)，以后我们将谈论一些Downstream Tasks
的例子。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613165843213.png" alt="image-20220613165843213" style="zoom:50%;"></p>
<p>所谓的 "Downstream Tasks
"是指，你真正关心的任务。但是，当我们想让BERT学习做这些任务时，我们仍然<strong>需要一些标记的信息</strong>。</p>
<p>总之，BERT只是学习填空，但是，以后可以用来做各种你感兴趣的Downstream
Tasks
。它就像胚胎中的干细胞,它有各种无限的潜力，虽然它还没有使用它的力量,它只能填空,但以后它有能力解决各种任务。我们只需要给它一点数据来激发它，然后它就能做到。</p>
<h4><span id="bert怎么测试性能">BERT怎么测试性能？</span></h4>
<p><font color="red"><strong>BERT分化成各种任务的功能细胞，被称为==Fine-tune==(微调)</strong>
</font>。所以，我们经常听到有人说，他对BERT进行了微调，也就是说他手上有一个BERT，他对这个BERT进行了微调，使它能够完成某种任务，与微调相反，在微调之前产生这个BERT的过程称为==预训练==。<strong>所以，生成BERT的过程就是Self-supervised学习。但是，你也可以称之为预训练</strong>。</p>
<p>好的，在我们谈论如何微调BERT之前，我们应该先看看它的能力。今天，为了测试Self-supervised学习的能力，通常，你会在<strong>多个任务上测试</strong>它。因为我们刚才说，BERT就像一个胚胎干细胞，它要分化成各种任务的功能细胞，我们通常不会只在一个任务上测试它的能力，你会让这个BERT分化成各种任务的功能细胞，看看它在每个任务上的准确性，然后我们取其平均值，得到一个总分。这种不同任务的集合，，我们可以称之为任务集。任务集中最著名的基准被称为==GLUE==，它是<strong>General
Language Understanding Evaluation</strong>的缩写。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613170138102.png" alt="image-20220613170138102" style="zoom: 50%;"></p>
<p>在GLUE中，总共有9个任务。一般来说，你想知道像BERT这样的模型是否被训练得很好。所以，你实际上会得到9个模型，用于9个单独的任务。你看看这<strong>9个任务的平均准确率</strong>，然后，你得到一个值。这个值代表这个Self-supervised模型的性能。让我们看看BERT在GLUE上的性能。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613170213354.png" alt="image-20220613170213354" style="zoom:50%;"></p>
<p>有了BERT，GLUE得分，也就是9个任务的平均得分，确实逐年增加。在这张图中，,横轴表示不同的模型，这里列出了，你可以发现，除了ELMO和GPT，其他的还有很多BERT，各种BERT。</p>
<p><strong>黑色的线</strong>，表示<strong>人类的工作</strong>，也就是人类在这个任务上的准确度，那么，我们把这个当作1，这里每一个点代表一个任务，那么，你为什么要和人类的准确度进行比较呢？</p>
<p>人类的准确度是1，如果他们比人类好，这些点的值就会大于1，如果他们比人类差，这些点的值就会小于1，这是因为这些任务，其评价指标可能不是准确度。每个任务使用的评价指标是不同的，它可能不是准确度。如果我们只是比较它们的值，可能是没有意义的。所以，这里我们看的是人类之间的差异。所以，你会发现，在原来的9个任务中，只有1个任务，机器可以比人类做得更好。随着越来越多的技术被提出，越来越多的,还有3个任务可以比人类做得更好。对于那些远不如人类的任务，,它们也在逐渐追赶。</p>
<p><strong>蓝色曲线</strong>表示机器<strong>GLUE得分的平均值</strong>。还发现最近的一些强势模型，例如XLNET，甚至超过了人类。当然，这只是这些数据集的结果，并不意味着机器真的在总体上超过了人类。它<strong>在这些数据集上超过了人类</strong>。这意味着这些数据集并不能代表实际的表现，而且难度也不够大。所以，在GLUE之后，有人做了Super
GLUE。他们找到了更难的自然语言处理任务，让机器来解决。好了！展示这幅图的意义主要是告诉大家，有了BERT这样的技术，机器在自然语言处理方面的能力确实又向前迈进了一步。</p>
<h2><span id="how-to-use-bert">How to use BERT</span></h2>
<h3><span id="case-1-sentiment-analysis">Case 1： Sentiment analysis</span></h3>
<p>第一个案例是这样的，我们假设我们的Downstream Tasks
是输入一个序列，然后输出一个class，这是一个分类问题。比如说
<strong>Sentiment analysis
情感分析</strong>，就是给机器一个句子，让它判断这个句子是正面的还是负面的。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613170630474.png" alt="image-20220613170630474" style="zoom: 50%;"></p>
<h4><span id="对于bert来说它是如何解决情感分析的问题的">对于BERT来说，它是如何解决情感分析的问题的？</span></h4>
<p>你只要给它一个句子，也就是你想用它来判断情绪的句子，然后把<strong>CLS标记放在这个句子的前面</strong>，我刚才提到了CLS标记。<font color="red">
我们把CLS标记放在前面，扔到BERT中,这<strong>4个输入实际上对应着4个输出</strong>。然后，我们<strong>只看CLS的部分。</strong>CLS在这里输出一个向量，我们对它进行<strong>Linear
transform</strong>，也就是将它乘以一个Linear
transform的矩阵，这里省略了Softmax。</font></p>
<p>然而，在实践中，你必须为你的Downstream Tasks
提供<strong>标记数据</strong>，换句话说，<strong>BERT没有办法从头开始解决情感分析问题，你仍然需要向BERT提供一些标记数据，你需要向它提供大量的句子，以及它们的正负标签，来训练这个BERT模型。</strong></p>
<p>在训练的时候，<strong>Linear
transform</strong>和<strong>BERT模型</strong>都是利用Gradient
descent来更新参数的。</p>
<ul>
<li><font color="red"> Linear
transform的参数是<strong>随机初始化</strong>的</font></li>
<li><font color="red">
而BERT的参数是由<strong>学会填空的BERT初始化</strong>的。</font></li>
</ul>
<p>每次我们训练模型的时候，我们都要初始化参数，我们利用梯度下降来更新这些参数，然后尝试minimize
loss，例如，我们正在做情感分类，但是，我们现在有BERT。我们不必随机初始化所有的参数。,我们唯一随机初始化的部分是Linear这里。BERT的骨干是一个巨大的transformer的Encoder。这个网络的参数不是随机初始化的。把学过填空的BERT参数，放到这个地方的BERT中作为参数初始化。</p>
<h4><span id="我们为什么要这样做呢为什么要用学过填空的bert再放到这里呢">我们为什么要这样做呢？为什么要用学过填空的BERT，再放到这里呢？</span></h4>
<p><font color="red">
<strong>最直观和最简单的原因是，它比随机初始化新参数的网络表现更好。当你把学会填空的BERT放在这里时，它将获得比随机初始化BERT更好的性能。</strong></font></p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613171706649.png" alt="image-20220613171706649" style="zoom:50%;"></p>
<p>在这里有篇文章中有一个例子。横轴是训练周期，纵轴是训练损失，到目前为止，大家对这种图一定很熟悉，随着训练的进行，损失当然会越来越低，这个图最有趣的地方是，有各种任务。我们不会解释这些任务的细节，我只想说明有各种任务。</p>
<ul>
<li>"fine-tune"是指模型被用于预训练，这是网络的BERT部分。该部分的参数是由学习到的BERT的参数来初始化的，以填补空白。</li>
<li>scratch表示整个模型，包括BERT和Encoder部分都是随机初始化的。</li>
</ul>
<p>首先，在训练网络时，scratch与用学习填空的BERT初始化的网络相比，<strong>损失下降得比较慢</strong>，最后，用随机初始化参数的网络的损失仍然高于用学习填空的BERT初始化的参数。</p>
<ul>
<li>当你进行Self-supervised学习时，你使用了大量的<strong>无标记数据</strong>。</li>
<li>另外，Downstream Tasks 需要少量的<strong>标记数据</strong>。</li>
</ul>
<p>所谓的 "半监督
"是指，你有大量的无标签数据和少量的有标签数据，这种情况被称为
"半监督"，所以使用BERT的整个过程是连续应用Pre-Train和Fine-Tune，它可以被视为一种半监督方法。</p>
<h3><span id="case-2-pos-tagging">Case 2 ：POS tagging</span></h3>
<p>第二个案例是，输入一个序列，然后输出另一个序列，而输入和输出的长度是一样的。我们在讲Self-Attention的时候，也举了类似的例子。
例如，==POS tagging==。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613172015343.png" alt="image-20220613172015343" style="zoom:50%;"></p>
<p>POS
tagging的意思是词性标记。你给机器一个句子，它必须告诉你这个句子中每个词的词性，即使这个词是相同的，也可能有不同的词性。</p>
<p>你只需向BERT输入一个句子。之后，对于这个句子中的每一个标记，它是一个中文单词，有一个代表这个单词的相应向量。然后，这些向量会依次通过Linear
transform和Softmax层。最后，网络会预测给定单词所属的类别，例如，它的词性。</p>
<p>当然，类别取决于你的任务，如果你的任务不同，相应的类别也会不同。接下来你要做的事情和案例1完全一样。换句话说，你需要有一些标记的数据。这仍然是一个典型的分类问题。唯一不同的是，BERT部分，即网络的Encoder部分，其参数不是随机初始化的。在<strong>预训练过程中，它已经找到了不错的参数</strong>。</p>
<p>当然，我们在这里展示的例子属于自然语言处理。但是，你可以把这些例子改成<strong>其他任务</strong>，例如，你可以把它们改成语音任务，或者改成计算机视觉任务。我在Self-supervised
Learning一节中提到，语音、文本和图像都可以表示为一排向量。虽然下面的例子是文字，但这项技术<strong>不仅限于处理文字</strong>，它还可以用于其他任务，如计算机视觉。</p>
<h3><span id="case-3natural-languageinference">Case 3：Natural Language
Inference</span></h3>
<p>在案例3中，模型输入两个句子，输出一个类别。好了，第三个案例以两个句子为输入，输出一个类别，什么样的任务采取这样的输入和输出？
最常见的是Natural Language Inference ，它的缩写是NLI</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613172722820.png" alt="image-20220613172722820" style="zoom:50%;"></p>
<p>机器要做的是判断，是否有可能<strong>从前提中推断出假设</strong>。这个前提与这个假设相矛盾吗？或者说它们不是相矛盾的句子？</p>
<p>在这个例子中，我们的前提是，一个人骑着马，然后他跳过一架破飞机，这听起来很奇怪。但这个句子实际上是这样的。这是一个基准语料库中的例子。</p>
<p>这里的<strong>假设</strong>是，这个人在一个餐馆。所以<strong>推论</strong>说这是一个<strong>矛盾</strong>。</p>
<p>所以机器要做的是，把两个句子作为输入，并输出这两个句子之间的关系。这种任务很常见。它可以用在哪里呢？例如，舆情分析。给定一篇文章，下面有一个评论，这个消息是同意这篇文章，还是反对这篇文章？该模型想要预测的是每条评论的位置。事实上，有很多应用程序接收两个句子，并输出一个类别。</p>
<p>BERT是如何解决这个问题的？你只要给它两个句子，我们在这两个句子之间放一个<strong>特殊的标记</strong>，并在最开始放CLS标记。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613172928476.png" alt="image-20220613172928476" style="zoom:50%;"></p>
<p>这个序列是BERT的输入。但我们只把CLS标记作为Linear
transform的输入。它决定这两个输入句子的类别。对于NLI，你必须问，这两个句子是否是矛盾的。它是用一些<strong>预先训练好的权重来初始化的</strong>。</p>
<h3><span id="case4extraction-based-question-answering-qa">Case
4：Extraction-based Question Answering (QA)</span></h3>
<p>如果你不理解前面的案例，就忘掉它们。这第四个案例，就是我们在作业7中要做的。作业7是一个问题回答系统。也就是说，在机器读完一篇文章后，你问它一个问题，它将给你一个答案。</p>
<p>但是，这里的问题和答案稍有限制。这是Extraction-based的QA。也就是说，我们假设<strong>答案必须出现在文章</strong>中。答案必须是文章中的一个片段。</p>
<p>在这个任务中，一个输入序列包含<strong>一篇文章</strong>和<strong>一个问题</strong>，文章和问题都是一个<strong>序列</strong>。对于中文来说，每个d代表一个汉字，每个q代表一个汉字。你把d和q放入QA模型中，我们希望它输出<strong>两个正整数s和e</strong>。根据这两个正整数，我们可以直接从文章中<strong>截取一段</strong>，它就是答案。这个片段就是正确的答案。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613173207333.png" alt="image-20220613173207333" style="zoom:50%;"></p>
<p>这听起来很疯狂，但是，这是现在使用的一个相当标准的方法。六年前，当我第一次听说这个机制可以解决QA任务时，我简直不敢相信。但是，无论如何，这是今天一个非常普遍的方法。</p>
<p>好吧，如果你仍然不明白我在说什么，更具体地说，这里有一个问题和一篇文章，正确答案是
"gravity"。机器如何输出正确答案？</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613173414502.png" alt="image-20220613173414502" style="zoom:50%;"></p>
<p>你的保证模型应该输出，s等于17，e等于17，来表示gravity。因为它是整篇文章中的第17个词，所以s等于17，e等于17，意味着输出第17个词作为答案。或者举另一个例子，答案是，"within
a
cloud"，这是文章中的第77至79个词。你的模型要做的是，输出77和79这两个正整数，那么文章中从第77个词到第79个词的分割应该是最终的答案。这就是作业7要你做的。当然，我们不是从头开始训练QA模型，为了训练这个QA模型，我们<strong>使用BERT预训练的模型</strong>。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613173621416.png" alt="image-20220613173621416" style="zoom:50%;"></p>
<p>这个解决方案是这样的。对于BERT来说，你必须向它展示一个问题，一篇文章，以及在问题和文章之间的一个特殊标记，然后我们在开头放一个CLS标记。在这个任务中，你唯一需要<strong>从头训练</strong>的只有<strong>两个向量</strong>。"从头训练
"是指<strong>随机初始化</strong>。这里我们用橙色向量和蓝色向量来表示，这两个向量的长度与BERT的输出相同。假设BERT的输出是768维的向量，这两个向量也是768维的向量。那么，如何使用这两个向量？</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613173644376.png" alt="image-20220613173644376" style="zoom:50%;"></p>
<p>首先,计算这个<strong>橙色向量</strong>和那些与文件相对应的<strong>输出向量的内积</strong>,由于有3个代表文章的标记,它将输出三个向量,计算这三个向量与橙色向量的内积,你将得到三个值,然后将它们通过softmax函数,你将得到另外三个值。</p>
<p>这个内积<strong>和attention很相似</strong>，你可以把橙色部分看成是query，黄色部分看成是key，这是一个attention，那么我们应该尝试找到分数最大的位置，就是这里，橙色向量和d2的内积，如果这是最大值，s应该等于2，你输出的起始位置应该是2蓝色部分做的是完全一样的事情。</p>
<figure>
<img src="../../../../../../Library/Application%20Support/typora-user-images/image-20220613173749525.png" alt="image-20220613173749525">
<figcaption aria-hidden="true">image-20220613173749525</figcaption>
</figure>
<p>蓝色部分代表答案的终点，我们计算这个蓝色向量与文章对应的黄色向量的内积，然后，我们在这里也使用softmax，最后，找到最大值，如果第三个值是最大的，e应该是3，正确答案是d2和d3。</p>
<p>因为答案必须在文章中，如果<strong>答案不在文章中，你就不能使用这个技巧</strong>。这就是一个QA模型需要做的。注意，这两个向量是随机初始化的,而BERT是通过它预先训练的权重初始化的。</p>
<h2><span id="qampa">Q&amp;A</span></h2>
<p><strong>Q：</strong>==<font color="red"><strong>BERT的输入长度有限制吗？</strong>
</font>==</p>
<p><strong>A：</strong>理论上，没有。在现实中，是的，在理论上，因为BERT模型，是一个transformer的Encoder，所以它可以输入很长的序列，只要你必须能够做Self-Attention，但Self-Attention的计算复杂性是非常高的。所以你会发现，在实践中，<strong>BERT实际上不能输入太长的序列，你最多可以输入512长度的序列，如果你输入一个512长度的序列，Self-Attention在中间就要产生512乘以512大小的Attention
Metric</strong>，那么你可能会被计算所淹没。所以实际上它的长度不是无限的。在助教的程序中，已经为大家处理了这个问题。我们限制了BERT的输入长度，而且用一篇文章来训练需要很长的时间。然后每次，我们只取其中的一段进行训练。我们不会将整篇文章输入BERT。因为你想要的距离太长了，你的训练会有问题。</p>
<p><strong>Q：</strong> "它与填空题有什么关系？</p>
<p><strong>A：</strong>",哇，这个问题很好。,你会认为这个填空题只是一个填空题。但我要在这里做一个Q&amp;A。,这两件事之间有什么关系呢？这里先卖个关子，待会会试着回答你。</p>
<h2><span id="training-bert-is-challenging">Training BERT is challenging!</span></h2>
<p>BERT是这样一个著名的模型，它可以做任何事情，那么你可能会认为BERT，在预训练中，它只是填空题，但是，<strong>你自己真的不能把它训练起来</strong>。</p>
<p>首先，谷歌最早的BERT,它使用的<strong>数据规模已经很大</strong>了,它的数据中包含了30亿个词汇,30亿个词汇有多少？,是《哈利波特全集》的3000倍。,《哈利波特全集》大约是100万个词汇。,那么谷歌在训练BERT时，最早的BERT，它使用的数据量是《哈利波特全集》的3000倍。</p>
<p>所以你处理起来会比较痛苦,<strong>更痛苦的是训练过程</strong>,为什么我知道训练过程是痛苦的呢,因为我们实验室有一个学生,他其实是助教之一,他自己试着训练一个BERT,他觉得他不能重现谷歌的结果,好,那么在这个图中,纵轴代表GLUE分数,我们刚才讲到GLUE,对吧?有9个任务，平均有9个任务，,平均分数就叫GLUE分数,好的，那么蓝线就是，谷歌原来的BERT的GLUE分数。</p>
<p>那么我们的目标其实不是实现BERT，我们的目标是实现ALBERT。ALBERT是一个高级版本，是橙色的线，蓝线是我们自己训练的ALBERT，但是我们实际训练的不是最大版本，BERT有一个base版本和一个large版本。对于大版本，我们很难自己训练它，所以我们尝试用最小的版本来训练，看它是否与谷歌的结果相同。</p>
<p>你可能会说这30亿个数据，30亿个词似乎有很多数据。实际上，因为它是无标签数据，所以你只是从互联网上整理了一堆文本，有相同的信息量。所以你要<strong>爬上这个级别的信息并不难，难的是训练过程</strong></p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613174300000.png" alt="image-20220613174300000" style="zoom:50%;"></p>
<p>好的，这个横轴是训练过程，参数更新多少次，大约一百万次的更新，需要多长时间，用TPU运行8天，所以你的TPU要运行8天，如果你在Colab上做，这个至少要运行200天，你甚至可能到明年才能得到结果。</p>
<p>所以，你真的很难自己训练这种BERT模型。幸运的是，作业只是对它进行微调。你可以在Colab上进行微调，在Colab上微调BERT只需要半小时到一小时。但是，如果你想从头开始训练它，也就是说，训练它做填空题，这将需要大量的时间，而且，你不能在Colab上自己完成它。</p>
<h2><span id="bert-embryology-胚胎學">BERT Embryology (胚胎學)</span></h2>
<p>谷歌已经训练了BERT，而且这些Pre-Train模型是公开的，我们自己训练一个，结果和谷歌的BERT差不多，这有什么意义呢？其实是想建立==BERT胚胎学==。"BERT胚胎学是什么意思？"</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613174341275.png" alt="image-20220613174341275" style="zoom:50%;">我们知道在BERT的训练过程中需要非常大的计算资源，所以我们想知道有没有可能，<strong>节省这些计算资源</strong>？有没有可能让它训练得更快？,要知道如何让它训练得更快，也许我们可以从观察它的训练过程开始。</p>
<p>过去没有人观察过BERT的训练过程。因为在谷歌的论文中，他们只是告诉你，我有这个BERT。然后它在各种任务中做得很好。</p>
<p>BERT在学习填空的过程中，学到了什么？"它在这个过程中何时学会填动词？什么时候学会填名词？
什么时候学会填代词？ 没有人研究过这个问题。</p>
<p>所以我们自己训练BERT后，可以观察到BERT什么时候学会填什么词汇，它是如何提高填空能力的？
好了，细节不是这门课的重点，所以我不在这里讲了。我把论文的链接https://arxiv.org/abs/2010.02480放在这里，供大家参考。不过可以提前爆冷一下就是：事实和你直观想象的不一样。</p>
<h2><span id="pre-training-a-seq2seq-model">Pre-training a seq2seq model</span></h2>
<p>我们补充一点，上述的任务都不包括，Seq2Seq模型，如果我们要解决，Seq2Seq模型呢？BERT只是一个预训练Encoder，有没有办法预训练Seq2Seq模型的Decoder？</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613174910438.png" alt="image-20220613174910438" style="zoom:50%;"></p>
<p>有，你就说我有一个Seq2Seq模型，有一个transformer，还有一个Encoder和Decoder。输入是一串句子，输出是一串句子，中间用Cross
Attention连接起来，然后你故意在Encoder的输入上做一些<strong>干扰来破坏它</strong>，我以后会具体告诉你我说的
"破坏 "是什么意思</p>
<p>Encoder看到的是被破坏的结果，那么Decoder应该输出句子被破坏前的结果，训练这个模型实际上是预训练一个Seq2Seq模型。</p>
<h4><span id="有一篇论文叫mass">有一篇论文叫<strong>MASS</strong>：</span></h4>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613174937690.png" alt="image-20220613174937690" style="zoom:50%;"></p>
<p>在MASS中，它说破坏的方法是，就像BERT做的那样，只要遮住一些地方就可以了，然后有各种方法来破坏它，比如，删除一些词，打乱词的顺序，旋转词的顺序。或者插入一个MASK，再去掉一些词。总之，有各种方法。在破坏了输入的句子之后，它可以通过Seq2Seq模型来恢复它。</p>
<p>你可能会问,有那么多的<strong>mask方法</strong>,哪种方法更好呢?也许你想自己做一些实验来试试,让我告诉你,你不需要做,谷歌为你做的,有一篇论文叫T5。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220613175206776.png" alt="image-20220613175206776" style="zoom:50%;"></p>
<p><strong>T5的全称是Transfer Text-To-Text
Transformer，有五个T，所以叫T5。在这个T5里面，它只是做了各种尝试，它做了你能想象的所有组合。</strong>这篇论文有67页，你可以回去读一下，看看结论。</p>
<p>T5是在一个语料库上训练的，叫 "Colossal Clean Crawled
Corpus"，对于这个数据集，Colossal就是巨无霸，就是非常巨大的意思，它叫C4，你用C4来训练T5，大家都是命名高手。这个命名非常强大，这个C4有多大？</p>
<p>C4是一个公共数据集，你可以下载它，它是公共的，但是它的原始文件大小是7TB，你可以下载它，但是你不知道把它保存在哪里，加载之后，你可以通过脚本做预处理，由谷歌提供。这个脚本有一个文件，我看到它在网站上发布了，语料库网站上的文件说，用一个GPU做预处理需要355天，你可以下载它，但你在预处理时有问题。所以，你可以发现，在深度学习中，数据量和模型都很惊人。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-NLP（4）BERT*-P2</title>
    <url>/posts/3KV4V6N/</url>
    <content><![CDATA[<h1><span id="fun-facts-about-bert">Fun Facts about BERT</span></h1>
<h4><span id="why-does-bert-work">Why does BERT work?</span></h4>
<p>"为什么BERT有用？"最常见的解释是，当输入一串文本时，每个文本都有一个对应的向量。对于这个向量，我们称之为<strong>embedding</strong>。</p>
<p><img src="image-20220613180116363.png" alt="image-20220613180116363" style="zoom:50%;"></p>
<p>它的特别之处在于，这些向量代表了<strong>输入词</strong>的<strong>含义</strong>。例如，模型输入
"台湾大学"（国立台湾大学），输出4个向量。这4个向量分别代表
"台"、"湾"、"大 "和
"学"。更具体地说，如果你把这些词所对应的向量画出来，或者计算它们之间的<strong>距离</strong>。</p>
<p><img src="image-20220613180203638.png" alt="image-20220613180203638" style="zoom:50%;"></p>
<p>你会发现，<strong>意思比较相似的词</strong>，它们的<strong>向量比较接近</strong>。例如，水果和草都是植物，它们的向量比较接近。但这是一个假的例子，我以后会给你看一个真正的例子。"鸟
"和 "鱼 "是动物，所以它们可能更接近。</p>
<p>你可能会问，中文有歧义，其实不仅是中文，很多语言都有歧义，<strong>BERT可以考虑上下文</strong>，所以，同一个词，比如说
"苹果"，它的上下文和另一个 "苹果 "不同，它们的向量也不会相同。</p>
<p>水果 "苹果 "和手机 "苹果 "都是
"苹果"，但根据上下文，它们的<strong>含义是不同</strong>的。所以，它的<strong>向量和相应的embedding会有很大不同</strong>。水果
"苹果 "可能更接近于 "草"，手机 "苹果 "可能更接近于 "电"。</p>
<p><strong>现在我们看一个真实的例子</strong>。假设我们现在考虑 "苹果
"这个词，我们会收集很多有 "苹果 "这个词的句子，比如
"喝苹果汁"、"苹果Macbook "等等。然后，我们把这些句子放入BERT中。</p>
<p><img src="image-20220613180822924.png" alt="image-20220613180822924" style="zoom:50%;"></p>
<p>接下来，我们将计算 "苹果 "一词的相应embedding。输入
"喝苹果汁"，得到一个 "苹果
"的向量。为什么不一样呢？在Encoder中存在Self-Attention，所以根据 "苹果
"一词的不同语境，得到的向量会有所不同。接下来，我们计算这些结果之间的==cosine
similarity==，即计算它们的相似度。结果是这样的，这里有10个句子：</p>
<p><img src="image-20220613180921490.png" alt="image-20220613180921490" style="zoom:50%;"></p>
<ul>
<li><p>前5个句子中的 "苹果
"代表<strong>可食用</strong>的苹果。例如，第一句是
"我今天买了苹果吃"，第二句是 "进口富士苹果平均每公斤多少钱"，第三句是
"苹果茶很难喝"，第四句是 "智利苹果的季节来了"，第五句是
"关于进口苹果的事情"，这五个句子都有 "苹果 "一词，</p></li>
<li><p>后面五个句子也有 "苹果
"一词，但提到的是<strong>苹果公司</strong>的苹果。例如，"苹果即将在下个月发布新款iPhone"，"苹果获得新专利"，"我今天买了一部苹果手机"，"苹果股价下跌"，"苹果押注指纹识别技术"，共有十个
"苹果"</p></li>
</ul>
<p>计算每一对之间的相似度，得到一个10×10的矩阵。<strong>相似度越高，这个颜色就越浅</strong>。所以，自己和自己之间的相似度一定是最大的，自己和别人之间的相似度一定是更小的。但前五个
"苹果 "和后五个 "苹果 "之间的相似度相对较低。<font color="red">
<strong>BERT知道，前五个 "苹果
"是指可食用的苹果，所以它们比较接近。最后五个 "苹果
"指的是苹果公司，所以它们比较接近。所以BERT知道，上下两堆 "苹果
"的含义不同</strong>。</font></p>
<p>BERT的这些向量是输出向量，每个向量代表该词的含义。BERT在填空的过程中已经学会了每个汉字的意思。",也许它真的理解了中文，对它来说，汉字不再是毫无关联的，既然它理解了中文，它就可以在接下来的任务中做得更好。</p>
<p>那么接下来你可能会问，"为什么BERT有如此神奇的能力？",为什么......,为什么它能输出代表输入词含义的向量？
这里，约翰-鲁伯特-弗斯，一位60年代的语言学家，提出了一个假说。他说，要知道一个词的意思，我们需要看它的
"<strong>Company</strong>"，也就是经常和它<strong>一起出现的词汇</strong>，也就是它的<strong>上下文</strong>。</p>
<p><img src="image-20220613181131296.png" alt="image-20220613181131296" style="zoom:50%;"></p>
<p>一个词的意思，取决于它的上下文</p>
<ul>
<li><p>所以以苹果（apple）中的果字为例。如果它经常与 "吃"、"树
"等一起出现，那么它可能指的是可食用的苹果。</p></li>
<li><p>如果它经常与电子、专利、股票价格等一起出现，那么它可能指的是苹果公司。</p></li>
</ul>
<p>当我们训练BERT时，我们给它w1、w2、w3和w4，我们覆盖w2，并告诉它预测w2，而它就是从上下文中提取信息来预测w2。所以这个向量是其上下文信息的精华，可以用来预测w2是什么。</p>
<p><font color="red"> <strong>这样的想法在BERT之前已经存在了。在word
embedding中，有一种技术叫做CBOW</strong>。</font></p>
<p><img src="image-20220613181612756.png" alt="image-20220613181612756" style="zoom:50%;"></p>
<p>CBOW所做的，与BERT完全一样。做一个空白，并要求它预测空白处的内容。这个CBOW，这个word
embedding技术，可以给每个词汇一个向量，代表这个词汇的意义。</p>
<p>CBOW是一个非常简单的模型，它使用两个变换，是一个<strong>非常简单的模型</strong>，有人会问，"为什么它只使用两个变换？"，"它可以更复杂吗？"，CBOW的作者，Thomas
Mikolov，曾经来到台湾。当时我在上课的时候，经常有人问我，为什么CBOW只用线性，为什么不用深度学习，我问过Thomas
Mikolov这个问题，他说可以用深度学习，但是之所以选择线性模型，一个简单的模型，最大的担心，其实是<strong>算力问题</strong>。当时的计算能力和现在不在一个数量级上，可能是2016年的时候，几年前的技术也不在一个数量级上，当时要训练一个非常大的模型还是比较困难的，所以他选择了一个比较简单的模型。</p>
<p><font color="red">
<strong>今天，当你使用BERT的时候，就相当于一个深度版本的CBOW</strong></font>。你可以做更复杂的事情，而且<strong>BERT还可以根据不同的语境，从同一个词汇产生不同的embedding</strong>。因为它是一个考虑到语境的高级版本的词embedding，BERT也被称为Contextualized
embedding，这些由<strong>BERT提取的向量或embedding被称为Contextualized
embedding</strong>，希望大家能接受这个答案。</p>
<h4><span id="但是这个答案它真的是真的吗">但是，这个答案，它真的是真的吗？</span></h4>
<p>这是你在文献中听到最多的答案。当你和别人讨论BERT时，这是大多数人都会告诉你的理由。它真的是真的吗？这里有一个难以理解的，由我们实验室的一个学生做的实验。实验是这样的：<strong>我们应用为文本训练的BERT对蛋白质、DNA链和音乐进行分类</strong>。</p>
<p><img src="image-20220613182040464.png" alt="image-20220613182040464" style="zoom:50%;"></p>
<p>让我们以DNA链的分类为例。DNA是一系列的脱氧核团核酸，有四种，分别用A、T、C和G表示，所以一条DNA链是这样的。你可能会问，"EI
IE和N代表什么？"不要在意细节，我也不知道，总之，这是一个分类问题。只要用训练数据和标记数据来训练它，就可以了。神奇的部分来了，DNA可以用ATCG来表示，现在，我们要用BERT来对DNA进行分类：</p>
<p><img src="image-20220613182514103.png" alt="image-20220613182514103" style="zoom:50%;"></p>
<p>例如，"A "是 "we"，"T "是 "you"，"C "是 "he"，"G "是
"she"。对应的词并不重要，你可以随机生成。"A "可以对应任何词汇，"T"、"C
"和 "G "也可以，这并不重要，对结果影响很小。只是这串文字无法理解。</p>
<p>例如，"AGAC "变成了 "we she we
he"，不知道它在说什么。然后，把它扔进一个一般的BERT，用CLS标记，一个输出向量，一个Linear
transform，对它进行分类。只是分类到了DNA类,我不知道他们是什么意思。和以前一样，Linear
transform使用随机初始化，而BERT是通过预训练模型初始化的。但用于初始化的模型，是学习填空的模型。它已经学会了英语填空。你可能会认为,这个实验完全是无稽之谈。如果我们把一个DNA序列预处理成一个无意义的序列,那么BERT的目的是什么?
大家都知道,BERT可以分析一个有效句子的语义,你怎么能给它一个无法理解的句子呢?
做这个实验的意义是什么?</p>
<p>蛋白质有三种分类，那么蛋白质是由氨基酸组成的，有十种氨基酸，只要给每个氨基酸一个随机的词汇，那么DNA是一组ATCG，音乐也是一组音符，给它每个音符一个词汇，然后，把它作为一个文章分类问题来做。</p>
<p><img src="image-20220613182551067.png" alt="image-20220613182551067" style="zoom:50%;"></p>
<p>你会发现，如果你不使用BERT，你得到的结果是蓝色部分，如果你使用BERT，你得到的结果是红色部分，这实际上更好，你们大多数人现在一定很困惑。这个实验只能用神奇来形容，没有人知道它为什么有效，而且目前还没有很好的解释，我之所以要谈这个实验，是想告诉你们，要了解BERT的力量，还有很多工作要做。</p>
<p>我并不是要否认BERT能够分析句子的含义这一事实。从embedding中，我们清楚地观察到，BERT知道每个词的含义，它能找出含义相似的词和不相似的词。但正如我想指出的那样，即使你给它一个无意义的句子，它仍然可以很好地对句子进行分类。</p>
<p>所以，<strong>也许它的力量并不完全来自于对实际文章的理解</strong>。也许还有其他原因。例如，也许，BERT只是一套更好的初始参数。也许这与语义不一定有关。也许这套初始参数，只是在训练大型模型时更好。</p>
<p>是这样吗？这个问题<strong>需要进一步研究</strong>来回答。我之所以要讲这个实验，是想让大家知道，我们目前使用的模型往往是非常新的，需要进一步的研究，以便我们了解它的能力。如果你想了解更多关于BERT的知识，你可以参考这些链接。你的作业不需要它，,这学期剩下的时间也不需要。我只想告诉你，BERT还有很多其他的变种。</p>
<h2><span id="multi-lingual-bert">Multi-lingual BERT</span></h2>
<p>接下来，我要讲的是，一种叫做<strong>Multi-lingual
BERT的BERT（多语言）</strong>。Multi-lingual BERT有什么神奇之处？</p>
<p><img src="image-20220613182656588.png" alt="image-20220613182656588" style="zoom:50%;"></p>
<p>它是由很多语言来训练的，比如中文、英文、德文、法文等等，用填空题来训练BERT，这就是Multi-lingual
BERT的训练方式。</p>
<h3><span id="zero-shot-readingcomprehension">Zero-shot Reading
Comprehension</span></h3>
<p>google训练了一个Multi-lingual
BERT，它能够做这104种语言的填空题。神奇的地方来了，如果你用<strong>英文</strong>问答<strong>数据</strong>训练它，它就会自动学习如何做<strong>中文问答</strong>：</p>
<p><img src="image-20220613182729448.png" alt="image-20220613182729448" style="zoom:50%;"></p>
<p>我不知道你是否完全理解我的意思，所以这里有一个真实的实验例子。</p>
<p><img src="image-20220613182748495.png" alt="image-20220613182748495" style="zoom:50%;"></p>
<p>这是一些训练数据。他们用SQuAD进行fine-tune。这是一个英文Q&amp;A数据集。中文数据集是由台达电发布的，叫DRCD。这个数据集也是我们在作业中要用到的数据集。</p>
<p>在BERT提出之前，效果并不好。在BERT之前，最强的模型是QANet。它的正确率只有......，嗯，我是说F1得分，而不是准确率，但你可以暂时把它看成是准确率或正确率。</p>
<p>如果我们允许用中文填空题进行预训练，然后用中文Q&amp;A数据进行微调，那么它在中文Q&amp;A测试集上的正确率达到89%。因此，其表现是相当令人印象深刻的。</p>
<p>神奇的是，如果我们把一个Multi-lingual的BERT，用英文Q&amp;A数据进行微调，它仍然可以回答中文Q&amp;A问题，并且有78%的正确率，这几乎与QANet的准确性相同。它从未接受过中文和英文之间的翻译训练，也从未阅读过中文Q&amp;A的数据收集。,它在没有任何准备的情况下参加了这个中文Q&amp;A测试，尽管它从未见过中文测试，但不知为何，它能回答这些问题。</p>
<h3><span id="cross-lingual-alignment">Cross-lingual Alignment?</span></h3>
<p>你们中的一些人可能会说："它在预训练中读过104种语言，104种语言中的一种是中文，是吗？
如果是，这并不奇怪。"但是在预训练中，学习的目标是填空。它只能用中文填空。有了这些知识，再加上做英文问答的能力，不知不觉中，它就自动学会了做中文问答。</p>
<p><img src="image-20220613183052341.png" alt="image-20220613183052341" style="zoom:50%;"></p>
<p>听起来很神奇，那么BERT是怎么做到的呢？一个简单的解释是：也许对于多语言的BERT来说，<strong>不同的语言并没有那么大的差异</strong>。无论你用中文还是英文显示，对于具有相同含义的单词，它们的embedding都很接近。</p>
<p>汉语中的 "跳 "与英语中的 "jump "接近，汉语中的 "鱼 "与英语中的 "fish
"接近，汉语中的 "游 "与英语中的 "swim
"接近，也许在学习过程中它已经自动学会了。它是可以被验证的。我们实际上做了一些验证。<font color="red">验证的标准被称为<strong>Mean
Reciprocal
Rank</strong>，缩写为MRR。我们在这里不做详细说明。你只需要知道，<strong>MRR的值越高，不同embedding之间的Alignment就越好</strong>。
</font></p>
<p>更好的Alignment意味着，具有相同含义但来自不同语言的词将被转化为更接近的向量。如果MRR高，那么具有相同含义但来自不同语言的词的向量就更接近。</p>
<p><img src="image-20220613183548674.png" alt="image-20220613183548674" style="zoom:50%;"></p>
<p><strong>这条深蓝色的线是谷歌发布的104种语言的Multi-lingual
BERT的MRR，它的值非常高，这说明不同语言之间没有太大的差别。Multi-lingual
BERT只看意思，不同语言对它没有太大的差别。</strong></p>
<p>橙色这条是我们试图自己训练Multi-lingual
BERT。我们使用的<strong>数据较少</strong>，每种语言只使用了20万个句子。数据较少。我们自我训练的模型结果并不好。我们不知道为什么我们的Multi-lingual
BERT不能将不同的语言统一起来。似乎它不能学习那些在不同语言中具有相同含义的符号，它们应该具有相同的含义。这个问题困扰了我们很长时间。</p>
<p>为什么我们要做这个实验？为什么我们要自己训练Multi-lingual
BERT？因为我们想了解，是什么让Multi-lingual
BERT。我们想设置不同的参数，不同的向量，看看哪个向量会影响Multi-lingual
BERT。</p>
<p>但是我们发现，对于我们的Multi-lingual
BERT来说，无论你如何调整参数，它就是不能达到Multi-lingual的效果，它就是不能达到Alignment的效果。我们把数据量<strong>增加了五倍</strong>，看看能不能达到Alignment的效果。在做这个实验之前，大家都有点抵触，大家都觉得有点害怕，因为训练时间要比原来的长五倍。<strong>训练了两天后，什么也没发生，损失甚至不能减少，就在我们要放弃的时候，损失突然下降了</strong>。</p>
<p><img src="image-20220613183941470.png" alt="image-20220613183941470" style="zoom:50%;"></p>
<p>用了8个V100来训练，我们的实验室也没有8个V100，是在NCHC（国家高性能计算中心）的机器上运行的，训练了两天后，损失没有下降，似乎失败了。当我们要放弃的时候，损失下降了。</p>
<p>这是某个学生在Facebook上发的帖子，我在这里引用它来告诉你，我当时心里的感叹。整个实验，必须运行一个多星期，才能把它学好，每一种语言1000K的数据。</p>
<p><img src="image-20220613184000971.png" alt="image-20220613184000971" style="zoom:50%;"></p>
<p>所以看起来，<strong>数据量是一个非常关键的因素</strong>，关系到能否成功地将不同的语言排列在一起。所以有时候，神奇的是，很多问题或很多现象，只有在有足够的数据量时才会显现出来。它可以在A语言的QA上进行训练，然后直接转移到B语言上，从来没有人说过这一点。这是过去几年才出现的，一个可能的原因是，过去没有足够的数据，现在有足够的数据，现在有大量的计算资源，所以这个现象现在有可能被观察到。</p>
<p>最后一个神奇的实验，我觉得这件事很奇怪：</p>
<h4><span id="why">Why？</span></h4>
<p><img src="image-20220613184030869.png" alt="image-20220613184030869" style="zoom:50%;"></p>
<p>你说BERT可以把不同语言中含义相同的符号放在一起，使它们的向量接近。但是，当训练多语言的BERT时，如果给它英语，它可以用英语填空，如果给它中文，它可以用中文填空，它不会混在一起。那么，如果不同语言之间没有区别，怎么可能只用英语标记来填英语句子呢？为什么它不会用中文符号填空呢？它就是不填，这说明它知道语言的信息也是不同的，那些不同语言的符号毕竟还是不同的，它并没有完全抹去语言信息，所以我想出了一个研究课题，我们来找找，语言信息在哪里。</p>
<p><font color="red">
后来我们发现，语言信息并没有隐藏得很深。一个学生发现，我们把所有<strong>英语单词</strong>的embedding，放到多语言的BERT中，<strong>取embedding的平均值</strong>，我们对<strong>中文单词</strong>也做<strong>同样的事情</strong>。在这里，我们给Multi-lingual
BERT一个英语句子，并得到它的embedding。我们在embedding中<strong>加上</strong>这个<strong>蓝色的向量</strong>，这就是<strong>英语和汉语之间的差距</strong>。</font></p>
<p><img src="image-20220613184257490.png" alt="image-20220613184257490" style="zoom:50%;"></p>
<p>这些向量，从Multi-lingual
BERT的角度来看，变成了汉语。有了这个神奇的东西，你可以做一个奇妙的无监督翻译。例如，你给BERT看这个中文句子。</p>
<p><img src="image-20220613184444235.png" alt="image-20220613184444235" style="zoom:50%;"></p>
<p>这个中文句子是，"能帮助我的小女孩在小镇的另一边，，没人能够帮助我"，现在我们把这个句子扔到Multi-lingual
BERT中。然后我们取出Multi-lingual
BERT中的一个层，它不需要是最后一层，可以是任何一层。我们拿出某一层，给它一个embedding，加上这个蓝色的向量。对它来说，这个句子马上就从中文变成了英文。</p>
<p>在向BERT输入英文后，通过在中间加一个<strong>蓝色的向量来转换隐藏</strong>层，转眼间，中文就出来了。"没有人可以帮助我"，变成了
"是（是）没有人（没有人）可以帮助我（我）"，"我 "变成了 "我"，"没有人
"变成了
"没有人"，所以它在某种程度上可以做无监督的标记级翻译，尽管它并不完美，神奇的是，Multi-lingual的BERT仍然保留了语义信息。</p>
<h2><span id="bert-qampa">BERT Q&amp;A</span></h2>
<h3><span id="11-bert如何解决长文本问题-"><strong>1.1 Bert
如何解决长文本问题？</strong> -</span></h3>
<p>何枝的回答 - 知乎
https://www.zhihu.com/question/327450789/answer/2455518614</p>
<p>当我们遇到一个文本分类问题，大多数人首先会想到用BERT系列的模型做尝试。对于短文本而言（小于等于510个token）是work的，但如果遇到输入文本大于510个token时，此时就无法直接调用开源的pretrained-model来做fine-tuning了，本篇文章将通过Pooling的方法来尝试解决长文本下的分类问题。</p>
<p>要想将一个大于510个token的文本输入，一般有以下几种方法：</p>
<ul>
<li><strong>Clipping（<a href="https://www.zhihu.com/search?q=截断法&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2455518614%7D">截断法</a>）</strong>：对长输入进行截断，挑选其中「重要」的token输入模型。一种最常见的办法是挑选文章的前
Top N 个 token，和文末的 Top K 个 token，保证 N + K &lt;=
510，这种方法基于的前提假设是「文章的首尾信息最能代表篇章的全局概要」；此外，还有一种
two stage 的方法：先将文章过一遍 summarize 的模型，再将 summarize
模型的输出喂给分类模型。但无论哪种截断方式，都必将会丢失一部分的文本信息，可能会导致分类错误。</li>
<li><strong>Pooling（池化法）</strong>：截断法最大的问题在于需要丢掉一部分文本信息，如果我们能够保留文本中的所有信息，想办法让模型能够接收文本中的全部信息，这样就能避免文本丢失带来的影响。</li>
<li><strong>RNN（<a href="https://www.zhihu.com/search?q=循环法&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2455518614%7D">循环法</a>）</strong>：BERT之所以会有最大长度的限制，是因为其在进行MLM预训练的时候就规定了最大的输入长度，而对于类RNN的网络来讲则不会有句子长度的限制（有多少个token就过多少次NN就行了）。但RNN相较于
Transformer 来讲最大问题就在于效果不好，如何将 RNN 的思想用在
Transformer 中就是一个比较有意思的话题了。推荐可以看看<a href="%5BERNIE/README_zh.md%20at%20repro%20·%20PaddlePaddle/ERNIE%5D(https://link.zhihu.com/?target=https%3A//github.com/PaddlePaddle/ERNIE/blob/repro/ernie-doc/README_zh.md)">ERNIE-DOC</a>，官网上是这么描述的，感兴趣的同学可以研究研究</li>
</ul>
<blockquote>
<p>#### Pooling思想</p>
<p>#### 1.1 句子分片</p>
<p>由于 BERT 最多只能接受 510 个token
的输入，因此我们需要将长文本切割成若干段。</p>
<p>假设我们有 2 句 1000 个 token 的句子，那么我就需要先将这 2 个句子切成
4 段（第 1 个句子的 2 段 + 第 2 个句子的 2 段），并放到一个 batch
的输入中喂给模型。</p>
<p><img src="https://pic2.zhimg.com/50/v2-f6b167e4ef46242086e5946ed6256462_720w.jpg?source=1940ef5c" alt="img" style="zoom: 50%;"></p>
<p>文本分段，BERT输入数据维度（4, 510）</p>
<p>#### 1.2 Pooling</p>
<p><strong>当切完片后的数据喂给 BERT 后，我们取 BERT 模型的 [CLS]
的输出，此时输出维度应该为：(4, 768) 。</strong></p>
<p><strong>随即，我们需要将这 4 个 output
按照所属句子分组，由下图所示，前 2
个向量属于一个句子，因此我们将它们归为一组，此时的维度变化：(4, 768)
-&gt; (2, 2, 768)。</strong></p>
<p>接着，我们对同一组的向量进行 Pooling 操作，使其下采样为 1
维的向量，即（1, 768）。</p>
<p>Pooling 的方式有两种：Max-Pooling 和
Avg-Pooling，我们会在后面的实验中比较两种不同 Pooling 的效果。</p>
<p>这里推荐大家使用Max-Pooling比较好，因为 Avg-Pooling
很有可能把特征值给拉平，选择保留显著特征（Max-Pooling）效果会更好一些。</p>
<p><img src="https://pica.zhimg.com/80/v2-2b4ffc235b1135bedc1bc5caa700502b_1440w.jpg?source=1940ef5c" alt="img" style="zoom: 33%;"></p>
</blockquote>
<h4><span id></span></h4>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-NLP（5）GPT3</title>
    <url>/posts/1QVQV5N/</url>
    <content><![CDATA[<h1><span id="gpt3">GPT3</span></h1>
<p>除了BERT以外,还有下一个,也是鼎鼎有名的模型,就是==GPT==系列的模型</p>
<p><img src="image-20220613185324111.png" alt="image-20220613185324111" style="zoom: 33%;"></p>
<p><font color="red">
<strong>BERT做的是填空题,GPT就是改一下我们现在在,self-supervised
learning的时候,要模型做的任务</strong>。</font></p>
<h3><span id="predict-next-token">Predict Next Token</span></h3>
<p>GPT要做的任务是：<strong>预测接下来,会出现的token是什麼</strong>？</p>
<p>举例来说,假设你的训练资料裡面,有一个句子是台湾大学,那GPT拿到这一笔训练资料的时候,它做的事情是这样。</p>
<p><strong>你给它BOS这个token</strong>,然后GPT
output一个embedding,然后接下来,你用这个embedding去预测下一个,应该出现的token是什麼？</p>
<p><img src="image-20220613185452298.png" alt="image-20220613185452298" style="zoom: 33%;"></p>
<p>那在这个句子裡面,根据这笔训练资料,下一个应该出现的token是"台",所以你要训练你的模型,根据第一个token,根据BOS给你的embedding,那它要输出"台"这个token。</p>
<p>这个部分,详细来看就是这样,你有一个embedding,这边用h来表示,然后通过一个Linear
Transform,再通过一个softmax,得到一个distribution,跟一般你做分类的问题是一样的,接下来,你希望你output的distribution,跟正确答案的Cross
entropy,越小越好,也就是你要去预测,下一个出现的token是什麼。</p>
<p>好那接下来要做的事情,就是<strong>以此类推</strong>了,你给你的GPT,BOS跟"台",它產生embedding,接下来它会预测,下一个出现的token是什麼,那你告诉它说,下一个应该出现的token,是"湾"。</p>
<p><img src="image-20220613185654700.png" alt="image-20220613185654700" style="zoom: 33%;"></p>
<p>好再反覆继续下去,你给它BOS
"台"跟"湾",然后预测下一个应该出现的token,它应该要预测"大"。你给它"台"跟"湾"跟"大",接下来,下一个应该出现的token是"学"。</p>
<p><img src="image-20220613185722536.png" alt="image-20220613185722536" style="zoom: 33%;"></p>
<p>那这边呢,是指拿一笔资料
一个句子,来给GPT训练,当然实际上你不会只用一笔句子,你会用成千上万个句子,来训练这个模型,然后就这样子说完了。<strong>它厉害的地方就是,用了很多资料,训了一个异常巨大的模型</strong>。</p>
<p><strong><font color="red">
GPT的模型像是一个transformer的decoder,不过拿掉BOS的attention这个部分,也就是说,你会做那个mask的attention。
</font></strong></p>
<p><img src="image-20220613185925358.png" alt="image-20220613185925358" style="zoom: 50%;"></p>
<p><strong>就是你现在在预测给BOS,预测台的时候,你不会看到接下来出现的词汇,给它台要预测湾的时候,你不会看到接下来要输入的词汇,以此类推这个就是GPT</strong>。</p>
<p>那这个GPT最知名的就是,因為GPT可以预测下一个token,那所以它有<strong>生成的能力</strong>,你可以让它不断地预测下一个token,產生完整的文章,所以我每次提到GPT的时候,它的形象都是一隻独角兽。</p>
<p><img src="image-20220613190018230.png" alt="image-20220613190018230" style="zoom:50%;"></p>
<p>GPT系列最知名的一个例子,就是用GPT写了一篇,跟独角兽有关的新闻,因為他放一个假新闻,然后那个假新闻裡面说,在安地斯山脉发现独角兽等等,一个活灵活现的假新闻。</p>
<p>為了让你更清楚了解,GPT运作起来是什麼样子,那这个线上有一个demo的网页,叫做talk
to transformer,就是有人把一个比较小的,不是那个最大的GPT的模型,不是public
available的,有人把比较小的GPT模型放在线上,让你可以输入一个句子,让它会把接下来的其餘的内容,把它补完</p>
<h3><span id="how-to-use-gpt">How to use GPT?</span></h3>
<p>怎麼把它用在downstream 的任务上呢,举例来说,怎麼把它用在question
answering,或者是其他的,跟人类语言处理有关的任务上呢？</p>
<p><strong>GPT用的想法跟BERT不一样</strong>,其实我要强调一下,GPT也可以跟BERT用一样的做法。在使用BERT时，把BERT
model
拿出来,后面接一个简单的linear的classifier,那你就可以做很多事情,你也可以把GPT拿出来,接一个简单的classifier,我相信也是会有效。</p>
<p>但是在GPT的论文中,它没有这样做,它有一个更狂的想法,為什麼会有更狂的想法呢,因為首先就是,BERT那一招BERT用过了嘛,所以总不能再用一样的东西,这样写paper就没有人觉得厉害了,然后再来就是,<strong>GPT这个模型,也许真的太大了,大到连fine
tune可能都有困难</strong>。</p>
<p>我们在用BERT的时候,你要把BERT模型,后面接一个linear
classifier,然后BERT也是你的,要train的model的一部分,所以它的参数也是要调的,所以在刚才助教公告的,BERT相关的作业裡面,你还是需要花一点时间来training,虽然助教说你大概20分鐘,就可以train完了,因為你并不是要train一个,完整的BERT的模型,BERT的模型在之前,在做这个填空题的时候,已经训练得差不多了,你只需要微调它就好了,但是微调还是要花时间的,也许GPT实在是太过巨大,巨大到要微调它,要train一个epoch,可能都有困难,所以GPT系列,有一个更狂的使用方式。</p>
<p>这个更狂的使用方式<strong>和人类更接近</strong>,你想想看假设你去考,譬如说托福的听力测验,你是怎麼去考。</p>
<p><img src="image-20220613190341900.png" alt="image-20220613190341900" style="zoom: 33%;"></p>
<h3><span id="in-context-learning">“In-context” Learning</span></h3>
<h4><span id="few-shot-learning">“Few-shot” Learning</span></h4>
<p>举例来说假设要GPT这个模型做翻译：</p>
<p><img src="image-20220613190432234.png" alt="image-20220613190432234" style="zoom:50%;"></p>
<ul>
<li><p>你就先打Translate English to French</p></li>
<li><p>就先给它这个句子,这个句子代表问题的描述</p></li>
<li><p>然后给它几个范例跟它说,sea
otter然后=&gt;,后面就应该长这个样子</p></li>
<li><p>或者是这个什麼plush girafe,plush
girafe后面,就应该长这个样子等等</p></li>
<li><p>然后接下来,你问它说cheese=&gt;,叫它把后面的补完,希望它就可以產生翻译的结果</p></li>
</ul>
<p>不知道大家能不能够了解,这一个想法是多麼地狂,在training的时候,GPT并没有教它做翻译这件事,它唯一学到的就是,给一段文字的前半段,把后半段补完,就像我们刚才给大家示范的例子一样,现在我们直接给它前半段的文字,就长这个样子,告诉它说你要做翻译了,给你几个例子,告诉你说翻译是怎麼回事,接下来给它cheese这个英文单字,后面能不能就直接接出,法文的翻译结果呢</p>
<p>这个在GPT的文献裡面,叫做==Few-shot Learning==,但是它跟一般的Few-shot
Learning,又不一样,所谓Few
Shot的意思是说,确实只给了它一点例子,所以叫做Few
Shot,但是它不是一般的learning,这裡面<strong>完全没有gradient
descent</strong>,完全没有要去调,GPT那个模型参数的意思,所以在GPT的文献裡面,把这种训练给了一个特殊的名字,它们叫做==In-context
Learning==,代表说它不是一种,一般的learning,它连gradient
descent都没有做</p>
<h4><span id="one-shot-learningzero-shot-learning">“One-shot” Learning
“Zero-shot” Learning</span></h4>
<p>当然你也可以给GPT更大的挑战,我们在考托福听力测验的时候,都只给一个例子而已,那GPT可不可以只看一个例子,就知道它要做翻译这件事,这个叫One-shot
Learning。</p>
<p><img src="image-20220613190603332.png" alt="image-20220613190603332" style="zoom: 33%;"></p>
<p>还有更狂的,是Zero-shot
Learning,直接给它一个叙述,说我们现在要做翻译了,GPT能不能够自己就看得懂,就自动知道说要来做翻译这件事情呢,那如果能够做到的话,那真的就非常地惊人了,那GPT系列,到底有没有达成这个目标呢,这个是一个见仁见智的问题啦。</p>
<p><img src="image-20220613190625552.png" alt="image-20220613190625552" style="zoom: 33%;"></p>
<p>它不是完全不可能答对,但是<strong>正确率有点低</strong>,相较於你可以微调模型,正确率是有点低的,那细节你就再看看GPT那篇文章。</p>
<p>第三代的GPT,它测试了42个任务,这个纵轴是正确率,这些实线
这三条实线,是42个任务的平均正确率,那这边包括了Few Shot,One Shot跟Zero
Shot,三条线分别代表Few Shot,One Shot跟Zero
Shot,横轴代表模型的大小,它们测试了一系列不同大小的模型,从只有0.1个billion的参数,到175个billion的参数,那从只有0.1个billion的参数,到175个billion的参数,我们看Few
Shot的部分,从20几%的正确率
平均正确率,一直做到50几%的平均正确率,那至於50几％的平均正确率,算是有做起来
还是没有做起来,那这个就是见仁见智的问题啦。</p>
<p>目前看起来状况是,<strong>有些任务它还真的学会了</strong>,举例来说2这个加减法,你给它一个数字加另外一个数字,它真的可以得到,正确的两个数字加起来的结果,但是有些任务,它可能怎麼学都学不会,譬如说一些跟<strong>逻辑推理</strong>有关的任务,它的结果就非常<strong>非常地惨</strong>,好
那有关GPT3的细节,这个就留给大家再自己研究,然后这边有一个过去上课的录影,我把连结放在这边给大家参考。</p>
<h2><span id="beyond-text">Beyond Text</span></h2>
<p>到目前為止我们举的例子,都是只有跟文字有关,但是你不要误会说,这种self-supervised
learning的概念,只能用在文字上</p>
<p>在CV, CV就是computer
vision,也就是影像,<strong>在语音跟影像的应用上也都可以用,self-supervised
learning的技术</strong>,那其实今天,self-supervised
learning的技术,非常非常地多,我们讲的<strong>BERT跟GPT系列,它只是三个类型的,这个self-supervised
learning的方法,的其中一种</strong>,它们是属於<strong>prediction</strong>那一类。</p>
<p><img src="image-20220613190824763.png" alt="image-20220613190824763" style="zoom:50%;"></p>
<p>那其实还有其他的类型,那就不是我们这一堂课要讲的,那接下来的课程,你可能会觉得有点流水帐,就是我们每一个主题呢,就是告诉你说这个主题裡面,有什麼
但是细节这个更多的知识,就留给大家自己来做更进一步的研究,所以这些投影片,只是要告诉你说,在self-supervised
learning这个部分,我们讲的只是整个领域的其中一小块,那还有更多的内容,是等待大家去探索的。</p>
<h3><span id="image-simclr">Image - SimCLR</span></h3>
<p>好那有关影像的部分呢,我们就真的不会细讲,我这边就是放两页投影片带过去,告诉你说有一招非常有名的,叫做SimCLR,它的概念也不难,我相信你自己读论文,应该也有办法看懂它。</p>
<p><img src="image-20220613190911297.png" alt="image-20220613190911297" style="zoom:33%;"></p>
<h3><span id="image-byol">Image - BYOL</span></h3>
<p>那还有很奇怪的,叫做BYOL。BYOL这个东西呢,我们是不太可能在上课讲它,為什麼呢,因為根本不知道它為什麼会work,不是
这个是很新的论文,这个是去年夏天的论文,那这个论文是,假设它不是已经发表的文章,然后学生来跟我提这个想法,我一定就是,我一定不会让他做,这不可能会work的,这是个不可能会实现的想法,不可能会成功的,这个想法感觉有一个巨大的瑕疵,但不知道為什麼它是work的,而且还曾经一度得到,state
of the art的结果,deep learning就是这麼神奇。</p>
<p><img src="image-20220613190925800.png" alt="image-20220613190925800" style="zoom:33%;"></p>
<h3><span id="speech">Speech</span></h3>
<p>那在语音的部分,你也完全可以使用,self-supervised learning的概念。</p>
<p><img src="image-20220613191009513.png" alt="image-20220613191009513" style="zoom:50%;"></p>
<p>你完全可以试著训练,语音版的BERT。那怎麼训练语音版的BERT呢,你就看看文字版的BERT,是怎麼训练的,譬如说做填空题,语音也可以做填空题,就把一段声音讯号盖起来,叫机器去猜盖起来的部分是什麼嘛,语音也可以预测接下来会出现的内容,讲GPT就是预测,接下来要出现的token嘛,那语音你也可以叫它预测,叫模型预测接下来会出现的声音去套,所以你也可以做语音版的GPT,不管是语音版的BERT,语音版的GPT,其实都已经有很多相关的研究成果了。</p>
<h3><span id="speech-glue-superb">Speech GLUE - SUPERB</span></h3>
<p>不过其实在语音上,相较於文字处理的领域,还是有一些比较缺乏的东西,那我认為现在很缺乏的一个东西,就是像GLUE这样子的benchmark
corpus。</p>
<p>在自然语言处理的领域,在文字上有GLUE这个corpus,我们在这门课的刚开头,这个投影片的刚开头,就告诉你说有一个,这个基準的资料库叫做GLUE,它裡面有九个NLP的任务,今天你要知道BERT做得好不好,就让它去跑那九个任务在去平均,那代表这个self-supervised
learning,模型的好坏。</p>
<p>但在语音上
到目前為止,还没有类似的基準的资料库,所以我们实验室就跟其他的研究团队,共同开发了一个语音版的GLUE。</p>
<p><img src="image-20220613191139242.png" alt="image-20220613191139242" style="zoom: 33%;"></p>
<p>我们叫做SUPERB,它是Speech processing Universal,PERformance
Benchmark的缩写,你知道今天你做什麼模型,都一定要硬凑梗才行啦,所以这边也是要硬凑一个梗,把它叫做SUPERB。</p>
<p>那其实我们已经準备了差不多了,其实网站都已经做好了,只等其他团队的人看过以后,就可以上线了,所以现在虽然还没有上线,但是再过一阵子,你应该就可以找得到相关的连结。</p>
<p>在这个基準语料库裡面,包含了十个不同的任务,那语音其实有非常多不同的面向,很多人讲到语音相关的技术,都只知道语音辨识把声音转成文字,但这并不是语音技术的全貌,语音其实包含了非常丰富的资讯,它除了有内容的资讯,就是你说了什麼,还有其他的资讯,举例来说这句话是谁说的,举例这个人说这句话的时候,他的语气是什麼样,还有这句话背后,它到底有什麼样的语意,所以我们準备了十个不同的任务,这个任务包含了语音不同的面向,包括去检测一个模型,它能够识别内容的能力,识别谁在说话的能力,识别他是怎麼说的能力,甚至是识别这句话背后语意的能力,从全方位来检测一个,self-supervised
learning的模型,它在理解人类语言上的能力。</p>
<p>而且我们还有一个Toolkit,这个Toolkit裡面就包含了,各式各样的,self-supervised
learning的模型：</p>
<p><img src="image-20220613191333351.png" alt="image-20220613191333351" style="zoom:50%;"></p>
<p>还有这些,self-supervised
learning的模型,它可以做的,各式各样语音的下游的任务,然后把连结放在这边给大家参考。讲这些只是想告诉大家说,self-supervised
learning的技术,不是只能被用在文字上,在这个影像上
在语音上,都仍然有非常大的空间可以使用,self-supervised learning的技术,好
那这个,self-supervised
learning的部分呢,这个BERT跟GPT我们就讲到这边。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-NLP（6）【Nan】FastText</title>
    <url>/posts/28RKHA6/</url>
    <content><![CDATA[<h2><span id="fasttext">FastText</span></h2>
<blockquote>
<ul>
<li>FastText代码详解(一) - BlockheadLS的文章 - 知乎
https://zhuanlan.zhihu.com/p/52154254</li>
<li>【DL&amp;NLP】fasttext不仅仅只做文本分类 - 叮当猫的文章 - 知乎
https://zhuanlan.zhihu.com/p/442768234</li>
<li><strong>fastText原理及实践 - 陈运文的文章</strong> - 知乎
https://zhuanlan.zhihu.com/p/32965521</li>
</ul>
</blockquote>
<h3><span id="abstract">Abstract</span></h3>
<p>“本文探索了一种简单有效的文本分类基准（方法）。我们的实验表明，我们的快速文本分类器fastText在准确性方面与深度学习分类器平分秋色，其训练和评估速度（相比深度学习模型更是）要快许多个数量级。我们可以使用标准的多核CPU在不到10分钟的时间内用fastText训练超过10亿个单词，并在一分钟之内将50万个句子在31万2千个类中做分类。”</p>
<p>作者中又出现了托老师，不知道是不是受他影响，这篇文章在表述上也很有word2vec的味道，更不用说模型本身。fastText和word2vec的卖点都是简单高效（快）。</p>
<h3><span id="一-什么是fasttext">一、什么是fastText？</span></h3>
<p>先说结论，fastText在不同语境中至少有两个含义：</p>
<ol type="1">
<li>在文章Bag of Tricks for Efficient Text Classification[<a href="#ref_1">1]</a>中，fastText是作者提出的文本分类器的名字。<strong>与sub-word无关！也不是新的词嵌入训练模型！是<a href="https://www.zhihu.com/search?q=word2vec&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22138019676%22%7D">word2vec</a>中CBOW模型的简单变种。</strong></li>
<li>作为Facebook开源包，<a href="https://link.zhihu.com/?target=https%3A//fasttext.cc/">fastText</a>是用来训练词嵌入或句嵌入的，其不仅包括1中论文的代码实现，还包括Enriching
Word Vectors with Subword Information[<a href="#ref_2">2]</a>及FastText.zip: Compressing text classification
models[<a href="#ref_3">3]</a>两文的代码实现。</li>
</ol>
<p>本来觉得这些含义区别不重要，直到连我自己都被弄迷糊了。在写这篇解读前，我心中的fastText一直是第三种含义：<strong>用sub-word信息加强词嵌入训练，解决OOV（Out-Of-Vocabulary）表征的方法</strong>。结果带着这个预先的理解读Bag
of Tricks for Efficient Text Classification，越读越迷惑。</p>
<p>为理清思路，fastText（一）中我们就先讲讲Bag of Tricks for Efficient
Text Classification中的fastText，fastText（二）则围绕Enriching Word
Vectors with Subword Information。</p>
<h3><span id="二-一句话介绍fasttext">二、一句话介绍fastText</span></h3>
<p>word2vec的CBOW模型中将中心词替换为类别标签就得到了fastText。</p>
<p>具体到一些小区别：</p>
<ul>
<li>CBOW中词袋的大小由window_size决定，而fastText中就是整个要分类的文本。</li>
<li>CBOW实际运行中用Hierarchical <a href="https://www.zhihu.com/search?q=softmax&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22138019676%22%7D">softmax</a>，fastText用softmax或Hierarchical
softmax，具体试类的数量决定。</li>
</ul>
<p>这就是一个标配版且可以实际应用的fastText了，我要再强调三点它和CBOW无区别的地方，因为在别的讲该论文的文章中看到了一些错误的理解：</p>
<ul>
<li>CBOW和fastText都是用平均值来预测的。（CBOW不是求和，是求平均）</li>
<li>N-gram对于CBOW和fastText都是锦上添花的元素，不是标配。</li>
<li><strong><font color="red">
词向量初始化都是随机的</font></strong>，fastText并没有在word2vec预训练词嵌入的基础上再训练。</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-NLP（7）ELMO</title>
    <url>/posts/181HVAR/</url>
    <content><![CDATA[<h2><span id="elmo-具有上下文语境的词嵌入">ELMO-具有上下文语境的词嵌入</span></h2>
<blockquote>
<p>https://zhuanlan.zhihu.com/p/504527165</p>
</blockquote>
<p><img src="https://pic3.zhimg.com/v2-17095ae7e4d6965c968518e446e64475_720w.png?source=d16d100b" alt="ELMO-具有上下文语境的词嵌入-长文多图预警" style="zoom:67%;"></p>
<h4><span id="1从静态词嵌入到动态词嵌入具有语境的词嵌入">1.从静态词嵌入到动态词嵌入（具有语境的词嵌入）</span></h4>
<p><strong>词嵌入：</strong>将词用一个具有语义信息的多维向量来表示</p>
<p><strong>静态词嵌入：</strong>多维稠密向量来表示，是一个固定的向量，不会根据语境的差异发生改变，
<strong>没办法结合语境给出正确的词向量，即一词多义的问题</strong></p>
<p><strong>动态词嵌入：</strong>根据不同的上下文语境调整词的语义，能较好的应对<strong>一词多义(polysemy)</strong>问题</p>
<p>如何做到动态词嵌入呢？NAACL 2018 best paper <strong>ELMO(Embeddings
from Language Model)</strong>能给你一个较好的答案</p>
<h4><span id="2elmodeepcontextualized-word-representations">2.ELMO：Deep
Contextualized Word Representations</span></h4>
<p>可以看到模型整体由 <strong>前向+后向LSTM</strong> 与
<strong>CNN</strong> 字符嵌入组成，详情见下图，还是非常直观的</p>
<ul>
<li><strong>CNN字符嵌入:</strong> 输入一句话(多个word)
先由CNN字符嵌入进行编码
得到每个word的词向量,简单来说就是<strong>把一个词分解成字母，然后对字母进行卷积操作获得词向量</strong>;</li>
<li><strong>将词向量按照顺序分别输入到前向 后向
LSTM中进行嵌入：</strong>其实就是基于已知的词预测下一个词，对词的编码采用LSTM架构（不熟悉LSTM的话就简单看成是一个编码器就行了）前向+后向分别是从前到后和从后到前，<strong>注意：前向和后向的LSTM之间并不连接，why?
假如连接了预测过程就相当于泄题了，这个地方比较抽象，让我再深入一下：</strong>
<ul>
<li>假如这里有一句话，由N个词组成 <img src="https://www.zhihu.com/equation?tex=%28x_1%2Cx_2%2C...%2Cx_N%29" alt="[公式]">
组成,LSTM具有较好的记忆能力，能够记忆已经给出序列的信息，前向LSTM从前向后扫的时候会不停的记忆已知的信息，每一时刻预测结果出来以后会将其信息存储起来，这样每次预测下一时刻信息的时候都会已知前面词的信息，比如：预测
<img src="https://www.zhihu.com/equation?tex=x_2" alt="[公式]"> 时已知
<img src="https://www.zhihu.com/equation?tex=x_1" alt="[公式]"> ；预测
<img src="https://www.zhihu.com/equation?tex=x_3" alt="[公式]"> 时已知
<img src="https://www.zhihu.com/equation?tex=x_1%2Cx_2" alt="[公式]">.</li>
<li>相应的，后向LSTM也一样，只不过词的输入顺序反过来了，在这里是从 <img src="https://www.zhihu.com/equation?tex=x_N+%5Crightarrow+x_%7BN-1%7D%2C...%2C+%5Crightarrow+x_%7B2%7D+%5Crightarrow+x_1%2C+" alt="[公式]">
当t=N-1的时候,<strong>（就相当于前向LSTM的t=2时刻）</strong>，
后向LSTM会存储着 <img src="https://www.zhihu.com/equation?tex=x_N%2Cx_%7BN-1%7D%2C...%2Cx_4%2Cx_3" alt="[公式]"> 的信息</li>
<li>对于前向LSTM来说，<strong>在t=3时刻</strong>，预测x_3,
后向LSTM存储着的 <img src="https://www.zhihu.com/equation?tex=x_N%2Cx_%7BN-1%7D%2C...%2Cx_4%2Cx_3" alt="[公式]">
信息，<strong>由于前向LSTM与后向LSTM的连接给了两者信息交互的机会（泄题的机会)</strong>，因此这时候后向的LSTM会告诉前向LSTM：嘿
boy，不要再猜了，答案就是X3</li>
</ul></li>
<li><strong>将CNN层的输出与多个LSTM层的输出拼接在一起
就得到一个词的表示了</strong></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-NLP（8）Glove</title>
    <url>/posts/2X3S5YA/</url>
    <content><![CDATA[<h2><span id="词嵌入-glove-基于全局共现词频信息的词嵌入">词嵌入-GloVe-基于全局共现词频信息的词嵌入</span></h2>
<blockquote>
<p>词嵌入-GloVe-基于全局共现词频信息的词嵌入 - Glenn1Q84的文章 - 知乎
https://zhuanlan.zhihu.com/p/485447934</p>
<p><strong>CS224n笔记[3]:共现矩阵、SVD与GloVe词向量</strong> -
蝈蝈的文章 - 知乎 https://zhuanlan.zhihu.com/p/147312345</p>
</blockquote>
<h4><span id="whyfrom-lsalatent-semantic-analysis-and-skip-gram-to-glove"><strong>why?
From LSA(latent semantic analysis) and skip-gram to GloVe</strong></span></h4>
<ul>
<li><strong>LSA:</strong> 基于<strong>全局词频</strong>的稀疏矩阵,
在词义推理任务上表现较差</li>
</ul>
<figure>
<img src="https://pic1.zhimg.com/v2-693a7371161b1ffd55e7d88c5ec26399_720w.jpg?source=d16d100b" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>风控算法（3）阿里云-风险商品图算法识别</title>
    <url>/posts/1RE0J1S/</url>
    <content><![CDATA[<h2><span id="阿里安全-icdm-2022大规模电商图上的风险商品检测赛">【阿里安全 ×
ICDM 2022】大规模电商图上的风险商品检测赛</span></h2>
<blockquote>
<ul>
<li><p><strong>比赛链接</strong>：Https://tianchi.aliyun.com/competition/entrance/531976/introduction</p></li>
<li><p>ICDM 2022: Risk Commodities Detection on Large-Scale E-Commence
Graphs：https://github.com/EdisonLeeeee/ICDM2022_competition_3rd_place_solution</p></li>
<li><p>ICDM2022大规模电商图上的风险商品检测比赛（第六名）：https://github.com/JaySaligia/SGHQS</p></li>
<li><p><strong>ICDM 2022 : 大规模电商图上的风险商品检测 --
top1方案分享+代码</strong>：https://github.com/fmc123653/Competition/tree/main/ICDMCup2022-top1</p></li>
<li><p><strong><font color="blue">ICDM2022_competition_3rd_place_solution</font></strong>：https://github.com/EdisonLeeeee/ICDM2022_competition_3rd_place_solution</p></li>
<li><p><strong>【论文笔记】KGAT：融合知识图谱的 CKG 表示 +
图注意力机制的推荐系统</strong>：https://zhuanlan.zhihu.com/p/364002920</p></li>
</ul>
</blockquote>
<h3><span id="一-黑灰产vs风控系统">一、<strong>黑灰产VS风控系统</strong></span></h3>
<p>近年来，图计算尤其是图神经网络等技术获得了快速的发展以及广泛的应用。</p>
<p>在电商平台上的风险商品检测场景中，<strong>黑灰产和风控系统</strong>之间存在着<strong>激烈的对抗</strong>，黑灰产为了躲避平台管控，会蓄意掩饰风险信息，通过引入场景中存在的图数据，可以缓解因黑灰产对抗带来的检测效果下降。</p>
<p>在实际应用中，图算法的效果往往和图结构的质量紧密相关，由于风险商品检测场景中对抗的存在，<strong>恶意用户会通过伪造设备、伪造地址等方式，伪造较为“干净”的关联关系</strong>。<strong><font color="red">
如何能够在这种存在着大量噪声的图结构数据中充分挖掘风险信息，是一个十分有挑战性的问题，另外该场景中还存在着黑白样本严重不均衡、图结构规模巨大且异构等多种挑战</font></strong>。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305061917408.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="二-赛题背景">二、赛题背景</span></h3>
<p>在电商平台上，商品是最主要的内容之一。风险商品检测旨在识别平台上存在的假货商品、违禁商品等，对维护平台内容信息健康、保护消费者权益起着至关重要的作用。</p>
<p>风险商品检测和其他风控领域一样，<strong>面临风险的对抗和变异</strong>，如对商品风险内容的刻意隐藏等，而使用平台广泛存在的各类图关系数据可以提供更多证据，提升黑灰产的攻击成本。</p>
<p>本次比赛提供了<strong>阿里巴巴平台来源于真实场景的风险商品检测数据</strong>，需要参赛者利用大规模的异构图结构以及比例不均衡的黑白样本，利用图算法，检测出风险商品。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182039050.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h3><span id="三-结题思路">三、结题思路</span></h3>
<h4><span id="31-deepfm模型">3.1 DeepFM模型</span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182039128.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong><font color="red"> 低阶和高阶特征选择</font></strong></p>
<h4><span id="32-序列模型">3.2 序列模型</span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040137.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic3.zhimg.com/v2-1e23798979f03dd7369306c91df35042_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="33-图模型">3.3 图模型</span></h4>
<figure>
<img src="https://pic4.zhimg.com/v2-526f68f85c8b9d6116039bf2b98f3403_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic4.zhimg.com/v2-9eadc122d63374a77d5090b3f62a8ff3_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic4.zhimg.com/v2-4602cba212d520cb5babfde5865856a7_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>算法比赛</category>
        <category>业务安全</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习-【draft】生成对抗网络</title>
    <url>/posts/T623MZ/</url>
    <content><![CDATA[<h1><span id="李宏毅-gan学习笔记"></span></h1>
<h3><span id="1-介绍gan">1. 介绍GAN</span></h3>
<ul>
<li>GAN的基本思想</li>
<li>为什么生成器不自己学？</li>
<li>为什么判别器不自己做?</li>
<li>具体算法</li>
<li>笔记： <a href="https://blog.csdn.net/oldmao_2001/article/details/105887797">李宏毅学习笔记30.GAN.01.</a>
<a href="https://zhuanlan.zhihu.com/p/57174645">李宏毅GAN教程（1）</a></li>
</ul>
<h3><span id="2gan的数学原理gan背后的理论">2.
Gan的数学原理（GAN背后的理论）</span></h3>
<ul>
<li>笔记： <a href="https://zhuanlan.zhihu.com/p/57184819">李宏毅GAN教程（2）</a> <a href="https://blog.csdn.net/oldmao_2001/article/details/105918115">李宏毅学习笔记33.GAN.04.Theory
behind GAN</a></li>
</ul>
<h2><span id="3-conditional-gan-条件gan">3. Conditional GAN (条件GAN)</span></h2>
<ul>
<li>笔记： <a href="https://zhuanlan.zhihu.com/p/57308383">李宏毅GAN教程（5）</a> <a href="https://blog.csdn.net/oldmao_2001/article/details/105903619">李宏毅学习笔记31.GAN.02.Conditional
Generation by GAN</a></li>
</ul>
<h2><span id="研讨厅思路">研讨厅思路：</span></h2>
<h3><span id="背景意义">背景意义</span></h3>
<p>Generative Adversarial
Network（GAN）<strong>被引次数：26083次</strong></p>
<p>Ian J. Goodfellow:phD</p>
<p><img src="apple/Desktop/GAN介绍/Goodlflow-phD.png" alt="Goodlflow-phD" style="zoom: 33%;"></p>
<p>https://github.com/hindupuravinash/the-gan-zoo</p>
<p><img src="https://github.com/hindupuravinash/the-gan-zoo/blob/master/cumulative_gans.jpg?raw=true" alt="cumulative_gans.jpg" style="zoom: 50%;"></p>
<h3><span id="gan的应用">GAN的应用</span></h3>
<h3><span id="gan的原理">GAN的原理</span></h3>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20210105212933337.png" alt="image-20210105212933337" style="zoom:33%;"></p>
<p>调节Generator和Discrimnator的训练次数比。一般来说，<strong>Discrimnator要训练的比Genenrator多。比如训练五次Discrimnator，再训练一次Genenrator(WGAN论文
是这么干的)</strong>。这一条不一定对！</p>
<p><a href="https://www.youtube.com/watch?v=ebMei6bYeWw">GAN的训练过程</a></p>
<h3><span id="gan与vae的比较">GAN与VAE的比较</span></h3>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20210109170402276.png" alt="image-20210109170402276" style="zoom: 33%;"><img src="/Users/apple/Library/Application Support/typora-user-images/image-20210109170435958.png" alt="image-20210109170435958" style="zoom: 25%;"></p>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20210112105214591.png" alt="image-20210112105214591" style="zoom:50%;"></p>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20210112110242541.png" alt="image-20210112110242541" style="zoom: 33%;"></p>
<h3><span id="gan的发展">GAN的发展</span></h3>
<p>http://nooverfit.com/wp/独家｜gan大盘点，聊聊这些年的生成对抗网络-lsgan-wgan-cgan-info/</p>
<p>10个必读的GAN</p>
<p>WGAN，DCGAN，CGAN,<strong>Improved Techniques for Training
GANs</strong></p>
<p>优化GAN的方法</p>
<p>（1) 结构上的改进CGAN</p>
<p>（2）除了结构上的改进还有，loss, 模型初始化和权重上的改进</p>
<p>（3）GAN的重要实现</p>
<p>目前各领域最先进的GAN</p>
<p>GAN研究方向汇总（附源码） - 清华阿罗的文章 - 知乎
https://zhuanlan.zhihu.com/p/69305310</p>
<figure>
<img src="/Users/apple/Library/Application%20Support/typora-user-images/image-20210110202318149.png" alt="image-20210110202318149">
<figcaption aria-hidden="true">image-20210110202318149</figcaption>
</figure>
<h1><span id="level-0-definition-of-gans">Level 0: Definition of GANs</span></h1>
<table>
<colgroup>
<col style="width: 4%">
<col style="width: 34%">
<col style="width: 10%">
<col style="width: 16%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>Level</th>
<th style="text-align: left;">Title</th>
<th>authors</th>
<th>Publication</th>
<th>Links</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Beginner</td>
<td style="text-align: left;">GAN : Generative Adversarial Nets</td>
<td>Goodfellow &amp; et al.</td>
<td>NeurIPS (NIPS) 2014</td>
<td><a href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">link</a></td>
</tr>
<tr class="even">
<td>Beginner</td>
<td style="text-align: left;">GAN : Generative Adversarial Nets
(Tutorial)</td>
<td>Goodfellow &amp; et al.</td>
<td>NeurIPS (NIPS) 2016 Tutorial</td>
<td><a href="https://arxiv.org/pdf/1701.00160.pdf">link</a></td>
</tr>
<tr class="odd">
<td>Beginner</td>
<td style="text-align: left;">CGAN : Conditional Generative Adversarial
Nets</td>
<td>Mirza &amp; et al.</td>
<td>-- 2014</td>
<td><a href="https://gist.github.com/shagunsodhani/5d726334de3014defeeb701099a3b4b3">link</a></td>
</tr>
<tr class="even">
<td>Beginner</td>
<td style="text-align: left;">InfoGAN : Interpretable Representation
Learning by Information Maximizing Generative Adversarial Nets</td>
<td>Chen &amp; et al.</td>
<td>NeuroIPS (NIPS) 2016</td>
<td></td>
</tr>
</tbody>
</table>
<h1><span id="level-1-improvements-ofgans-training">Level 1: Improvements of
GANs training</span></h1>
<p>然后看看 loss、参数、权重的改进：</p>
<table>
<colgroup>
<col style="width: 4%">
<col style="width: 31%">
<col style="width: 8%">
<col style="width: 24%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>Level</th>
<th>Title</th>
<th>Co-authors</th>
<th>Publication</th>
<th>Links</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Beginner</td>
<td>LSGAN : Least Squares Generative Adversarial Networks</td>
<td>Mao &amp; et al.</td>
<td>ICCV 2017</td>
<td><a href="https://ieeexplore.ieee.org/document/8237566">link</a></td>
</tr>
<tr class="even">
<td>Advanced</td>
<td>Improved Techniques for Training GANs</td>
<td>Salimans &amp; et al.</td>
<td>NeurIPS (NIPS) 2016</td>
<td><a href="https://ceit.aut.ac.ir/http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf">link</a></td>
</tr>
<tr class="odd">
<td>Advanced</td>
<td>WGAN : Wasserstein GAN</td>
<td>Arjovsky &amp; et al.</td>
<td>ICML 2017</td>
<td><a href="http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf">link</a></td>
</tr>
<tr class="even">
<td>Advanced</td>
<td>WGAN-GP : improved Training of Wasserstein GANs</td>
<td>2017</td>
<td><a href="https://arxiv.org/pdf/1704.00028v3.pdf">link</a></td>
<td></td>
</tr>
<tr class="odd">
<td>Advanced</td>
<td>Certifying Some Distributional Robustness with Principled
Adversarial Training</td>
<td>Sinha &amp; et al.</td>
<td>ICML 2018</td>
<td><a href="https://arxiv.org/pdf/1710.10571.pdf">link</a><a href="https://github.com/duchi-lab/certifiable-distributional-robustness">code</a></td>
</tr>
</tbody>
</table>
<h1><span id="level-2-implementation-skill">Level 2: Implementation skill</span></h1>
<p>GAN的实现</p>
<table style="width:100%;">
<colgroup>
<col style="width: 31%">
<col style="width: 13%">
<col style="width: 8%">
<col style="width: 31%">
<col style="width: 7%">
<col style="width: 5%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Co-authors</th>
<th>Publication</th>
<th>Links</th>
<th>size</th>
<th>FID/IS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Keras Implementation of GANs</td>
<td>Linder-Norén</td>
<td>Github</td>
<td><a href="https://github.com/eriklindernoren/Keras-GAN">link</a></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>GAN implementation hacks</td>
<td>Salimans paper &amp; Chintala</td>
<td>World research</td>
<td><a href="https://github.com/soumith/ganhacks">link</a><a href="https://ceit.aut.ac.ir/~khalooei/tutorials/gan/#gan-hack-paper-2016">paper</a></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>DCGAN : Unsupervised Representation Learning with Deep Convolutional
Generative Adversarial Networks</td>
<td>Radford &amp; et al.</td>
<td>2015.11-ICLR 2016</td>
<td><a href="https://github.com/carpedm20/DCGAN-tensorflow">link</a><a href="https://arxiv.org/pdf/1511.06434.pdf">paper</a></td>
<td>64x64 human</td>
<td></td>
</tr>
<tr class="even">
<td>ProGAN:Progressive Growing of GANs for Improved Quality, Stability,
and Variation</td>
<td>Tero Karras</td>
<td>2017.10</td>
<td><a href="https://arxiv.org/pdf/1710.10196.pdf">paper</a><a href="https://github.com/tkarras/progressive_growing_of_gans">link</a></td>
<td>1024x1024 human</td>
<td>8.04</td>
</tr>
<tr class="odd">
<td>SAGAN：Self-Attention Generative Adversarial Networks</td>
<td>Han Zhang &amp; Ian Goodfellow</td>
<td>2018.05</td>
<td><a href="https://arxiv.org/pdf/1805.08318.pdf">paper</a><a href="https://github.com/taki0112/Self-Attention-GAN-Tensorflow">link</a></td>
<td>128x128 obj</td>
<td>18.65/52.52</td>
</tr>
<tr class="even">
<td>BigGAN:Large Scale GAN Training for High Fidelity Natural Image
Synthesis</td>
<td>Brock et al.</td>
<td>2018.09-ICLR 2019</td>
<td><a href="https://tfhub.dev/deepmind/biggan-256">demo</a><a href="https://arxiv.org/pdf/1809.11096.pdf">paper</a><a href="https://github.com/AaronLeong/BigGAN-pytorch">link</a></td>
<td>512x512 obj</td>
<td>9.6/166.3</td>
</tr>
<tr class="odd">
<td>StyleGAN:A Style-Based Generator Architecture for Generative
Adversarial Networks</td>
<td>Tero Karras</td>
<td>2018.12</td>
<td><a href="https://arxiv.org/pdf/1812.04948.pdf">paper</a><a href="https://github.com/NVlabs/stylegan">link</a></td>
<td>1024x1024 human</td>
<td>4.04</td>
</tr>
</tbody>
</table>
<h1><span id="gan的应用-level-3-gansapplications">GAN的应用 Level 3： GANs
Applications</span></h1>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th><a href="https://github.com/weslynn/AlphaTree-graphic-deep-neural-network/tree/master/GAN对抗生成网络/Image-translation图像翻译">图像翻译
(Image Translation)</a></th>
<th><a href="https://github.com/weslynn/AlphaTree-graphic-deep-neural-network/tree/master/GAN对抗生成网络/Super-Resolution超分辨率">超分辨率
(Super-Resolution)</a></th>
<th style="text-align: left;"><a href="https://github.com/weslynn/AlphaTree-graphic-deep-neural-network/tree/master/GAN对抗生成网络/Colourful-Image%20Colorization图像上色">图像上色(Colourful
Image Colorization)</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/weslynn/AlphaTree-graphic-deep-neural-network/blob/master/GAN对抗生成网络/Image%20Inpainting图像修复/README.md">图像修复(Image
Inpainting)</a></td>
<td><a href="https://github.com/weslynn/AlphaTree-graphic-deep-neural-network/tree/master/GAN对抗生成网络/Image-denoising图像去噪">图像去噪(Image
denoising)</a></td>
<td style="text-align: left;"><a href="https://github.com/weslynn/AlphaTree-graphic-deep-neural-network/tree/master/GAN对抗生成网络/交互式图像生成">交互式图像生成</a></td>
</tr>
</tbody>
</table>
<p>JS散度在没有重合的时候，是常数log2，分辨不出来</p>
<figure>
<img src="/Users/apple/Library/Application%20Support/typora-user-images/image-20210111131150941.png" alt="image-20210111131150941">
<figcaption aria-hidden="true">image-20210111131150941</figcaption>
</figure>
<h3><span id="lsgan">LSGAN</span></h3>
<figure>
<img src="/Users/apple/Library/Application%20Support/typora-user-images/image-20210111131817659.png" alt="image-20210111131817659">
<figcaption aria-hidden="true">image-20210111131817659</figcaption>
</figure>
<h3><span id="wgan">WGAN</span></h3>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20210111135312650.png" alt="image-20210111135312650" style="zoom: 50%;"><img src="/Users/apple/Library/Application Support/typora-user-images/image-20210111135334561.png" alt="image-20210111135334561" style="zoom:50%;"></p>
<figure>
<img src="/Users/apple/Library/Application%20Support/typora-user-images/image-20210111134930564.png" alt="image-20210111134930564">
<figcaption aria-hidden="true">image-20210111134930564</figcaption>
</figure>
<h3><span id="cganamp-acgan"></span></h3>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20210112232646090.png" alt="image-20210112232646090" style="zoom:33%;"></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>GAN</category>
      </categories>
  </entry>
  <entry>
    <title>模型训练（2）梯度消失&amp;爆炸</title>
    <url>/posts/3NAHDTK/</url>
    <content><![CDATA[<p><strong>本质上</strong>是因为神经网络的更新方法，梯度消失是因为反向传播过程中对梯度的求解会产生sigmoid导数和参数的连乘，sigmoid导数的最大值为0.25，权重一般初始都在0，1之间，乘积小于1，多层的话就会有多个小于1的值连乘，导致靠近输入层的梯度几乎为0，得不到更新。梯度爆炸是也是同样的原因，只是如果初始权重大于1，或者更大一些，多个大于1的值连乘，将会很大或溢出，导致梯度更新过大，模型无法收敛。<strong><font color="red">
梯度爆炸和梯度消失问题都是因为网络太深，网络权值更新不稳定造成的，本质上是因为梯度反向传播中的连乘效应。</font></strong></p>
<span id="more"></span>
<h3><span id="一-反向传播推导到梯度消失and爆炸的原因">一、反向传播推导到梯度消失and爆炸的原因</span></h3>
<h4><span id="11-反向传播推导">1.1 反向传播推导：</span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301915342.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>以上图为例开始推起来，先说明几点，i1，i2是输入节点，h1，h2为隐藏层节点，o1，o2为输出层节点，除了输入层，其他两层的节点结构为下图所示：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301915186.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>举例说明, <span class="math inline">\(N E T_{o 1}\)</span>
为输出层的输入, 也就是隐藏层的输出经过线性变换后的值, <span class="math inline">\(O U T_{o 1}\)</span> 为经过激活函数 sigmoid后的值;
同理 <span class="math inline">\(N E T_{h 1}\)</span> 为隐藏层的输入,
也就是输入层经过线性变换后的值, <span class="math inline">\(O U T_{h
1}\)</span> 为经过激活函数 sigmoid 的值。只有这两层有激活函数,
输入层没有。</p>
<p><strong>定义一下sigmoid的函数：</strong> <span class="math display">\[
\sigma(z)=\frac{1}{1+e^{-z}}
\]</span> <strong>说一下sigmoid的求导:</strong> <span class="math display">\[
\begin{aligned}
\sigma^{\prime}(z) &amp; =\left(\frac{1}{1+e^{-z}}\right)^{\prime} \\
&amp; =\frac{e^{-z}}{\left(1+e^{-z}\right)^2} \\
&amp; =\frac{1+e^{-z}-1}{\left(1+e^{-z}\right)^2} \\
&amp; =\frac{\sigma(z)}{\left(1+e^{-z}\right)^2} \\
&amp; =\sigma(z)(1-\sigma(z))
\end{aligned}
\]</span> 定义一下损失函数，这里的损失函数是均方误差函数，即: <span class="math display">\[
\text { Loss }_{\text {total }}=\sum \frac{1}{2}(\text { target }- \text
{ output })^2
\]</span> 具体到上图，就是: <span class="math display">\[
\text { Loss }_{\text {total }}=\frac{1}{2}(\operatorname{target}
1-\text out_{o1} )^2+\frac{1}{2}(\operatorname{target} 2-\text
out_{o2})^2
\]</span> 到这里, 所有前提就交代清楚了，前向传播就不推了，默认大家都会,
下面推反向传播。</p>
<ul>
<li><strong>第一个反向传播（热身）</strong></li>
</ul>
<p>先来一个简单的热热身, 求一下损失函数对W5的偏导, 即： <span class="math display">\[
\frac{\partial L o s s_{\text {total }}}{\partial w_5}
\]</span></p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304302031329.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><img src="https://pic2.zhimg.com/80/v2-7c0b41fdbd084ed875480516967857ed_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>首先根据链式求导法则写出对W5求偏导的总公式, 再把图拿下来对照 (如上),
可以看出, 需要计算三部分的求 导【损失函数、激活函数、线性函数】,
下面就一步一步来:</p>
<p><strong>第一步:</strong> <span class="math display">\[
\frac{\partial \text { Loss }_{\text {total }}}{\partial o u t_{o
1}}=\frac{\partial \frac{1}{2}\left(\text { target }_1-o u t_{o
1}\right)^2+\frac{1}{2}\left(\text { target }_2-\text { out }_{o
2}\right)^2}{\partial o u t_{o 1}}=out _{o 1}- target _1
\]</span> <strong>第二步：</strong> <span class="math display">\[
\frac{\partial o u t_{o 1}}{\partial \text { net }_{o 1}}=\frac{\partial
\frac{1}{1+e^{-n e t_{o 1}}}}{\partial \text { net }_{o
1}}=\sigma\left(\right.net \left._{o
1}\right)\left(1-\sigma\left(\right.\right. net \left.\left._{o
1}\right)\right)
\]</span></p>
<p><strong>第三步:</strong> <span class="math display">\[
\frac{\partial n e t_{o 1}}{\partial w_5}=\frac{\partial o u t_{h 1}
w_5+\text { out }_{h 2} w_6}{\partial w_5}= out _{h_1}
\]</span> 综上三个步骤，得到总公式:</p>
<p><strong>总公式:</strong> <span class="math display">\[
\frac{\partial L_{o s s_{t o t a l}}}{\partial w_5}=\left(o u t_{o
1}-\right. target \left._1\right) \cdot\left(\sigma\left(\right.\right.
net \left._{o 1}\right)\left(1-\sigma\left(\right.\right. net
\left.\left.\left._{o 1}\right)\right)\right) \cdot out _{h_1}
\]</span></p>
<ul>
<li><strong>第二个反向传播：</strong></li>
</ul>
<p>接下来，要求损失函数对<span class="math inline">\(w1\)</span>的偏导，即： <span class="math display">\[
\frac{\partial \operatorname{Loss}_{\text {total }}}{\partial w_1}
\]</span></p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-cbcb60d90cbd259a717cbe991aa93f5c_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><img src="https://pic2.zhimg.com/80/v2-7c0b41fdbd084ed875480516967857ed_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>还是把图摆在这, 方便看, 先写出总公式, 对w1求导有个地方要注意, <span class="math inline">\(w 1\)</span> 的影响不仅来自 01 还来自 02 , 从图上
可以一目了然, 所以总公式为: <span class="math display">\[
\frac{\partial \text { Loss }_{\text {total }}}{\partial w_1}= l1 + l2
\]</span></p>
<p><span class="math display">\[
l1 = \frac{\partial \text { Loss }_{\text {total }}}{\partial o u t_{o
1}} \frac{\partial o u t_{o 1}}{\partial \text { net }_{o 1}}
\frac{\partial n e t_{o 1}}{\partial \text { out }_{h 1}} \frac{\partial
o u t_{h 1}}{\partial \text { net }_{h 1}} \frac{\partial \text { net
}_{h 1}}{\partial w_1}
\]</span></p>
<p><span class="math display">\[
l2 = \frac{\partial \text { Loss }_{\text {total }}}{\partial \text {
out }_{o 2}} \frac{\text { out }_{o 2}}{\partial \text { net }_{o 2}}
\frac{\partial \text { net }_{o 2}}{\partial \text { out }_{h 1}}
\frac{\partial \text { out }_{h 1}}{\partial \text { net }_{h 1}}
\frac{\partial n e t_{h 1}}{\partial w_1}
\]</span></p>
<p>所以总共分为左右两个式子, 分别又对应 5 个步骤, 详细写一下左边,
右边同理:</p>
<p>第一步: <span class="math display">\[
\frac{\partial \text { Loss }_{\text {total }}}{\partial o u t_{o
1}}=out _{o 1}- target _1
\]</span></p>
<p>第二步: <span class="math display">\[
\frac{\partial o u t_{o 1}}{\partial \text { net }_{o 1}}=\sigma\left(n
e t_{o 1}\right)\left(1-\sigma\left(n_{e 1} t_{o 1}\right)\right)
\]</span></p>
<p>第三步: <span class="math display">\[
\frac{\partial \text { net }_{o 1}}{\partial o u t_{h 1}}=\frac{\partial
o u t_{h 1} w_5+\text { out }_{h 2} w_6}{\partial o u t_{h 1}}=w_5
\]</span></p>
<p>第四步： <span class="math display">\[
\frac{\partial o u t_{h 1}}{\partial \text { net }_{h
1}}=\sigma\left(\right. net \left._{h
1}\right)\left(1-\sigma\left(\right.\right.net \left.\left._{h
1}\right)\right)
\]</span></p>
<p>第二步: <span class="math display">\[
\frac{\partial n e t_{h 1}}{\partial w_1}=\frac{\partial i_1 w_1+i_2
w_2}{\partial w_1}=i_1
\]</span></p>
<p>右边也是同理, 就不详细写了, 写一下总的公式: <span class="math display">\[
\begin{aligned}
&amp; \frac{\partial \text { Loss }_{\text {total }}}{\partial
w_1}=\left(\left(\text { out }_{o 1}-\text { target }_1\right)
\cdot\left(\sigma\left(\text { net }_{o
1}\right)\left(1-\sigma\left(\text { net }_{o 1}\right)\right)\right)
\cdot w_5 \cdot\left(\sigma\left(\text { net }_{h
1}\right)\left(1-\sigma\left(\text { net }_{h 1}\right)\right)\right)
\cdot i_1\right) \\
&amp; +\left(\left(\text { out }_{o 2}-\text { target }_2\right)
\cdot\left(\sigma\left(\text { net }_{o
2}\right)\left(1-\sigma\left(\text { net }_{o 2}\right)\right)\right)
\cdot w_7 \cdot\left(\sigma\left(\text { net }_{h
1}\right)\left(1-\sigma\left(\text { net }_{h 1}\right)\right)\right)
\cdot i_1\right) \\
&amp;
\end{aligned}
\]</span> 这个公式只是对如此简单的一个网络结构的一个节点的偏导,
就这么复杂。。亲自推完才深深的意识到。。。</p>
<p>为了后面描述方便, 把上面的公式化简一下, out <span class="math inline">\({ }_{o 1}-\)</span> target <span class="math inline">\(_1\)</span> 记为 <span class="math inline">\(C_{o
1}, \sigma\left(\right.\)</span> net <span class="math inline">\(\left._{o
1}\right)\left(1-\sigma\left(\right.\right.\)</span> net <span class="math inline">\(\left.\left._{o 1}\right)\right)\)</span> 记为
<span class="math inline">\(\sigma\left(n_e t_{o
1}\right)^{\prime}\)</span> ，则: <span class="math display">\[
\frac{\partial \text { Loss }_{t_{\text {otal }}}}{\partial w_1}=C_{o 1}
\cdot \sigma\left(\text { net }_{o 1}\right)^{\prime} \cdot w_5 \cdot
\sigma\left(\text { net }_{h 1}\right)^{\prime} \cdot i_1+C_{o 2} \cdot
\sigma\left(\text { net }_{o 2}\right)^{\prime} \cdot w_7 \cdot
\sigma\left(n e t_{h 1}\right)^{\prime} \cdot i_1
\]</span></p>
<h4><span id="12梯度消失爆炸产生原因">1.2
<strong>梯度消失，爆炸产生原因</strong></span></h4>
<p>从上式其实已经能看出来, 求和操作其实不影响,
主要是是看乘法操作就可以说明问题, 可以看出, 损失函数对 w1的偏导, 与
<span class="math inline">\(C_{o 1}\)</span>, 权重w, sigmoid的导数有关,
明明还有输入i为什么不提? 因为如果是多层神经网络的中间
某层的某个节点，那么就没有输入什么事了。所以产生影响的就是刚刚提的三个因素。</p>
<p>再详细点描述，如图，多层神经网络：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011352977.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>参考：</strong><a href="https://zhuanlan.zhihu.com/p/25631496">PENG：神经网络训练中的梯度消失与梯度爆炸282
赞同 · 26 评论文章</a></p>
<p>假设 (假设每一层只有一个神经元且对于每一层 <span class="math inline">\(y_i=\sigma\left(z_i\right)=\sigma\left(w_i
x_i+b_i\right)\)</span>, 其中 <span class="math inline">\(\sigma\)</span> 为sigmoid函数), 如图:</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-ea9beb6c28c7d4e89be89dc5f4cbae2e_1440w.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>则：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \frac{\partial C}{\partial b_1}=\frac{\partial C}{\partial y_4}
\frac{\partial y_4}{\partial z_4} \frac{\partial z_4}{\partial x_4}
\frac{\partial x_4}{\partial z_3} \frac{\partial z_3}{\partial x_3}
\frac{\partial x_3}{\partial z_2} \frac{\partial z_2}{\partial x_2}
\frac{\partial x_2}{\partial z_1} \frac{\partial z_1}{\partial b_1} \\
&amp; =C_{y 4} \sigma^{\prime}\left(z_4\right) w_4
\sigma^{\prime}\left(z_3\right) w_3 \sigma^{\prime}\left(z_2\right) w_2
\sigma^{\prime}\left(z_1\right)
\end{aligned}
\]</span></p>
<p>看一下sigmoid函数的求导之后的样子：</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-208a4aa5dc657fe86919f3549d853793_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>发现sigmoid函数求导后最大最大也只能是0.25。</strong></p>
<p>再来看W，一般我们初始化权重参数W时，通常都小于1，用的最多的应该是0，1正态分布吧。</p>
<p><font color="red">所以 <span class="math inline">\(\left|\sigma^{\prime}(z) w\right| \leq
0.25\)</span>, 多个小于1的数连乘之后, 那将会越来越小,
导致靠近输入层的层的权重的偏导几乎为 0 ,
也就是说几乎不更新，这就是梯度消失的根本原因。</font></p>
<p>再来看看<strong>梯度爆炸</strong>的原因, 也就是说如果 <span class="math inline">\(\left|\sigma^{\prime}(z) w\right| \geq 1\)</span>
时，连乘下来就会导致梯度过大, 导致梯度更新幅度特别 大, 可能会溢出,
导致模型无法收玫。sigmoid的函数是不可能大于1了, 上图看的很清楚,
那只能是w了, 这也 就是经常看到别人博客里的一句话, 初始权重过大,
一直不理解为啥。。现在明白了。</p>
<p>但梯度爆炸的情况一般不会发生, 对于sigmoid函数来说, <span class="math inline">\(\sigma(z)^{\prime}\)</span> 的大小也与w有关, 因为
<span class="math inline">\(z=w x+b\)</span>, 除非该层的输入值 <span class="math inline">\(x\)</span> 在一直一个比较小的范围内。</p>
<p>其实<strong>梯度爆炸和梯度消失问题都是因为网络太深</strong>,
网络权值更新不稳定造成的, 本质上是因为<strong>梯度反向传播中的连
乘效应。</strong></p>
<p><strong><font color="red">所以，总结一下，为什么会发生梯度爆炸和消失：</font></strong></p>
<p>本质上是因为神经网络的更新方法，梯度消失是因为反向传播过程中对梯度的求解会产生sigmoid导数和参数的连乘，sigmoid导数的最大值为0.25，权重一般初始都在0，1之间，乘积小于1，多层的话就会有多个小于1的值连乘，导致靠近输入层的梯度几乎为0，得不到更新。梯度爆炸是也是同样的原因，只是如果初始权重大于1，或者更大一些，多个大于1的值连乘，将会很大或溢出，导致梯度更新过大，模型无法收敛。</p>
<h3><span id="二-梯度消失-爆炸解决方案">二、梯度消失、爆炸解决方案</span></h3>
<h4><span id="21预训练加微调"><strong>2.1（预训练加微调）：</strong></span></h4>
<p>提出采取无监督逐层训练方法，其基本思想是每次训练一层隐节点，训练时将上一层隐节点的输出作为输入，而本层隐节点的输出作为下一层隐节点的输入，此过程就是逐层“预训练”（pre-training）；在预训练完成后，再对整个网络进行“微调”（<strong>fine-tunning</strong>）。</p>
<p>Hinton在训练深度信念网络（Deep Belief
Networks中，使用了这个方法，在各层预训练完成后，再利用BP算法对整个网络进行训练。此思想相当于是先寻找局部最优，然后整合起来寻找全局最优，此方法有一定的好处，但是目前应用的不是很多了。</p>
<h4><span id="22梯度剪切-正则"><strong>2.2（梯度剪切、正则）：</strong></span></h4>
<p><strong>梯度剪切</strong>这个方案主要是针对梯度爆炸提出的，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。</p>
<p><strong>正则化</strong>是通过对网络权重做正则限制过拟合，仔细看正则项在损失函数的形式：
<span class="math display">\[
Loss =\left(y-W^T x\right)^2+\alpha\|W\|^2
\]</span> 其中，<span class="math inline">\(\alpha\)</span>是指正则项系数，因此，如果发生梯度爆炸，权值的范数就会变的非常大，通过正则化项，可以部分限制梯度爆炸的发生。</p>
<p>注：事实上，在深度神经网络中，往往是梯度消失出现的更多一些</p>
<h4><span id="23改变激活函数"><strong><font color="red">
2.3（改变激活函数）：</font></strong></span></h4>
<p>首先说明一点，<strong>tanh激活函数不能有效的改善这个问题</strong>，先来看tanh的形式：</p>
<p><span class="math display">\[
\tanh (x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}
\]</span></p>
<p>再来看tanh的导数图像：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011401273.jpg" alt="img" style="zoom:50%;"></p>
<p><strong>发现虽然比sigmoid的好一点，sigmoid的最大值小于0.25，tanh的最大值小于1，但仍是小于1的，所以并不能解决这个问题。</strong></p>
<p><strong>Relu</strong>:思想也很简单，如果激活函数的导数为1，那么就不存在梯度消失爆炸的问题了，每层的网络都可以得到相同的更新速度，relu就这样应运而生。先看一下relu的数学表达式：
<span class="math display">\[
\operatorname{Re} \operatorname{lu}(\mathrm{x})=\max (\mathrm{x},
0)=\left\{\begin{array}{l}0, x&lt;0 \\ x, x&gt;0\end{array}\right\}
\]</span></p>
<p><img src="https://pic2.zhimg.com/80/v2-55475ee2d90cd7257a39f62549a65769_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>从上图中，我们可以很容易看出，<strong>relu函数的导数在正数部分是恒等于1的，因此在深层网络中使用relu激活函数就不会导致梯度消失和爆炸的问题。</strong></p>
<p><strong>relu</strong>的主要贡献在于：</p>
<ul>
<li>解决了梯度消失、爆炸的问题</li>
<li>计算方便，计算速度快</li>
<li>加速了网络的训练</li>
</ul>
<p>同时也存在一些<strong>缺点</strong>：</p>
<ul>
<li><strong>由于负数部分恒为0，会导致一些神经元无法激活（可通过设置小学习率部分解决）</strong></li>
<li>输出不是以0为中心的</li>
</ul>
<p><strong>leakrelu</strong></p>
<p>leakrelu就是为了解决relu的0区间带来的影响, 其数学表达为： leakrelu
<span class="math inline">\(=f(x)=\left\{\begin{array}{ll}x, &amp;
x&gt;0 \\ x * k, &amp; x \leq 0\end{array}\right.\)</span> 其中k是leak
系数, 一般选择 0.1 或者 0.2 , 或者通过学习而来解决死神经元的问题。</p>
<p><img src="https://pic4.zhimg.com/80/v2-3ab1bd8fb85542a0c85eb907b73fa327_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>leakrelu解决了0区间带来的影响，而且包含了relu的所有优点</p>
<p><strong>elu</strong></p>
<p>elu激活函数也是为了解决relu的0区间带来的影响, 其数学表达为: <span class="math display">\[
\left\{\begin{array}{cc}
x, &amp; \text { if } x&gt;0 \\
\alpha\left(e^x-1\right), &amp; \text { otherwise }
\end{array}\right.
\]</span> 其函数及其导数数学形式为：</p>
<p><img src="https://pic3.zhimg.com/80/v2-ec3c80e51129bd76d49cad6e52d449c2_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>但是elu相对于leakrelu来说，计算要更耗时间一些，因为有e。</p>
<h4><span id="24batchnorm梯度消失"><strong>2.4（batchnorm）：</strong>【梯度消失】</span></h4>
<p>Batchnorm是深度学习发展以来提出的最重要的成果之一了,
目前已经被广泛的应用到了各大网络中, 具有加速网络收玫速度,
提升训练稳定性的效果,
Batchnorm本质上是解决反向传播过程中的梯度问题。batchnorm全名是batch
normalization, 简称 <span class="math inline">\(\mathrm{BN}\)</span>,
即批规范化, 通过规范化操作将输出信号x规范化到均值为 0 , 方差为 1
保证网络的稳定性。</p>
<p>具体的batchnorm原理非常复杂, 在这里不做详细展开,
此部分大概讲一下batchnorm解决梯度的问题上。具体来说就是反向传播中,
经过每一层的梯度会乘以该层的权重, 举个简单例子：正向传播中 <span class="math inline">\(f_3=f_2\left(w^T * x+b\right)\)</span>,
那么反向传播中, <span class="math inline">\(\frac{\partial f_2}{\partial
x}=\frac{\partial f_2}{\partial f_1} w\)</span>, 反向传播式子中有 <span class="math inline">\(w\)</span> 的存在, 所以 <span class="math inline">\(w\)</span>
的大小影响了梯度的消失和爆炸,batchnorm就是通过对每一层的输出做scale和shift的方法，通过一定的规范化手段，<strong>把每层神经网络任意神经元这个输入值的分布【假设原始是正态分布】强行拉回到接近均值为0方差为1的标准正太分布，即严重偏离的分布强制拉回比较标准的分布，<font color="red">
这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，使得让梯度变大，避免梯度消失问题产生</font>，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。</strong></p>
<h4><span id="25残差结构"><strong><font color="red">
2.5（残差结构）：</font></strong></span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011409884.jpg" alt="img" style="zoom:50%;"></p>
<p>如图, 把输入加入到某层中, 这样求导时, 总会有个1在,
这样就不会梯度消失了。 <span class="math display">\[
\frac{\partial \text { loss }}{\partial x_l}=\frac{\partial \text { loss
}}{\partial x_L} \cdot \frac{\partial x_L}{\partial x_l}=\frac{\partial
\text { loss }}{\partial x_L} \cdot\left(1+\frac{\partial}{\partial x_L}
\sum_{i=l}^{L-1} F\left(x_i, W_i\right)\right)
\]</span> 式子的第一个因子 <span class="math inline">\(\frac{\partial l
o s s}{\partial x_L}\)</span> 表示的损失函数到达 <span class="math inline">\(\mathrm{L}\)</span> 的梯度, 小括号中的 1
表明短路机制可以无损地传播梯度,
而另外一项残差梯度则需要经过带有weights的层,
梯度不是直接传递过来的。残差梯度不会那么巧全为- 1 , 而且就算其比较小, 有
1 的存在也不会导致梯度消失。所以残差学习会更容易。</p>
<p><code>注：上面的推导并不是严格的证</code>，只为帮助理解</p>
<h4><span id="26lstm"><strong><font color="red">2.6（LSTM）</font></strong></span></h4>
<p>在介绍这个方案之前，有必要来推导一下RNN的反向传播，<strong>因为关于梯度消失的含义它跟DNN不一样！不一样！不一样！</strong></p>
<p>先推导再来说，从这copy的：<a href="https://zhuanlan.zhihu.com/p/28687529">沉默中的思索：RNN梯度消失和爆炸的原因565
赞同</a></p>
<p>RNN结构如图：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011410693.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>假设我们的时间序列只有三段, <span class="math inline">\(S_0\)</span>
为给定值, 神经元没有激活函数, 则RNN最简单的前向传播过程如下: <span class="math display">\[
\begin{array}{ll}
S_1=W_x X_1+W_s S_0+b_1 &amp; O_1=W_o S_1+b_2 \\
S_2=W_x X_2+W_s S_1+b_1 &amp; O_2=W_o S_2+b_2 \\
S_3=W_x X_3+W_s S_2+b_1 &amp; O_3=W_o S_3+b_2
\end{array}
\]</span> 假设在 <span class="math inline">\(\mathrm{t}=3\)</span> 时刻,
损失函数为 <span class="math inline">\(L_3=\frac{1}{2}\left(Y_3-O_3\right)^2\)</span>
。</p>
<p>则对于一次训练任务的损失函数为 <span class="math inline">\(L=\sum_{t=0}^T L_t\)</span>,
即每一时刻损失值的累加。</p>
<p>使用随机梯度下降法训练 <span class="math inline">\(\mathrm{RNN}\)</span> 其实就是对 <span class="math inline">\(W_x\)</span> 、 <span class="math inline">\(W_s\)</span> 、 <span class="math inline">\(W_o\)</span> 以及 <span class="math inline">\(b_1
b_2\)</span> 求偏导, 并不断调整它们以使L尽可能达 到最小的过程。</p>
<p>现在假设我们我们的时间序列只有三段, <span class="math inline">\(t 1,
t 2, t 3\)</span> 。<strong>我们只对 <span class="math inline">\(\mathrm{t}\)</span> 时刻的 <span class="math inline">\(W_x 、 W_s 、 W_0\)</span>
求偏导（其他时刻类似）：</strong> <span class="math display">\[
\begin{gathered}
\frac{\partial L_3}{\partial W_0}=\frac{\partial L_3}{\partial O_3}
\frac{\partial O_3}{\partial W_o} \\
\frac{\partial L_3}{\partial W_x}=\frac{\partial L_3}{\partial O_3}
\frac{\partial O_3}{\partial S_3} \frac{\partial S_3}{\partial
W_x}+\frac{\partial L_3}{\partial O_3} \frac{\partial O_3}{\partial S_3}
\frac{\partial S_3}{\partial S_2} \frac{\partial S_2}{\partial
W_x}+\frac{\partial L_3}{\partial O_3} \frac{\partial O_3}{\partial S_3}
\frac{\partial S_3}{\partial S_2} \frac{\partial S_2}{\partial S_1}
\frac{\partial S_1}{\partial W_x} \\
\frac{\partial L_3}{\partial W_s}=\frac{\partial L_3}{\partial O_3}
\frac{\partial O_3}{\partial S_3} \frac{\partial S_3}{\partial
W_s}+\frac{\partial L_3}{\partial O_3} \frac{\partial O_3}{\partial S_3}
\frac{\partial S_3}{\partial S_2} \frac{\partial S_2}{\partial
W_s}+\frac{\partial L_3}{\partial O_3} \frac{\partial O_3}{\partial S_3}
\frac{\partial S_3}{\partial S_2} \frac{\partial S_2}{\partial S_1}
\frac{\partial S_1}{\partial W_s}
\end{gathered}
\]</span> <strong>可以看出对于 <span class="math inline">\(W_0\)</span>
求偏导并没有长期依赖，但是对于 <span class="math inline">\(W_x 、
W_s\)</span> 求偏导，会随着时间序列产生长期依赖。</strong>因为 <span class="math inline">\(S_t\)</span> 随着时间序列向前传播, 而 <span class="math inline">\(S_t\)</span> 又是 <span class="math inline">\(W_x
、 W_s\)</span> 的函数。</p>
<p>根据上述求偏导的过程, 我们可以得出任意时刻对 <span class="math inline">\(W_x 、 W_s\)</span> 求偏导的公式： <span class="math display">\[
\frac{\partial L_t}{\partial W_x}=\sum_{k=0}^t \frac{\partial
L_t}{\partial O_t} \frac{\partial O_t}{\partial
S_t}\left(\prod_{j=k+1}^t \frac{\partial S_j}{\partial S_{j-1}}\right)
\frac{\partial S_k}{\partial W_x}
\]</span> 任意时刻对 <span class="math inline">\(W_s\)</span>
求偏导的公式同上。</p>
<p>如果加上激活函数, <span class="math inline">\(S_j=\tanh \left(W_x
X_j+W_s S_{j-1}+b_1\right)\)</span> ，则 <span class="math inline">\(\prod_{j=k+1}^t \frac{\partial S_j}{\partial
S_{j-1}}=\prod_{j=k+1}^t \tanh W_s^{\prime}\)</span> 激活函数tanh和它的
导数图像在上面已经说过了, 所以原因在这就不帻述了, 还是一样的,
激活函数导数小于 1 。</p>
<p><strong><font color="red">现在来解释一下，为什么说RNN和DNN的梯度消失问题含义不一样？</font></strong></p>
<ul>
<li><strong>先来说DNN中的反向传播：</strong>在上文的DNN反向传播中，我推导了两个权重的梯度，第一个梯度是直接连接着输出层的梯度，求解起来并没有梯度消失或爆炸的问题，因为它没有连乘，只需要计算一步。第二个梯度出现了连乘，也就是说越靠近输入层的权重，梯度消失或爆炸的问题越严重，可能就会消失会爆炸。<strong>一句话总结一下，DNN中各个权重的梯度是独立的，该消失的就会消失，不会消失的就不会消失。</strong></li>
<li><strong>再来说RNN：</strong>RNN的特殊性在于，它的权重是共享的。抛开W_o不谈，因为它在某时刻的梯度不会出现问题（某时刻并不依赖于前面的时刻），但是W_s和W_x就不一样了，每一时刻都由前面所有时刻共同决定，是一个相加的过程，这样的话就有个问题，当距离长了，计算最前面的导数时，最前面的导数就会消失或爆炸，但当前时刻整体的梯度并不会消失，因为它是求和的过程，当下的梯度总会在，只是前面的梯度没了，但是更新时，由于权值共享，所以整体的梯度还是会更新，<strong>通常人们所说的梯度消失就是指的这个，指的是当下梯度更新时，用不到前面的信息了，因为距离长了，前面的梯度就会消失，也就是没有前面的信息了，但要知道，整体的梯度并不会消失，因为当下的梯度还在，并没有消失。</strong></li>
<li><strong>一句话概括：</strong>RNN的梯度不会消失，RNN的梯度消失指的是当下梯度用不到前面的梯度了，但DNN靠近输入的权重的梯度是真的会消失。</li>
</ul>
<p>说完了RNN的反向传播及梯度消失的含义，终于该说<strong>为什么LSTM可以解决这个问题了</strong>，这里默认大家都懂LSTM的结构，对结构不做过多的描述。<strong>见第三节</strong>。【LSTM通过它的“门控装置”有效的缓解了这个问题，这也就是为什么我们现在都在使用LSTM而非普通RNN。】</p>
<h3><span id="三-缓解梯度消失amp爆炸-qampa">三、缓解梯度消失&amp;爆炸 Q&amp;A</span></h3>
<h4><span id="1-残差神经网络为什么可以缓解梯度消失">1、残差神经网络为什么可以缓解梯度消失？</span></h4>
<p><strong>残差单元可以以跳层连接的形式实现，即将单元的输入直接与单元输出加在一起，然后再激活</strong>。因此残差网络可以轻松地用主流的自动微分深度学习框架实现，直接使用BP算法更新参数损失对某低层输出的梯度，被分解为了两项。</p>
<p><strong>（1）从前后向信息传播的角度来看</strong></p>
<p><strong>普通神经网络前向传播</strong>。前向传播将数据特征逐层抽象,
最终提取出完成任务所需要的特征/表示。 <span class="math display">\[
a^{l_2}=F\left(a^{l_2-1}\right)=F\left(F\left(a^{l_2-2}\right)\right)=\ldots
\]</span>
<strong>普通神经网络反向传播</strong>。梯度涉及两层参数交叉相乘,
可能会在离输入近的网络中产生梯度消失的现象。 <span class="math display">\[
\frac{\partial \epsilon}{\partial a^{l_1}}=\frac{\partial
\epsilon}{\partial a^{l_2}} \frac{\partial a^{l_2}}{\partial
a^{l_1}}=\frac{\partial \epsilon}{\partial a^{l_2}} \frac{\partial
a^{l_2}}{\partial a^{l_2-1}} \ldots \frac{\partial a^{l_1+1}}{\partial
a^{l_1}}
\]</span>
<strong>残差网络前向传播</strong>。输入信号可以从任意低层直接传播到高层。由于包含了一个天然的恒等映射，一定程度上可以
解决网络退化问题。 <span class="math display">\[
a^{l_2}=a^{l_2-1}+F\left(a^{l_2-1}\right)=\left(a^{l_2-2}+F\left(a^{l_2-2}\right)\right)+F\left(a^{l_2-1}\right)=\ldots=a^{l_1}+\sum_{i=l_1}^{l_2-1}
F\left(a^i\right)
\]</span> <strong>残差网络反向传播</strong>。 <span class="math inline">\(\frac{\partial \epsilon}{\partial
a^{l_2}}\)</span> 表明, 反向传播时,
错误信号可以不经过任何中间权重矩阵变换直接传播到低层, 一定
程度上可以缓解梯度弥散问题（即便中间层矩阵权重很小，梯度也基本不会消失）。
<span class="math display">\[
\frac{\partial \epsilon}{\partial a^{l_1}}=\frac{\partial
\epsilon}{\partial a^{l_2}}\left(1+\frac{\partial \sum_{i=l_1}^{l_2-1}
F\left(a^i\right)}{a^{l_1}}\right)
\]</span> 所以可以认为残差连接使得信息前后向传播更加顺畅。</p>
<p><strong>(2) 集成学习的角度</strong></p>
<p>将残差网络展开，以一个三层的ResNet为例，可得到下面的树形结构: <span class="math display">\[
\begin{array}{ll}
y_3=y_2+f_3\left(y_2\right)=
\left[y_1+f_2\left(y_1\right)\right]+f_3\left(y_1+f_2\left(y_1\right)\right)
\\
=\left[y_0+f_1\left(y_0\right)+f_2\left(y_0+f_1\left(y_0\right)\right)\right]+f_3\left(y_0+f_1\left(y_0\right)+f_2\left(y_0+f_1\left(y_0\right)\right)\right)
\end{array}
\]</span> <img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011420876.jpg" alt="img"></p>
<p>残差网络就可以被看作是一系列路径集合组装而成的一个集成模型，其中不同的路径包含了不同的网络层子集。</p>
<h5><span id="特点">特点：</span></h5>
<ol type="1">
<li>跳层连接;</li>
<li>例子：DCN（Deep Cross Network）、Transformer;</li>
<li>有效的缓解梯度消失问题的手段;</li>
<li>输入和输出维度一致，因为残差正向传播有相加的过程<span class="math inline">\(a^{l_2}=a^{l_2-1}+F\left(a^{l_2-1}\right)\)</span>;</li>
</ol>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><strong>残差神经网络为什么可以缓解梯度消失？</strong> - 十三的文章 -
知乎 https://zhuanlan.zhihu.com/p/452867110</li>
<li>从反向传播推导到梯度消失and爆炸的原因及解决方案（从DNN到RNN，内附详细反向传播公式推导）
- 韦伟的文章 - 知乎 https://zhuanlan.zhihu.com/p/76772734</li>
<li><a href="https://zhuanlan.zhihu.com/p/33006526">DoubleV：详解深度学习中的梯度消失、爆炸原因及其解决方法</a></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>训练技巧</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>梯度消失</tag>
        <tag>梯度爆炸</tag>
      </tags>
  </entry>
  <entry>
    <title>模型训练（1）loss不下降</title>
    <url>/posts/K4HD8V/</url>
    <content><![CDATA[<h3><span id="一-训练的时候-loss不下降">一、<strong>训练的时候 loss
不下降</strong></span></h3>
<ul>
<li><strong>模型结构问题</strong>。当模型结构不好、规模小时，模型对数据的拟合能力不足。</li>
<li>训练时间问题。不同的模型有不同的计算量，当需要的计算量很大时，耗时也会很大</li>
<li><strong>权重初始化问题</strong>。常用的初始化方案有全零初始化、正态分布初始化和均匀分布初始化等，合适的初始化方案很重要，之前提到过<strong><a href="http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/OcEqqQq59a-djZqBsh_7Zw">神经网络初始化为0可能会带来的影响</a></strong></li>
<li><strong>正则化问题</strong>。L1、L2以及Dropout是为了防止过拟合的，当训练集loss下不来时，就要考虑一下是不是正则化过度，导致模型欠拟合了。正则化相关可参考<strong><a href="https://zhuanlan.zhihu.com/p/418228948">正则化之L1 &amp;
L2</a></strong></li>
<li><strong>激活函数问题</strong>。全连接层多用ReLu，神经网络的输出层会使用sigmoid
或者 softmax。激活函数可参考<strong><a href="https://zhuanlan.zhihu.com/p/455086947">常用的几个激活函数</a></strong>。在使用Relu激活函数时，当每一个神经元的输入为负时，会使得该神经元输出恒为0，导致失活，由于此时梯度为0，无法恢复。</li>
<li><strong>优化器问题</strong>。优化器一般选取Adam，但是当Adam难以训练时，需要使用如SGD之类的其他优化器。常用优化器可参考<strong><a href="https://zhuanlan.zhihu.com/p/446357922">机器学习中常用的优化器有哪些？</a></strong></li>
<li><strong>学习率问题</strong>。学习率决定了网络的训练速度，但学习率不是越大越好，当网络趋近于收敛时应该选择较小的学习率来保证找到更好的最优点。所以，我们需要手动调整学习率，首先选择一个合适的初始学习率，当训练不动之后，稍微降低学习率。</li>
<li><strong><font color="red">
梯度消失和爆炸。</font></strong>这时需要考虑激活函数是否合理，网络深度是否合理，可以通过调节sigmoid
-&gt; relu，假如残差网络等，相关可参考<strong><a href="https://zhuanlan.zhihu.com/p/442914336">为什么神经网络会有梯度消失和梯度爆炸问题？如何解决？</a></strong></li>
<li><strong>batch
size过小</strong>，会导致模型损失波动大，难以收敛，过大时，模型前期由于梯度的平均，导致收敛速度过慢。</li>
<li>数据集问题。（1）数据集未打乱，可能会导致网络在学习过程中产生一定的偏见（2）噪声过多、标注有大量错误时，会导致神经网络难以学到有用的信息，从而出现摇摆不定的情况，<strong><a href="https://zhuanlan.zhihu.com/p/434532885">噪声、缺失值、异常值</a></strong>（3）数据类别不均衡使得少数类别由于信息量不足，难以学到本质特征，样本不均衡相关可以看<strong><a href="https://zhuanlan.zhihu.com/p/411613746">样本不均衡及其解决办法</a></strong>。</li>
<li><strong>特征问题</strong>。特征选择不合理，会使网络学习难度增加。之前有提到过特征选择的文章，<strong><a href="http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/WO_NCTt1O1tgYkZV4vnd7g">如何找到有意义的组合特征</a></strong>,<strong><a href="http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/CN7AIhoU3SKOK_Sej6i5Jw">特征选择方法</a></strong></li>
</ul>
<h3><span id="二-测试的时候-loss不下降">二、<strong>测试的时候 loss
不下降</strong></span></h3>
<blockquote>
<p>训练的时候过拟合导致效果不好</p>
</blockquote>
<ul>
<li><strong><a href="https://zhuanlan.zhihu.com/p/437803892">交叉检验</a></strong>，通过交叉检验得到较优的模型参数;</li>
<li><strong><a href="https://zhuanlan.zhihu.com/p/434089082">特征选择</a></strong>，减少特征数或使用较少的特征组合，对于按区间离散化的特征，增大划分的区间;</li>
<li><strong><a href="https://zhuanlan.zhihu.com/p/418228948">正则化</a></strong>，常用的有
L1、L2 正则。而且 L1正则还可以自动进行特征选择;</li>
<li>如果有正则项则可以考虑增大正则项参数<img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="[公式]">;</li>
<li>增加训练数据可以有限的避免过拟合;</li>
<li>Bagging ,将多个弱学习器Bagging
一下效果会好很多，比如随机森林等.</li>
<li>早停策略。本质上是交叉验证策略，选择合适的训练次数，避免训练的网络过度拟合训练数据。</li>
<li><strong><a href="https://zhuanlan.zhihu.com/p/410867062">DropOut策略</a></strong>。</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>训练技巧</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>训练技巧</tag>
      </tags>
  </entry>
  <entry>
    <title>模型训练（4）Batch and Momentum</title>
    <url>/posts/N29PC4/</url>
    <content><![CDATA[<h3><span id="一-李宏毅课程笔记batchand-momentum">一、李宏毅课程笔记：Batch
and Momentum</span></h3>
<h4><span id="11-review-optimization-withbatch">1.1 Review： Optimization with
Batch</span></h4>
<p>上次我们有讲说,我们<strong>实际上在算微分的时候,并不是真的对所有 Data
算出来的 L 作微分</strong>,你是把所有的 Data 分成一个一个的
Batch,有的人是叫Mini Batch ,那我这边叫做
Batch,其实指的是一样的东西,助教投影片里面,是写 Mini Batch。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011438961.png" style="zoom:67%;"></p>
<p>每一个 Batch 的大小呢,就是大 B 一笔的资料,我们每次<strong>在 Update
参数的时候,我们是拿大 B 一笔资料出来,算个 Loss,算个 Gradient,Update
参数</strong>,拿另外B一笔资料,再算个 Loss,再算个 Gradient,再 Update
参数,以此类推,所以我们不会拿所有的资料一起去算出 Loss,我们只会拿一个
Batch 的资料,拿出来算 Loss。</p>
<p><strong>所有的 Batch 看过一遍,叫做一个
Epoch</strong>,那事实上啊,你今天在做这些 Batch 的时候,你会做一件事情叫做
Shuffle</p>
<p>Shuffle
有很多不同的做法,但一个常见的做法就是,<strong><font color="red">
在每一个 Epoch 开始之前,会分一次 Batch,然后呢,每一个 Epoch 的 Batch
都不一样</font></strong>,就是第一个 Epoch,我们分这样子的 Batch,第二个
Epoch,会重新再分一次 Batch,所以哪些资料在同一个 Batch 里面,每一个 Epoch
都不一样的这件事情,叫做 <strong>Shuffle</strong>。</p>
<h4><span id="12-small-batch-vs-largebatch">1.2 Small Batch v.s. Large
Batch</span></h4>
<p>​ 我们先解释为什么要用 Batch,再说 Batch 对 Training
带来了什么样的帮助。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011438778.png" alt="image-20220616164656382" style="zoom:50%;"></p>
<p>我们来比较左右两边这两个 Case,那假设现在我们有20笔训练资料</p>
<ul>
<li>左边的 Case 就是没有用 Batch,Batch
Size,直接设的跟我训练资料一样多,这种状况叫做 Full Batch,就是没有用 Batch
的意思</li>
<li>那右边的 Case 就是,Batch Size 等於1</li>
</ul>
<p>​ 这是两个最极端的状况</p>
<p>我们先来看左边的 Case,在左边 Case 里面,因为没有用 Batch,我们的 Model
必须把20笔训练资料都看完,才能够计算 Loss,才能够计算
Gradient,所以我们必须要把<strong>所有20笔 Example s
都看完以后,我们的参数才能够 Update
一次</strong>。就假设开始的地方在上边边,把所有资料都看完以后,Update
参数就从这里移动到下边。</p>
<p>如果 Batch Size 等於1的话,代表我们只需要拿一笔资料出来算
Loss,我们就可以 Update 我们的参数,所以每次我们 Update
参数的时候,看一笔资料就好,所以我们开始的点在这边,看一笔资料 就 Update
一次参数,再看一笔资料 就 Update 一次参数,如果今天总共有20笔资料的话
那<strong>在每一个 Epoch 里面,我们的参数会 Update
20次</strong>,那不过,因为我们现在是只看一笔资料,就 Update
一次参数,所以用一笔资料算出来的 Loss,显然是比较 Noisy 的,所以我们今天
Update 的方向,你会发现它是曲曲折折的</p>
<p>所以如果我们比较左边跟右边，哪一个比较好呢,他们有什么差别呢？</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011438236.png" alt="image-20220616165328450" style="zoom:50%;"></p>
<p>你会发现左边没有用 Batch
的方式,它蓄力的时间比较长,还有它技能冷却的时间比较长,你要把所有的资料都看过一遍,才能够
Update 一次参数</p>
<p>而右边的这个方法,Batch Size
等於1的时候,蓄力的时间比较短,每次看到一笔参数,每次看到一笔资料,你就会更新一次你的参数</p>
<p>所以今天假设有20笔资料,看完所有资料看过一遍,你已经更新了20次的参数,但是左边这样子的方法有一个优点,就是它这一步走的是稳的,那右边这个方法它的缺点,就是它每一步走的是不稳的</p>
<p>看起来左边的方法跟右边的方法,他们各自都有擅长跟不擅长的东西,左边是蓄力时间长,但是威力比较大,右边技能冷却时间短,但是它是比较不準的,看起来各自有各自的优缺点,但是你会觉得说,左边的方法技能冷却时间长,右边的方法技能冷却时间短,那只是你没有考虑并行运算的问题。</p>
<p><strong>实际上考虑并行运算的话,左边这个并不一定时间比较长</strong></p>
<h4><span id="13larger-batch-size-does-not-require-longer-time-to-compute-gradient">1.3
Larger batch size does not require longer time to compute gradient</span></h4>
<p>这边是真正的实验结果了,事实上,比较大的 Batch Size,你要算
Loss,再进而算 Gradient,所需要的时间,不一定比小的 Batch Size
要花的时间长。</p>
<p>那以下是做在一个叫做 MNIST 上面,MNIST (Mixed National Institute of
Standards and Technology
database)是美国国家标准与技术研究院收集整理的大型手写数字数据库,机器要做的事情,就是给它一张图片,然后判断这张图片,是0到9的哪一个数字,它要做数字的分类,那
MNIST 呢
是机器学习的helloworld,就是假设你今天,从来没有做过机器学习的任务,一般大家第一个会尝试的机器学习的任务,往往就是做
MNIST 做手写数字辨识,</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011438827.png" alt="image-20220616165208136" style="zoom:50%;"></p>
<p>这边我们就是做了一个实验,我们想要知道说,给机器一个 Batch,它要计算出
Gradient,进而 Update 参数,到底需要花多少的时间</p>
<p>这边列出了 Batch Size 等於1 等於10,等於100 等於1000
所需要耗费的时间</p>
<p><strong>你会发现说 Batch Size
从1到1000,需要耗费的时间几乎是一样的,你可能直觉上认为有1000笔资料</strong>,那需要计算
Loss,然后计算
Gradient,花的时间不会是一笔资料的1000倍吗,但是实际上并不是这样的</p>
<p><strong><font color="red"> 因为在实际上做运算的时候,我们有
GPU,可以做并行运算,是因为你可以做平行运算的关係,这1000笔资料是平行处理的,所以1000笔资料所花的时间,并不是一笔资料的1000倍</font></strong>。当然
GPU 平行运算的能力还是有它的极限,当你的 Batch Size
真的非常非常巨大的时候,GPU 在跑完一个 Batch,计算出 Gradient
所花费的时间,还是会随著 Batch Size 的增加,而逐渐增长</p>
<p>所以今天如果 Batch Size
是从1到1000,所需要的时间几乎是一样的,但是当你的 Batch Size 增加到
10000,乃至增加到60000的时候,你就会发现 GPU 要算完一个 Batch,把这个 Batch
里面的资料都拿出来算 Loss,再进而算 Gradient,所要耗费的时间,确实有随著
Batch Size 的增加而逐渐增长,但你会发现这边用的是
V100,所以它挺厉害的,给它60000笔资料,一个 Batch
里面,塞了60000笔资料,它在10秒鐘之内,也是把 Gradient 就算出来</p>
<p>而那这个 Batch Size
的大小跟时间的关係,其实每年都会做这个实验,我特别把旧的投影片放在这边了,如果你有兴趣的话m,,可以看到这个时代的演进这样,17年的时候用的是那个980啊,2015年的时候用的是那个760啊,然后980要跑什么60000个
Batch,那要跑好几分鐘才跑得完啊,现在只要10秒鐘就可以跑得完了,你可以看到这个时代的演进,</p>
<h4><span id="14-smallerbatch-requires-longer-time-for-one-epoch">1.4 Smaller
batch requires longer time for one epoch</span></h4>
<p>所以 GPU 虽然有平行运算的能力,但它平行运算能力终究是有个极限,所以你
Batch Size 真的很大的时候,时间还是会增加的</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011438416.png" alt="image-20220616165344706" style="zoom: 67%;"></p>
<p>但是因为有平行运算的能力,因此实际上,当你的 <strong>Batch Size
小的时候,你要跑完一个 Epoch,花的时间是比大的 Batch Size
还要多</strong>的,怎么说呢</p>
<p>如果今天假设我们的训练资料只有60000笔,那 Batch Size 设1,那你要60000个
Update 才能跑完一个 Epoch,如果今天是 Batch Size 等於1000,你要60个 Update
才能跑完一个 Epoch,假设今天一个 Batch Size 等於1000,要算 Gradient
的时间根本差不多,那60000次 Update,跟60次 Update
比起来,它的时间的差距量就非常可观了</p>
<p>所以左边这个图是 Update 一次参数,拿一个 Batch 出来计算一个
Gradient,Update 一次参数所需要的时间,右边这个图是,跑完一个完整的
Epoch,需要花的时间,你会发现左边的图跟右边的图,它的趋势正好是相反的,假设你
Batch Size 这个1,跑完一个 Epoch,你要 Update
60000次参数,它的时间是非常可观的,但是假设你的 Batch Size
是1000,你只要跑60次,Update 60次参数就会跑完一个 Epoch,所以你跑完一个
Epoch,看完所有资料的时间,如果你的 Batch Size 设1000,其实是比较短的,Batch
Size 设1000的时候,把所有的资料看过一遍,其实是比 Batch Size 设1
还要更快</p>
<p>所以如果我们看右边这个图的话,看完一个
Batch,把所有的资料看过一次这件事情,大的 Batch Size
反而是较有效率的,是不是跟你直觉想的不太一样</p>
<p>在没有考虑平行运算的时候,你觉得大的 Batch
比较慢,但实际上,在有考虑平行运算的时候,一个 Epoch 大的 Batch
花的时间反而是比较少的</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011438492.png" alt="image-20220616165607814">
<figcaption aria-hidden="true">image-20220616165607814</figcaption>
</figure>
<p>我们如果要比较这个 Batch Size
大小的差异的话,看起来直接用技能时间冷却的长短,并不是一个精确的描述,看起来在技能时间上面,大的
Batch 并没有比较吃亏,甚至还佔到优势了.</p>
<p>所以事实上,20笔资料 Update 一次的时间,跟右边看一笔资料 Update
一次的时间,如果你用 GPU 的话,其实可能根本就是所以一样的,所以大的
Batch,它的技能时间,它技能冷却的时间,并没有比较长,那所以这时候你可能就会说,欸
那个大的 Batch 的劣势消失了,那难道它真的就,那这样看起来大的 Batch
应该比较好?</p>
<p>你不是说大的 Batch,这个 Update 比较稳定,小的 Batch,它的 Gradient
的方向比较 Noisy 吗,那这样看起来,大的 Batch 好像应该比较好哦,小的 Batch
应该比较差,因为现在大的 Batch
的劣势已经,因为平行运算的时间被拿掉了,它好像只剩下优势而已.</p>
<p>那神奇的地方是 <strong>Noisy 的 Gradient,反而可以帮助
Training</strong>,这个也是跟直觉正好相反的</p>
<p>如果你今天拿不同的 Batch
来训练你的模型,你可能会得到这样子的结果,左边是坐在 MNIST 上,右边是坐在
CIFAR-10 上,不管是 MNIST 还是 CIFAR-10,都是影像辨识的问题</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011438160.png" alt="image-20220616165544738"></p>
<ul>
<li>横轴代表的是 Batch Size,从左到右越来越大</li>
<li>纵轴代表的是正确率,越上面正确率越高,当然正确率越高越好</li>
</ul>
<p>而如果你今天看 Validation Acc 上的结果，会发现说,Batch Size
越大,Validation Acc 上的结果越差,但这个不是 Overfitting,因为如果你看你的
Training 的话,会发现说 Batch Size 越大,Training
的结果也是越差的,而我们现在用的是同一个模型哦,照理说,它们可以表示的
Function 就是一模一样的</p>
<p>但是神奇的事情是,大的 Batch Size,往往在 Training
的时候,会给你带来比较差的结果</p>
<p>所以这个是什么样的问题,同样的 Model,所以这个不是 Model Bias
的问题,<strong>这个是 Optimization 的问题,代表当你用大的 Batch Size
的时候,你的 Optimization 可能会有问题</strong>,小的 Batch
Size,Optimization 的结果反而是比较好的,好 为什么会这样子呢</p>
<h4><span id="15-noisy-update-isbetter-for-training">1,5 “Noisy” update is
better for training</span></h4>
<p>为什么小的 Batch Size,在 Training Set 上会得到比较好的结果,为什么
Noisy 的 Update,Noisy 的 Gradient 会在 Training
的时候,给我们比较好的结果呢？一个可能的解释是这样子的</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011438387.png" alt="image-20220626154658708" style="zoom:67%;"></p>
<p>假设你是 Full Batch,那你今天在 Update 你的参数的时候,你就是沿著一个
Loss Function 来 Update 参数,今天 Update 参数的时候走到一个 Local
Minima,走到一个 Saddle Point,显然就停下来了,Gradient
是零,如果你不特别去看Hession的话,那你用 Gradient Descent
的方法,你就没有办法再更新你的参数了</p>
<p>但是假如是 Small Batch 的话,因为我们每次是挑一个 Batch 出来,算它的
Loss,所以等於是,等於你每一次 Update 你的参数的时候,你用的 Loss Function
都是越有差异的,你选到第一个 Batch 的时候,你是用 L1 来算你的
Gradient,<strong>你选到第二个 Batch 的时候,你是用 L2 来算你的
Gradient,假设你用 L1 算 Gradient 的时候,发现 Gradient 是零,卡住了,但 L2
它的 Function 跟 L1 又不一样,L2 就不一定会卡住,所以 L1 卡住了
没关係,换下一个 Batch 来,L2 再算 Gradient。</strong></p>
<p><strong>你还是有办法 Training 你的 Model,还是有办法让你的 Loss
变小,所以今天这种 Noisy 的 Update 的方式,结果反而对
Training,其实是有帮助的。</strong></p>
<h4><span id="16-noisy-update-isbetter-for-generalization">1.6 “Noisy” update is
better for generalization</span></h4>
<p>那这边还有另外一个更神奇的事情，其实<strong>小的 Batch 也对 Testing
有帮助</strong>。</p>
<p>假设我们今天在 Training 的时候,都不管是大的 Batch 还小的 Batch,都
Training 到一样好,刚才的 Case是Training 的时候就已经 Training
不好了。</p>
<p>假设你有一些方法,你努力的调大的 Batch 的 Learning
Rate,然后想办法把大的 Batch,跟小的 Batch Training
得一样好,结果你会发现<strong>小的 Batch,居然在 Testing
的时候会是比较好的</strong>,那以下这个实验结果是引用自,On Large-Batch
Training For Deep Learning,Generalization Gap And Sharp
Minimahttps://arxiv.org/abs/1609.04836,这篇 Paper 的实验结果：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011438308.png" alt="image-20220626154838373">
<figcaption aria-hidden="true">image-20220626154838373</figcaption>
</figure>
<p>那这篇 Paper 里面,作者 Train 了六个 Network 里面有 CNN 的,有 Fully
Connected Network 的,做在不同的 Cover
上,来代表这个实验是很泛用的,在很多不同的 Case
都观察到一样的结果,那它有小的 Batch,一个 Batch 里面有256笔 Example,大的
Batch 就是那个 Data Set 乘 0.1,Data Set 乘 0.1,Data Set
有60000笔,那你就是一个 Batch 里面有6000笔资料</p>
<p>然后他想办法,在大的 Batch 跟小的 Batch,都 Train 到差不多的 Training
的 Accuracy,所以刚才我们看到的结果是,Batch Size 大的时候,Training
Accuracy 就已经差掉了,这边不是想办法 Train 到大的 Batch 的时候,Training
Accuracy 跟小的 Batch,其实是差不多的</p>
<p>但是就算是在 Training 的时候结果差不多,Testing
的时候你还是看到了,小的 Batch 居然比大的 Batch 差,Training
的时候都很好,<strong>Testing 的时候大的 Batch 差,代表 Over
Fitting</strong>,这个才是 Over Fitting 对不对,好
那为什么会有这样子的现象呢？在这篇文章里面也给出了一个解释,</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011438056.png" alt="image-20220626154919498" style="zoom:67%;"></p>
<p>假设这个是我们的 Training Loss,那在这个 Training Loss
上面呢,可能有很多个 Local Minima,有不只一个 Local Minima,那这些 Local
Minima 它们的 Loss 都很低,它们 Loss 可能都趋近於 0,但是这个
<strong>Local Minima,还是有好 Minima 跟坏 Minima 之分</strong></p>
<p>如果一个 Local Minima 它在一个峡谷里面,它是坏的
Minima,然后它在一个平原上,它是好的 Minima,为什么会有这样的差异呢</p>
<ul>
<li>因为假设现<strong>在 Training 跟 Testing 中间,有一个
Mismatch</strong>,Training 的 Loss 跟 Testing 的 Loss,它们那个 Function
不一样,有可能是本来你 Training 跟 Testing 的 Distribution就不一样。</li>
<li>那也有可能是因为 Training 跟 Testing,你都是从 Sample 的 Data
算出来的,也许 Training 跟 Testing,Sample 到的 Data
不一样,那所以它们算出来的 Loss,当然是有一点差距。</li>
</ul>
<p>那我们就假设说这个 Training 跟 Testing,它的差距就是把 Training 的
Loss,这个 Function
往右平移一点,这时候你会发现,对左边这个在一个盆地里面的 Minima
来说,它的在 Training 跟 Testing
上面的结果,不会差太多,只差了一点点,但是对右边这个在峡谷里面的 Minima
来说,一差就可以天差地远</p>
<p>它在这个 Training Set 上,算出来的 Loss 很低,但是因为 Training 跟
Testing 之间的不一样,所以 Testing 的时候,这个 Error Surface
一变,它算出来的 Loss 就变得很大,而很多人相信这个<strong>大的 Batch
Size,会让我们倾向於走到峡谷里面,而小的 Batch
Size,倾向於让我们走到盆地里面</strong></p>
<p>那他直觉上的想法是这样,就是小的 Batch,它有很多的 Loss,它每次 Update
的方向都不太一样,所以如果今天这个峡谷非常地窄,它可能一个不小心就跳出去了,因为每次
Update 的方向都不太一样,它的 Update
的方向也就随机性,所以一个很小的峡谷,没有办法困住小的 Batch</p>
<p>如果峡谷很小,它可能动一下就跳出去,之后停下来如果有一个非常宽的盆地,它才会停下来,那对於大的
Batch Size,反正它就是顺著规定
Update,然后它就很有可能,走到一个比较小的峡谷里面</p>
<p>但这只是一个解释,那也不是每个人都相信这个解释,那这个其实还是一个<strong>尚待研究的问题</strong>那这边就是比较了一下,大的
Batch 跟小的 Batch</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011439577.png" alt="image-20220616171325318" style="zoom: 67%;"></p>
<p>左边这个是第一个 Column 是小的 Batch,第二个 Column 是大的 Batch</p>
<p>在有平行运算的情况下,小的 Batch 跟大的
Batch,其实运算的时间并没有太大的差距,除非你的大的 Batch
那个大是真的非常大,才会显示出差距来。但是一个 Epoch 需要的时间,小的
Batch 比较长,大的 Batch 反而是比较快的,所以从一个 Epoch
需要的时间来看,大的 Batch 其实是佔到优势的。</p>
<p>而小的 Batch,你会 Update 的方向比较 Noisy,大的 Batch Update
的方向比较稳定,但是 Noisy 的 Update 的方向,反而在 Optimization
的时候会佔到优势,而且在 Testing 的时候也会佔到优势,所以大的 Batch 跟小的
Batch,它们各自有它们擅长的地方。</p>
<p><strong><font color="red">所以 Batch Size,变成另外一个 你需要去调整的
Hyperparameter。</font></strong></p>
<p>那我们能不能够鱼与熊掌兼得呢,我们能不能够截取大的 Batch 的优点,跟小的
Batch 的优点,我们用大的 Batch Size
来做训练,用平行运算的能力来增加训练的效率,但是训练出来的结果同时又得到好的结果呢,又得到好的训练结果呢。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011439138.png" alt="image-20220626155139635" style="zoom:67%;"></p>
<p>这是有可能的,有很多文章都在探讨这个问题,那今天我们就不细讲,我们把这些
Reference 列在这边给大家参考,那你发现这些
Paper,往往它想要做的事情都是什么,哇 76分鐘 Train BERT,15分鐘 Train
ResNet,一分鐘 Train Imagenet
等等,这为什么他们可以做到那么快,就是因为他们 Batch Size
是真的开很大,比如说在第一篇 Paper 里面,Batch Size 里面有三万笔 Example
这样,Batch Size 开很大,Batch Size 开大
真的就可以算很快,你可以在很短的时间内看到大量的资料,那他们需要有一些特别的方法来解决,Batch
Size 可能会带来的劣势。</p>
<h3><span id="二-momentum">二、Momentum</span></h3>
<p><strong><font color="red"> Momentum,这也是另外一个,有可能可以对抗
Saddle Point,或 Local Minima 的技术</font></strong>,Momentum
的运作是这个样子的，</p>
<h4><span id="21-small-gradient">2.1 Small Gradient</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011439981.png" alt="image-20220616171440148" style="zoom:80%;"></p>
<p>它的概念,你可以想像成在物理的世界里面,假设 Error Surface
就是真正的斜坡,而我们的参数是一个球,你把球从斜坡上滚下来,如果今天是
Gradient Descent,它走到 Local Minima 就停住了,走到 Saddle Point
就停住了</p>
<p>但是在物理的世界里,一个球如果从高处滚下来,从高处滚下来就算滚到 Saddle
Point,如果有<strong>惯性</strong>,它从左边滚下来,因为惯性的关係它还是会继续往右走,甚至它走到一个
Local
Minima,如果今天它的动量够大的话,它还是会继续往右走,甚至翻过这个小坡然后继续往右走</p>
<p>那所以今天在物理的世界里面,一个球从高处滚下来的时候,它并不会被 Saddle
Point,或 Local Minima卡住,不一定会被 Saddle Point,或 Local Minima
卡住,我们有没有办法运用这样子的概念,到 Gradient Descent
里面呢,那这个就是我们等一下要讲的,Momentum 这个技术</p>
<h4><span id="22-vanilla-gradient-descent">2.2 Vanilla Gradient Descent</span></h4>
<p>那我们先很快的复习一下,原来的 Gradient Descent 长得是什么样子,这个是
Vanilla 的 Gradient Descent,Vanilla
的意思就是一般的的意思,它直译是香草的,但就其实是一般的,一般的 Gradient
Descent 长什么样子呢？</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011439050.png" alt="image-20220616171504634">
<figcaption aria-hidden="true">image-20220616171504634</figcaption>
</figure>
<p>​</p>
<p>一般的 Gradient Descent 是说,我们有一个初始的参数叫做 <span class="math inline">\(θ^0\)</span>,我们计算一下 Gradient,然后计算完这个
Gradient 以后呢,我们往 Gradient 的反方向去 Update 参数 <span class="math display">\[
θ^1 = θ^0 - {\eta}g^0
\]</span> 我们到了新的参数以后,再计算一次 Gradient,再往 Gradient
的反方向,再 Update 一次参数,到了新的位置以后再计算一次 Gradient,再往
Gradient 的反方向去 Update 参数,这个 Process 就一直这样子下去</p>
<h4><span id="23-gradient-descent-momentum">2.3 Gradient Descent + Momentum</span></h4>
<p>加上 Momentum 以后,每一次我们在移动我们的参数的时候,我们不是只往
Gradient Descent,我们不是只往 Gradient 的反方向来移动参数,我们是
<strong>Gradient
的反方向,加上前一步移动的方向,两者加起来的结果,去调整去到我们的参数,</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011439582.png" alt="image-20220616171740139" style="zoom:50%;"></p>
<p>那具体说起来是这个样子,一样找一个初始的参数,然后我们假设前一步的参数的
Update 量呢,就设为 0 <span class="math display">\[
m^0 = 0
\]</span> 接下来在 <span class="math inline">\(θ^0\)</span> 的地方,计算
Gradient 的方向<span class="math inline">\(g^0\)</span>，然后接下来你要决定下一步要怎么走,它是
Gradient 的方向加上前一步的方向,不过因为前一步正好是
0,现在是刚初始的时候所以前一步是 0,所以 Update 的方向,跟原来的 Gradient
Descent 是一样的,这没有什么有趣的地方</p>
<p><span class="math display">\[
m^1 = {\lambda}m^0-{\eta}g^0\\\
θ^1 = θ^0 + m^1
\]</span> 但从第二步开始,有加上 Momentum
以后就不太一样了,从第二步开始,我们计算 <span class="math inline">\(g^1\)</span>,然后接下来我们 Update 的方向,不是
<span class="math inline">\(g^1\)</span>的反方向,而是根据上一次 Update
方向,也就是 m1 减掉 g1,当做我们新的 Update 的方向,这边写成 m2 <span class="math display">\[
m^2 = {\lambda}m^1-{\eta}g^1
\]</span> 那我们就看下面这个图</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011439226.png" alt="image-20220616171749421">
<figcaption aria-hidden="true">image-20220616171749421</figcaption>
</figure>
<p>g1 告诉我们,<strong>Gradient
告诉我们要往红色反方向这边走</strong>,但是我们不是只听 Gradient
的话,加上 Momentum 以后,我们不是只根据 Gradient
的反方向,来调整我们的参数,我们<strong>也会看前一次 Update
的方向</strong></p>
<ul>
<li>如果前一次说要往<strong><span class="math inline">\(m^1\)</span>蓝色及蓝色虚线</strong>这个方向走</li>
<li>Gradient 说要往<strong>红色反方向这个方向</strong>走</li>
<li><strong>把两者相加起来</strong>,走两者的折中,也就是往<strong>蓝色<span class="math inline">\(m^2\)</span>这一个方向走</strong>,所以我们就移动了
m2,走到 θ2 这个地方</li>
</ul>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011439931.png" alt="image-20220616171805517">
<figcaption aria-hidden="true">image-20220616171805517</figcaption>
</figure>
<p>接下来就反覆进行同样的过程,在这个位置我们计算出
Gradient,但我们不是只根据 Gradient
反方向走,我们看前一步怎么走,前一步走这个方向,走这个蓝色虚线的方向,我们把蓝色的虚线加红色的虚线,前一步指示的方向跟
Gradient 指示的方向,当做我们下一步要移动的方向</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011439028.png"></p>
<p>每一步的移动,我们都用 m 来表示,那这个 m
其实可以写成之前所有算出来的,Gradient 的 Weighted
Sum.从右边的这个式子,其实就可以轻易的看出来 <span class="math display">\[
m^0 = 0\\\
m^1 = -{\eta}g^0\\\
m^2 = -{\lambda}{\eta}g^0-{\eta}g^1\\\
...
\]</span> m0 我们把它设为 0,m1 是 m0 减掉 g0,m0 为 0,所以 m1 就是 g0
乘上负的 η,m2 是 λ 乘上 m1,λ 就是另外一个参数,就好像 η 是 Learning Rate
我们要调,λ 是另外一个参数,这个也是需要调的,m2 等於 λ 乘上 m1,减掉 η 乘上
g1,然后 m1 在哪里呢,m1 在这边,你把 m1 代进来,就知道说 m2,等於负的 λ 乘上
η 乘以 g0,减掉 η 乘上 g1,它是 g0 跟 g1 的 Weighted Sum</p>
<p>以此类推,所以你会发现说,现在这个加上 Momentum 以后,一<strong>个解读是
Momentum 是,Gradient
的负反方向加上前一次移动的方向</strong>,那但另外一个解读方式是,所谓的
Momentum,<strong>当加上 Momentum 的时候,我们 Update
的方向,不是只考虑现在的 Gradient,而是考虑过去所有 Gradient
的总合.</strong></p>
<p>​ 有一个更简单的例子,希望帮助你了解 Momentum</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011439946.png" alt="image-20220616172323699" style="zoom:67%;"></p>
<p>那我们从这个地方开始 Update 参数,根据 Gradient
的方向告诉我们,应该往右 Update 参数,那现在没有前一次 Update
的方向,所以我们就完全按照 Gradient 给我们的指示,往右移动参数,好
那我们的参数,就往右移动了一点到这个地方</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011439011.png" alt="image-20220616172349096" style="zoom:67%;"></p>
<p>Gradient
变得很小,告诉我们往右移动,但是只有往右移动一点点,但前一步是往右移动的,我们把前一步的方向用虚线来表示,放在这个地方,我们把之前
Gradient
告诉我们要走的方向,跟前一步移动的方向加起来,得到往右走的方向,那再往右走
走到一个 Local Minima,照理说走到 Local Minima,一般 Gradient Descent
就无法向前走了,因为已经没有这个 Gradient 的方向,那走到 Saddle Point
也一样,没有 Gradient 的方向已经无法向前走了</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011439099.png" alt="image-20220616172359508" style="zoom:67%;"></p>
<p>但没有关係,如果有 Momentum 的话,你还是有办法继续走下去,因为 Momentum
不是只看 Gradient,Gradient 就算是
0,你还有前一步的方向,前一步的方向告诉我们向右走,我们就继续向右走,甚至你走到这种地方,Gradient
告诉你应该要往左走了,但是假设你前一步的影响力,比 Gradient
要大的话,你还是有可能继续往右走,甚至翻过一个小丘,搞不好就可以走到更好
Local Minima,这个就是 Momentum 有可能带来的好处。</p>
<h3><span id="concluding-remarks">Concluding Remarks</span></h3>
<ul>
<li><strong>Critical points have zero gradients.</strong></li>
<li>Critical points can be either <strong>saddle points or local
minima</strong>.
<ul>
<li>Can be determined by the Hessian matrix.</li>
<li>Local minima may be rare.</li>
<li>It is possible to escape saddle points along the direction of
eigenvectors of the Hessian matrix</li>
</ul></li>
<li>Smaller batch size and momentum help escape critical points.</li>
</ul>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>python+numpy实现线性回归中梯度下降算法（对比sklearn官方demo） -
sciengieer的文章 - 知乎 https://zhuanlan.zhihu.com/p/390002941</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>训练技巧</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>Batch</tag>
        <tag>Momentum</tag>
      </tags>
  </entry>
  <entry>
    <title>模型训练（7）【draft】参数初始化</title>
    <url>/posts/CCPH1H/</url>
    <content><![CDATA[<h2><span id="参数初始化">参数初始化</span></h2>
<blockquote>
<ul>
<li>https://paddlepedia.readthedocs.io/en/latest/tutorials/deep_learning/model_tuning/weight_initializer.html</li>
</ul>
</blockquote>
<p>在我们开始训练神经网络之前，首先要做的是给网络中的每一个权重和偏置赋值，这个赋值的过程就是参数初始化。<strong>合理的初始化可以缩短神经网络的训练时间，而不合理的初始化可能使网络难以收敛</strong>。那么，我们要如何对参数进行初始化呢？或许你有想到过将全部参数都设置为0，这看起来是一个简单又方便的办法，但遗憾的是神经网络中不能对权重进行全零初始化。在讨论如何对参数进行初始化前，我们先来看看为什么不能进行全零初始化。</p>
<h4><span id="一-为什么不能全零初始化">一、为什么不能全零初始化？</span></h4>
<p>以一个三层网络为例，假设其具体的网络示意图如图1所示。</p>
<p><img src="https://paddlepedia.readthedocs.io/en/latest/_images/net_for_params_init.png" alt="net_for_params_init" style="zoom:50%;"></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>训练技巧</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习（10）AutoEncoder</title>
    <url>/posts/21E1VBV/</url>
    <content><![CDATA[<h2><span id="自编码器autoencoder">自编码器（AutoEncoder）</span></h2>
<h4><span id="引言">引言</span></h4>
<p>    当你在看论文的时候，经常会遇到编码器、解码器、自编码器（Autoencoder）这些字眼，它们到底是干什么的呢？其主要作用又是什么呢？那么本篇主要带大家了解自编码器（Autoencoder）。</p>
<h3><span id="一-自编码器autoencoder介绍">一、自编码器（Autoencoder）介绍</span></h3>
<p>暂且不谈神经网络、深度学习等，仅仅是自编码器的话，其原理其实很简单。自编码器可以理解为一个试图去还原其原始输入的系统。自编码器模型如下图所示。</p>
<p><img src="https://pic4.zhimg.com/80/v2-f4444b7343ef311fd04f0dc0dc1db3b7_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>从上图可以看出，自编码器模型主要由编码器（Encoder）和解码器（Decoder）组成，其主要目的是将输入x转换成中间变量y，然后再将y转换成
<img src="https://www.zhihu.com/equation?tex=%5Coverline+x" alt="[公式]"> ，然后对比输入x和输出 <img src="https://www.zhihu.com/equation?tex=%5Coverline+x" alt="[公式]">
使得他们两个无限接近。</p>
<h4><span id="11-神经网络自编码模型">1.1 神经网络自编码模型</span></h4>
<p>在深度学习中，自动编码器是一种无监督的神经网络模型，它可以学习到输入数据的隐含特征，这称为编码(coding)，同时用学习到的新特征可以重构出原始输入数据，称之为解码(decoding)。从直观上来看，自动编码器可以用于特征降维，类似主成分分析PCA，但是其相比PCA其性能更强，这是由于神经网络模型可以提取更有效的新特征。除了进行特征降维，自动编码器学习到的新特征可以送入有监督学习模型中，所以自动编码器可以起到特征提取器的作用<strong>。举个例子，我有一张清晰图片，首先我通过编码器压缩这张图片的大小（如果展现出来可能比较模型），然后在需要解码的时候将其还原成清晰的图片</strong>。具体过程如下图所示。</p>
<h4><span id="12-神经网络自编码器三大特点">1.2 神经网络自编码器三大特点</span></h4>
<ul>
<li><strong>自动编码器是数据相关</strong>的（data-specific 或
data-dependent），这意味着自动编码器只能压缩那些与训练数据类似的数据。比如，使用人脸训练出来的自动编码器在压缩别的图片，比如树木时性能很差，因为它学习到的特征是与人脸相关的。</li>
<li><strong>自动编码器是有损的</strong>，意思是解压缩的输出与原来的输入相比是退化的，MP3，JPEG等压缩算法也是如此。这与无损压缩算法不同。</li>
<li>自动编码器是从数据样本中自动学习的，这意味着很容易对指定类的输入训练出一种特定的编码器，而不需要完成任何新工作。</li>
</ul>
<h4><span id="13-自编码器autoencoder搭建">1.3 自编码器（Autoencoder）搭建</span></h4>
<p>搭建一个自动编码器需要完成下面三样工作：搭建<strong>编码器</strong>，搭建<strong>解码器</strong>，设定一个<strong>损失函数，用以衡量由于压缩而损失掉的信息</strong>。编码器和解码器一般都是参数化的方程，并关于损失函数可导，典型情况是使用神经网络。编码器和解码器的参数可以通过最小化损失函数而优化，例如<strong>SGD</strong>。举个例子：根据上面介绍，自动编码器看作由两个级联网络组成。</p>
<ul>
<li>第一个网络是一个编码器，负责接收输入 x，并将输入通过函数 h
变换为信号 y：</li>
</ul>
<figure>
<img src="https://pic3.zhimg.com/80/v2-b9331fbb152409c69a14c056b6d56c52_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>第二个网络将编码的信号 y 作为其输入，通过函数f得到重构的信号
r：</li>
</ul>
<figure>
<img src="https://pic2.zhimg.com/80/v2-38e2787955e83ebf81b74992ac77da79_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>定义误差 e 为原始输入 x 与重构信号 r
之差，e=x–r，网络训练的目标是减少<strong>均方误差（MSE）</strong>，同
MLP 一样，误差被反向传播回隐藏层。</li>
</ul>
<h4><span id="14-几种常见编码器">1.4 几种常见编码器</span></h4>
<p>自编码器（autoencoder）是神经网络的一种，经过训练后能尝试将输入复制到输出。自编码器（）autoencoder）内部有一个隐藏层
h，可以产生编码（code）表示输入。该网络可以看作由两部分组成：一个由函数
h = f(x) 表示的编码器和一个生成重构的解码器 r =
g(h)。如果一个自编码器只是简单地学会将处处设置为 g(f(x)) =
x，那么这个自编码器就没什么特别的用处。相反，<strong>我们不应该将自编码器设计成输入到输出完全相等</strong>。这通常需要向自编码器强加一些约束，使它只能近似地复制，并只能复制与训练数据相似的输入。这些约束强制模型考虑输入数据的哪些部分需要被优先复制，因此它往往能学习到数据的有用特性。</p>
<ul>
<li><strong>堆栈自动编码器</strong>
前面讲的自编码器只是简答的含有一层，其实可以采用更深层的架构，这就是堆栈自动编码器或者深度自动编码器，本质上就是增加中间特征层数。这里我们以MNIST数据为例来说明自动编码器，建立两个隐含层的自动编码器，如下图所示：</li>
</ul>
<figure>
<img src="https://pic4.zhimg.com/80/v2-e1b65e3d86fd1a8fbb56df20eeefd113_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>    对于MNIST来说，其输入是<span class="math inline">\(28*28=784\)</span>维度的特征，这里使用了两个隐含层其维度分别为300和150，可以看到是不断降低特征的维度了。得到的最终编码为150维度的特征，使用这个特征进行反向重构得到重建的特征，我们希望重建特征和原始特征尽量相同。</p>
<ul>
<li><p><strong>欠完备自编码器</strong>从自编码器获得有用特征的一种方法是限制
h的维度比 x
小，这种编码维度小于输入维度的自编码器称为欠完备（undercomplete）自编码器。<strong>学习欠完备的表示将强制自编码器捕捉训练数据中最显著的特征</strong>。</p></li>
<li><p><strong>正则自编码器</strong>使用的损失函数可以鼓励模型学习其他特性（除了将输入复制到输出），而不必限制使用浅层的编码器和解码器以及小的编码维数来限制模型的容量。这些特性包括稀疏表示、表示的小导数、以及对噪声或输入缺失的鲁棒性。即使模型容量大到足以学习一个无意义的恒等函数，非线性且过完备的正则自编码器仍然能够从数据中学到一些关于数据分布的有用信息。</p></li>
<li><p><strong>去噪自编码器</strong>（denoisingautoencoder,
DAE）是一类接受损坏数据作为输入，并训练来预测原始未被损坏数据作为输出的自编码器。</p></li>
</ul>
<h2><span id="二-李宏毅-auto-encoder-p1">二、李宏毅-Auto-Encoder P1</span></h2>
<h3><span id="21-self-supervisedlearning-framework"><strong>2.1 Self-supervised
Learning Framework</strong></span></h3>
<p>在讲 Auto-Encoder 之前,其实 Auto-Encoder 也可以算是,Self-Supervised
Learning 的一环,所以再让我们用非常短的时间,来看一下Self-Supervised
Learning 的 Framework。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615182816027.png" alt="image-20220615182816027" style="zoom:50%;"></p>
<p>首先你有大量的没有标注的资料,用这些没有标注的资料,你可以去训练一个模型,你必须发明一些不需要标注资料的任务,比如说做填空题,比如说预测下一个
Token。</p>
<p>这个不用标注资料的学习叫做,==Self-Supervised
Learning==,或者是也有人叫
==Pre-Training==,那用这些不用标注资料的任务,学完一个模型以后,它本身没有什麽用,BERT
只能做填空题,GPT
只能够把一句话补完,但是你可以把它用在其他下游的任务里面。你可以把
Self-Supervised Learning 的
Model,做一点点的微微的调整,就可以用在下游的任务里面。</p>
<p><strong><font color="red"> 在有 BERT 在有 GPT
之前,其实有一个更古老的任务,更古老的不需要用标注资料的任务,就叫做
Auto-Encoder,所以你也可以把 Auto-Encoder,看作是 Self-Supervised Learning
的,一种 Pre-Train 的方法。</font></strong></p>
<p>当然可能不是所有人都会同意这个观点,有人可能会说这个
Auto-Encoder,不算是 Self-Supervised Learning,这个 Auto-Encoder
很早就有了嘛,2006 年 15 年前就有了嘛,然后 Self-Supervised Learning 是,19
年才有这个词彙嘛,所以 Auto-Encoder,不算 Self-Supervised Learning
的一环。</p>
<p>那这个都是见仁见智的问题,这种名词定义的问题,真的我们就不用太纠结在这个地方,从
Self-Supervised Learning,它是不需要用 Label Data
来训练,这个观点来看,<strong>Auto-Encoder
我认为它可以算是,Self-Supervised Learning 的其中的一种方法,它就跟填空
预测,接下来的 Token
是很类似的概念,只是用的是另外不一样的想法</strong>。</p>
<h3><span id="22-auto-encoder">2.2 Auto-encoder</span></h3>
<p>Auto-Encoder 是怎麽运作的呢,那现在我们,因为刚才在讲 Self-Supervised
Learning 的时候,都是用文字做例子,那现在我们换成用影像来做例子：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615183004489.png" alt="image-20220615183004489" style="zoom:50%;"></p>
<p>假设你有非常大量的图片,在 Auto-Encoder 里面你有两个 Network,一个叫做
Encoder,一个叫做 Decoder,他们就是两个 Network</p>
<ul>
<li><p><strong>Encoder 把一张图片读进来,它把这张图片变成一个向量,就
Encoder 它可能是很多层的
CNN,把一张图片读进来,它的输出是一个向量,接下来这个向量会变成 Decoder
的输入</strong></p></li>
<li><p><strong>Decoder 会产生一张图片,所以 Decoder 的 Network
的架构,可能会像是 GAN 里面的 Generator,它是 11
个向量输出一张图片</strong></p></li>
</ul>
<p><strong><font color="red"> 训练的目标是希望,Encoder 的输入跟 Decoder
的输出,越接近越好，假设你把图片看作是一个很长的向量的话,我们就希望这个向量跟
Decoder
的输出,这个向量,这两个向量他们的距离越接近越好,也有人把这件事情叫做
==Reconstruction==,叫做重建。</font></strong></p>
<p>所以它是一个 <strong>Unsupervised Learning 的方法</strong>,跟
Self-Supervised 那一系列,Pre-Training
的做法一样,你<strong>完全不需要任何的标注资料</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615183155224.png" alt="image-20220615183155224" style="zoom: 50%;"></p>
<p>那像这样子这个 <strong>Encoder 的输出,有时候我们叫它
Embedding</strong>,我们在讲 BERT 的时候,也提过 Embedding
这个词彙了,那有的人叫它 Representation,有的人叫它 Code,因为 Encoder
是一个编码嘛,所以这个有人把这个 Vector 叫做
Code,那其实指的都是同一件事情。</p>
<h5><span id="怎麽把train-的-auto-encoder用在-downstream-的任务里面呢">怎麽把
Train 的 Auto-Encoder,用在 Downstream 的任务里面呢？</span></h5>
<p>常见的用法就是,原来的图片,你也可以把它看作是一个很长的向量,但这个<strong>向量太长了不好处理</strong>,那怎麽办呢？你把这个图片丢到
<strong>Encoder
以后,输出另外一个向量,这个向量你会让它比较短</strong>,比如说只有 10 维
只有 100
维,那你拿这个新的向量来做你接下来的任务,也就是图片不再是一个很高维度的向量,它通过
Encoder
的压缩以后,变成了一个低维度的向量,你再拿这个低维度的向量,来做接下来想做的事情,这就是常见的,Auto-Encoder用在
Downstream 的任务,用在下游任务的方法。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615183309937.png" alt="image-20220615183309937" style="zoom:50%;"></p>
<p><strong><font color="red"> 而 Encoder
做的事情,是把本来很高维度的东西,转成低维度的东西,把高维度的东西转成低维度的东西又叫做
==Dimension Reduction==。</font></strong></p>
<p>Dimension Reduction 这个技术,我相信你在 Machine Learning
相关的应用上,应该常常听到这个名词,那有关 Dimension Reduction
的技术,它其实牵涉的非常非常地广,所以我们这边就不再细讲,因为这门课,我们只专注在深度学习相关的技术,你可以把
Auto-Encoder 的 Encoder,当作拿来做 Dimension
Reduction,那其他还有很多不是 Deep Learning
Base的,不是以深度学习为基础的,Dimension Reduction的技术。<strong>比如说
PCA 比如说 T-SNE</strong>。</p>
<h3><span id="24-de-noising-auto-encoder">2.4 De-noising Auto-encoder</span></h3>
<p>那 Auto-Encoder 还有一个常见的变形,叫做 De-Noising 的
Auto-Encoder</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615185731272.png" alt="image-20220615185731272" style="zoom:67%;"></p>
<p>De-Noising 的 Auto-Encoder 是说,我们把原来要输进去给 Encoder
的图片,<strong>加上一些杂讯</strong>,就自己随便找一个杂讯把它加进去,然后一样通过
Encoder,一样再通过 Decoder,试图还原原来的图片。那我们现在还原的,不是
Encoder 的输入,Encoder 的输入的图片是有加杂讯的,我们要还原的不是 Encoder
的输入,我们<strong>要还原的是加入杂讯之前的结果</strong>。</p>
<p>所以你会发现说,现在 Encoder 跟
Decoder,除了还原原来的图片这个任务以外,它还<strong>多了一个任务</strong>,这个任务是什麽,这个任务就是,它必须要<strong>自己学会把杂讯去掉</strong>。Encoder
看到的是没有杂讯的图片,但 Decode要还原的目标是,Encoder
看到的是有加杂讯的图片,但 Decoder 要还原的目标是,没有加杂讯的图片,所以
Encoder 加
Decoder,他们合起来必须要联手能够把杂讯去掉,这样你才能够把,De-Noising 的
Auto-Encoder 训练起来。</p>
<p>但是如果你看今天的 BERT 的话,其实你也可以把它看作就是一个,De-Noising
的 Auto-Encoder：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615185813727.png" alt="image-20220615185813727" style="zoom:50%;"></p>
<p>输入我们会加 Masking,那些 <strong>Masking 其实就是
Noise</strong>,BERT 的模型就是 Encoder,它的输出就是 Embedding。在讲 BERT
的技术的时候,我们就告诉你说这个输出就叫做 Embedding,接下来有一个 Linear
的模型,就是Decoder,所以我们可以说,BERT 其实就是一个,De-Noising 的
Auto-Encoder。</p>
<h2><span id="三-auto-encoder-p2">三、Auto-Encoder P2</span></h2>
<h3><span id="31-feature-disentangle">3.1 Feature Disentangle</span></h3>
<p><strong><font color="red"> 除了 Aauto-Encoder,可以用来做当 strime
的任务以外,我还想跟大家分享一下,Aauto-Encoder 其他有意思的应用：
==Feature Disentanglement==。Disentangle
的意思就是,把一堆本来纠缠在一起的东西把它解开。</font></strong></p>
<h5><span id="那为什么会有disentangle-这个议题呢我们来想想看aauto-encoder它在做的事情是什么">那为什么会有
Disentangle 这个议题呢,我们来想想看,Aauto-Encoder
它在做的事情是什么？</span></h5>
<h5><span id="auto-encoder-在做的事情是">Auto-Encoder 在做的事情是：</span></h5>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615190047133.png" alt="image-20220615190047133" style="zoom: 67%;"></p>
<ul>
<li>如果是图片的话,就是把一张图片变成一个 Code,再把 Code 呢
变回图片,既然这个 Code 可以变回图片,代表说这个 Code
里面啊,有很多的资讯,包含图片里面所有的资讯,举例来说,图片里面有什么样的东西啊,图片的色泽纹理啊等等</li>
<li>Auto-Encoder
这个概念也不是只能用在影像上,如果用在语音上,你可以把一段声音丢到 Encoder
里面,变成向量 再丢回
Decoder,变回原来的声音,代表这个向量包含了,语音里面所有重要的资讯,包括这句话的内容是什么,就是
Encoder 的资讯,还有这句话是谁说的,就是 Speaker 语者的资讯</li>
<li>那如果今天是一篇文章,丢到 Encoder 里面变成向量,这个向量通过 Decoder
会变回原来的文章,那这个向量里面有什么,它可能包含文章里面,文句的句法的资讯,也包含了语意的资讯,但是这些资讯是全部纠缠在一个向量里面,我们并不知道一个向量的哪些维,代表了哪些资讯</li>
</ul>
<p>举例来说,如果我们今天把一段声音讯号丢进
Encoder,它会给我们一个向量,但是这个向量里面,哪些维度代表了这句话的内容,哪些维度代表这句话的语者,也就是谁说的,我们没有这样的资讯。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615190127357.png" alt="image-20220615190127357" style="zoom:67%;"></p>
<p>而 Feature Disentangle 想要做到的事情就是,我们有没有可能想办法,在
Train 一个 Aauto-Encoder 的时候,同时有办法知道,这个
Representation,或又叫做 Embedding,或又叫做 Code,我们这个
<strong><font color="red"> Embedding
的哪些维度代表了哪些资讯呢？</font></strong></p>
<p>这边举一个语音上的应用,这个应用叫做 Voice Conversion,Voice Conversion
的中文叫做语者转换,所以也许你没有听过语者转换这个词彙,但是你一定看过它的应用,它就是柯南的领结变身器。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615190304137.png" alt="image-20220615190304137" style="zoom:67%;"></p>
<p>这个在二十年前,阿笠博士就已经做得很成功了啦</p>
<p>那只是过去,阿笠博士在做这个 Voice Conversion
的时候啊,我们需要成对的声音讯号,也就是假设你要把 A 的声音转成 B
的声音,你必须把 A 跟 B 都找来,叫他唸一模一样的句子。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615190330572.png" alt="image-20220615190330572" style="zoom:67%;"></p>
<p>就 A 说好 How are you,B 也说好 How are you,A 说 Good morning,B 也说
Good morning,他们两个各说一样的句子,说个 1000 句,接下来呢,就结束了,就是
<strong>Supervised Learning 的问题</strong>啊,你有成对的资料,Train 一个
Supervised 的 Model,把 A 的声音丢进去,输出就变成 B 的声音,就结束了。</p>
<p>但是如果 A 跟 B 都需要唸一模一样的句子,念个 500 1000
句,显然是不切实际的,举例来说,假设我想要把我的声音转成新垣结衣的声音,我得把新垣结衣找来,更退一万步说,假设我真的把新垣结衣找来,她也不会说中文啊,所以她没有办法跟我唸一模一样的句子</p>
<p>而今天有了 Feature Disentangle
的技术以后,也许我们期待机器可以做到,<strong>就给它 A 的声音 给它 B
的声音,A 跟 B
不需要唸同样的句子,甚至不需要讲同样的语言,机器也有可能学会把 A
的声音转成 B 的声音</strong></p>
<p>那实际上是怎么做的呢,假设我们收集到一大堆人类的声音讯号,然后拿这堆声音讯号呢,去
Train 一个 Aauto-Encoder,同时我们又做了 Feature Disentangle
的技术,所以我们<strong>知道在 Encoder
的输出里面,哪些维度代表了语音的内容,哪些维度代表了语者的特徵</strong>。接下来,我们就可以<strong>把两句话,声音跟内容的部分互换</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191019338.png" alt="image-20220615191019338" style="zoom: 67%;"></p>
<p>举例来说,这边是我的声音,我说 How are you,丢进 Encoder
以后,那你就可以抽出,你就知道说这个 Encoder 里面,<strong>某些维度代表 How
are you 的内容,某些维度代表我的声音</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191033830.png" alt="image-20220615191033830" style="zoom:67%;"></p>
<p>今天你把这个你老婆的声音丢进
Encoder,它就知道某一些维度,代表你老婆说的话的内容,某一些维度,代表你老婆声音的特徵,接下来我们只要<strong>把我说话的内容的部分取出来</strong>,<strong>把你老婆说话的声音特徵的部分取出来,把它拼起来</strong>,丢到
Decoder
里面,就可以用<strong>你老婆的声音,讲我说的话的内容</strong>。</p>
<p>这件事情真的有可能办到吗,以下是真正的例子,听起来像是这个样子,Do you
want to study a PhD,这个是我的声音，那把我的声音丢到 Encoder
里面以后呢,你可以想像说在 Encoder
里面,我们知道哪些维度代表了念博班这件事,哪些维度代表了我的声音。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191448638.png" alt="image-20220615191448638" style="zoom: 67%;"></p>
<p>那为了简化起见,它输出 100 维的向量,前 50 维代表内容,后 50
维代表说话人的特徵,好 接下来这句话是你老婆说的,仕事忙しいのがな,不知道
不太确定在说什么,就是日文啊</p>
<p>接下来呢,就把我的声音的前 50
维,代表内容的部分取出来,把你老婆的,把你老婆的声音丢进 Encoder 以后,后 50
维的部分抽出来,拼起来,一样是一个 100 维的向量,丢到 Decoder
里面,看看输出来的声音,是不是就是你老婆叫你念博班的声音,听起来像是这个样子,Do
you want to study a PhD</p>
<p>那其实反过来也可以啦,就是换成把日文的部分拿出来,把我的声音的特徵拿出来,一样串成一个
100 维的向量,丢到 Decoder
里面,它听起来就会变成这样,仕事忙しいのがな,我也不知道自己在说什么就是了</p>
<p>所以确实用 Feature Disentangle,你有机会做到 Voice
Conversion,那其实在影像上,在 NLP
上,也都可以有类似的应用,所以可以想想看,Feature Disentangle
可以做什么样的事情</p>
<h3><span id="32-discrete-latentrepresentation">3.2 Discrete Latent
Representation</span></h3>
<p>下一个要跟大家讲的应用,叫做 Discrete Latent
Representation。到目前为止我们都假设这个
Embedding,它就是一个向量,这样就是一串数字,它是 Real
Numbers,那它可不可以是别的东西呢？</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191527797.png" alt="image-20220615191527797" style="zoom:67%;"></p>
<ul>
<li>举例来说,它可不可以是 Binary,Binary
的好处也许是说,每一个维度,它就代表了某种特徵的有或者是没有,举例来说,输入的这张图片,如果是女生,可能第一维就是
1,男生第一维就是 0,如果有戴眼镜,就是第三维 1,没有戴眼镜 就是第三维是
0,也许我们把这个向量,这个 Embedding 变成 Binary,变成只有 0 跟 1
的数字,可以让我们再解释 Encoder 输出的时候,更为容易</li>
<li>甚至有没有可能这个向量,强迫它一定要是 One-Hot 呢,也就只有一维是
1,其他就是 0,如果我们强迫它是
One-Hot,也就是每一个东西图片丢进去,你只可以有,你的 Embedding
里面只可以有一维是 1,其他都是 0
的话,那可以做到什么样的效果呢,也许可以做到 unSupervised
的分类,举例来说,假设你有一大堆的,假设你想要做那个手写数字辨识,你有 0 到
9 的图片,你把 0 到 9 的图片统统收集起来,Train 一个这样子的
Aauto-Encoder,然后强迫中间的 Latent Representation,强迫中间的这个 Code
啊,一定要是 One-Hot Vector,那你这个 Code 正好设个 10 维,也许每一个
One-Hot 的 Code,所以这 10 维,就有 10 种可能的 One-Hot 的 Code,也许每一种
One-Hot 的 Code,正好就对应到一个数字也说不定,所以今天如果用 One-Hot 的
Vector,来当做你的 Embedding 的话,也许就可以做到完全在没有,完全没有Llabel
Data 的情况下,让机器自动学会分类。</li>
</ul>
<p>其实还有其他,在这种啊 Discrete 的 Representation
的这个,技术里面啊,其中最知名的就是 ==VQVAE==,Vector Quantized
Variational Aauto-Encoder,VQVAE
啊,是这样子运作的,就是你输入一张图片,Encoder 呢
输出一个向量,这个向量它是一般的向量,它是 Continuous 的,但接下来你有一个
==Codebook==。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191635308.png" alt="image-20220615191635308" style="zoom:67%;"></p>
<p>所谓 Codebook 的意思就是,你有一排向量,这排向量也是 Learn 出来的,你把
Encoder
的输出,去跟这排向量都去算个<strong>相似度</strong>,那你发现这件事情啊,其实跟
Self-attention 有点像,上面这个 Vector 就是 Query,下面这些 Vector 就是
Key,那接下来呢就看这些 Vector
里面,谁的<strong>相似度最大</strong>,那你把相似度最大的那个 Vector
拿出来。==【类似self-attention】==</p>
<p>这边就是那个,这个 Key 跟那个 Value,是等于是共用同一个 Vector。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191720041.png" alt="image-20220615191720041" style="zoom:67%;"></p>
<p>如果你把这整个 Process,用 Self-attention 来比喻的话,那就等于是 Key 跟
Value 是共同的 Vector,然后把这个 Vector 呢,丢到 Decoder
里面,然后要它输出一张图片,然后接下来 Training
的时候,就是要让输入跟输出越接近越好</p>
<p>这一个 Decoder,这个 Encoder,这一个
Codebook,都是一起从资料里面被学出来的,这样做的好处就是你就可以,你就有
Discrete 的这个 Latent Representation,也就是说这边 Decoder
的输入,一定是这边这个 Codebook,里面的向量的其中一个,假设你 Codebook
里面有 32 个向量,那你 Decoder 的输入,就只有 32
种可能,你等于就是让你的这个
Embedding,它是离散的,它没有无穷无尽的可能,它只有 32 种可能而已</p>
<p>那其实像这样子的技术啊,如果你拿它
把它用在语音上,你就是一段声音讯号输进来,通过 Encoder
以后产生一个向量,接下来呢,你去计算这个相似度,把最像的那个向量拿出来丢给
Decoder,再输出一样的声音讯号,这个时候你会发现说你的 Codebook
啊,可能可以学到最基本的发音部位</p>
<p>举例来说 你的,这个最基本的发音单位啊,又叫做
==Phonetic==,那如果你不知道 Phonetic 是什么的话,你就把它想成是 KK
音标,那你就会发现说,这个 Codebook 里面每一个
Vector,它就对应到某一个发音,就对应到 KK 音标里面的某一个符号,这个是
VQVAE。</p>
<h3><span id="33-anomalydetection"><strong><font color="red"> 3.3 Anomaly
Detection </font></strong></span></h3>
<p>那接下来,就是我们在作业里面要使用的技术,在作业里面我们会拿
Aauto-Encoder,来做 Anomaly 的
Detection,那我在规划作业的时候,其实就是想要 Aauto-Encoder 出一个作业,那
Aauto-Encoder 的技术很多,那最后我决定做 Anomaly 的
Detection，因为这个是你在非常多的场合,都有机会应用到的一个技术。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615194339007.png" alt="image-20220615194339007" style="zoom:67%;"></p>
<p>Anomaly 的 Detection ,假设你有一堆的训练资料,这边用 X1 到 XN
来表示我们的训练资料,而 Anomaly
Detection,它的中文通常翻译成异常检测。</p>
<p><strong><font color="red">
异常检测要做的事情就是,来了一笔新的资料,它到底跟我们之前在训练资料里面看过的资料,相不相似呢？</font></strong>也就是说你需要找出,你需要有一个异常检测的系统,这个异常检测的系统,是透过大量你已经看过的资料训练出来的。</p>
<ul>
<li>给它一笔新的资料,如果这笔新的资料,看起来像是训练资料里面的
Data,就说它是正常的</li>
<li>如果看起来不像是训练资料里面的 Data,就说它是异常的</li>
</ul>
<p>那其实 Anomaly,Anomaly
这个词啊,有很多不同的其他的称呼,比如说有时候你会叫它
<strong>Outlier</strong>,有时候你会叫它 Novelty,有时候你会叫它
Exceptions,但其实指的都是同样的事情,你就是要看某一笔新的资料,它跟之前看过的资料到底相不相似,但是所谓的<strong>相似这件事啊,其实并没有非常明确的定义</strong>,它是见仁见智的,会根据你的应用情境而有所不同。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615194546961.png" alt="image-20220615194546961" style="zoom:67%;"></p>
<p>举例来说</p>
<ul>
<li>假设现在你的训练资料这个都是雷丘,那这个皮卡丘就算是异常的东西</li>
<li>但是假设你的训练资料里面,你所有的动物都是皮卡丘,那雷丘就是异常的东西,所以我们并不会说,某一个东西它一定就是
Normal,一定就是
Anomaly,我们不会说某个东西它一定是正常或异常,它<strong>是正常或异常,取决于你的训练资料长什么样子</strong></li>
<li>或者是说假设你的训练资料里面,通通都是宝可梦,那雷丘跟皮卡丘通通都算是正常的,而可能数码宝贝,亚古兽知道吗,这应该是亚古兽
对不对,亚古兽算是异常的</li>
</ul>
<h4><span id="那个这个异常检测有什么样的应用呢">那个这个异常检测有什么样的应用呢？</span></h4>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615194611806.png" alt="image-20220615194611806" style="zoom:67%;"></p>
<ul>
<li>举例来说,它可以来做<strong>诈欺侦测</strong>,假设你的训练资料里面,有一大堆信用卡的交易纪录,那我们可以想像说,多数信用卡的交易都是正常的,那你拿这些正常的信用卡训练的交易纪录,来训练一个异常检测的模型,那有一笔新的交易纪录进来,你就可以让机器帮你判断说,这笔纪录算是正常的
还是异常的,所以这种异常检测的技术,可以拿来做诈欺侦测。</li>
<li>或者是它可以拿来做网路的这个<strong>侵入侦测</strong>,举例来说,你有很多连线的纪录资料,那你相信多数人连到你的网站的时候,他的行为都是正常的,多数人都是好人,你收集到一大堆正常的连线的纪录,那接下来有一笔新的连线进来,你可以根据过去正常的连线,训练出一个异常检测的模型,看看新的连线,它是正常的连线
还是异常的连线,它是有攻击性的
还是正常的连线,或者是它在医学上也可能有应用,你收集到一大堆正常细胞的资料,拿来训练一个异常检测的模型,那也许看到一个新的细胞,它可以知道这个细胞有没有突变,也许有突变,它就是一个癌细胞等等。</li>
</ul>
<p>那讲到这边有人可能会想说,Anomaly Detection
异常检测的问题,我们能不能够把它当做<strong>二元分类</strong>的问题来看啊？</p>
<figure>
<img src="../../../../../Library/Application%20Support/typora-user-images/image-20220615194724455.png" alt="image-20220615194724455">
<figcaption aria-hidden="true">image-20220615194724455</figcaption>
</figure>
<p>你说你要做诈欺侦测,你就收集一大堆正常的信用卡纪录,一堆诈欺的信用卡纪录,训练一个
Binary 的
Classifier,就结束啦,就这样子不是吗？比较<strong>难点就是你要收资料</strong>。</p>
<p>这种异常检测的问题它的难点,正在就在收资料上面,通常你<strong>比较有办法收集到正常的资料,你比较不容易收集到异常的资料</strong>,你可能有一大堆信用卡交易的纪录,但是多数信用卡交易的纪录可能都是正常的,异常的资料相较于正常的资料,可能非常地少,甚至有一些异常的资料混在正常的里面,你也不太可,你可能也完全没有办法侦测出来,所以在这一种异常检测的问题里面。</p>
<p><strong><font color="red">
我们往往假设,我们有一大堆正常的资料,但我们几乎没有异常的资料,所以它不是一个一般的分类的问题,这种分类的问题又叫做
==One Class
的分类问题==。</font></strong>就是我们只有一个类别的资料,那你怎么训练一个模型,因为你想你要训练一个分类器,你得有两个类别的资料,你才能训练分类器啊,如果只有一个类别的资料,那我们可以训练什么东西,这个时候就是
Aauto-Encoder,可以派得上用场的时候了。</p>
<p>举例来说,假设我们现在想要做一个系统,这个系统是要侦测说一张图片：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615194856711.png" alt="image-20220615194856711" style="zoom:67%;"></p>
<p>举例来说,它是不是真人的人脸,那你可以找到一大堆图片,它都是真正的人脸,那我们就拿这些真人的人脸,来训练一个
Aauto-Encoder。这个是你老婆的照片,那你可以拿它来训练一个
Aauto-Encoder,那你训练完这个 Aauto-Encoder
以后,在测试的时候,如果进来的也是你老婆的照片,那因为在训练的时候有看过这样的照片,所以它可以顺利地被还原回来。</p>
<p>你可以计算这一张照片通过 Encoder,再通过 Decoder
以后,它的变化有多大,你可以去<strong>计算这个输入的照片,跟这个输出的照片,它们的差异有多大</strong>,如果差异很小,你的
Decoder
可以顺利地还原原来的照片,代表这样类型的照片,是在训练的时候有看过的,不过反过来说,假设有一张照片是训练的时候没有看过的。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615195012966.png" alt="image-20220615195012966" style="zoom:67%;"></p>
<p>她是那个凉宫春日,但是她不是真人,她是一个动画的人物,她是二次元的人物,一个二次元人物的照片,输入
Encoder 再输出 Decoder
以后,因为这是没有看过的东西,这是训练的时候没有看过的照片,那你的
Decoder,就很难把它还原回来,<strong>如果你计算输入跟输出的差异,发现差异非常地大</strong>,那就代表说,现在输入给
Encoder
的这张照片,可能是一个异常的状况,可能是训练的时候没有看过的状况,所以你就可以<strong>看
reconstruction 的 loss</strong>,这个 reconstruction
的好坏,来决定说你现在在测试的时候,看到这张照片,是不是训练的时候有看过同类型的照片。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>Seq2Seq</category>
      </categories>
  </entry>
  <entry>
    <title>模型训练（3）Adaptive Learning Rate</title>
    <url>/posts/2D5Z22P/</url>
    <content><![CDATA[<h3><span id="李宏毅课程笔记adaptivelearning-rate">李宏毅课程笔记：Adaptive
Learning Rate</span></h3>
<p>critical
point其实不一定是,你在训练一个Network的时候,会遇到的最大的障碍,今天要告诉大家的是一个叫做Adaptive
Learning Rate的技术,我们要给每一个参数不同的learning rate</p>
<h3><span id="一-training-stuck-smallgradient">一、Training stuck ≠ Small
Gradient</span></h3>
<h5><span id="peoplebelieve-training-stuck-because-the-parameters-are-around-a-criticalpoint">People
believe training stuck because the parameters are around a critical
point …</span></h5>
<p><strong>人们认为，由于参数处于临界点附近，培训陷入困境</strong>;為什麼我说这个critical
point不一定是我们训练过程中,最大的阻碍呢？</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011433865.png" alt="image-20220616182046388">
<figcaption aria-hidden="true">image-20220616182046388</figcaption>
</figure>
<p>往往同学们,在训练一个network的时候,你会把它的loss记录下来,所以你会看到,你的loss原来很大,随著你参数不断的update,横轴代表参数update的次数,随著你参数不断的update,这个loss会越来越小,最后就卡住了,你的loss不再下降。</p>
<p>那多数这个时候,大家就会猜说,那是不是走到了critical
point,因為gradient等於零的关係,所以我们没有办法再更新参数,但是真的是这样吗？</p>
<p>当我们说 走到critical
point的时候,意味著gradient非常的小,但是你有确认过,当<strong>你的loss不再下降的时候,gradient真的很小吗？</strong>其实多数的同学可能,都没有确认过这件事,而事实上在这个例子裡面,在今天我show的这个例子裡面,当我们的loss不再下降的时候,gradient并没有真的变得很小</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011433585.png" alt="image-20220616182117000"></p>
<p>gradient是一个向量，下面是gradient的norm,即gradient这个向量的长度,随著参数更新的时候的变化,你会发现说<strong>虽然loss不再下降,但是这个gradient的norm,gradient的大小并没有真的变得很小</strong></p>
<p>这样子的结果其实也不难猜想,也许你遇到的是这样子的状况</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011434572.png"></p>
<p>这个是我们的error surface,然后你现在的gradient,在error
surface山谷的两个谷壁间,<strong>不断的来回的震荡</strong></p>
<p>这个时候你的loss不会再下降,所以你会觉得它真的卡到了critical
point,卡到了saddle point,卡到了local
minima吗？不是的,<strong>它的gradient仍然很大,只是loss不见得再减小了</strong></p>
<p>所以你要注意,当你今天训练一个network,train到后来发现,loss不再下降的时候,你不要随便说,我卡在local
minima,我卡在saddle
point,<strong>有时候根本两个都不是,你只是单纯的loss没有办法再下降</strong></p>
<p>就是為什麼你在在<a href="https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW02/HW02-2.ipynb">作业2-2</a>,会有一个作业叫大家,算一下gradient的norm,然后算一下说,你现在是卡在saddle
point,还是critical
point,因為多数的时候,当你说你训练卡住了,很少有人会去分析卡住的原因,為了强化你的印象,我们有一个作业,让你来分析一下,卡住的原因是什麼,</p>
<h4><span id="11-wait-a-minute">1.1 Wait a minute</span></h4>
<p>有的同学就会有一个问题,如果我们在训练的时候,其实很少卡到saddle
point,或者是local minima,那这一个图是怎麼做出来的呢?</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011434590.png" alt="image-20220616182149914" style="zoom:67%;"></p>
<p>我们上次有画过这个图是说我们现在训练一个Network,训练到现在参数<strong>在critical
point附近,然后我们再来根据eigen value的正负号,来判断说这个critical
point,比较像是saddle point,还是local minima</strong></p>
<p>那如果实际上在训练的时候,要走到saddle point,或者是local
minima,是一件困难的事情,那这个图到底是怎麼画出来的。那这边告诉大家一个秘密,这个图你要训练出这样子的结果,你要训练到你的参数很接近critical
point,用一般的gradient descend,其实是做不到的,用一般的gradient descend
train,你往往会得到的结果是,你在这个gradient还很大的时候,你的loss就已经掉了下去,这个是需要特别方法train的。</p>
<p>所以做完这个实验以后,我更感觉你要走到一个critical
point,其实是困难的一件事,多数时候training,在还没有走到critical
point的时候,就已经停止了,那这并不代表说,critical
point不是一个问题,我只是想要告诉你说,我们真正目前,<strong>当你用gradient
descend,来做optimization的时候,你真正应该要怪罪的对象,往往不是critical
point,而是其他的原因。</strong></p>
<h4><span id="12training-can-be-difficult-even-without-critical-points">1.2
Training can be difficult even without critical points</span></h4>
<p>如果今天critical
point不是问题的话,為什麼我们的training会卡住呢,我这边举一个非常简单的例子,我这边有一个,非常简单的error
surface</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011434181.png"></p>
<p>我们只有两个参数,这两个参数值不一样的时候,Loss的值不一样,我们就画出了一个error
surface,这个<strong>error
surface的最低点</strong>在黄色X这个地方,事实上,这个error
surface是convex的形状(可以理解为凸的或者凹的，convex
optimization常翻译为“凸优化”)</p>
<p>如果你不知道convex是什麼,没有关係,总之它是一个,它的这个等高线是椭圆形的,只是它在横轴的地方,它的gradient非常的小,它的坡度的变化非常的小,非常的平滑,所以这个椭圆的长轴非常的长,短轴相对之下比较短,在纵轴的地方gradient的变化很大,error
surface的坡度非常的陡峭</p>
<p>那现在我们要从<strong>黑点</strong>这个地方,这个地方当作<strong>初始的点</strong>,然后来做gradient
descend，你可能觉得说,这个convex的error surface,做gradient
descend,有什麼难的吗？不就是一路滑下来,然后可能再走过去吗,应该是非常容易。你实际上自己试一下,你会发现说,就连这种convex的error
surface,形状这麼简单的error surface,你用gradient
descend,都不见得能把它做好,举例来说这个是我实际上,自己试了一下的结果</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011434016.png"></p>
<p>我learning
rate设10⁻²的时候,我的这个参数在峡谷的两端,我的参数在山壁的两端不断的震盪,我的loss掉不下去,但是gradient其实仍然是很大的。那你可能说,就是因為你<strong>learning
rate设太大了</strong>阿,learning
rate决定了我们update参数的时候步伐有多大,learning
rate显然步伐太大,你没有办法慢慢地滑到山谷裡面只要把learning
rate设小一点,不就可以解决这个问题了吗？</p>
<p>事实不然,因為我试著去,调整了这个learning
rate,就会发现你光是要train这种convex的optimization的问题,你就觉得很痛苦,我就调这个learning
rate,从10⁻²,一直调到10⁻⁷,调到10⁻⁷以后,终於不再震盪了</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011434853.png"></p>
<p>终於从这个地方滑滑滑,滑到山谷底终於左转,但是你发现说,这个训练永远走不到终点,因為我的<strong>learning
rate已经太小了</strong>,竖直往上这一段这个很斜的地方,因為这个坡度很陡,gradient的值很大,所以还能够前进一点,左拐以后这个地方坡度已经非常的平滑了,这麼小的learning
rate,根本没有办法再让我们的训练前进。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011434838.png" alt style="zoom:50%;"></p>
<p>事实上在左拐这个地方,看到这边一大堆黑点,这边<strong>有十万个点</strong>,这个是张辽八百冲十万的那个十万,但是我都没有办法靠近,这个local
minima的地方,所以显然<strong>就算是一个convex的error
surface,你用gradient descend也很难train</strong></p>
<p>这个convex的optimization的问题,确实有别的方法可以解,但是你想想看,如果今天是更复杂的error
surface,你真的要train一个deep network的时候,gradient
descend是你,唯一可以仰赖的工具,但是gradient
descend这个工具,连这麼简单的error surface都做不好,一室之不治
何以天下国家為,这麼简单的问题都做不好,那如果难的问题,它又怎麼有可能做好呢</p>
<p>所以我们需要更好的gradient
descend的版本,<strong><font color="red">在之前我们的gradient
descend裡面,所有的参数都是设同样的learning rate,这显然是不够的,learning
rate它应该要為,每一个参数客製化</font></strong>,所以接下来我们就是要讲,客製化的learning
rate,怎麼做到这件事情</p>
<h3><span id="二-differentparameters-needs-different-learning-rate">二、Different
parameters needs different learning rate</span></h3>
<p>那我们要怎麼客製化learning
rate呢,我们不同的参数到底,需要什麼样的learning
rate呢？从刚才的例子裡面,其实我们可以看到一个大原则,<strong>如果在某一个方向上,我们的gradient的值很小,非常的平坦,那我们会希望learning
rate调大一点,如果在某一个方向上非常的陡峭,坡度很大,那我们其实期待,learning
rate可以设得小一点</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011434345.png"></p>
<h5><span id="那这个learningrate要如何自动的根据这个gradient的大小做调整呢">那这个learning
rate要如何自动的,根据这个gradient的大小做调整呢？</span></h5>
<p><strong>我们要改一下,gradient
descend原来的式子,我们只放某一个参数update的式子,我们之前在讲gradient
descend,</strong>我们往往是讲,所有参数update的式子,那这边為了等一下简化这个问题,我们只看一个参数,但是你完全可以把这个方法,推广到所有参数的状况
<span class="math display">\[
{θ{_i}{^{t+1}}} ← {θ{_i}{^{t}}}-{\eta}{g{_i}{^{t}}}
\]</span> 我们只看一个参数,这个参数叫做<span class="math inline">\({θ{_i}{^{t}}}\)</span>,这个<span class="math inline">\({θ{_i}{^{t}}}\)</span>在第t个iteration的值,减掉在第t个iteration这个参数i算出来的gradient
<span class="math inline">\({g{_i}{^{t}}}\)</span> <span class="math display">\[
{g{_i}{^{t}}}=\frac{\partial{L}}{\partial{θ_i}}|_{θ=θ^t}
\]</span> 这个<span class="math inline">\({g{_i}{^{t}}}\)</span>代表在第t个iteration,也就是θ等於θᵗ的时候,参数θᵢ对loss的微分,我们把这个θᵢᵗ减掉learning
rate,乘上gᵢᵗ会更新learning rate到θᵢᵗ⁺¹,<strong>这是我们原来的gradient
descend</strong>,<strong>我们的learning rate是固定的</strong></p>
<p>现在我们要有一个<strong>随著参数客製化的learning
rate</strong>,我们把原来learning rate <span class="math inline">\(η\)</span>这一项呢,改写成<span class="math inline">\(\frac{η}{σᵢᵗ}\)</span> <span class="math display">\[
{θ{_i}{^{t+1}}} ← {θ{_i}{^{t}}}-{\frac{η}{σᵢᵗ}}{g{_i}{^{t}}}
\]</span> <strong><font color="red"> 这个<span class="math inline">\(σᵢᵗ\)</span>你发现它有一个上标t,有一个下标i,这代表说这个σ这个参数,首先它是depend
on i的,不同的参数我们要给它不同的σ,同时它也是iteration
dependent的,不同的iteration我们也会有不同的σ。</font></strong></p>
<p>所以当我们把我们的learning rate,从η改成<span class="math inline">\(\frac{η}{σᵢᵗ}\)</span>的时候,我们就有一个,parameter
dependent的learning rate,接下来我们是要看说,这个parameter
dependent的learning rate有什麼常见的计算方式。</p>
<h4><span id="21-root-mean-square">2.1 Root mean square</span></h4>
<p>那这个σ有什麼样的方式,可以把它计算出来呢,一个常见的类型是算,gradient的<strong>Root
Mean Square（均方根）</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011435453.png" alt="image-20220616183815859" style="zoom:50%;"></p>
<p>现在参数要update的式子,我们从θᵢ⁰初始化参数减掉gᵢ⁰,乘上learning rate
η除以σᵢ⁰,就得到θᵢ¹, <span class="math display">\[
{θ{_i}{^{1}}} ← {θ{_i}{^{0}}}-{\frac{η}{σᵢ^0}}{g{_i}{^{0}}}
\]</span></p>
<ul>
<li><p>这个<strong>σᵢ⁰</strong>在<strong>第一次update参数</strong>的时候,这个σᵢ⁰是(gᵢ⁰)²开根号
<span class="math display">\[
  {σᵢ^0}=\sqrt{({g{_i}{^{0}}})^2}=|{g{_i}{^{0}}}|
  \]</span>
这个gᵢ⁰就是我们的gradient,就是gradient的平方开根号,其实就是gᵢ⁰的绝对值,所以你把gᵢ⁰的绝对值代到<span class="math inline">\({θ{_i}{^{1}}} ←
{θ{_i}{^{0}}}-{\frac{η}{σᵢ^0}}{g{_i}{^{0}}}\)</span>,这个式子中gᵢ⁰跟这个根号底下的gᵢ⁰,它们的大小是一样的,所以式子中这一项只会有一个,要嘛是正一
要嘛是负一,就代表说我们第一次在update参数,从θᵢ⁰update到θᵢ¹的时候,要嘛是加上η
要嘛是减掉η,跟这个gradient的大小没有关係,是看你η设多少,这个是第一步的状况</p></li>
<li><p>重点是接下来怎麼处理,那θᵢ¹它要一样,减掉gradient gᵢ¹乘上η除以σᵢ¹,
<span class="math display">\[
  {θ{_i}{^{1}}}-{\frac{η}{σᵢ^1}}{g{_i}{^{1}}}
  \]</span> 现在在第二次update参数的时候,是要除以σᵢ¹
,这个σᵢ¹就是我们过去,<strong>所有计算出来的gradient,它的平方的平均再开根号</strong>
<span class="math display">\[
  {σᵢ^1}=\sqrt{\frac{1}{2}[{(g{_i}{^{0}}})^2+{(g{_i}{^{1}}})^2]}
  \]</span>
我们到目前為止,在第一次update参数的时候,我们算出了gᵢ⁰,在第二次update参数的时候,我们算出了gᵢ¹,所以这个σᵢ¹就是(gᵢ⁰)²,加上(gᵢ¹)²除以½再开根号,这个就是Root
Mean Square,我们算出这个σᵢ¹以后,我们的learning
rate就是η除以σᵢ¹,然后把θᵢ¹减掉,η除以σᵢ¹乘以gᵢ¹ 得到θᵢ² <span class="math display">\[
  {θ{_i}{^{2}}} ← {θ{_i}{^{1}}}-{\frac{η}{σᵢ^1}}{g{_i}{^{1}}}
  \]</span></p></li>
<li><p>同样的操作就反覆继续下去,在θᵢ²的地方,你要减掉η除以σᵢ²乘以gᵢ²,
<span class="math display">\[
  {θ{_i}{^{2}}}-{\frac{η}{σᵢ^2}}{g{_i}{^{2}}}
  \]</span>
那这个σ是什麼呢,这个σᵢ²就是过去,所有算出来的gradient,它的平方和的平均再开根号
<span class="math display">\[
  {σᵢ^2}=\sqrt{\frac{1}{3}[{(g{_i}{^{0}}})^2+{(g{_i}{^{1}}})^2+{(g{_i}{^{2}}})^2]}
  \]</span> 所以你把gᵢ⁰取平方,gᵢ¹取平方
gᵢ²取平方,的平均再开根号,得到σᵢ²放在这个地方,然后update参数 <span class="math display">\[
  {θ{_i}{^{3}}} ← {θ{_i}{^{2}}}-{\frac{η}{σᵢ^2}}{g{_i}{^{2}}}
  \]</span></p></li>
<li><p>所以这个process这个过程,就反覆继续下去,到第t次update参数的时候,其实这个是第t
+ 1次,第t +
1次update参数的时候,你的这个σᵢᵗ它就是过去所有的gradient,gᵢᵗ从第一步到目前為止,所有算出来的gᵢᵗ的平方和,再平均
再开根号得到σᵢᵗ, <span class="math display">\[
  {σᵢ^t}=\sqrt{\frac{1}{t+1}\sum_{i=0}^{t}{(g{_i}{^{t}}})^2}
  \]</span> 然后在把它除learning rate,然后用这一项当作是,新的learning
rate来update你的参数, <span class="math display">\[
  {θ{_i}{^{t+1}}} ← {θ{_i}{^{t}}}-{\frac{η}{σᵢ^t}}{g{_i}{^{t}}}
  \]</span></p></li>
</ul>
<h4><span id="22-adagrad">2.2 Adagrad</span></h4>
<p>那这一招被用在一个叫做Adagrad的方法裡面,<strong>為什麼这一招可以做到我们刚才讲的,坡度比较大的时候,learning
rate就减小,坡度比较小的时候,learning rate就放大呢?</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011435534.png"></p>
<p>你可以想像说,现在我们有两个参数:<strong>一个叫θᵢ¹ 一个叫θᵢ² θᵢ¹坡度小
θᵢ²坡度大</strong></p>
<ul>
<li>θᵢ¹因為它坡度小,所以你在θᵢ¹这个参数上面,算出来的gradient值都比较小</li>
<li>因為gradient算出来的值比较小,然后这个σ是gradient的平方和取平均再开根号</li>
</ul>
<p><span class="math display">\[
{σᵢ^t}=\sqrt{\frac{1}{t+1}\sum_{i=0}^{t}{(g{_i}{^{t}}})^2}
\]</span></p>
<ul>
<li>所以算出来的σ就小,σ小 learning rate就大 <span class="math display">\[
  {\frac{η}{σᵢ^t}}
  \]</span></li>
</ul>
<p>反过来说θᵢ²,θᵢ²是一个比较陡峭的参数,在θᵢ²这个方向上loss的变化比较大,所以算出来的gradient都比较大,,你的σ就比较大,你在update的时候
你的step,你的参数update的量就比较小</p>
<p>所以有了σ这一项以后,你就可以随著gradient的不同,每一个参数的gradient的不同,来自动的调整learning
rate的大小,那这个并不是,你今天会用的最终极的版本,</p>
<h4><span id="23-rmsprop">2.3 RMSProp</span></h4>
<p>刚才那个版本,就算是同一个参数,它需要的learning
rate,也会随著时间而改变,我们刚才的假设,好像是同一个参数,它的gradient的大小,就会固定是差不多的值,但事实上并不一定是这个样子的。举例来说我们来看,这个新月形的error
surface：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011435083.png" alt style="zoom:67%;"></p>
<p>如果我们考虑横轴的话,考虑左右横的水平线的方向的话,你会发现说,在绿色箭头这个地方坡度<strong>比较陡峭,所以我们需要比较小的learning
rate</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011435667.png" style="zoom: 67%;"></p>
<p>但是走到了中间这一段，到了红色箭头的时候呢,坡度又变得平滑了起来,<strong>平滑了起来就需要比较大的learning
rate</strong>,所以就算是<strong>同一个参数同一个方向,我们也期待说,learning
rate是可以动态的调整的</strong>,于是就有了一个新的招数,这个招数叫做RMS
Prop。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011436790.png"></p>
<p>RMS Prop这个方法,<strong>它的第一步跟刚才讲的Root Mean
Square,也就是那个Apagrad的方法,是一模一样的</strong> <span class="math display">\[
{σᵢ^0}=\sqrt{({g_i^0})^2}
\]</span>
我们看第二步,一样要算出σᵢ¹,只是我们现在算出σᵢ¹的方法跟刚才,算Root Mean
Square的时候不一样,刚才在算Root Mean
Square的时候,每一个gradient都有同等的重要性,但<strong>在RMS
Prop裡面,它决定你可以自己调整,现在的这个gradient,你觉得它有多重要</strong>
<span class="math display">\[
{σᵢ^1}=\sqrt[]{\alpha(σ_i^0)^2+(1-\alpha)(g_i^1)^2}
\]</span> 所以在RMS
Prop裡面,我们这个σᵢ¹它是前一步算出来的σᵢ⁰,裡面就是有gᵢ⁰,所以这个<strong>σᵢ⁰就代表了gᵢ⁰的大小</strong>,所以它是(σᵢ⁰)²,乘上α加上(1-α),乘上现在我们刚算出来的,新鲜热腾腾的gradient就是gᵢ¹</p>
<p>那这个<strong>α就像learning
rate一样,这个你要自己调它,它是一个hyperparameter</strong></p>
<ul>
<li>如果我今天<strong>α设很小趋近於0</strong>,就代表我觉得<strong>gᵢ¹相较於之前所算出来的gradient而言,比较重要</strong></li>
<li>我<strong>α设很大趋近於1</strong>,那就代表我觉得<strong>现在算出来的gᵢ¹比较不重要,之前算出来的gradient比较重要</strong></li>
</ul>
<p>所以同理在第三次update参数的时候,我们要算σᵢ²
,我们就把σᵢ¹拿出来取平方再乘上α,那σᵢ¹裡面有gᵢ¹跟σᵢ⁰
,σᵢ⁰裡面又有gᵢ⁰,所以你知道σᵢ¹裡面它有gᵢ¹有gᵢ⁰,
然后这个gᵢ¹跟gᵢ⁰呢他们会被乘上α,然后再加上1-α乘上这个(gᵢ²)² <span class="math display">\[
{σᵢ^2}=\sqrt[]{\alpha(σ_i^1)^2+(1-\alpha)(g_i^2)^2}
\]</span> 所以这个α就会决定说gᵢ²,它在整个σᵢ²裡面佔有多大的影响力</p>
<p>那同样的过程就反覆继续下去,σᵢᵗ等於根号α乘上(σᵢᵗ⁻¹)²,加上(1-α) (gᵢᵗ)²,
<span class="math display">\[
{σᵢ^t}=\sqrt[]{\alpha(σ_i^{t-1})^2+(1-\alpha)(g_i^t)^2}
\]</span>
你用α来决定现在刚算出来的gᵢᵗ,它有多重要,好那这个就是RMSProp。那RMSProp我们刚刚讲过说,透过α这一项你可以决定说,gᵢᵗ相较於之前存在,σᵢᵗ⁻¹裡面的gᵢᵗ到gᵢᵗ⁻¹而言,它的重要性有多大,如果你用RMS
Prop的话,你就可以动态调整σ这一项,我们现在假设从这个地方开始：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011436779.png" alt="image-20220616194330541" style="zoom: 67%;"></p>
<p>这个黑线是我们的error
surface,从这个地方开始你要update参数,好你这个球就从这边走到这边,那因為一路上都很平坦,很平坦就代表说g算出来很小,代表现在update参数的时候,我们会走比较大的步伐</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011436078.png" alt="image-20220616194342782" style="zoom:67%;"></p>
<p>接下来继续滚,滚到这边以后我们gradient变大了,如果不是RMS
Prop,原来的Adagrad的话它反应比较慢,但如果你用RMS
Prop,然后呢你把α设小一点,你就是让新的,刚看到的gradient影响比较大的话,那你就可以很快的让σ的值变大,也可以很快的让你的步伐变小</p>
<p>你就可以踩一个煞车,本来很平滑走到这个地方,突然变得很陡,那RMS
Prop可以很快的踩一个煞车,把learning
rate变小,如果你没有踩剎车的话,你走到这裡这个地方,learning
rate太大了,那gradient又很大,两个很大的东西乘起来,你可能就很快就飞出去了,飞到很远的地方</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011436278.png" alt="image-20220616194447003" style="zoom: 67%;"></p>
<p>如果继续走,又走到平滑的地方了,因為这个σᵢᵗ
你可以调整α,让它比较看重於,最近算出来的gradient,所以你gradient一变小,σ可能就反应很快,它的这个值就变小了,然后呢你走的步伐就变大了,这个就是RMS
Prop,</p>
<h4><span id="24-adam">2.4 Adam</span></h4>
<p>那今天你最常用的,optimization的策略,有人又叫做optimizer,今天最常用的optimization的策略,就是Adam</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011436991.png"></p>
<p>Adam就是RMS
Prop加上Momentum,那Adam的演算法跟原始的论文https://arxiv.org/pdf/1412.6980.pdf</p>
<p>今天pytorch裡面,都帮你写得好好的了,所以这个你今天,不用担心这种optimization的问题,optimizer这个deep
learning的套件,往往都帮你做好了,然后这个optimizer裡面,也有一些参数需要调,也有一些hyperparameter,需要人工决定,但是你往往用预设的,那一种参数就够好了,你自己调有时候会调到比较差的,往往你直接copy,这个pytorch裡面,Adam这个optimizer,然后预设的参数不要随便调,就可以得到不错的结果了,关於Adam的细节,就留给大家自己研究</p>
<h3><span id="三-learning-rate-scheduling">三、Learning Rate Scheduling</span></h3>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011436318.png" alt style="zoom:67%;"></p>
<p>我们刚才讲说这个简单的error
surface,我们都train不起来,现在我们来看一下,加上Adaptive Learning
Rate以后,train不train得起来。</p>
<p>那这边是採用,最原始的Adagrad那个做法啦,就是把过去看过的,这个learning
rate通通都,过去看过的gradient,通通都取平方再平均再开根号当作这个σ
,做起来是这个样子的</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011436316.png" alt style="zoom:67%;"></p>
<p>这个走下来没有问题,然后接下来在左转的时候,这边也是update了十万次,之前update了十万次,只卡在左转这个地方</p>
<p>那现在有Adagrad以后,你可以再继续走下去,走到非常接近终点的位置,因為当你走到这个地方的时候,你因為这个左右的方向的,这个gradient很小,所以learning
rate会自动调整,左右这个方向的,learning
rate会自动变大,所以你这个步伐就可以变大,就可以不断的前进</p>
<p>接下来的问题就是,為什麼快走到终点的时候突然爆炸了呢？你想想看
我们在做这个σ的时候,我们是把过去所有看到的gradient,都拿来作平均</p>
<ul>
<li><p>所以这个纵轴的方向,在这个初始的这个地方,感觉gradient很大</p></li>
<li><p>可是这边走了很长一段路以后,这个纵轴的方向,gradient算出来都很小,所以纵轴这个方向,这个y轴的方向就累积了很小的σ</p></li>
<li><p>因為我们在这个y轴的方向,看到很多很小的gradient,所以我们就累积了很小的σ,累积到一个地步以后,这个step就变很大,然后就爆走就喷出去了</p></li>
<li><p>喷出去以后没关係,有办法修正回来,因為喷出去以后,就走到了这个gradient比较大的地方,走到gradient比较大的地方以后,这个σ又慢慢的变大,σ慢慢变大以后,这个参数update的距离,Update的步伐大小就慢慢的变小</p></li>
</ul>
<p>你就发现说走著走著,突然往左右喷了一下,但是这个喷了一下不会永远就是震盪,不会做简谐运动停不下来,这个力道慢慢变小,有摩擦力
让它慢慢地慢慢地,又回到中间这个峡谷来,然后但是又累计一段时间以后
又会喷,然后又慢慢地回来
怎麼办呢,<strong>有一个方法也许可以解决这个问题,这个叫做learning
rate的scheduling</strong></p>
<h5><span id="什麼是learningrate的scheduling呢">什麼是learning
rate的scheduling呢？</span></h5>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011437242.png" alt="image-20220616194800158" style="zoom: 67%;"></p>
<p>我们刚才这边还有一项η,这个η是一个固定的值,learning rate
scheduling的意思就是说,我们<strong>不要把η当一个常数,我们把它跟时间有关</strong></p>
<p><strong><font color="red"> 最常见的策略叫做Learning Rate
Decay,也就是说，随著时间的不断地进行,随著参数不断的update,我们这个η让它越来越小。</font></strong></p>
<p>那这个也就合理了,因為一开始我们距离终点很远,随著参数不断update,我们距离终点越来越近,所以我们把learning
rate减小,让我们参数的更新踩了一个煞车,让我们参数的更新能够慢慢地慢下来,所以刚才那个状况,如果加上Learning
Rate Decay有办法解决。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011437755.png" alt="image-20220616195004172" style="zoom: 67%;"></p>
<p>刚才那个状况,如果加上Learning Rate
Decay的话,我们就可以很平顺的走到终点,因為在这个地方,这个η已经变得非常的小了,虽然说它本来想要左右乱喷,但是因為乘上这个非常小的η,就停下来了
就可以慢慢地走到终点,那除了Learning Rate
Decay以外,还有另外一个经典，常用的Learning Rate
Scheduling的方式,叫做Warm Up</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011437476.png" alt="image-20220616195017126" style="zoom:67%;"></p>
<p>Warm Up这个方法,听起来有点匪夷所思,这Warm
Up的方法是<strong>让learning rate,要先变大后变小</strong>,你会问说
变大要变到多大呢,变大速度要多快呢
，小速度要多快呢,<strong>这个也是hyperparameter</strong>,你要自己用手调的,但是大方向的大策略就是,learning
rate要先变大后变小,那这个方法听起来很神奇,就是一个黑科技这样,这个黑科技出现在,很多远古时代的论文裡面。</p>
<p>这个warm up,最近因為在训练BERT的时候,往往需要用到Warm
Up,所以又被大家常常拿出来讲,但它并不是有BERT以后,才有Warm Up的,Warm
Up这东西远古时代就有了,举例来说,Residual Network裡面是有Warm Up的</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011437761.png" alt="image-20220616195035436" style="zoom:67%;"></p>
<p>这边是放了Residual
network,放在arXiv上面的文章连结啦,今天这种有关machine learning
的,文章往往在投conference之前,投国际会议之前,就先放到一个叫做arXiv的网站上,把它公开来让全世界的人都可以看。</p>
<p>你其实看这个arXiv的网址,你就可以知道,这篇文章是什麼时候放到网路上的,怎麼看呢
arXiv的前四个数字,这15代表年份,代表说residual
network这篇文章,是2015年放到arXiv上面的,后两个数字代表月份,所以它是15年的12月,15年的年底放在arXiv上面的</p>
<p>所以五六年前的文章,在deep
learning变化,这麼快速的领域裡面,五六年前就是上古时代,那在上古时代,这个Residual
Network裡面,就已经记载了Warm Up的这件事情,它说我们<strong>用learning
rate 0.01,取Warm Up,先用learning rate 0.01,再把learning
rate改成0.1</strong></p>
<p>用过去我们通常最常见的train,Learning Rate
Scheduling的方法,就是让learning rate越来越小,但是Residual
Network,这边特别註明它反其道而行,一开始要设0.01
接下来设0.1,还特别加一个註解说,一开始就用0.1反而就train不好,不知道為什麼
也没解释,反正就是train不好,需要Warm
Up这个黑科技。而在这个黑科技,在知名的Transformer裡面(这门课也会讲到),也用一个式子提了它。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011437043.png" alt="image-20220616195112806" style="zoom:80%;"></p>
<p>它这边有一个式子说,它的learning
rate遵守这一个,神奇的function来设定,它的learning
rate,这个神奇的function,乍看之下会觉得 哇
在写什麼,不知道在写些什麼。这个东西你实际上,把这个function画出来,你实际上把equation画出来的话,就会发现它就是Warm
Up,learning rate会先增加,然后接下来再递减。所以你发现说Warm
Up这个技术,在很多知名的network裡面都有,被当作一个黑科技,就论文裡面不解释说,為什麼要用这个,但就偷偷在一个小地方,你没有注意到的小地方告诉你说,这个network要用这种黑科技,才能够把它训练起来。那為什麼需要warm
Up呢,这个仍然是今天,一个可以研究的问题啦。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011437649.png" alt="image-20220616195206977" style="zoom:80%;"></p>
<p>这边有一个可能的解释是说,你想想看当我们在用Adam RMS
Prop,或Adagrad的时候,我们会需要计算σ,它是一个统计的结果,<strong>σ告诉我们,某一个方向它到底有多陡,或者是多平滑</strong>,那这个统计的结果,<strong>要看得够多笔数据以后,这个统计才精準,所以一开始我们的统计是不精準的</strong></p>
<p>一开始我们的σ是不精準的,所以我们一开始不要让我们的参数,走离初始的地方太远,先让它在初始的地方呢,做一些像是探索这样,所以<strong>一开始learning
rate比较小,是让它探索 收集一些有关error
surface的情报</strong>,先收集有关σ的统计数据,<strong>等σ统计得比较精準以后,在让learning
rate呢慢慢地爬升</strong></p>
<p>所以这是一个解释,為什麼我们需要warm
up的可能性,那如果你想要学更多,有关warm
up的东西的话,你其实可以看一篇paper,它是Adam的进阶版叫做RAdam,裡面对warm
up这件事情,有更多的理解。</p>
<h3><span id="四-summary-of-optimization">四、Summary of Optimization</span></h3>
<p>所以我们从最原始的gradient descent,进化到这一个版本：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011437020.png" alt="image-20220616202420654" style="zoom:80%;"></p>
<p>这个版本裡面</p>
<ul>
<li><p>我们有Momentum,也就是说我们现在,不是完全顺著gradient的方向,现在不是完全顺著这一个时间点,算出来的gradient的方向,来update参数,而是把过去,所有算出来gradient的方向,做一个加总当作update的方向,这个是momentum</p></li>
<li><p>接下来应该要update多大的步伐呢,我们要除掉,gradient的Root Mean
Square</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011437789.png" alt="image-20220616202442527" style="zoom:67%;"></p>
<p>那讲到这边可能有同学会觉得很困惑,这一个momentum是考虑,过去所有的gradient,这个σ也是考虑过去所有的gradient,一个放在分子一个放在分母,都考虑过去所有的gradient,不就是正好<strong>抵销了吗</strong>？,</p>
<p><strong>但是其实这个Momentum跟这个σ,它们在使用过去所有gradient的方式是不一样的</strong>：</p>
<ul>
<li><p><strong><font color="red">
Momentum是直接把所有的gradient通通都加起来,所以它有考虑方向,它有考虑gradient的正负号,它有考虑gradient是往左走还是往右走。</font></strong></p></li>
<li><p><strong><font color="red"> Root Mean
Square,它就不考虑gradient的方向了</font></strong>。它只考虑gradient的大小,记不记得我们在算σ的时候,我们都要取平方项,我们都要把gradient取一个平方项,我们是把平方的结果加起来,所以我们只考虑gradient的大小,不考虑它的方向,所以Momentum跟这个σ,算出来的结果并不会互相抵销掉。</p></li>
</ul></li>
<li><p>那最后我们还会加上,一个learning rate的scheduling：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011437624.png" alt="image-20220616202650308" style="zoom:80%;"></p>
<p>那这个是今天<strong>optimization</strong>的,完整的版本了,这种Optimizer,除了Adam以外,Adam可能是今天最常用的,但除了Adam以外,还有各式各样的变形,但其实各式各样的变形都不脱,就是要嘛不同的方法算M,要嘛不同的方法算σ,要嘛不同的,Learning
Rate Scheduling的方式。</p></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>训练技巧</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>学习率</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习（7）Seq2Seq</title>
    <url>/posts/32X3GH2/</url>
    <content><![CDATA[<h2><span id="一-seq2seq">一、Seq2Seq</span></h2>
<blockquote>
<p>CS224n笔记[7]:整理了12小时，只为让你20分钟搞懂Seq2seq - 蝈蝈的文章 -
知乎 https://zhuanlan.zhihu.com/p/147310766</p>
<p>目录：</p>
<ul>
<li><p>机器翻译</p></li>
<li><ul>
<li>传统机器翻译，SMT</li>
<li>神经机器翻译，NMT</li>
</ul></li>
<li><p>Seq2seq</p></li>
<li><ul>
<li>Seq2seq结构详解</li>
<li>为什么训练和预测时的Decoder不一样？</li>
<li>Seq2seq的损失函数</li>
<li>Decoding和Beam Search</li>
</ul></li>
<li><p>总结</p></li>
<li><ul>
<li>NMT的优缺点</li>
<li>机器翻译的评价指标</li>
</ul></li>
</ul>
</blockquote>
<h3><span id="11-seq2seq结构详解">1.1 <strong>seq2seq结构详解</strong></span></h3>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182130235.png" alt="CS224n笔记[7]:整理了12小时，只为让你20分钟搞懂Seq2seq">
<figcaption aria-hidden="true">CS224n笔记[7]:整理了12小时，只为让你20分钟搞懂Seq2seq</figcaption>
</figure>
<p>这张图，展示了在<strong>「训练时」</strong>，seq2seq内部的详细结构。</p>
<p>在Encoder端，我们将source文本的词序列先经过embedding层转化成向量，然后输入到一个RNN结构（可以是普通RNN，LSTM，GRU等等）中。另外，这里的RNN也可以是多层、双向的。经过了RNN的一系列计算，最终隐层的输入，就作为源文本整体的一个表示向量，称为<strong>「context
vector」</strong>。</p>
<p>Decoder端的操作就稍微复杂一些了。首先，Decoder的输入是什么呢？Decoder的输入，训练和测试时是不一样的！
<strong>「在训练时，我们使用真实的目标文本，即“标准答案”作为输入」</strong>（注意第一步使用一个特殊的<code>&lt;start&gt;</code>字符，表示句子的开头）。每一步根据当前正确的输出词、上一步的隐状态来预测下一步的输出词。</p>
<p>下图则展示了在<strong>「预测时」</strong>，seq2seq的内部结构：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182130580.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>预测时，Encoder端没什么变化，在Decoder端，由于此时没有所谓的“真实输出”或“标准答案”了，所以只能<strong>「自产自销：每一步的预测结果，都送给下一步作为输入」</strong>，直至输出<code>&lt;end&gt;</code>就结束。如果你对我之前写的笔记很熟悉的话，会发现，<strong>「这时的Decoder就是一个语言模型」</strong>。由于这个语言模型是根据context
vector来进行文本的生成的，因此这种类型的语言模型，被称为“条件语言模型”：Conditional
LM。正因为如此，在训练过程中，我们可以使用一些预训练好的语言模型来对Decoder的参数进行初始化，从而加快迭代过程。</p>
<h3><span id="12为什么训练和预测时的decoder不一样"><strong>1.2
为什么训练和预测时的Decoder不一样？</strong></span></h3>
<p>很多人可能跟我一样，对此感到疑惑：为什么在训练的时候，不能直接使用这种语言模型的模式，使用上一步的预测来作为下一步的输入呢？</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182130314.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>我们称这两种模式，根据标准答案来decode的方式为<strong>「teacher
forcing」</strong>，而根据上一步的输出作为下一步输入的decode方式为<strong>「free
running」</strong>。</p>
<p>其实，free
running的模式真的不能在训练时使用吗？——当然是可以的！从理论上没有任何的问题，又不是不能跑。但是，在实践中人们发现，这样训练太南了。因为没有任何的引导，一开始会完全是瞎预测，正所谓“一步错，步步错”，而且越错越离谱，这样会导致训练时的累积损失太大（<strong>「误差爆炸」</strong>问题，exposure
bias），训练起来就很费劲。这个时候，如果我们能够在每一步的预测时，让老师来指导一下，即提示一下上一个词的正确答案，decoder就可以快速步入正轨，训练过程也可以更快收敛。因此大家把这种方法称为teacher
forcing。所以，这种操作的目的就是为了使得训练过程更容易。</p>
<p><strong>所以，更好的办法，更常用的办法，是老师只给适量的引导，学生也积极学习</strong>。即我们设置一个概率p，每一步，以概率p靠自己上一步的输入来预测，以概率1-p根据老师的提示来预测，这种方法称为<strong>「计划采样」</strong>（scheduled
sampling）：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182130613.jpg" alt="img" style="zoom: 67%;"></p>
<p>另外有一个小细节：在seq2seq的训练过程中，decoder即使遇到了<code>&lt;end&gt;</code>标识也不会结束，因为训练的时候并不是一个生成的过程
，我们需要等到“标准答案”都输入完才结束。</p>
<h3><span id="13-seq2seq的损失函数">1.3 <strong>Seq2Seq的损失函数</strong></span></h3>
<p>在上面的图中，我们看到<strong>decoder的每一步产生隐状态后，会通过一个projection层映射到对应的词</strong>。那怎么去计算每一步的损失呢？实际上，<strong>这个projection层，通常是一个softmax神经网络层，假设词汇量是V，则会输出一个V维度的向量，每一维代表是某个词的概率</strong>。映射的过程就是把最大概率的那个词找出来作为预测出的词。</p>
<p>在计算损失的时候，我们使用交叉熵作为损失函数，所以我们要找出这个V维向量中，正确预测对应的词的那一维的概率大小<img src="https://www.zhihu.com/equation?tex=%5Chat%7Bp%7D" alt="[公式]">，则这一步的损失就是它的负导数<img src="https://www.zhihu.com/equation?tex=-log%28%5Chat%7Bp%7D%29" alt="[公式]">，将每一步的损失求和，即得到总体的损失函数：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D+J%26%3D-log%28p%28%5Chat%7By_1%7D%29%29-log%28p%28%5Chat%7By_2%7D%29%29-...-log%28p%28%5Chat%7By_n%7D%29%29-log%28p%28%5BEOS%5D%29%29+%5Cnonumber+%5C%5C+%26%3D+-%5Cfrac%7B1%7D%7BT%7D%5Csum%5E%7BT%7D_%7Bi%7Dlog%28p%28%5Chat%7By_i%7D%29%29+%5Cnonumber+%5Cend%7Balign%7D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中T代表Decoder有多少步，[EOS]代表‘end of sentence’这个特殊标记.</p>
<h3><span id="14-decoding和beamsearch">1.4 <strong>Decoding和Beam
search</strong></span></h3>
<p>前面画的几个图展示的预测过程，其实就是最简单的decoding方式——<strong>「Greedy
Decoding」</strong>，即每一步，都预测出概率最大的那个词，然后输入给下一步。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182130276.jpg" alt="img" style="zoom:67%;"></p>
<p>这种Greedy的方式，简单快速，但是既然叫“贪心”，肯定会有问题，那就是<strong>「每一步最优，不一定全局最优」</strong>，这种方式很可能“捡了芝麻，丢了西瓜”。</p>
<p>改进的方法，就是使用<strong>「Beam
Search」</strong>方法：每一步，多选几个作为候选，最后综合考虑，选出最优的组合。</p>
<p>下面我们来具体看看Beam Search的操作步骤：</p>
<ul>
<li>首先，我们需要设定一个候选集的大小beam size=k；</li>
<li>每一步的开始，我们从每个当前输入对应的所有可能输出，计算每一条路的“序列得分”；</li>
<li>保留“序列得分”最大的k个作为下一步的输入；</li>
<li>不断重复上述过程，直至结束，选择“序列得分”最大的那个序列作为最终结果。</li>
</ul>
<p>这里的重点就在于这个“序列得分”的计算。</p>
<p>我们使用如下的score函数来定义<strong>「序列得分」</strong>：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=score%28y_1%2C...%2Cy_t%29%3D%5Csum%5E%7Bt%7D_%7Bi%3D1%7DlogP%28y_i%7Cy_1%2Cy_2%2C...%2Cy_%7Bi-1%7D%2Cx%29+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>这个score代表了当前到第t步的输出序列的一个综合得分，越高越好。其中<img src="https://www.zhihu.com/equation?tex=logP%28y_i%7Cy_1%2Cy_2%2C...%2Cy_%7Bi-1%7D%2Cx%29" alt="[公式]">类似于前面我们写的第t步的交叉熵损失的负数。所以这个score越到，就意味着到当前这一步为止，输出序列的累积损失越小。</p>
<p>再多描述不如一张图直观，我用下图描绘一个极简的案例（只有3个词的语料，k=2）：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182131550.jpg" alt="img" style="zoom: 67%;"></p>
<p>最后还有一个问题：由于会有多个分支，所以很有可能我们会遇到多个<code>&lt;end&gt;</code>标识，由于分支较多，如果等每一个分支都遇到<code>&lt;end&gt;</code>才停的话，可能耗时太久，因此一般我们会设定一些规则，比如已经走了T步，或者已经积累了N条已完成的句子，就终止beam
search过程。</p>
<p>在search结束之后，我们需要对已完成的N个序列做一个抉择，挑选出最好的那个，那不就是通过前面定义的score函数来比较吗？确实可以，但是如果直接使用score来挑选的话，会导致那些很短的句子更容易被选出。<strong>因为score函数的每一项都是负的，序列越长，score往往就越小。因此我们可以使用长度来对score函数进行细微的调整：对每个序列的得分，除以序列的长度。根据调整后的结果来选择best
one。</strong></p>
<p>Beam Search的使用，往往可以得到比Greedy
Search更好的结果，道理很容易理解，高手下棋想三步，深思熟虑才能走得远。</p>
<h3><span id="15-nmt的优缺点">1.5 <strong>NMT的优缺点</strong></span></h3>
<p>NMT相比于SMT，最大的优点当然就如前面所说的——简洁。我们<strong>不需要什么人工的特征工程，不需要各种复杂的前后组件，就是一个端到端的神经网络，整个结构一起进行优化</strong>。</p>
<p>另外，由于使用了深度学习的方法，我们可以引入很多语义特征，比如利用文本的相似度，利用文本内隐含的多层次特征，这些都是统计学方法没有的。</p>
<p>但是，没有什么东西是绝对好或绝对差的，NMT也有其不足。它的不足也是跟深度学习的黑箱本质息息相关。<strong>NMT的解释性差，难以调试，难以控制，我们谁也不敢保证遇到一个新的文本它会翻译出什么奇怪的玩意儿，所以NMT在重要场合使用是有明显风险的。</strong></p>
<h3><span id="16-nmt的评价">1.6 <strong>NMT的评价</strong></span></h3>
<p>机器翻译的效果如何评价呢？——<strong>「BLEU」</strong>指标。<strong>BLEU，全称是Bilingual
Evaluation
Understudy，它的主要思想是基于N-gram等特征来比较人工翻译和机器翻译结果的相似程度。</strong></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>Seq2Seq</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习（8）Attention</title>
    <url>/posts/QAPBHZ/</url>
    <content><![CDATA[<h1><span id="attention-注意力机制">Attention-注意力机制</span></h1>
<blockquote>
<p><a href="https://paddlepedia.readthedocs.io/en/latest/tutorials/deep_learning/model_tuning/attention/attention_description.html">注意力机制</a></p>
<p>如何理解attention中的Q,K,V？ - 林亿的回答 - 知乎
https://www.zhihu.com/question/298810062/answer/2274132657</p>
<p>Self-attention中dot-product操作为什么要被缩放：https://www.zhihu.com/question/339723385/answer/782509914</p>
</blockquote>
<h3><span id="一-注意力机制是什么">一、注意力机制是什么</span></h3>
<p>假设有一天热爱绘画的你决定去户外写生，你来到一片山坡上，极目远去，心旷神怡。头顶一片蔚蓝，脚踩一席草绿，远处山川连绵，眼前花草送香，暖阳含羞云后，轻风拂动衣襟，鸟啼虫鸣入耳，美景丹青共卷。</p>
<p>你集中精神，拿起画笔将蓝天、白云、青草等等这些元素，按照所思所想纷纷绘入画板。在绘画的过程中，你会持续地关注你构思到画板上的元素（比如蓝天，白云），而不会太多关注那些其他的元素，比如风，虫鸣，阳光等等。即你的精神是聚焦在你关心的那些事物上，这其实就是注意力的体现，这种有意识的聚焦被称为<strong>聚焦式注意力（Focus
Attention</strong>）。</p>
<p>在深度学习领域，模型往往需要接收和处理大量的数据，然而在特定的某个时刻，往往只有少部分的某些数据是重要的，这种情况就非常适合<strong>Attention机制</strong>发光发热。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220529190526010.png" alt="image-20220529190526010" style="zoom:50%;"></p>
<p>举个例子，<strong>上图</strong>展示了一个机器翻译的结果，在这个例子中，我们想将”who
are
you”翻译为”你是谁”，传统的模型处理方式是一个seq-to-seq的模型，其包含一个encoder端和一个decoder端，其中encoder端对”who
are
you”进行编码，然后将整句话的信息传递给decoder端，由decoder解码出”我是谁”。在这个过程中，decoder是逐字解码的，在每次解码的过程中，如果接收信息过多，可能会导致模型的内部混乱，从而导致错误结果的出现。</p>
<p>我们可以使用<strong>Attention机制</strong>来解决这个问题，从<strong>图中</strong>可以看到，在生成”你”的时候和单词”you”关系比较大，和”who
are”关系不大，所以我们更希望在这个过程中能够使用<strong>Attention机制</strong>，将更多注意力放到”you”上，而不要太多关注”who
are”，从而提高整体模型的表现。</p>
<blockquote>
<p>备注：在深度学习领域，无意识的<strong>显著性注意力</strong>更加常见。</p>
</blockquote>
<p>Attention机制自提出以来，出现了很多不同Attention应用方式，但大道是共同的，均是将模型的注意力聚焦在重要的事情上。本文后续将选择一些经典或常用的Attention机制展开讨论。</p>
<h3><span id="二-经典注意力机制">二、经典注意力机制</span></h3>
<h4><span id="21用机器翻译任务带你看attention机制的计算">2.1
用机器翻译任务带你看Attention机制的计算</span></h4>
<p>单独地去讲<strong>Attention机制</strong>会有些抽象，也有些枯燥，所以我们不妨以<strong>机器翻译</strong>任务为例，通过讲解<strong>Attention机制</strong>在机器翻译任务中的应用方式，来了解<strong>Attention机制</strong>的使用。</p>
<p>什么是机器翻译任务？以<strong>中译英</strong>为例，机器翻译是将一串中文语句翻译为对应的英文语句，如<strong>图1</strong>所示。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220529201640683.png" alt="image-20220529201640683" style="zoom:50%;"></p>
<p>图1展示了一种经典的机器翻译结构Seq-to-Seq,
并且向其中添加了Attention计算。<strong>Seq-to-Seq结
构包含两个部分：Encoder和Decoder</strong>。其中Encoder用于将中文语句进行编码,
这些编码后续将提 供给Decoder进行使用;
Decoder将根据Encoder的数据进行解码。我们还是以图1为例详细解释一
下Decoder的解码过程。 更明确的讲,
图1展示的是生成单词"machine"时的计算方式。首先将前一个时刻的输出状态
<span class="math inline">\(q_{2}\)</span> 和 Encoder的输出 <span class="math inline">\(h=\left[h_{1}, h_{2}, h_{3}, h_{4}\right]\)</span>
进行Attention计算, 得到一个当前时刻的 context, 用公式可 以这样组织:
<span class="math display">\[
\begin{aligned}
{\left[a_{1}, a_{2}, a_{3}, a_{4}\right] }
&amp;=\operatorname{softmax}\left(\left[s\left(q_{2}, h_{1}\right),
s\left(q_{2}, h_{2}\right), s\left(q_{2}, h_{3}\right), s\left(q_{2},
h_{4}\right)\right]\right) \\
\text { context } &amp;=\sum_{i=1}^{4} a_{i} \cdot h_{i}
\end{aligned}
\]</span> 我们来解释一下, 这里的 <span class="math inline">\(s\left(q_{i}, h_{j}\right)\)</span>
表示注意力打分函数, 它是个标量, 其大小描述了当前时刻在这
些Encoder的结果上的关注程度,
这个函数在后边会展开讨论。然后用softmax对这个结果进行归一 化,
最后使用加权评价获得当前时刻的上下文向量 context。这个context
可以解释为：截止到当前 已经有了"I love",
在此基础上下一个时刻应该更加关注源中文语句的那些内容。这就是关于
Attention机制的一个完整计算。</p>
<p><strong>最后,
将这个context和上个时刻的输出”love"进行融合作为当前时刻RNN单元的输入</strong>。图1中采用了继续融合上一步的输出结果,
例如上述描述中融合了"love", 在有些实现中, 并没 有融入这个上一步的输出,
默认 <span class="math inline">\(q_{2}\)</span>
中已经携带了"love"的信息, 这也是合理的。</p>
<h4><span id="22-注意力机制的正式引入">2.2 注意力机制的正式引入</span></h4>
<p>前边我们通过机器翻译任务介绍了<strong>Attention机制</strong>的整体计算。但是还有点<strong>小尾巴</strong>没有展开，就是那个<strong>注意力打分函数</strong>的计算，现在我们将来讨论这个事情。但在讲这个函数之前，我们先来对上边的<strong>Attention机制</strong>的计算做个总结，<strong>图2</strong>详细地描述了Attention机制的计算原理。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220529202937945.png" alt="image-20220529202937945" style="zoom:50%;"></p>
<p>假设现在我们要对一组输入 <span class="math inline">\(H=\left[h_{1},
h_{2}, h_{3}, \ldots, h_{n}\right]\)</span>
使用<strong>Attention机制</strong>计算重要的内容, 这里往
往需要一个<strong>查询向量</strong> <span class="math inline">\(q\)</span> (这个向量往往和你做的任务有关,
比如机器翻译中用到的那个 <span class="math inline">\(q_{2}\)</span> ),
然后通 过一个<strong>打分函数</strong>计算查询向量 <span class="math inline">\(q\)</span> 和每个输入 <span class="math inline">\(h_{i}\)</span> 之间的相关性,
得出一个分数。<strong>接下来使用softmax 对这些分数进行归一化,
归一化后的结果便是查询向量 <span class="math inline">\(q\)</span>
在各个输入 <span class="math inline">\(h_{i}\)</span>
上的注意力分布</strong><span class="math inline">\(a=\left[a_{1}, a_{2},
a_{3}, \ldots, a_{n}\right]\)</span>, 其中每一项数值和原始的输入<span class="math inline">\(H=\left[h_{1}, h_{2}, h_{3}, \ldots,
h_{n}\right]\)</span> 一一对应。以 <span class="math inline">\(a_{i}\)</span> 为例, 相关计算公式如下: <span class="math display">\[
a_{i}=\operatorname{softmax}\left(s\left(h_{i},
q\right)\right)=\frac{\exp \left(s\left(h_{i},
q\right)\right)}{\sum_{j=1}^{n} \exp \left(s\left(h_{j},
q\right)\right)}
\]</span> 最后根据这些注意力分布可以去有选择性的从输入信息 <span class="math inline">\(H\)</span> 中提取信息, 这里比较常用的信息提取方式,
是一种”软性”的信息提取（图2展示的就是一种"软性"注意力）,
即根据注意力分布对输入信 息进行加权求和，最终的这个结果 context
体现了模型当前应该关注的内容： <span class="math display">\[
\text { context }=\sum_{i=1}^{n} a_{i} \cdot h_{i}
\]</span> 现在我们来解决之前一直没有展开的小尾巴-打分函数,
它可以使用以下几种方式来计算: - <strong>加性模型</strong>: <span class="math inline">\(s(h, q)=v^{T} \tanh (W h+U q)\)</span> -
<strong>点积模型</strong>: <span class="math inline">\(s(h, q)=h^{T}
q\)</span> - <strong><font color="red"> 缩放点积模型</font></strong>:
<span class="math inline">\(s(h, q)=\frac{h^{T} q}{\sqrt{D}}\)</span> -
<strong>双线性模型</strong>: <span class="math inline">\(s(h, q)=h^{T} W
q\)</span></p>
<p>以上公式中的参数 <span class="math inline">\(W 、 U\)</span> 和 <span class="math inline">\(v\)</span> 均是可学习的参数矩阵或向量, <span class="math inline">\(D\)</span> 为输入向量的维度。下边我们来分
析一下这些分数计算方式的差别。</p>
<p><strong>加性模型</strong>引入了可学习的参数, 将查询向量 <span class="math inline">\(q\)</span> 和原始输入向量 <span class="math inline">\(h\)</span> 映射到不同的向量空间后进行计算打分,
显然相较于加性模型, <strong>点积模型</strong>具有更好的计算效率。</p>
<p>另外, 当输入向量的维度比较高的时候,
<strong>点积模型</strong>通常有比较大的方差, 从而导致Softmax函数的
梯度会比较小。因此<strong>缩放点积模型</strong>通过除以一个<strong>平方根项</strong>来平滑分数数值,
也相当于平滑最终的<strong>注意力分布</strong>, 缓解这个问题。</p>
<p>最后, <strong>双线性模型</strong>可以重塑为 <span class="math inline">\(s\left(h_{i}, q\right)=h^{T} W q=h^{T}\left(U^{T}
V\right) q=(U h)^{T}(V q)\)</span>, 即分别对查询向量 <span class="math inline">\(q\)</span> 和原始输入向量 <span class="math inline">\(h\)</span> 进行线性变换之后,
再计算点积。<strong>相比点积模型, 双线性模型在计算相似度时
引入了非对称性</strong>。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>Seq2Seq</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习（8）Self Attention*-p1</title>
    <url>/posts/VR9NEX/</url>
    <content><![CDATA[<h2><span id="一-李宏毅-selfattention自注意力机制-p1"><font color="red"> 一、李宏毅-Self
Attention自注意力机制 - p1</font></span></h2>
<blockquote>
<p>相关性查询（q, k）-softmax - 乘上v</p>
<p>视频链接：https://www.bilibili.com/video/BV1JK4y1D7Wb?p=26&amp;vd_source=29387dc08d18f642078183a6816e93e8</p>
</blockquote>
<blockquote>
<p>跟自己计算关联性重要吗？</p>
<p>为什么用softmax？relu也行</p>
</blockquote>
<p>到目前为止,我们的Network的<strong>Input</strong>都是<strong>一个向量</strong>,不管是在预测这个,YouTube观看人数的问题上啊,还是影像处理上啊,我们的输入都可以看作是一个向量,然后我们的输出,可能是一个<strong>数值</strong>,这个是<strong>Regression</strong>,可能是一个<strong>类别</strong>,这是<strong>Classification</strong></p>
<h3><span id="11-what-is-the-output">1.1 What is the output?</span></h3>
<p>我们刚才已经看说输入是一堆向量,它可以是文字,可以是语音,可以是Graph,那这个时候,我们有可能有什么样的<strong>输出呢,</strong>有三种可能性。</p>
<h4><span id="111每一个向量都有一个对应的label">1.1.1
每一个向量都有一个对应的Label</span></h4>
<p>当你的模型,看到输入是四个向量的时候,它就要输出四个Label,而每一个Label,它可能是一个数值,那就是Regression的问题,如果每个Label是一个Class,那就是一个Classification的问题。</p>
<p><img src="image-20220612171420908.png" alt="image-20220612171420908" style="zoom: 33%;"></p>
<p>举例来说 在文字处理上,假设你今天要做的是==<strong>POS
Tagging</strong>==,POS Tagging就是词性标註,你要让机器自动决定每一个词汇
它是什么样的词性,它是名词 还是动词 还是形容词等等。</p>
<p>这个任务啊,其实并没有很容易,举例来说,你现在看到一个句子,I saw a
saw。这并不是打错,并不是“我看一个看”,而是“我看到一个锯子”,这个第二个saw当名词用的时候,它是锯子，那所以机器要知道,第一个saw是个动词,第二个saw虽然它也是个saw,但它是名词,但是每一个输入的词汇,都要有一个对应的输出的词性。</p>
<h4><span id="112一整个sequence只需要输出一个label">1.1.2
一整个Sequence,只需要输出一个Label</span></h4>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220612171433616.png" alt="image-20220612171433616" style="zoom:50%;"></p>
<p>举例来说,如果是文字的话,我们就说<strong>Sentiment
Analysis</strong>。Sentiment
Analysis就是给机器看一段话,它要<strong>决定说这段话是正面的还是负面的</strong>。</p>
<p>那你可以想像说这种应用很有用,假设你的公司开发了一个产品,这个产品上线了,你想要知道网友的评价怎么样,但是你又不可能一则一则网友的留言都去分析,那也许你就可以用这种,Sentiment
Analysis的技术,让机器自动去判读说,当一则贴文里面有提到某个产品的时候,它是正面的
还是负面的,那你就可以知道你的产品,在网友心中的评价怎么样,这个是Sentiment
Analysis给一整个句子,只需要一个Label,那Positive或Negative,那这个就是第二类的输出。</p>
<p>那如果是语音的例子的话呢,在作业四里面我们会做语者辨认,机器要听一段声音,然后决定他是谁讲的。或者是如果是Graph的话呢,今天你可能想要给一个分子,然后要预测说这个分子,比如说它有没有毒性,或者是它的亲水性如何,那这就是给一个Graph
输出一个Label。</p>
<h4><span id="113机器要自己决定应该要输出多少个label">1.1.3
机器要自己决定,应该要输出多少个Label</span></h4>
<p>我们不知道应该输出多少个Label,机器要自己决定,应该要输出多少个Label,可能你输入是N个向量,输出可能是N'个Label,为什么是N',机器自己决定。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220612171446043.png" alt="image-20220612171446043" style="zoom:50%;"></p>
<p>这种任务又叫做==sequence to
sequence==的任务,那我们在作业五会有sequence to
sequence的作业,所以这个之后我们还会再讲</p>
<ul>
<li>翻译就是sequence to
sequence的任务,因为输入输出是不同的语言,它们的词汇的数目本来就不会一样多</li>
<li>或者是语音辨识也是,真正的语音辨识也是一个sequence to
sequence的任务,输入一句话,然后输出一段文字,这也是一个sequence to
sequence的任务</li>
</ul>
<p>第二种类型有作业四,感兴趣可以去看看作业四的程式，那因为上课时间有限,所以上课,我们今天就先只讲第一个类型,也就是输入跟输出数目一样多的状况。</p>
<h3><span id="12-sequence-labeling">1.2 Sequence Labeling</span></h3>
<p>那这种输入跟输出数目一样多的状况又叫做<strong>Sequence
Labeling</strong>,你要给Sequence里面的每一个向量,都给它一个Label,那要怎么解Sequence
Labeling的问题呢？那直觉的想法就是我们就拿个<strong>Fully-Connected的Network</strong>。</p>
<p>然后虽然这个输入是一个Sequence,但我们就各个击破,不要管它是不是一个Sequence,把每一个向量,分别输入到Fully-Connected的Network里面，然后Fully-Connected的Network就会给我们输出,那现在看看,你要做的是Regression还是Classification,产生正确的对应的输出,就结束了,</p>
<p><font color="red">
那这么做显然有<strong>非常大的瑕疵</strong>,假设今天是,词性标记的问题,你给机器一个句子,I
saw a saw,对Fully-Connected
Network来说,<strong>后面这一个saw跟前面这个saw完全一模一样</strong>,它们是同一个词汇啊。</font></p>
<h4><span id="方案一window">方案一：Window</span></h4>
<p>既然Fully-Connected的Network<strong>输入同一个词汇,它没有理由输出不同的东西</strong>。但实际上,你期待第一个saw要输出动词,第二个saw要输出名词,但对Network来说它不可能做到,因为这两个saw
明明是一模一样的,你叫它一个要输出动词,一个要输出名词,它会非常地困惑,完全不知道要怎么处理。所以怎么办,有没有可能<strong>让Fully-Connected的Network,考虑更多的,比如说上下文的Context的资讯</strong>呢。这是有可能的,你就<strong>把前后几个向量都串起来,一起丢到Fully-Connected的Network就结束了</strong>。</p>
<p>所以我们可以给Fully-Connected的Network,一整个Window的资讯,让它可以考虑一些上下文的,跟我现在要考虑的这个向量,相邻的其他向量的资讯。把Window开大一点啊,大到可以把整个Sequence盖住就结束了。</p>
<p>如果你今天说我真的要开一个Window,把整个Sequence盖住,那你可能要<strong>统计一下你的训练资料</strong>,然后看看你的训练资料里面,最长的Sequence有多长,然后开一个Window比最长的Sequence还要长,你才有可能把整个Sequence盖住但是你开一个这么大的Window,意味著说你的Fully-Connected的Network,它需要非常多的参数,那可能不只<strong>运算量很大,可能还容易Overfitting</strong>。</p>
<h4><span id="方案二self-attention">方案二：self-attention</span></h4>
<p>Self-Attention的运作方式就是,<strong>Self-Attention会吃一整个Sequence的资讯</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613211233215.png" alt="image-20220613211233215" style="zoom:50%;"></p>
<p>然后你Input几个Vector,它就输出几个Vector,比如说你这边Input一个深蓝色的Vector,这边就给你一个另外一个Vector。这边给个浅蓝色,它就给你另外一个Vector,这边输入4个Vector,它就Output
4个Vector。那这4个Vector有什么特别的地方呢,<strong>这4个Vector,他们都是考虑一整个Sequence以后才得到的</strong>,那等一下我会讲说Self-Attention,怎么考虑一整个Sequence的资讯。</p>
<p><strong><font color="red">
如此一来你这个Fully-Connected的Network,它就不是只考虑一个非常小的范围,或一个小的Window,而是考虑整个Sequence的资讯,再来决定现在应该要输出什么样的结果，这个就是Self-Attention</font></strong>。<strong>Self-Attention不是只能用一次,你可以叠加很多次</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613211415203.png" alt="image-20220613211415203" style="zoom:50%;"></p>
<p>可以Self-Attention的输出,通过Fully-Connected
Network以后,再做一次Self-Attention,Fully-Connected的Network,再过一次Self-Attention,再重新考虑一次整个Input
Sequence的资讯,再丢到另外一个Fully-Connected的Network,最后再得到最终的结果。</p>
<p>所以<strong>可以把Fully-Connected的Network,跟Self-Attention交替使用</strong></p>
<ul>
<li>Self-Attention处理整个Sequence的资讯</li>
<li>Fully-Connected的Network,专注于处理某一个位置的资讯</li>
<li>再用Self-Attention,再把整个Sequence资讯再处理一次</li>
<li>然后交替使用Self-Attention跟Fully-Connected</li>
</ul>
<p>有关Self-Attention,最知名的相关的文章,就是《Attention is all you
need》.那在这篇Paper里面呢,Google提出了==Transformer==这样的Network架构,那Transformer就是变形金刚,所以提到这个Network的时候呢,我们就会有变形金刚这个形象。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613211500443.png" alt="image-20220613211500443" style="zoom:50%;"></p>
<p>Transformer我们今天还不会讲到,但我们之后会讲到,Transformer里面一个最重要的Module就是Self-Attention,它就是变形金刚的火种源。那这篇Paper最厉害的地方,就是它有一个<strong>霸气的名字Attention
is all you need.</strong></p>
<p>那其实像Self-Attention这样的架构,最早我并不会说它是出现在《Attention
is all you
need》这样的Paper,因为其实很多更早的Paper,就有提出过类似的架构,只是不见得叫做Self-Attention,比如说叫做Self-Matching,或者是叫别的名字,不过呢是Attention
is all you need.这篇Paper,把Self-Attention这个Module,把它发扬光大。</p>
<h3><span id="13-self-attention过程">1.3 Self-Attention过程</span></h3>
<p><strong><font color="red">
Self-Attention的Input,它就是一串的Vector,那这个Vector可能是你整个Network的Input,它也可能是某个Hidden
Layer的Output,所以我们这边不是用<span class="math inline">\(x\)</span>来表示它，用<span class="math inline">\(a\)</span>来表示它。</font></strong></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613211620957.png" alt="image-20220613211620957" style="zoom:50%;"></p>
<p>我们用<span class="math inline">\(a\)</span>来表示它，代表它有可能是前面已经做过一些处理,它是某个Hidden
Layer的Output,那Input一排a这个向量以后,Self-Attention要Output另外一排b这个向量。那这<strong>每一个b都是考虑了所有的a以后才生成出来的</strong>,所以这边刻意画了非常非常多的箭头,告诉你$b^1
<span class="math inline">\(考虑了\)</span>a<sup>1<span class="math inline">\(到\)</span>a</sup>4<span class="math inline">\(产生的,\)</span>b<sup>2<span class="math inline">\(考虑\)</span>a</sup>1<span class="math inline">\(到\)</span>a<sup>4<span class="math inline">\(产生的,\)</span>b</sup>3
b^4$也是一样,考虑整个input的sequence,才产生出来的。</p>
<p>那接下来呢就是要跟大家说明,<strong>怎么产生<span class="math inline">\(b^1\)</span>这个向量</strong>,那你知道怎么产生<span class="math inline">\(b^1\)</span>这个向量以后,你就知道怎么产生剩下<span class="math inline">\(b^1 b^2 b^3 b^4\)</span>剩下的向量。</p>
<p><font color="red">
这里有一个<strong>特别的机制</strong>,<strong>这个机制是根据<span class="math inline">\(a^1\)</span>这个向量,找出整个很长的sequence里面,到底哪些部分是重要的,哪些部分跟判断<span class="math inline">\(a^1\)</span>是哪一个label是有关系的,哪些部分是我们要决定<span class="math inline">\(a^1\)</span>的class,决定<span class="math inline">\(a^1\)</span>的regression数值的时候,所需要用到的资讯</strong>。</font></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613212112611.png" alt="image-20220613212112611" style="zoom:50%;"></p>
<p><strong>每一个向量跟<span class="math inline">\(a^1\)</span>的关联的程度,用一个数值叫α来表示</strong>，这个self-attention的module,<strong>怎么自动决定两个向量之间的关联性</strong>呢,你给它两个向量<span class="math inline">\(a^1\)</span>跟<span class="math inline">\(a^4\)</span>,它怎么决定<span class="math inline">\(a^1\)</span>跟<span class="math inline">\(a^4\)</span>有多相关,然后给它一个数值α呢,那这边呢你就需要一个<strong>计算attention的模组</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613212206065.png" alt="image-20220613212206065" style="zoom:50%;"></p>
<p>这个计算attention的模组,就是拿<strong>两个向量作为输入</strong>,然后它就直接输出α那个数值,计算这个α的数值有各种不同的做法：</p>
<ul>
<li><p>==dot
product==：<strong>输入的这两个向量分别乘上两个不同的矩阵</strong>,左边这个向量乘上<span class="math inline">\(W^q\)</span>这个矩阵得到矩阵<span class="math inline">\(q\)</span>,右边这个向量乘上<span class="math inline">\(W^k\)</span>这个矩阵得到矩阵<span class="math inline">\(k\)</span></p>
<p>再把<span class="math inline">\(q\)</span>跟<span class="math inline">\(k\)</span>做dot product,就是把他们做element-wise
的相乘,再全部加起来以后就得到一个
scalar,这个scalar就是α,这是一种计算α的方式</p></li>
<li><p>==Additive==：把同样这两个向量通过<span class="math inline">\(W^q\)</span> <span class="math inline">\(W^k\)</span>,得到<span class="math inline">\(q\)</span>跟<span class="math inline">\(k\)</span>,那我们不是把它做Dot-Product,是把它这个串起来,然后丢到这个过一个Activation
Function，然后再通过一个Transform,然后得到α。</p></li>
</ul>
<p>总之有非常多不同的方法,可以计算Attention,可以计算这个α的数值,可以计算这个关联的程度，但是在接下来的讨论里面,我们都<strong>只用左边这个方法</strong>,这也是今日最常用的方法,也<strong>是用在Transformer里面的方法</strong>。那你就要把这边的<span class="math inline">\(a^1\)</span>去跟这边的<span class="math inline">\(a^2 a^3
a^4\)</span>,分别都去计算他们之间的关联性,也就是计算他们之间的α。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613212357947.png" alt="image-20220613212357947" style="zoom:50%;"></p>
<p>你把<span class="math inline">\(a^1\)</span>乘上$W^q <span class="math inline">\(得到\)</span>q^1$,那这个q有一个名字,我们叫做==Query==,它就像是你搜寻引擎的时候,去搜寻相关文章的问题,就像搜寻相关文章的关键字,所以这边叫做Query。</p>
<p>然后接下来呢,<span class="math inline">\(a^2 a^3
a^4\)</span>你都要去把它乘上<span class="math inline">\(W^k\)</span>,得到<span class="math inline">\(k\)</span>这个Vector,<span class="math inline">\(k\)</span>这个Vector叫做==Key==,那你把这个<font color="red">
<strong>Query q1,跟这个Key k2,算 Inner-Product就得到 α‘
（注意力矩阵）</strong>。</font>我们这边用<span class="math inline">\(α_{1,2}\)</span>来代表说,Query是1提供的,Key是2提供的时候,这个1跟2他们之间的关联性,这个α这个关联性叫做==Attention的Score==,叫做Attention的分数。</p>
<p>接下来也要跟<span class="math inline">\(a^3
a^4\)</span>来计算，把<span class="math inline">\(a_3\)</span>乘上<span class="math inline">\(W^k\)</span>,得到另外一个Key也就是<span class="math inline">\(k^3\)</span>,<span class="math inline">\(a^4\)</span>乘上<span class="math inline">\(W^k\)</span>得到<span class="math inline">\(k^4\)</span>,然后你再把<span class="math inline">\(k^3\)</span>这个Key,跟<span class="math inline">\(q^1\)</span>这个Query做Inner-Product,得到1跟3之间的关联性,得到1跟3的Attention,你把<span class="math inline">\(k^4\)</span>跟<span class="math inline">\(q^1\)</span>做Dot-Product,得到<span class="math inline">\(α_{1,4}\)</span>,得到1跟4之间的关联性。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613212536289.png" alt="image-20220613212536289" style="zoom:50%;"></p>
<p><font color="red"> 其实一般在实作时候,<strong><span class="math inline">\(q^1\)</span>也会跟自己算关联性</strong>,自己跟自己计算关联性这件事情有多重要。</font>计算出,a1跟每一个向量的关联性以后,接下来这边会<strong>接入一个Soft-Max</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613221201944.png" alt="image-20220613221201944" style="zoom:50%;"></p>
<p><strong><font color="red">这个Soft-Max跟分类的时候的那个Soft-Max是一模一样的
</font></strong>,所以Soft-Max的输出就是一排α,所以本来有一排α,通过Soft-Max就得到<span class="math inline">\(α&#39;\)</span>。</p>
<p>这边你<strong>不一定要用Soft-Max,用别的替代也没问题</strong>,比如说有人尝试过说做个ReLU,这边通通做个ReLU,那结果发现还比Soft-Max好一点,所以这边你不一定要用Soft-Max,这边你要用什么Activation
Function都行,你高兴就好,你可以试试看,那Soft-Max是最常见的,那你可以自己试试看,看能不能试出比Soft-Max更好的结果。</p>
<p>接下来得到这个<span class="math inline">\(α&#39;\)</span>以后,我们就要根据这个<span class="math inline">\(α&#39;\)</span>去抽取出这个Sequence里面重要的资讯,根据这个α我们已经知道说,哪些向量跟<span class="math inline">\(a^1\)</span>是最有关系的,<strong>怎么抽取重要的资讯呢？</strong></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613221501080.png" alt="image-20220613221501080" style="zoom:50%;"></p>
<ul>
<li><p>首先把<span class="math inline">\(a^1\)</span>到<span class="math inline">\(a^4\)</span>这边每一个向量,乘上$W^v <span class="math inline">\(得到新的向量,这边分别就是用\)</span>v^1 v^2 v^3
v^4$来表示</p></li>
<li><p>接下来把这边的<span class="math inline">\(v^1\)</span>到<span class="math inline">\(v^4\)</span>,每一个向量都去乘上Attention的分数,都去乘上<span class="math inline">\(α&#39;\)</span></p></li>
<li><p>然后再把它加起来,得到<span class="math inline">\(b^1\)</span></p></li>
</ul>
<p><span class="math display">\[
b^1=\sum_i\alpha&#39;_{1,i}v^i
\]</span></p>
<p>如果某一个向量它得到的分数越高,比如说如果<span class="math inline">\(a^1\)</span>跟<span class="math inline">\(a^2\)</span>的关联性很强,这个<span class="math inline">\(α&#39;\)</span>得到的值很大,那我们今天在做Weighted
Sum以后,得到的<span class="math inline">\(b^1\)</span>的值,就可能会比较接近<span class="math inline">\(v^2\)</span>，所以<strong>谁的那个Attention的分数最大,谁的那个<span class="math inline">\(v\)</span>就会Dominant你抽出来的结果</strong>。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>Seq2Seq</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习（8）Self Attention*-p2</title>
    <url>/posts/2Q8V137/</url>
    <content><![CDATA[<h2><span id="二-李宏毅-selfattention自注意力机制-p2"><font color="red"> 二、李宏毅-Self
Attention自注意力机制 - p2</font></span></h2>
<p><img src="image-20220613221835154.png" alt="image-20220613221835154" style="zoom:50%;"></p>
<p>从这一排 vector 得到 <span class="math inline">\(b^1\)</span>,跟从这一排 vector 得到 <span class="math inline">\(b^2\)</span>,它的操作是一模一样的.要强调一点是,这边的
<span class="math inline">\(b^1\)</span> 到 <span class="math inline">\(b^4\)</span>,它们并<strong>不需要依序产生</strong>,它们是一次同时被计算出来的。</p>
<p>怎么计算这个 <span class="math inline">\(b^2\)</span>？我们现在的主角,就变成 <span class="math inline">\(a^2\)</span></p>
<p><img src="image-20220613221854934.png" alt="image-20220613221854934" style="zoom:50%;"></p>
<ul>
<li><p>把 <span class="math inline">\(a^2\)</span> 乘上一个 matrix,变成
<span class="math inline">\(q^2\)</span></p></li>
<li><p>然后接下来根据 <span class="math inline">\(q^2\)</span>,去对<span class="math inline">\(a^1\)</span>到 <span class="math inline">\(a^4\)</span> 这四个位置,都去计算 attention 的
score</p>
<ul>
<li>把 <span class="math inline">\(q^2\)</span> 跟 <span class="math inline">\(k^1\)</span> 做个这个 dot product</li>
<li>把 <span class="math inline">\(q^2\)</span> 跟 <span class="math inline">\(k^2\)</span> 也做个 dot product</li>
<li>把 <span class="math inline">\(q^2\)</span> 跟 <span class="math inline">\(k^3\)</span> 也做 dot product</li>
<li>把 <span class="math inline">\(q^2\)</span> 跟 <span class="math inline">\(k^4\)</span> 也做 dot product,得到四个分数</li>
</ul></li>
<li><p>得到这四个分数以后,可能还会做一个 <strong>normalization
</strong>和 <strong>softmax</strong>,然后得到最后的 attention 的
score,<span class="math inline">\(α&#39;_{2,1} \space α&#39;_{2,2}
\space α&#39;_{2,3} \space α&#39;_{2,4}\)</span>那我们这边用 <span class="math inline">\(α&#39;\)</span>表示经过 normalization
以后的attention score</p></li>
<li><p>接下来拿这四个数值,分别乘上 <span class="math inline">\(v^1
\space v^2 \space v^3 \space v^4\)</span></p>
<p><img src="image-20220613221952411.png" alt="image-20220613221952411" style="zoom:50%;"></p>
<ul>
<li>把 <span class="math inline">\(α&#39;_{2,1}\)</span>乘上 <span class="math inline">\(v^1\)</span></li>
<li>把 <span class="math inline">\(α&#39;_{2,2}\)</span> 乘上 <span class="math inline">\(v^2\)</span></li>
<li>把 <span class="math inline">\(α&#39;_{2,3}\)</span> 乘上 <span class="math inline">\(v^3\)</span></li>
<li>把 <span class="math inline">\(α&#39;_{2,4}\)</span> 乘上 <span class="math inline">\(v^4\)</span>,然后全部加起来就是 $ b^2$</li>
</ul>
<p><span class="math display">\[
  b^2=\sum_iα&#39;_{2,i}v^i
  \]</span></p></li>
</ul>
<p>同理就可以,由 <span class="math inline">\(a^3\)</span> 乘一个
transform 得到 <span class="math inline">\(q^3\)</span>,然后就计算 <span class="math inline">\(b^3\)</span>,从 <span class="math inline">\(a^4\)</span> 乘一个 transform 得到 <span class="math inline">\(q^4\)</span>,就计算 <span class="math inline">\(b^4\)</span>,以上说的是 Self-attention
它运作的过程。</p>
<h3><span id="22-矩阵的角度">2.2 矩阵的角度</span></h3>
<p>接下来我们从矩阵乘法的角度,再重新讲一次我们刚才讲的,Self-attention
是怎么运作的，我们现在已经知道每一个 a 都产生 q k v。</p>
<p><img src="image-20220613222115187.png" alt="image-20220613222115187" style="zoom:50%;"></p>
<h5><span id="如果要用矩阵运算表示这个操作的话是什么样子呢">如果要用矩阵运算表示这个操作的话,是什么样子呢</span></h5>
<p>我们每一个 a,都乘上一个矩阵,我们这边用 <span class="math inline">\(W^q\)</span> 来表示它,得到 <span class="math inline">\(q^i\)</span>,每一个 a 都要乘上 <span class="math inline">\(W^q\)</span>,得到<span class="math inline">\(q^i\)</span>,<strong>这些不同的 a
你可以把它合起来,当作一个矩阵来看待</strong>。</p>
<p><img src="image-20220613222137478.png" alt="image-20220613222137478" style="zoom:50%;"></p>
<p>一样$a<sup>2a</sup>3a^4 $也都乘上 <span class="math inline">\(W^q\)</span> 得到$q^2 q^3 $跟 <span class="math inline">\(q^4\)</span>,那你可以<strong>把 a1 到 a4
拼起来</strong>,看作是一个矩阵,这个矩阵我们用 I 来表示，这个矩阵的四个
column 就是 <span class="math inline">\(a^1\)</span> 到 <span class="math inline">\(a^4\)</span>。</p>
<p><span class="math inline">\(I\)</span> 乘上 <span class="math inline">\(W^q\)</span> 就得到另外一个矩阵,我们用 <span class="math inline">\(Q\)</span> 来表示它,这个 <span class="math inline">\(Q\)</span> 就是把 <span class="math inline">\(q^1\)</span> 到 <span class="math inline">\(q^4\)</span> 这四个 vector 拼起来,就是 <span class="math inline">\(Q\)</span> 的四个 column。</p>
<p>所以我们从 <span class="math inline">\(a^1\)</span> 到 <span class="math inline">\(a^4\)</span>,得到 <span class="math inline">\(q^1\)</span> 到 <span class="math inline">\(q^4\)</span>这个操作,其实就是<strong>把 I
这个矩阵,乘上另外一个矩阵 <span class="math inline">\(W^q\)</span>，得到矩阵<span class="math inline">\(Q\)</span></strong>。<span class="math inline">\(I\)</span> 这个矩阵它里面的 column就是我们
Self-attention 的 input是 <span class="math inline">\(a^1\)</span> 到
<span class="math inline">\(a^4\)</span>；<strong><span class="math inline">\(W^q\)</span>其实是 network
的参数,它是等一下会被learn出来的</strong> ；<span class="math inline">\(Q\)</span> 的四个 column,就是 <span class="math inline">\(q^1\)</span> 到 <span class="math inline">\(q^4\)</span>。接下来产生 k 跟 v 的操作跟 q
是一模一样的。</p>
<p><img src="image-20220613222206939.png" alt="image-20220613222206939" style="zoom:50%;"></p>
<p>所以每一个 a 得到 q k v ,其实就是把输入的这个,vector sequence
乘上三个不同的矩阵,你就得到了 q,得到了 k,跟得到了 v。下一步是,每一个 q
都会去跟每一个 k,去计算这个 inner product,去<strong>得到这个 attention
的分数</strong>。那得到 attention
分数这一件事情,如果从矩阵操作的角度来看,它在做什么样的事情呢？</p>
<p><img src="image-20220613222251046.png" alt="image-20220613222251046" style="zoom:50%;"></p>
<p>你就是把 <span class="math inline">\(q^1\)</span> 跟 <span class="math inline">\(k^1\)</span> 做 inner product,得到 <span class="math inline">\(α_{1,1}\)</span>,所以 <span class="math inline">\(α_{1,1}\)</span>就是 <span class="math inline">\(q^1\)</span> 跟<span class="math inline">\(k^1\)</span> 的 inner
product,那这边我就把这个,<span class="math inline">\(k^1\)</span>它背后的这个向量,把它画成比较宽一点代表说它是
transpose。同理 <span class="math inline">\(α_{1,2}\)</span> 就是 <span class="math inline">\(q^1\)</span> 跟 <span class="math inline">\(k^2\)</span>,做 inner product, <span class="math inline">\(α_{1,3}\)</span> 就是 <span class="math inline">\(q^1\)</span> 跟 <span class="math inline">\(k^3\)</span> 做 inner product,这个 <span class="math inline">\(α_{1,4}\)</span> 就是 <span class="math inline">\(q^1\)</span> 跟 <span class="math inline">\(k^4\)</span> 做 inner
product。那这个四个步骤的操作,你其实可以把它拼起来,看作是<strong>矩阵跟向量相乘</strong>。</p>
<p><img src="image-20220613222335546.png" alt="image-20220613222335546" style="zoom:50%;"></p>
<p>这四个动作,你可以看作是我们<strong>把 <span class="math inline">\(k^1\)</span> 到 <span class="math inline">\(k^4\)</span> 拼起来,当作是一个矩阵的四个
row</strong>。那我们刚才讲过说,我们不只是 <span class="math inline">\(q^1\)</span>,要对<span class="math inline">\(k^1\)</span> 到 <span class="math inline">\(k^4\)</span> 计算 attention,<span class="math inline">\(q^2,q^3,q^4\)</span>也要对 <span class="math inline">\(k^1\)</span> 到 <span class="math inline">\(k^4\)</span> 计算
attention,操作其实都是一模一样的。</p>
<p><img src="image-20220613222430034.png" alt="image-20220613222430034" style="zoom:50%;"></p>
<p>所以这些 <strong>attention
的分数可以看作是两个矩阵的相乘</strong>,一个矩阵它的 row,就是 <span class="math inline">\(k^1\)</span> 到 <span class="math inline">\(k^4\)</span>,另外一个矩阵它的 column 。我们会在
attention 的分数,<strong>做一下 normalization</strong>,比如说你会做
softmax,你会对这边的每一个 column,每一个 column 做 softmax,让每一个
column 里面的值相加是 1。</p>
<p>之前有讲过说 其实这边做
<strong>softmax不是唯一的选项</strong>,你完全可以选择其他的操作,比如说
ReLU 之类的,那其实得到的结果也不会比较差,通过了 softmax
以后,它得到的值有点不一样了,所以我们用 <span class="math inline">\(A&#39;\)</span>,来表示通过 softmax
以后的结果。</p>
<p>我们已经计算出 $A' <span class="math inline">\(，那我们把这个\)</span>v^1$ 到 <span class="math inline">\(v^4\)</span>乘上这边的 α 以后,就可以得到 b。</p>
<p><img src="image-20220613223101872.png" alt="image-20220613223101872" style="zoom:50%;"></p>
<p>你就把<span class="math inline">\(v^1\)</span> 到 <span class="math inline">\(v^4\)</span> 拼起来,你<strong>把 <span class="math inline">\(v^1\)</span> 到 <span class="math inline">\(v^4\)</span>当成是V 这个矩阵的四个
column</strong>,把它拼起来,然后接下来你把 v 乘上,<span class="math inline">\(A&#39;\)</span> 的第一个 column
以后,你得到的结果就是 <span class="math inline">\(b^1\)</span></p>
<p>如果你熟悉线性代数的话,你知道说把这个 <span class="math inline">\(A&#39;\)</span> 乘上 V,就是把 <span class="math inline">\(A&#39;\)</span>的第一个 column,乘上 V
这一个矩阵,你会得到你 output 矩阵的第一个 column。而把 A 的第一个
column乘上 V 这个矩阵做的事情,其实就是把 V 这个矩阵里面的每一个
column,<strong>根据第 <span class="math inline">\(A&#39;\)</span>
这个矩阵里面的每一个 column 里面每一个 element,做 weighted
sum</strong>,那就得到 <span class="math inline">\(b^1\)</span></p>
<p>那就是这边的操作,把 <span class="math inline">\(v^1\)</span> 到 <span class="math inline">\(v^4\)</span> 乘上 weight,全部加起来得到 <span class="math inline">\(b^1\)</span>,如果你是用矩阵操作的角度来看它,就是把$
A'$ 的第一个 column 乘上 V,就得到 <span class="math inline">\(b^1\)</span>,然后接下来就是以此类推。</p>
<p><img src="image-20220613223143878.png" alt="image-20220613223143878" style="zoom:50%;"></p>
<p>就是以此类推,把 <span class="math inline">\(A&#39;\)</span> 的第二个
column 乘上 V,就得到 <span class="math inline">\(b^2\)</span>,<span class="math inline">\(A&#39;\)</span> 的第三个 column 乘上 V 就得到
<span class="math inline">\(b^3\)</span>,<span class="math inline">\(A&#39;\)</span> 的最后一个 column 乘上 V,就得到
<span class="math inline">\(b^4\)</span>。所以我们等于就是把 <span class="math inline">\(A&#39;\)</span> 这个矩阵,乘上 V 这个矩阵,得到 O
这个矩阵,O 这个矩阵里面的每一个 column,就是 Self-attention 的输出,也就是
<span class="math inline">\(b^1\)</span> 到 <span class="math inline">\(b^4\)</span>,</p>
<p><strong><font color="red"> 所以其实整个
Self-attention,我们在讲操作的时候,我们在最开始的时候
跟你讲的时候我们讲说,我们先产生了 q k v,然后再根据这个 q
去找出相关的位置,然后再对 v 做 weighted
sum,其实这一串操作,就是一连串矩阵的乘法而已</font></strong>。</p>
<h3><span id="23-self-attention-流程">2.3 Self-attention 流程</span></h3>
<h5><span id="我们再复习一下我们刚才看到的矩阵乘法">我们再复习一下我们刚才看到的矩阵乘法：</span></h5>
<p><img src="image-20220613223238727.png" alt="image-20220613223238727" style="zoom:50%;"></p>
<ul>
<li><p>I 是 Self-attention 的 input,Self-attention 的 input
是一排的vector,这排 vector 拼起来当作矩阵的 column,就是 I；</p></li>
<li><p>这个 input 分别乘上三个矩阵,<span class="math inline">\(W^q\)</span> <span class="math inline">\(W^k\)</span> 跟$ W^v$,得到 Q K V ；</p></li>
<li><p>这三个矩阵,接下来 Q 乘上 K 的 transpose,得到 A 这个矩阵,A
的矩阵你可能会做一些处理,得到 <span class="math inline">\(A&#39;\)</span>,那有时候我们会把这个 <span class="math inline">\(A&#39;\)</span>,叫做 <strong>Attention
Matrix</strong>，<strong>生成Q矩阵就是为了得到Attention的score</strong>；</p></li>
<li><p>然后接下来你把 <span class="math inline">\(A&#39;\)</span> 再乘上
V,就得到 O,O 就是 Self-attention 这个 layer
的输出,<strong>生成V是为了计算最后的b，也就是矩阵O；</strong></p></li>
</ul>
<p>所以 Self-attention 输入是 I,输出是 O,那你会发现说虽然是叫
attention,但是<strong>其实 Self-attention layer
里面,唯一需要学的参数,就只有 <span class="math inline">\(W^q\)</span>
<span class="math inline">\(W^k\)</span> 跟$ W^v$ 而已,只有<span class="math inline">\(W^q\)</span> <span class="math inline">\(W^k\)</span> 跟$
W^v$是未知的</strong>,是需要透过我们的训练资料把它找出来的。但是其他的操作都没有未知的参数,都是我们人为设定好的,都不需要透过
training data 找出来,那这整个就是 Self-attention 的操作,从 I 到 O
就是做了 Self-attention。</p>
<h3><span id="24-multi-head-self-attention">2.4 Multi-head Self-attention</span></h3>
<p><strong>Self-attention 有一个进阶的版本,叫做 ==Multi-head
Self-attention==, Multi-head
Self-attention,其实今天的使用是非常地广泛的</strong>。在作业 4
里面,助教原来的 code 4 有,Multi-head Self-attention,它的 head
的数目是设成 2,那刚才助教有给你提示说,把 head 的数目改少一点 改成
1,其实就可以过medium baseline。</p>
<p>但并不代表所有的任务,都适合用比较少的
head,有一些任务,比如说翻译,比如说语音辨识,其实用比较多的
head,你反而可以得到比较好的结果。至于<strong>需要用多少的
head,这个又是另外一个 hyperparameter</strong>,也是你需要调的。</p>
<h5><span id="那为什么我们会需要比较多的head-呢你可以想成说相关这件事情">那为什么我们会需要比较多的
head 呢,你可以想成说相关这件事情？</span></h5>
<p>我们在做这个 Self-attention 的时候,我们就是用 q 去找相关的
k,但是<strong>==相关==这件事情有很多种不同的形式</strong>,有很多种不同的定义,所以也许我们不能只有一个
q,我们应该要有多个 q,<strong>不同的 q
负责不同种类的相关性</strong>。</p>
<h5><span id="所以假设你要做multi-head-self-attention-的话你会怎么操作呢">所以假设你要做
Multi-head Self-attention 的话,你会怎么操作呢?</span></h5>
<p><img src="image-20220613223634261.png" alt="image-20220613223634261" style="zoom:50%;"></p>
<ul>
<li>先把 a 乘上一个矩阵得到 q</li>
<li>再把 q 乘上另外两个矩阵,分别得到 <span class="math inline">\(q^1\)</span> 跟 <span class="math inline">\(q^2\)</span>,那这边还有 这边是用两个上标,i
代表的是位置,然后这个 1 跟 2 代表是,这个位置的第几个 q,所以这边有 <span class="math inline">\(q^{i,1}\)</span> 跟 <span class="math inline">\(q^{i,2}\)</span>,代表说我们有两个 head</li>
</ul>
<p>我们认为这个问题,里面有两种不同的相关性,是我们需要产生两种不同的
head,来找两种不同的相关性。既然 q 有两个,那 k 也就要有两个,那 v
也就要有两个,从 q 得到 <span class="math inline">\(q^1 q^2\)</span>,从 k
得到 <span class="math inline">\(k^1 k^2\)</span>,从 v 得到 <span class="math inline">\(v^1 v^2\)</span>,那其实就是把 q 把 k 把
v,分别乘上两个矩阵,得到这个不同的
head,就这样子而已,对另外一个位置,也做一样的事情只是现在<span class="math inline">\(q^1\)</span>,它在算这个 attention
的分数的时候,它就不要管那个 <span class="math inline">\(k^2\)</span>
了。</p>
<p><img src="image-20220613223730387.png" alt="image-20220613223730387" style="zoom:50%;"></p>
<ul>
<li><p>所以 <span class="math inline">\(q_{i,1}\)</span> 就跟 <span class="math inline">\(k^{i,1}\)</span> 算 attention</p></li>
<li><p><span class="math inline">\(q_{i,1}\)</span> 就跟 <span class="math inline">\(k^{j,1}\)</span> 算 attention,也就是算这个 dot
product,然后得到这个 attention 的分数</p></li>
<li><p>然后今天在做 weighted sum 的时候,也不要管 <span class="math inline">\(v^2\)</span> 了,看 <span class="math inline">\(V^{i,1}\)</span> 跟 <span class="math inline">\(v^{j,1}\)</span> 就好,所以你把 attention 的分数乘
<span class="math inline">\(v^{i,1}\)</span>,把 attention 的分数乘 <span class="math inline">\(v^{j,1}\)</span></p></li>
<li><p>然后接下来就得到 <span class="math inline">\(b^{i,1}\)</span></p></li>
</ul>
<p>这边只用了其中一个 head,那你会用另外一个
head,也做一模一样的事情。</p>
<p><img src="image-20220613223749217.png" alt="image-20220613223749217" style="zoom:50%;"></p>
<p>所以 <span class="math inline">\(q^2\)</span> 只对 <span class="math inline">\(k^2\)</span> 做 attention,它们在做 weighted sum
的时候,只对 <span class="math inline">\(v^2\)</span> 做 weighted
sum,然后接下来你就得到 <span class="math inline">\(b^{i,2}\)</span></p>
<p>如果你有多个 head,有 8 个 head 有 16 个
head,那也是一样的操作,那这边是用两个 head 来当作例子,来给你看看有两个
head 的时候,是怎么操作的,现在得到 <span class="math inline">\(b^{i,1}\)</span> 跟 <span class="math inline">\(b^{i,2}\)</span>。<strong>然后接下来你可能会把
<span class="math inline">\(b^{i,1}\)</span> 跟 <span class="math inline">\(b^{i,2}\)</span>,把它接起来,然后再通过一个
transform。</strong></p>
<p><img src="image-20220613223832789.png" alt="image-20220613223832789" style="zoom:50%;"></p>
<p>也就是再乘上一个矩阵,然后得到 bi,然后再送到下一层去,那这个就是
Multi-head attention,一个这个 Self-attention 的变形。</p>
<h3><span id="25-positional-encoding">2.5 Positional Encoding</span></h3>
<blockquote>

</blockquote>
<h4><span id="no-positioninformation-in-self-attention">No position
information in self-attention</span></h4>
<p>那讲到目前为止,你会发现说 Self-attention 的这个
layer,它少了一个也许很重要的资讯,这个资讯是<strong>位置的资讯</strong>。对一个
Self-attention layer 而言,每一个 input,它是出现在 sequence
的最前面,还是最后面,它是完全没有这个资讯的。</p>
<p><font color="red"> 对 Self-attention 而言,<strong>位置 1 跟位置 2
跟位置 3 跟位置
4,完全没有任何差别,这四个位置的操作其实是一模一样</strong>,对它来说 q1
到跟 q4 的距离,并没有特别远,1 跟 4 的距离并没有特别远,2 跟 3
的距离也没有特别近。</font></p>
<p>对它来说就是天涯若比邻,所有的位置之间的距离都是一样的,没有任何一个位置距离比较远,也没有任何位置距离比较近,也没有谁在整个
sequence 的最前面,也没有谁在整个 sequence
的最后面。但是这样子设计可能会有一些问题,因为有时候位置的资讯也许很重要,举例来说,我们在做这个
POS
tagging,就是词性标记的时候,也许你知道说<strong>动词比较不容易出现在句首</strong>,所以如果我们知道说,某一个词汇它是放在句首的,那它是动词的可能性可能就比较低,这样子的位置的资讯往往也是有用的。</p>
<h4><span id="each-positon-hasa-unique-positional-vector-ei">Each positon has
a unique positional vector <span class="math inline">\(e^i\)</span></span></h4>
<p>可是在我们到目前为止,讲的 Self-attention
的操作里面,根本就没有位置的资讯,所以怎么办呢,所以你做 Self-attention
的时候,如果你觉得位置的资讯是一个重要的事情,那你可以把位置的资讯把它塞进去,怎么把位置的资讯塞进去呢,这边就要用到一个叫做,==positional
encoding== 的技术。</p>
<p><img src="image-20220613224025472.png" alt="image-20220613224025472" style="zoom:50%;"></p>
<p><font color="red"> <strong>你为每一个位置设定一个 vector,叫做
positional vector</strong>,这边<strong>用 <span class="math inline">\(e^i\)</span> 来表示,上标 i
代表是位置,每一个不同的位置</strong></font>,就有不同的 vector,就是 <span class="math inline">\(e^1\)</span> 是一个 vector,<span class="math inline">\(e^2\)</span> 是一个vector,<span class="math inline">\(e^{128}\)</span>
是一个vector,不同的位置都有一个它专属的 e,然后把这个 e 加到 <span class="math inline">\(a^i\)</span> 上面,就结束了。就是告诉你的
Self-attention,位置的资讯,如果它看到说 <span class="math inline">\(a^i\)</span> 好像有被加上 $
e^i$,它就知道说现在出现的位置,应该是在 i 这个位置。</p>
<p><strong>最早的这个 transformer,就 Attention Is All You Need 那篇
paper 里面,它用的 $ e^i$长的是这个样子</strong>。</p>
<p><img src="image-20220613224248928.png" alt="image-20220613224248928" style="zoom:50%;"></p>
<h4><span id="hand-crafted-or-learned-fromdata">Hand-crafted or Learned from
data</span></h4>
<p><strong>这样子的 positional vector,它是 handcrafted
的,也就是它是人设的</strong>,那人设的这个 vector
有很多问题,就假设我现在在定这个 vector 的时候,只定到 128,那我现在
sequence 的长度,如果是 129 怎么办呢？不过在最早的那个,Attention Is All
You Need paper里面,没有这个问题,<strong>它 vector
是透过某一个规则所产生的</strong>,透过一个很神奇的sin和cos 的 function
所产生的。</p>
<p>其实你不一定要这么产生, <strong>positional
encoding仍然是一个尚待研究的问题</strong>,你可以创造自己新的方法,或甚至
positional encoding,是可以根据资料学出来的。那有关 positional
encoding,你可以再参考一下文献,这个是一个尚待研究的问题,比如说我这边引用了一篇,这个是去年放在
arxiv 上的论文,所以可以想见这其实都是很新的论文。</p>
<p><img src="image-20220613224538933.png" alt="image-20220613224538933" style="zoom:50%;"></p>
<p>里面就是比较了跟提出了,新的 positional encoding</p>
<ul>
<li>比如说这个是最早的 positional encoding,它是用一个神奇的 sin function
所产生的</li>
<li>那如果你的 positional encoding,你把 positional encoding
里面的数值,当作 network 参数的一部分,直接 learn
出来,看起来是这个样子的,这个图是那个横著看的,它是横著看的,它是每一个
row,代表一个 position,好 所以这个是这个最原始的,用 sin function
产生的,这个是 learn 出来的</li>
<li>它里面又有神奇的做法,比如说这个,这个是用 RNN 生出来的,positional
encording 是用 RNN 出来的,这篇 paper 提出来的叫做 FLOATER,是用个神奇的
network 生出来的,</li>
</ul>
<p>总之你有各式各样不同的方法,来产生 positional
encoding,那目前我们还不知道哪一种方法最好,这是一个尚待研究中的问题,所以你不用纠结说,为什么
Sinusoidal 最好,<strong>你永远可以提出新的做法</strong>。</p>
<h3><span id="26-applications">2.6 Applications …</span></h3>
<p><strong>Self-attention 当然是用得很广,我们已经提过很多次 transformer
这个东西</strong>。</p>
<p><img src="image-20220613224644049.png" alt="image-20220613224644049" style="zoom:50%;"></p>
<p>那我们大家也都知道说,在 NLP 的领域有一个东西叫做 BERT,BERT 里面也用到
Self-attention,所以 Self-attention 在 NLP
上面的应用,是大家都耳熟能详的。但 <strong>Self-attention,不是只能用在
NLP 相关的应用上,它还可以用在很多其他的问题上</strong>。</p>
<h3><span id="self-attention-for-speech">Self-attention for Speech</span></h3>
<p>比如说在做语音的时候,你也可以用
Self-attention,不过在做语音的时候,你可能会对
Self-attention,做一些小小的改动。因为一般语音的,如果你要把一段声音讯号,表示成一排向量的话,这排<strong>向量可能会非常地长</strong>。</p>
<p><img src="image-20220613224723147.png" alt="image-20220613224723147" style="zoom:50%;"></p>
<p>而每一个向量,其实只代表了 10 millisecond 的长度而已,所以如果今天是 1
秒鐘的声音讯号,它就有 100 个向量了,5 秒鐘的声音讯号,就 500
个向量了,你随便讲一句话,都是上千个向量了。所以一段声音讯号,你要描述它的时候,那个像这个
vector 的 sequence 它的长度是非常可观的,那可观的
sequence,可观的长度,会造成什么问题呢？</p>
<p>你想想看,我们今天在<strong>计算这个 attention matrix
的时候,它的计算complexity 是长度的平方。</strong></p>
<p><img src="image-20220613224807917.png" alt="image-20220613224807917" style="zoom:50%;"></p>
<p><strong>计算这个 attention matrix A′你需要做 L 乘以 L 次的 inner
product,那如果这个 L 的值很大的话,它的计算量就很可观,你也需要很大的这个
memory,才能够把这个矩阵存下来。</strong></p>
<p>所以今天如果在做语音辨识的时候,一句话所产生的这个 attention
matrix,可能会太大,大到你根本就不容易处理,不容易训练,所以怎么办呢？<strong>在做语音的时候,有一招叫做
==Truncated Self-attention==</strong>。</p>
<p><img src="image-20220613224906348.png" alt="image-20220613224906348" style="zoom:50%;"></p>
<p><font color="red"><strong>Truncated Self-attention</strong>
做的事情就是,我们今天在做 Self-attention
的时候,<strong>不要看一整句话,就我们就只看一个小的范围就好</strong>，那至于<strong>这个范围应该要多大,那个是人设定的。</strong></font></p>
<p>那为什么我们知道说,今天在做语音辨识的时候,也许只需要看一个小的范围就好,那就是<strong>取决于你对这个问题的理解</strong>,也许我们要辨识这个位置有什么样的<strong>phoneme</strong>,这个位置有什么样的内容,我们并不需要看整句话,只要看这句话,跟它前后一定范围之内的资讯,其实就可以判断。</p>
<p>所以如果在做 Self-attention
的时候,也许没有必要看过一整个句子,也许没有必要让 Self-attention
考虑一整个句子,也许只需要考虑一个小范围就好,这样就可以加快运算的速度，这个是
Truncated Self-attention。</p>
<h3><span id="self-attention-for-image">Self-attention for Image</span></h3>
<p>那其实 Self-attention
,还可以被用在影像上,Self-attention那到目前为止,我们在讲 Self-attention
的时候,我们都说 <strong>Self-attention 适用的范围是：输入是一个 vector
set
的时候</strong>，一张图片啊,我们把它看作是一个很长的向量,那<strong>其实一张图片,我们也可以换一个观点,把它看作是一个
vector 的 set。</strong></p>
<p><img src="image-20220613225206980.png" alt="image-20220613225206980" style="zoom:50%;"></p>
<p><strong>这个是一个解析度 5 乘以 10
的图片,那这一张图片呢,可以看作是一个 tensor,这个 tensor 的大小是 5 乘以
10 乘以 3,3 代表 RGB 这 3 个 channel。你可以把每一个位置的
pixel,看作是一个三维的向量,所以每一个
pixel,其实就是一个三维的向量,那整张图片,其实就是 5 乘以 10
个向量的set</strong>。</p>
<p>所以我们其实可以换一个角度,影像这个东西,其实也是一个 vector
set,它既然也是一个 vector set 的话,你完全可以用 Self-attention
来处理一张图片,那有没有人用 Self-attention
来处理一张图片呢,是有的。那这边就举了两个例子,来给大家参考,那现在把
Self-attention 用在影像处理上,也不算是一个非常石破天惊的事情。</p>
<p><img src="image-20220613225244115.png" alt="image-20220613225244115" style="zoom:50%;"></p>
<h3><span id="self-attention-vs-cnn">==Self-attention v.s. CNN==</span></h3>
<p>我们可以来比较一下,<strong>Self-attention 跟 CNN
之间,有什么样的差异或者是关联性</strong>。如果我们今天,是用
Self-attention 来处理一张图片,代表说,假设这个是你要考虑的 pixel,那它产生
query,其他 pixel 产生 key。</p>
<p><img src="image-20220613225357976.png" alt="image-20220613225357976" style="zoom:50%;"></p>
<p>你今天在<strong>做 inner product 的时候,你考虑的不是一个小的receptive
field的信息,而是整张影像的资讯</strong>，但是今天在做 CNN
的时候,,会画出一个 receptive field,每一个 filter,每一个 neural,只考虑
receptive field 范围里面的资讯。</p>
<p><img src="image-20220613225442244.png" alt="image-20220613225442244" style="zoom:50%;"></p>
<ul>
<li>所以如果我们比较 CNN 跟 Self-attention
的话,<strong><font color="red">CNN 可以看作是一种简化版的 Self-attention
</font></strong>，因为在做CNN的时候,我们只考虑 receptive field
里面的资讯,而在做 Self-attention 的时候,我们是考虑整张图片的资讯,所以
CNN,是简化版的
Self-attention。或者是你可以反过来说,<strong><font color="red">
Self-attention 是一个复杂化的 CNN</font></strong></li>
<li>在 CNN 里面,我们要划定 receptive field,每一个 neural,只考虑
receptive field 里面的资讯,而 <strong><font color="red"> receptive field
的范围跟大小,是人决定的。而对 Self-attention 而言,我们用
attention,去找出相关的 pixel,就好像是 receptive field
是自动被学出的,network 自己决定说,receptive field
的形状长什么样子,network 自己决定说,以这个 pixel 为中心,哪些 pixel
是我们真正需要考虑的,那些 pixel 是相关的</font></strong>。<strong>所以
receptive field
的范围,不再是人工划定,而是让机器自己学出来</strong>。</li>
</ul>
<p>其实你可以读一篇 paper,叫做 On the Relationship,between
Self-attention and Convolutional Layers。</p>
<p><img src="image-20220613230146104.png" alt="image-20220613230146104" style="zoom:50%;"></p>
<p>在这篇 paper 里面,会用数学的方式严谨的告诉你说,其实这个
<strong>CNN就是 Self-attention 的特例,Self-attention
只要设定合适的参数,它可以做到跟 CNN 一模一样的事情</strong>。所以 self
attention,是更 flexible 的 CNN,而 CNN 是有受限制的
Self-attention,Self-attention 只要透过某些设计,某些限制,它就会变成
CNN。</p>
<p><img src="image-20220613230212397.png" alt="image-20220613230212397" style="zoom:50%;"></p>
<p>那这也不是很旧的 paper,你发现它放到网路上的时间呢,是 19 年的 11
月,所以你知道这些,我们今天上课里面讲的东西,其实都是很新的资讯。<strong><font color="red">
既然Self-attention 比较 flexible,之前有讲说比较 flexible 的
model,比较需要更多的 data,如果你 data 不够,就有可能
overfitting。</font></strong></p>
<p>如果你今天用不同的 data 量,来训练 CNN 跟
Self-attention,你确实可以看到我刚才讲的现象。</p>
<p><img src="image-20220613230309663.png" alt="image-20220613230309663" style="zoom:50%;"></p>
<p>那这个实验结果,来自于 An image is worth 16 乘以 16 的 words,这个是
Google 的 paper,它就是把这个 Self-attention,apply
在影像上面。那其实<strong>把一张影像呢,拆成 16 乘以 16 个
patch,它把每一个 patch想像成是一个 word</strong>,因为一般我们这个
Self-attention,比较常用在 NLP 上面,所以他就说,想像每一个 patch
其实就是一个 word,所以他就取了一个很 fancy 的 title,叫做<strong>一张图值
16 乘以 16 个文字</strong>。</p>
<p>横轴是训练的影像的量,那你发现说,对 Google 来说
用的,所谓的资料量比较少,也是你没有办法用的资料量啦这边有 10 个 million
就是,1000 万张图,是资料量比较小的 setting,然后资料量比较大的 setting
呢,有 3 亿张图片,在这个实验里面呢,比较了 Self-attention
是浅蓝色的这一条线,跟 CNN 是深灰色的这条线。</p>
<p>就会发现说,<strong>随著资料量越来越多,那 Self-attention
的结果就越来越好,最终在资料量最多的时候,Self-attention 可以超过
CNN,但在资料量少的时候,CNN 它是可以比
Self-attention,得到更好的结果的。</strong></p>
<p>那为什么会这样,你就可以从 CNN 跟
Self-attention,它们的弹性来加以解释：</p>
<ul>
<li><strong><font color="red"> Self-attention
它弹性比较大,所以需要比较多的训练资料,训练资料少的时候,就会
overfitting。</font></strong></li>
<li>CNN
它弹性比较小,在训练资料少的时候,结果比较好,但训练资料多的时候,它没有办法从更大量的训练资料得到好处。</li>
</ul>
<p>所以这个就是 Self-attention 跟 CNN 的比较，那 Self-attention 跟
CNN,谁比较好呢,<strong>我应该选哪一个呢,事实上你也可以都用</strong>,在我们作业四里面,如果你要做
strong baseline 的话,就特别给你一个提示,就是用 conformer,里面就是有用到
Self-attention,也有用到 CNN。</p>
<h3><span id="self-attention-vs-rnn"><strong><font color="red">
Self-attention v.s. RNN</font></strong></span></h3>
<p>我们来比较一下,Self-attention 跟 RNN,RNN就是 recurrent neural
network,这门课里面现在就不会讲recurrent neural network,因为 recurrent
neural network 的角色,很大一部分都可以用 Self-attention 来取代了,但是
RNN 是什么呢,假设你想知道的话,那这边很快地三言两语把它带过去,RNN 跟
Self-attention 一样,都是要处理 input 是一个 sequence 的状况。</p>
<p><img src="image-20220613230659968.png" alt="image-20220613230659968" style="zoom:50%;"></p>
<p>在 RNN 里面呢</p>
<ul>
<li>左边是你的 input sequence,你有一个 <strong>memory</strong> 的
vector</li>
<li>然后你有一个 RNN 的 block,这个 RNN 的 block 呢,它吃 memory 的
vector,吃第一个 input 的 vector</li>
<li>然后 output 一个东西,然后根据这个 output 的东西,我们通常叫做这个
hidden,这个 hidden 的 layer 的 output</li>
<li>然后通过这个 fully connected network,然后再去做你想要的
prediction</li>
</ul>
<p>接下来当sequence 里面,第二个 vector 作为 input
的时候,也会把前一个时间点吐出来的东西,当做下一个时间点的输入,再丢进 RNN
里面,然后再产生新的 vector,再拿去给 fully connected network。然后第三个
vector 进来的时候,你把第三个 vector 跟前一个时间点的输出,一起丢进
RNN,再产生新的输出,然后在第四个时间点。第四个 vector 输入的时候,把第四个
vector 跟前一个时间点,产生出来的输出,再一起做处理,得到新的输出,再通过
fully connected network 的 layer,这个就是 RNN。</p>
<p>Recurrent Neural Network跟 Self-attention 做的事情其实也非常像,它们的
<strong>input 都是一个 vector sequence</strong>，Self-attention output
是另外一个 vector sequence,这里面的每一个 vector,都<strong>考虑了整个
input sequence 以后</strong>,再给 fully connected network 去做处理。</p>
<p>那 RNN 呢,它也会 output 另外一群 vector,这<strong>另外一排
vector</strong> 也会给,fully connected network 做进一步的处理,那
Self-attention 跟 RNN 有什么不同呢。</p>
<p><img src="image-20220613230944896.png" alt="image-20220613230944896" style="zoom:50%;"></p>
<p><strong>当然一个非常显而易见的不同,你可能会说,这边的每一个
vector,它都考虑了整个 input 的 sequence,而 RNN 每一个
vector,只考虑了左边已经输入的 vector,它没有考虑右边的
vector,那这是一个很好的观察。</strong></p>
<p>但是 <strong>RNN 其实也可以是双向的</strong>,所以如果你 RNN 用双向的
RNN 的话,其实这边的每一个 hidden 的 output,每一个 memory 的
output,其实也可以看作是考虑了整个 input 的 sequence。但是假设我们把 RNN
的 output,跟 Self-attention 的 output 拿来做对比的话,就算你用
bidirectional 的 RNN,还是有一些差别的。</p>
<ul>
<li><p><strong><font color="red">对RNN 来说,假设最右边这个黄色的
vector,要考虑最左边的这个输入,那它必须要把最左边的输入存在 memory
里面,然后接下来都不能够忘掉,一路带到最右边,才能够在最后一个时间点被考虑。</font></strong></p></li>
<li><p><strong><font color="red"> 对 Self-attention
来说没有这个问题,它只要这边输出一个 query,这边输出一个 key,只要它们
match 得起来,天涯若比邻,你可以从非常远的 vector,在整个 sequence
上非常远的 vector,轻易地抽取资讯,所以这是 RNN 跟
Self-attention,一个不一样的地方。</font></strong></p></li>
<li><p>RNN 今天在处理的时候, input 一排 sequence,output 一排 sequence
的时候,<strong><font color="red"> RNN
是没有办法平行化的。</font></strong>RNN 它今天 input 一排是
vector,output 另外一排 vector
的时候,它没有办法一次处理,没有办法平行处理所有的 output。但
Self-attention 有一个优势,是它可以平行处理所有的输出,你今天 input 一排
vector,再 output 这四个 vector 的时候,<strong>这四个 vector
是平行产生的,并不需要等谁先运算完才把其他运算出来</strong>,output 的这个
vector,里面的 output 这个 vector sequence 里面,每一个 vector
都是同时产生出来的。<strong><font color="red">
所以在运算速度上,Self-attention 会比 RNN
更有效率。</font></strong></p></li>
</ul>
<p><img src="image-20220613231148500.png" alt="image-20220613231148500" style="zoom:50%;"></p>
<p>那你今天发现说,<strong>很多的应用都往往把 RNN 的架构,逐渐改成
Self-attention 的架构了</strong>,如果你想要更进一步了解,RNN 跟
Self-attention 的关係的话,你可以看下面这篇文章,Transformers are
RNNs,里面会告诉你说,Self-attention 你加上了什么东西以后,其实它就变成了
RNN,发现说这也不是很旧的 paper,这个是去年的六月放到 arXiv 上。</p>
<h3><span id="self-attention-for-graph">Self-attention for Graph</span></h3>
<p>Graph 也可以看作是一堆 vector,那如果是一堆 vector,就可以用
Self-attention 来处理,所以 Self-attention 也可以用在 Graph
上面,但是<strong>当我们把 Self-attention,用在Graph
上面的时候,有什么样特别的地方呢？</strong></p>
<p><strong><font color="red"> Graph 往往是人为根据某些 domain knowledge
建出来的,那 domain knowledge
告诉我们说,这两个向量彼此之间没有关联,我们就没有必要再用机器去学习这件事情。</font></strong></p>
<p><img src="image-20220613231411144.png" alt="image-20220613231411144" style="zoom:50%;"></p>
<p>在 Graph 上面,每一个 node 可以表示成一个向量,但<strong>不只有 node
的资讯,还有 edge 的资讯</strong>,我们知道哪些 node
之间是有相连的,也就是哪些 node 是有关联的。</p>
<p>我们知道哪些向量间是有关联,那之前我们在做 Self-attention
的时候,所谓的关联性是 network 自己找出来的,但是现在既然有了 Graph
的资讯,<strong>有了 edge
的资讯,那关联性也许就不需要透过机器自动找出来,这个图上面的 edge
已经暗示了我们,node 跟 node 之间的关联性</strong>。</p>
<p>所以今天当你把 Self-attention,用在 Graph
上面的时候,你有一个选择是你在做这个,Attention Matrix
计算的时候,你可以<strong>只计算有 edge 相连的 node
就好</strong>。那如果两个 node
之间没有相连,那其实很有可能就暗示我们,这两个 node
之间没有关係,<strong>既然没有关係,我们就不需要再去计算它的 attention
score,直接把它设为 0 就好了</strong>。</p>
<h3><span id="27-more">2.7 More</span></h3>
<p>其实Self-attention 有非常非常多的变形,你可以看一篇 paper
叫做,<strong>Long Range Arena</strong>,里面比较了各种不同的
Self-attention 的变形。</p>
<p><img src="image-20220613231703000.png" alt="image-20220613231703000" style="zoom:50%;"></p>
<p>Self-attention
它最大的问题就是,<strong>它的运算量非常地大</strong>,所以怎么样减少
Self-attention 的运算量,是一个未来的重点,可以看到这边有,各种各式各样
Self-attention 的变形。</p>
<p><strong>Self-attention 最早是,用在 Transformer 上面,所以很多人讲
Transformer 的时候,其实它指的就是这个 Self-attention,有人说广义的
Transformer,指的就是
Self-attention</strong>。那所以后来各式各样的,Self-attention
的变形都这样做,都叫做是什么 former,比如说 Linformer Performer Reformer
等等,所以 Self-attention 的变形,现在都叫做 xxformer。</p>
<p>那可以看到，往右代表它运算的速度,所以有很多各式各样新的
xxformer,它们的速度会比原来的 Transformer 快,但是快的速度带来的就是
performance 变差。这个纵轴代表是 performance,所以它们往往比原来的
Transformer,performance 差一点,但是速度会比较快。那到底什么样的
Self-attention,才能够真的又快又好,这仍然是一个尚待研究的问题,如果你对
Self-attention,想要进一步研究的话,你还可以看一下,<strong>Efficient
Transformers: A Survey 这篇 paper,里面会跟你介绍,各式各样 Self-attention
的变形。</strong></p>
<h2><span id="三-注意力机制-qampa">三、注意力机制 Q&amp;A</span></h2>
<h3><span id="31self-attention-cnn-rnn对比">3.1
Self-Attention、CNN、RNN对比？</span></h3>
<h4><span id="self-attention-vs-cnn">Self-Attention vs CNN</span></h4>
<ul>
<li><strong><font color="red">CNN 可以看作是一种简化版的 Self-attention
</font></strong>，因为在做CNN的时候,我们只考虑 receptive field
里面的资讯,而在做 Self-attention 的时候,我们是考虑整张图片的资讯。</li>
<li>在 CNN 里面 <strong><font color="red"> receptive field
的范围跟大小,是人决定的。而对 Self-attention
,不再是人工划定,而是让机器自己学出来</font></strong>。</li>
<li><strong>Self-attention 比较 flexible,之前有讲说比较 flexible 的
model,比较需要更多的 data,如果你 data 不够,就有可能
overfitting</strong>。</li>
</ul>
<h4><span id="self-attention-vs-rnn">Self-Attention vs RNN</span></h4>
<ul>
<li><strong><font color="red">RNN 右边的
vector,要考虑最左边的这个输入,那它必须要把最左边的输入存在 memory
里面,然后接下来都不能够忘掉,一路带到最右边,才能够在最后一个时间点被考虑。</font></strong>
Self-attention 只要a1输出一个 query,a4输出一个 key,只要它们 match
得起来,天涯若比邻,你可以从非常远的 vector,在整个 sequence 上非常远的
vector,轻易地抽取资讯,所以这是 RNN 跟
Self-attention一个不一样的地方。</li>
<li><strong><font color="red"> RNN
是没有办法平行化的。所以在运算速度上,Self-attention 会比 RNN
更有效率。</font></strong></li>
</ul>
<h3><span id="32self-attention-cnn-rnn时间复杂度对比">3.2
Self-Attention、CNN、RNN时间复杂度对比？</span></h3>
<blockquote>
<p>##### 计算效率: 一个形状为 <img src="https://www.zhihu.com/equation?tex=N%5Ctimes+M" alt="[公式]">
的矩阵，与另一个形状为 <img src="https://www.zhihu.com/equation?tex=M%5Ctimes+P" alt="[公式]">
的矩阵相乘，其运算复杂度来源于乘法操作的次数，时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28NMP%29" alt="[公式]"></p>
</blockquote>
<h4><span id="self-attention">Self-Attention</span></h4>
<figure>
<img src="https://www.zhihu.com/equation?tex=A%28Q%2CK%2CV%29%3D%5Cmathrm%7BSoftmax%7D%28QK%5ET%29V+%5C%5C+" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<ul>
<li><figure>
<img src="https://www.zhihu.com/equation?tex=Q%2CK%2CV%3An%5Ctimes+d" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure></li>
<li>相似度计算 <img src="https://www.zhihu.com/equation?tex=QK%5ET" alt="[公式]"> ： <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=d%5Ctimes+n" alt="[公式]"> 运算，得到 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+n" alt="[公式]">
矩阵，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"></li>
<li>softmax计算：对每行做softmax，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%29" alt="[公式]"> ，则n行的复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2%29" alt="[公式]"></li>
<li>加权和： <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+n" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]">
运算，得到 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]"> 矩阵，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"></li>
</ul>
<p>故最后self-attention的时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"></p>
<p>对于受限的self-attention，每个元素仅能和周围 <img src="https://www.zhihu.com/equation?tex=r" alt="[公式]">
个元素进行交互，即和 <img src="https://www.zhihu.com/equation?tex=r" alt="[公式]"> 个 <img src="https://www.zhihu.com/equation?tex=d" alt="[公式]"> 维向量做内积运算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28rd%29" alt="[公式]"> ，则 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 个元素的总时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%28rnd%29%7D" alt="[公式]"></p>
<h4><span id="multi-head-attention">Multi-Head Attention</span></h4>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BMultiHead%7D%28Q%2CK%2CV%29%3D%5Cmathrm%7BConcat%28head_1%2C...%2Chead_h%29%7DW%5EO+%5C%5C+%5Cmathrm%7Bwhere%5Cquad+head_i%7D%3DA%28QW_i%5EQ%2CKW_i%5EK%2CVW_i%5EV%29%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>对于multi-head attention，假设有 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]"> 个head，这里
<img src="https://www.zhihu.com/equation?tex=h" alt="[公式]">
是一个常数，对于每个head，首先需要把三个矩阵分别映射到 <img src="https://www.zhihu.com/equation?tex=d_q%2Cd_k%2Cd_v" alt="[公式]">
维度。这里考虑一种简化情况： <img src="https://www.zhihu.com/equation?tex=d_q%3Dd_k%3Dd_v%3D%5Cfrac%7Bd%7D%7Bh%7D" alt="[公式]"> 。(对于dot-attention计算方式， <img src="https://www.zhihu.com/equation?tex=d_k" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=d_v" alt="[公式]">
可以不同)。</p>
<ul>
<li>输入线性映射的复杂度： <img src="https://www.zhihu.com/equation?tex=n+%5Ctimes+d" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=d%5Ctimes+%5Cfrac%7Bd%7D%7Bh%7D" alt="[公式]"> 运算，忽略常系数，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nd%5E2%29" alt="[公式]"> 。</li>
<li>Attention操作复杂度：主要在相似度计算及加权和的开销上， <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+%5Cfrac%7Bd%7D%7Bh%7D" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7Bd%7D%7Bh%7D%5Ctimes+%7Bn%7D" alt="[公式]"> 运算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7B%7D" alt="[公式]"></li>
<li>输出线性映射的复杂度：concat操作拼起来形成 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]">
的矩阵，然后经过输出线性映射，保证输入输出相同，所以是 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=d%5Ctimes+d" alt="[公式]"> 计算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nd%5E2%29" alt="[公式]"></li>
</ul>
<p>故最后的复杂度为： <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%2Bnd%5E2%29" alt="[公式]"></p>
<blockquote>
<p>注意：多头的计算并不是通过循环完成的，而是通过 transposes and
reshapes，用矩阵乘法来完成的。假设有 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]">
个head，则新的representation dimension： <img src="https://www.zhihu.com/equation?tex=m%3D%5Cfrac%7Bd%7D%7Bh%7D" alt="[公式]"> 。因为，我们将 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]">
的矩阵拆为 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+h%5Ctimes+m" alt="[公式]"> 的张量，再利用转置操作转为 <img src="https://www.zhihu.com/equation?tex=h%5Ctimes+n+%5Ctimes+m" alt="[公式]"> 的张量。故 <img src="https://www.zhihu.com/equation?tex=QK%5ET" alt="[公式]">
的计算为： <img src="https://www.zhihu.com/equation?tex=h%5Ctimes+n%5Ctimes+m" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=h%5Ctimes+m+%5Ctimes+n" alt="[公式]"> 做计算，得到 <img src="https://www.zhihu.com/equation?tex=h%5Ctimes+n%5Ctimes+n" alt="[公式]"> 的张量，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28h%5E2n%5E2m%29" alt="[公式]"> ，即 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2dh%29" alt="[公式]"> 。注意，此处 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]">
实际是一个常数，故 <img src="https://www.zhihu.com/equation?tex=QK%5ET" alt="[公式]"> 复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"> 。</p>
</blockquote>
<h4><span id="recurrent">Recurrent</span></h4>
<figure>
<img src="https://www.zhihu.com/equation?tex=h_t%3Df%28Ux_t%2BWh_%7Bt-1%7D%29+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=Ux_t" alt="[公式]">
： <img src="https://www.zhihu.com/equation?tex=d%5Ctimes+m" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=m%5Ctimes+1" alt="[公式]">
运算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28md%29" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=m" alt="[公式]"> 为input size</li>
<li><img src="https://www.zhihu.com/equation?tex=Wh_%7Bt-1%7D" alt="[公式]"> ： <img src="https://www.zhihu.com/equation?tex=d%5Ctimes+d" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=d%5Ctimes+1" alt="[公式]"> 运算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28d%5E2%29" alt="[公式]"></li>
</ul>
<p>故一次操作的时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28d%5E2%29" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 次序列操作后的总时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nd%5E2%29" alt="[公式]"></p>
<h4><span id="convolution">Convolution</span></h4>
<blockquote>
<p>注: 这里保证输入输出都是一样的，即均是 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]"></p>
</blockquote>
<ul>
<li>为了保证输入和输出在第一个维度都相同，故需要对输入进行padding操作，因为这里kernel
size为 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]">
，（实际kernel的形状为 <img src="https://www.zhihu.com/equation?tex=k%5Ctimes+d" alt="[公式]">
）如果不padding的话，那么输出的第一个维度为 <img src="https://www.zhihu.com/equation?tex=n-k%2B1" alt="[公式]">
，因为这里stride是为1的。为了保证输入输出相同，则需要对序列的前后分别padding长度为
<img src="https://www.zhihu.com/equation?tex=%28k-1%29%2F2" alt="[公式]"> 。</li>
<li>大小为 <img src="https://www.zhihu.com/equation?tex=k%5Ctimes+d" alt="[公式]"> 的卷积核一次运算的复杂度为： <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28kd%29" alt="[公式]"> ，一共做了 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]">
次，故复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nkd%29" alt="[公式]"></li>
<li>为了保证第二个维度在第二个维度都相同，故需要 <img src="https://www.zhihu.com/equation?tex=d" alt="[公式]">
个卷积核，所以卷积操作总的时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nkd%5E2%29" alt="[公式]"></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>Seq2Seq</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习（9）Transformer*-p1</title>
    <url>/posts/2NQRYHA/</url>
    <content><![CDATA[<h2><span id="一-李宏毅-transformer_encoder"><strong><font color="red">
一、李宏毅 - Transformer_Encoder </font></strong></span></h2>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614150150803.png" alt="image-20220614150150803" style="zoom:50%;"></p>
<p>变形金刚的英文就是Transformer,那Transformer也跟我们之后会,提到的BERT有非常强烈的关系,所以这边有一个BERT探出头来,代表说Transformer跟BERT,是很有关系的。</p>
<h3><span id="11-sequence-to-sequenceseq2seq">1.1 Sequence-to-sequence
(Seq2seq)</span></h3>
<p>Transformer就是一个,==Sequence-to-sequence==的model,他的缩写,我们会写做==Seq2seq==,那Sequence-to-sequence的model,又是什么呢？</p>
<p>举例来说,Seq2seq一个很好的应用就是 <strong>语音辨识</strong>：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614150604358.png" alt="image-20220614150604358" style="zoom:50%;"></p>
<p>在做语音辨识的时候,输入是声音讯号<strong>,声音讯号其实就是一串的vector</strong>,输出是语音辨识的结果,也就是输出的这段声音讯号,所对应的文字。我们这边用圈圈来代表文字,每一个圈圈就代表,比如说中文里面的一个方块子,今天<strong>输入跟输出的长度,当然是有一些关系,但是却没有绝对的关系</strong>，输入的声音讯号,他的长度是大T,我们并没有办法知道说,根据大T输出的这个长度N一定是多少。<strong>输出的长度由机器自己决定</strong>,由机器自己去听这段声音讯号的内容,自己决定他应该要输出几个文字,他输出的语音辨识结果,输出的句子里面应该包含几个字,由机器自己来决定,这个是语音辨识。</p>
<h3><span id="12-question-answering-qa">1.2 Question Answering (QA)</span></h3>
<p>那事实上Seq2Seq model,在NLP的领域,在natural language
processing的领域的使用,是比你想像的更为广泛,其实很多<strong>natural
language processing的任务,都可以想成是==question
answering,QA==的任务。</strong>Question
Answering,就是给机器读一段文字,然后你问机器一个问题,希望他可以给你一个正确的答案。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614151056373.png" alt="image-20220614151056373" style="zoom:50%;"></p>
<ul>
<li>假设你今天想做的是翻译,那机器读的文章就是一个英文句子,<strong>问题</strong>就是这个句子的德文翻译是什么,然后输出的<strong>答案</strong>就是德文</li>
<li>或者是你想要叫机器自动作摘要,摘要就是给机器读一篇长的文章,叫他把长的文章的重点节录出来,那你就是给机器一段文字,<strong>问题</strong>是这段文字的摘要是什么,然后期待他<strong>答案</strong>可以输出一个摘要</li>
<li>或者是你想要叫机器做Sentiment analysis,Sentiment
analysis就是机器要自动判断一个句子,是正面的还是负面的；假设你有做了一个产品,然后上线以后,你想要知道网友的评价,但是你又不可能一直找人家ptt上面,把每一篇文章都读过,所以就做一个Sentiment
analysis
model,看到有一篇文章里面,有提到你的产品,然后就把这篇文章丢到,你的model里面,去判断这篇文章,是正面还是负面。你就给机器要判断正面还负面的文章,<strong>问题</strong>就是这个句子,是正面还是负面的,然后希望机器可以告诉你<strong>答案</strong></li>
</ul>
<p>必须要强调一下,对多数NLP的任务,或对多数的语音相关的任务而言,往往为这些任务<strong>客制化模型,你会得到更好的结果</strong>。但是各个任务客制化的模型,就不是我们这一门课的重点了,如果你对人类语言处理,包括语音
包括自然语言处理,这些相关的任务有兴趣的话呢,可以参考一下以下课程网页的<a href="Source%20webpage:%20https://speech.ee.ntu.edu.tw/~hylee/dlhlp/2020-spring.html">连结</a>,就是去年上的深度学习,与人类语言处理,这门课的内容里面就会教你,各式各样的任务最好的模型,应该是什么。</p>
<blockquote>
<p>举例来说在做语音辨识,我们刚才讲的是一个Seq2Seq
model,输入一段声音讯号,直接输出文字,今天啊 Google的
pixel4,Google官方告诉你说,Google pixel4也是用,N to N的Neural
network,pixel4里面就是,有一个Neural
network,输入声音讯号,输出就直接是文字。</p>
<p>但他其实用的不是Seq2Seq model,他用的是一个叫做,RNN transducer的
model,像这些模型他就是为了,语音的某些特性所设计,这样其实可以表现得更好,至于每一个任务,有什么样客制化的模型,这个就是另外一门课的主题,就不是我们今天想要探讨的重点。</p>
</blockquote>
<h3><span id="13-seq2seq-for-syntacticparsing">1.3 Seq2seq for Syntactic
Parsing</span></h3>
<p>在语音还有自然语言处理上的应用,其实有很多应用,你<strong>不觉得他是一个Seq2Seq
model的问题,但你都可以硬用Seq2Seq model的问题硬解他</strong>。</p>
<p>举例来说<strong>文法剖析</strong>,给机器一段文字,比如Deep learning is
very powerful</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614151449212.png" alt="image-20220614151449212" style="zoom:50%;"></p>
<p>机器要做的事情是产生,一个<strong>文法的剖析树</strong>
告诉我们,deep加learning合起来,是一个名词片语,very加powerful合起来,是一个形容词片语,形容词片语加is以后会变成,一个动词片语,动词片语加名词片语合起来,是一个句子。</p>
<p>那今天文法剖析要做的事情,就是产生这样子的一个Syntactic
tree,所以在文法剖析的任务里面,假设你想要deep
learning解的话,输入是一段文字,他是一个Sequence,但输出看起来不像是一个Sequence,输出是一个树状的结构,但<strong>事实上一个树状的结构,可以硬是把他看作是一个Sequence</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614151522382.png" alt="image-20220614151522382" style="zoom:50%;"></p>
<p>这个树状结构可以对应到一个,这样子的Sequence,从这个Sequence里面,你也可以看出</p>
<ul>
<li>这个树状的结构有一个S，有一个左括号,有一个右括号</li>
<li>S里面有一个noun phrase,有一个左括号跟右括号</li>
<li>NP里面有一个左括号跟右括号,NP里面有is</li>
<li>然后有这个形容词片语,他有一个左括号右括号</li>
</ul>
<p>这一个<strong>Sequence就代表了这一个tree
的structure</strong>,你先把tree
的structure,转成一个Sequence以后,你就可以用Seq2Seq
model硬解他。train一个Seq2Seq
model,读这个句子,然后直接输入这一串文字,再把这串文字转成一个树状的结构,你就可以硬是用Seq2Seq
model,来做文法剖析这件事,这个概念听起来非常的狂,但这是真的可以做得到的。</p>
<h3><span id="14multi-label-classification"><strong><font color="red"> 1.4
multi-label classification</font></strong></span></h3>
<p>还有一些任务可以用seq2seq's model,举例来说
==multi-label的classification==。==multi-class==的classification,跟==multi-label==的classification,听起来名字很像,但他们其实是不一样的事情,multi-class的classification意思是说,我们有不只一个class机器要做的事情,是从数个class里面,选择某一个class出来。</p>
<p>但是multi-label的classification,意思是说<strong>同一个东西,它可以属于多个class</strong>,举例来说
你在做文章分类的时候。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614151845511.png" alt="image-20220614151845511" style="zoom:50%;"></p>
<p>可能这篇文章 属于class 1跟3,这篇文章属于class 3 9
17等等,你可能会说,这种multi-label
classification的问题,能不能<strong>直接把它当作一个multi-class
classification的问题来解</strong></p>
<p>举例来说,我把这些文章丢到一个classifier里面：</p>
<ul>
<li><strong>本来classifier只会输出一个答案,输出分数最高的那个答案</strong></li>
<li><strong>我现在就输出分数最高的前三名,看看能不能解,multi-label的classification的问题</strong></li>
</ul>
<p>但<strong>这种方法可能是行不通的</strong>,因为每一篇文章对应的class的数目,根本不一样
有些东西 有些文章,对应的class的数目,是两个 有的是一个 有的是三个。所以
如果你说 我直接取一个threshold,我直接取分数最高的前三名,class file
output分数最高的前三名,来当作我的输出 显然,不一定能够得到好的结果
那怎么办呢？</p>
<p>这边可以用seq2seq硬做,<strong>输入一篇文章</strong>
<strong>输出就是class</strong> 就结束了,机器自己决定
它要输出几个class。我们说seq2seq
model,就是由机器自己决定输出几个东西,输出的output
sequence的长度是多少,既然你没有办法决定class的数目,那就让机器帮你决定,每篇文章
要属于多少个class。</p>
<h3><span id="15-encoder-decoder">1.5 Encoder-Decoder</span></h3>
<p><strong><font color="red">
我们现在就是要来学,怎么做seq2seq这件事,一般的seq2seq's
model,它里面会分成两块一块是Encoder,另外一块是Decoder。</font></strong></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614152636868.png" alt="image-20220614152636868" style="zoom:50%;"></p>
<p>你input一个sequence有Encoder,负责处理这个sequence,再把处理好的结果丢给Decoder,由Decoder决定,它要输出什么样的sequence,等一下
我们都还会再细讲,Encoder跟 Decoder内部的架构。seq2seq
model的起源,其实非常的早 在14年的9月,就有一篇seq2seq's
model,用在翻译的文章 被放到Arxiv上。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614152900181.png" alt="image-20220614152900181" style="zoom:50%;"></p>
<p><strong>可以想像当时的seq2seq's
model,看起来还是比较年轻的,今天讲到seq2seq's
model的时候,大家第一个会浮现在脑中的,可能都是我们今天的主角,也就是transformer</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614152931023.png" alt="image-20220614152931023" style="zoom: 50%;"></p>
<p>它有一个Encoder架构,有一个Decoder架构,它里面有很多花花绿绿的block,等一下就会讲一下,这里面每一个花花绿绿的block,分别在做的事情是什么。</p>
<h3><span id="151-encoder">1.5.1 Encoder</span></h3>
<p><strong><font color="red"> seq2seq model
==Encoder==要做的事情,就是给一排向量，输出另外一排向量</font></strong></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614153244524.png" alt="image-20220614153244524" style="zoom:50%;"></p>
<p>给一排向量、输出一排向量这件事情,很多模型都可以做到,可能第一个想到的是,我们刚刚讲完的self-attention,其实不只self-attention,RNN
CNN 其实也都能够做到,input一排向量, output另外一个同样长度的向量。</p>
<p>在transformer里面,transformer的Encoder,用的就是self-attention,
这边看起来有点复杂,我们用另外一张图,来仔细地解释一下,这个Encoder的架构,等一下再来跟原始的transformer的,论文里面的图进行比对。</p>
<p>现在的Encoder里面,会<strong>分成很多很多的block</strong>：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614153801973.png" alt="image-20220614153801973" style="zoom:50%;"></p>
<p>每一个block都是输入一排向量,输出一排向量,你输入一排向量
第一个block,第一个block输出另外一排向量,再输给另外一个block,到最后一个block,会输出最终的vector
sequence,<strong>每一个block 其实,并不是neural
network的一层</strong>。</p>
<p><strong>每一个block里面做的事情,是好几个layer在做的事情</strong>,在transformer的Encoder里面,每一个block做的事情,大概是这样子的：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614153842957.png" alt="image-20220614153842957" style="zoom:50%;"></p>
<ul>
<li><strong><font color="red">先做一个self-attention,input一排vector以后,做self-attention,考虑整个sequence的资讯，Output另外一排vector。</font></strong></li>
<li><strong><font color="red"> 接下来这一排vector,会再丢到fully
connected的feed forward
network里面,再output另外一排vector,这一排vector就是block的输出。</font></strong></li>
</ul>
<h4><span id="multi-self-attention-residual-connection">Multi-self-attention +
residual connection</span></h4>
<p>事实上在原来的<strong>transformer里面,它做的事情是更复杂的</strong>。在之前self-attention的时候,我们说
输入一排vector,就输出一排vector,这边的每一个vector,它是<strong>考虑了所有的input以后</strong>,所得到的结果：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614154211285.png" alt="image-20220614154211285" style="zoom:50%;"></p>
<p>在transformer里面,它加入了一个设计,我们<strong>不只是输出这个vector</strong>,我们还要<strong>把这个vector加上它的input</strong>,它要把input拉过来
直接加给输出,得到新的output。也就是说,这边假设这个vector叫做<span class="math inline">\(a\)</span>,这个vector叫做<span class="math inline">\(b\)</span> 你要把<span class="math inline">\(a+b\)</span>当作是新的输出。</p>
<p><strong><font color="red"> 这样子的network架构,叫做==residual
connection==,那其实这种residual connection</font></strong>,在deep
learning的领域用的是非常的广泛,之后如果我们有时间的话,再来详细介绍,为什么要用residual
connection。</p>
<p>那你现在就先知道说,有一种network设计的架构,叫做<strong>residual
connection,它会把input直接跟output加起来,得到新的vector。</strong></p>
<h4><span id="norm">Norm</span></h4>
<p>得到<strong>residual</strong>的结果以后,再把它做一件事情叫做<strong>normalization</strong>,这边用的不是batch
normalization,这边用的叫做==<strong>layer normalization</strong>==。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614155147989.png" alt="image-20220614155147989" style="zoom:50%;"></p>
<p>layer normalization做的事情,比bacth
normalization更简单一点。输入一个向量，输出另外一个向量,不需要考虑batch,它会<strong>把输入的这个向量,计算它的mean跟standard
deviation</strong>。</p>
<p>但是要注意一下,<strong>==batch
normalization==是对不同example,不同feature的同一个dimension,去计算mean跟standard
deviation</strong>。但<strong>==layer
normalization==,它是对同一个feature,同一个example里面,不同的dimension,去计算mean跟standard
deviation</strong></p>
<p>计算出mean,跟standard deviation以后,就可以做一个normalize,我们把input
这个vector里面每一个,dimension减掉mean,再除以standard
deviation以后得到x',就是layer normalization的输出。 <span class="math display">\[
x&#39;_i=\frac{x_i-m}{\sigma}
\]</span> <strong>得到layer normalization的输出以后,它的这个输出，才是FC
network的输入。</strong></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614155555973.png" alt="image-20220614155555973" style="zoom:50%;"></p>
<p>而<strong>FC network这边,也有residual的架构</strong>,所以 我们会把FC
network的input,跟它的output加起来做一下residual,得到新的输出。这个FC
network做完residual以后,还不是结束
你要把residual的结果,<strong>再做一次layer
normalization</strong>,得到的输出,才是residual
network里面,一个block的输出。</p>
<p><img src="https://github.com/unclestrong/DeepLearning_LHY21_Notes/blob/master/Notes_pic/image-20210429212721750.png?raw=true" alt="image-20210429212721750" style="zoom:50%;"></p>
<ul>
<li>首先有self-attention,其实在input的地方,还有加上<strong>positional
encoding</strong>,我们之前已经有讲过,如果你只光用self-attention,你没有未知的资讯,所以你需要加上positional的information,然后在这个图上,有特别画出positional的information。</li>
<li><strong>Multi-Head
Attention</strong>,这个就是self-attention的block,这边有特别强调说,它是Multi-Head的self-attention。</li>
<li><strong>Add&amp;norm</strong>,就是residual加layer
normalization,我们刚才有说self-attention,有加上residual的connection,加下来还要过<strong>layer
normalization</strong>,这边这个图上的Add&amp;norm,就是residual加layer
norm的意思。</li>
<li>接下来,要过<strong>feed forward network</strong>，fc的feed forward
network以后再做一次<strong>Add&amp;norm</strong>,再做一次residual加layer
norm,才是一个block的输出。</li>
</ul>
<p>然后这个block会重复n次,这个复杂的block,其实在之后会讲到的,一个非常重要的模型BERT里面,会再用到
BERT,它其实就是transformer的encoder。</p>
<h2><span id="to-learn-more">To Learn more</span></h2>
<p>讲到这边 你心里一定充满了问号,就是为什么
transformer的encoder,要这样设计 不这样设计行不行?</p>
<p>行
不一定要这样设计,这个encoder的network架构,现在设计的方式,本文是按照原始的论文讲给你听的,但<strong>原始论文的设计
不代表它是最好的,最optimal的设计</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220614155914421.png" alt="image-20220614155914421" style="zoom:50%;"></p>
<ul>
<li>有一篇文章叫,<a href="https://arxiv.org/abs/2002.04745">on layer
normalization in the transformer
architecture</a>，它问的问题就是<strong>为什么,layer
normalization是放在那个地方呢,</strong>为什么我们是先做,residual再做layer
normalization,能不能够把layer
normalization,放到每一个block的input,也就是说 你做residual以后,再做layer
normalization,再加进去
你可以看到说左边这个图,是原始的transformer,右边这个图是稍微把block,更换一下顺序以后的transformer,更换一下顺序以后
结果是会比较好的,这就代表说,原始的transformer
的架构,并不是一个最optimal的设计,你永远可以思考看看,有没有更好的设计方式</li>
<li><strong><font color="red"> 再来还有一个问题就是,为什么是layer norm
为什么是别的,不是别的,为什么不做batch
normalization</font></strong>,也许这篇paper可以回答你的问题,这篇paper是<a href="https://arxiv.org/abs/2003.07845">Power Norm：,Rethinking Batch
Normalization In Transformers</a>,它首先告诉你说 为什么,batch
normalization不如,layer normalization,在Transformers里面为什么,batch
normalization不如,layer
normalization,接下来在说,它提出来一个<strong>power
normalization</strong>,一听就是很power的意思,都可以比layer
normalization,还要performance差不多或甚至好一点。</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>Seq2Seq</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习（9）Transformer*-p2</title>
    <url>/posts/S7AAWG/</url>
    <content><![CDATA[<h2><span id="二-李宏毅-transformer_decoder-p2">二、李宏毅 -
Transformer_decoder P2</span></h2>
<h3><span id="21-decoder-autoregressiveat">2.1 Decoder – Autoregressive
(AT)</span></h3>
<p>Decoder其实有两种,接下来会花比较多时间介绍,比较常见的
==<strong>Autoregressive Decoder（自回归解码器）</strong>==,这个
Autoregressive 的 Decoder,是怎么运作的。</p>
<p>用<strong>语音辨识</strong>,来当作例子来说明,或用在作业里面的<strong>机器翻译</strong>,其实是一模一样的,你只是把输入输出,改成不同的东西而已。<strong>语音辨识</strong>就是<strong>输入一段声音,输出一串文字</strong>,你会把一段声音输入给
Encoder,比如说你对机器说,机器学习,机器收到一段声音讯号,声音讯号 进入
Encoder以后,输出会是什么,输出会变成一排 Vector。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615160428118.png" alt="image-20220615160428118" style="zoom:50%;"></p>
<p><strong>Encoder</strong> 做的事情,就是<strong>输入一个 Vector
Sequence</strong>,<strong>输出另外一个 Vector
Sequence</strong>。接下来,就轮到 Decoder 运作了,<strong>Decoder
要做的事情就是产生输出</strong>,也就是<strong>产生语音辨识的结果</strong>,</p>
<h4><span id="decoder怎么产生这个语音辨识的结果">Decoder
怎么产生这个语音辨识的结果？</span></h4>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615160726062.png" alt="image-20220615160726062" style="zoom:50%;"></p>
<p>Decoder 做的事情,就是<strong>把 Encoder
的输出先读进去</strong>,至于怎么读进去,这个我们等一下再讲
我们先,你先假设 Somehow 就是有某种方法,把 Encoder 的输出读到 Decoder
里面,这步我们等一下再处理。</p>
<h4><span id="decoder-怎么产生一段文字">Decoder 怎么产生一段文字？</span></h4>
<p><strong>首先,你要先给它一个特殊的符号,这个特殊的符号,代表开始,在助教的投影片里面,是写
Begin Of Sentence,缩写是 BOS</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615160908630.png" alt="image-20220615160908630" style="zoom:50%;"></p>
<p>BOS就是 Begin 的意思,这个是一个 Special 的 Token,你就是在你的个
Lexicon 里面,你就在你可能,本来 Decoder
可能产生的文字里面,多加一个特殊的字,这个字就代表了
BEGIN,代表了开始这个事情。</p>
<p>在这个机器学习里面,假设你要处理 NLP 的问题,<strong>每一个
Token,你都可以把它用一个 One-Hot 的 Vector 来表示</strong>,One-Hot
Vector 就其中一维是 1,其他都是 0,所以 <strong>BEGIN 也是用 One-Hot
Vector 来表示</strong>,其中一维是 1,其他是 0。<strong><font color="red">
接下来Decoder 会吐出一个向量,这个 Vector 的长度很长,跟你的 Vocabulary 的
Size 是一样的。</font></strong></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615161211480.png" alt="image-20220615161211480" style="zoom:50%;"></p>
<blockquote>
<p>#### Vocabulary Size 则是什么意思?</p>
<p>你就先想好说,你的 Decoder
<strong>输出的单位</strong>是什么,假设我们今天做的是中文的语音辨识,我们
Decoder 输出的是中文,你这边的 Vocabulary 的 Size
,可能就是中文的方块字的数目。用 Subword
当作英文的单位,就有一些方法,可以把英文的字首字根切出来,拿字首字根当作单位,如果中文的话,我觉得就比较单纯,通常今天你可能就用中文的这个方块字,来当作单位。</p>
<p>每一个中文的字,都会对应到一个数值,因为在<strong>产生这个向量之前,你通常会先跑一个
Softmax</strong>,就跟做分类一样,所以这一个向量里面的分数,它是一个
Distribution,也就是,它这个向量里面的值,它全部加起来,总和 会是 1</p>
</blockquote>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615162226148.png" alt="image-20220615162226148" style="zoom:50%;"></p>
<p><strong>分数最高的一个中文字,它就是最终的输出</strong>。在这个例子里面,机的分数最高,所以机,就当做是这个
Decoder 第一个输出。然后接下来,你<strong>把“机”当做是 Decoder 新的
Input</strong>,原来 Decoder 的 Input,只有 BEGIN
这个特别的符号,现在它除了 BEGIN 以外,它还有“机”作为它的 Input。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615162308793.png" alt="image-20220615162308793" style="zoom:50%;"></p>
<p>所以 Decoder <strong>现在它有两个输入</strong></p>
<ul>
<li>一个是 <strong>BEGIN</strong> 这个符号</li>
<li>一个是<strong>“机”</strong></li>
</ul>
<p>根据这两个输入,它输出一个蓝色的向量,根据这个蓝色的向量里面,给每一个中文的字的分数,我们会决定第二个输出，哪一个字的分数最高,它就是输出,假设"器"的分数最高,<strong>"器"就是输出</strong>。</p>
<p>然后现在 Decoder</p>
<ul>
<li>看到了 BEGIN</li>
<li>看到了"机"</li>
<li>看到了"器"</li>
</ul>
<p>它接下来,还要再决定接下来要输出什么,它可能,就输出"学",这一个过程就反覆的持续下去</p>
<p>所以现在 Decode</p>
<ul>
<li><p>看到了 BEGIN</p></li>
<li><p>看到了"机"</p></li>
<li><p>看到了"器"</p></li>
<li><p>还有"学"</p></li>
</ul>
<p><strong>Encoder 这边其实也有输入</strong>,等一下再讲 Encoder
的输入,Decoder 是怎么处理的,所以 Decoder 看到 Encoder
这边的输入,看到"机" 看到"器"
看到"学",决定接下来输出一个向量,这个向量里面,"习"这个中文字的分数最高的,所以它就输出"习"。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615162732493.png" alt="image-20220615162732493" style="zoom:50%;"></p>
<p><strong>然后这个 Process
,就反覆持续下去</strong>,这边有一个关键的地方,我们特别用红色的虚线把它标出来。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615162754592.png" alt="image-20220615162754592" style="zoom:50%;"></p>
<p><strong><font color="red"> Decoder
看到的输入,其实是它在前一个时间点自己的输出,Decoder
会把自己的输出,当做接下来的输入。</font></strong></p>
<blockquote>
<p>如果Decoder 看到<strong>错误的输入</strong>,让 Decoder
看到自己产生出来的错误的输入,再被 Decoder 自己吃进去,会不会造成 ==Error
Propagation== 的问题.</p>
<p>Error Propagation 的问题就是,<strong>一步错
步步错</strong>这样,就是在这个地方,如果不小心把机器的“器”,不小心写成天气的"气",会不会接下来就整个句子都坏掉了,都没有办法再产生正确的词汇了?</p>
<p>有可能,这个等一下,我们最后会稍微讲一下,这个问题要怎么处理,我们现在,先无视这个问题,继续走下去</p>
</blockquote>
<p>我们来看一下这个 <strong>Decoder内部的结构</strong>长什么样子?</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615162953318.png" alt="image-20220615162953318" style="zoom:50%;"></p>
<p>那我们这边,<strong>把 Encoder 的部分先暂时省略掉</strong>,那在
Transformer 里面,Decoder 的结构,长得是这个样子的,看起来有点复杂,比
Encoder 还稍微复杂一点,那我们现在先把 Encoder 跟 Decoder 放在一起。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615163023898.png" alt="image-20220615163023898" style="zoom:50%;"></p>
<p>稍微比较一下它们之间的差异,那你会发现说,如果我们把 Decoder
中间这一块,<strong>中间这一块把它盖起来,其实 Encoder 跟
Decoder,并没有那么大的差别</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615163100379.png" alt="image-20220615163100379" style="zoom:50%;"></p>
<p>你看 Encoder 这边,<strong>Multi-Head Attention</strong>,然后
<strong>Add &amp; Norm</strong>,<strong>Feed Forward,Add &amp;
Norm</strong>,重复 N 次,Decoder 其实也是一样。</p>
<p>当我们把中间这一块遮起来以后,我们等一下再讲,遮起来这一块里面做了什么事,但当我们把中间这块遮起来以后,
那 Decoder 也是,有一个 Multi-Head Attention,Add &amp; Norm,然后 Feed
Forward,然后 Add &amp; Norm,所以 Encoder 跟
Decoder,其实并没有非常大的差别,除了中间这一块不一样的地方,那只是最后,我们可能会再做一个
Softmax,使得它的输出变成一个机率,那这边有一个<strong>稍微不一样的地方</strong>是,在
Decoder 这边,Multi-Head Attention 这一个 Block 上面,还<strong>加了一个
==Masked==</strong>,</p>
<p>这个 Masked 的意思是这样子的,这是我们原来的 Self-Attention ，Input
一排 Vector,Output 另外一排 Vector,这一排 Vector
<strong>每一个输出</strong>,都要看过完整的 Input 以后,才做决定,所以输出
<span class="math inline">\(b^1\)</span> 的时候,其实是根据 <span class="math inline">\(a^1\)</span> 到 <span class="math inline">\(a^4\)</span> 所有的资讯,去输出 <span class="math inline">\(b^1\)</span>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615163239723.png" alt="image-20220615163239723" style="zoom:50%;"></p>
<p><strong><font color="red"> 当我们把 Self-Attention,转成 Masked
Attention 的时候,它的不同点是,现在我们不能再看右边的部分,也就是产生
<span class="math inline">\(b^1\)</span> 的时候,我们只能考虑 <span class="math inline">\(a^1\)</span> 的资讯,你不能够再考虑 <span class="math inline">\(a^2\)</span> <span class="math inline">\(a^3\)</span> <span class="math inline">\(a^4\)</span></font></strong>。产生 <span class="math inline">\(b^2\)</span> 的时候,你只能考虑 <span class="math inline">\(a^1\)</span> <span class="math inline">\(a^2\)</span> 的资讯,不能再考虑 <span class="math inline">\(a^3\)</span> <span class="math inline">\(a^4\)</span> 的资讯。产生 <span class="math inline">\(b^3\)</span> 的时候,你就不能考虑 <span class="math inline">\(a^4\)</span> 的资讯。产生 <span class="math inline">\(b^4\)</span> 的时候,你可以用整个 Input Sequence
的资讯,这个就是 Masked 的 Self-Attention。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615163708618.png" alt="image-20220615163708618" style="zoom:50%;"></p>
<p>讲得更具体一点,你做的事情是,当我们要产生 <span class="math inline">\(b^2\)</span> 的时候,我们只拿第二个位置的 Query
<span class="math inline">\(b^2\)</span>,去跟第一个位置的
Key,和第二个位置的 Key,去计算
Attention,第三个位置跟第四个位置,就不管它,不去计算 Attention。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615163452245.png" alt="image-20220615163452245" style="zoom:50%;"></p>
<p>我们这样子不去管这个 <span class="math inline">\(a^2\)</span>
右边的地方,只考虑 <span class="math inline">\(a^1\)</span> 跟 <span class="math inline">\(a^2\)</span>,只考虑 <span class="math inline">\(q^1\)</span> <span class="math inline">\(q^2\)</span>,只考虑 <span class="math inline">\(k^1\)</span> <span class="math inline">\(k^2\)</span>,<span class="math inline">\(q^2\)</span> 只跟 <span class="math inline">\(k^1\)</span> 跟 <span class="math inline">\(k^2\)</span> 去计算 Attention,然后最后只计算 <span class="math inline">\(b^1\)</span> 跟 <span class="math inline">\(b^2\)</span> 的 Weighted Sum。然后当我们输出这个
<span class="math inline">\(b^2\)</span> 的时候,<span class="math inline">\(b^2\)</span> 就只考虑了 <span class="math inline">\(a^1\)</span> 跟 <span class="math inline">\(a^2\)</span>,就没有考虑到 <span class="math inline">\(a^3\)</span> 跟 <span class="math inline">\(a^4\)</span>。</p>
<h4><span id="那为什么会这样为什么需要加-masked"><strong><font color="red">
那为什么会这样,为什么需要加 Masked ？</font></strong></span></h4>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615163642567.png" alt="image-20220615163642567" style="zoom:50%;"></p>
<p>这件事情其实非常地直觉:我们一开始 Decoder
的运作方式,它是<strong>一个一个输出</strong>,所以是先有 <span class="math inline">\(a^1\)</span> 再有 <span class="math inline">\(a^2\)</span>,再有 <span class="math inline">\(a^3\)</span> 再有 <span class="math inline">\(a^4\)</span>。<strong>这跟原来的 Self-Attention
不一样</strong>,原来的 Self-Attention,<span class="math inline">\(a^1\)</span> 跟 <span class="math inline">\(a^4\)</span> 是一次整个输进去你的 Model
里面的,在我们讲 Encoder 的时候,Encoder 是一次把 <span class="math inline">\(a^1\)</span> 跟 <span class="math inline">\(a^4\)</span>,都整个都读进去。但是对 Decoder
而言,先有 <span class="math inline">\(a^1\)</span> 才有 <span class="math inline">\(a^2\)</span>,才有 <span class="math inline">\(a^3\)</span> 才有 <span class="math inline">\(a^4\)</span>,所以实际上,当你有 <span class="math inline">\(a^2\)</span>,你要计算 <span class="math inline">\(b^2\)</span> 的时候,你是没有 <span class="math inline">\(a^3\)</span> 跟 <span class="math inline">\(a^4\)</span> 的,所以你根本就没有办法把 <span class="math inline">\(a^3\)</span> <span class="math inline">\(a^4\)</span> 考虑进来。</p>
<p>所以这就是为什么,在那个 Decoder 的那个图上面,Transformer 原始的 Paper
特别跟你强调说,<strong>那不是一个一般的 Attention,</strong>
<strong><font color="red"> 这是一个 Masked 的
Self-Attention,意思只是想要告诉你说,Decoder 它的
Tokent,它输出的东西是一个一个产生的,所以它只能考虑它左边的东西,它没有办法考虑它右边的东西。</font></strong></p>
<p>讲了 Decoder
的运作方式,但是这边,还有一个非常关键的问题,<strong>Decoder
必须自己决定,输出的 Sequence 的长度</strong></p>
<p>可是到底输出的 Sequence 的长度应该是多少,我们不知道。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615164352622.png" alt="image-20220615164352622" style="zoom:50%;"></p>
<p>你没有办法轻易的从输入的 Sequence 的长度,就知道输出的 Sequence
的长度是多少,并不是说,输入是 4 个向量,输出一定就是 4
个向量。这边在这个例子里面,输入跟输出的长度是一样的,但是你知道实际上在你真正的应用里面,并不是这样,输入跟输出长度的关係,是非常复杂的,我们其实是期待机器可以自己学到,今天给它一个
Input Sequence 的时候,Output 的 Sequence 应该要多长。</p>
<p>但在我们目前的这整个
Decoder的这个运作的机制里面,<strong>机器不知道它什么时候应该停下来</strong>,它产生完习以后,它还可以继续重复一模一样的
Process,就把习,当做输入,然后也许 Decoder
,就会接一个惯,然后接下来,就一直持续下去,<strong>永远都不会停下来</strong>。</p>
<p><strong><font color="red"> 我们要让 Decoder
做的事情,也是一样,要让它可以输出一个断,所以你要特别准备一个特别的符号,这个符号,就叫做断,我们这边,用
END 来表示这个特殊的符号。</font></strong></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615164518484.png" alt="image-20220615164518484" style="zoom:50%;"></p>
<p>所以除了所有中文的方块字,还有 BEGIN
以外,你还要<strong>准备一个特殊的符号,叫做"断"</strong>,那其实在助教的程式里面,它是把
BEGIN 跟 END,就是开始跟这个断,用同一个符号来表示。</p>
<p>反正这个,这个 BEGIN
只会在输入的时候出现,断只会在输出的时候出现,所以在助教的程式里面,如果你仔细研究一下的话,会发现说
END 跟
BEGIN,用的其实是同一个符号,但你用不同的符号,也是完全可以的,也完全没有问题</p>
<p>所以我们现在,当把"习"当作输入以后,就 Decoder 看到 Encoder 输出的这个
Embedding,看到了 "BEGIN",然后"机" "器" "学" "习"以后,看到这些资讯以后
它要知道说,这个语音辨识的结果已经结束了,不需要再产生更多的词汇了。</p>
<p>它产生出来的向量END,就是断的那个符号,它的机率必须要是最大的,然后你就输出断这个符号,那整个运作的过程,整个
Decoder 产生 Sequence 的过程,就结束了这个就是 ==Autoregressive
Decoder==,它运作的方式。</p>
<h3><span id="22-decoder-non-autoregressivenat">2.2 Decoder – Non-autoregressive
(NAT)</span></h3>
<p>Non-Autoregressive ,通常缩写成 NAT,所以有时候 Autoregressive 的
Model,也缩写成 AT,Non-Autoregressive 的 Model
是怎么运作的。<strong>先输入 BEGIN</strong>,<strong>然后</strong>出现
w1,然后<strong>再</strong>把 w1 当做输入,<strong>再</strong>输出
w2,<strong>直到输出 END 为止</strong></p>
<p>那 ==NAT== 是这样,它<strong>不是依次产生</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615164801974.png" alt="image-20220615164801974" style="zoom:50%;"></p>
<p>就假设我们现在产生是中文的句子,它不是依次产生一个字,它是<strong>一次把整个句子都产生出来</strong>。NAT
的 Decoder<strong>可能吃的是一整排的 BEGIN 的
Token</strong>,你就把一堆一排 BEGIN 的 Token 都丢给它,让它一次产生一排
Token 就结束了</p>
<p>举例来说,如果你丢给它 4 个 BEGIN 的 Token,它就产生 4
个中文的字,变成一个句子,就结束了，所以它只要一个步骤,就可以完成句子的生成，这边你可能会问一个问题：刚才不是说不知道输出的长度应该是多少吗,那我们这边<strong>怎么知道
BEGIN 要放多少个</strong>,当做 NAT Decoder 的收入？</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615172838842.png" alt="image-20220615172838842" style="zoom:50%;"></p>
<p>没错
这件事没有办法很自然的知道,没有办法很直接的知道,所以有几个,所以有几个做法</p>
<ul>
<li>一个做法是,你<strong>另外learn一个 Classifier</strong>,这个
Classifier ,它吃 Encoder 的 Input,然后输出是一个数字,这个数字代表
Decoder 应该要输出的长度,这是一种可能的做法</li>
<li>另一种可能做法就是,你就不管三七二十一,<strong>给它一堆 BEGIN 的
Token</strong>,你就假设说,你现在输出的句子的长度,绝对不会超过 300
个字,你就假设一个句子长度的上限,然后 BEGIN ,你就给它 300 个
BEGIN,然后就会输出 300 个字嘛,然后,你再看看<strong>什么地方输出
END</strong>,输出 END 右边的,就当做它没有输出,就结束了,这是另外一种处理
NAT 的这个 Decoder,它应该输出的长度的方法</li>
</ul>
<p>NAT 的
Decoder,最近它之所以是一个热门研究主题,就是它虽然表面上看起来有种种的厉害之处,尤其是<strong>平行化是它最大的优势</strong>,但是
<strong>NAT 的 Decoder ,它的 Performance,往往都不如 AT 的
Decoder</strong>。</p>
<h3><span id="23-encoder-decoder">2.3 Encoder-Decoder</span></h3>
<p>接下来就要讲<strong>Encoder 跟
Decoder它们中间是怎么传递资讯</strong>的了,也就是我们要讲,刚才我们刻意把它遮起来的那一块。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615173000109.png" alt="image-20220615173000109"></p>
<p><strong><font color="red"> 这块叫做 ==Cross Attention==,它是连接
Encoder 跟 Decoder 之间的桥樑,那这一块里面啊,会发现有两个输入来自于
Encoder,Encoder 提供两个箭头,然后 Decoder
提供了一个箭头,所以从左边这两个箭头,Decoder 可以读到 Encoder
的输出。</font></strong></p>
<p>那这个模组实际上是怎么运作的呢,那我们就实际把它运作的过程跟大家展示一下，这个是你的
Encoder：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615173054575.png" alt="image-20220615173054575" style="zoom:50%;"></p>
<p>输入一排向量,输出一排向量,我们叫它 <span class="math inline">\(a^1
a^2 a^3\)</span>。</p>
<p>接下来 轮到你的 Decoder,你的 Decoder 呢,会先吃 BEGIN 当做,BEGIN 这个
Special 的 Token,那 BEGIN 这个 Special 的 Token 读进来以后,你可能会经过
Self-Attention,这个 Self-Attention 是有做 Mask 的,然后得到一个向量,就是
<strong>Self-Attention 就算是有做
Mask,还是一样输入多少长度的向量,输出就是多少向量</strong>。</p>
<p>所以输入一个向量
输出一个向量,然后接下来把这个向量呢,乘上一个矩阵做一个
Transform,得到一个 Query 叫做 q：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615173148542.png" alt="image-20220615173148542" style="zoom:50%;"></p>
<p>然后这边的 <span class="math inline">\(a^1 a^2 a^3\)</span>
呢,也都产生 Key,Key1 Key2 Key3,那把这个 q 跟 <span class="math inline">\(k^1 k^2 k^3\)</span>,去计算 Attention 的分数,得到
<span class="math inline">\(α_1 α_2 α_3\)</span>,当然你可能一样会做
Softmax,把它稍微做一下 Normalization,所以我这边加一个 ',代表它可能是做过
Normalization。接下来再把 <span class="math inline">\(α_1 α_2
α_3\)</span>,就乘上 <span class="math inline">\(v^1 v^2
v^3\)</span>,再把它 Weighted Sum 加起来会得到 v。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615173220252.png" alt="image-20220615173220252" style="zoom:50%;"></p>
<p>那这一个 V,就是接下来会丢到 Fully-Connected 的,Network
做接下来的处理,那这个步骤就是 q 来自于 Decoder,k 跟 v 来自于
Encoder,这个步骤就叫做 Cross Attention。 <strong><font color="red">
Decoder 就是凭藉著产生一个 q,去 Encoder 这边抽取资讯出来,当做接下来的
Decoder 的,Fully-Connected 的 Network 的 Input。</font></strong></p>
<p>当然这个,就现在假设产生第二个,第一个这个中文的字产生一个“机”,接下来的运作也是一模一样的。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615173332499.png" alt="image-20220615173332499" style="zoom:50%;"></p>
<p>输入 BEGIN 输入机,产生一个向量,这个向量一样乘上一个 Linear 的
Transform,得到 q',得到一个 Query,这个 Query 一样跟 <span class="math inline">\(k^1 k^2 k^3\)</span>,去计算 Attention
的分数,一样跟 <span class="math inline">\(v^1 v^2 v^3\)</span> 做
Weighted Sum 做加权,然后加起来得到 v',交给接下来 Fully-Connected Network
做处理，所以这就是Cross Attention 的运作的过程。</p>
<p>也许有人会有<strong>疑问</strong>：那这个 Encoder 有很多层啊,Decoder
也有很多层啊,从刚才的讲解里面好像听起来,这个 Decoder
不管哪一层,都是<strong>拿 Encoder
的最后一层的输出</strong>这样对吗？</p>
<p>对,<strong>在原始 Paper
里面的实做是这样子</strong>,那一定要这样吗？</p>
<p><strong>不一定要这样</strong>,你永远可以自己兜一些新的想法,所以我这边就是引用一篇论文告诉你说,也有人尝试不同的
Cross Attension 的方式。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615173812815.png" alt="image-20220615173812815" style="zoom:50%;"></p>
<p>Encoder 这边有很多层,Decoder 这边有很多层,为什么 Decoder
这边每一层都一定要看,Encoder
的最后一层输出呢,能不能够有各式各样不同的连接方式,这完全可以当做一个研究的问题来
Study。</p>
<h3><span id="24-training">2.4 Training</span></h3>
<p>已经清楚说 Input 一个
Sequence,是怎么得到最终的输出,那接下来就进入训练的部分。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615173844330.png" alt="image-20220615173844330" style="zoom:50%;"></p>
<p>刚才讲的都还只是,假设你模型训练好以后它是怎么运作的,它是怎么做
Testing 的,它是怎么做 Inference 的,Inference 就是 Testing
，那是怎么做训练的呢？</p>
<p>接下来就要讲怎么做训练,那如果是做语音辨识,那你要有<strong>训练资料</strong>,你要收集一大堆的声音讯号,每一句声音讯号都要有工读生来听打一下,打出说它的这个对应的词汇是什么？</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615173903283.png" alt="image-20220615173903283"></p>
<p>工读生听这段是机器学习,他就把机器学习四个字打出来,所以就知道说你的这个
Transformer,应该要学到
听到这段声音讯号,它的输出就是机器学习这四个中文字。</p>
<p>那怎么让机器学到这件事呢?
我们已经知道说输入这段声音讯号,第一个应该要输出的中文字是“机”,所以今天当我们把
BEGIN,丢给这个 Encoder 的时候,它第一个输出应该要跟“机”越接近越好。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615174107627.png" alt="image-20220615174107627" style="zoom:50%;"></p>
<p><strong>“机”这个字会被表示成一个 One-Hot 的 Vector</strong>,在这个
Vector 里面,只有机对应的那个维度是 1,其他都是 0,这是正确答案,那我们的
Decoder,它的输出是一个
Distribution,是一个机率的分布,我们会希望这一个机率的分布,跟这个 One-Hot
的 Vector 越接近越好。所以你会去计算这个 Ground Truth,跟这个
Distribution 它们之间的 Cross Entropy,然后我们希望这个 ==Cross Entropy==
的值,越小越好。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615174938615.png" alt="image-20220615174938615" style="zoom:50%;"></p>
<p>它就<strong>跟分类很像</strong>,刚才助教在讲解作业的时候也有提到这件事情,你可以想成每一次我们在产生,每一次
Decoder
在产生一个中文字的时候,其实就是做了一次分类的问题,中文字假设有四千个,那就是<strong>做有四千个类别的分类的问题</strong></p>
<p>所以实际上训练的时候这个样子,我们已经知道输出应该是“机器学习”这四个字,就告诉你的
Decoder ,现在你第一次的输出 第二次的输出,第三次的输出
第四次输出,应该分别就是“机” “器” “学”跟“习”,这四个中文字的 One-Hot
Vector,我们<strong>希望我们的输出,跟这四个字的 One-Hot Vector
越接近越好</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615175011374.png" alt="image-20220615175011374" style="zoom:50%;"></p>
<p><strong><font color="red"> 在训练的时候,每一个输出都会有一个 Cross
Entropy,每一个输出跟 One-Hot Vector,跟它对应的正确答案都有一个 Cross
Entropy,我们要希望所有的 Cross Entropy
的总和最小越小越好。</font></strong>所以这边做了四次分类的问题,我们希望这些分类的问题,它总合起来的
Cross Entropy 越小越好,<strong>还有 END 这个符号</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615175531572.png" alt="image-20220615175531572" style="zoom:50%;"></p>
<p>那这个就是 Decoder 的训练，<strong>把 Ground Truth ,正确答案给它,希望
Decoder 的输出跟正确答案越接近越好</strong>。</p>
<p>那这边有一件值得我们注意的事情,在<strong>训练</strong>的时候我们会给
Decoder 看<strong>正确答案</strong>,也就是我们会告诉它说</p>
<ul>
<li>在已经有 "BEGIN",在有"机"的情况下你就要输出"器"</li>
<li>有 "BEGIN" 有"机" 有"器"的情况下输出"学"</li>
<li>有 "BEGIN" 有"机" 有"器" 有"学"的情况下输出"习"</li>
<li>有 "BEGIN" 有"机" 有"器" 有"学" 有"习"的情况下,你就要输出"断"</li>
</ul>
<p>在 Decoder
训练的时候,我们会在输入的时候给它<strong>正确的答案</strong>,那这件事情叫做
==Teacher Forcing==</p>
<p>那这个时候你马上就会有一个问题了？</p>
<ul>
<li>训练的时候,Decoder 有偷看到正确答案了</li>
<li>但是测试的时候,显然没有正确答案可以给 Decoder 看</li>
</ul>
<p>刚才也有强调说在真正使用这个模型,在 Inference 的时候,Decoder
看到的是自己的输入,这<strong>中间显然有一个
==Mismatch==</strong>,那等一下我们会有一页投影片的说明,有什么样可能的解决方式。</p>
<h3><span id="25-tips">2.5 Tips</span></h3>
<p>那接下来,不侷限于 Transformer ,讲一些训练这种 Sequence To Sequence
Model 的Tips</p>
<h4><span id="copy-mechanism">Copy Mechanism</span></h4>
<p>在我们刚才的讨论里面,我们都要求 Decoder
自己产生输出,但是对很多任务而言,也许 <strong>Decoder
没有必要自己创造输出</strong>出来,它需要做的事情,也许是<strong>从输入的东西里面复製</strong>一些东西出来。</p>
<p>像这种复製的行为在哪些任务会用得上呢,一个例子是做聊天机器人。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615175700028.png" alt="image-20220615175700028" style="zoom:50%;"></p>
<ul>
<li><p>人对机器说:你好 我是库洛洛,</p></li>
<li><p>机器应该回答说:库洛洛你好 很高兴认识你</p></li>
</ul>
<p>对机器来说,它其实<strong>没有必要创造</strong>库洛洛这个词汇,这对机器来说一定会是一个非常怪异的词汇,所以它可能很难,在训练资料里面可能一次也没有出现过,所以它不太可能正确地产生这段词汇出来。</p>
<p>但是假设今天机器它在学的时候,它学到的是看到输入的时候说我是某某某,就直接把某某某,不管这边是什么复製出来说某某某你好。</p>
<p>那这样子机器的<strong>训练显然会比较容易</strong>,它显然比较有可能得到正确的结果,所以复製对于对话来说,可能是一个需要的技术
需要的能力。</p>
<h4><span id="guided-attention">Guided Attention</span></h4>
<p>机器就是一个黑盒子,有时候它里面学到什么东西,你实在是搞不清楚,那有时候它会犯<strong>非常低级的错误</strong>。但是<strong>对语音辨识
语音合成,Guiding Attention,可能就是一个比较重要的技术</strong>。</p>
<p><strong><font color="red"> Guiding Attention
要做的事情就是,要求机器它在做 Attention
的时候,是有固定的方式的,举例来说,对语音合成或者是语音辨识来说,我们想像中的
Attention,应该就是由左向右。</font></strong></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615175853638.png" alt="image-20220615175853638" style="zoom:50%;"></p>
<p>在这个例子里面,我们用红色的这个曲线,来代表 Attention
的分数,这个越高就代表 Attention 的值越大</p>
<p>我们以语音合成为例,那你的输入就是一串文字,那你在合成声音的时候,显然是<strong>由左念到右</strong>,所以机器应该是,先看最左边输入的词汇产生声音,再看中间的词汇产生声音,再看右边的词汇产生声音</p>
<p>如果你今天在做语音合成的时候,你发现机器的
Attention,是<strong>颠三倒四的</strong>,它先看最后面,接下来再看前面,那再胡乱看整个句子,那显然有些是做错了,显然有些是,Something
is wrong,有些是做错了,</p>
<p>所以 Guiding Attention 要做的事情就是,强迫 Attention
有一个固定的样貌,那如果你对这个问题,本身就已经有理解知道说,语音合成 TTS
这样的问题,你的 Attention 的分数,Attention
的位置都应该由左向右,那不如就直接把这个限制,放进你的 Training
里面,要求机器学到 Attention,就应该要由左向右。</p>
<h4><span id="optimizing-evaluationmetrics">Optimizing Evaluation
Metrics?</span></h4>
<p><strong><font color="red"> 在作业里面,我们评估的标准用的是,BLEU
Score,BLEU Score 是你的
Decoder,先产生一个完整的句子以后,再去跟正确的答案一整句做比较,我们是拿两个句子之间做比较,才算出
BLEU Score。</font></strong></p>
<p>但我们在训练的时候显然不是这样,<strong>训练</strong>的时候,<strong>每一个词汇是分开考虑的</strong>,训练的时候,我们
Minimize 的是 Cross Entropy,Minimize Cross Entropy,真的可以 Maximize
BLEU Score 吗？</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615180128331.png" alt="image-20220615180128331" style="zoom:67%;"></p>
<p>不一定,因为这两个根本就是,它们可能有一点点的关联,但它们又没有那么直接相关,它们根本就是两个不同的数值,所以我们
Minimize Cross Entropy,不见得可以让 BLEU Score 比较大。</p>
<p><strong>所以你发现说在助教的程式里面,助教在做 Validation
的时候,并不是拿 Cross Entropy 来挑最好的 Model,而是挑 BLEU Score
最高的那一个 Model,所以我们训练的时候,是看 Cross
Entropy,但是我们实际上你作业真正评估的时候,看的是 BLEU Score,所以你
Validation Set,其实应该考虑用 BLEU Score</strong>。</p>
<p>那接下来有人就会想说,那我们能不能<strong>在 Training 的时候,就考虑
BLEU Score 呢</strong>,我们能不能够训练的时候就说,我的 Loss 就是,BLEU
Score 乘一个负号,那我们要 Minimize 那个 Loss,假设你的 Loss 是,BLEU
Score乘一个负号,它也等于就是 Maximize BLEU
Score。但是<strong>这件事实际上没有那么容易</strong>,你当然可以把 BLEU
Score,当做你训练的时候,你要最大化的一个目标,但是 BLEU Score
本身很复杂,它是不能微分的。</p>
<p>这边之所以採用 Cross
Entropy,而且是每一个中文的字分开来算,就是因为这样我们才有办法处理,如果你是要计算,两个句子之间的
BLEU Score,这一个
Loss,根本就没有办法做微分,那怎么办呢？这边就教大家一个口诀,遇到你在
Optimization 无法解决的问题,==用 RL 硬 Train 一发==就对了这样,遇到你无法
Optimize 的 Loss Function,把它当做是 RL 的 Reward,把你的 Decoder 当做是
Agent,它当作是 RL,Reinforcement Learning 的问题硬做。</p>
<h4><span id="scheduled-sampling计划采样">Scheduled Sampling
（计划采样）</span></h4>
<p>那我们要讲到,我们刚才反覆提到的问题了,就是<strong>训练跟测试居然是不一致</strong>的</p>
<p><strong><font color="red"> 测试的时候,Decoder
看到的是自己的输出,所以测试的时候,Decoder
会看到一些错误的东西,但是在训练的时候,Decoder
看到的是完全正确的,那这个不一致的现象叫做,==Exposure
Bias==。</font></strong></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615181122702.png" alt="image-20220615181122702" style="zoom: 67%;"></p>
<p>假设 Decoder
在训练的时候,永远只看过正确的东西,那在测试的时候,你只要有一个错,那就会<strong>一步错
步步错</strong>,因为对 Decoder
来说,它从来没有看过错的东西,它看到错的东西会非常的惊奇,然后接下来它产生的结果可能都会错掉。</p>
<h4><span id="所以要怎么解决这个问题呢">所以要怎么解决这个问题呢？</span></h4>
<p>有一个可以的思考的方向是,<strong>给 Decoder
的输入加一些错误的东西</strong>,就这么直觉,你不要给 Decoder
都是正确的答案,偶尔给它一些错的东西,它反而会学得更好,这一招叫做,==Scheduled
Sampling==,它不是那个 Schedule Learning Rate,刚才助教有讲 Schedule
Learning Rate,那是另外一件事,不相干的事情,这个是 Scheduled
Sampling。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615181204628.png" alt="image-20220615181204628" style="zoom: 67%;"></p>
<p>Scheduled Sampling 其实很早就有了,这个是 15 年的 Paper,很早就有
Scheduled Sampling,在还没有 Transformer,只有 LSTM 的时候,就已经有
Scheduled Sampling,但是 Scheduled Sampling
这一招,它其实会伤害到,Transformer
的平行化的能力,那细节可以再自己去了解一下,所以对 Transformer 来说,它的
Scheduled Sampling,另有招数跟传统的招数,跟原来最早提在,这个
LSTM上被提出来的招数,也不太一样,那我把一些 Reference
的,列在这边给大家参考。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615181229880.png" alt="image-20220615181229880" style="zoom:67%;"></p>
<p>Transformer 和种种的训练技巧,这个我们已经讲完了 Encoder,讲完了
Decoder,也讲完了它们中间的关係,也讲了怎么训练,也讲了种种的 Tip。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>Seq2Seq</category>
      </categories>
  </entry>
  <entry>
    <title>深度学习（9）Transformer-code</title>
    <url>/posts/PSEWDM/</url>
    <content><![CDATA[<h1><span id="transformer">Transformer</span></h1>
<blockquote>
<p>Transformer：（Self-attention）自注意力机制的序列到序列的模型</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/415318478">Transformer
代码完全解读!</a></li>
<li><a href="https://www.zhihu.com/question/471328838/answer/1996725528">如何从浅入深理解transformer？</a></li>
<li><a href="https://www.zhihu.com/question/428626879/answer/1556915218">Transformer和GNN有什么联系吗？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/48508221"><strong>详解<em>Transformer</em>
（Attention Is All You Need）</strong></a></li>
<li><strong><a href="https://zhuanlan.zhihu.com/p/438634058"><em>Transformer</em>代码+面试细节</a></strong></li>
</ul>
</blockquote>
<h3><span id="一-模型结构概述">一、模型结构概述</span></h3>
<p>如下是Transformer的两个结构示意图：</p>
<p><img src="https://pic2.zhimg.com/80/v2-7d8daf8e5dbba5ed3f26f3e03f61d395_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>上图是从一篇英文博客中截取的Transformer的结构简图，下图是原论文中给出的结构简图，更细粒度一些，可以结合着来看。</p>
<p><img src="https://pic1.zhimg.com/80/v2-f70598121a15f713eeafa4bc696d528c_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>模型大致分为<code>Encoder</code>(编码器)和<code>Decoder</code>(解码器)两个部分，分别对应上图中的左右两部分。</p>
<p><strong>编码器</strong>由N个相同的层堆叠在一起(我们后面的实验取N=6)，每一层又有两个子层：</p>
<ul>
<li>第一个子层是一个<code>Multi-Head Attention</code>(<strong>==多头的自注意机制==</strong>)
<ul>
<li>Self-attention多个头类似于cnn中多个卷积核的作用，使用多头注意力，能够从不同角度提取信息，提高信息提取的全面性。</li>
</ul></li>
<li>第二个子层是一个简单的<code>Feed Forward</code>(全连接前馈网络)</li>
<li>两个子层都添加了一个<strong>残差连接</strong>+==layer
normalization==的操作。</li>
</ul>
<p><strong>解码器</strong>同样是堆叠了N个相同的层，不过和编码器中每层的结构稍有不同。</p>
<ul>
<li>第一个子层是一个<code>Multi-Head Attention</code>(<strong>==多头的自注意机制==</strong>)</li>
<li>第二个子层是一个简单的<code>Feed Forward</code>(全连接前馈网络)</li>
<li><strong>==Masked Multi-Head Attention==</strong></li>
<li>每个子层同样也用了<strong>==residual==</strong>以及layer
normalization。</li>
</ul>
<p>模型的输入由<code>Input Embedding</code>和<code>Positional Encoding</code>(位置编码)两部分组合而成。</p>
<p>模型的输出由Decoder的输出简单的经过softmax得到。</p>
<h3><span id="二-模型输入">二、<strong>模型输入</strong></span></h3>
<p>首先我们来看模型的输入是什么样的，先明确模型输入，后面的模块理解才会更直观。输入部分包含两个模块，<code>Embedding</code>和<code>Positional Encoding</code>。</p>
<h4><span id="21-embedding层"><strong>2.1 Embedding层</strong></span></h4>
<p><strong>Embedding层的作用是将某种格式的输入数据，例如文本，转变为模型可以处理的向量表示，来描述原始数据所包含的信息</strong>。<code>Embedding</code>层输出的可以理解为当前时间步的特征，如果是文本任务，这里就可以是<code>Word Embedding</code>，如果是其他任务，就可以是任何合理方法所提取的特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Embeddings</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, vocab</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        类的初始化函数</span></span><br><span class="line"><span class="string">        d_model：指词嵌入的维度</span></span><br><span class="line"><span class="string">        vocab:指词表的大小</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(Embeddings, self).__init__()</span><br><span class="line">        <span class="comment">#之后就是调用nn中的预定义层Embedding，获得一个词嵌入对象self.lut</span></span><br><span class="line">        self.lut = nn.Embedding(vocab, d_model)</span><br><span class="line">        <span class="comment">#最后就是将d_model传入类中</span></span><br><span class="line">        self.d_model =d_model</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Embedding层的前向传播逻辑</span></span><br><span class="line"><span class="string">        参数x：这里代表输入给模型的单词文本通过词表映射后的one-hot向量</span></span><br><span class="line"><span class="string">        将x传给self.lut并与根号下self.d_model相乘作为结果返回</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        embedds = self.lut(x)</span><br><span class="line">        <span class="keyword">return</span> embedds * math.sqrt(self.d_model)</span><br></pre></td></tr></table></figure>
<h4><span id="22-位置编码">2.2 <strong>位置编码</strong></span></h4>
<p><strong><code>Positional Encodding</code>位置编码的作用是为模型提供当前时间步的前后出现顺序的信息</strong>。因为Transformer不像RNN那样的循环结构有前后不同时间步输入间天然的先后顺序，所有的时间步是同时输入，并行推理的，因此在时间步的特征中融合进位置编码的信息是合理的。位置编码可以有很多选择，可以是固定的，也可以设置成可学习的参数。这里，我们使用固定的位置编码。<strong>具体地，使用不同频率的sin和cos函数来进行位置编码</strong>，如下所示：
<span class="math display">\[
\begin{gathered}
P E_{(p o s, 2 i)}=\sin \left(p o s / 10000^{2 i / d_{\text {model
}}}\right) \\
P E_{(p o s, 2 i+1)}=\cos \left(p o s / 10000^{2 i / d_{\text {model
}}}\right)
\end{gathered}
\]</span>
其中pos代表时间步的下标索引，向量也就是第pos个时间步的位置编码，编码长度同<code>Embedding</code>层，这里我们设置的是512。上面有两个公式，代表着位置编码向量中的元素，奇数位置和偶数位置使用两个不同的公式。思考：<strong>为什么上面的公式可以作为位置编码？</strong>我的理解：在上面公式的定义下，<strong><font color="red">
时间步p和时间步p+k的位置编码的内积，即是与p无关，只与k有关的定值（不妨自行证明下试试）。也就是说，任意两个相距k个时间步的位置编码向量的内积都是相同的，这就相当于蕴含了两个时间步之间相对位置关系的信息。</font></strong>此外，每个时间步的位置编码又是唯一的，这两个很好的性质使得上面的公式作为位置编码是有理论保障的。下面是位置编码模块的代码实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, dropout, max_len=<span class="number">5000</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        位置编码器类的初始化函数</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        共有三个参数，分别是</span></span><br><span class="line"><span class="string">        d_model：词嵌入维度</span></span><br><span class="line"><span class="string">        dropout: dropout触发比率</span></span><br><span class="line"><span class="string">        max_len：每个句子的最大长度</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute the positional encodings</span></span><br><span class="line">        <span class="comment"># 注意下面代码的计算方式与公式中给出的是不同的，但是是等价的，你可以尝试简单推导证明一下。</span></span><br><span class="line">        <span class="comment"># 这样计算是为了避免中间的数值计算结果超出float的范围，</span></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>) *</span><br><span class="line">                             -(math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x + Variable(self.pe[:, :x.size(<span class="number">1</span>)], requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br></pre></td></tr></table></figure>
<p>因此，可以认为，最终模型的输入是若干个时间步对应的embedding，每一个时间步对应一个embedding，可以理解为是当前时间步的一个综合的特征信息，即包含了本身的语义信息，又包含了当前时间步在整个句子中的位置信息。</p>
<h4><span id="23encoder和decoder都包含输入模块"><strong>2.3
Encoder和Decoder都包含输入模块</strong></span></h4>
<p>此外有一个点刚刚接触Transformer的同学可能不太理解，<strong>编码器和解码器两个部分都包含输入，且两部分的输入的结构是相同的，只是推理时的用法不同，编码器只推理一次，而解码器是类似RNN那样循环推理，不断生成预测结果的。</strong></p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-ab0188042d72481d479f8951dc0d702c_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>怎么理解？假设我们现在做的是一个法语-英语的机器翻译任务，想把<code>Je suis étudiant</code>翻译为<code>I am a student</code>。那么我们输入给编码器的就是时间步数为3的embedding数组，编码器只进行一次并行推理，即获得了对于输入的法语句子所提取的若干特征信息。而对于解码器，是循环推理，逐个单词生成结果的。最开始，由于什么都还没预测，我们会将编码器提取的特征，以及一个句子起始符传给解码器，解码器预期会输出一个单词<code>I</code>。然后有了预测的第一个单词，我们就将<code>I</code>输入给解码器，会再预测出下一个单词<code>am</code>，再然后我们将<code>I am</code>作为输入喂给解码器，以此类推直到预测出句子终止符完成预测。</p>
<h3><span id="三-encoder">三、<strong>Encoder</strong></span></h3>
<h4><span id="31-编码器"><strong>3.1 编码器</strong></span></h4>
<p><strong><font color="red">
编码器作用是用于对输入进行特征提取，为解码环节提供有效的语义信息整体来看编码器由N个编码器层简单堆叠而成</font></strong>，因此实现非常简单，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义一个clones函数，来更方便的将某个结构复制若干份</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clones</span>(<span class="params">module, N</span>):</span><br><span class="line">    <span class="string">&quot;Produce N identical layers.&quot;</span></span><br><span class="line">    <span class="keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(N)])</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Encoder</span></span><br><span class="line"><span class="string">    The encoder is composed of a stack of N=6 identical layers.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, layer, N</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line">        <span class="comment"># 调用时会将编码器层传进来，我们简单克隆N分，叠加在一起，组成完整的Encoder</span></span><br><span class="line">        self.layers = clones(layer, N)</span><br><span class="line">        self.norm = LayerNorm(layer.size)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask</span>):</span><br><span class="line">        <span class="string">&quot;Pass the input (and mask) through each layer in turn.&quot;</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x, mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></table></figure>
<p><strong>上面的代码中有一个小细节，就是编码器的输入除了x，也就是embedding以外，还有一个<code>mask</code>，为了介绍连续性</strong>，这里先忽略，后面会讲解。下面我们来看看单个的编码器层都包含什么，如何实现。</p>
<h4><span id="32-编码器层"><strong>3.2 编码器层</strong></span></h4>
<p>每个编码器层由两个子层连接结构组成：<strong>第一个子层包括一个多头自注意力层和规范化层以及一个残差连接</strong>；<strong>第二个子层包括一个前馈全连接层和规范化层以及一个残差连接</strong>；如下图所示：</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-4a57b7e6f8a4a7260c4e841f393f873a_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>可以看到，两个子层的结构其实是一致的，只是中间核心层的实现不同</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-ee127bacaf444e5c3612ca819b53bb8c_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic1.zhimg.com/80/v2-4f3a1f34553d5d568c99e8d2ace9e6c0_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>我们先定义一个SubLayerConnection类来描述这种结构关系:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SublayerConnection</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">    实现子层连接结构的类</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size, dropout</span>):</span><br><span class="line">        <span class="built_in">super</span>(SublayerConnection, self).__init__()</span><br><span class="line">        self.norm = LayerNorm(size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, sublayer</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 原paper的方案</span></span><br><span class="line">        <span class="comment">#sublayer_out = sublayer(x)</span></span><br><span class="line">        <span class="comment">#x_norm = self.norm(x + self.dropout(sublayer_out))</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 稍加调整的版本</span></span><br><span class="line">        sublayer_out = sublayer(x)</span><br><span class="line">        sublayer_out = self.dropout(sublayer_out)</span><br><span class="line">        x_norm = x + self.norm(sublayer_out)</span><br><span class="line">        <span class="keyword">return</span> x_norm</span><br></pre></td></tr></table></figure>
<p>注：上面的实现中，我对残差的链接方案进行了小小的调整，和原论文有所不同。<strong>把x从norm中拿出来，保证永远有一条“高速公路”，这样理论上会收敛的快一些，但我无法确保这样做一定是对的，请一定注意</strong>。定义好了SubLayerConnection，我们就可以实现EncoderLayer的结构了.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderLayer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;EncoderLayer is made up of two sublayer: self-attn and feed forward&quot;</span>                                                                                                         </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size, self_attn, feed_forward, dropout</span>):</span><br><span class="line">        <span class="built_in">super</span>(EncoderLayer, self).__init__()</span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">2</span>)</span><br><span class="line">        self.size = size   <span class="comment"># embedding&#x27;s dimention of model, 默认512</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask</span>):</span><br><span class="line">        <span class="comment"># attention sub layer</span></span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, mask))</span><br><span class="line">        <span class="comment"># feed forward sub layer</span></span><br><span class="line">        z = self.sublayer[<span class="number">1</span>](x, self.feed_forward)</span><br><span class="line">        <span class="keyword">return</span> z</span><br></pre></td></tr></table></figure>
<p>继续往下拆解，我们需要了解 attention层 和
feed_forward层的结构以及如何实现。</p>
<h4><span id="33-注意力机制-self-attention">3.3 注意力机制 Self-Attention</span></h4>
<p>人类在观察事物时，无法同时仔细观察眼前的一切，只能聚焦到某一个局部。通常我们大脑在简单了解眼前的场景后，能够很快把注意力聚焦到最有价值的局部来仔细观察，从而作出有效判断。或许是基于这样的启发，大家想到了在算法中利用注意力机制。注意力计算：它需要三个指定的输入Q（query），K（key），V（value），然后通过下面公式得到注意力的计算结果。</p>
<blockquote>
<figure>
<img src="https://www.zhihu.com/equation?tex=A%28Q%2CK%2CV%29%3D%5Cmathrm%7BSoftmax%7D%28QK%5ET%29V+%5C%5C+" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<ul>
<li><figure>
<img src="https://www.zhihu.com/equation?tex=Q%2CK%2CV%3An%5Ctimes+d" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure></li>
<li>相似度计算 <img src="https://www.zhihu.com/equation?tex=QK%5ET" alt="[公式]"> ： <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=d%5Ctimes+n" alt="[公式]"> 运算，得到 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+n" alt="[公式]">
矩阵，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"></li>
<li>softmax计算：对每行做softmax，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%29" alt="[公式]"> ，则n行的复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2%29" alt="[公式]"></li>
<li>加权和： <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+n" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]">
运算，得到 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]"> 矩阵，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"></li>
</ul>
<p>故最后self-attention的时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]">; 对于受限的self-attention，每个元素仅能和周围 <img src="https://www.zhihu.com/equation?tex=r" alt="[公式]">
个元素进行交互，即和 <img src="https://www.zhihu.com/equation?tex=r" alt="[公式]"> 个 <img src="https://www.zhihu.com/equation?tex=d" alt="[公式]"> 维向量做内积运算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28rd%29" alt="[公式]"> ，则 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 个元素的总时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%28rnd%29%7D" alt="[公式]"></p>
</blockquote>
<p><strong>计算流程图如下：</strong></p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-be94b689af1b76a1f64a2581709d67cd_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>可以这么简单的理解，<strong>当前时间步的注意力计算结果，是一个组系数
*
每个时间步的特征向量value的累加，而这个系数，通过当前时间步的query和其他时间步对应的key做内积得到，这个过程相当于用自己的query对别的时间步的key做查询，判断相似度，决定以多大的比例将对应时间步的信息继承过来</strong>。下面是注意力模块的实现代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">attention</span>(<span class="params">query, key, value, mask=<span class="literal">None</span>, dropout=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;Compute &#x27;Scaled Dot Product Attention&#x27;&quot;</span></span><br><span class="line">    <span class="comment">#首先取query的最后一维的大小，对应词嵌入维度</span></span><br><span class="line">    d_k = query.size(-<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#按照注意力公式，将query与key的转置相乘，这里面key是将最后两个维度进行转置，再除以缩放系数得到注意力得分张量scores</span></span><br><span class="line">    scores = torch.matmul(query, key.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(d_k)</span><br><span class="line">    <span class="comment">#接着判断是否使用掩码张量</span></span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment">#使用tensor的masked_fill方法，将掩码张量和scores张量每个位置一一比较，如果掩码张量则对应的scores张量用-1e9这个置来替换</span></span><br><span class="line">        scores = scores.masked_fill(mask == <span class="number">0</span>, -<span class="number">1e9</span>)</span><br><span class="line">    <span class="comment">#对scores的最后一维进行softmax操作，使用F.softmax方法，这样获得最终的注意力张量</span></span><br><span class="line">    p_attn = F.softmax(scores, dim = -<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#之后判断是否使用dropout进行随机置0</span></span><br><span class="line">    <span class="keyword">if</span> dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        p_attn = dropout(p_attn)</span><br><span class="line">    <span class="comment">#最后，根据公式将p_attn与value张量相乘获得最终的query注意力表示，同时返回注意力张量</span></span><br><span class="line">    <span class="keyword">return</span> torch.matmul(p_attn, value), p_attn</span><br></pre></td></tr></table></figure>
<h4><span id="34-多头注意力机制"><strong>3.4 多头注意力机制</strong></span></h4>
<p><strong>刚刚介绍了attention机制，在搭建EncoderLayer时候所使用的Attention模块，实际使用的是多头注意力，可以简单理解为多个注意力模块组合在一起。</strong></p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-e0f18101e6c6c621c87bcb880eb3c795_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong><font color="red">
多头注意力机制的作用：这种结构设计能让每个注意力机制去优化每个词汇的不同特征部分，从而均衡同一种注意力机制可能产生的偏差，让词义拥有来自更多元表达，实验表明可以从而提升模型效果。</font></strong></p>
<blockquote>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BMultiHead%7D%28Q%2CK%2CV%29%3D%5Cmathrm%7BConcat%28head_1%2C...%2Chead_h%29%7DW%5EO+%5C%5C+%5Cmathrm%7Bwhere%5Cquad+head_i%7D%3DA%28QW_i%5EQ%2CKW_i%5EK%2CVW_i%5EV%29%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>对于multi-head attention，假设有 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]"> 个head，这里
<img src="https://www.zhihu.com/equation?tex=h" alt="[公式]">
是一个常数，对于每个head，首先需要把三个矩阵分别映射到 <img src="https://www.zhihu.com/equation?tex=d_q%2Cd_k%2Cd_v" alt="[公式]">
维度。这里考虑一种简化情况： <img src="https://www.zhihu.com/equation?tex=d_q%3Dd_k%3Dd_v%3D%5Cfrac%7Bd%7D%7Bh%7D" alt="[公式]"> 。(对于dot-attention计算方式， <img src="https://www.zhihu.com/equation?tex=d_k" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=d_v" alt="[公式]">
可以不同)。</p>
<ul>
<li>输入线性映射的复杂度： <img src="https://www.zhihu.com/equation?tex=n+%5Ctimes+d" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=d%5Ctimes+%5Cfrac%7Bd%7D%7Bh%7D" alt="[公式]"> 运算，忽略常系数，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nd%5E2%29" alt="[公式]"> 。</li>
<li>Attention操作复杂度：主要在相似度计算及加权和的开销上， <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+%5Cfrac%7Bd%7D%7Bh%7D" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7Bd%7D%7Bh%7D%5Ctimes+%7Bn%7D" alt="[公式]"> 运算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7B%7D" alt="[公式]"></li>
<li>输出线性映射的复杂度：concat操作拼起来形成 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]">
的矩阵，然后经过输出线性映射，保证输入输出相同，所以是 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=d%5Ctimes+d" alt="[公式]"> 计算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nd%5E2%29" alt="[公式]"></li>
</ul>
<p>故最后的复杂度为： <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%2Bnd%5E2%29" alt="[公式]"></p>
</blockquote>
<p>举个更形象的例子，<strong>bank是银行的意思，如果只有一个注意力模块，那么它大概率会学习去关注类似money、loan贷款这样的词。如果我们使用多个多头机制，那么不同的头就会去关注不同的语义，比如bank还有一种含义是河岸，那么可能有一个头就会去关注类似river这样的词汇，这时多头注意力的价值就体现出来了</strong>。下面是多头注意力机制的实现代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadedAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, h, d_model, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="comment">#在类的初始化时，会传入三个参数，h代表头数，d_model代表词嵌入的维度，dropout代表进行dropout操作时置0比率，默认是0.1</span></span><br><span class="line">        <span class="built_in">super</span>(MultiHeadedAttention, self).__init__()</span><br><span class="line">        <span class="comment">#在函数中，首先使用了一个测试中常用的assert语句，判断h是否能被d_model整除，这是因为我们之后要给每个头分配等量的词特征，也就是embedding_dim/head个</span></span><br><span class="line">        <span class="keyword">assert</span> d_model % h == <span class="number">0</span></span><br><span class="line">        <span class="comment">#得到每个头获得的分割词向量维度d_k</span></span><br><span class="line">        self.d_k = d_model // h</span><br><span class="line">        <span class="comment">#传入头数h</span></span><br><span class="line">        self.h = h</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#创建linear层，通过nn的Linear实例化，它的内部变换矩阵是embedding_dim x embedding_dim，然后使用，为什么是四个呢，这是因为在多头注意力中，Q,K,V各需要一个，最后拼接的矩阵还需要一个，因此一共是四个</span></span><br><span class="line">        self.linears = clones(nn.Linear(d_model, d_model), <span class="number">4</span>)</span><br><span class="line">        <span class="comment">#self.attn为None，它代表最后得到的注意力张量，现在还没有结果所以为None</span></span><br><span class="line">        self.attn = <span class="literal">None</span></span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, query, key, value, mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment">#前向逻辑函数，它输入参数有四个，前三个就是注意力机制需要的Q,K,V，最后一个是注意力机制中可能需要的mask掩码张量，默认是None</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># Same mask applied to all h heads.</span></span><br><span class="line">            <span class="comment">#使用unsqueeze扩展维度，代表多头中的第n头</span></span><br><span class="line">            mask = mask.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#接着，我们获得一个batch_size的变量，他是query尺寸的第1个数字，代表有多少条样本</span></span><br><span class="line">        nbatches = query.size(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 1) Do all the linear projections in batch from d_model =&gt; h x d_k </span></span><br><span class="line">        <span class="comment"># 首先利用zip将输入QKV与三个线性层组到一起，然后利用for循环，将输入QKV分别传到线性层中，做完线性变换后，开始为每个头分割输入，这里使用view方法对线性变换的结构进行维度重塑，多加了一个维度h代表头，这样就意味着每个头可以获得一部分词特征组成的句子，其中的-1代表自适应维度，计算机会根据这种变换自动计算这里的值，然后对第二维和第三维进行转置操作，为了让代表句子长度维度和词向量维度能够相邻，这样注意力机制才能找到词义与句子位置的关系，从attention函数中可以看到，利用的是原始输入的倒数第一和第二维，这样我们就得到了每个头的输入</span></span><br><span class="line">        query, key, value = \</span><br><span class="line">            [l(x).view(nbatches, -<span class="number">1</span>, self.h, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">             <span class="keyword">for</span> l, x <span class="keyword">in</span> <span class="built_in">zip</span>(self.linears, (query, key, value))]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2) Apply attention on all the projected vectors in batch. </span></span><br><span class="line">        <span class="comment"># 得到每个头的输入后，接下来就是将他们传入到attention中，这里直接调用我们之前实现的attention函数，同时也将mask和dropout传入其中</span></span><br><span class="line">        x, self.attn = attention(query, key, value, mask=mask, </span><br><span class="line">                                 dropout=self.dropout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3) &quot;Concat&quot; using a view and apply a final linear. </span></span><br><span class="line">        <span class="comment"># 通过多头注意力计算后，我们就得到了每个头计算结果组成的4维张量，我们需要将其转换为输入的形状以方便后续的计算，因此这里开始进行第一步处理环节的逆操作，先对第二和第三维进行转置，然后使用contiguous方法。这个方法的作用就是能够让转置后的张量应用view方法，否则将无法直接使用，所以，下一步就是使用view重塑形状，变成和输入形状相同。  </span></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous() \</span><br><span class="line">             .view(nbatches, -<span class="number">1</span>, self.h * self.d_k)</span><br><span class="line">        <span class="comment">#最后使用线性层列表中的最后一个线性变换得到最终的多头注意力结构的输出</span></span><br><span class="line">        <span class="keyword">return</span> self.linears[-<span class="number">1</span>](x)</span><br></pre></td></tr></table></figure>
<h4><span id="35-前馈全连接层"><strong>3.5 前馈全连接层</strong></span></h4>
<p><strong>EncoderLayer中另一个核心的子层是 Feed Forward
Layer</strong>，我们这就介绍一下。在进行了Attention操作之后，encoder和decoder中的每一层都包含了一个全连接前向网络，对每个position的向量分别进行相同的操作，包括两个线性变换和一个ReLU激活输出：</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-776124756aeaa1aab51f630819d372b7_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong><font color="red"> Feed Forward Layer
其实就是简单的由两个前向全连接层组成，核心在于，Attention模块每个时间步的输出都整合了所有时间步的信息，==而Feed
Forward
Layer每个时间步只是对自己的特征的一个进一步整合，与其他时间步无关。==</font></strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PositionwiseFeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, d_ff, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="comment">#初始化函数有三个输入参数分别是d_model，d_ff，和dropout=0.1，第一个是线性层的输入维度也是第二个线性层的输出维度，因为我们希望输入通过前馈全连接层后输入和输出的维度不变，第二个参数d_ff就是第二个线性层的输入维度和第一个线性层的输出，最后一个是dropout置0比率。</span></span><br><span class="line">        <span class="built_in">super</span>(PositionwiseFeedForward, self).__init__()</span><br><span class="line">        self.w_1 = nn.Linear(d_model, d_ff)</span><br><span class="line">        self.w_2 = nn.Linear(d_ff, d_model)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment">#输入参数为x，代表来自上一层的输出，首先经过第一个线性层，然后使用F中的relu函数进行激活，之后再使用dropout进行随机置0，最后通过第二个线性层w2，返回最终结果</span></span><br><span class="line">        <span class="keyword">return</span> self.w_2(self.dropout(F.relu(self.w_1(x))))</span><br></pre></td></tr></table></figure>
<p>到这里Encoder中包含的主要结构就都介绍了，上面的代码中涉及了两个小细节还没有介绍，<strong>layer
normalization 和 mask</strong>，下面来简单讲解一下。</p>
<h4><span id="36-规范化层"><strong>3.6. 规范化层</strong></span></h4>
<p><strong>规范化层的作用：它是所有深层网络模型都需要的标准网络层，因为随着网络层数的增加，通过多层的计算后输出可能开始出现过大或过小的情况，这样可能会导致学习过程出现异常，模型可能收敛非常慢</strong>。因此都会在一定层后接规范化层进行数值的规范化，使其特征数值在合理范围内。Transformer中使用的normalization手段是layer
norm，实现代码很简单，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LayerNorm</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;Construct a layernorm module (See citation for details).&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, feature_size, eps=<span class="number">1e-6</span></span>):</span><br><span class="line">        <span class="comment">#初始化函数有两个参数，一个是features,表示词嵌入的维度,另一个是eps它是一个足够小的数，在规范化公式的分母中出现,防止分母为0，默认是1e-6。</span></span><br><span class="line">        <span class="built_in">super</span>(LayerNorm, self).__init__()</span><br><span class="line">        <span class="comment">#根据features的形状初始化两个参数张量a2，和b2，第一初始化为1张量，也就是里面的元素都是1，第二个初始化为0张量，也就是里面的元素都是0，这两个张量就是规范化层的参数。因为直接对上一层得到的结果做规范化公式计算，将改变结果的正常表征，因此就需要有参数作为调节因子，使其即能满足规范化要求，又能不改变针对目标的表征，最后使用nn.parameter封装，代表他们是模型的参数</span></span><br><span class="line">        self.a_2 = nn.Parameter(torch.ones(feature_size))</span><br><span class="line">        self.b_2 = nn.Parameter(torch.zeros(feature_size))</span><br><span class="line">        <span class="comment">#把eps传到类中</span></span><br><span class="line">        self.eps = eps</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="comment">#输入参数x代表来自上一层的输出，在函数中，首先对输入变量x求其最后一个维度的均值，并保持输出维度与输入维度一致，接着再求最后一个维度的标准差，然后就是根据规范化公式，用x减去均值除以标准差获得规范化的结果。</span></span><br><span class="line">    <span class="comment">#最后对结果乘以我们的缩放参数，即a2,*号代表同型点乘，即对应位置进行乘法操作，加上位移参b2，返回即可</span></span><br><span class="line">        mean = x.mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        std = x.std(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> self.a_2 * (x - mean) / (std + self.eps) + self.b_2</span><br></pre></td></tr></table></figure>
<h4><span id="37-掩码及其作用"><strong>3.7 掩码及其作用</strong></span></h4>
<p><strong>掩码：掩代表遮掩，码就是我们张量中的数值，它的尺寸不定，里面一般只有0和1；代表位置被遮掩或者不被遮掩。</strong>掩码的作用：<strong><font color="red">
在transformer中，掩码主要的作用有两个，一个是屏蔽掉无效的padding区域，一个是屏蔽掉来自“未来”的信息。</font></strong></p>
<p><strong>Encoder中的掩码主要是起到第一个作用，Decoder中的掩码则同时发挥着两种作用</strong>。屏蔽掉无效的padding区域：我们训练需要组batch进行，就以机器翻译任务为例，一个batch中不同样本的输入长度很可能是不一样的，此时我们要设置一个最大句子长度，然后对空白区域进行padding填充，而填充的区域无论在Encoder还是Decoder的计算中都是没有意义的，因此需要用mask进行标识，屏蔽掉对应区域的响应。屏蔽掉来自未来的信息：我们已经学习了attention的计算流程，它是会综合所有时间步的计算的，那么在解码的时候，就有可能获取到未来的信息，这是不行的。因此，这种情况也需要我们使用mask进行屏蔽。现在还没介绍到Decoder，如果没完全理解，可以之后再回过头来思考下。mask的构造代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">subsequent_mask</span>(<span class="params">size</span>):</span><br><span class="line">    <span class="comment">#生成向后遮掩的掩码张量，参数size是掩码张量最后两个维度的大小，它最后两维形成一个方阵</span></span><br><span class="line">    <span class="string">&quot;Mask out subsequent positions.&quot;</span></span><br><span class="line">    attn_shape = (<span class="number">1</span>, size, size)</span><br><span class="line">    <span class="comment">#然后使用np.ones方法向这个形状中添加1元素，形成上三角阵</span></span><br><span class="line">    subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="number">1</span>).astype(<span class="string">&#x27;uint8&#x27;</span>)</span><br><span class="line">    <span class="comment">#最后将numpy类型转化为torch中的tensor，内部做一个1- 的操作。这个其实是做了一个三角阵的反转，subsequent_mask中的每个元素都会被1减。</span></span><br><span class="line">    <span class="comment">#如果是0，subsequent_mask中的该位置由0变成1</span></span><br><span class="line">    <span class="comment">#如果是1，subsequect_mask中的该位置由1变成0</span></span><br><span class="line">    <span class="keyword">return</span> torch.from_numpy(subsequent_mask) == <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>以上便是编码器部分的全部内容，有了这部分内容的铺垫，解码器的介绍就会轻松一些。</p>
<h3><span id="四-decoder"><strong>四、 Decoder</strong></span></h3>
<h4><span id="41-解码器整体结构"><strong>4.1 解码器整体结构</strong></span></h4>
<p>解码器的作用：根据编码器的结果以及上一次预测的结果，输出序列的下一个结果。整体结构上，解码器也是由N个相同层堆叠而成。构造代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#使用类Decoder来实现解码器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;Generic N layer decoder with masking.&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, layer, N</span>):</span><br><span class="line">        <span class="comment">#初始化函数的参数有两个，第一个就是解码器层layer，第二个是解码器层的个数N</span></span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        <span class="comment">#首先使用clones方法克隆了N个layer，然后实例化一个规范化层，因为数据走过了所有的解码器层后最后要做规范化处理。</span></span><br><span class="line">        self.layers = clones(layer, N)</span><br><span class="line">        self.norm = LayerNorm(layer.size)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, memory, src_mask, tgt_mask</span>):</span><br><span class="line">        <span class="comment">#forward函数中的参数有4个，x代表目标数据的嵌入表示，memory是编码器层的输出，source_mask，target_mask代表源数据和目标数据的掩码张量，然后就是对每个层进行循环，当然这个循环就是变量x通过每一个层的处理，得出最后的结果，再进行一次规范化返回即可。</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x, memory, src_mask, tgt_mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></table></figure>
<h4><span id="42-解码器层"><strong>4.2 解码器层</strong></span></h4>
<p><strong>每个解码器层由三个子层连接结构组成，第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接，第二个子层连接结构包括一个多头注意力子层和规范化层以及一个残差连接，第三个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接。</strong></p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-fda2b501fe89662dd5f76326b102c650_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>解码器层中的各个子模块，如，多头注意力机制，规范化层，前馈全连接都与编码器中的实现相同。</p>
<p>有一个细节需要注意，第一个子层的多头注意力和编码器中完全一致，<strong><font color="red">
第二个子层，它的多头注意力模块中，query来自上一个子层，key 和 value
来自编码器的输出。</font></strong>可以这样理解，就是第二层负责，利用解码器已经预测出的信息作为query，去编码器提取的各种特征中，查找相关信息并融合到当前特征中，来完成预测。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#使用DecoderLayer的类实现解码器层</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderLayer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;Decoder is made of self-attn, src-attn, and feed forward (defined below)&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size, self_attn, src_attn, feed_forward, dropout</span>):</span><br><span class="line">        <span class="comment">#初始化函数的参数有5个，分别是size，代表词嵌入的维度大小，同时也代表解码器的尺寸，第二个是self_attn，多头自注意力对象，也就是说这个注意力机制需要Q=K=V，第三个是src_attn,多头注意力对象，这里Q!=K=V，第四个是前馈全连接层对象，最后就是dropout置0比率</span></span><br><span class="line">        <span class="built_in">super</span>(DecoderLayer, self).__init__()</span><br><span class="line">        self.size = size</span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.src_attn = src_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        <span class="comment">#按照结构图使用clones函数克隆三个子层连接对象</span></span><br><span class="line">        self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">3</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, memory, src_mask, tgt_mask</span>):</span><br><span class="line">        <span class="comment">#forward函数中的参数有4个，分别是来自上一层的输入x，来自编码器层的语义存储变量memory，以及源数据掩码张量和目标数据掩码张量，将memory表示成m之后方便使用。</span></span><br><span class="line">        <span class="string">&quot;Follow Figure 1 (right) for connections.&quot;</span></span><br><span class="line">        m = memory</span><br><span class="line">        <span class="comment">#将x传入第一个子层结构，第一个子层结构的输入分别是x和self-attn函数，因为是自注意力机制，所以Q,K,V都是x，最后一个参数时目标数据掩码张量，这时要对目标数据进行遮掩，因为此时模型可能还没有生成任何目标数据。</span></span><br><span class="line">        <span class="comment">#比如在解码器准备生成第一个字符或词汇时，我们其实已经传入了第一个字符以便计算损失，但是我们不希望在生成第一个字符时模型能利用这个信息，因此我们会将其遮掩，同样生成第二个字符或词汇时，模型只能使用第一个字符或词汇信息，第二个字符以及之后的信息都不允许被模型使用。</span></span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, tgt_mask))</span><br><span class="line">        <span class="comment">#接着进入第二个子层，这个子层中常规的注意力机制，q是输入x;k,v是编码层输出memory，同样也传入source_mask，但是进行源数据遮掩的原因并非是抑制信息泄露，而是遮蔽掉对结果没有意义的padding。</span></span><br><span class="line">        x = self.sublayer[<span class="number">1</span>](x, <span class="keyword">lambda</span> x: self.src_attn(x, m, m, src_mask))</span><br><span class="line">        <span class="comment">#最后一个子层就是前馈全连接子层，经过它的处理后就可以返回结果，这就是我们的解码器结构</span></span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">2</span>](x, self.feed_forward)</span><br></pre></td></tr></table></figure>
<h3><span id="五-模型输出"><strong>五、模型输出</strong></span></h3>
<p>输出部分就很简单了，每个时间步都过一个 线性层 + softmax层</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-27f90c6393de75bc8d237fca3e4758b8_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>线性层的作用：通过对上一步的线性变化得到指定维度的输出，也就是转换维度的作用。转换后的维度对应着输出类别的个数，如果是翻译任务，那就对应的是文字字典的大小。</strong></p>
<h3><span id="六-模型构建">六、<strong>模型构建</strong></span></h3>
<p>下面是Transformer总体架构图，回顾一下，再看这张图，是不是每个模块的作用都有了基本的认知。</p>
<p><img src="https://pic1.zhimg.com/80/v2-f70598121a15f713eeafa4bc696d528c_1440w.jpg" alt="img" style="zoom: 50%;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Model Architecture</span></span><br><span class="line"><span class="comment">#使用EncoderDecoder类来实现编码器-解码器结构</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderDecoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A standard Encoder-Decoder architecture. </span></span><br><span class="line"><span class="string">    Base for this and many other models.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, encoder, decoder, src_embed, tgt_embed, generator</span>):</span><br><span class="line">        <span class="comment">#初始化函数中有5个参数，分别是编码器对象，解码器对象,源数据嵌入函数，目标数据嵌入函数，以及输出部分的类别生成器对象.</span></span><br><span class="line">        <span class="built_in">super</span>(EncoderDecoder, self).__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line">        self.src_embed = src_embed    <span class="comment"># input embedding module(input embedding + positional encode)</span></span><br><span class="line">        self.tgt_embed = tgt_embed    <span class="comment"># ouput embedding module</span></span><br><span class="line">        self.generator = generator    <span class="comment"># output generation module</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, src, tgt, src_mask, tgt_mask</span>):</span><br><span class="line">        <span class="string">&quot;Take in and process masked src and target sequences.&quot;</span></span><br><span class="line">        <span class="comment">#在forward函数中，有四个参数，source代表源数据，target代表目标数据,source_mask和target_mask代表对应的掩码张量,在函数中，将source source_mask传入编码函数，得到结果后与source_mask target 和target_mask一同传给解码函数</span></span><br><span class="line">        memory = self.encode(src, src_mask)</span><br><span class="line">        res = self.decode(memory, src_mask, tgt, tgt_mask)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, src, src_mask</span>):</span><br><span class="line">        <span class="comment">#编码函数，以source和source_mask为参数,使用src_embed对source做处理，然后和source_mask一起传给self.encoder</span></span><br><span class="line">        src_embedds = self.src_embed(src)</span><br><span class="line">        <span class="keyword">return</span> self.encoder(src_embedds, src_mask)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, memory, src_mask, tgt, tgt_mask</span>):</span><br><span class="line">        <span class="comment">#解码函数，以memory即编码器的输出，source_mask target target_mask为参数,使用tgt_embed对target做处理，然后和source_mask,target_mask,memory一起传给self.decoder</span></span><br><span class="line">        target_embedds = self.tgt_embed(tgt)</span><br><span class="line">        <span class="keyword">return</span> self.decoder(target_embedds, memory, src_mask, tgt_mask)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Full Model</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_model</span>(<span class="params">src_vocab, tgt_vocab, N=<span class="number">6</span>, d_model=<span class="number">512</span>, d_ff=<span class="number">2048</span>, h=<span class="number">8</span>, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    构建模型</span></span><br><span class="line"><span class="string">    params:</span></span><br><span class="line"><span class="string">        src_vocab:</span></span><br><span class="line"><span class="string">        tgt_vocab:</span></span><br><span class="line"><span class="string">        N: 编码器和解码器堆叠基础模块的个数</span></span><br><span class="line"><span class="string">        d_model: 模型中embedding的size，默认512</span></span><br><span class="line"><span class="string">        d_ff: FeedForward Layer层中embedding的size，默认2048</span></span><br><span class="line"><span class="string">        h: MultiHeadAttention中多头的个数，必须被d_model整除</span></span><br><span class="line"><span class="string">        dropout:</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    c = copy.deepcopy</span><br><span class="line">    attn = MultiHeadedAttention(h, d_model)</span><br><span class="line">    ff = PositionwiseFeedForward(d_model, d_ff, dropout)</span><br><span class="line">    position = PositionalEncoding(d_model, dropout)</span><br><span class="line">    model = EncoderDecoder(</span><br><span class="line">        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),</span><br><span class="line">        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),</span><br><span class="line">        Generator(d_model, tgt_vocab))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># This was important from their code. </span></span><br><span class="line">    <span class="comment"># Initialize parameters with Glorot / fan_avg.</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">        <span class="keyword">if</span> p.dim() &gt; <span class="number">1</span>:</span><br><span class="line">            nn.init.xavier_uniform_(p)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h1><span id="transformer-qampa">Transformer Q&amp;A</span></h1>
<blockquote>
<p>3，Transformer的Feed Forward层在训练的时候到底在训练什么？ -
zzzzzzz的回答 - 知乎
https://www.zhihu.com/question/499274875/answer/2250085650</p>
</blockquote>
<h4><span id="feed-forward-networkffn的作用"><strong>Feed forward network
(FFN)的作用？</strong></span></h4>
<p>Transformer在抛弃了 LSTM 结构后，FFN
中的激活函数成为了一个主要的提供<strong>非线性变换</strong>的单元。</p>
<h4><span id="gelu原理相比relu的优点"><strong>GELU原理？相比RELU的优点？</strong></span></h4>
<p>ReLU会<strong>确定性</strong>的将输入乘上一个0或者1(当x&lt;0时乘上0，否则乘上1)，Dropout则是随机乘上0。而GELU虽然也是将输入乘上0或1，但是输入到底是乘以0还是1，是在<strong>取决于输入自身</strong>的情况下<strong>随机</strong>选择的。</p>
<p>什么意思呢？具体来说：</p>
<p>我们将神经元的输入 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 乘上一个服从伯努利分布的 <img src="https://www.zhihu.com/equation?tex=m" alt="[公式]">
。而该伯努利分布又是依赖于 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 的：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=m+%5Csim+Bernoulli%28%5CPhi%28x%29%29+%2C+~where+~%5CPhi%28x%29+%3D+P%28X+%3C%3D+x%29" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中， <img src="https://www.zhihu.com/equation?tex=X+%5Csim+N%280%2C+1%29" alt="[公式]">，那么 <img src="https://www.zhihu.com/equation?tex=%5CPhi%28x%29" alt="[公式]">
就是标准正态分布的累积分布函数。这么做的原因是因为神经元的输入 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]">
往往遵循正态分布，尤其是深度网络中普遍存在Batch
Normalization的情况下。当<img src="https://www.zhihu.com/equation?tex=x" alt="[公式]">减小时，<img src="https://www.zhihu.com/equation?tex=%5CPhi%28x%29" alt="[公式]">的值也会减小，此时<img src="https://www.zhihu.com/equation?tex=x" alt="[公式]">被“丢弃”的可能性更高。所以说这是<strong>随机依赖于输入</strong>的方式。</p>
<p>现在，给出GELU函数的形式：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=GELU%28x%29+%3D+%5CPhi%28x%29+%2A+I%28x%29+%2B+%281+-+%5CPhi%28x%29%29+%2A+0x+%3D+x%5CPhi%28x%29" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%5CPhi%28x%29" alt="[公式]">
是上文提到的标准正态分布的累积分布函数。因为这个函数没有解析解，所以要用近似函数来表示。</p>
<h5><span id="图像">图像：</span></h5>
<p><img src="https://pic3.zhimg.com/v2-0fde0599700a8045a7c1b7d006de33fa_b.jpg" alt="img" style="zoom:50%;"></p>
<h5><span id="导数形式">导数形式：</span></h5>
<p><img src="https://pic4.zhimg.com/v2-c55ded292a81733eb0944abdc4332d43_b.jpg" alt="img" style="zoom:50%;"></p>
<p>GELU和RELU一样，可以解决梯度消失，所以，GELU的优点就是在ReLU上增加随机因素，x越小越容易被mask掉。</p>
<h4><span id="为什么用layernorm不用batchnorm">==<strong>为什么用layernorm不用batchnorm？</strong>==</span></h4>
<p>对于RNN来说，sequence的长度是不一致的，所以用很多padding来表示无意义的信息。如果BN会导致有意义的embedding损失信息。所以，BN一般用于CNN，而LN用于RNN。</p>
<p><a href="https://www.zhihu.com/search?q=layernorm&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22438634058%22%7D">layernorm</a>是在hidden
size的维度进行的，跟batch和seq_len无关。每个hidden
state都计算自己的均值和方差，这是因为不同hidden
state的量纲不一样。beta和gamma的维度都是(hidden_size,)，经过白化的hidden
state * beta + gamma得到最后的结果。</p>
<p>LN在BERT中主要起到白化的作用，增强模型稳定性（如果删除则无法收敛）</p>
<h4><span id="multi-head-self-attention">==Multi-head Self-Attention==</span></h4>
<p>如果是<strong>单头</strong>注意力，就是每个位置的embedding对应 <img src="https://www.zhihu.com/equation?tex=Q%2CK%2CV" alt="[公式]">
三个向量，这三个向量分别是embedding点乘 <img src="https://www.zhihu.com/equation?tex=W_Q%2CW_K%2CW_V" alt="[公式]">
矩阵得来的。每个位置的Q向量去乘上所有位置的K向量，其结果经过softmax变成attention
score，以此作为权重对所有V向量做<a href="https://www.zhihu.com/search?q=加权求和&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22438634058%22%7D">加权求和</a>即可。</p>
<p>用公式表示为：<img src="https://www.zhihu.com/equation?tex=Attention%28Q%2CK%2CV%29+%3D+softmax%28%5Cfrac%7BQK%5ET%7D%7B%5Csqrt%7Bd_k%7D%7D%29V" alt="[公式]"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=d_k" alt="[公式]"> 为 <img src="https://www.zhihu.com/equation?tex=Q%2CK" alt="[公式]"> 向量的hidden size。除以 <img src="https://www.zhihu.com/equation?tex=d_k" alt="[公式]"> 叫做scaled
dot product.</p>
<ul>
<li><h5><span id="多头注意力是怎样的呢"><strong>多头</strong>注意力是怎样的呢？</span></h5></li>
</ul>
<p>Transformer中先通过切头（<a href="https://www.zhihu.com/search?q=spilt&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22438634058%22%7D">spilt</a>）再分别进行Scaled
Dot-Product Attention。</p>
<p><strong>step1</strong>：一个768维的hidden向量，被映射成Q，K，V。
然后三个向量分别切分成12(head_num)个小的64维的向量，每一组小向量之间做attention。不妨假设batch_size为32，<a href="https://www.zhihu.com/search?q=seqlen&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22438634058%22%7D">seqlen</a>为512，隐层维度为768，12个head。</p>
<blockquote>
<p>hidden(32 x 512 x 768) -&gt; Q(32 x 512 x 768) -&gt; 32 x 12 x 512 x
64 hidden(32 x 512 x 768) -&gt; K(32 x 512 x 768) -&gt; 32 x 12 x 512 x
64 hidden(32 x 512 x 768) -&gt; V(32 x 512 x 768) -&gt; 32 x 12 x 512 x
64</p>
</blockquote>
<p><strong>step2</strong>：然后Q和K之间做attention，得到一个32 x 12 x
512 x 512的权重矩阵（时间复杂度O( <img src="https://www.zhihu.com/equation?tex=n%5E2d" alt="[公式]">
))，然后根据这个权重矩阵加权V中切分好的向量，得到一个32 x 12 x 512 x 64
的向量，拉平输出为768向量。</p>
<blockquote>
<p>32 x 12 x 512 x 64(query_hidden) * 32 x 12 x 64 x 512(key_hidden)
-&gt; 32 x 12 x 512 x 512 32 x 12 x 64 x 512(value_hidden) * 32 x 12 x
512 x 512 (权重矩阵) -&gt; 32 x 12 x 512 x 64</p>
</blockquote>
<p>然后再还原成 -&gt; 32 x 512 x 768
。简言之是12个头，每个头都是一个64维度，分别去与其他的所有位置的hidden
embedding做attention然后再合并还原。</p>
<ul>
<li><h5><span id="多头机制为什么有效">多头机制为什么有效？</span></h5></li>
</ul>
<p>类似于CNN中通过多通道机制进行特征选择。Transformer中使用切头(split)的方法，是为了在不增加复杂度（
<img src="https://www.zhihu.com/equation?tex=O%28n%5E2d%29" alt="[公式]"> )的前提下享受类似CNN中“不同卷积核”的优势。</p>
<h4><span id="为什么要做scaled-dotproduct">==为什么要做scaled dot
product?==</span></h4>
<p>当输入信息的维度 d 比较高，会导致 softmax
函数接近饱和区，梯度会比较小。因此，缩放点积模型可以较好地解决这一问题。</p>
<h4><span id="为什么用双线性点积模型即qk两个向量">==为什么用双线性点积模型（即Q，K两个向量）？==</span></h4>
<p>双线性点积模型使用Q，K两个向量，而不是只用一个Q向量，这样引入非对称性，更具健壮性（Attention对角元素值不一定是最大的，也就是说当前位置对自身的注意力得分不一定最高）。</p>
<h4><span id="transformer的非线性来自于哪里">==Transformer的非线性来自于哪里？==</span></h4>
<ul>
<li>FFN的gelu激活函数</li>
<li>self-attention：注意self-attention是非线性的（因为有相乘和softmax）</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>Seq2Seq</category>
      </categories>
  </entry>
  <entry>
    <title>模型训练（6）Local Minimum And Saddle Point</title>
    <url>/posts/1T7T14B/</url>
    <content><![CDATA[<h3><span id="李宏毅课程笔记whengradient-is-small">李宏毅课程笔记：When
gradient is small</span></h3>
<h3><span id="一-critical-point">一、Critical Point</span></h3>
<h4><span id="11-training-fails-because">1.1 Training Fails because</span></h4>
<p>现在我们要讲的是Optimization的部分,所以我们要讲的东西基本上跟Overfitting没有什么太大的关联,我们只讨论Optimization的时候,怎么把gradient
descent做得更好,那为什么Optimization会失败呢？</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011444482.png" alt="image-20220616161429257" style="zoom:67%;"></p>
<p>你常常在做Optimization的时候,你会发现,<strong>随著你的参数不断的update,你的training的loss不会再下降</strong>,但是你对这个loss仍然不满意,就像我刚才说的,你可以把deep的network,跟linear的model,或比较shallow
network
比较,发现说它没有做得更好,所以你觉得deepnetwork,没有发挥它完整的力量,所以Optimization显然是有问题的。</p>
<p><strong>但有时候你会甚至发现,一开始你的model就train不起来,一开始你不管怎么update你的参数,你的loss通通都掉不下去,那这个时候到底发生了什么事情呢？</strong></p>
<p>过去常见的一个猜想,是因为我们现在走到了一个地方,<strong>这个地方参数对loss的微分为零</strong>,当你的参数对loss微分为零的时候,gradient
descent就没有办法再update参数了,这个时候training就停下来了,loss当然就不会再下降了。</p>
<p>讲到gradient为零的时候,大家通常脑海中最先浮现的,可能就是<strong>local
minima</strong>,所以常有人说做deep learning,用gradient
descent会卡在local minima,然后所以gradient descent不work,所以deep
learning不work。</p>
<p><strong>但是如果有一天你要写,跟deep
learning相关paper的时候,你千万不要讲卡在local
minima这种事情,别人会觉得你非常没有水准,为什么？</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011444929.png" alt="image-20220626143535169"></p>
<p>因为<strong>不是只有local
minima的gradient是零</strong>,还有其他可能会让gradient是零,比如说
<strong>saddle point</strong>,所谓的saddle
point,其实就是gradient是零,但是不是local minima,也不是local
maxima的地方,像在右边这个例子里面
红色的这个点,它在左右这个方向是比较高的,前后这个方向是比较低的,它就像是一个马鞍的形状,所以叫做saddle
point,那中文就翻成<strong>鞍点</strong>。</p>
<p>像saddle point这种地方,它也是gradient为零,但它不是local
minima,那像这种gradient为零的点,统称为critical
point,所以<strong>你可以说你的loss,没有办法再下降,也许是因为卡在了critical
point,但你不能说是卡在local minima,因为saddle
point也是微分为零的点</strong></p>
<p>但是今天如果你发现你的gradient,真的很靠近零,卡在了某个critical
point,我们有没有办法知道,到底是local minima,还是saddle
point？其实是有办法的</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011444794.png" alt="image-20220616161554342" style="zoom:50%;"></p>
<p><strong>为什么我们想要知道到底是卡在local minima,还是卡在saddle
point呢</strong></p>
<ul>
<li>因为如果是<strong>卡在local
minima,那可能就没有路可以走了</strong>,因为四周都比较高,你现在所在的位置已经是最低的点,loss最低的点了,往四周走
loss都会比较高,你会不知道怎么走到其他的地方去</li>
<li>但saddle point就比较没有这个问题,如果你今天是<strong>卡在saddle
point的话,saddle
point旁边还是有路可以走的,</strong>还是有路可以让你的loss更低的,你只要逃离saddle
point,你就有可能让你的loss更低</li>
</ul>
<p><strong>所以鉴别今天我们走到,critical point的时候,到底是local
minima,还是saddle
point,是一个值得去探讨的问题,那怎么知道今天一个critical
point,到底是属于local minima,还是saddle point呢？</strong></p>
<h4><span id="12-warning-of-math">1.2 Warning of Math</span></h4>
<p>这边需要用到一点数学,以下这段其实没有很难的数学,就只是微积分跟线性代数,但如果你没有听懂的话,以下这段skip掉是没有关系的，那怎么知道说一个点,到底是local
minima,还是saddle point呢？</p>
<p>你要知道我们loss function的形状,可是我们怎么知道,loss
function的形状呢,network本身很复杂,用复杂network算出来的loss
function,显然也很复杂,我们怎么知道loss
function,长什么样子,虽然我们没有办法完整知道,整个loss function的样子</p>
<h5><span id="taylerseries-approximation"><strong><font color="red"> Tayler
Series Approximation</font></strong></span></h5>
<p>但是如果给定某一组参数,比如说蓝色的这个<span class="math inline">\(θ&#39;\)</span>,在<span class="math inline">\(θ&#39;\)</span>附近的loss
function,是有办法被写出来的,它写出来就像是这个样子：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011444883.png" alt="image-20220626143850955" style="zoom:67%;"></p>
<p>所以这个<span class="math inline">\(L(θ)\)</span>完整的样子写不出来,但是它在<span class="math inline">\(θ&#39;\)</span>附近,你可以用这个式子来表示它,这个式子是,Tayler
Series
Appoximation泰勒级数展开,这个假设你在微积分的时候,已经学过了,所以我就不会细讲这一串是怎么来的,但我们就只讲一下它的概念,这一串里面包含什么东西呢?</p>
<ul>
<li><p>第一项是<span class="math inline">\(L(θ&#39;)\)</span>,就告诉我们说,当<span class="math inline">\(θ\)</span>跟<span class="math inline">\(θ&#39;\)</span>很近的时候,<span class="math inline">\(L(θ)\)</span>应该跟<span class="math inline">\(L(θ&#39;)\)</span>还蛮靠近的</p></li>
<li><p>第二项是<span class="math inline">\((θ-θ&#39;)^Tg\)</span></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011444585.png" alt="image-20220626143927098" style="zoom:67%;"></p>
<p><strong><span class="math inline">\(g\)</span>是一个向量,这个g就是我们的gradient</strong>,我们用绿色的这个g来代表gradient,这个<strong>gradient会来弥补,<span class="math inline">\(θ&#39;\)</span>跟<span class="math inline">\(θ\)</span>之间的差距</strong>,我们虽然刚才说<span class="math inline">\(θ&#39;\)</span>跟<span class="math inline">\(θ\)</span>,它们应该很接近,但是中间还是有一些差距的,那这个差距,第一项我们用这个gradient,来表示他们之间的差距,有时候gradient会写成<span class="math inline">\(∇L(θ&#39;)\)</span>,这个地方的<span class="math inline">\(g\)</span>是一个向量,<strong>它的第i个component,就是θ的第i个component对L的微分</strong>,光是看g还是没有办法,完整的描述L(θ),你还要看第三项</p></li>
<li><p>第三项跟Hessian有关,这边有一个$H $</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011444461.png" alt="image-20220626143956011" style="zoom:67%;"></p>
<p>这个<span class="math inline">\(H\)</span>叫做Hessian,它是一个矩阵,这个第三项是,再<span class="math inline">\((θ-θ&#39;)^TH(θ-θ&#39;)\)</span>,所以第三项会再补足,再加上gradient以后,与真正的L(θ)之间的差距.<strong>H里面放的是L的二次微分</strong>,<strong>它第i个row,第j个column的值,就是把θ的第i个component,对L作微分,再把θ的第j个component,对L作微分,再把θ的第i个component,对L作微分,做两次微分以后的结果</strong>
就是这个<span class="math inline">\(H_i{_j}\)</span></p></li>
</ul>
<p>如果这边你觉得有点听不太懂的话,也没有关系,反正你就记得这个<span class="math inline">\(L(θ)\)</span>,这个loss function,这个error
surface在<span class="math inline">\(θ&#39;\)</span>附近,可以写成这个样子,这个式子跟两个东西有关系,<strong>跟gradient有关系,跟hessian有关系,gradient就是一次微分,hessian就是里面有二次微分的项目</strong></p>
<h5><span id="hession">Hession</span></h5>
<p><strong>那如果我们今天走到了一个critical
point,意味著gradient为零,也就是绿色的这一项完全都不见了</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011444340.png" alt="image-20220626144155017" style="zoom:50%;"></p>
<p><span class="math inline">\(g\)</span><strong>是一个zero
vector,绿色的这一项完全都不见了</strong>,只剩下红色的这一项,所以当在critical
point的时候,这个loss function,它可以被近似为<span class="math inline">\(L(θ&#39;)\)</span>,加上红色的这一项。我们可以<strong>根据红色的这一项来判断</strong>,在<span class="math inline">\(θ&#39;\)</span>附近的error
surface,到底长什么样子。知道error surface长什么样子,我就可以判断。</p>
<h5><span id="判断-θ39它是一个local-minima还是一个saddlepoint"><strong><font color="red">判断 <span class="math inline">\(θ&#39;\)</span>它是一个local minima,还是一个saddle
point</font>。</strong></span></h5>
<p>我们可以靠这一项来了解,这个error
surface的地貌,大概长什么样子,知道它地貌长什么样子,我们就可以知道说,现在是在什么样的状态,这个是Hessian。</p>
<p>那我们就来看一下怎么根据Hessian,怎么根据红色的这一项,来判断θ'附近的地貌。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011444553.png" alt="image-20220626144347777" style="zoom:67%;"></p>
<p>我们现在为了等一下符号方便起见,我们<strong>把<span class="math inline">\((θ-θ&#39;)\)</span>用<span class="math inline">\(v\)</span>这个向量来表示</strong></p>
<ul>
<li>如果今天对任何可能的<span class="math inline">\(v\)</span><strong>,<span class="math inline">\(v^THv\)</span>都大于零</strong>,也就是说
现在θ不管代任何值,v可以是任何的v,也就是θ可以是任何值,不管θ代任何值,<strong>红色框框里面通通都大于零</strong>,那意味著说
<span class="math inline">\(L(θ)&gt;L(θ&#39;)\)</span>。<span class="math inline">\(L(θ)\)</span>不管代多少 只要在<span class="math inline">\(θ&#39;\)</span>附近,<span class="math inline">\(L(θ)\)</span>都大于<span class="math inline">\(L(θ&#39;)\)</span>,<strong>代表<span class="math inline">\(L(θ&#39;)\)</span>是附近的一个最低点,所以它是local
minima</strong></li>
<li>如果今天反过来说,对所有的<span class="math inline">\(v\)</span>而言,<strong><span class="math inline">\(v^THv\)</span>都小于零,也就是红色框框里面永远都小于零</strong>,也就是说<span class="math inline">\(θ\)</span>不管代什么值,红色框框里面都小于零,意味著说<span class="math inline">\(L(θ)&lt;L(θ&#39;)\)</span>,<strong>代表<span class="math inline">\(L(θ&#39;)\)</span>是附近最高的一个点,所以它是local
maxima</strong></li>
<li>第三个可能是假设,<strong><span class="math inline">\(v^THv\)</span>,有时候大于零
有时候小于零</strong>,你代不同的v进去
代不同的θ进去,红色这个框框里面有时候大于零,有时候小于零,意味著说在θ'附近,有时候L(θ)&gt;L(θ')
有时候L(θ)&lt;L(θ'),在L(θ')附近,有些地方高
有些地方低,这意味著什么,<strong>这意味著这是一个saddle
point</strong></li>
</ul>
<p>但是你这边是说我们要代所有的<span class="math inline">\(v\)</span>,去看<span class="math inline">\(v^THv\)</span>是大于零,还是小于零.我们怎么有可能把所有的v,都拿来试试看呢,所以有一个更简便的方法,去确认说这一个条件或这一个条件,会不会发生.</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011445282.png" alt="image-20220626144425820" style="zoom:67%;"></p>
<p><strong><font color="red">
这个就直接告诉你结论,线性代数理论上是有教过这件事情的,如果今天对所有的v而言,<span class="math inline">\(v^THv\)</span>都大于零,那这种矩阵叫做positive
definite 正定矩阵,positive definite的矩阵,它所有的eigen
value特征值都是正的</font></strong></p>
<p>所以如果你今天算出一个hessian,你不需要把它跟所有的v都乘看看,你只要去直接看这个H的eigen
value,如果你发现：</p>
<ul>
<li><strong>所有eigen
value都是正的</strong>,那就代表说这个条件成立,就<span class="math inline">\(v^THv\)</span>,会大于零,也就代表说是一个local
minima。所以你从hessian metric可以看出,它是不是local
minima,你只要算出hessian metric算完以后,看它的eigen
value发现都是正的,它就是local minima。</li>
<li>那反过来说也是一样,如果今天在这个状况,对所有的v而言,<span class="math inline">\(v^THv\)</span>小于零,那H是negative
definite,那就代表所有<strong>eigen
value都是负的</strong>,就保证他是local maxima</li>
<li><strong>那如果eigen value有正有负</strong>,那就代表是saddle
point,</li>
</ul>
<p>那假设在这里你没有听得很懂的话,你就可以记得结论,<strong>你只要算出一个东西,这个东西的名字叫做hessian,它是一个矩阵,这个矩阵如果它所有的eigen
value,都是正的,那就代表我们现在在local
minima,如果它有正有负,就代表在saddle point。</strong></p>
<p>那如果刚才讲的,你觉得你没有听得很懂的话,我们这边举一个例子：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011445797.png" alt="image-20220626145009069">
<figcaption aria-hidden="true">image-20220626145009069</figcaption>
</figure>
<p>我们现在有一个史上最废的network,输入一个x,它只有一个neuron，乘上<span class="math inline">\(w₁\)</span>,而且这个neuron,还没有activation
function,所以x乘上<span class="math inline">\(w₁\)</span>以后
之后就输出,然后再乘上<span class="math inline">\(w₂\)</span>
然后就再输出,就得到最终的数据就是y.总之这个function非常的简单 <span class="math display">\[
y= w₁×w₂×x
\]</span> 我们有一个史上最废的training set,这个data
set说,我们只有一笔data,这笔data是x,是1的时候,它的level是1
所以输入1进去,你希望最终的输出跟1越接近越好</p>
<p>而这个史上最废的training,它的error
surface,也是有办法直接画出来的,因为反正只有两个参数 w₁
w₂,连bias都没有,假设没有bias,只有w₁跟w₂两个参数,这个network只有两个参数
w₁跟w₂,那我们可以穷举所有w₁跟w₂的数值,算出所有w₁
w₂数值所代来的loss,然后就画出error surface 长这个样</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011445240.png" alt="image-20220626145041635">
<figcaption aria-hidden="true">image-20220626145041635</figcaption>
</figure>
<p>四个角落loss是高的,好 那这个图上你可以看出来说,有一些critical
point,这个黑点点的地方(0,0),<strong>原点的地方是critical
point</strong>,然后事实上,<strong>右上三个黑点也是一排critical
point,左下三个点也是一排critical
point</strong>。如果你更进一步要分析,他们是saddle point,还是local
minima的话,那圆心这个地方,<strong>原点这个地方 它是saddle
point</strong>,为什么它是saddle point呢？你往左上这个方向走
loss会变大,往右下这个方向走 loss会变大,往左下这个方向走
loss会变小,往右下这个方向走 loss会变小,它是一个saddle point。</p>
<p>而这两群critical point,它们都是local
minima,所以这个山沟里面,有一排local minima,这一排山沟里面有一排local
minima,然后在原点的地方,有一个saddle point,这个是我们把error
surface,暴力所有的参数,得到的loss
function以后,得到的loss的值以后,画出error
surface,可以得到这样的结论。</p>
<p>现在假设如果不暴力所有可能的loss,如果要直接算说一个点,是local
minima,还是saddle point的话 怎么算呢</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011445178.png" alt="image-20220626145125121" style="zoom: 67%;"></p>
<p>我们可以把loss的function写出来,这个loss的function 这个L是 <span class="math display">\[
L=(\hat{y}-w_1 w_2 x)^2
\]</span> 正确答案 ŷ减掉model的输出,也就是w₁ w₂x,这边取square
error,这边<strong>只有一笔data,所以就不会summation over所有的training
data</strong>,因为反正只有一笔data,x代1
ŷ代1,我刚才说过只有一笔训练资料最废的,所以只有一笔训练资料,所以loss
function就是<span class="math inline">\(L=(\hat{y}-w_1 w_2
x)^2\)</span>,那你可以把这一个loss
function,它的gradient求出来,w₁对L的微分,w₂对L的微分写出来是这个样子
<span class="math display">\[
\frac{∂L}{∂w_1 }=2(1-w_1 w_2 )(-w_2 )
\]</span></p>
<p><span class="math display">\[
\frac{∂L}{∂w_2 }=2(1-w_1 w_2 )(-w_1 )
\]</span></p>
<p>​ 这个东西 <span class="math display">\[
\begin{bmatrix}
\frac{∂L}{∂w_1 }\\\
\frac{∂L}{∂w_2 }
\end{bmatrix}
\]</span>
就是所谓的g,所谓的gradient,什么时候gradient会零呢,什么时候会到一个critical
point呢?</p>
<p>举例来说 如果w₁=0 w₂=0,就在圆心这个地方,如果w₁代0 w₂代0,w₁对L的微分
w₂对L的微分,算出来就都是零
就都是零,这个时候我们就知道说,原点就是一个critical
point,但<strong>它是local maxima,它是local maxima,local
minima,还是saddle point呢,那你就要看hessian才能够知道了</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011445367.png" alt="image-20220626145206428" style="zoom:67%;"></p>
<p>当然 我们刚才已经暴力所有可能的w₁
w₂了,所以你已经知道说,它显然是一个saddle
point,但是现在假设还没有暴力所有可能的loss,所以我们要看看能不能够用H,用Hessian看出它是什么样的critical
point,那怎么算出这个H呢？</p>
<p><strong>H它是一个矩阵,这个矩阵里面元素就是L的二次微分</strong>,所以这个矩阵里面第一个row,第一个coloumn的位置,就是w₁对L微分两次,第一个row
第二个coloumn的位置,就是先用w₂对L作微分,再用w₁对L作微分,然后这边就是w₁对L作微分,w₂对L作微分,然后w₂对L微分两次,这四个值组合起来,就是我们的hessian,那这个hessian的值是多少呢</p>
<p>这个hessian的式子,我都已经把它写出来了,你只要把w₁=0 w₂=0代进去,代进去
你就得到在原点的地方,hessian是这样的一个矩阵 <span class="math display">\[
\begin{bmatrix}
{0}&amp;-2\\\
{-2}&amp;0
\end{bmatrix}
\]</span> 这个hessian告诉我们,它是local minima,还是saddle
point呢,那你就要看这个矩阵的eigen value,算一下发现,这个矩阵有两个eigen
value,2跟-2 <strong>eigen value有正有负,代表saddle point</strong></p>
<p>所以我们现在就是用一个例子,跟你操作一下
告诉你说,你怎么从hessian看出一个点,它一个critical point 它是saddle
point,还是local minima</p>
<h4><span id="13-dont-afraid-of-saddlepoint">1.3 Don't afraid of saddle
point</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011445833.png" alt="image-20220626145319827" style="zoom:67%;"></p>
<p>如果今天你卡的地方是saddle
point,也许你就不用那么害怕了,因为如果你今天你发现,你停下来的时候,是因为saddle
point 停下来了,那其实就有机会可以放心了。</p>
<p>因为H它不只可以帮助我们判断,现在是不是在一个saddle
point,它还指出了我们参数,可以update的方向,就之前我们参数update的时候,都是看gradient
看g,但是我们走到某个地方以后,发现g变成0了 不能再看g了,g不见了
gradient没有了<strong>,但如果是一个saddle
point的话,还可以再看H,怎么再看H呢,H怎么告诉我们,怎么update参数呢</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011445962.png" alt="image-20220626145640713" style="zoom:67%;"></p>
<p>我们这边假设<span class="math inline">\(\mu\)</span>是H的eigenvector特征向量,然后<span class="math inline">\(λ\)</span>是u的eigen
value特征值。如果我们把这边的<span class="math inline">\(v\)</span>换成<span class="math inline">\(\mu\)</span>的话,我们把<span class="math inline">\(\mu\)</span>乘在H的左边,跟H的右边,也就是<span class="math inline">\(\mu^TH\mu\)</span>, <span class="math inline">\(H\mu\)</span>会得到<span class="math inline">\(λ\mu\)</span>，因为<span class="math inline">\(\mu\)</span>是一个eigen vector。H乘上eigen
vector特征向量会得到特征向量λ eigen value乘上eigen vector即<span class="math inline">\(λ\mu\)</span></p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011445930.png" alt="image-20220626145734569">
<figcaption aria-hidden="true">image-20220626145734569</figcaption>
</figure>
<p>所以我们在这边得到uᵀ乘上λu,然后再整理一下,把uᵀ跟u乘起来,得到‖u‖²,所以得到λ‖u‖²</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011445674.png" alt="image-20220626145742180">
<figcaption aria-hidden="true">image-20220626145742180</figcaption>
</figure>
<p>假设我们这边v,代的是一个eigen vector,我们这边θ减θ',放的是一个eigen
vector的话,会发现说我们这个红色的项里面,其实就是λ‖u‖²</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011445829.png" alt="image-20220626145756118" style="zoom:67%;"></p>
<p>那今天如果λ<strong>小于零</strong>,eigen
value小于零的话,那λ‖u‖²就会小于零,因为‖u‖²一定是正的,所以eigen
value是负的,那这一整项就会是<strong>负的</strong>,也就是u的transpose乘上H乘上u,它是负的,也就是<strong>红色这个框里是负的</strong>。所以这意思是说假设<span class="math inline">\(θ-θ&#39;=\mu\)</span>,那这一项<span class="math inline">\((θ-θ&#39;)^TH(θ-θ&#39;)\)</span>就是负的,也就是<span class="math inline">\(L(θ)&lt;L(θ&#39;)\)</span>。也就是说假设<span class="math inline">\(θ-θ&#39;=\mu\)</span>,也就是,<strong>你在θ'的位置加上u,沿著u的方向做update得到θ,你就可以让loss变小</strong>。</p>
<p>因为根据这个式子,你只要θ减θ'等于u,loss就会变小,所以你今天只要让θ等于θ'加u,你就可以让loss变小,你只要沿著u,也就是eigen
vector的方向,去更新你的参数 去改变你的参数,你就可以让loss变小了</p>
<p><strong><font color="red"> 所以虽然在critical
point没有gradient,如果我们今天是在一个saddle
point,你也不一定要惊慌,你只要找出负的eigen value,再找出它对应的eigen
vector,用这个eigen
vector去加θ',就可以找到一个新的点,这个点的loss比原来还要低。</font></strong></p>
<h5><span id="举具体的例子">举具体的例子：</span></h5>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011445872.png" alt="image-20220626145931496" style="zoom: 67%;"></p>
<p>刚才我们已经发现,原点是一个critical
point,它的Hessian长这个样,那我现在发现说,这个Hessian有一个负的eigen
value,这个eigen value等于-2,那它对应的eigen
vector,它有很多个,其实是无穷多个对应的eigen
vector,我们就取一个出来,我们取<span class="math inline">\(\begin{bmatrix}{1} \\\
{1}\end{bmatrix}\)</span>是它对应的一个eigen
vector,那我们其实只要顺著这个u的方向,顺著<span class="math inline">\(\begin{bmatrix}{1} \\\
{1}\end{bmatrix}\)</span>这个vector的方向,去更新我们的参数,就可以找到一个,比saddle
point的loss还要更低的点。</p>
<p>如果以今天这个例子来看的话,你的saddle
point在(0,0)这个地方,你在这个地方会没有gradient,Hessian的eigen
vector告诉我们,只要往<span class="math inline">\(\begin{bmatrix}{1} \\\
{1}\end{bmatrix}\)</span>的方向更新,你就可以让loss变得更小,也就是说你可以逃离你的saddle
point,然后让你的loss变小,所以从这个角度来看,似乎saddle
point并没有那么可怕。如果你今天在training的时候,你的gradient你的训练停下来,你的gradient变成零,你的训练停下来,是因为saddle
point的话,那似乎还有解。</p>
<p><strong>但是当然实际上,在实际的implementation里面,你几乎不会真的把Hessian算出来</strong>,这个要是二次微分,要计算这个矩阵的computation,需要的运算量非常非常的大,更遑论你还要把它的eigen
value,跟 eigen
vector找出来,所以在实作上,你几乎没有看到,有人用这一个方法来逃离saddle
point。</p>
<p><strong>等一下我们会讲其他,也有机会逃离saddle
point的方法,他们的运算量都比要算这个H,还要小很多</strong>,那今天之所以我们把,这个saddle
point跟 eigen vector,跟Hessian的eigen
vector拿出来讲,是想要告诉你说,如果是卡在saddle
point,也许没有那么可怕,最糟的状况下你还有这一招,可以告诉你要往哪一个方向走.</p>
<h4><span id="14-saddle-point-vs-localminima">1.4 Saddle Point v.s. Local
Minima</span></h4>
<p>讲到这边你就会有一个问题了,这个问题是,那到底<strong>saddle
point跟local minima,谁比较常见呢</strong>,我们说,saddle
point其实并没有很可怕,那如果我们今天,常遇到的是saddle
point,比较少遇到local minima,那就太好了,那到底saddle point跟local
minima,哪一个比较常见呢?</p>
<p>总之这个<strong>从三维的空间来看,是没有路可以走的东西,在高维的空间中是有路可以走的,error
surface会不会也一样呢？</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011446813.png" alt="image-20220626150135469" style="zoom:67%;"></p>
<p>而经验上,如果你自己做一些实验的话,也支持这个假说</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011446029.png" alt="image-20220626150207285" style="zoom: 67%;"></p>
<p>这边是训练某一个network的结果,每一个点代表,训练那个network训练完之后,把它的Hessian拿出来进行计算,所以这边的每一个点,都代表一个network,就我们训练某一个network,然后把它训练训练,训练到gradient很小,卡在critical
point,把那组参数出来分析,看看它比较像是saddle point,还是比较像是local
minima</p>
<ul>
<li>纵轴代表training的时候的loss,就是我们今天卡住了,那个loss没办法再下降了,那个loss是多少,那很多时候,你的loss在还很高的时候,训练就不动了
就卡在critical point,那很多时候loss可以降得很低,才卡在critical
point,这是纵轴的部分</li>
<li>横轴的部分是minimum ratio,minimum ratio是<strong>eigen
value的数目分之正的eigen value的数目</strong>,又<strong>如果所有的eigen
value都是正的,代表我们今天的critical point,是local
minima,如果有正有负代表saddle
point</strong>,那在实作上你会发现说,你几乎找不到完全所有eigen
value都是正的critical point,你看这边这个例子里面,这个minimum
ratio代表eigen value的数目分之正的eigen
value的数目,最大也不过0.5到0.6间而已,代表说只有一半的eigen
value是正的,还有一半的eigen value是负的,</li>
</ul>
<p>所以今天虽然在这个图上,越往右代表我们的critical point越像local
minima,<strong>但是它们都没有真的,变成local
minima</strong>,就算是在最极端的状况,我们仍然有一半的case,我们的eigen
value是负的,这一半的case eigen
value是正的,代表说在所有的维度里面有一半的路,这一半的路
如果要让loss上升,还有一半的路可以让loss下降。</p>
<p><strong><font color="red"> 所以从经验上看起来,其实local
minima并没有那么常见,多数的时候,你觉得你train到一个地方,你gradient真的很小,然后所以你的参数不再update了,往往是因为你卡在了一个saddle
point。</font></strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011446758.png" alt="image-20220616164405732" style="zoom: 33%;"></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>训练技巧</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>Critical Point</tag>
      </tags>
  </entry>
  <entry>
    <title>模型训练（5）Batch Normalization</title>
    <url>/posts/1HFEDWZ/</url>
    <content><![CDATA[<h3><span id="李宏毅课程笔记quickintroduction-of-batch-normalization">李宏毅课程笔记：Quick
Introduction of Batch Normalization</span></h3>
<p>本篇是一个很快地介绍,Batch Normalization 这个技术</p>
<h3><span id="一-changinglandscape不变化的景观">一、Changing
Landscape（不变化的景观）</span></h3>
<p>之前才讲过说,我们能不能够直接改error surface 的 landscape,我们觉得说
error surface 如果很崎嶇的时候,它比较难
train,那我们能不能够直接把山剷平,让它变得比较好 train 呢？</p>
<p><strong><font color="red">Batch Normalization</font></strong>
就是其中一个,<strong>把山剷平的想法</strong>。我们一开始就跟大家讲说,不要小看
optimization 这个问题,有时候就算你的 error surface 是
convex的,它就是一个碗的形状,都不见得很好
train。假设你的两个参数啊,它们对 <strong>Loss
的斜率差别非常大</strong>,在 <span class="math inline">\(w_1\)</span>
这个方向上面,你的斜率变化很小,在 <span class="math inline">\(w_2\)</span> 这个方向上面斜率变化很大。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011440832.png" alt="image-20220616212321383">
<figcaption aria-hidden="true">image-20220616212321383</figcaption>
</figure>
<p>如果是<strong>固定的 learning
rate</strong>,你可能很难得到好的结果,所以我们才说你需要adaptive 的
learning rate、 Adam 等等比较进阶的 optimization
的方法,才能够得到好的结果。</p>
<p>现在我们要从另外一个方向想,<strong>直接把难做的 error surface
把它改掉</strong>,看能不能够改得好做一点。在做这件事之前,也许我们第一个要问的问题就是,有这一种状况,$w_1
$ 跟 <span class="math inline">\(w_2\)</span>
它们的<strong>斜率差很多</strong>的这种状况,到底是从什麼地方来的。</p>
<p>假设我现在有一个非常非常非常简单的 model,它的输入是 <span class="math inline">\(x_1\)</span> 跟 <span class="math inline">\(x_2\)</span>,它对应的参数就是 $ w_1 $ 跟 <span class="math inline">\(w_2\)</span>,它是一个 linear 的 model,没有
activation function。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011440514.png" alt="image-20220616212341359" style="zoom:67%;"></p>
<p>$ w_1 $ 乘 <span class="math inline">\(x_1\)</span>,<span class="math inline">\(w_2\)</span> 乘 <span class="math inline">\(x_2\)</span> 加上 b 以后就得到 y,然后会计算 y 跟
<span class="math inline">\(\hat{y}\)</span> 之间的差距当做 e,把所有
training data e 加起来就是你的 Loss，然后去 minimize 你的
Loss，那什麼样的状况我们会產生像上面这样子,<strong>比较不好 train 的
error surface</strong> 呢？</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011440611.png" alt="image-20220616212421658" style="zoom:67%;"></p>
<p>当我们对 <strong>$ w_1 $ 有一个小小的改变</strong>,比如说加上 delta $
w_1 $ 的时候,那这个 L 也会有一个改变,那这个 $ w_1 $ 呢,是透过 $ w_1 $
改变的时候,你就改变了 y,y 改变的时候你就改变了
e,然后接下来就<strong>改变了 L</strong>。</p>
<p>那什麼时候 $ w_1 $ 的改变会对 L 的影响很小呢,也就是它在 error surface
上的斜率会很小呢？一个可能性是当你的 <strong>input
很小的时候</strong>,假设 <span class="math inline">\(x_1\)</span>
的值在不同的 training example 裡面,它的值都很小,那因為 <span class="math inline">\(x_1\)</span> 是直接乘上 $ w_1 $，如果 <span class="math inline">\(x_1\)</span> 的值都很小,$ w_1 $
有一个变化的时候,它得到的,它<strong>对 y 的影响也是小的</strong>,对 e
的影响也是小的,它对 L 的影响就会是小的。反之呢,如果今天是 <span class="math inline">\(x_2\)</span> 的话。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011440761.png" alt="image-20220616212503953" style="zoom:67%;"></p>
<p>那假设 <strong><span class="math inline">\(x_2\)</span>
的值都很大</strong>,当你的 <span class="math inline">\(w_2\)</span>
有一个小小的变化的时候,虽然 <span class="math inline">\(w_2\)</span>
这个变化可能很小,但是因為它乘上了 <span class="math inline">\(x_2\)</span>,<span class="math inline">\(x_2\)</span> 的值很大,那 y 的变化就很大,那 e
的变化就很大,那 L 的变化就会很大,就会导致我们在 w
这个方向上,做变化的时候,我们把 w 改变一点点,那我们的 error surface
就会有很大的变化。</p>
<p>所以你发现说,既然在这个 linear 的 model 裡面,当我们 input 的
feature,<strong>每一个 dimension 的值,它的 scale
差距很大</strong>的时候,我们就可能產生像这样子的 error
surface,就可能產生<strong>不同方向,斜率非常不同,坡度非常不同的 error
surface</strong>。</p>
<p>所以怎麼办呢,我们有没有可能给feature 裡面<strong>不同的
dimension,让它有同样的数值的范围</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011441571.png" alt="image-20220616212559236" style="zoom:67%;"></p>
<p>如果我们可以给不同的
dimension,同样的数值范围的话,那我们可能就可以製造比较好的 error
surface,让 training 变得比较容易一点</p>
<p>其实有很多不同的方法,这些不同的方法,往往就合起来统称為Feature
Normalization</p>
<h3><span id="二-feature-normalization">二、Feature Normalization</span></h3>
<p>以下所讲的方法只是Feature Normalization 的一种可能性,它<strong>并不是
Feature Normalization 的全部</strong>,假设 <span class="math inline">\(x^1\)</span> 到 <span class="math inline">\(x^R\)</span>,是我们所有的训练资料的 feature
vector</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011441532.png" alt="image-20220616221138101" style="zoom:67%;"></p>
<p>我们把所有训练资料的 feature vector ,统统都集合起来,那每一个 vector
,<span class="math inline">\(x_1\)</span> 裡面就 $x^1_1 $代表 <span class="math inline">\(x_1\)</span> 的第一个 element,$x^2_1 $,就代表
<span class="math inline">\(x_2\)</span> 的第一个 element,以此类推</p>
<p>那我们把<strong>不同笔资料即不同 feature vector,同一个
dimension</strong> 裡面的数值,把它取出来,然后去计算某一个 dimension 的
mean，它的 mean 呢 就是<span class="math inline">\(m_i\)</span>，我们计算第 i 个 dimension
的,standard deviation,我们用<span class="math inline">\(\sigma_i\)</span>来表示它</p>
<p>那接下来我们就可以做一种 normalization,那这种 normalization
其实叫做<strong>标準化</strong>,其实叫
standardization,不过我们这边呢,就等一下都统称 normalization 就好了 <span class="math display">\[
\tilde{x}^r_i ← \frac{x^r_i-m_i}{\sigma_i}
\]</span> 我们就是把这边的某一个数值x,减掉这一个 dimension 算出来的
mean,再除掉这个 dimension,算出来的 standard deviation,得到新的数值叫做
<span class="math inline">\(\tilde{x}\)</span></p>
<p>然后得到新的数值以后,<strong>再把新的数值把它塞回去</strong>,以下都用这个
tilde来代表有被 normalize 后的数值</p>
<p>那做完 normalize 以后有什麼好处呢？</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011441247.png" alt="image-20220616221152221" style="zoom:67%;"></p>
<ul>
<li><p>做完 normalize 以后啊,这个 dimension 上面的数值就会平均是
0,然后它的 variance就会是 1,所以<strong>这一排数值的分布就都会在 0
上下</strong></p></li>
<li><p>对每一个 dimension都做一样的 normalization,就会发现所有 feature
不同 dimension 的数值都在 0 上下,那你可能就可以<strong>製造一个,比较好的
error surface</strong></p></li>
</ul>
<p>所以像这样子 Feature Normalization 的方式,往往对你的 training
有帮助,它可以让你在做 gradient descent 的时候,这个 gradient
descent,<strong>它的 Loss 收敛更快一点,可以让你的 gradient
descent,它的训练更顺利一点</strong>,这个是 Feature Normalization</p>
<h3><span id="三-considering-deep-learning">三、Considering Deep Learning</span></h3>
<p><span class="math inline">\(\tilde{x}\)</span> 代表 normalize 的
feature,把它丢到 deep network 裡面,去做接下来的计算和训练,所以把 <span class="math inline">\(x_1\)</span> tilde 通过第一个 layer 得到 <span class="math inline">\(z^1\)</span>,那你有可能通过 activation
function,不管是选 Sigmoid 或者 ReLU 都可以,然后再得到 <span class="math inline">\(a^1\)</span>,然后再通过下一层等等,那就看你有几层
network 你就做多少的运算</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011441807.png" alt="image-20220616221202386" style="zoom:67%;"></p>
<p>所以每一个 x 都做类似的事情,但是如果我们进一步来想的话,对 <span class="math inline">\(w_2\)</span> 来说</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011441112.png" alt="image-20220616221211793" style="zoom:67%;"></p>
<p>这边的 <span class="math inline">\(a^1\)</span> <span class="math inline">\(a^3\)</span> 这边的 <span class="math inline">\(z^1\)</span> <span class="math inline">\(z^3\)</span>,其实也是另外一种 input,如果这边 <span class="math inline">\(\tilde{x}\)</span>,虽然它已经做 normalize
了,但是通过 $ w_1 $ 以后它就<strong>没有做 normalize</strong>,如果 <span class="math inline">\(\tilde{x}\)</span> 通过 $ w_1 $ 得到是 <span class="math inline">\(z^1\)</span>,而 <span class="math inline">\(z^1\)</span> 不同的 dimension
间,它的数值的分布仍然有很大的差异的话,那我们要 train <span class="math inline">\(w_2\)</span> 第二层的参数,会不会也有困难呢</p>
<p>对 <span class="math inline">\(w_2\)</span> 来说,这边的 a 或这边的 z
其实也是一种 feature,我们应该要对这些 feature 也做 normalization</p>
<p>那如果你选择的是 Sigmoid,那可能比较推荐对 z 做 Feature
Normalization,因為Sigmoid 是一个 s 的形状,那它在 0
附近斜率比较大,所以如果你对 z 做 Feature Normalization,把所有的值都挪到
0 附近,那你到时候算 gradient 的时候,算出来的值会比较大</p>
<p>那不过因為你不见得是用 sigmoid ,所以你也不一定要把 Feature
Normalization放在 z
这个地方,如果是选别的,也许你选a也会有好的结果,也说不定，<strong>Ingeneral
而言,这个 normalization,要放在 activation function
之前,或之后都是可以的,在实作上,可能没有太大的差别</strong>,好
那我们这边呢,就是对 z 呢,做一下 Feature Normalization，</p>
<p>那怎麼对 z 做 Feature Normalization 呢</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011441486.png" alt="image-20220616221239128" style="zoom:67%;"></p>
<p>那你就把 z,想成是另外一种 feature ,我们这边有 <span class="math inline">\(z^1\)</span> <span class="math inline">\(z^2\)</span> <span class="math inline">\(z^3\)</span>,我们就把 <span class="math inline">\(z^1\)</span> <span class="math inline">\(z^2\)</span> <span class="math inline">\(z^3\)</span> 拿出来</p>
<ul>
<li><strong>算一下它的 mean</strong>，这边的 <span class="math inline">\(μ\)</span> 是一个 vector,我们就把 <span class="math inline">\(z^1\)</span> <span class="math inline">\(z^2\)</span> <span class="math inline">\(z^3\)</span>,这三个 vector 呢,把它平均起来,得到
<span class="math inline">\(μ\)</span> 这个 vector</li>
<li><strong>算一个 standard deviation</strong>,这个 standard deviation
呢,这边这个成 <span class="math inline">\(\sigma\)</span>,它也代表了一个
vector,那这个 vector 怎麼算出来呢,你就把 <span class="math inline">\(z^i\)</span>减掉 <span class="math inline">\(μ\)</span>,然后取平方,这边的平方,这个 notation
有点 abuse 啊,这边的平方就是指,对每一个 element
都去做平方,然后再开根号,这边开根号指的是对每一个
element,向量裡面的每一个 element,都去做开根号,得到 <span class="math inline">\(\sigma\)</span>,反正你知道我的意思就好</li>
</ul>
<p>把这三个 vector,裡面的每一个 dimension,都去把它的 <span class="math inline">\(μ\)</span> 算出来,把它的 <span class="math inline">\(\sigma\)</span> 算出来,好
我这边呢,就不把那些箭头呢 画出来了,从 <span class="math inline">\(z^1\)</span> <span class="math inline">\(z^2\)</span> <span class="math inline">\(z^3\)</span>,算出 <span class="math inline">\(μ\)</span>,算出 <span class="math inline">\(\sigma\)</span>。</p>
<p>接下来就把这边的每一个 z ,都去减掉 <span class="math inline">\(μ\)</span> 除以 <span class="math inline">\(\sigma\)</span>,你把 <span class="math inline">\(z^i\)</span>减掉 <span class="math inline">\(μ\)</span>,除以 <span class="math inline">\(\sigma\)</span>,就得到 <span class="math inline">\(z^i\)</span>的 tilde。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011441288.png" alt="image-20220616221403703" style="zoom:50%;"></p>
<p>那这边的 <span class="math inline">\(μ\)</span> 跟 <span class="math inline">\(\sigma\)</span>,它都是<strong>向量</strong>,所以这边这个除的意思是<strong>element
wise 的相除</strong>,就是 <span class="math inline">\(z^i\)</span>减
<span class="math inline">\(μ\)</span>,它是一个向量,所以分子的地方是一个向量,分母的地方也是一个向量,把这个两个向量,它们对应的
element 的值相除,是我这边这个除号的意思,这边得到 Z 的 tilde。</p>
<p>所以我们就是把 <span class="math inline">\(z^1\)</span> 减 <span class="math inline">\(μ\)</span> 除以 <span class="math inline">\(\sigma\)</span>,得到 <span class="math inline">\(z^1\)</span> tilde,同理 <span class="math inline">\(z^2\)</span> 减 <span class="math inline">\(μ\)</span> 除以 <span class="math inline">\(\sigma\)</span>,得到 <span class="math inline">\(z^2\)</span> tilde,<span class="math inline">\(z^3\)</span> 减 <span class="math inline">\(μ\)</span> 除以 <span class="math inline">\(\sigma\)</span>,得到 <span class="math inline">\(z^3\)</span> tilde,那就把这个 <span class="math inline">\(z^1\)</span> <span class="math inline">\(z^2\)</span> <span class="math inline">\(z^3\)</span>,做 Feature Normalization,变成 <span class="math inline">\(z^1\)</span> tilde,<span class="math inline">\(z^2\)</span> tilde 跟 <span class="math inline">\(z^3\)</span> 的 tilde。</p>
<p>接下来就看你爱做什麼 就做什麼啦,通过 activation function,得到其他
vector,然后再通过,再去通过其他 layer 等等,这样就可以了,这样你就等於对
<span class="math inline">\(z^1\)</span> <span class="math inline">\(z^2\)</span> <span class="math inline">\(z^3\)</span>,做了 Feature Normalization,变成 <span class="math inline">\(\tilde{z}^1\)</span> <span class="math inline">\(\tilde{z}^2\)</span> <span class="math inline">\(\tilde{z}^3\)</span> 。</p>
<p>在这边有一件有趣的事情,这边的 <span class="math inline">\(μ\)</span>
跟 <span class="math inline">\(\sigma\)</span>,它们其实都是根据 <span class="math inline">\(z^1\)</span> <span class="math inline">\(z^2\)</span> <span class="math inline">\(z^3\)</span> 算出来的。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011442381.png" alt="image-20220616221515889" style="zoom: 67%;"></p>
<p>所以这边 <span class="math inline">\(z^1\)</span>
啊,它本来,如果我们没有做 Feature Normalization 的时候,你改变了 <span class="math inline">\(z^1\)</span> 的值,你会改变这边 a
的值,但是现在啊,当你改变 <span class="math inline">\(z^1\)</span>
的值的时候,<span class="math inline">\(μ\)</span> 跟 <span class="math inline">\(\sigma\)</span> 也会跟著改变,<span class="math inline">\(μ\)</span> 跟 <span class="math inline">\(\sigma\)</span> 改变以后,<span class="math inline">\(z^2\)</span> 的值 <span class="math inline">\(a^2\)</span> 的值,<span class="math inline">\(z^3\)</span> 的值 <span class="math inline">\(a^3\)</span> 的值,也会跟著改变。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011442075.png" alt="image-20220616221555203" style="zoom: 67%;"></p>
<p>所以<strong>之前</strong>,我们每一个 <span class="math inline">\(\tilde{x}_1\)</span> <span class="math inline">\(\tilde{x}_2\)</span> <span class="math inline">\(\tilde{x}_3\)</span>,它是<strong>独立分开处理的</strong>,但是我们在做
<strong>Feature Normalization 以后</strong>,这三个
example,它们变得<strong>彼此关联</strong>了。</p>
<p>我们这边 <span class="math inline">\(z^1\)</span> 只要有改变,接下来
<span class="math inline">\(z^2\)</span> <span class="math inline">\(a^2\)</span> <span class="math inline">\(z^3\)</span> <span class="math inline">\(a^3\)</span>,也都会跟著改变,所以这边啊,其实你要把,当你有做
Feature Normalization 的时候,你要把这一整个 process,就是有收集一堆
feature,把这堆 feature 算出 <span class="math inline">\(μ\)</span> 跟
<span class="math inline">\(\sigma\)</span> 这件事情,当做是 network
的一部分。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011442417.png" alt="image-20220616221637917" style="zoom:67%;"></p>
<p>也就是说,你现在有一个比较大的 network</p>
<ul>
<li>你之前的 network,都只吃一个 input,得到一个 output</li>
<li>现在你有一个比较大的 network,这个大的 network,它是吃一堆
input,用这堆 input 在这个 network 裡面,要算出 <span class="math inline">\(μ\)</span> 跟 <span class="math inline">\(\sigma\)</span>,然后接下来產生一堆 output</li>
</ul>
<p>那这个地方比较抽象,只可会意 不可言传这样子</p>
<p>那这边就会有一个问题了,因為你的训练资料裡面的 data 非常多,现在一个
data set,benchmark corpus 都上百万笔资料， GPU 的
memory,根本没有办法,把它整个 data set 的 data 都 load 进去。</p>
<p><strong><font color="red"> 在实作的时候,你不会让这一个 network
考虑整个 training data 裡面的所有 example,你只会考虑一个 batch 裡面的
example</font></strong>,举例来说,你 batch 设 64,那你这个巨大的
network,就是把 64 笔 data 读进去,算这 64 笔 data 的 <span class="math inline">\(μ\)</span>,算这 64 笔 data 的 <span class="math inline">\(\sigma\)</span>,对这 64 笔 data 都去做
normalization</p>
<p>因為我们在实作的时候,我们只对一个 batch 裡面的 data,做
normalization,所以这招叫做 <strong>Batch Normalization</strong></p>
<p>那这个 Batch Normalization,显然有一个问题
就是,<strong>你一定要有一个够大的 batch,你才算得出 <span class="math inline">\(μ\)</span> 跟 <span class="math inline">\(\sigma\)</span></strong>,假设你今天,你 batch size
设 1,那你就没有什麼 <span class="math inline">\(μ\)</span> 或 <span class="math inline">\(\sigma\)</span> 可以算</p>
<p>所以这个 Batch Normalization,是适用於 batch size 比较大的时候,因為
batch size 如果比较大,<strong>也许这个 batch size 裡面的
data,就足以表示,整个 corpus
的分布</strong>,那这个时候你就可以,把这个本来要对整个 corpus,做 Feature
Normalization 这件事情,改成只在一个 batch,做 Feature Normalization,作為
approximation。</p>
<p><strong>在做 Batch Normalization
的时候,往往还会有这样的设计你算出这个 <span class="math inline">\(\tilde{z}\)</span> 以后</strong></p>
<ul>
<li><strong><font color="red"> 接下来你会把这个 <span class="math inline">\(\tilde{z}\)</span>,再乘上另外一个向量叫做 <span class="math inline">\(γ\)</span>,这个 <span class="math inline">\(γ\)</span> 也是一个向量,所以你就是把 <span class="math inline">\(\tilde{z}\)</span> 跟 <span class="math inline">\(γ\)</span> 做 element wise 的相乘,把 z
这个向量裡面的 element,跟 <span class="math inline">\(γ\)</span>
这个向量裡面的 element,两两做相乘。</font></strong></li>
<li><strong><font color="red"> 再加上 <span class="math inline">\(β\)</span> 这个向量,得到 <span class="math inline">\(\hat{z}\)</span>。</font></strong></li>
</ul>
<p><strong>而 <span class="math inline">\(β\)</span> 跟 <span class="math inline">\(γ\)</span>,你要把它想成是 network
的参数,它是另外再被learn出来的,</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011442134.png" alt="image-20220616222053826" style="zoom:50%;"></p>
<h5><span id="那為什麼要加上-β-跟-γ-呢">那為什麼要加上 <span class="math inline">\(β\)</span> 跟 <span class="math inline">\(γ\)</span> 呢？</span></h5>
<p>有人可能会觉得说,如果我们做 normalization 以后,那这边的 <span class="math inline">\(\tilde{z}\)</span>,它的平均就一定是
0,那也许,<strong>今天如果平均是 0 的话,就是给那 network
一些限制</strong>,那<strong>也许这个限制会带来什麼负面的影响</strong>,所以我们把
<span class="math inline">\(β\)</span> 跟 <span class="math inline">\(γ\)</span> 加回去。</p>
<p>然后让 network 呢,现在它的 hidden layer 的 output平均不是 0
的话,他就自己去learn这个 <span class="math inline">\(β\)</span> 跟 <span class="math inline">\(γ\)</span>,来调整一下输出的分布,来调整这个 <span class="math inline">\(\hat{z}\)</span> 的分布</p>
<p>但讲到这边又会有人问说,刚才不是说做 Batch Normalization
就是,為了要让每一个不同的 dimension,它的 range
都是一样吗,现在如果加去乘上 <span class="math inline">\(γ\)</span>,再加上 <span class="math inline">\(β\)</span>,把 <span class="math inline">\(γ\)</span> 跟 <span class="math inline">\(β\)</span> 加进去,</p>
<h5><span id="这样不会不同dimension-的分布它的-range-又都不一样了吗">这样不会不同
dimension 的分布,它的 range 又都不一样了吗？</span></h5>
<p>有可能,但是你实际上在训练的时候,这个 <span class="math inline">\(γ\)</span> 跟 <span class="math inline">\(β\)</span> 的初始值啊</p>
<ul>
<li><strong>你会把这个 <span class="math inline">\(γ\)</span> 的初始值
就都设為 1,所以 <span class="math inline">\(γ\)</span>
是一个裡面的值,一开始其实是一个裡面的值,全部都是 1 的向量</strong></li>
<li><strong>那 <span class="math inline">\(β\)</span>
是一个裡面的值,全部都是 0 的向量,所以 <span class="math inline">\(γ\)</span> 是一个 one vector,都是 1 的向量,<span class="math inline">\(β\)</span> 是一个 zero vector,裡面的值都是 0
的向量</strong></li>
</ul>
<p>所以让你的 network 在一开始训练的时候,每一个 dimension
的分布,是比较接近的,也许训练到后来,你已经训练够长的一段时间,已经找到一个比较好的
error surface,走到一个比较好的地方以后,那再把 <span class="math inline">\(γ\)</span> 跟 <span class="math inline">\(β\)</span> 慢慢地加进去,好所以加 Batch
Normalization,往往对你的训练是有帮助的。</p>
<h3><span id="四-testing">四、Testing</span></h3>
<h5><span id="这个batch-normalization-在-inference或是-testing的时候会有什麼样的问题呢">这个
Batch Normalization 在 inference,或是 testing
的时候,会有什麼样的问题呢？</span></h5>
<p>在 testing 的时候,如果 当然如果今天你是在做作业,我们一次会把所有的
testing 的资料给你,所以你确实也可以在 testing 的资料上面,製造一个一个
batch。</p>
<p><strong>但是假设你真的有系统上线,你是一个真正的线上的
application,你可以说,我今天一定要等 30,比如说你的 batch size 设
64,我一定要等 64
笔资料都进来,我才一次做运算吗,这显然是不行的。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011442171.png" alt="image-20220616222338443" style="zoom: 67%;"></p>
<p>但是在做 Batch Normalization 的时候,一个 <span class="math inline">\(\tilde{x}\)</span>,一个 normalization 过的 feature
进来,然后你有一个 z,你的 z 呢,要减掉 <span class="math inline">\(μ\)</span> 跟除 <span class="math inline">\(\sigma\)</span>,那这个 <span class="math inline">\(μ\)</span> 跟 <span class="math inline">\(\sigma\)</span>,是<strong>用一个 batch
的资料算出来的</strong></p>
<h5><span id="但如果今天在testing-的时候根本就没有-batch那我们要怎麼算这个-μ跟怎麼算这个-sigma-呢">但如果今天在
testing 的时候,根本就没有 batch,那我们要怎麼算这个 <span class="math inline">\(μ\)</span>,跟怎麼算这个 <span class="math inline">\(\sigma\)</span> 呢？</span></h5>
<p>所以真正的,这个实作上的解法是这个样子的,如果你看那个 PyTorch
的话呢,Batch Normalization 在 testing
的时候,你并不需要做什麼特别的处理,PyTorch 帮你处理好了</p>
<p><strong><font color="red"> 在 training 的时候,如果你有在做 Batch
Normalization 的话,在 training 的时候,你每一个 batch 计算出来的 <span class="math inline">\(μ\)</span> 跟 <span class="math inline">\(\sigma\)</span>,他都会拿出来算 moving
average</font></strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011442960.png" alt="image-20220616222438574" style="zoom:67%;"></p>
<p>你每一次取一个 batch 出来的时候,你就会算一个 <span class="math inline">\(μ^1\)</span>,取第二个 batch 出来的时候,你就算个
<span class="math inline">\(μ^2\)</span>,一直到取第 t 个 batch
出来的时候,你就算一个 <span class="math inline">\(μ^t\)</span>
。接下来你会算一个 moving average,你会把你现在算出来的 <span class="math inline">\(μ\)</span> 的一个平均值,叫做 <span class="math inline">\(μ\)</span> bar,乘上某一个
factor,那这也是一个常数,这个这也是一个 constant,这也是一个那个 hyper
parameter,也是需要调的。</p>
<p>在 PyTorch 裡面,我没记错 他就设 0.1,我记得他 P 就设 0.1,好,然后加上 1
减 P,乘上 <span class="math inline">\(μ^t\)</span> ,然后来更新你的 <span class="math inline">\(μ\)</span> 的平均值,然后最后在 testing
的时候,你就不用算 batch 裡面的 <span class="math inline">\(μ\)</span> 跟
<span class="math inline">\(\sigma\)</span> 了。</p>
<p>因為 testing 的时候,在真正 application 上,也没有 batch
这个东西,你就直接拿 <span class="math inline">\(\barμ\)</span> 跟 <span class="math inline">\(\bar\sigma\)</span> ,也就是 <span class="math inline">\(μ\)</span> 跟 <span class="math inline">\(\sigma\)</span> 在训练的时候,得到的 moving
average,<span class="math inline">\(\barμ\)</span> 跟 <span class="math inline">\(\bar\sigma\)</span> ,来取代这边的 <span class="math inline">\(μ\)</span> 跟 <span class="math inline">\(\sigma\)</span>,这个就是 Batch Normalization,在
testing 的时候的运作方式。</p>
<h3><span id="五-comparison">五、Comparison</span></h3>
<p>好 那这个是从 Batch
Normalization,原始的文件上面截出来的一个实验结果,那在原始的文件上还讲了很多其他的东西,举例来说,我们今天还没有讲的是<strong>,Batch
Normalization 用在 CNN
上,要怎麼用呢</strong>,那你自己去读一下原始的文献,裡面会告诉你说,Batch
Normalization 如果用在 CNN 上,应该要长什麼样子。</p>
<blockquote>
<p><strong>卷积层上的BN使用</strong>，其实也是使用了<strong>类似权值共享的策略</strong>，<strong>把一整张特征图当做一个神经元进行处理</strong>。</p>
<p>卷积神经网络经过卷积后得到的是一系列的特征图，如果min-batch
sizes为m，那么网络某一层输入数据可以表示为四维矩阵(m,f,p,q)，m为min-batch
sizes，f为特征图个数，p、q分别为特征图的宽高。</p>
<p>在cnn中我们可以把每个特征图看成是一个特征处理（一个神经元），因此在使用Batch
Normalization，mini-batch size 的大小就是：m * p *
q，于是对于每个特征图都只有一对可学习参数：γ、β。</p>
<p>相当于求取所有样本所对应的一个特征图的所有神经元的平均值、方差，然后对这个特征图神经元做归一化。</p>
<ul>
<li><strong>nb在每一个特征图上的所有点沿着一个batch的样本数据的方向对数据进行求和，求平均等处理，不考虑不同特征图的数据间的运算。</strong></li>
<li><strong>lrb在每一个特征图上沿着不同特征图的方向对数据进行求和，求平均等处理，不考虑不同输入样本数据间的运算。</strong></li>
</ul>
</blockquote>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011442587.png" alt="image-20220616222534083">
<figcaption aria-hidden="true">image-20220616222534083</figcaption>
</figure>
<p>这个是原始文献上面截出来的一个数据</p>
<ul>
<li>横轴呢,代表的是训练的过程，纵轴代表的是 validation set 上面的
accuracy</li>
<li>那这个<strong>黑色</strong>的虚线是<strong>没有做 Batch
Normalization</strong> 的结果,它用的是 inception 的 network,就是某一种
network 架构啦,也是以 CNN 為基础的 network 架构</li>
<li>然后如果有做 Batch
Normalization,你会得到<strong>红色</strong>的这一条虚线,那你会发现说,红色这一条虚线,它<strong>训练的速度,显然比黑色的虚线还要快很多</strong>,虽然最后收敛的结果啊,就你只要给它足够的训练的时间,可能都跑到差不多的
accuracy,但是<strong>红色这一条虚线,可以在比较短的时间内,就跑到一样的
accuracy</strong>,那这边这个蓝色的菱形,代表说这几个点的那个 accuracy
是一样的</li>
<li><strong>粉红色</strong>的线是 sigmoid function,就 sigmoid function
一般的认知,我们虽然还没有讨论这件事啦,但一般都会选择 ReLu,而不是用
sigmoid function,因為 sigmoid function,它的 training
是比较困难的,但是这边想要强调的点是说,<strong>就算是 sigmoid
比较难搞的,加 Batch Normalization,还是 train 的起来</strong>,那这边没有
sigmoid,没有做 Batch Normalization
的结果,因為在这个实验上,作者有说,sigmoid 不加 Batch Normalization,根本连
train 都 train 不起来</li>
<li>蓝色的实线跟这个蓝色的虚线呢,是把 learning rate 设比较大一点,乘
5,就是 learning rate 变原来的 5 倍,然后乘 30,就是 learning rate 变原来的
30 倍,那因為<strong>如果你做 Batch Normalization 的话,那你的 error
surface 呢,会比较平滑
比较容易训练,所以你可以把你的比较不崎嶇,所以你就可以把你的 learning rate
呢,设大一点</strong></li>
</ul>
<h3><span id="六-internal-covariate-shift">六、Internal Covariate Shift?</span></h3>
<p><strong>好接下来的问题就是,Batch
Normalization,它為什麼会有帮助呢</strong>,在原始的 Batch
Normalization,那篇 paper 裡面,他提出来一个概念,叫做<strong>internal
covariate shift,covariate
shift</strong>(训练集和预测集样本分布不一致的问题就叫做“<em>covariate
shift</em>”现象) 这个词汇是原来就有的,internal covariate
shift,我认為是,Batch Normalization 的作者自己发明的。他认為说今天在
train network 的时候,会有以下这个问题,这个问题是这样。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011443501.png" alt="image-20220616225043073" style="zoom: 67%;"></p>
<p>network 有很多层</p>
<ul>
<li><p>x 通过第一层以后 得到 a</p></li>
<li><p>a 通过第二层以后 得到 b</p></li>
<li><p>计算出 gradient 以后,把 A update 成 A′,把 B 这一层的参数 update
成 B′</p></li>
</ul>
<p>但是作者认為说,我们在计算 B,update 到 B′ 的 gradient
的时候,这个时候前一层的参数是 A 啊,或者是前一层的 output 是小 a 啊</p>
<p>那当前一层从 A 变成 A′ 的时候,它的 output 就从小 a 变成小 a′ 啊</p>
<p>但是我们计算这个 gradient 的时候,我们是根据这个 a 算出来的啊,所以这个
update 的方向,也许它<strong>适合用在 a 上,但不适合用在 a′
上面</strong></p>
<p>那如果说 Batch Normalization 的话,我们会让,因為我们每次都有做
normalization,我们就会让 a 跟 a′
呢,它的分布比较接近,也许这样就会对训练呢,有帮助。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011443393.png" alt="image-20220616225149673" style="zoom:67%;"></p>
<p>但是有一篇 paper 叫做,How Does Batch Normalization,Help
Optimization,然后他就<strong>打脸了internal covariate shift
的这一个观点</strong>。</p>
<p>在这篇 paper 裡面,他从各式各样的面向来告诉你说,i<strong>nternal
covariate shift,首先它不一定是 training network 的时候的一个问题,然后
Batch Normalization,它会比较好,可能不见得是因為,它解决了 internal
covariate shift。</strong></p>
<p>那在这篇 paper
裡面呢,他做了很多很多的实验,比如说他比较了训练的时候,这个 a 的分布的变化
发现<strong>,不管有没有做 Batch
Normalization,它的变化都不大</strong>。</p>
<p>然后他又说,就算是变化很大,对 training
也没有太大的伤害,然后他又说,不管你是根据 a 算出来的 gradient,还是根据 a′
算出来的 gradient,方向居然都差不多。</p>
<p>所以他告诉你说,internal covariate shift,可能不是 training network
的时候,最主要的问题,它可能也不是,Batch Normalization
会好的一个的关键,那有关更多的实验,你就自己参见这篇文章。</p>
<h5><span id="為什麼-batchnormalization-会比较好呢">為什麼 Batch
Normalization 会比较好呢？</span></h5>
<p>那在这篇 How Does Batch Normalization,Help Optimization
这篇论文裡面,他从实验上,也从理论上,至少<strong>支持了 Batch
Normalization,可以改变 error surface,让 error surface
比较不崎嶇这个观点</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011443110.png" alt="image-20220616225308853" style="zoom:67%;"></p>
<p>所以这个观点是有理论的支持,也有实验的佐证的,那在这篇文章裡面呢,作者还讲了一个非常有趣的话,他说他觉得啊,这个
Batch Normalization 的 positive impact。</p>
<p>因為他说,如果我们要让 network,这个 error surface
变得比较不崎嶇,<strong>其实不见得要做 Batch
Normalization,感觉有很多其他的方法,都可以让 error surface
变得不崎嶇</strong>,那他就试了一些其他的方法,发现说,跟 Batch
Normalization performance
也差不多,甚至还稍微好一点,所以他就讲了下面这句感嘆。</p>
<p>他觉得说,这个,positive impact of batchnorm on training,可能是
somewhat,<strong>serendipitous</strong>,什麼是 serendipitous
呢,这个字眼可能可以翻译成偶然的,但偶然并没有完全表达这个词汇的意思,这个词汇的意思是说,你发现了一个什麼意料之外的东西。</p>
<p>那这篇文章的作者也觉得,Batch Normalization
也像是盘尼西林一样,是一种偶然的发现,但无论如何,它是一个有用的方法。</p>
<h3><span id="to-learn-more">To learn more ……</span></h3>
<p>那其实 Batch Normalization,不是唯一的 normalization,normalization
的方法有一把啦,那这边就是列了几个比较知名的,</p>
<p>Batch Renormalization https://arxiv.org/abs/1702.03275 Layer
Normalization https://arxiv.org/abs/1607.06450 Instance Normalization
https://arxiv.org/abs/1607.08022 Group Normalization
https://arxiv.org/abs/1803.08494 Weight Normalization
https://arxiv.org/abs/1602.07868 Spectrum Normalization
https://arxiv.org/abs/1705.10941</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>训练技巧</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>BatchNormalization</tag>
      </tags>
  </entry>
  <entry>
    <title>理论基础（2）激活函数</title>
    <url>/posts/M1YMBK/</url>
    <content><![CDATA[<h3><span id="一-激活函数">一、激活函数</span></h3>
<p><strong><font color="red">
激活函数简述激活函数是向神经网络中引入非线性因素，通过激活函数神经网络就可以拟合各种曲线。激活函数主要分为饱和激活函数（Saturated
Neurons）和非饱和函数（One-sided
Saturations）。</font></strong>Sigmoid和Tanh是饱和激活函数，而ReLU以及其变种为非饱和激活函数。非饱和激活函数主要有如下优势：</p>
<ul>
<li><strong>非饱和激活函数可以解决梯度消失问题</strong>。</li>
<li><strong>非饱和激活函数可以加速收敛</strong>。</li>
</ul>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301635756.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<span id="more"></span>
<h4><span id="11-梯度消失vanishinggradients">1.1 梯度消失(Vanishing
Gradients)</span></h4>
<p>Sigmoid的函数图像和Sigmoid的梯度函数图像分别为(a)、(e)，从图像可以看出，函数两个边缘的梯度约为0，梯度的取值范围为(0,0.25)。求解方程为：</p>
<p><span class="math display">\[
\begin{gathered}y=1 /\left(1+e^{-x}\right) \\
y^{\prime}=y(1-y)\end{gathered}
\]</span></p>
<ul>
<li><strong>Sigmoid极容易导致梯度消失问题</strong>。饱和神经元会使得梯度消失问题雪上加霜，假设神经元输入Sigmoid的值特别大或特别小，对应的梯度约等于0，即使从上一步传导来的梯度较大，该神经元权重(w)和偏置(bias)的梯度也会趋近于0，导致参数无法得到有效更新。</li>
<li><strong>计算费时</strong>。
在神经网络训练中，常常要计算Sigmid的值进行幂计算会导致耗时增加。</li>
<li><strong>Sigmoid函数不是关于原点中心对称的（zero-centered)</strong>，Tanh激活函数解决了原点中心对称问题。</li>
</ul>
<h4><span id="12-relu与死亡神经元">1.2 ReLU与死亡神经元</span></h4>
<p><strong>(1) ReLU解决梯度消失问题</strong></p>
<p><strong>ReLU激活函数的提出就是为了解决梯度消失问题。</strong>ReLU的梯度只可以取两个值：0或1，当输入小于0时，梯度为0；当输入大于0时，梯度为1。好处就是：ReLU的梯度的连乘不会收敛到0，连乘的结果也只可以取两个值：0或1
。如果值为1，梯度保持值不变进行前向传播；如果值为0
,梯度从该位置停止前向传播。</p>
<ul>
<li><strong>Sigmoid函数是双侧饱和的，即朝着正负两个方向函数值都会饱和</strong>；</li>
<li><strong>ReLU函数是单侧饱和的，即只有朝着负方向，函数值才会饱和</strong>。严格意义上来说，将ReLU函数值为0的部分称作饱和是不正确的(饱和应该是取值趋近于0)，但效果和饱和是一样的。</li>
</ul>
<p>假设神经元为检测某种特定特征的开关，高层神经元负责检测高级的/抽象的特征(有着更丰富的语义信息)，例如眼睛或者轮胎；低层神经元负责检测低级的/具象的特征(曲线或者边缘)。当开关处于开启状态，说明在输入范围内检测到了对应的特征，且正值越大代表特征越明显。加入某个神经元负责检测边缘，则正值越大代表边缘区分越明显(sharp)。假设一个负责检测边缘的神经元，激活值为1相对于激活值为0.5来说，检测到的边缘区分地更明显；但激活值-1相对于-0.5来说就没有意义了，因为低于0的激活值都代表没有检测到边缘。<strong>所以用一个常量值0来表示检测不到特征是更为合理的，像ReLU这样单侧饱和的神经元就满足要求。</strong></p>
<p><strong>单侧饱和还能使得神经元对于噪声干扰更具鲁棒性</strong>。假设一个双侧都不饱和的神经元，正侧的不饱和导致神经元正值的取值各不相同，这是所希望的，因为正值的大小代表了检测特征信号的强弱。但负值的大小引入了背景噪声或者其他特征信息，这会给后续的神经元带来无用的干扰且可能导致神经元之间的相关性，相关性是容易造成模型病态的。例如检测直线的神经元和检测曲线的神经元可能有负相关性。在负值区域单侧饱和的神经元则不会有上述问题，噪声的程度大小被饱和区域都截断为0,避免了无用信息的干扰。</p>
<p>使用ReLU激活函数在计算上也是高效的。相对于Sigmoid函数梯度的计算，ReLU函数梯度取值只有0或1。且ReLU将负值截断为0
，为网络引入了稀疏性，进一步提升了计算高效性。</p>
<h4><span id="13-神经元死亡">1.3 神经元死亡</span></h4>
<p>ReLU尽管稀疏性可以提升计算高效性，但同样也可能阻碍训练过程。通常，激活函数的输入值有一偏置项(bias)，假设bias变得太小，以至于输入激活函数的值总是负的，那么反向传播过程经过该处的梯度恒为0,对应的权重和偏置参数此次无法得到更新。如果对于所有的样本输入，<strong>该激活函数的输入都是负的，那么该神经元再也无法学习，称为神经元”死亡“问题。</strong></p>
<p><strong>(1) Leaky ReLU可以解决神经元”死亡“问题</strong></p>
<p>Leaky ReLU的提出就是为了解决神经元”死亡“问题，Leaky
ReLU与ReLU很相似，仅在输入小于0的部分有差别，ReLU输入小于0的部分值都为0，而LeakyReLU输入小于0的部分，值为负，且有微小的梯度。函数图像为(d)。</p>
<p><strong>使用Leaky ReLU的好处就是：在反向传播过程中，对于Leaky
ReLU激活函数输入小于零的部分，也可以计算得到梯度(而不是像ReLU一样值为0)，这样就避免了梯度方向锯齿问题。</strong></p>
<p>α的分布满足均值为0,标准差为1的正态分布，该方法叫做随机Leaky
ReLU(Randomized Leaky ReLU)。原论文指出随机Leaky ReLU相比Leaky
ReLU能得更好的结果，且给出了参数α的经验值1/5.5(好于0.01)。至于为什么随机Leaky
ReLU能取得更好的结果，解释之一就是随机Leaky
ReLU小于0部分的随机梯度，为优化方法引入了随机性，这些随机噪声可以帮助参数取值跳出局部最优和鞍点。将α作为了需要学习的参数，该激活函数为PReLU(Parametrized
ReLU)。</p>
<h4><span id="14-eluexponential-linearunit">1.4 ELU(Exponential Linear
Unit)</span></h4>
<p>理想的激活函数应满足两个条件：</p>
<ul>
<li><strong>输出的分布是零均值的，可以加快训练速度。</strong></li>
<li><strong>激活函数是单侧饱和的，可以更好的收敛。</strong></li>
</ul>
<p>LeakyReLU和PReLU满足第1个条件，不满足第2个条件；而ReLU满足第2个条件，不满足第1个条件。两个条件都满足的激活函数为ELU(Exponential
Linear Unit)，函数图像如图（e）。其表达式如下：</p>
<p><span class="math display">\[
f(x)= \begin{cases}x, &amp; x&gt;0 . \\ \alpha\left(e^x-1\right), &amp;
x \leq 0 .\end{cases}
\]</span></p>
<h4><span id="15-梯度爆炸">1.5 梯度爆炸</span></h4>
<p>梯度误差是在神经网络训练期间计算的方向和梯度，神经网络以正确的方向和数值更新网络权重。在深度网络或递归神经网络中，梯度误差可能在更新过程中累积，造成非常大的梯度。这反过来会导致网络权重的大量更新，进而导致网络不稳定。<strong>在极端情况下，权重值可能变得太大，以至于溢出并导致NaN值现成梯度爆炸现象</strong>。</p>
<p><strong>梯度爆炸是通过指数增长发生的，通过在网络层（其值大于1.0）中重复乘以梯度。</strong></p>
<p><strong>梯度爆炸现象</strong>：模型无法“加入”训练数据，比如损失函数很差；模型不稳定，每次更新的损失变化很大；模型损失在训练过程中变为NaN</p>
<h5><span id="如何解决梯度爆炸"><strong><font color="red">如何解决梯度爆炸？</font></strong></span></h5>
<p>1.重现设计神经网络<strong>，减少网络层数、减小batch
szie、截断</strong>。</p>
<p>2.使用<strong>LSTM</strong></p>
<p>3.使用梯度裁剪、clipnorm=1.0 clipvalue=0.5</p>
<p>4.使用权重正则L1 &amp; L2</p>
<h3><span id="二-常用激活函数">二、常用激活函数</span></h3>
<p><strong>常用的激活函数：sigmoid，Tanh，ReLU，Leaky
ReLU，PReLU，ELU，Maxout</strong></p>
<h4><span id="21-sigmoid函数">2.1 <strong>sigmoid函数</strong></span></h4>
<p>sigmoid函数又称
Logistic函数，用于隐层神经元输出，取值范围为(0,1)，可以用来做二分类。</p>
<p><strong>表达式:</strong> <span class="math display">\[
$\sigma(x)=\frac{1}{1+e^{-x}}$
\]</span></p>
<p><strong>导数为：</strong> <span class="math display">\[
\sigma^{\prime}(x)=\sigma(x)[1-\sigma(x)]
\]</span>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301636365.jpg" alt="img" style="zoom: 50%;"></p>
<p><strong>优点</strong>：</p>
<ul>
<li>Sigmoid函数的输出在(0,1)之间，输出范围有限，优化稳定，可以用作输出层。</li>
<li>线性回归在实数域上敏感度一致，而<strong>逻辑回归在 0
附近敏感</strong>，在远离 0
点位置不敏感，这个的好处就是模型更加关注分类边界，可以增加模型的鲁棒性。</li>
<li>连续函数，便于求导。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>sigmoid函数在变量取绝对值非常大的正值或负值时会出现<strong>饱和</strong>现象，意味着函数会变得很平，并且对输入的微小改变会变得不敏感。【<strong>梯度消失</strong>】</li>
<li><strong>sigmoid函数的输出不是0均值的</strong>，会导致后层的神经元的输入是非0均值的信号，这会对梯度产生影响。具体可参考下面，简单说就是可能导致<strong>收敛效率低</strong>的问题；</li>
<li><strong>计算复杂度高</strong>，因为sigmoid函数是指数形式。</li>
</ul>
<h4><span id="22-tanh函数">2.2 <strong>Tanh函数</strong></span></h4>
<p>Tanh函数也称为双曲正切函数，取值范围为[-1,1]。Tanh函数是 0
均值的，因此实际应用中 Tanh 会比 sigmoid
更好。但是仍然存在<strong>梯度饱和</strong>与<strong>exp计算复杂度高</strong>的问题。</p>
<p>Tanh函数定义如下: <span class="math display">\[
f(x)=\operatorname{Tanh} x=\frac{\sinh x}{\cosh
x}=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}
\]</span> 它的导数为: <span class="math display">\[
f^{\prime}(x)=1-[f(x)]^{2}
\]</span>
<img src="https://pic4.zhimg.com/v2-b3d1085558d8a5a00cf837cf93a8cacb_b.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="23-relu函数">2.3 ReLU函数</span></h4>
<p><strong>整流线性单元 (Rectified linear unit, ReLU)
是现代神经网络中最常用的激活函数, 大多数
前馈神经网络默认使用的激活函数。</strong></p>
<p>ReLU函数定义如下: <span class="math inline">\(\quad f(x)=\max (0,
x)\)</span></p>
<p><img src="https://pic3.zhimg.com/v2-59192e63d9c658e045f6c6e533ac9546_b.jpg" alt="img" style="zoom:50%;"></p>
<p><strong>优点:</strong></p>
<ol type="1">
<li><strong>使用ReLU的SGD算法的收敛速度比 sigmoid 和 tanh
快。</strong></li>
<li><strong>在 <span class="math inline">\(x&gt;0\)</span> 区域上,
不会出现梯度饱和、梯度消失的问题。</strong></li>
<li><strong>计算复杂度低, 不需要进行指数运算,
只要一个阈值就可以得到激活值。</strong></li>
</ol>
<p><strong>缺点:</strong></p>
<ol type="1">
<li><strong>ReLU的输出不是O均值的。</strong></li>
<li><strong>Dead ReLU
Problem(神经元坏死现象)</strong>：ReLU在负数区域被kill的现象叫做dead
relu。 ReLU在训练的时很“脆弱”。在 <span class="math inline">\(x&lt;0\)</span> 时, 梯度为 0
。这个神经元及之后的神经元梯度永远为 0
；<strong>产生</strong>这种现象的两个<strong>原因</strong>：参数初始化问题；learning
rate太高导致在训练过程中参数更新太大。</li>
</ol>
<h3><span id="三-激活函数">三、激活函数</span></h3>
<h4><span id="21在神经网络中激活函数sigmoid和tanh除了阈值取值外有什么不同吗">2.1
在神经网络中，激活函数sigmoid和tanh除了阈值取值外有什么不同吗？</span></h4>
<h4><span id="22了解那些激活函数以及应用"><strong>2.2
了解那些激活函数以及应用？</strong></span></h4>
<p>回答主要分两类（饱和/非饱和），以及应用场景等。有时候可能特定到具体经典模型，比如<strong>LSTM用到Tanh,Transfromer中用到的ReLU,Bert中的GeLU,YOLO的Leaky
ReLU等。</strong></p>
<h4><span id="23梯度消失与梯度爆炸现象与原因以及解决办法"><strong>2.3
梯度消失与梯度爆炸现象与原因以及解决办法？</strong></span></h4>
<h4><span id="24relu激活函数为什么会出现死神经元解决办法">2.4
ReLU激活函数为什么会出现死神经元，解决办法？</span></h4>
<p><strong>输入为负值时，ReLU的梯度为0造成神经元死亡。还有Learning
rate太高导致在训练过程中参数更新太大 。</strong></p>
<p>解决办法主要有：</p>
<ul>
<li>优化参数。</li>
<li>避<strong>免将learning
rate设置太大</strong>，或者<strong>使用Adam等自动调节learning
rate的方法</strong>。</li>
<li>更换激活函数。</li>
</ul>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><p>深度学习领域最常用的10个激活函数，一文详解数学原理及优缺点 -
机器之心的文章 - 知乎 https://zhuanlan.zhihu.com/p/352668984</p></li>
<li><p><strong><font color="blue">详解激活函数（Sigmoid/Tanh/ReLU/Leaky
ReLu等）</font></strong> - 李见黎的文章 - 知乎
https://zhuanlan.zhihu.com/p/427541517</p></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>理论基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>激活函数</tag>
      </tags>
  </entry>
  <entry>
    <title>理论基础（1）【draft】神经网络</title>
    <url>/posts/3119A3X/</url>
    <content><![CDATA[<h3><span id="一-深度学习有哪些应用">一、深度学习有哪些应用</span></h3>
<ul>
<li>图像：图像识别、物体识别、图片美化、图片修复、目标检测。</li>
<li>自然语言处理：机器创作、个性化推荐、文本分类、翻译、自动纠错、情感分析。</li>
<li>数值预测、量化交易</li>
</ul>
<h3><span id="二-什么是神经网络">二、什么是神经网络</span></h3>
<p>我们以房价预测的案例来说明一下，把房屋的面积作为神经网络的输入（我们称之为𝑥），通过一个节点（一个小圆圈），最终输出了价格（我们用𝑦表示）。其实这个小圆圈就是一个单独的神经元，就像人的大脑神经元一样。如果这是一个单神经元网络，不管规模大小，<strong>它正是通过把这些单个神经元叠加在一起来形成。如果你把这些神经元想象成单独的乐高积木，你就通过搭积木来完成一个更大的神经网络。</strong></p>
<p>神经网络与大脑关联不大。这是一个过度简化的对比，把一个神经网络的逻辑单元和右边的生物神经元对比。至今为止其实连神经科学家们都很难解释，究竟一个神经元能做什么。</p>
<h4><span id="21-什么是感知器">2.1 什么是感知器</span></h4>
<p>这要从逻辑回归讲起，我们都知道逻辑回归的目标函数如下所示：</p>
<p><span class="math display">\[
\begin{aligned} &amp; z=\theta_0+\theta_1 X_1+\theta_2 X_2 \\ &amp;
a=g(z)=\frac{1}{1+e^{-z}}\end{aligned}
\]</span></p>
<p>我们用网络来表示，这个网络就叫做感知器：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011554556.jpeg" style="zoom:50%;"></p>
<p>如果在这个感知器的基础上加上隐藏层，就会得到下面我们要说的神经网络结构了。</p>
<h4><span id="22-神经网络的结构">2.2 神经网络的结构</span></h4>
<p>神经网络的一般结构是由<strong>输入层、隐藏层(神经元)、输出层</strong>构成的。隐藏层可以是1层或者多层叠加，层与层之间是相互连接的，如下图所示。<strong>神经网络具有非线性切分能力</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305011554188.jpeg" alt="img" style="zoom:50%;"></p>
<p><strong>一般说到神经网络的层数是这样计算的，输入层不算，从隐藏层开始一直到输出层，一共有几层就代表着这是一个几层的神经网络</strong>，例如上图就是一个三层结构的神经网络。</p>
<p><strong>解释隐藏层的含义：</strong>在一个神经网络中，当你使用监督学习训练它的时候，训练集包含了输入𝑥也包含了目标输出𝑦，所以术语隐藏层的含义是在训练集中，这些中间结点的准确值我们是不知道到的，也就是说你看不见它们在训练集中应具有的值。</p>
<ul>
<li>多隐藏层的神经网络比单隐藏层的神经网络工程效果好很多。</li>
<li>提升隐层层数或者隐层神经元个数，神经网络“容量”会变大，空间表达力会变强。</li>
<li>过多的隐层和神经元节点，会带来过拟合问题。</li>
<li><strong>不要试图通过降低神经网络参数量来减缓过拟合，用正则化或者dropout</strong>。</li>
</ul>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/10.%20Neural%20Network</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>理论基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>深度神经网络</tag>
        <tag>DNN</tag>
      </tags>
  </entry>
  <entry>
    <title>理论基础（3）优化算法</title>
    <url>/posts/30588BP/</url>
    <content><![CDATA[<h4><span id="总结">总结：</span></h4>
<ul>
<li>SGD为随机梯度下降,每一次迭代计算数据集的mini-batch的梯度,然后对参数进行更新。</li>
<li>Momentum参考了物理中动量的概念,前几次的梯度也会参与到当前的计算中,但是前几轮的梯度叠加在当前计算中会有一定的衰减。</li>
<li>Adagard在训练的过程中可以自动变更学习的速率,设置一个全局的学习率,而实际的学习率与以往的参数模和的开方成反比。</li>
<li>Adam利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率,在经过偏置的校正后,每一次迭代后的学习率都有个确定的范围,使得参数较为平稳。</li>
</ul>
<h4><span id="引言"><strong>引言</strong></span></h4>
<p><strong>最优化问题</strong>是计算数学中最为重要的研究方向之一。而在深度学习领域，优化算法的选择也是一个模型的重中之重。即使在数据集和模型架构完全相同的情况下，采用不同的优化算法，也很可能导致截然不同的训练效果。</p>
<p>梯度下降是目前神经网络中使用最为广泛的优化算法之一。为了弥补朴素梯度下降的种种缺陷，研究者们发明了一系列变种算法，从最初的
SGD (随机梯度下降) 逐步演进到
NAdam。<strong>然而，许多学术界最为前沿的文章中，都并没有一味使用
Adam/NAdam 等公认“好用”的自适应算法，很多甚至还选择了最为初级的 SGD 或者
SGD with Momentum 等</strong>。</p>
<span id="more"></span>
<h3><span id="一-常见的优化算法">一、常见的优化算法</span></h3>
<h4><span id="11-gradient-descent框架"><strong>1.1 Gradient Descent</strong>
框架</span></h4>
<p><font color="red">梯度下降是指,在给定待优化的模型参数 <span class="math inline">\(\theta \in \mathbb{R}^d\)</span> 和目标函数 <span class="math inline">\(J(\theta)\)</span> 后, 算法通过沿梯度 <span class="math inline">\(\nabla_\theta J(\theta)\)</span> 的相反方向更新
<span class="math inline">\(\theta\)</span> 来最小化 <span class="math inline">\(J(\theta)\)</span> 。</font>学习率 <span class="math inline">\(\eta\)</span>
决定了每一时刻的更新步长。对于每一个时刻 <span class="math inline">\(t\)</span>, 我们可以用下述步骤描述梯
度下降的流程：</p>
<ol type="1">
<li>计算目标函数关于参数的梯度 <span class="math display">\[
g_t=\nabla_\theta J(\theta)
\]</span> <strong>(2) 根据历史梯度计算一阶和二阶动量</strong> <span class="math display">\[
\begin{aligned}
&amp; m_t=\phi\left(g_1, g_2, \cdots, g_t\right) \\
&amp; v_t=\psi\left(g_1, g_2, \cdots, g_t\right)
\end{aligned}
\]</span></li>
<li>更新模型参数 <span class="math display">\[
\theta_{t+1}=\theta_t-\frac{1}{\sqrt{v_t+\epsilon}} m_t
\]</span> 其中, <span class="math inline">\(\epsilon\)</span>
为平滑项，防止分母为零，通常取 1e-8。</li>
</ol>
<h4><span id="12-vanilla-sgd">1.2 Vanilla SGD</span></h4>
<p><strong>朴素 SGD (Stochastic Gradient Descent)
最为简单，没有动量的概念</strong>，即 <span class="math display">\[
m_t=\eta g_t
\]</span></p>
<p><span class="math display">\[
v_t=I^2
\]</span></p>
<p><span class="math display">\[
\epsilon=0
\]</span></p>
<p>这时，更新步骤就是最简单的 <span class="math display">\[
\theta_{i+1}=\theta_t-\eta g_t
\]</span> <strong>SGD 的缺点在于收玫速度慢,
可能在鞍点处震荡</strong>。并且, 如何合理的选择学习率是 SGD
的一大难点。</p>
<h4><span id="13-momentum"><font color="red">1.3 Momentum</font></span></h4>
<p>SGD 在遇到沟壑时容易陷入震荡。为此，可以为其引入动量 Momentum，加速
SGD 在正确方向的下降并抑制震荡。</p>
<p><span class="math display">\[
m_t=\gamma m_{t-1}+\eta g_t
\]</span> SGD-M 在原步长之上，增加了与上一时刻步长相关的 <span class="math inline">\(\gamma m_{t-1} ， \gamma\)</span> 通常取 0.9
左右。<strong><font color="red">这意味着参数更新方向不仅由当前的梯度决定，也与此前累积的下降方向有关。这使得参数中那些梯度方向变化不大的维度可以加速更新，并减少梯度方向变化较大的维度上的更新幅度</font>。由此产生了加速收敛和减小震荡的效果。</strong>从图中可以看出，引入动量有效的加速了梯度下降收敛过程。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301638833.gif" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301638673.gif" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="14adagrad-二阶动量-改变学习率"><font color="red">1.4
Adagrad</font> 【二阶动量 改变学习率】</span></h4>
<p>SGD、SGD-M 和 NAG 均是以相同的学习率去更新 <span class="math inline">\(\theta\)</span>
的各个分量。<strong>而深度学习模型中往往涉及大量的参数,
不同参数的更新频率往往有所区别</strong>。对于更新不频繁的参数（典型例子：更新
word embedding 中的低频词）， 我们希望单次步长更大, 多学习一些知识;
对于更新频繁的参数, 我们则希望步长较小, 使得学习到的参数更稳定,
不至于被单个样本影响太多。</p>
<p>Adagrad算法即可达到此效果。其引入了二阶动量: <span class="math display">\[
v_t=\operatorname{diag}\left(\sum_{i=1}^t g_{i, 1}^2, \sum_{i=1}^t g_{i,
2}^2, \cdots, \sum_{i=1}^t g_{i, d}^2\right)
\]</span> 其中, <span class="math inline">\(v_t \in \mathbb{R}^{d \times
d}\)</span> 是对角矩阵, 其元素 <span class="math inline">\(v_{t, i
i}\)</span> 为参数第 <span class="math inline">\(i\)</span>
维从初始时刻到时刻 <span class="math inline">\(t\)</span>
的梯度平方和。</p>
<p>此时, 可以这样理解: 学习率等效为 <span class="math inline">\(\eta /
\sqrt{v_t+\epsilon}\)</span> 。对于此前频繁更新过的参数,
其二阶动量的对应分量较大,
学习率就较小。这一方法在稀疏数据的场景下表现很好。</p>
<h4><span id="15rmsprop-定制之前梯度的重要性"><font color="red">1.5
RMSprop</font> 【定制之前梯度的重要性】</span></h4>
<p>在 Adagrad 中, <span class="math inline">\(v_t\)</span> 是单调递增的,
使得学习率逐渐递减至 0 , 可能导致训练过程提前结束。为了改进这一缺点,
<strong>可以考虑在计算二阶动量时不累积全部历史梯度,
而只关注最近某一时间窗口内的下降梯度</strong>。根据此思想有
了RMSprop。记 <span class="math inline">\(g_t \odot g_t\)</span> 为
<span class="math inline">\(g_t^2\)</span> ，有 <span class="math display">\[
v_t=\gamma v_{t-1}+(1-\gamma) \cdot
\operatorname{diag}\left(g_t^2\right)
\]</span> 其二阶动量采用指数移动平均公式计算,
这样即可避免二阶动量持续累积的问题。和 SGD-M 中的参数类似, <span class="math inline">\(\gamma\)</span> 通常取 0.9 左右。</p>
<h4><span id="16-adamrms-prop-momentum"><strong><font color="red"> 1.6 Adam
【RMS prop + momentum】</font></strong></span></h4>
<p><strong>Adam可以认为是 RMSprop 和 Momentum 的结合</strong>。和
RMSprop 对二阶动量使用指数移动平均类似, Adam
中对一阶动量也是用指数移动平均计算。 <span class="math display">\[
\begin{gathered}
m_t=\eta\left[\beta_1 m_{t-1}+\left(1-\beta_1\right) g_t\right] \\
v_t=\beta_2 v_{t-1}+\left(1-\beta_2\right) \cdot
\operatorname{diag}\left(g_t^2\right)
\end{gathered}
\]</span> 其中, 初值 <span class="math display">\[
\begin{aligned}
&amp; m_0=0 \\
&amp; v_0=0
\end{aligned}
\]</span> 注意到, 在迭代初始阶段, <span class="math inline">\(m_t\)</span> 和 <span class="math inline">\(v_t\)</span> 有一个向初值的偏移（过多的偏向了 0)
。因此, 可以对一阶和二阶动量做偏置校正 (bias correction), <span class="math display">\[
\begin{aligned}
&amp; \hat{m}_t=\frac{m_t}{1-\beta_1^t} \\
&amp; \hat{v}_t=\frac{v_t}{1-\beta_2^t}
\end{aligned}
\]</span> 再进行更新, <span class="math display">\[
\theta_{t+1}=\theta_t-\frac{1}{\sqrt{\hat{v}_t}+\epsilon} \hat{m}_t
\]</span> 可以保证迭代较为平稳。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>从 SGD 到 Adam ——
深度学习优化算法概览(一)：https://zhuanlan.zhihu.com/p/32626442</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>理论基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>优化算法</tag>
        <tag>参数估计</tag>
      </tags>
  </entry>
  <entry>
    <title>理论基础（6）特征归一化</title>
    <url>/posts/1KES3SV/</url>
    <content><![CDATA[<h3><span id="一-机器学习的特征归一化方法">一、机器学习的特征归一化方法</span></h3>
<p>在迈入深度神经网络之前，本文主要介绍下传统机器学习中有哪些特征归一化方法。</p>
<h4><span id="11-常见的特征归一化">1.1 常见的特征归一化</span></h4>
<p>上文我们讲了特征归一化，就是要让各个特征有相似的尺度。相似的尺度一般是讲要有相似的取值范围。因此我们可以通过一些方法<strong>把特征的取值范围约束到一个相同的区间</strong>。另一方面，这个尺度也可以理解为这些特征都是从一个相似的分布中采样得来。因此我们还可以通过一些方法<strong>使得不同特征的取值均符合相似的分布</strong>。这里我们介绍一些常见的特征归一化方法的细节，原理和实现。</p>
<span id="more"></span>
<p><strong>(1) rescaling (min-max normalization, range scaling)</strong>
<span class="math display">\[
x^{\prime}=a+\frac{(x-\min (\mathrm{x}))(\mathrm{b}-\mathrm{a})}{\max
(\mathrm{x})-\min (\mathrm{x})}
\]</span> <strong>这里是把每一维的值都映射到目标区间</strong> <span class="math inline">\([a, b]\)</span> 。一般常用的目标区间是 <span class="math inline">\([0,1],[-1,1]\)</span> 。特别的, 映射到0和1区
间的的计算方式为: <span class="math inline">\(x^{\prime}=\frac{x-\min
(\mathrm{x})}{\max (\mathrm{x})-\min (\mathrm{x})}\)</span> 。</p>
<p><strong>(2) mean normalization</strong></p>
<p><span class="math inline">\(x^{\prime}=\frac{x-\mu}{\max
(\mathrm{x})-\min (\mathrm{x})}\)</span> 。这里 <span class="math inline">\(\mu\)</span> 指的向量的均值。与上面不同的是,
这里减去的是均值。<strong>这样能够保证向量中所有元素的均值为 0
。</strong></p>
<p><strong>(3) 标准化 standard normalization (z-score
normalization)</strong></p>
<p><span class="math inline">\(x^{\prime}=\frac{x-\mu}{\sigma}\)</span>
。这里 <span class="math inline">\(\sigma\)</span>
指的是向量的标准差。更常见的是这种, 使得所有元素的均值为 0 , 方差为 1
。</p>
<p><strong>(4) scaling to unit length</strong></p>
<p><span class="math inline">\(x^{\prime}=\frac{x}{\|x\|}\)</span>
。这里是把向量除以其长度, 即对向量的长度进行归一化。长度度量一般采用
<span class="math inline">\(\mathrm{L}\)</span> 范数或者 <span class="math inline">\(L 2\)</span> 范数。</p>
<p><strong>范数（英语：Norm），是具有“长度"概念的函数。</strong>在线性代数、泛函分析及相关的数学领域,
是一个函数, 其为向量空间内的所有向量赋予非零的正长度或大小。 <span class="math inline">\(L p(p=1 . . n)\)</span> 范数: <span class="math inline">\(\|x\|_p:=\left(\sum_{i=1}^n x_i^p\right)^{1 /
p}\)</span> 。</p>
<h4><span id="12-原理">1.2 原理</span></h4>
<p>总结来看，前三种特征归一化方法的计算方式是<strong>减一个统计量再除以一个统计量</strong>，最后一种为<strong>除以向量自身的长度。</strong></p>
<ul>
<li><strong>减去一个统计量可以看做选哪个值作为原点</strong>（是最小值或者均值），然后将整个数据集都平移到这个新的原点位置。如果特征之间的偏置不同会对后续过程产生负面影响，则该操作是有益的，可以看做某种偏置无关操作。如果原始特征值是有特殊意义的，则该操作可能会有害。<strong>如何理解</strong>：对于一堆二维数据，计算均值得到(a,b)，减去这个均值点，就相当于把整个平面直角坐标系平移到这个点上，为什么呢？因为(a,b)-(a,b)
= (0,0)就是原点，其他的点在x轴和y轴上做相应移动。</li>
<li><strong>除以一个统计量可以看做在坐标轴方向上对特征进行缩放</strong>，用于降低特征尺度的影响，可以看做某种特征无关操作。缩放可以采用最大值和最小值之间的跨度，也可以用标准差(到中心点的平均距离)。<strong>如何理解</strong>：(a,b)/
3 = (a/3,
b/3)，就相当于这些点在x轴上的值缩小三倍，在y轴上缩小三倍。</li>
<li><strong>除以长度相当于把长度归一化，把所有特征都映射到单位球上，</strong>可以看作某种长度无关操作。比如词频特征要移除文章长度的影响，图像处理中某些特征要移除光照强度的影响，以及方便计算向量余弦相似度等。<strong>如何理解</strong>：除以向量的模，实际就是让向量的长度为1，这样子，若干个n维向量就分布在一个单位球上，只是方向不同。</li>
</ul>
<p>更直观地，可以从下图（来自于CS231n课程）观察上述方法的作用。下图是一堆二维数据点的可视化，<strong>可以看到，减去了每个维度的均值
以后，数据点的中心移动到了原点位置，进一步的，每个维度用标准差缩放以后</strong>，在每个维度上，数据点的取值范围均保持相同。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301710035.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="13-标准化和归一化">1.3 标准化和归一化</span></h4>
<blockquote>
<p>PCA、k-means、回归模型、神经网络</p>
</blockquote>
<h5><span id="定义">定义</span></h5>
<p><strong>归一化和标准化</strong>都是对<strong>数据做变换</strong>的方式，将原始的一列数据转换到某个范围，或者某种形态，具体的：</p>
<ul>
<li><strong>归一化(Normalization)</strong>：将一列数据变化到某个固定区间(范围)中，通常，这个区间是[0,
1]，广义的讲，可以是各种区间，比如映射到[0，1]一样可以继续映射到其他范围，图像中可能会映射到[0,255]，其他情况可能映射到[-1,1]；</li>
<li><strong>标准化(Standardization)</strong>：将数据变换为均值为0，标准差为1的分布切记，<strong>并非一定是正态的；</strong></li>
<li><strong>中心化</strong>：另外，还有一种处理叫做中心化，也叫零均值处理，就是将每个原始数据减去这些数据的均值。</li>
</ul>
<h5><span id="差异">差异</span></h5>
<blockquote>
<p><strong>归一化：对处理后的数据范围有严格要求;</strong></p>
<p><strong>标准化: 数据不为稳定，存在极端的最大最小值;
涉及距离度量、协方差计算的时候;</strong></p>
</blockquote>
<ul>
<li><strong>归一化会严格的限定变换后数据的范围</strong>，比如按之前最大最小值处理的，它的范围严格在[
0 , 1
]之间；而<strong>标准化</strong>就没有严格的区间，变换后的数据没有范围，只是其均值是0，标准差为1。</li>
<li><strong>归一化的缩放比例仅仅与极值有关</strong>，容易受到异常值的影响。</li>
</ul>
<h5><span id="用处">用处</span></h5>
<ul>
<li><strong>可解释性</strong>：<strong>回归模型</strong>中自变量X的量纲不一致导致了<strong>回归系数无法直接解读</strong>或者错误解读；需要将X都处理到统一量纲下，这样才可比【可解释性】；<strong>取决于我们的逻辑回归是不是用了正则化</strong>。如果你不用正则，标准化并不是必须的，如果用正则，那么标准化是必须的。</li>
<li><strong>距离计算</strong>：机器学习任务和统计学任务中有很多地方要用到<strong>“距离”的计算</strong>，比如<strong>PCA，比如KNN，比如kmeans</strong>等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果；</li>
<li><strong>加速收敛</strong>：参数估计时使用<strong>梯度下降</strong>，在使用梯度下降的方法求解最优化问题时，
归一化/标准化后可以加快梯度下降的求解速度，即<strong>提升模型的收敛速度</strong>。</li>
<li><del><strong>L1、L2正则化减少过拟合</strong></del></li>
</ul>
<h5><span id="其他log-sigmod-softmax-变换">其他：log、sigmod、softmax 变换</span></h5>
<h3><span id="二-深度学习的特征归一化方法">二、深度学习的特征归一化方法</span></h3>
<p>今天我们开始介绍这些特征归一化方法在复杂的深度神经网络的作用</p>
<h4><span id="21-前置内容domainadaption中的covariate-shift">2.1 前置内容：Domain
Adaption中的Covariate Shift</span></h4>
<p>在讲传统机器学习的特征归一化在深度网络中的应用之前，先要讲下迁移学习中的领域自适应（DA）。在迁移学习中，源域有很多标注数据，目标域没有或者只有少量的标注数据，但是有大量无标注数据。比如常见的问题就是机器学习模型的泛化性问题，希望在A领域上训练的模型，能够在B领域也有比较好的性能。</p>
<p>在DA中, 一般假设源领域和目标领域有相同的样本空间, 比如猫狗分类问题,
样本空间就是两个类：猫和狗, 但是数据分布不同 <span class="math inline">\(p_s(x, y) \neq p_t(x, y)\)</span>
。由贝叶斯公式可以把这个联合分布分解为 <span class="math display">\[
p(x, y)=p(x \mid y) p(y)=p(y \mid x) p(x) \text { 。 }
\]</span> 所以数据分布不一致有3种情况：(具体可以看我的回答：<a href="https://www.zhihu.com/question/293820673/answer/2308925558">在迁移学习中，边缘概率分布和条件概率分布有什么含义？</a>)。这里主要介绍Covariate
Shift现象。</p>
<p>variate指的是一个随机变量，co-variate指的是随这个随机变量变化的另一个随机变量。Covariate
Shift指的就是：<strong>源领域和目标领域的输入边缘分布不同</strong>，但是条件分布相同
<span class="math inline">\(p_s(x) \neq p_t(x) ; p_s(y \mid x)=p_t(y
\mid x)\)</span>。以猫狗识别问题为例：</p>
<ul>
<li>源领域中的狗都是哈士奇，而目标领域中的狗都是拉布拉多，所以输入的边缘分布不同。</li>
<li>不管是什么狗，最后输出为狗的概率都为1，也就是输出的label都要是狗，也就是条件分布相同，也就是学习任务是相同的。</li>
<li>解决这种情况的做法一般是学习一个domain
invariant的representation，也就是不管是什么领域的狗，最后输出都要是狗这个标签。</li>
</ul>
<h4><span id="22-深度神经网络中的归一化">2.2 深度神经网络中的归一化</span></h4>
<p>把传统机器学习中的特征归一化方法用在具有多个隐藏层的深度神经网络中，对隐藏层的输入进行归一化，也能够提升训练效率。其”可能“的原因有几派的观点：</p>
<h5><span id="1更好的尺度不变性即不同层输入的取值范围或者分布都比较一致">（1）更好的尺度不变性(即不同层输入的取值范围或者分布都比较一致)</span></h5>
<p>一般上认为，<strong>深度神经网络中存在一种叫做internal covariate
shift
(ICS)的现象</strong>：在深度神经网络中，一个神经层的输入是之前神经层的输出。给定一个神经层，它之前的所有神经层的参数变化会导致其输入的分布发生较大的改变。当使用随机梯度下降来训练网络时，每次参数更新都会导致该神经层的输入分布发生改变。越高的层，其输入分布会改变得越明显．就像一栋高楼，低楼层发生一个较小的偏移，可能会导致高楼层较大的偏移。</p>
<p>该现象会导致下面几个问题：</p>
<ul>
<li><strong>在训练的过程中，网络需要不断适应新的输入数据分布（其实就是之前讲的梯度更新迭代步数增多），所以会大大降低学习速度</strong>。</li>
<li>由于参数的分布不同，所以可能导致很多数据落入梯度饱和区，使得学习过早停止。</li>
<li>某些参数分布偏离太大，对其他层或者输出产生了巨大影响。</li>
</ul>
<p>对比上面的概念就是：在神经网络的各层输出，由于它们经过了层内操作作用，其分布显然与各层对应的输入分布不同，而且差异会随着网络深度增大而增大。<strong>各层的输入和输出分布可以看作源领域和目标领域的输入边缘分布</strong>（因为这一层的输出分布也是下一层的输入分布），<strong>显然这两个分布已经变的不同了，但是其要预测的条件分布是相同的</strong>，因为两个输入预测出来的最后的label肯定要是一样的。</p>
<p><strong>为了缓解ICS问题，需要对隐藏层的输入进行归一化</strong>，比如都归一化成标准正态分布，可以使得每个神经层对其输入具有更好的尺度不变性．不论低层的参数如何变化，高层的输入保持相对稳定。</p>
<h5><span id="2更平滑的优化地形optimizationlandscape">（2）更平滑的”优化地形“（optimization
landscape）</span></h5>
<p>在NIPS2018的<a href="https://link.zhihu.com/?target=http%3A//cn.arxiv.org/abs/1805.11604">How
Does Batch Normalization Help
Optimization?</a>一文中，作者详细阐述了batch normalization
(一种用在DNN上的归一化方法)真正起作用的原因。该文中对ICS有了更精要的阐述，即该层的输入分布会因为之前层的更新而发生改变。同时，论文提出了两个问题，即<strong>BN的作用是否与ICS相关，以及BN是否会消除或减少ICS</strong>。</p>
<p>为了探究第一个问题，作者在BN层后面人为引入了一个随时间随机改变（该分布不容易被DNN学到）的噪声分布（即人为引入漂移现象，使得下一层的分布不再稳定）。结果发现，<strong>加了噪声以后，层的分布的稳定性（通过可视化每层采样一定神经元的激活值来度量分布的方差和均值）并不好，但是最后的效果依然很好，</strong>这说明BN层和ICS似乎没有啥关系。（因为加了BN层，虽然分布不稳定，但是效果依然好）。</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-91d6d1b0291a19917129c1147fa5f76f_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>为了探究第二个问题，作者又设计了指标来量化ICS现象：通过测量更新到前一层和当前层的梯度差异(L2距离)来量化一个层中的参数在多大程度上必须“调整”以应对前一层中的参数更新。理想来说<strong>，ICS现象越小，上一层参数更新对当前层的分布影响越小，梯度变化程度越小。</strong>最后实验发现BN并不能减少ICS，甚至可能还会有一定程度上的增加。</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-6590bf66e3ff3e7d561a6026975a3c0a_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>由此，作者认为BN层的作用可能和ICS没啥关系，也不能减少ICS。而作者认为，<strong>BN的作用在于使得optimization
landscape更加光滑。</strong></p>
<p><strong>神经网络的高维损失函数构成了一个损失曲面，也被称为优化地形（optimization
landscape）。</strong>这里用L-Lipschitz函数即<span class="math inline">\(\left|f\left(x_1\right)-f\left(x_2\right)\right|
\leq
L\left\|x_1-x_2\right\|\)</span>来定量描述这种光滑度。<strong>作者发现确实加了BN层以后，optimization
landscape更加光滑了。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301712469.jpg" alt="img" style="zoom: 67%;"></p>
<p>进一步地，作者还以平滑优化地形为目标设计了另一种方法，结果发现和BN的效果差不多。这也说明了BN层的作用在于使得优化地形更加平滑。</p>
<h4><span id="23-总结">2.3 总结</span></h4>
<p>今天我们主要介绍了<strong>归一化方法（Batch
Normalization）在深度神经网络中的作用：有人认为是更好的尺度不变性来缓解ICS现象。有人认为是更平滑的优化地形。</strong>当然，BN层究竟怎么起作用的，现在还是没太探究清楚。实际上，咱们还没开始介绍BN是什么！！！哈哈哈，下一篇文章俺们就从缓解ICS现象的角度来讲解BN的原理和实现，并和之前讲过的机器学习中的归一化方法进行关联。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><p>Transformer中的归一化(二)：机器学习中的特征归一化方法 - Gordon
Lee的文章 - 知乎 https://zhuanlan.zhihu.com/p/477116352</p></li>
<li><p>Transformer中的归一化(三)：特征归一化在深度神经网络的作用 -
Gordon Lee的文章 - 知乎 https://zhuanlan.zhihu.com/p/481179310</p></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>理论基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>归一化</tag>
        <tag>特征选择</tag>
      </tags>
  </entry>
  <entry>
    <title>理论基础（4）Dropout</title>
    <url>/posts/FJFCEV/</url>
    <content><![CDATA[<h4><span id="为什么dropout可以解决过拟合-共享隐藏单元的bagging集成模型">为什么dropout
可以解决过拟合？ 【共享隐藏单元的bagging集成模型】</span></h4>
<ul>
<li><p><strong>集成取平均的作用：</strong>
整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</p></li>
<li><p><strong>减少神经元之间复杂的共适应关系：</strong>
因为dropout程序导致两个神经元不一定每次都在一个dropout网络中出现。这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况
。<strong>从这个角度看dropout就有点像L1，L2正则，减少权重使得网络对丢失特定神经元连接的鲁棒性提高。</strong></p></li>
<li><p><strong>Dropout纯粹作为一种高效近似Bagging的方法。</strong>然而,有比这更进一步的Dropout观点。<strong><font color="red">
Dropout不仅仅是训练一个Bagging的集成模型,并且是共享隐藏单元的集成模型。</font></strong>这意味着无论其他隐藏单元是否在模型中,每个隐藏单元必须都能够表现良好。</p></li>
</ul>
<span id="more"></span>
<h3><span id="一-dropout">一、Dropout</span></h3>
<h4><span id="11-dropout简介">1.1 <strong>Dropout简介</strong></span></h4>
<p>在机器学习的模型中，如果模型的参数太多，而训练样本又太少，训练出来的模型<strong>很容易产生过拟合</strong>的现象。在训练神经网络的时候经常会遇到过拟合的问题，过拟合具体表现在：模型在训练数据上损失函数较小，预测准确率较高；但是在测试数据上损失函数比较大，预测准确率较低。</p>
<p>过拟合是很多机器学习的通病。如果模型过拟合，那么得到的模型几乎不能用。为了解决过拟合问题，一般会采用模型集成的方法，即训练多个模型进行组合。此时，训练模型费时就成为一个很大的问题，不仅训练多个模型费时，测试多个模型也是很费时。</p>
<p><strong>综上所述，训练深度神经网络的时候，总是会遇到两大缺点：</strong></p>
<p>（1）<strong>容易过拟合</strong></p>
<p>（2）<strong>费时</strong></p>
<p><strong>Dropout可以比较有效的缓解过拟合的发生，在一定程度上达到正则化的效果。</strong></p>
<h4><span id="12-dropout原理">1.2 <strong>Dropout原理</strong></span></h4>
<p>在2012年，Hinton在其论文《Improving neural networks by preventing
co-adaptation of feature
detectors》中提出Dropout。当一个复杂的前馈神经网络被训练在小的数据集时，容易造成过拟合。为了防止过拟合，可以通过阻止特征检测器的共同作用来提高神经网络的性能。</p>
<p>在2012年，Alex、Hinton在其论文《ImageNet Classification with Deep
Convolutional Neural
Networks》中用到了Dropout算法，用于防止过拟合。并且，这篇论文提到的AlexNet网络模型引爆了神经网络应用热潮，并赢得了2012年图像识别大赛冠军，使得CNN成为图像分类上的核心算法模型。</p>
<p>随后，又有一些关于Dropout的文章《Dropout:A Simple Way to Prevent
Neural Networks from Overfitting》、《Improving Neural Networks with
Dropout》、《Dropout as data augmentation》。</p>
<p><strong>Dropout可以作为训练深度神经网络的一种trick供选择</strong>。在每个训练批次中，通过忽略一半的特征检测器（让一半的隐层节点值为0），可以明显地减少过拟合现象。这种方式可以减少特征检测器（隐层节点）间的相互作用，检测器相互作用是指某些检测器依赖其他检测器才能发挥作用。</p>
<p><strong>Dropout说的简单一点就是：我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。</strong></p>
<p><strong>Dropout 是另一种抑制过拟合的方法</strong>。在使用 dropout
时，数据尺度会发生变化，如果设置 dropout_prob
=0.3，那么在训练时，数据尺度会变为原来的 70%；<strong><font color="red">
而在测试时，执行了 model.eval() 后，dropout
是关闭的，因此所有权重需要乘以 (1-dropout_prob)，把数据尺度也缩放到
70%。</font></strong> 加了 dropout 之后，权值更加集中在 0
附近，使得神经元之间的依赖性不至于过大。</p>
<p><strong>PyTorch 中 Dropout
层如下，通常放在每个网路层的最前面：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.Dropout(p=0.5, inplace=False)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li>p：主力需要注意的是，p
是被舍弃的概率，也叫失活概率；<strong>代码层面实现让某个神经元以概率p停止工作，其实就是让它的激活函数值以概率p变为0</strong></li>
</ul>
<h4><span id="13dropout具体工作流程"><strong>1.3
Dropout具体工作流程</strong></span></h4>
<ol type="1">
<li><strong>首先随机（临时）删掉网络中一部分的隐藏神经元，输入输出神经元保持不变</strong>；</li>
<li>然后把输入x通过修改后的网络前向传播，然后把得到的损失结果通过修改的网络反向传播。一小批训练样本执行完这个过程后，<strong>在没有被删除的神经元上按照随机梯度下降法更新对应的参数</strong>（w，b）。</li>
<li><strong>恢复被删掉的神经元</strong>（<strong><font color="red">
此时被删除的神经元保持原样，而没有被删除的神经元已经有所更新</font></strong>）</li>
<li>重复上述过程</li>
</ol>
<h5><span id="1训练阶段">（1）训练阶段</span></h5>
<ul>
<li><strong>无可避免的，在训练网络的每个单元都要添加一道概率流程</strong>。</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301700504.jpg" alt="img" style="zoom:50%;"></p>
<p>对应的公式变化如下: - <strong>没有Dropout的网络计算公式</strong>
<span class="math display">\[
\begin{aligned}
z_{i}^{(l+1)} &amp;=\mathbf{w}_{i}^{(l+1)} \mathbf{y}^{l}+b_{i}^{(l+1)}
\\
y_{i}^{(l+1)} &amp;=f\left(z_{i}^{(l+1)}\right)
\end{aligned}
\]</span> - <strong>采用Dropout的网络计算公式</strong> <span class="math display">\[
\begin{aligned}
r_{j}^{(l)} &amp; \sim \operatorname{Bernoulli}(p), \\
\widetilde{\mathbf{y}}^{(l)} &amp;=\mathbf{r}^{(l)} * \mathbf{y}^{(l)},
\\
z_{i}^{(l+1)} &amp;=\mathbf{w}_{i}^{(l+1)}
\widetilde{\mathbf{y}}^{l}+b_{i}^{(l+1)}, \\
y_{i}^{(l+1)} &amp;=f\left(z_{i}^{(l+1)}\right) .
\end{aligned}
\]</span> <strong><font color="red">
上面公式中Bernoulli函数是为了生成概率r向量,
也就是随机生成一个0、1的向量。</font></strong></p>
<p>代码层面实现让某个神经元以概率 <span class="math inline">\(p\)</span>
停止工作, 其实就是让它的激活函数值以概率 <span class="math inline">\(p\)</span> 变为 0
。比如我们某一层网络神经元的个数为 1000 个, 其激活函数输出值为 <span class="math inline">\(y 1 、 y 2 、 y 3 、 \ldots \ldots, y
1000\)</span>, 我们 dropout比率选择0.4, 那么这一层神经元经过dropout后,
1000个神经元中会有大约400个的值被置为 0 。</p>
<p><strong>注意</strong>: 经过上面屏蔽掉某些神经元, 使其激活值为 0 以后,
我们还需要对向量y1.......y1000进行缩放, 也就是乘以 <span class="math inline">\(1 /(1-p)\)</span> 。如果你在训练的时候, 经过置0后,
没有对y1......y1000进行缩放 (rescale) , 那么在测试的时候,
就需要对权重进行缩放, 操作如下。</p>
<h5><span id="2测试阶段">（2）测试阶段</span></h5>
<p>预测模型的时候, 每一个神经单元的权重参数要乘以概率p。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301700871.jpg" alt="img" style="zoom:50%;"></p>
<p><strong>测试阶段Dropout公式：</strong> <span class="math display">\[
w_{\text {test }}^{(l)}=p W^{(l)}
\]</span></p>
<h4><span id="14为什么dropout-可以解决过拟合-共享隐藏单元的bagging集成模型">1.4
为什么dropout 可以解决过拟合？ 【共享隐藏单元的bagging集成模型】</span></h4>
<ul>
<li><p><strong>集成取平均的作用：</strong>
整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</p></li>
<li><p><strong>减少神经元之间复杂的共适应关系：</strong>
因为dropout程序导致两个神经元不一定每次都在一个dropout网络中出现。这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况
。<strong>从这个角度看dropout就有点像L1，L2正则，减少权重使得网络对丢失特定神经元连接的鲁棒性提高。</strong></p></li>
<li><p><strong>Dropout纯粹作为一种高效近似Bagging的方法。</strong>然而,有比这更进一步的Dropout观点。<strong><font color="red">
Dropout不仅仅是训练一个Bagging的集成模型,并且是共享隐藏单元的集成模型。</font></strong>这意味着无论其他隐藏单元是否在模型中,每个隐藏单元必须都能够表现良好。</p>
<blockquote>
<p><strong>面试常见问题-dropout与bagging的区别</strong></p>
<ul>
<li>dropout训练与bagging训练不太一样，bagging的各个子模型之间是完全独立的，而在dropout里，这些参数是共享的。</li>
<li>在bagging的情况下，每一个模型在其训练集上训练到收敛，而在dropout情况下，通常大部分的模型都没有显式的训练</li>
</ul>
</blockquote></li>
</ul>
<h4><span id="15-modeleval-和modeltrian">1.5 <strong>model.eval() 和
model.trian()</strong></span></h4>
<p>有些网络层在训练状态和测试状态是不一样的，如 dropout 层，在训练时
dropout
层是有效的，但是数据尺度会缩放，为了保持数据尺度不变，所有的权重需要除以
1-p。而在测试时 dropout
层是关闭的。因此在测试时需要先调用<code>model.eval()</code>设置各个网络层的的<code>training</code>属性为
False，在训练时需要先调用<code>model.train()</code>设置各个网络层的的<code>training</code>属性为
True。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>深度学习中Dropout原理解析 - Microstrong的文章 - 知乎
https://zhuanlan.zhihu.com/p/38200980</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>理论基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>Dropout</tag>
      </tags>
  </entry>
  <entry>
    <title>理论基础（5）归一化</title>
    <url>/posts/1MG9WE6/</url>
    <content><![CDATA[<h5><span id="归一化的作用">归一化的作用：</span></h5>
<ul>
<li><strong>可解释性</strong>：<strong>回归模型</strong>中自变量X的量纲不一致导致了<strong>回归系数无法直接解读</strong>或者错误解读；需要将X都处理到统一量纲下，这样才可比【可解释性】；<strong>取决于我们的逻辑回归是不是用了正则化</strong>。如果你不用正则，标准化并不是必须的，如果用正则，那么标准化是必须的。</li>
<li><strong>距离计算</strong>：机器学习任务和统计学任务中有很多地方要用到<strong>“距离”的计算</strong>，比如<strong>PCA，比如KNN，比如kmeans</strong>等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果；</li>
<li><strong>加速收敛（BN）</strong>：参数估计时使用<strong>梯度下降</strong>，在使用梯度下降的方法求解最优化问题时，
归一化/标准化后可以加快梯度下降的求解速度，即<strong>提升模型的收敛速度</strong>。</li>
</ul>
<span id="more"></span>
<h3><span id="一-归一化">一、归一化</span></h3>
<h4><span id="概要">概要</span></h4>
<p>为了讲清楚Transformer中的归一化细节，我们首先需要了解下，什么是归一化，以及为什么要归一化。本文主要解决这两个问题：</p>
<ul>
<li><strong>什么是归一化</strong></li>
<li><strong>为什要归一化</strong></li>
</ul>
<h4><span id="11-从函数的等高线说起">1.1 <strong>从函数的等高线说起</strong></span></h4>
<h5><span id="函数的等高线是什么">函数的等高线是什么</span></h5>
<p>讨论一个二元损失函数的情况，即损失函数只有两个参数: <span class="math inline">\(J\left(w_1, w_2\right)=w_1^2+w_2^2+5\)</span></p>
<ul>
<li>下图就是这个损失函数的图像, <strong>等高线就是函数 <span class="math inline">\(J\)</span> 在参数平面 <span class="math inline">\(\left(w_1, w_2\right)\)</span>
上的投影;</strong></li>
<li>等高的理解：<strong>在投影面上的任意一个环中，所有点的函数值都一样;</strong></li>
<li>等高的理解：在函数曲面上存在一个环，环上所有点的函数值一样，即距离投影平面的距离都一样;</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301703044.jpg" alt="img" style="zoom:67%;"></p>
<p><strong>具体看这个参数平面的话，绘制等高线图是：</strong></p>
<ul>
<li>任意一个环上的不同参数取值 <span class="math inline">\(\left(w_1,
w_2\right)\)</span>, 其函数值都一样;</li>
<li>可以看到, 当 <span class="math inline">\(\left(w_1=0,
w_2=0\right)\)</span> 时, 函数值 <span class="math inline">\(=5\)</span>, 即全局最小点;</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301703852.jpg" alt="img" style="zoom: 33%;"></p>
<h4><span id="12-梯度与等高线的关系">1.2 梯度与等高线的关系</span></h4>
<p>假设存在一个损失函数 <span class="math inline">\(z=f(x, y)\)</span>,
在空间中是一个曲面, 当其被一个平面 <span class="math inline">\(z=c\)</span>, c为常数所截后, 得到的曲线方程是：
<span class="math display">\[
\left\{\begin{array}{l}
z=f(x, y) \\
z=c
\end{array}\right.
\]</span> 曲线在xoy平面上的投影是一个平面曲线, 即 <span class="math inline">\(f(x, y)=c\)</span>,
即损失函数在xoy平面的某一条等高线, 在这条等高线上, 所有函数值均为 <span class="math inline">\(c\)</span> 。</p>
<p>在这条等高线上，任意一点的切线斜率为 <span class="math inline">\(\frac{d y}{d x}\)</span> 。由隐函数存在定理：
<span class="math display">\[
f^{\prime}(x)=-\frac{F_x(x, y)}{F_y(x, y)}
\]</span> 可知： <span class="math inline">\(\frac{d y}{d
x}=-\frac{f_x}{f_y}\)</span></p>
<p>任意一点的法线由于和切线垂直, 所以斜率相乘为-1, 则法线斜率为: <span class="math display">\[
-1 /\left(\frac{d y}{d
x}\right)=-\frac{1}{-\frac{f_x}{f_y}}=\frac{f_y}{f_x}
\]</span> 又由梯度的定义: <span class="math display">\[
\operatorname{gradf}(x, y)=\nabla f(x, y)=\left(\frac{\partial
f}{\partial x}, \frac{\partial f}{\partial y}\right)=\left(f_x,
f_y\right)
\]</span> 梯度向量的斜率, 即正切值= <span class="math inline">\(\frac{f_y}{f_x}\)</span>
，可以看到恰好等于法线的斜率,
<strong>因此：梯度的方向和等高线上的切线时时垂 直。</strong></p>
<h4><span id="13从等高线看为什么特征需要归一化">1.3
从等高线看为什么特征需要归一化</span></h4>
<p><strong><font color="red">
采用梯度下降算法时，因为梯度的方向和等高线的切线是垂直的，所以沿着梯度反方向迭代时，实际就是垂直于等高线一步步迭代。</font></strong>如下图所示，这是两种不同的等高线采用梯度下降算法时的迭代情况。<strong><font color="red">
很明显，左图也就是等高线呈现正圆形时能够有最少的迭代步数，因此收敛速度更快。</font></strong>然而在有些情况下，等高线是椭圆形的，会有更多的迭代步数才能到达函数最低点，收敛变慢。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301704564.jpg" alt="img" style="zoom: 33%;"></p>
<p>那么，<strong>什么时候会出现这种椭圆形的等高线情况呢？我们对线性回归和逻辑回归分别进行分析。</strong></p>
<p>以线性回归为例，假设某线性回归模型为 <span class="math inline">\(\hat{y}=w_1 x_1+w_2 x_2, x_1 \in[0,1], x_2
\in[10,100]\)</span> 。目标函数为(忽略偏 置): <span class="math display">\[
J\left(w_1, w_2\right)=\frac{1}{2} \sum_{i=1}^m\left(y^{(i)}-\left(w_1
x_1^{(i)}+w_2 x_2^{(i)}\right)\right)^2
\]</span> 从上式可以看出, 由于 <span class="math inline">\(x_2&gt;&gt;x_1\)</span>, 那么当 <span class="math inline">\(w_1, w_2\)</span> 产生相同的增量时,
后者能产生更大的函数变化值, 从而产 生椭圆形的环状等高线。本质上,
这是因为输入的特征的尺度（即取值范围)不一样!</p>
<p><strong><font color="red">
因此，在线性回归中若各个特征变量之间的取值范围差异较大，则会导致目标函数收敛速度慢等问题，需要对输入特征进行归一化，尽量避免形成椭圆形的等高线。</font></strong></p>
<p><strong>以逻辑回归为例，由于逻辑回归中特征组合的加权和还会作用上sigmoid函数</strong>，影响收敛的因素，除了梯度下降算法的效率外，更重要的是最后的输出<span class="math inline">\(z\)</span>的大小的影响。</p>
<p><img src="https://pic4.zhimg.com/80/v2-327e6fc1e096d387e2650b4057afd633_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>从上图可以看出，当z的值小于-5左右时，函数值约等于0，当z的值大于5左右时，函数值约等于1。<strong>这两种情况下面，梯度趋近于0，使得参数无法得到更新</strong>。因此，对于逻辑回归来说，主要影响的是特征组合加权和后的sigmoid输出，而特征的输入范围又会影响最终的sigmoid输出，影响模型的收敛性，所以要对输入特征进行归一化，避免最后的输出处于梯度饱和区。</p>
<h4><span id="14-总结">1.4 总结</span></h4>
<p>总结来说，<strong>输入特征的尺度会影响梯度下降算法的迭代步数以及梯度更新的难度，从而影响训练的收敛性。</strong></p>
<p><strong>因此，我们需要对特征进行归一化，即使得各个特征有相似的尺度。</strong></p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>Transformer中的归一化(一)：什么是归一化&amp;为什么要归一化 - Gordon
Lee的文章 - 知乎 https://zhuanlan.zhihu.com/p/476102712</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>理论基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>归一化</tag>
        <tag>标准化</tag>
        <tag>Batch Normalization</tag>
        <tag>Layer Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title>理论基础（7）BatchNormalization</title>
    <url>/posts/2SEFCDG/</url>
    <content><![CDATA[<h5><span id="归一化的作用">归一化的作用：</span></h5>
<ul>
<li><strong>可解释性</strong>：<strong>回归模型</strong>中自变量X的量纲不一致导致了<strong>回归系数无法直接解读</strong>或者错误解读；需要将X都处理到统一量纲下，这样才可比【可解释性】；<strong>取决于我们的逻辑回归是不是用了正则化</strong>。如果你不用正则，标准化并不是必须的，如果用正则，那么标准化是必须的。</li>
<li><strong>距离计算</strong>：机器学习任务和统计学任务中有很多地方要用到<strong>“距离”的计算</strong>，比如<strong>PCA，比如KNN，比如kmeans</strong>等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果；</li>
<li><strong>加速收敛（BN）</strong>：参数估计时使用<strong>梯度下降</strong>，在使用梯度下降的方法求解最优化问题时，
归一化/标准化后可以加快梯度下降的求解速度，即<strong>提升模型的收敛速度</strong>。</li>
</ul>
<h5><span id="batch-normalization-作用">Batch Normalization 作用：</span></h5>
<ul>
<li><strong>更好的尺度不变性：</strong>也就是说不管低层的参数如何变化，逐层的输入分布都保持相对稳定。
<ul>
<li><strong><font color="red">尺度不变性能够提高梯度下降算法的效率，从而加快收敛</font></strong>;</li>
<li><strong><font color="red">归一化到均值为0，方差为1的分布也能够使得经过sigmoid，tanh等激活函数以后，尽可能落在梯度非饱和区，缓解梯度消失的问题。</font></strong>【<strong>bn和ln都可以比较好的抑制梯度消失和梯度爆炸的情况</strong>】;</li>
</ul></li>
<li><strong>更平滑的优化地形：</strong>更平滑的优化地形意味着<strong>局部最小值的点更少</strong>，能够使得梯度更加reliable和predictive，从而让我们有更大的”信心”迈出更大的step来优化，即可以使用更大的学习率来加速收敛。</li>
<li><strong><font color="red">
对参数初始化和学习率大小不太敏感：</font></strong>BN操作可以抑制参数微小变化随网络加深的影响，使网络可以对参数初始化和尺度变化适应性更强，从而可以使用更大的学习率而不用担心参数更新step过大带来的训练不稳定。</li>
<li><strong>隐性的正则化效果：（Batch）</strong>训练时采用随机选取mini-batch来计算均值和方差，不同mini-batch的均值和方差不同，近似于引入了随机噪音，使得模型不会过拟合到某一特定的均值和方差参数下，提高网络泛化能力。</li>
</ul>
<span id="more"></span>
<h3><span id="一-batchnormalization的原理-作用和实现">一、BatchNormalization的原理、作用和实现</span></h3>
<blockquote>
<p><strong>归一化（白化）的方法有很多，为什么要设计BN这个样子的？</strong></p>
</blockquote>
<h4><span id="概要">概要</span></h4>
<p>上一节介绍了<strong>归一化方法（Batch
Normalization）在深度神经网络中的作用：有人认为是更好的尺度不变性来缓解ICS现象。有人认为是更平滑的优化地形。</strong>但实际上我们还没有介绍Batch
Normalization究竟是什么东西。这一节我们从缓解ICS现象的角度来引出Batch
Normalization，并介绍其原理和实现。</p>
<p>必须要说明的是，这个出发点在现在看来很可能已经有问题了。。（参见上一篇文章对优化地形的讨论）</p>
<h4><span id="11-从缓解ics现象出发">1.1 从缓解ICS现象出发</span></h4>
<p>ICS现象指的是该层的输入分布会因为之前层的参数更新而发生改变。为了缓解这一问题，我们需要对输入分布进行归一化。上上节讲了<strong>白化</strong>（其实还没填坑）是一种机器学习中常见的归一化手段，其好处在于：</p>
<ul>
<li><strong>能够使得逐层的输入分布具有相同的均值和方差</strong>（<strong>PCA白化能够使得所有特征分布均值为0，方差为1</strong>）</li>
<li>同时去除特征之间的相关性</li>
</ul>
<p><strong>通过白化这一方法，可以有效缓解ICS现象，加速收敛</strong>。然而呢，其存在一些问题：</p>
<ul>
<li>计算成本高（参见上上节还没填坑的计算过程，需要涉及到协方差，奇异值分解等）</li>
<li>由于对输入分布进行了限制，会损害输入数据原本的表达能力（其实就是说原本数据的分布信息丢失了）</li>
<li>均值为0，方差为1的输入分布容易使得经过sigmoid或者tanh的激活函数时，落入梯度饱和区</li>
</ul>
<p><strong><font color="red">
解决思路很简单：设计一种简化计算的白化操作，归一化后让数据尽量保留原始的表达能力。</font></strong></p>
<ul>
<li><strong>单独对每一维特征进行归一化，使其满足均值为0，方差为1</strong></li>
<li><strong>增加线性变换操作，让数据能够尽量恢复本身表达能力</strong></li>
</ul>
<h4><span id="12batch-normalization的算法过程"><strong><font color="red"> 1.2
Batch Normalization的算法过程</font></strong></span></h4>
<p><strong>首先是对每一维特征进行归一化</strong>，可以借助上上节介绍的归一化方法：<strong>本质上是减去一个统计量，再除以一个统计量</strong>。另一方面，BN的操作是在mini-batch层面进行计算，而不是full
batch。具体来说：</p>
<p>假设输入样本的形状是 <span class="math inline">\(m \times d\)</span>,
其中 <span class="math inline">\(m\)</span> 指batch size。</p>
<ul>
<li>计算第 <span class="math inline">\(i\)</span> 个样本的第 <span class="math inline">\(j\)</span> 个维度上的均值: <span class="math inline">\(\mu_j=\frac{1}{m} \sum_{i=1}^m
Z_j^{(i)}\)</span></li>
<li>计算第 <span class="math inline">\(i\)</span> 个样本的第 <span class="math inline">\(j\)</span> 个维度上的方差: <span class="math inline">\(\frac{1}{m}
\sum_{i=1}^m\left(Z_j^{(i)}-\mu_j\right)^2\)</span></li>
<li>归一化: <span class="math inline">\(\hat{Z}_j=\frac{Z_j-\mu_j}{\sqrt{\sigma^2+\epsilon}}\)</span>
(加 <span class="math inline">\(\epsilon\)</span> 防止分母为 0 )</li>
</ul>
<p><strong>通过上述变换实现每个特征维度上的均值和方差为0和1。</strong></p>
<p><font color="red">进一步的, 为了保证输入数据的表达能力,
引入两个可学习参数 <span class="math inline">\(\gamma\)</span> 和 <span class="math inline">\(\beta\)</span> (都是 <span class="math inline">\(\mathrm{d}\)</span> 维向量)
来对归一化后的数据进行线性变换: <span class="math inline">\(\tilde{Z}_j=\gamma_j \hat{Z}_j+\beta_j\)</span>
。</font>特别地, 当 <span class="math inline">\(\gamma^2=\sigma^2,
\beta=\mu\)</span> 时, 即可实现identity transform,
并保留了原始输入特征的分布信息。</p>
<p><strong>通过上述变换，在一定程度上保证了输入数据的表达能力。</strong></p>
<p><strong>综上所述：</strong> <span class="math display">\[
\tilde{Z}_j=\gamma_j \cdot
\frac{Z_j-\mu_j}{\sqrt{\sigma^2+\epsilon}}+\beta_j
\]</span></p>
<blockquote>
<p>补充：在进行归一化过程中, 由于归一化操作会减去均值,
所以偏置项可以忽略或者置0, 即 <span class="math inline">\(BN(W x+b)=B
N(Wx)\)</span></p>
</blockquote>
<h4><span id="13-batchnormalization在测试阶段">1.3 Batch
Normalization在测试阶段</span></h4>
<p>首先, 在训练阶段,
我们是对一个mini-batch的数据计算每个维度上的均值和方差。为什么不用全量数据的均值
和方差呢? 这样一来,
不管哪个batch都用的一种分布了，会降低模型的鲁棒性。</p>
<ul>
<li><p>在测试阶段, 有可能只需要预测一个样本或者很少样本,
不足以拼成一个mini-batch, 此时计算得到的均值和方
差一定是有偏估计。为了解决这一问题, BN的原论文中提出下面的方法:</p></li>
<li><p><font color="red">保留训练阶段, 每个mini-batch的均值和方差信息:
<span class="math inline">\(\mu_{\text {batch }}, \sigma_{\text {batch
}}^2\)</span> 。对测试集的数据, 计算均值和方差的无偏
估计：</font></p></li>
</ul>
<p><span class="math display">\[
\begin{gathered}
\mu_{\text {test }}=\mathbb{E}\left(\mu_{\text {batch }}\right),
\sigma_{\text {test }}^2=\frac{m}{m-1} \mathbb{E}\left(\sigma_{\text
{batch }}^2\right) \\
B N\left(X_{\text {test }}\right)=\gamma \cdot \frac{X_{\text {test
}}-\mu_{\text {test }}}{\sqrt{\sigma^2+\epsilon}}+\beta
\end{gathered}
\]</span></p>
<h5><span id="为什么训练和测试的时候计算方差不一样呢"><strong>为什么训练和测试的时候计算方差不一样呢？</strong></span></h5>
<p>训练时，计算当前batch
var时，当前batch的样本就是该随机变量的所有样本了，因此除以n就好了。而测试时是全局样本的var，<strong>因此当前batch的样本只是该随机变量的部分采样样本，为了是无偏估计，必须乘以
n/n-1</strong>。</p>
<p>在计算随机变量的均值和方差时, 一般情况下无法知道该随机变量的分布公式,
因此我们通常会采样一些样本,
然后计算这些样本的均值和方差作为该随机变量的均值和方差。<strong>由于计算这些样本的方差时减的是样本均值而不
是随机变量的均值, 而样本均值是和采样的样本有关的, 是有偏估计,
如果要得到无偏估计, 需要乘以 <span class="math inline">\(n /
n-1\)</span> 。</strong> <span class="math display">\[
\begin{array}{r}
E\left(\frac{1}{n}
\sum_{i=1}^n\left(X_i-\bar{X}\right)^2\right)=\frac{1}{n}
E\left(\sum_{i=1}^n\left(X_i-\mu+\mu-\bar{X}\right)^2\right) \\
=\frac{1}{n}\left(\sum_{i=1}^n E\left(\left(x_i-\mu\right)^2\right)-n
E\left((\bar{X}-\mu)^2\right)\right) \\
=\frac{1}{n}(n \operatorname{Var}(X)-n
\operatorname{Var}(\bar{X}))=\operatorname{Var}(X)-\operatorname{Var}(\bar{X})
\\
=\sigma^2-\frac{\sigma^2}{n}=\frac{n-1}{n} \sigma^2
\end{array}
\]</span> 在实际中，<strong>采用的是moving
average的方式来实现</strong>，也就是在每个batch训练时，用当前batch计算出的均值和方差(即sample_mean和sample_var)
来更新
running_mean和runing_var。<strong>最后测试使用的实际是running_mean和running_var</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">running_mean = momentum * running_mean + (<span class="number">1</span> - momentum) * sample_mean</span><br><span class="line">running_var = momentum * running_var + (<span class="number">1</span> - momentum) * sample_var</span><br><span class="line"></span><br><span class="line">x_stand = (x - running_mean) / np.sqrt(running_var)</span><br><span class="line">out = x_stand * gamma + beta</span><br></pre></td></tr></table></figure>
<h4><span id="14-batch-normalization的作用">1.4 Batch Normalization的作用</span></h4>
<p>总结起来就是为了<strong>稳定训练，加速收敛</strong>。具体来说，有下面几种作用：</p>
<ul>
<li><strong>更好的尺度不变性：</strong>也就是说不管低层的参数如何变化，逐层的输入分布都保持相对稳定。
<ul>
<li><strong><font color="red">尺度不变性能够提高梯度下降算法的效率，从而加快收敛</font></strong>;</li>
<li><strong><font color="red">归一化到均值为0，方差为1的分布也能够使得经过sigmoid，tanh等激活函数以后，尽可能落在梯度非饱和区，缓解梯度消失的问题。</font></strong>【<strong>bn和ln都可以比较好的抑制梯度消失和梯度爆炸的情况</strong>】;</li>
</ul></li>
<li><strong>更平滑的优化地形：</strong>更平滑的优化地形意味着<strong>局部最小值的点更少</strong>，能够使得梯度更加reliable和predictive，从而让我们有更大的”信心”迈出更大的step来优化，即可以使用更大的学习率来加速收敛。</li>
<li><strong>隐性的正则化效果：</strong>训练时采用随机选取mini-batch来计算均值和方差，不同mini-batch的均值和方差不同，近似于引入了随机噪音，使得模型不会过拟合到某一特定的均值和方差参数下，提高网络泛化能力。</li>
<li><strong><font color="red">
对参数初始化和学习率大小不太敏感：</font></strong>BN操作可以抑制参数微小变化随网络加深的影响，使网络可以对参数初始化和尺度变化适应性更强，从而可以使用更大的学习率而不用担心参数更新step过大带来的训练不稳定。</li>
</ul>
<p>假设对网络参数 <span class="math inline">\(W\)</span> 进行缩放得到
<span class="math inline">\(a W\)</span> 。对于缩放前的值 <span class="math inline">\(W x\)</span>, 设其均值为 <span class="math inline">\(\mu_1\)</span>, 方差为 <span class="math inline">\(\sigma_1^2\)</span>; 对于缩放值 <span class="math inline">\(a W x\)</span>, 设其均值为 <span class="math inline">\(\mu_2\)</span>, 方差为 <span class="math inline">\(\sigma_2^2\)</span>, 则有: <span class="math inline">\(\mu_2=a \mu_1, \sigma_2^2=a^2 \sigma_1^2\)</span>
。忽略 <span class="math inline">\(\epsilon\)</span>, 则有: <span class="math display">\[
\begin{aligned}
&amp; B N(a W x)=\gamma \cdot \frac{a W
x-\mu_2}{\sqrt{\sigma_2^2}}+\beta=\gamma \cdot \frac{a W x-a
\mu_1}{\sqrt{a^2 \sigma_1^2}}+\beta=\gamma \cdot \frac{W
x-\mu_1}{\sqrt{\sigma_1^2}}+\beta=B N(W x) \\
&amp; \frac{\partial B N(a W x)}{\partial x}=\gamma \cdot \frac{a
W}{\sqrt{\sigma_2^2}}=\gamma \cdot \frac{a W}{\sqrt{a^2
\sigma_1^2}}=\gamma \cdot \frac{W}{\sqrt{\sigma_1^2}}=\frac{\partial B
N(W x)}{\partial x} \\
&amp; \frac{\partial B N(a W x)}{\partial(a W)}=\gamma \cdot
\frac{x}{\sqrt{\sigma_2^2}}=\gamma \cdot \frac{x}{a
\sqrt{\sigma_1^2}}=\frac{1}{a} \frac{\partial B N(W x)}{\partial W}
\end{aligned}
\]</span> <strong>经过BN操作后, 权重的缩放会被抺去, 保证输入分布稳定,
同时权重的缩放也不会改变对输入的梯度</strong>, 而当权 重越大时
(即a越大时)，权重的梯度越小，即变化越小，保证了梯度不会依赖于参数的尺度。
注意一个问题是: 计算特征 <span class="math inline">\(x\)</span>
的统计量的时候, 都是在统计每个特征维度上统计量, 也就是对该维度上的所有样
本求和取均值，或者求方差, axis=bsz那个维度!</p>
<p><strong>还要注意一个问题： (一个简单的MLP)
上面讨论的所有情况的shape都是</strong>：(batch_size，hidden_dim),
此时针对每个特征维度,
我们对整个batch的样本在这个维度上计算统计量。但实际情况是, CV和NLP在应用
normalization时, shape并没有这么简单。</p>
<h4><span id="15-cnn中的batchnormalization实现">1.5 CNN中的Batch
Normalization实现</span></h4>
<p>针对CV，<strong>一个CNN的常见的输出shape是</strong>：(N, C, H, W)
，针对BN的话，这个特征维度是Channel，也就是我们需要在一个batch中所有样本<em>所有H</em>所有W上进行统计。最后得到的均值和方差向量都是(C),
因此两个参数也是C维的向量。</p>
<p>卷积操作：最初输入的图片样本的 channels
，取决于图片类型，比如RGB；常见的图像就是（N，3，H，W）。一开始，卷积核的shape可以是（3，3，3），第一个维度表示3个通道，也就是说通道有多少个，卷积核就有多少个。注意不同图像，图像不同位置使用的卷积核的参数都共享的。一个卷积核可以输出一个特征图（h1，w1），多个卷积核可以得到多个特征图，从而形成特征图的shape是（C，H，W），也就是说<strong>卷积核数=
通道数</strong>。</p>
<p>因为卷积核数=通道数, 所以一个卷积核可以得到一个通道的特征图数据,
<strong>我们希望不同图像, 图像不同位置用
这个卷积核执行卷积以后的数据分布是稳定的，所以需要在通道维度执行normalization。</strong></p>
<p>对于输入的特征图: <span class="math inline">\(x \in \mathbb{R}^{N
\times C \times H \times W}\)</span> 包含 <span class="math inline">\(\mathrm{N}\)</span> 个样本, 每个样本的通道数为
<span class="math inline">\(\mathrm{C}\)</span>, 高为 <span class="math inline">\(\mathrm{H}\)</span>, 宽为 <span class="math inline">\(\mathrm{W}\)</span> 。求均值和方差 时, 是在 <span class="math inline">\(N, H, W\)</span> 上操作, 保留 <span class="math inline">\(\mathrm{C}\)</span> 的维度, 最后形成维度为 <span class="math inline">\(\mathrm{C}\)</span> 的均值和方差向量。 <span class="math display">\[
\begin{gathered}
\mu_c(x)=\frac{1}{N H W} \sum_{n=1}^N \sum_{h=1}^H \sum_{w=1}^W x_{n c h
w} \\
\sigma_c(x)=\sqrt{\frac{1}{N H W} \sum_{n=1}^N \sum_{h=1}^H
\sum_{w=1}^W\left(x_{n c h w}-\mu_c(x)\right)^2+\epsilon}
\end{gathered}
\]</span>
<strong>在实现中需要注意的一点是：到底是对哪个维度求均值和方差</strong></p>
<ul>
<li><strong>对于shape为 <span class="math inline">\(b x d\)</span>
的张量来说, 特征维度是最后一维</strong>： <span class="math inline">\(d\)</span> 。求均值和方差实际就是：对于 <span class="math inline">\(d\)</span> 中的每一维, 统 计 <span class="math inline">\(b\)</span> 个样本的均值和方差,
均值和方差向量的形状为( <span class="math inline">\(d)\)</span>
。实现：x.mean(dim=0)。</li>
<li><strong>对于shape为BCHW的张量来说, 如果是batch Normalization,
特征维度是channel: C</strong>。求均值和方差 实际就是：先reshape：C, BHW,
然后统计BHW个样本的均值和方差, 均值和方差向量形状为(C)。实现: x.permute
<span class="math inline">\((1,0,2,3) \cdot v i e w(3,-1) \cdot\)</span>
mean(dim=1)</li>
<li>总结来说: batch
Normalization实际是对特征的每一维统计所有样本的均值和方差,
CNN里面特征维度是 channel维, 所以最后向量形状就是(C)。</li>
<li><font color="red">提前说一下: Layer
Normalization实际是对每个样本的所有维度统计均值和方差,
所以求和取平均的是d 维度, 最后向量形状就是(B, max_len)。</font></li>
</ul>
<h3><span id="二-batchnormalization-vs-layer-normalization">二、Batch
Normalization VS Layer Normalization</span></h3>
<h4><span id="概要">概要</span></h4>
<p><strong>上一节介绍了Batch
Normalization的原理，作用和实现（既讲了MLP的情况，又讲了CNN的情况）</strong>。然而我们知道，<strong>Transformer里面实际使用的Layer
Normalization</strong>。因此，本文将对比Batch Normalization介绍Layer
Normalization。</p>
<h4><span id="21-batchnormalization的些许缺陷">2.1 Batch
Normalization的些许缺陷</span></h4>
<p>要讲Layer Normalization，先讲讲Batch
Normalization存在的一些问题：即不适用于什么场景。</p>
<ul>
<li><strong>BN在mini-batch较小的情况下不太适用</strong>。BN是对整个mini-batch的样本统计均值和方差，当训练样本数很少时，<strong>样本的均值和方差不能反映全局的统计分布信息</strong>，从而导致效果下降。</li>
<li><strong>BN无法应用于RNN（Sq2Sq）</strong>，RNN实际是共享的MLP，在时间维度上展开，每个step的输出是(bsz,
hidden_dim)。由于不同句子的同一位置的分布大概率是不同的，所以应用BN来约束是没意义的。注：<strong>而BN应用在CNN可以的原因是同一个channel的特征图都是由同一个卷积核产生的</strong>。</li>
</ul>
<p><strong>LN原文的说法是</strong>：在训练时，对BN来说需要保存每个step的统计信息（均值和方差）。在测试时，由于变长句子的特性，测试集可能出现比训练集更长的句子，所以对于后面位置的step，是没有训练的统计量使用的。（不过实践中的话都是固定了maxlen，然后padding的。）<strong>不同句子的长度不一样，对所有的样本统计均值是无意义的，因为某些样本在后面的timestep时其实是padding。</strong></p>
<h4><span id="22-layer-normalization的原理">2.2 Layer Normalization的原理</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301903590.jpg" alt="img" style="zoom: 50%;"></p>
<p><strong>BN是对batch的维度去做归一化，也就是针对不同样本的同一特征做操作。LN是对hidden的维度去做归一化，也就是针对单个样本的不同特征做操作。</strong>因此<strong>LN可以不受样本数的限制。</strong></p>
<p><strong>BN就是在每个特征维度上统计所有样本的值，计算均值和方差；LN就是在每个样本上统计所有维度的值，计算均值和方差</strong>（注意，这里都是指的简单的MLP情况，输入特征是（<strong>bsz，hidden_dim</strong>））。所以BN在每个特征维度上分布是稳定的，LN是每个样本的分布是稳定的。</p>
<h4><span id="23-transformer中layernormalization的实现">2.3 Transformer中Layer
Normalization的实现</span></h4>
<p>对于一个输入tensor：(batch_size, max_len, hidden_dim)
应该如何应用LN层呢？</p>
<blockquote>
<p>注意，和Batch
Normalization一样，同样会施以线性映射的。区别就是操作的维度不同而已！公式都是统一的：<strong>减去均值除以标准差，施以线性映射</strong>。同时LN也有BN的那些个好处！</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># features: (bsz, max_len, hidden_dim)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LayerNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, features, eps=<span class="number">1e-6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(LayerNorm, self).__init__()</span><br><span class="line">        self.a_2 = nn.Parameter(torch.ones(features))</span><br><span class="line">        self.b_2 = nn.Parameter(torch.zeros(features))</span><br><span class="line">        self.eps = eps</span><br><span class="line">	</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 就是在统计每个样本所有维度的值，求均值和方差，所以就是在hidden dim上操作</span></span><br><span class="line">        <span class="comment"># 相当于变成[bsz*max_len, hidden_dim], 然后再转回来, 保持是三维</span></span><br><span class="line">        mean = x.mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>) <span class="comment"># mean: [bsz, max_len, 1]</span></span><br><span class="line">        std = x.std(-<span class="number">1</span>, keepdim=<span class="literal">True</span>) <span class="comment"># std: [bsz, max_len, 1]</span></span><br><span class="line">        <span class="comment"># 注意这里也在最后一个维度发生了广播</span></span><br><span class="line">        <span class="keyword">return</span> self.a_2 * (x - mean) / (std + self.eps) + self.b_2</span><br></pre></td></tr></table></figure>
<h4><span id="24讨论transformer-为什么使用-layernormalization而不是其他的归一化方法">2.4
讨论：Transformer 为什么使用 Layer
normalization，而不是其他的归一化方法？</span></h4>
<p>当然这个问题还没有啥定论，包括BN和LN为啥能work也众说纷纭。这里先列出一些相关的研究论文。</p>
<ul>
<li>Leveraging Batch Normalization for Vision Transformers</li>
<li>PowerNorm: Rethinking Batch Normalization in Transformers</li>
<li>Understanding and Improving Layer Normalization</li>
</ul>
<h5><span id="1understanding-and-improving-layer-normalization">(1)
Understanding and Improving Layer Normalization</span></h5>
<p>这篇文章主要研究LN为啥work，除了一般意义上认为可以稳定前向输入分布，加快收敛快，还有没有啥原因。最后的结论有：</p>
<ul>
<li><strong>相比于稳定前向输入分布，反向传播时mean和variance计算引入的梯度更有用，可以稳定反向传播的梯度</strong>（让<span class="math inline">\(\frac{\partial l o s s}{\partial x}\)</span>
梯度的均值趋于0，同时降低其方差，相当于re-zeros和re-scales操作），起名叫gradient
normalization（其实就是ablation了下，把mean和variance的梯度断掉，看看效果)</li>
<li><strong>去掉
gain和bias这两个参数可以在很多数据集上有提升，可能是因为这两个参数会带来过拟合</strong>，因为这两个参数是在训练集上学出来的</li>
</ul>
<blockquote>
<p>注：Towards Stabilizing Batch Statistics in Backward Propagation
也讨论了额外两个统计量：mean和variance的梯度的影响。实验中看到了对于小的batch
size，在反向传播中这两个统计量的方差甚至大于前向输入分布的统计量的方差，其实说白了就是这两个与梯度相关的统计量的不稳定是BN在小batch
size下不稳定的关键原因之一。</p>
</blockquote>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301903952.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h5><span id="2powernorm-rethinking-batch-normalization-in-transformers">(2)
PowerNorm: Rethinking Batch Normalization in Transformers</span></h5>
<p><strong>这篇文章就主要研究Transformer中BN为啥表现不太好</strong>。研究了训练中的四个统计量：batch的均值和方差，以及他们的梯度的均值和方差。对于batch的均值和方差，计算了他们和running
statistics（就是用移动平均法累积的均值和方差，见前面的文章）的欧氏距离。可以看到NLP任务上（IWSLT14）batch的均值和方差一直震荡，偏离全局的running
statistics，而CV任务也相对稳定。对于他们梯度的均值和方差，研究了其magnitude（绝对值），可以看到CV任务上震荡更小，且训练完成后，也没有离群点。</p>
<p>总结来说，<strong>Transformer中BN表现不太好的原因可能在于CV和NLP数据特性的不同，对于NLP数据，前向和反向传播中，batch统计量及其梯度都不太稳定。</strong></p>
<h5><span id="3leveraging-batch-normalization-for-vision-transformers">(3)
Leveraging Batch Normalization for Vision Transformers</span></h5>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304301903408.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>刚刚讲了对于NLP
data，为啥Transformer的BN表现不好。这篇文章就是去研究对于CV
data，VIT中能不能用BN呢。有一些有意思的观点：</p>
<ul>
<li><strong>LN特别适合处理变长数据，因为是对channel维度做操作(这里指NLP中的hidden维度)，和句子长度和batch大小无关</strong></li>
<li><strong>BN比LN在inference的时候快，因为不需要计算mean和variance，直接用running
mean和running variance就行</strong></li>
<li><strong>直接把VIT中的LN替换成BN，容易训练不收敛，原因是FFN没有被Normalized，所以还要在FFN
block里面的两层之间插一个BN层。（可以加速20% VIT的训练）</strong></li>
</ul>
<h4><span id="总结">总结</span></h4>
<ul>
<li><strong>Layer Normalization和Batch
Normalization一样都是一种归一化方法，因此，BatchNorm的好处LN也有</strong></li>
<li>然而BN无法胜任mini-batch size很小的情况，也很难应用于RNN。</li>
<li>LN特别适合处理变长数据，因为是对channel维度做操作(这里指NLP中的hidden维度)，和句子长度和batch大小无关。</li>
<li>BN比LN在inference的时候快，因为不需要计算mean和variance，直接用running
mean和running variance就行。</li>
<li>BN和LN在实现上的区别仅仅是：BN是对batch的维度去做归一化，也就是针对不同样本的同一特征做操作。LN是对hidden的维度去做归一化，也就是针对单个样本的不同特征做操作。因此，他们都可以归结为：减去均值除以标准差，施以线性映射。</li>
</ul>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><strong>Transformer中的归一化(四)：BatchNormalization的原理、作用和实现</strong>:https://zhuanlan.zhihu.com/p/481277619?utm_source=wechatMessage_undefined_bottom</li>
<li><strong>Transformer中的归一化(五)：Layer Norm的原理和实现 &amp;
为什么Transformer要用LayerNorm</strong> - Gordon Lee的文章 - 知乎
https://zhuanlan.zhihu.com/p/492803886</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>【draft】深度学习</category>
        <category>理论基础</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>理论基础</tag>
        <tag>归一化</tag>
        <tag>Batch Normalization</tag>
        <tag>Layer Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树（1）ID3</title>
    <url>/posts/2J7SQ0E/</url>
    <content><![CDATA[<span id="more"></span>
<h2><span id="一-id3删特征">一、ID3【删特征】</span></h2>
<p>ID3
算法是建立在奥卡姆剃刀[<strong>“切勿浪费较多东西去做，用较少的东西，同样可以做好的事情”</strong>]（用较少的东西，同样可以做好事情）的基础上：越是小型的决策树越优于大的决策树。</p>
<!--more-->
<h3><span id="11-思想">1.1 思想</span></h3>
<p>从信息论的知识中我们知道：信息熵越大，从而样本纯度越低，。ID3
算法的核心思想就是以<strong>信息增益</strong>来度量特征选择，选择信息增益最大的特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间（C4.5
也是贪婪搜索）。 其大致步骤为：</p>
<ol type="1">
<li>初始化特征集合和数据集合；</li>
<li>计算数据集合信息熵和所有特征的条件熵，选择信息增益最大的特征作为当前决策节点；</li>
<li>更新数据集合和特征集合（删除上一步使用的特征，并按照特征值来划分不同分支的数据集合）；</li>
<li>重复 2，3 两步，若子集值包含单一特征，则为分支叶子节点。</li>
</ol>
<h3><span id="12-划分标准">1.2 划分标准</span></h3>
<p>ID3 使用的分类标准是信息增益，它表示得知特征 A
的信息而使得样本集合不确定性减少的程度。</p>
<p>数据集的<strong>信息熵</strong>：</p>
<p><span class="math display">\[
H(D)=-\sum_{k=1}^{K} \frac{\left|C_{k}\right|}{|D|} \log _{2}
\frac{\left|C_{k}\right|}{|D|}
\]</span></p>
<p>其中<span class="math inline">\(C_{k}\)</span>表示集合 D 中属于第 k
类样本的样本子集。针对某个特征 A，对于数据集 D 的条件熵 <span class="math inline">\(H(D \mid A)\)</span>为：</p>
<p><span class="math display">\[
\begin{aligned} H(D \mid A) &amp;=\sum_{i=1}^{n}
\frac{\left|D_{i}\right|}{|D|} H\left(D_{i}\right) \\
&amp;=-\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|}\left(\sum_{k=1}^{K}
\frac{\left|D_{i k}\right|}{\left|D_{i}\right|} \log _{2}
\frac{\left|D_{i k}\right|}{\left|D_{i}\right|}\right) \end{aligned}
\]</span></p>
<p><strong>信息增益</strong> = 信息熵 - 条件熵。信息增益越大表示使用特征
A 来划分所获得的“纯度提升越大”。 <span class="math display">\[
\operatorname{Gain}(D, A)=H(D)-H(D \mid A)
\]</span></p>
<p>信息增益越大表示使用特征 A 来划分所获得的“纯度提升越大”。</p>
<h3><span id="13缺点没有剪枝-特征偏好-缺失值">1.3
缺点【没有剪枝、特征偏好、缺失值】</span></h3>
<ul>
<li>ID3 没有剪枝策略，容易过拟合；</li>
<li>信息增益准则对可取值数目较多的特征有所偏好，类似“编号”的特征其信息增益接近于
1；</li>
<li>只能用于处理离散分布的特征；</li>
<li>没有考虑缺失值。</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>决策树</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
        <tag>ID3</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树（2）C4-5</title>
    <url>/posts/12ZJKX/</url>
    <content><![CDATA[<h2><span id="一-c45">一、C4.5</span></h2>
<p>C4.5 算法最大的特点是克服了 ID3
对特征数目的偏重这一缺点，引入信息增益率来作为分类标准。</p>
<p>C4.5 相对于 ID3 的缺点对应有以下改进方式：</p>
<ul>
<li>引入<strong>悲观剪枝策略进行后剪枝</strong>；</li>
<li>引入<strong>信息增益率</strong>作为划分标准；</li>
<li><strong>将连续特征离散化</strong>，假设 n 个样本的连续特征 A 有 m
个取值，C4.5 将其排序并取相邻两样本值的平均数共 m-1
个划分点，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点；</li>
<li>对于<strong>缺失值的处理</strong>可以分为两个子问题：</li>
<li>问题一：在特征值缺失的情况下进行划分特征的选择？（即如何计算特征的信息增益率）
<ul>
<li>C4.5
的做法是：对于具有缺失值特征，用没有缺失的样本子集所占比重来折算；</li>
</ul></li>
<li>问题二：选定该划分特征，对于缺失该特征值的样本如何处理？（即到底把这个样本划分到哪个结点里）
<ul>
<li>C4.5
的做法是：将样本同时划分到所有子节点，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</li>
</ul></li>
</ul>
<h3><span id="12-划分标准">1.2 划分标准</span></h3>
<p>利用信息增益率可以克服信息增益的缺点，其公式为:</p>
<p><span class="math display">\[
\operatorname{Gain}_{\text {ratio }}(D, A) =\frac{\operatorname{Gain}(D,
A)}{H_{A}(D)}     \\
\]</span></p>
<p><span class="math display">\[
H_{A}(D)=-\sum_{i=1}^{n}   \frac{\left|D_{i}\right|}{|D|} \log _{2}
\frac{\left|D_{i}\right|}{|D|}
\]</span></p>
<p>信息增益率对可取值较少的特征有所偏好（分母越小，整体越大），因此 C4.5
并不是直接用增益率最大的特征进行划分，而是使用一个<strong>启发式方法</strong>：先从候选划分特征中找到信息增益高于平均值的特征，再从中选择增益率最高的。</p>
<h3><span id="13-剪枝策略">1.3 剪枝策略</span></h3>
<p>为什么要剪枝：<strong>过拟合的树在泛化能力的表现非常差。</strong></p>
<p><strong>预剪枝和悲观剪枝</strong></p>
<h4><span id="131-预剪枝"><strong>1.3.1 预剪枝</strong></span></h4>
<p>在节点划分前来确定是否继续增长，及早停止增长的主要方法有：</p>
<ul>
<li>节点内数据样本低于<strong>某一阈值</strong>；</li>
<li>所有节点特征都已分裂；</li>
<li>节点划分前准确率比划分后准确率高。</li>
</ul>
<p>预剪枝不仅可以降低过拟合的风险而且还可以减少训练时间，但另一方面它是基于“贪心”策略，会带来欠拟合风险。</p>
<h4><span id="132后剪枝悲观剪枝方法-httpgitlinuxnet2019-06-04-c45"><strong>1.3.2
后剪枝</strong>【悲观剪枝方法】 http://gitlinux.net/2019-06-04-C45/</span></h4>
<p>在已经生成的决策树上进行剪枝，从而得到简化版的剪枝决策树。</p>
<p>C4.5
采用的<strong>悲观剪枝方法</strong>，用递归的方式从低往上针对每一个非叶子节点，评估用一个最佳叶子节点去代替这课子树是否有益。如果剪枝后与剪枝前相比其错误率是保持或者下降，则这棵子树就可以被替换掉。<strong>C4.5
通过训练数据集上的错误分类数量来估算未知样本上的错误率</strong>。</p>
<p>后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但同时其训练时间会大的多。</p>
<h3><span id="14-缺点">1.4 缺点</span></h3>
<ul>
<li><strong>剪枝策略</strong>可以再优化；</li>
<li>C4.5 用的是<strong>多叉树</strong>，用二叉树效率更高；</li>
<li>C4.5 只能用于<strong>分类</strong>；</li>
<li>C4.5
使用的熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>；</li>
<li>C4.5
在构造树的过程中，<strong>对数值属性值需要按照其大小进行排序</strong>，从中选择一个分割点，所以只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时，程序无法运行。</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>决策树</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
        <tag>C4.5</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树（3）CART</title>
    <url>/posts/7ATN5F/</url>
    <content><![CDATA[<h2><span id="一-cart">一、CART</span></h2>
<p>ID3 和 C4.5
虽然在对训练样本集的学习中可以尽可能多地挖掘信息，但是其生成的决策树分支、规模都比较大，CART
算法的二分法可以简化决策树的规模，提高生成决策树的效率。</p>
<h3><span id="11-思想">1.1 思想</span></h3>
<p>CART 包含的基本过程有分裂，剪枝和树选择。</p>
<ul>
<li><strong>分裂：</strong>分裂过程是一个二叉递归划分过程，其输入和预测特征既可以是连续型的也可以是离散型的，CART
没有停止准则，会一直生长下去；</li>
<li><strong>剪枝：</strong>采用<strong>代价复杂度剪枝</strong>，从最大树开始，每次选择训练数据熵对整体性能贡献最小的那个分裂节点作为下一个剪枝对象，直到只剩下根节点。CART
会产生一系列嵌套的剪枝树，需要从中选出一颗最优的决策树；</li>
<li><strong>树选择：</strong>用单独的测试集评估每棵剪枝树的预测性能（也可以用交叉验证）。</li>
</ul>
<p>CART 在 C4.5 的基础上进行了很多提升。</p>
<ul>
<li>C4.5 为多叉树，运算速度慢，CART
为<strong>二叉树</strong>，运算速度快；</li>
<li>C4.5 只能分类，CART 既可以分类也可以<strong>回归</strong>；</li>
<li>CART 使用 <strong>Gini
系数作为变量的不纯度量</strong>，减少了<strong>大量的对数运算</strong>；</li>
<li>CART 采用<strong>代理测试来估计缺失值</strong>，而 C4.5
以不同概率划分到不同节点中；</li>
<li>CART 采用<strong>“基于代价复杂度剪枝”方法进行剪枝，而 C4.5
采用悲观剪枝方法</strong>。</li>
</ul>
<h3><span id="12-划分标准">1.2 划分标准</span></h3>
<p><strong>熵模型拥有大量耗时的对数运算</strong>，基尼指数在简化模型的同时还保留了熵模型的优点。基尼指数代表了模型的不纯度，基尼系数越小，不纯度越低，特征越好。这和信息增益（率）正好相反。
<span class="math display">\[
\begin{aligned} \operatorname{Gini}(D) &amp;=\sum_{k=1}^{K}
\frac{\left|C_{k}\right|}{|D|}\left(1-\frac{\left|C_{k}\right|}{|D|}\right)
=1-
\sum_{k=1}^{K}\left(\frac{\left|C_{k}\right|}{|D|}\right)^{2}  &amp;\operatorname{Gini}(D
\mid A) =\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|}
\operatorname{Gini}\left(D_{i}\right) \end{aligned}
\]</span></p>
<p><strong>基尼指数</strong>反映了从<strong>数据集中随机抽取两个样本，其类别标记不一致的概率</strong>。因此基尼指数越小，则数据集纯度越高。基尼指数偏向于特征值较多的特征，类似信息增益。基尼指数可以用来度量任何不均匀分布，是介于
0~1 之间的数，0 是完全相等，1
是完全不相等，<strong>基尼指数可以理解为熵模型的一阶泰勒展开。</strong></p>
<blockquote>
<p><strong><em>基尼指数是信息熵中﹣logP在P=1处一阶泰勒展开后的结果！所以两者都可以用来度量数据集的纯度</em></strong></p>
</blockquote>
<h3><span id="13-缺失值处理">1.3 缺失值处理</span></h3>
<p>上文说到，模型对于缺失值的处理会分为两个子问题：</p>
<ul>
<li><strong>如何在特征值缺失的情况下进行划分特征的选择？</strong></li>
</ul>
<p>对于问题 1，<strong>CART
一开始严格要求分裂特征评估时只能使用在该特征上没有缺失值的那部分数据，在后续版本中，CART
算法使用了一种惩罚机制来抑制提升值，从而反映出缺失值的影响</strong>（例如，如果一个特征在节点的
20% 的记录是缺失的，那么这个特征就会减少 20% 或者其他数值）。</p>
<ul>
<li><strong>选定该划分特征，模型对于缺失该特征值的样本该进行怎样处理？</strong></li>
</ul>
<p>对于问题 2，CART
算法的机制是为树的每个节点都找到<strong>代理分裂器</strong>，无论在训练数据上得到的树是否有缺失值都会这样做。在代理分裂器中，特征的分值必须超过默认规则的性能才有资格作为代理（即代理就是<strong>代替缺失值特征作为划分特征的特征</strong>），<strong>当
CART
树中遇到缺失值时，这个实例划分到左边还是右边是决定于其排名最高的代理，如果这个代理的值也缺失了，那么就使用排名第二的代理</strong>，以此类推，如果所有代理值都缺失，那么默认规则就是把样本划分到较大的那个子节点。代理分裂器可以确保无缺失训练数据上得到的树可以用来处理包含确实值的新数据。</p>
<h3><span id="14-剪枝策略">1.4 剪枝策略</span></h3>
<p><strong>基于代价复杂度的剪枝</strong>:https://www.bilibili.com/read/cv11066239</p>
<p>采用一种<strong>“基于代价复杂度的剪枝</strong>”方法进行<strong>后剪枝</strong>，这种方法会生成一系列树，每<strong>个树都是通过将前面的树的某个或某些子树替换成一个叶节点而得到的，这一系列树中的最后一棵树仅含一个用来预测类别的叶节点</strong>。然后用一种成本复杂度的度量准则来判断哪棵子树应该被一个预测类别值的叶节点所代替。<strong>这种方法需要使用一个单独的测试数据集来评估所有的树，根据它们在测试数据集熵的分类性能选出最佳的树</strong>。</p>
<blockquote>
<p>从完整子树 <span class="math inline">\(T0\)</span> 开始， 通过在
<span class="math inline">\(Ti\)</span>
子树序列中裁剪真实误差最小【考虑叶子节点的个数】的子树，得到 <span class="math inline">\(Ti+1\)</span>。 <span class="math display">\[
  $\alpha=\frac{R(t)-R(T)}{N(T)-1}$
  \]</span></p>
<p>【剪枝之后的误差 - 剪枝前的误差 / 叶子节点数 - 1】</p>
<p>每次误差增加率最小的节点，得到一系列的子树，从中选择效果最好的【独立剪枝数据集】和【K折交叉验证】</p>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211501941.png" alt="image-20220320215056933" style="zoom: 33%;"></p>
<p>我们来看具体看一下代价复杂度剪枝算法：</p>
<p>首先我们将最大树称为 <span class="math inline">\(T_0\)</span>,
我们希望减少树的大小来防止过拟合, 但又担心去掉节点后预测误差会增大,
所以我
们定义了一个损失函数来达到这两个变量之间的平衡。损失函数定义如下： <span class="math display">\[
C_\alpha(T)=C(T)+\alpha|T|
\]</span> <span class="math inline">\(T\)</span> 为任意子树, <span class="math inline">\(C(T)\)</span> 为预测误差, <span class="math inline">\(|T|\)</span> 为子树 <span class="math inline">\(T\)</span> 的叶子节点个数, <span class="math inline">\(\alpha\)</span> 是参数, <span class="math inline">\(C(T)\)</span> 衡量训练数据的拟合 程度, <span class="math inline">\(|T|\)</span> 衡量树的复杂度, <span class="math inline">\(\alpha\)</span>
<strong>权衡拟合程度与树的复杂度</strong>。</p>
<h3><span id="15-类别不平衡">1.5 类别不平衡</span></h3>
<p><font color="red"> CART
的一大优势在于：无论训练数据集有多失衡，它都可以将其子冻消除不需要建模人员采取其他操作。</font></p>
<p>CART
使用了一种先验机制，其作用相当于对类别进行加权。这种先验机制嵌入于 CART
算法判断分裂优劣的运算 里, 在 CART 默认的分类模式中,
总是要计算每个节点关于根节点的类别频率的比值, 这就相当于对数据自动重加
权, 对类别进行均衡。</p>
<p>对于一个二分类问题，节点 node 被分成类别 1 当且仅当: <span class="math display">\[
\frac{N_1(\text { node })}{N_1(\text { root })}&gt;\frac{N_0(\text {
node })}{N_0(\text { root })}
\]</span> 比如二分类，根节点属于 1 类和 0 类的分别有 20 和 80
个。在子节点上有 30 个样本，其中属于 1 类和 0 类的分 别是 10 和 20
个。如果 10/20&gt;20/80，该节点就属于 1 类。</p>
<p>通过这种计算方式就无需管理数据真实的类别分布。假设有 <span class="math inline">\(\mathrm{K}\)</span>
个目标类别，就可以确保根节点中每个类别的概率 都是 <span class="math inline">\(1 / \mathrm{K}\)</span>
。这种默认的模式被称为“先验相等”。</p>
<p>先验设置和加权不同之处在于先验不影响每个节点中的各类别样本的数量或者份额。先验影响的是每个节点的类别
赋值和树生长过程中分裂的选择。</p>
<h3><span id="16-连续值处理">1.6 连续值处理</span></h3>
<h4><span id="161-分类树">1.6.1 分类树</span></h4>
<ul>
<li><p><strong><font color="red">如果特征值是连续值：CART的处理思想与C4.5是相同的，即将连续特征值离散化。唯一不同的地方是度量的标准不一样，</font></strong>
<strong>CART采用基尼指数，而C4.5采用信息增益比</strong>。</p></li>
<li><p>如果当前节点为连续属性，<strong>CART树中该属性（剩余的属性值）后面还可以参与子节点的产生选择过程</strong>。</p></li>
</ul>
<h3><span id="17-回归树">1.7 回归树</span></h3>
<p><strong>CART（Classification and Regression
Tree，分类回归树），从名字就可以看出其不仅可以用于分类，也可以应用于回归</strong>。其回归树的建立算法上与分类树部分相似，这里简单介绍下不同之处。</p>
<h5><span id="连续值处理rss残差平方和"><strong>连续值处理</strong>：RSS<strong>残差平方和</strong></span></h5>
<p><strong>对于连续值的处理, CART
分类树采用基尼系数的大小来度量特征的各个划分点。在回归模型中,
我们使用常见的 和方差度量方式</strong>, 对于任意划分特征 <span class="math inline">\(\mathrm{A}\)</span>, 对应的任意划分点 <span class="math inline">\(\mathrm{s}\)</span> 两边划分成的数据集 <span class="math inline">\(D_1\)</span> 和 <span class="math inline">\(D_2\)</span>, 求出使 <span class="math inline">\(D_1\)</span> 和 <span class="math inline">\(D_2\)</span>
各自<strong>集合的均方差最小</strong>, 同时 <span class="math inline">\(D_1\)</span> 和 <span class="math inline">\(D_2\)</span>
的均方差之和最小所对应的特征和特征值划分点。表达式为: <span class="math display">\[
\min _{a, s}\left[\min _{c_1} \sum_{x_i \in
D_1}\left(y_i-c_1\right)^2+\min _{c_2} \sum_{x_i \in
D_2}\left(y_i-c_2\right)^2\right]
\]</span> 其中, <span class="math inline">\(c_1\)</span> 为 <span class="math inline">\(D_1\)</span> 数据集的样本输出均值, <span class="math inline">\(c_2\)</span> 为 <span class="math inline">\(D_2\)</span> 数据集的样本输出均值。</p>
<h5><span id="预测方式"><strong>预测方式</strong></span></h5>
<p>对于决策树建立后做预测的方式，上面讲到了 CART
分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。而回归树输出不是类别，它采用的是用最终叶子的均值或者中位数来预测输出结果。</p>
<h4><span id="171cart分类树建模时预测变量中存在连续和离散时会自动分别进行处理吗">1.7.1
CART分类树建模时，预测变量中存在连续和离散时，会自动分别进行处理吗？</span></h4>
<blockquote>
<p>在使用sklearn的决策树CART建模时，预测变量中存在连续和离散时，会自动分别进行处理吗？
- 月来客栈的回答 - 知乎
https://www.zhihu.com/question/472579561/answer/2002434993</p>
</blockquote>
<p><strong>对于这种连续型的特征变量，Sklearn中的具体做法（包括ID3、CART、随机森林等）是先对连续型特征变量进行排序处理</strong>，<strong><font color="red">
然后取所有连续两个值的均值来离散化整个连续型特征变量。</font></strong></p>
<p>假设现在某数据集其中一个特征维度为: <span class="math display">\[
[0.5,0.2,0.8,0.9,1.2,2.1,3.2,4.5]
\]</span> 则首先需要对其进行排序处理, 排序后的结果为: <span class="math display">\[
[0.2,0.5,0.8,0.9,1.2,2.1,3.2,4.5]
\]</span> 接着再计算所有连续两个值之间的平均值： <span class="math display">\[
[0.35,0.65,0.85,1.05,1.65,2.65,3.85]
\]</span>
这样，便得到了该特征离散化后的结果。最后在构造决策树时，只需要使用式最后离散化后的特征进行划分指标的计算即可。同时，值得一说的地方是<strong>目前Sklearn在实际处理时，会把所有的特征均看作连续型变量进行处理</strong>。</p>
<p>下图所示为iris数据集根据sklearn中CART算法所建模的决策树的可视化结果：</p>
<p><img src="https://picx.zhimg.com/v2-9081bc3cd5f2ec069212b79d5c5ff7d3_b.jpg" alt="img" style="zoom:50%;"></p>
<p>从图中可以看到，<code>petal width</code>这个特征在前两次分类时的分割点分别为0.8和1.75。下面先来看看原始特征<code>petal width</code>的取值情况：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">1.</span>  <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">1.4</span> <span class="number">2.5</span> <span class="number">1.3</span> <span class="number">2.1</span> <span class="number">1.5</span> <span class="number">0.2</span> <span class="number">2.</span>  <span class="number">1.</span>  <span class="number">0.2</span> <span class="number">0.3</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">0.2</span> <span class="number">0.5</span> <span class="number">1.3</span> <span class="number">0.2</span> <span class="number">1.2</span> <span class="number">2.2</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">2.</span>  <span class="number">0.2</span> <span class="number">1.8</span> <span class="number">1.9</span> <span class="number">1.</span>  <span class="number">1.5</span> <span class="number">2.3</span> <span class="number">1.3</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">1.9</span> <span class="number">0.2</span> <span class="number">0.2</span> <span class="number">1.1</span> <span class="number">1.7</span> <span class="number">0.2</span> <span class="number">2.4</span> <span class="number">0.2</span> <span class="number">0.6</span> <span class="number">1.8</span> <span class="number">1.1</span> <span class="number">2.3</span> <span class="number">1.6</span> <span class="number">1.4</span> <span class="number">2.3</span> <span class="number">1.3</span> <span class="number">0.2</span> <span class="number">0.1</span> <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">0.3</span> <span class="number">0.2</span> <span class="number">1.5</span> <span class="number">2.4</span> <span class="number">0.3</span> <span class="number">2.1</span> <span class="number">2.5</span> <span class="number">0.2</span> <span class="number">1.4</span> <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">1.4</span> <span class="number">2.3</span> <span class="number">0.2</span> <span class="number">2.1</span> <span class="number">1.5</span> <span class="number">2.</span>  <span class="number">1.</span>  <span class="number">1.4</span> <span class="number">1.4</span> <span class="number">0.3</span> <span class="number">1.3</span> <span class="number">1.2</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">1.8</span> <span class="number">2.1</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">2.5</span> <span class="number">1.6</span> <span class="number">0.1</span> <span class="number">2.4</span> <span class="number">0.2</span> <span class="number">1.5</span> <span class="number">1.9</span> <span class="number">1.8</span> <span class="number">1.3</span> <span class="number">1.8</span> <span class="number">1.3</span> <span class="number">1.3</span> <span class="number">2.</span>  <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">1.7</span> <span class="number">0.2</span> <span class="number">1.2</span> <span class="number">2.1</span>]</span><br></pre></td></tr></table></figure>
<p>可以发现上面并没有0.8和1.75这两个取值。接着按上面的方法先排序，再取相邻两个值的平均作为离散化的特征，其结果为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">0.1</span>, <span class="number">0.15000000000000002</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, </span><br><span class="line"><span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.25</span>, <span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.35</span>, <span class="number">0.4</span>, <span class="number">0.4</span>,</span><br><span class="line"> <span class="number">0.45</span>, <span class="number">0.55</span>, <span class="number">0.8</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.05</span>, <span class="number">1.1</span>, <span class="number">1.15</span>, <span class="number">1.2</span>, <span class="number">1.2</span>, <span class="number">1.25</span>, <span class="number">1.3</span>,</span><br><span class="line"> <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.35</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.45</span>, <span class="number">1.5</span>, </span><br><span class="line"><span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.55</span>, <span class="number">1.6</span>, <span class="number">1.65</span>, <span class="number">1.7</span>, <span class="number">1.75</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, </span><br><span class="line"><span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.85</span>, <span class="number">1.9</span>, <span class="number">1.9</span>, <span class="number">1.95</span>, <span class="number">2.0</span>, <span class="number">2.0</span>, <span class="number">2.0</span>, <span class="number">2.05</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, </span><br><span class="line"><span class="number">2.1500000000000004</span>, <span class="number">2.25</span>, <span class="number">2.3</span>, <span class="number">2.3</span>, <span class="number">2.3</span>, <span class="number">2.3499999999999996</span>, <span class="number">2.4</span>, <span class="number">2.4</span>, <span class="number">2.45</span>, <span class="number">2.5</span>, <span class="number">2.5</span>]</span><br></pre></td></tr></table></figure>
<h2><span id="二-总结">二、 总结</span></h2>
<p>最后通过总结的方式对比下 ID3、C4.5 和 CART 三者之间的差异。</p>
<p>除了之前列出来的划分标准、剪枝策略、连续值确实值处理方式等之外，我再介绍一些其他差异：</p>
<ul>
<li><strong>划分标准的差异：</strong>ID3
使用信息增益偏向特征值多的特征，C4.5
使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART
使用基尼指数克服 C4.5 需要求 log
的巨大计算量，偏向于特征值较多的特征。</li>
<li><strong>使用场景的差异：</strong>ID3 和 C4.5
都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5
是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li>
<li><strong>样本数据的差异：</strong>ID3
只能处理离散数据且缺失值敏感，C4.5 和 CART
可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议
C4.5、大样本建议 CART。C4.5
处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART
本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li>
<li><strong>样本特征的差异：</strong>ID3 和 C4.5
层级之间只使用一次特征，CART 可多次重复使用特征（连续型）；</li>
<li><strong>剪枝策略的差异：</strong>ID3 没有剪枝策略，C4.5
是通过悲观剪枝策略来修正树的准确性，而 CART 是通过代价复杂度剪枝。</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>决策树</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
        <tag>CART</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树（4）总结</title>
    <url>/posts/1WP1250/</url>
    <content><![CDATA[<h2><span id="决策树id3-c45-cart">决策树——ID3、C4.5、CART</span></h2>
<p><strong>决策树</strong>是一个非常常见并且优秀的机器学习算法，它易于理解、可解释性强，其可作为分类算法，也可用于回归模型。</p>
<table>
<colgroup>
<col style="width: 7%">
<col style="width: 30%">
<col style="width: 30%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>ID3（分类）</th>
<th>C4.5（分类）</th>
<th>CART（分类和回归）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>思想</td>
<td>奥卡姆剃刀：越是小型的决策树越优于大的决策树;ID3
算法的核心思想就是以<strong>信息增益</strong>来度量特征选择，选择信息增益最大的特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间。</td>
<td>C4.5 算法最大的特点是<strong>克服了 ID3
对特征数目的偏重</strong>这一缺点，引入<strong>信息增益率</strong>来作为分类标准。</td>
<td>CART
算法的二分法可以<strong>简化决策树的规模</strong>，提高生成决策树的效率。CART
包含的基本过程有<strong>分裂</strong>，<strong>剪枝</strong>和<strong>树选择</strong>。</td>
</tr>
<tr class="even">
<td><strong>划分标准</strong></td>
<td><strong>信息增益</strong> = 类别熵 - 特征类别熵
<strong>类别熵</strong>：<span class="math inline">\(H(D)=-\sum_{k=1}^{K}
\frac{\left|C_{k}\right|}{|D|} \log _{2}
\frac{\left|C_{k}\right|}{|D|}\)</span>
<strong>特征类别熵</strong>：<span class="math inline">\(H(D \mid
A)=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|}
H\left(D_{i}\right)\)</span></td>
<td>先从候选划分特征中找到信息增益高于平均值的特征，再从中选择<strong>增益率</strong>最高的。</td>
<td><strong>Gini
系数</strong>作为变量的<strong>不纯度量</strong>，<strong>减少了大量的对数运算</strong>；<span class="math inline">\(G i n i(D)=\sum_{k=1}^{K}
\frac{\left|C_{k}\right|}{|D|}\left(1-\frac{\left|C_{k}\right|}{|D|}\right)\)</span></td>
</tr>
<tr class="odd">
<td>剪枝策略</td>
<td><strong>无</strong></td>
<td><strong>悲观剪枝策略</strong></td>
<td>基于<strong>代价复杂度剪枝</strong></td>
</tr>
<tr class="even">
<td>数据差异</td>
<td><strong>离散</strong>数据且<strong>缺失值</strong>敏感</td>
<td><strong>离散</strong>、<strong>连续特征离散化</strong>；【排序+离散化】</td>
<td><strong>连续型、离散型</strong></td>
</tr>
<tr class="odd">
<td><strong>连续值处理</strong></td>
<td>无</td>
<td><strong>排序</strong>并取相邻两样本值的<strong>平均数</strong>。</td>
<td><strong>排序</strong>并取相邻两样本值的<strong>平均数</strong>。<strong>CART
分类树</strong>【<strong>基尼系数</strong>】。<strong>回归树</strong>【<strong>和方差度量</strong>】。</td>
</tr>
<tr class="even">
<td>缺失值处理</td>
<td><strong>无</strong></td>
<td>1、有缺失值特征，用没有缺失的样本子集所占比重来折算；2、将样本同时划分到所有子节点</td>
<td><strong>代理测试</strong>来估计缺失值</td>
</tr>
<tr class="odd">
<td>类别不平衡</td>
<td><strong>无</strong></td>
<td><strong>无</strong></td>
<td><strong>先验机制</strong>：其作用相当于对数据自动重加权，对类别进行均衡。</td>
</tr>
<tr class="even">
<td><strong>缺点</strong></td>
<td>1、ID3
没有剪枝策略，容易过拟合；2、信息增益准则对可取值<strong>数目较多的特征有所偏好</strong>，类似“编号”的特征其信息增益接近于
1； 3、只能用于处理离散分布的特征； 没有考虑缺失值。</td>
<td>1、<strong>多叉树</strong>。2、<strong>只能用于分类</strong>。3、熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>。4、驻留于内存的数据集。</td>
<td>熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>。</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>划分标准的差异：</strong>ID3
使用信息增益偏向特征值多的特征，C4.5
使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART
使用基尼指数克服 C4.5 需要求 log
的巨大计算量，偏向于特征值较多的特征。</li>
<li><strong>使用场景的差异：</strong>ID3 和 C4.5
都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5
是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li>
<li><strong>样本数据的差异：</strong>ID3
只能处理离散数据且缺失值敏感，C4.5 和 CART
可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议
C4.5、大样本建议 CART。C4.5
处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART
本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li>
<li><strong>样本特征的差异：</strong>ID3 和 C4.5
层级之间只使用一次特征，CART 可多次重复使用特征；</li>
<li><strong>剪枝策略的差异：</strong>ID3 没有剪枝策略，C4.5
是通过<strong>悲观剪枝策略</strong>来修正树的准确性，而 CART
是通过<strong>代价复杂度</strong>剪枝。</li>
</ul>
<span id="more"></span>
<h2><span id="一-决策树qampa">一、决策树Q&amp;A</span></h2>
<h4><span id="11介绍决策树id2-c45-cart-3种决策树及其区别和适应场景">1.1
介绍决策树ID2、C4.5、CART, 3种决策树及其区别和适应场景？</span></h4>
<h4><span id="12-决策树处理连续值的方法">1.2 决策树处理连续值的方法?</span></h4>
<p><strong>ID3 只能离散型</strong>。<strong>C4.5
将连续特征离散化</strong>，假设 n 个样本的连续特征 A 有 m
个取值，<strong>C4.5 将其排序并取相邻两样本值的平均数共 m-1
个划分点</strong>，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点；</p>
<p><strong>CART分类树：离散化+基尼指数，</strong></p>
<p><strong>CART回归树：均方差之和度量方式</strong> <span class="math display">\[
\min _{a, s}\left[\min _{c_1} \sum_{x_i \in
D_1}\left(y_i-c_1\right)^2+\min _{c_2} \sum_{x_i \in
D_2}\left(y_i-c_2\right)^2\right]
\]</span></p>
<h4><span id="13-决策树处理缺失值的方式">1.3 决策树处理缺失值的方式？</span></h4>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/84519568">ID3、c4.5、cart、rf到底是如何处理缺失值的？</a></p>
</blockquote>
<h5><span id="131在特征值缺失的情况下进行划分特征的选择">1.3.1
<strong>在特征值缺失的情况下进行划分特征的选择？</strong></span></h5>
<p><strong>ID3</strong> 没有缺失值处理；</p>
<p><strong>C4.5</strong>：对于具有缺失值特征，用没有缺失的<strong>样本子集所占比重来折算</strong>；</p>
<p><strong>CART</strong>：<strong>初期</strong>：分裂特征评估时只能使用在该特征上没有缺失值的那部分数据<strong>；后续</strong>：CART
算法使用了一种惩罚机制来抑制提升值，从而反映出缺失值的影响。</p>
<h5><span id="132选定该划分特征对于缺失该特征值的样本如何处理">1.3.2
<strong>选定该划分特征，对于缺失该特征值的样本如何处理？</strong></span></h5>
<p><strong>ID3</strong> 没有缺失值处理；</p>
<p><strong>C4.5</strong>：<strong>将样本同时划分到所有子节点</strong>，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</p>
<p><strong>CART</strong>：sklearn中的cart的实现是没有对缺失值做任何处理的，也就是说sklearn的cart无法处理存在缺失值的特征。</p>
<h4><span id="14-决策树如何剪枝">1.4 决策树如何剪枝？</span></h4>
<ul>
<li><strong>预剪枝</strong>：在树的生成过程中，提前停止生长。简单，适合解决大规模问题。
<ul>
<li>深度</li>
<li>节点样本数</li>
<li>对测试集准确率的提升过小</li>
</ul></li>
<li><strong>后剪枝</strong>：生成一颗完全生长的二叉树，从低向上剪枝，将子树删除用叶子节点代替。【类别：多数投票】常见的剪枝方法：错误率降低剪枝（REP）、<strong>悲观剪枝（PEP）、代价复杂度剪枝（CCP）</strong>、最小误差剪枝（MEP）等。</li>
</ul>
<p><strong>代价复杂度剪枝（CCP）【CART树】</strong></p>
<p>从完整子树 <span class="math inline">\(T0\)</span> 开始， 通过在
<span class="math inline">\(Ti\)</span>
子树序列中裁剪真实误差最小【考虑叶子节点的个数】的子树，得到 <span class="math inline">\(Ti+1\)</span>。</p>
<p><img src="image-20220321203204744.png" alt="image-20220321203204744" style="zoom: 25%;">【剪枝之后的误差
- 剪枝前的误差 / 叶子节点数 - 1】</p>
<p>每次误差增加率最小的节点，得到一系列的子树，从中选择效果最好的【独立剪枝数据集】和【K折交叉验证】</p>
<h4><span id="15决策树特征选择特征重要性判断">1.5
决策树特征选择？特征重要性判断？</span></h4>
<p><strong>XGBoost</strong>：</p>
<ul>
<li><p>该特征在所有树中被用作分割样本的特征的总次数。</p></li>
<li><p>该特征在其出现过的所有树中产生的平均增益。</p></li>
<li><p>该特征在其出现过的所有树中的平均覆盖范围。</p>
<blockquote>
<p>注意：覆盖范围这里指的是一个特征用作分割点后，其影响的样本数量，即有多少样本经过该特征分割到两个子节点。</p>
</blockquote></li>
</ul>
<h4><span id="16-svm-lr-决策树的对比">1.6 SVM、LR、决策树的对比？</span></h4>
<blockquote>
<p>逻辑回归，决策树，支持向量机 选择方案:
https://cloud.tencent.com/developer/article/1435642</p>
<p>广义线性模型？</p>
<p>sigmod、softmax</p>
<p>为什么逻辑回归的连续值也需要离散化？</p>
<p>为什么逻辑回归要用交叉熵？</p>
<p>交叉熵和KL散度（相对熵）和GAN的损失函数的区别？</p>
</blockquote>
<table>
<colgroup>
<col style="width: 6%">
<col style="width: 31%">
<col style="width: 31%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>LR 逻辑回归</th>
<th>SVM</th>
<th>决策树</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>场景</td>
<td>逻辑回归 = 线性回归 + Sigmoid
函数（非线形）【分类问题】【参数模型】【统计方法】</td>
<td>【分类问题】【几何方法】【非参数模型】</td>
<td>【分类问题】【回归问题】【非参数模型】</td>
</tr>
<tr class="even">
<td><strong>思想</strong></td>
<td><strong>思路：</strong>先拟合决策边界(不局限于线性，还可以是多项式)，再建立这个边界与分类的概率联系，从而得到了二分类情况下的概率。<strong>细节</strong>：通过<strong>非线性映射减小了离分类平面较远的点的权重</strong>，相对提升了与分类最相关的数据点的权重；</td>
<td><strong>思想</strong>：SVM
想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</td>
<td><strong>思想</strong>：用启发算法来度量特征选择，选择特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间。</td>
</tr>
<tr class="odd">
<td><strong>关键样本</strong></td>
<td><strong>所有样本</strong>（通过非线性映射，大大减小了离分类平面较远的点的权重）</td>
<td><strong>支持向量</strong>（超平面到距离最近的不同标记样本集合）</td>
<td>所有样本【非缺失特征值】</td>
</tr>
<tr class="even">
<td><strong>目标函数</strong></td>
<td><span class="math inline">\(y=\frac{1}{1+e^{-\left(w^{T}
x+b\right)}}\)</span> 【极大似然函数】</td>
<td><span class="math inline">\(\min \frac{1}{2}\|w\|^2\)</span></td>
<td><strong>Gini
系数</strong>作为变量的<strong>不纯度量</strong>，<strong>减少了大量的对数运算</strong>；<span class="math inline">\(G i n i(D)=\sum_{k=1}^{K}
\frac{\left|C_{k}\right|}{|D|}\left(1-\frac{\left|C_{k}\right|}{|D|}\right)\)</span></td>
</tr>
<tr class="odd">
<td><strong>损失函数</strong></td>
<td><font color="red"> 【交叉熵损失】</font></td>
<td><strong><a href="https://www.zhihu.com/question/47746939">HingeLoss</a></strong>【合页损失函数】<span class="math inline">\(\sum_{i=1}^N\left[1-y_i\left(w \cdot
x_i+b\right)\right]_{+}+\left.\lambda||w\right|^2\)</span><span class="math inline">\([z]_{+}=\left\{\begin{array}{l}z, z&gt;0 \\ 0 . z
\leq 0\end{array}\right.\)</span></td>
<td></td>
</tr>
<tr class="even">
<td>决策面</td>
<td>线性可分</td>
<td></td>
<td>非线性</td>
</tr>
<tr class="odd">
<td>连续值处理</td>
<td>离散化</td>
<td></td>
<td>离线化</td>
</tr>
<tr class="even">
<td><strong>输出</strong></td>
<td>类别的概率</td>
<td>类别</td>
<td>类别、回归</td>
</tr>
<tr class="odd">
<td><strong>过拟合</strong></td>
<td><strong>正则化</strong></td>
<td>\</td>
<td>预剪枝和后剪枝</td>
</tr>
<tr class="even">
<td>优势</td>
<td><strong>本质其实是为了模型参数服从某一分布</strong>；1、对观测样本的概率值输出
2、实现简单高效3、<strong>多重共线性的问题可以通过L2正则化来应对</strong>。
4、大量的工业界解决方案5、支持online learning</td>
<td>1、可以处理<strong>高维特征</strong>
2、使用<strong>核函数</strong>轻松应对非线的性特征空间
3、分类面不依赖于所有数据4、关重要的<strong>关键样本</strong></td>
<td>1、直观的决策过程 2、能够处理非线性特征
3、考虑了<strong>特征相关性</strong></td>
</tr>
<tr class="odd">
<td>劣势</td>
<td>1、特征空间太大时表现不太好 2、对于大量的分类变量无能为力
3、对于非线性特征需要做特征变换 4、依赖所有的样本数据</td>
<td>1、<strong>对于大量的观测样本，效率会很低</strong>
2、找到一个“合适”的核函数还是很tricky的</td>
<td>1、极易过拟合 2、无法输出score，只能给出直接的分类结果</td>
</tr>
</tbody>
</table>
<h4><span id="17-多重共线性问题">1.7 <strong><a href="https://blog.csdn.net/Alphonse_Huang/article/details/114278377">多重共线性问题</a></strong></span></h4>
<p>多重共线性问题就是指一个解释变量的变化引起另一个解释变量地变化。多重共<a href="https://so.csdn.net/so/search?q=线性&amp;spm=1001.2101.3001.7020">线性</a>是使用线性回归算法时经常要面对的一个问题。在其他算法中，例如决策树或者朴素贝叶斯，前者的建模过程时逐渐递进，每次都只有一个变量参与，这种机制含有抗多重共线性干扰的功能；后者假设变量之间是相互独立的。但对于回归算法来说，都要同时考虑多个预测因子，因此多重共线性不可避免。</p>
<ul>
<li>PCA等降维方法。因为在原始特征空间中变量之间相关性大，很容易想到通过降低维度的形式来去除这种共线性。</li>
<li>正则化。使用<strong>岭回归（L2</strong>）或者lasso回归（L1）或者elasticnet回归（L1+L2）</li>
<li>逐步回归法</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>决策树</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>异常检测（1）概述</title>
    <url>/posts/WH7C02/</url>
    <content><![CDATA[<h3><span id="异常检测-anomaly-detection">异常检测 (anomaly detection)</span></h3>
<p><strong>异常检测工具</strong></p>
<ul>
<li><p>PyOD:超过30种算法，从经典模型到深度学习模型一应俱全，和sklearn的用法一致</p></li>
<li><p>Scikit-Learn:包含了4种常见的算法，简单易用</p></li>
<li><p>TODS:与PyOD类似，包含多种时间序列上的异常检测算法</p></li>
</ul>
<p><strong>异常检测算法</strong></p>
<ul>
<li>线性模型：PCA</li>
<li>基于相似度度量的算法：KNN、LOF、HBOS</li>
<li>基于概率的算法：COPOD</li>
<li>集成检测：孤立森林，XGBOD</li>
<li>神经网络算法：自编码器</li>
</ul>
<p><strong>评估方法</strong></p>
<ul>
<li>ROC-AUC 曲线</li>
<li>Precision Topk：top K的准确率</li>
<li>AVE Precision：平均准确率</li>
</ul>
<h3><span id="一-概述">一、概述</span></h3>
<h4><span id="11-什么是异常检测">1.1 什么是异常检测？</span></h4>
<p>不同于常规模式下的问题和任务，<strong>异常检测针对的是少数、不可预测或不确定、罕见的事件</strong>，它具有独特的复杂性，使得一般的机器学习和深度学习技术无效。</p>
<h4><span id="12-异常检测面临的挑战">1.2 <strong>异常检测面临的挑战</strong></span></h4>
<ul>
<li><strong>未知性</strong>：异常与许多未知因素有关，例如，具有未知的突发行为、数据结构和分布的实例。它们直到真正发生时才为人所知，比如恐怖袭击、诈骗和网络入侵等应用；</li>
<li><strong>异常类的异构性</strong>：
异常是不规则的，一类异常可能表现出与另一类异常完全不同的异常特征。例如，在视频监控中，抢劫、交通事故和盗窃等异常事件在视觉上有很大差异；</li>
<li><strong>类别不均衡</strong>：异常通常是罕见的数据实例，而正常实例通常占数据的绝大部分。<strong>因此，收集大量标了标签的异常实例是困难的，甚至是不可能的。这导致在大多数应用程序中无法获得大规模的标记数据。</strong></li>
</ul>
<h4><span id="13-异常的种类">1.3 <strong>异常的种类：</strong></span></h4>
<ul>
<li><strong>点异常</strong>（point
anomalies）指的是少数个体实例是异常的，大多数个体实例是正常的，例如正常人与病人的健康指标；</li>
<li><strong>条件异常</strong>（conditional
anomalies），又称上下文异常，指的是在特定情境下个体实例是异常的，在其他情境下都是正常的，例如在特定时间下的温度突然上升或下降，在特定场景中的快速信用卡交易；</li>
<li><strong>群体异常</strong>（group
anomalies）指的是在群体集合中的个体实例出现异常的情况，而该个体实例自身可能不是异常，例如社交网络中虚假账号形成的集合作为群体异常子集，但子集中的个体节点可能与真实账号一样正常。</li>
</ul>
<h4><span id="14-异常检测数据集">1.4 <strong>异常检测数据集：</strong></span></h4>
<ul>
<li>统计型数据static data（文本、网络流）</li>
<li><strong>序列型数据sequential data（sensor data ）</strong></li>
<li>空间型数据spatial data（图像、视频）</li>
</ul>
<h4><span id="15-异常检测的应用领域">1.5 <strong>异常检测的应用领域</strong></span></h4>
<ul>
<li><strong>入侵检测</strong>（Intrusion
detection）：通过从计算机网络或计算机系统中的若干关键点收集信息并对其执行分析，从中发觉网络或系统中能不能有违反安全策略的行为和遭到袭击的迹象，并对此做出适当反应的流程。最普遍的两种入侵检测系统包括<strong>基于主机的入侵检测系统（HIDS）</strong>、<strong>网络入侵检测系统（NIDS）</strong>。</li>
<li><strong>故障检测</strong>（Fraud
detection）：主要是监控系统，在故障发生时可以识别，并且准确指出故障的种类以及出现位置。主要应用领域包括银行欺诈、移动蜂窝网络故障、保险欺诈、医疗欺诈。</li>
<li><strong>恶意软件检测</strong>（Malware Detection）</li>
<li><strong>医疗异常检测</strong>（Medical Anomaly
Detection）：通过X光片、核磁共振、CT等医学图像检测疾病或量化异常，也可以通过EEG、ECG等时序信号进行疾病检测或异常预警。</li>
<li><strong>深度学习用于社交网络中的异常检测</strong>（Deep learning for
Anomaly detection in Social Networks）</li>
<li><strong>日志异常检测</strong>（Log Anomaly Detection）</li>
<li><strong>物联网大数据异常检测</strong>（Internet of things (IoT) Big
Data Anomaly
Detection）：通过监控数据流信息检测异常设备和系统行为。</li>
<li><strong>工业异常检测</strong>（Industrial Anomalies Detection）</li>
<li><strong>时间序列中的异常检测</strong>（Anomaly Detection in
TimeSeries）</li>
<li><strong>视频监控</strong>（Video
Surveillance）：检测视频中的异常场景。</li>
</ul>
<h4><span id="16基于标签的可获得性划分异常检测">1.6
<strong>基于标签的可获得性划分异常检测：</strong></span></h4>
<ul>
<li><strong>有监督异常检测</strong>：在训练集中的正常实例和异常实例都有标签，这类方法的缺点在于数据标签难以获得或数据不均衡（正常样本数量远大于异常样本数量）。</li>
<li><strong>半监督异常检测</strong>：<strong>在训练集中只有单一类别（正常实例）的实例，没有异常实例参与训练，目前很多异常检测研究都集中在半监督方法上</strong>，有很多声称是无监督异常检测方法的研究其实也是半监督的，对其解释的是该异常检测是无监督异常检测，学习特征的方式是无监督的，但是评价方式使用了半监督的方法，因此对于无监督与半监督的界定感觉没有那么规范。</li>
<li><strong>无监督异常检测</strong>：在训练集中既有正常实例也可能存在异常实例，但假设数据的比例是正常实例远大于异常实例，模型训练过程中没有标签进行校正。</li>
<li><strong>弱监督异常检测</strong>：该类我研究的少，不是特别了解，主要是针对异常实例不完全、粗粒度标签、部分实例标签错误等情况进行算法设计。</li>
</ul>
<h4><span id="17-基于传统方法的异常检测模型">1.7 基于传统方法的异常检测模型</span></h4>
<ul>
<li><strong>基于重构的方法</strong>：<strong><font color="red">
假设异常点是不可被压缩的或不能从低维映射空间有效地被重构的。</font></strong>常见的方法有<strong>PCA</strong>、<strong>Robust
PCA</strong>、random projection等降维方法 [4,5] 。</li>
<li><strong>聚类分析方法</strong>：通过聚类可以创建数据的模型，而异常点的存在可以扭曲、破坏该模型。常见的方法有Gaussian
Mixture Models、 k-means、 multivariate Gaussian Models [6,7,8]。</li>
<li><strong>一类分类方法</strong>：对正常数据建立区分性边界，异常点被划分到边界外。常见的方法有<strong>OC-SVM</strong>
[9,10]。</li>
</ul>
<h3><span id="二-常见异常检测算法">二、常见异常检测算法</span></h3>
<p><strong>一般情况下,
可以把异常检测看成是数据不平衡下的分类问题</strong>。因此,
如果数据条件允许, 优先使 用有监督的异常检测[6]。实验结果
[4]发现直接用XGBOOST进行有监督异常检测往往也能得到不错
的结果，没有思路时不妨一试。</p>
<p><strong>而在仅有少量标签的情况下,
也可采用半监督异常检测模型</strong>。比如把无监督学习作为一种特征抽取方式来辅助监督学习
<span class="math inline">\([4,8]\)</span>,
和stacking比较类似。这种方法也可以理解成通过无监督的特征工程
对数据进行预处理后, 喂给有监督的分类模型。</p>
<p>但在现实情况中, <strong>异常检测问题往往是没有标签的,
训练数据中并末标出哪些是异常点,
因此必须用无监督学习。</strong>从实用角度出发,
我们把文章的重点放在无监督学习上。</p>
<p>本文结构如下: 1. 介绍常见的无监督异常算法及实现; 2.
对比多种算法的检测能力；3. 对比多种算法的运算开销；4.
总结并归纳如何处理异常检测问题。5. 代码重现步骤。</p>
<h4><span id="21-无监督异常检测">2.1 无监督异常检测</span></h4>
<p>如果归类的话, 无监督异常检测模型可以大致分为:</p>
<ul>
<li><strong>统计与概率模型</strong> (statistical and probabilistic and
models) ：<strong>主要是对数据的分布做出假设,
并找出假设下所定义的“异常”,
因此往往会使用极值分析Q或者假设检验</strong>。比如对最简单的一维
数据假设高斯分布 <span class="math inline">\(Q\)</span>,
然后将距离均值特定范围以外的数据当做异常点。而推广到高维后, 可以
假设<strong>每个维度各自独立</strong>,
<strong>并将各个维度上的异常度相加</strong>。如果考虑特征间的相关性,
也可以用马 氏距离 (mahalanobis distance)
来衡量数据的异常度[12]。不难看出, 这类方法最大的好处就 是速度一般比较快,
但因为存在比较强的"假设", 效果不一定很好。<strong>稍微引申一点的话,
其实给每个维度做个直方图做密度估计, 再加起来就是HBOS。</strong></li>
<li><strong>线性模型（linear
models）</strong>：假设数据在低维空间上有嵌入,
那么无法、或者在低维空间投射后 表现不好的数据可以认为是离群点 <span class="math inline">\(Q\)</span> 。
<ul>
<li><strong>举个简单的例子, PCA可以用于做异常检测</strong> [10],
一种方法 就是找到 <span class="math inline">\(k\)</span> 个特征向量
(eigenvectora), 并计算每个样本再经过这 <span class="math inline">\(k\)</span> 个特征向量投射后的<strong>重建误差
(reconstruction error)</strong>, 而正常点的重建误差应该小于异常点。</li>
<li>同理, 也可以计算每个样本 到这 <span class="math inline">\(k\)</span>
个选特征向量所构成的超空间的加权欧氏距离（特征值越小权重越大）。在相似的思路下,
我们也可以直接对协方差矩阵 <span class="math inline">\(Q\)</span>
进行分析, 并把样本的马氏距离 (在考虑特征间关系时样本到分 布中心的距离)
作为样本的异常度, 而这种方法也可以被理解为一种软性 (Soft PCA) [6]。</li>
<li>同时, 另一种经典算法One-class SVM[3]也一般被归类为线性模型。</li>
</ul></li>
<li><strong>基于相似度衡量</strong>的模型 (proximity based models) :
<strong>异常点因为和正常点的分布不同, 因此相似度较低,
由此衍生了一系列算法通过相似度来识别异常点</strong>。
<ul>
<li>比如最简单的<strong>K近邻</strong>就可以做异常
检测,一个样本和它第k个近邻的距离就可以被当做是异常值,
显然异常点的k近邻距离更大。</li>
<li>同理, <strong>基于密度分析如LOF</strong>
[1]、<strong>LOCI</strong>和<strong>LoOP主要是通过局部的数据密度来检测异常</strong>。显然,
异常点所在空间的数据点少, 密度低。</li>
<li>相似的是, <strong><font color="red"> Isolation
Forest[2]通过划分超平面Q来计算"孤立"
一个样本所需的超平面数量</font></strong>（可以想象成在想吃蛋糕上的樱桃所需的最少刀数）。在密度低的空间里
(异常点所在空间中), 孤例一个样本所需要的划分次数更少。</li>
<li>另一种相似的算法<strong>ABOD</strong>[7]
<strong>是计算每个样本与所有其他样本对所形成的夹角的方差</strong>,
异常点因为远离正常点, 因此方差变化 小。换句话说,
大部分异常检测算法都可以被认为是一种估计相似度, 无论是通过密度、距离、
夹角或是划分超平面。通过聚类也可以被理解为一种相似度度量,
比较常见不再赘述。</li>
</ul></li>
<li><strong>集成异常检测与模型融合</strong>: 在无监督学习时,
提高模型的鲁棒性很重要, 因此集成学习就大有用
武之地。比如上面提到的lsolation Forest,
就是基于构建多棵决策树实现的。最早的集成检测框 架feature
bagging[9]与分类问题中的随机森林 (random forest) 很像,
先将训练数据随机划分 (每次选取所有样本的 <span class="math inline">\(d /
2-d\)</span> 个特征, <span class="math inline">\(d\)</span> 代表特征数)
, 得到多个子训练集, 再在每个训练集上训
练一个独立的模型（默认为LOF）并最终合并所有的模型结果（如通过平均）。值得注意的是,
因为没有标签, 异常检测往往是通过bagging和feature bagging比较多,
而boosting比较少见。 boosting情况下的异常检测, 一般需要生成伪标签Q,
可参靠 <span class="math inline">\([13,14]\)</span>
。集成异常检测是一个新兴但很有趣的领域, 综述文章可以参考 <span class="math inline">\([16,17,18]\)</span> 。</li>
<li><strong>特定领域上的异常检测</strong>：比如图像异常检测 [21],
顺序及<strong>流数据异常检测（时间序列异常检测）</strong> [22],
以及高维空间上的异常检测 [23], 比如前文提到的Isolation
Forest就很适合高维数据上的 异常检测。</li>
</ul>
<p><strong>不难看出,
上文提到的划分标准其实是互相交织的</strong>。比如k-近邻可以看做是概率模型非参数化后的
一种变形,
而通过马氏距离计算异常度虽然是线性模型但也对分布有假设（高斯分布）。Isolation
Forest虽然是集成学习, 但其实和分析数据的密度有关,
并且适合高维数据上的异常检测。在这种 基础上, 多种算法其实是你中有我,
我中有你, <strong><font color="red"> 相似的理念都可以被推广和应用,
比如计算重建误 差不仅可以用PCA,
也可以用神经网络中的auto-encoder。</font></strong>另一种划分异常检测模型的标准可以理
解为局部算法 (local) 和全局算法 (global),
这种划分方法是考虑到异常点的特性。想要了解更多异常检测还是推荐看经典教科书Outlier
Analysis [6], 或者综述文章[15]。</p>
<p><strong>虽然一直有新的算法被提出, 但因为需要采用无监督学习,
且我们对数据分布的有限了解, 模型选 择往往还是采用试错法,</strong>
因此快速迭代地尝试大量的算法就是一个必经之路。在这个回答下, 我们
会对比多种算法的预测能力、运算开销及模型特点。如无特别说明，本文中的图片、代码均来自于
开源Python异常检测工具库Pyod。文中实验所使用的17个数据集均来自于 (ODDS -
Outlier Detection DataSets) 。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><p>「异常检测」开源工具库推荐 - 微调的文章 - 知乎
https://zhuanlan.zhihu.com/p/37132428</p></li>
<li><p><strong>数据挖掘中常见的「异常检测」算法有哪些？</strong> -
微调的回答 - 知乎
https://www.zhihu.com/question/280696035/answer/417091151</p></li>
<li><p>不得不推荐这门课：<a href="http://link.zhihu.com/?target=http%3A//web.stanford.edu/class/cs259d/">CS259D:
Data Mining for Cyber Security</a>
虽然是网络安全方面的应用，但是方法都是通用的，看来也很有启发。https://leotsui.gitbooks.io/cs259d-notes-cn/content/</p></li>
<li><p>中科院在读美女博士带你全面了解“异常检测”领域 - 王晋东不在家的文章
- 知乎 https://zhuanlan.zhihu.com/p/260651151</p></li>
<li><p>Python 时间序列异常检测
ADTK：https://blog.csdn.net/BF02jgtRS00XKtCx/article/details/115343456</p></li>
<li><p>awesome-TS-anomaly-detection：https://github.com/rob-med/awesome-TS-anomaly-detection</p></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>异常检测</category>
      </categories>
  </entry>
  <entry>
    <title>异常检测（2）Isolation Forest</title>
    <url>/posts/ZQ2GRE/</url>
    <content><![CDATA[<h3><span id="一-isolation-forest">一、Isolation Forest</span></h3>
<h4><span id="11-概述">1.1 概述</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261520459.png" alt="Isolation Forest算法梳理🌳" style="zoom: 67%;"></p>
<p><strong>异常检测 (anomaly
detection)</strong>，或者又被称为“<strong>离群点检测</strong>” (outlier
detection)，是机器学习研究领域中跟现实紧密联系、有广泛应用需求的一类问题。但是，什么是异常，并没有标准答案，通常因具体应用场景而异。如果要给一个比较通用的定义，很多文献通常会引用
Hawkins
在文章开头那段话。很多后来者的说法，跟这个定义大同小异。这些定义虽然笼统，但其实暗含了认定“异常”的两个标准或者说假设：</p>
<p><strong>孤立森林 (Isolation Forest) 是一个基于 Ensemble
的快速异常检测方法，具有线性时间复杂度和高精准度</strong>。其
可以用于网络安全中的攻击检测，金融交易欺计检测，疾病侦测，和噪声数据过滤等。</p>
<p>孤立森林算法的理论基础有两点：</p>
<ul>
<li>异常数据占总样本量的比列很小</li>
<li>异常点的特征值与正常点的差异很大</li>
</ul>
<h4><span id="12-itree的构建">1.2 iTREE的构建</span></h4>
<p><span class="math inline">\(i T r e e\)</span> 是一棵随机二叉树,
每一个节点要么有两个孩子, 要么就是叶子节点。假设给定一堆数据集 <span class="math inline">\(\mathbb{D} ，\)</span> 这里 <span class="math inline">\(\mathbb{D}\)</span> 的所有属性都是连续型的变量,
iTree 的构建过程如下:</p>
<ol type="1">
<li><p><strong>随机选择一个属性 Attr</strong> ；</p></li>
<li><p><strong>随机选择该属性的一个值 Value</strong>， <span class="math inline">\(\min \{A t t r\}&lt;\)</span> Value <span class="math inline">\(&lt;\max \{\)</span> Attr <span class="math inline">\(\}\)</span> ；</p></li>
<li><p><strong>根据 Attr 对每条记录进行分类，把 Attr 小于 Value
的记录放在左子树，把大于等于 Value 的记录放在右子树；</strong></p></li>
<li><p><strong>递归构造左右子树，直到满足下列条件：（1）传入的数据集只有一条记录或者多条同样的记录；
(2) 树的 深度达到了限定深度</strong>。</p></li>
</ol>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261517402.jpg" alt="img" style="zoom: 33%;"></p>
<p>iTree 构建完成之后, 只需要追踪测试数据落在 iTree
哪个叶子节点上即可评估该数据是否为异常数据, 由图中 <span class="math inline">\(i T r e e\)</span>
的构造过程可以发现异常数据通常会很快被分配到叶子节点上,
因此可以使用叶子结点到根结点的路径长 度（即边的条数） <span class="math inline">\(h(x)\)</span> 来判断一条记录 <span class="math inline">\(x\)</span> 是否是异常点。</p>
<h4><span id="13-iforest-构建">1.3 iForest 构建</span></h4>
<p>由于 <span class="math inline">\(i T r e e\)</span>
是随机选择属性和随机选择属性值来构建的，因此可以预见对于单棵 <span class="math inline">\(i T r e e\)</span> 的预测效果肯定不会很理
想，因此通过引入多棵 iTree
共同来预测那么从效果上看肯定会更具有说服力。iForest 和 Random Forest 的
方法有些类似, 都是通过随机采样, 利用部分采样数据来构造每一棵树,
以保证不同树之间的差异性。在构建 <span class="math inline">\(i\)</span>
Forest 的过程中有, 采样的样本大小 <span class="math inline">\(\psi\)</span> 和 iTree 的数量 <span class="math inline">\(t\)</span> 这两个超参数需要确定, 样本采样大小超过
256 效 果就提升不大了。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182028401.jpg" alt="img" style="zoom:67%;"></p>
<p>通过采样数据不仅可以降低计算时间的上面的浪费，而且还能够解决一些其它的小问题：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182028205.jpg" alt="preview" style="zoom:67%;"></p>
<p>左图是原始数据, 右图是经过采样了的数据, 蓝色代表正常样本,
红色代表异常样本。可以看出, 在采样之前, 正 常样本和异常样本出现了重叠,
因此很难分开, 但通过采样之后, 异常样本和正常样本可以明显的分开。 <span class="math inline">\(t\)</span> 控制 了 iTree 的数量即 Ensemble size,
孤立森林算法提出者通过实验发现, 当 <span class="math inline">\(t=100\)</span> 之前时, 算法就会收玫, 故 通常设置
<span class="math inline">\(t\)</span> 为默认值 100 , 训练一个 iForest
最差情况下的时间复杂度为 <span class="math inline">\(\mathcal{O}\left(t
\psi^2\right)\)</span> 空间复杂度为 <span class="math inline">\(\mathcal{O}(t \psi)\)</span> 。</p>
<h4><span id="14-评估">1.4 评估</span></h4>
<p>为了更好的归一化和比较, <strong>孤立森林通过引入异常值函数</strong>
<span class="math inline">\(s(x, n)\)</span> 来衡量记录 <span class="math inline">\(x\)</span> 是否为异常点。</p>
<p>给定一个包含 <span class="math inline">\(n\)</span> 个样本的数据集,
<strong>树的平均路径长度为</strong>： <span class="math inline">\(c(\mathrm{n})\)</span> 。 <span class="math display">\[
c(n)=2 H(n-1)-\frac{2(n-1)}{n}
\]</span> 其中, <span class="math inline">\(H(*)\)</span> 为调和数,
<span class="math inline">\(H(*)=\ln (*)+\xi, \xi\)</span> 为欧拉常数,
约为 <span class="math inline">\(0.5772156649 。 c(n)\)</span>
为给定样本数 <span class="math inline">\(n\)</span> 时,
路径长度的平均值, 用来标准化记录 <span class="math inline">\(x\)</span>
的路径长度 <span class="math inline">\(h(x)\)</span> 。</p>
<p><font color="red">故记录 <span class="math inline">\(x\)</span>
的异常得分可以定义为： <span class="math inline">\(\mathbf{s}(\mathbf{x}, \mathbf{n})\)</span>. 其中,
<span class="math inline">\(E(h(x))\)</span> 为记录 <span class="math inline">\(x\)</span> 在多个 <span class="math inline">\(i T
r e e\)</span> 中的路径长度的期望值。</font>可视化 <span class="math inline">\(s(x, n)\)</span> 与 <span class="math inline">\(E(h(x))\)</span> 的关系: <span class="math display">\[
s(x, n)=2^{-\frac{E(h(x))}{c(n)}}
\]</span></p>
<p><img src="https://pic4.zhimg.com/80/v2-b7f0fe8132465c0b1919b7c283d1e887_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p><strong>可以得出以下结论:</strong></p>
<ul>
<li>当 <span class="math inline">\(E(h(x)) \rightarrow c(n)\)</span> 时,
<span class="math inline">\(s \rightarrow 0.5\)</span> ， 即记录 <span class="math inline">\(x\)</span> 的平均长度与树的平均路径长度相近时,
则不能区分是否为异 常;</li>
<li>当 <span class="math inline">\(E(h(x)) \rightarrow 0 ， s
\rightarrow 1\)</span> ，即记录 <span class="math inline">\(x\)</span>
的异常分数接近 1 时，被判定为异常数据；</li>
<li>当 <span class="math inline">\(E(h(x)) \rightarrow n-1\)</span> 时,
<span class="math inline">\(s \rightarrow 0\)</span> ，
被判定为正常数据。</li>
</ul>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>孤立森林(isolation Forest)-一个通过瞎几把乱分进行异常检测的算法 -
小伍哥聊风控的文章 - 知乎 https://zhuanlan.zhihu.com/p/484495545</li>
<li><a href="https://zhuanlan.zhihu.com/p/131406753">Isolation
Forest算法梳理🌳</a>Isolation Forest算法梳理🌳</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>异常检测</category>
      </categories>
  </entry>
  <entry>
    <title>异常检测（3）HBOS</title>
    <url>/posts/3FW9EBT/</url>
    <content><![CDATA[<h3><span id="一-hbos">一、HBOS</span></h3>
<p><strong>HBOS全名为：Histogram-based Outlier
Score</strong>。它是一种单变量方法的组合，不能对特征之间的依赖关系进行建模，但是计算速度较快，对大数据集友好，其基本假设是数据集的每个维度相互独立，然后对<strong>每个维度进行区间(bin)划分，区间的密度越高，异常评分越低。理解了这句话，基本就理解了这个算法。</strong></p>
<h4><span id="11-hbos算法流程"><strong>1.1 HBOS算法流程</strong></span></h4>
<h5><span id="1-静态宽度直方图"><strong>1、静态宽度直方图</strong></span></h5>
<p>标准的直方图构建方法，在值范围内使用k个等宽箱，样本落入每个箱的频率（相对数量）作为密度（箱子高度）的估计，时间复杂度：O(n)</p>
<p><strong>注意：</strong>等宽分箱，每个箱中的数据宽度相同，不是指数据个数相同。例如序列[5,10,11,13,15,35,50,55,72,92,204,215]，数据集中最大值是215，最小值是5，分成3个箱，故每个箱的宽度应该为（215-5）/3=70，所以箱的宽度是70，这就要求箱中数据之差不能超过70，并且要把不超过70的数据全放在一起，最后的分箱结果如下：</p>
<p><strong>箱一：5,10，11,13,15,35,50,55,72；箱二：92；箱三：204,215</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182026218.png" alt="图片" style="zoom:48%;"></p>
<h5><span id="2-动态宽度直方图"><strong>2、动态宽度直方图</strong></span></h5>
<p>首先对所有值进行排序，然后固定数量的N/k 个连续值装进一个箱里，其
中N是总实例数，k是箱个数，<strong>直方图中的箱面积表示实例数</strong>，因为箱的宽度是由箱中第一个值和最后一个值决定的，所有箱的面积都一样，因此每一个箱的高度都是可计算的。这意味着跨度大的箱的高度低，即密度小，只有一种情况例外，超过k个数相等，此时允许在同一个箱里超过N/k值，时间复杂度：O(n×log(n))</p>
<p>还是用序列[<strong>5,10,11,13,15</strong>,<strong>35,50,55,72</strong>,92,204,215]举例，也是假如分3箱，那么每箱都是4个，宽度为边缘之差，第一个差为15-5=10，第二差为72-35=37，第三个箱宽为215-92=123，为了保持面积相等，所以导致后面的很矮，前面的比较高，如下图所示（非严格按照规则）：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182026012.png" alt="图片" style="zoom:50%;"></p>
<h5><span id="3-算法推导过程"><strong>3、算法推导过程</strong></span></h5>
<p><strong>对每个维度都计算了一个独立的直方图，其中每个箱子的高度表示密度的估计，然后为了使得最大高度为1（确保了每个特征与异常值得分的权重相等），对直方图进行归一化处理。</strong>最后，每一个实例的HBOS值由以下公式计算：
<span class="math display">\[
H B O S(p)=\sum_{i=0}^d \log
\left(\frac{1}{\operatorname{hist}_i(p)}\right)
\]</span> 推导过程: 假设样本 <span class="math inline">\(\mathrm{p}\)</span> 第 <span class="math inline">\(\mathrm{i}\)</span> 个特征的概率密度为 pi ( <span class="math inline">\(p\)</span> ) , 则p的概率密度可以计算为, <span class="math inline">\(d\)</span> 为总的特征的个数： <span class="math display">\[
P(p)=P_1(p) P_2(p) \cdots P_d(p)
\]</span> 两边取对数： <span class="math display">\[
\log (P(p))=\log \left(P_1(p) P_2(p) \cdots P_d(p)\right)=\sum_{i=1}^d
\log \left(P_i(p)\right)
\]</span> 概率密度越大，异常评分越小，为了方便评分，两边乘以“-1”: <span class="math display">\[
-\log (P(p))=-1 \sum_{i=1}^d \log \left(P_t(p)\right)=\sum_{i=1}^d
\frac{1}{\log \left(P_i(p)\right)}
\]</span> 最后可得： <span class="math display">\[
H B O S(p)=-\log (P(p))=\sum_{i=1}^d \frac{1}{\log \left(P_i(p)\right)}
\]</span>
PyOD是一个可扩展的Python工具包，用于检测多变量数据中的异常值。它可以在一个详细记录API下访问大约
20 个离群值检测算法。</p>
<h3><span id="三-xgbod">三、 XGBOD</span></h3>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/349519844">【异常检测】<em>XGBOD</em>：用无监督表示学习改进有监督异常检测</a></p>
</blockquote>
<h3><span id="四-copod用统计机器学习检测异常">四、COPOD：用「统计」+「机器学习」检测异常</span></h3>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/338189299">COPOD：用「统计」+「机器学习」检测异常</a></p>
</blockquote>
<h3><span id="五-more-about-anomalydetection">五、More about Anomaly
Detection</span></h3>
<p>那这个异常检测啊,其实也是另外一门学问,那我们课堂上就没有时间讲了,异常检测不是只能用
Aauto-Encoder 这个技术,Aauto-Encoder
这个技术,只是众多可能方法里面的其中一个,我们拿它来当做 Aauto-Encoder
的作业,因为我相信,你未来有很多的机会用得上异常检测这个技术,那实际上有关异常检测更完整的介绍,我们把过去上课的录影放在这边,给大家参考,</p>
<p>Part 1: https://youtu.be/gDp2LXGnVLQ</p>
<ul>
<li><strong>简介</strong></li>
</ul>
<p>Part 2: https://youtu.be/cYrNjLxkoXs</p>
<ul>
<li><strong>信心分数</strong></li>
</ul>
<p>Part 3: https://youtu.be/ueDlm2FkCnw</p>
<ul>
<li><p>异常检测系统的评估？</p>
<ul>
<li><p>no ACC</p></li>
<li><p>cost loss设计</p></li>
<li><p>RUC</p></li>
</ul></li>
</ul>
<p>Part 4: https://youtu.be/XwkHOUPbc0Q</p>
<p>Part 5: https://youtu.be/Fh1xFBktRLQ</p>
<ul>
<li>无监督</li>
</ul>
<p>Part 6: https://youtu.be/LmFWzmn2rFY</p>
<p>Part 7: https://youtu.be/6W8FqUGYyDo</p>
<p>那以上就是有关 Aauto-Encoder 的部分</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>异常检测</category>
      </categories>
  </entry>
  <entry>
    <title>支持向量机（2）软间隔对偶性</title>
    <url>/posts/349WYTC/</url>
    <content><![CDATA[<p><strong><font color="red"> SVM
是一个非常优雅的算法，具有完善的数学理论，虽然如今工业界用到的不多，但还是决定花点时间去写篇文章整理一下。</font></strong></p>
<p><strong>本质：SVM
想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</strong>为了对数据中的噪声有一定的容忍能力。<strong>以几何的角度，在丰富的数据理论的基础上，简化了通常的分类和回归问题。</strong></p>
<p><strong>几何意义</strong>：找到一个超平面将特征空间的正负样本分开，最大分隔（对噪音有一定的容忍能力）；</p>
<p><strong>间隔表示</strong>：划分超平面到属于不同标记的最近样本的距离之和；</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191157912.jpg" alt="【机器学习】支持向量机 SVM（非常详细）" style="zoom: 33%;"></p>
<span id="more"></span>
<h3><span id="一-软间隔线性svm">一、软间隔线性SVM</span></h3>
<p>在实际应用中，完全线性可分的样本是很少的，如果遇到了不能够完全线性可分的样本，我们应该怎么办？比如下面这个：</p>
<p><img src="https://s2.loli.net/2023/04/17/zDNf9QWoTs2JxVp.jpg" alt="img" style="zoom: 33%;"></p>
<p>于是我们就有了软间隔，相比于硬间隔的苛刻条件，我们允许个别样本点出现在间隔带里面，比如：</p>
<p><img src="https://s2.loli.net/2023/04/17/ha4zMrmIS9Z7jnW.jpg" alt="img" style="zoom: 33%;"></p>
<p>我们允许部分样本点不满足约束条件: <span class="math display">\[
1-y_i\left(w^T x_i+b\right) \leq 0
\]</span> 为了度量这个间隔软到何种程度, 我们为每个样本引入一个松弛变量
<span class="math inline">\(\xi_i\)</span>, 令 <span class="math inline">\(\xi_i \geq 0\)</span>, 且 <span class="math inline">\(1-y_i\left(w^T x_i+b\right)-\xi_i \leq 0\)</span>
。对应如下图所示:</p>
<p><img src="https://s2.loli.net/2023/04/17/GlPvqnUM7FDeTyX.jpg" alt="img" style="zoom: 33%;"></p>
<p><strong>这边要注意一个问题，在间隔内的那部分样本点是不是支持向量？</strong></p>
<p>我们可以由求参数 w 的那个式子可看出，只要<span class="math inline">\(\lambda &gt;
0\)</span>的点都能够影响我们的超平面，因此都是支持向量。</p>
<p><strong>硬间隔线性SVM的基本型：</strong>【凸二次规划问题，
具有全局最小值】 <span class="math display">\[
\begin{array}{ll}
\min _{w, b} &amp; \frac{1}{2} w^{\top} w \\
\text { s.t. } &amp; y_{i}\left(w^{\top} x_{i}+b\right) \geq 1, \quad
i=1,2, \ldots, m
\end{array}
\]</span> 约束中要求所有的样本都满足 <span class="math inline">\(y_{i}\left(w^{\top}
\phi\left(x_{i}\right)+b\right) \geq 1\)</span>,
也就是让所有的样本都满足 <span class="math inline">\(y_{i}\left(w^{\top}
\phi\left(x_{i}\right)+b\right)&gt;0\)</span>。
现在我们想对<strong>该约束进行一点放松</strong>,
我们希望在优化间隔的同时, 允许分类错误的样本出现, 但这类样本应尽可能少:
<span class="math display">\[
\begin{array}{ll}
\min _{w, b} &amp; \frac{1}{2} w^{\top} w+C \sum_{i=1}^{m}
\mathbb{I}\left(y_{i} \neq \operatorname{sign}\left(w^{\top}
\phi\left(x_{i}\right)+b\right)\right) \\
\text { s.t. } &amp; y_{i}\left(w^{\top} \phi\left(x_{i}\right)+b\right)
\geq 1, \quad \text { 若 } y_{i}=\operatorname{sign}\left(w^{\top}
\phi\left(x_{i}\right)+b\right) .
\end{array}
\]</span> 其中, 优化目标的第一项 <span class="math inline">\(\frac{1}{2}
w^{\top} w\)</span> 源自硬间隔核化 SVM 的基本型,
即优化间隔。优化目标的第二项 中的 <span class="math inline">\(\mathbb{I}(\cdot)\)</span> 是指示函数,
函数的参数通常是一个条件, 如果条件为真（True）, 则指示函数值为 1 ;
如果条件为假 (False), 则指示函数值为 0 。 <span class="math inline">\(\sum_{i=1}^{m} \mathbb{I}\left(y_{i} \neq
\operatorname{sign}\left(w^{\top}
\phi\left(x_{i}\right)+b\right)\right)\)</span> 的含义是统计训练集 <span class="math inline">\(D\)</span>
中所有<strong>预测错误的样本总数</strong>。因此, 公式 162
的目标函数是同时优化间隔和最小化训练集预测错误的样本总数, <strong><span class="math inline">\(C\)</span> 是个可调节的超参数,
用于权衡优化间隔和出现少量分类错误的样本这两个目标。</strong></p>
<p>但是, 由于<strong>指示函数 <span class="math inline">\(I(\cdot)\)</span> 不是连续函数, 更不是凸函数,
使得优化问题不再是二次规划问题</strong>, 求解起来十分困难,
所以我们需要对其进行简化。另外<strong>指示函数没有区分预测错误的不同程度</strong>,因此,
我们<strong>引入松他变量</strong> (Slack Variable) <span class="math inline">\(\xi_{i} \in \mathbb{R}\)</span>,
用于<strong>度量训练集 <span class="math inline">\(D\)</span> 中第 <span class="math inline">\(i\)</span> 个样本违背约束的程度</strong>。当第
<span class="math inline">\(i\)</span>
个样本<strong>违背约束的程度</strong>越大, 松弛变量 <span class="math inline">\(\xi_{i}\)</span> 的值越大 <span class="math display">\[
\xi_{i}:= \begin{cases}0 &amp; \text { 若 } y_{i}\left(w^{\top}
\phi\left(x_{i}\right)+b\right) \geq 1 ; \\ 1-y_{i}\left(w^{\top}
\phi\left(x_{i}\right)+b\right) &amp; \text { 否则. }\end{cases}
\]</span> 基于以上定义, 松弛变量 <span class="math inline">\(\xi_{i}\)</span> 的取值有以下四种情况, 如图 27
所示, 注意图 27 只是示意图, 用于理 解概念,
不表示用图中数据训练得到的分类边界一定是这样: - 当 <span class="math inline">\(\xi_{i}=0\)</span> 时, 训练集 <span class="math inline">\(D\)</span> 中第 <span class="math inline">\(i\)</span> 个样本分类正确 <span class="math inline">\(h\left(x_{i}\right)=y_{i}\)</span>,
且满足大间隔约束 <span class="math inline">\(y_{i}\left(w^{\top}
\phi\left(x_{i}\right)+b\right) \geq 1\)</span>; - 当 <span class="math inline">\(0&lt;\xi_{i}&lt;1\)</span> 时, 训练集 <span class="math inline">\(D\)</span> 中第 <span class="math inline">\(i\)</span> 个样本分类正确 <span class="math inline">\(h\left(x_{i}\right)=y_{i}\)</span>,
但是不满足大间隔约束; - 当 <span class="math inline">\(\xi_{i}=1\)</span> 时, 训练集 <span class="math inline">\(D\)</span> 中第 <span class="math inline">\(i\)</span> 个样本恰好位于划分超平面 <span class="math inline">\(w^{\top} \phi\left(x_{i}\right)+b=0\)</span> 上,
且不满足大间 隔约束; - 当 <span class="math inline">\(\xi&gt;0\)</span>
时, 训练集 <span class="math inline">\(D\)</span> 中第 <span class="math inline">\(i\)</span> 个样本分类错误 <span class="math inline">\(h\left(x_{i}\right) \neq y_{i}\)</span>,
且不满足大间隔约束。</p>
<p><img src="https://s2.loli.net/2023/04/17/LPukQfqKiBNToV5.png" alt="image-20220409230106609" style="zoom:50%;"></p>
<h5><span id="软间隔核化svm基本型合页损失函数"><strong>软间隔核化SVM基本型：</strong>（<strong>合页损失函数</strong>）：</span></h5>
<p><span class="math display">\[
\begin{array}{ll}
\min _{\boldsymbol{w}, b, \boldsymbol{\xi}} &amp; \frac{1}{2}
\boldsymbol{w}^{\top} \boldsymbol{w}+C \sum_{i=1}^m \xi_i \\
\text { s.t. } &amp; y_i\left(\boldsymbol{w}^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)+b\right) \geq 1-\xi_i,
\quad i=1,2, \ldots, m \\
&amp; \xi_i \geq 0, \quad i=1,2, \ldots, m . \\
&amp; \xi_i=\max \left(1-y_i\left(\boldsymbol{w}^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)+b\right), 0\right) .
\end{array}
\]</span> 变为: <span class="math display">\[
\begin{aligned}
&amp; \min _{\boldsymbol{w}, b, \boldsymbol{\xi}} \frac{1}{2}
\boldsymbol{w}^{\top} \boldsymbol{w}+C \sum_{i=1}^m \xi_i \\
= &amp; \min _{\boldsymbol{w}, b} \frac{1}{2} \boldsymbol{w}^{\top}
\boldsymbol{w}+C \sum_{i=1}^m \max
\left(1-y_i\left(\boldsymbol{w}^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)+b\right), 0\right) \\
= &amp; \min _{\boldsymbol{w}, b} C \sum_{i=1}^m \max
\left(1-y_i\left(\boldsymbol{w}^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)+b\right),
0\right)+\frac{1}{2}\|\boldsymbol{w}\|^2 .
\end{aligned}
\]</span> 令 <span class="math inline">\(\lambda:=\frac{1}{m
C}:\)</span> 合页损失 <span class="math display">\[
\min _{\boldsymbol{w}, b} \frac{1}{m} \sum_{i=1}^m \max
\left(1-y_i\left(\boldsymbol{w}^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)+b,
0\right)+\frac{\lambda}{2}\|\boldsymbol{w}\|^2\right.
\]</span> <strong>回顾：对数几率回归:</strong> <span class="math display">\[
\min _{\boldsymbol{w}, b} \frac{1}{m} \sum_{i=1}^m \log \left(1+\exp
\left(-y_i\left(\boldsymbol{w}^{\top}
\boldsymbol{x}_i+b\right)\right)\right)+\frac{\lambda}{2}\|\boldsymbol{w}\|^2
.
\]</span> <strong>软间隔核化SVM对偶性：
软间隔的对偶性是在硬间隔的对偶性对拉格朗日参数添加一个上界。</strong>
<span class="math display">\[
\begin{array}{ll}
\min _{\boldsymbol{\alpha}} &amp; \frac{1}{2} \sum_{i=1}^m \sum_{j=1}^m
\alpha_i \alpha_j y_i y_j \kappa\left(\boldsymbol{x}_i,
\boldsymbol{x}_j\right)-\sum_{i=1}^m \alpha_i \\
\text { s. t. } &amp; 0 \leq \alpha_i \leq C, \quad i=1,2, \ldots, m, \\
&amp; \sum_{i=1}^m \alpha_i y_i=0 .
\end{array}
\]</span></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>支持向量机</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>支持向量机</tag>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机（1）硬间隔对偶性</title>
    <url>/posts/2P1GDXT/</url>
    <content><![CDATA[<p><strong><font color="red"> SVM
是一个非常优雅的算法，具有完善的数学理论，虽然如今工业界用到的不多，但还是决定花点时间去写篇文章整理一下。</font></strong></p>
<p><strong>本质：SVM
想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</strong>为了对数据中的噪声有一定的容忍能力。<strong>以几何的角度，在丰富的数据理论的基础上，简化了通常的分类和回归问题。</strong></p>
<p><strong>几何意义</strong>：找到一个超平面将特征空间的正负样本分开，最大分隔（对噪音有一定的容忍能力）；</p>
<p><strong>间隔表示</strong>：划分超平面到属于不同标记的最近样本的距离之和；</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191157912.jpg" alt="【机器学习】支持向量机 SVM（非常详细）" style="zoom: 33%;"></p>
<span id="more"></span>
<h3><span id="一-支持向量">一、支持向量</span></h3>
<blockquote>
<ul>
<li>https://zhuanlan.zhihu.com/p/52168498</li>
</ul>
<p>【机器学习】支持向量机
SVM（非常详细）:https://zhuanlan.zhihu.com/p/77750026</p>
<p><strong>KKT条件</strong>：<strong>判断不等式约束问题是否为最优解的必要条件</strong></p>
</blockquote>
<h4><span id="11-线性可分">1.1 线性可分</span></h4>
<p>首先我们先来了解下什么是线性可分。</p>
<p><img src="https://s2.loli.net/2023/04/17/ycmF6werxUvYLh5.jpg" alt="img" style="zoom: 33%;"></p>
<p>在二维空间上, 两类点被一条直线完全分开叫做线性可分。严格的数学定义是:
<span class="math inline">\(D_0\)</span> 和 <span class="math inline">\(D_1\)</span> 是 <span class="math inline">\(\mathrm{n}\)</span>
维欧氏空间中的两个点集。如果存在 <span class="math inline">\(\mathrm{n}\)</span> 维向量 <span class="math inline">\(\mathrm{w}\)</span> 和实数 <span class="math inline">\(\mathrm{b}\)</span>, 使得所有属于 <span class="math inline">\(D_0\)</span> 的点 <span class="math inline">\(x_i\)</span> 都有 <span class="math inline">\(w
x_i+b&gt;0\)</span> ， 而对于所有属于 <span class="math inline">\(D_1\)</span> 的点 <span class="math inline">\(x_j\)</span> 则有 <span class="math inline">\(w
x_j+b&lt;0\)</span> ， 则我们称 <span class="math inline">\(D_0\)</span>
和 <span class="math inline">\(D_1\)</span> 线性可分。</p>
<h4><span id="12-最大间隔超平面">1.2 最大间隔超平面</span></h4>
<p>从二维扩展到多维空间中时, 将 <span class="math inline">\(D_0\)</span>
和 <span class="math inline">\(D_1\)</span> 完全正确地划分开的 <span class="math inline">\(w x+b=0\)</span> 就成了一个超平面。
为了使这个超平面更具鲁棒性, 我们会去找最佳超平面,
以最大间隔把两类样本分开的超平面, 也称之为最大 间隔超平面。</p>
<ul>
<li>两类样本分别分割在该超平面的两侧；</li>
<li><strong>两侧距离超平面最近的样本点到超平面的距离被最大化了。</strong>【附近点】</li>
</ul>
<h4><span id="13-支持向量距离超平面最近的点">1.3 支持向量
【距离超平面最近的点】</span></h4>
<p><img src="https://s2.loli.net/2023/04/17/HDlAed2wZf8cXi1.jpg" alt="img" style="zoom: 33%;"></p>
<p>样本中距离超平面最近的一些点，这些点叫做支持向量。</p>
<h4><span id="14-svm-最优化问题">1.4 SVM 最优化问题</span></h4>
<p><strong>SVM 想要的就是找到各类样本点到超平面的距离最远,
也就是找到最大间隔超平面</strong>。任意超平面可以用下面这个
线性方程来描述： <span class="math display">\[
w^T x+b=0
\]</span> 二维空间点 <span class="math inline">\((x, y)\)</span> 到直线
<span class="math inline">\(A x+B y+C=0\)</span> 的距离公式是: <span class="math display">\[
\frac{|A x+B y+C|}{\sqrt{A^2+B^2}}
\]</span> 扩展到 <span class="math inline">\(\mathbf{n}\)</span>
维空间后, 点 <span class="math inline">\(x=\left(x_1, x_2 \ldots
x_n\right)\)</span> 到直线 <span class="math inline">\(w^T
x+b=0\)</span> 的距离为: <span class="math display">\[
\frac{\left|w^T x+b\right|}{\|w\|}
\]</span> 其中 <span class="math inline">\(\|w\|=\sqrt{w_1^2+\ldots
w_n^2}\)</span> 。 如图所示，根据支持向量的定义我们知道,
支持向量到超平面的距离为 <span class="math inline">\(d\)</span>
，其他点到超平面的距离大于 <span class="math inline">\(d\)</span> 。</p>
<p><img src="https://s2.loli.net/2023/04/17/2yZRMfWemFcoX75.jpg" alt="img" style="zoom: 33%;"></p>
<p>于是我们有这样的一个公式： <span class="math display">\[
\left\{\begin{array}{l}
\frac{w^T x+b}{\|w\|} \geq d \quad y=1 \\
\frac{w^T x+b}{\|w\|} \leq-d \quad y=-1
\end{array}\right.
\]</span> 将两个方程合并, 我们可以简写为: <span class="math display">\[
y\left(w^T x+b\right) \geq 1
\]</span> 至此我们就可以得到最大间隔超平面的上下两个超平面：</p>
<p><img src="https://s2.loli.net/2023/04/17/aZbmfK4zWsSjyo2.png" alt="image-20220409203050568" style="zoom:50%;"></p>
<p><strong>间隔</strong>：<strong>训练集中离划分超平面最近的样本到划分超平面距离的两倍</strong>。有了间隔的定义，划分超平面“离正负样本都比较远”这一目标可以等价描述为正负样本里划分超平面的距离尽可能远。即<strong>让离划分超平面最近的样本到划分超平面距离尽可能远</strong>。优化目标：
<span class="math display">\[
\begin{aligned}
\max _{w, b} \gamma &amp;=\max _{w, b}\left(2 \min _{i}
\frac{1}{\|w\|}\left|w^{\top} x_{i}+b\right|\right) \\
&amp;=\max _{w, b} \min _{i} \frac{2}{\|w\|}\left|w^{\top}
x_{i}+b\right|
\end{aligned}
\]</span> <strong>简化过程</strong>：</p>
<ul>
<li><p><strong>缩放</strong>：为了简化优化问题, 我们可以通过调整 <span class="math inline">\((w, b)\)</span> 使得： <span class="math display">\[
\min _{i}\left|w^{\top} x_{i}+b\right|=1 .
\]</span></p></li>
<li><p><strong>标签替换绝对值</strong>： <span class="math display">\[
s.t. \min _{i} y_{i}\left(w^{\top} x_{i}+b\right)=1
\]</span></p></li>
<li><p><strong>简化约束条件</strong>【<strong>反正法</strong>】</p></li>
</ul>
<h5><span id="硬间隔线性svm的基本型"><strong><font color="red">
硬间隔线性SVM的基本型：</font></strong></span></h5>
<p><span class="math display">\[
\begin{array}{ll}
\min _{w, b} &amp; \frac{1}{2} w^{\top} w \\
\text { s.t. } &amp; y_{i}\left(w^{\top} x_{i}+b\right) \geq 1, \quad
i=1,2, \ldots, m
\end{array}
\]</span></p>
<p><img src="https://s2.loli.net/2023/04/17/l4WjzV7smKBoe8f.png" alt="image-20220423163130805" style="zoom:50%;"></p>
<p><strong>二次规划是指目标函数是二次函数，约束是线性不等式约束的一类优化问题</strong>
+ 凸函数</p>
<h3><span id="二-硬间隔线性svm对偶型">二、硬间隔线性SVM对偶型</span></h3>
<h4><span id="21-数学原理">2.1 数学原理</span></h4>
<p><strong>本科高等数学学的拉格朗日程数法是等式约束优化问题</strong>:
<span class="math display">\[
\begin{gathered}
\min f\left(x_1, x_2, \ldots, x_n\right) \\
\text { s.t. } \quad h_k\left(x_1, x_2, \ldots, x_n\right)=0 \quad
k=1,2, \ldots, l
\end{gathered}
\]</span> 我们令 <span class="math inline">\(L(x,
\lambda)=f(x)+\sum_{k=1}^l \lambda_k h_k(x)\)</span>, 函数 <span class="math inline">\(L(x, y)\)</span> 称为 Lagrange 函数, 参数 <span class="math inline">\(\lambda\)</span> 称为 Lagrange 乘子没有非负 要求。
利用必要条件找到可能的极值点: <span class="math display">\[
\begin{cases}\frac{\partial L}{\partial x_i}=0 &amp; i=1,2, \ldots, n \\
\frac{\partial L}{\partial \lambda_k}=0 &amp; k=1,2, \ldots,
l\end{cases}
\]</span>
具体是否为极值点需根据问题本身的具体情况检验。这个方程组称为等式约束的极值必要条件。等式约束下的
Lagrange 乘数法引入了 <span class="math inline">\(l\)</span> 个 Lagrange
乘子, 我们将 <span class="math inline">\(x_i\)</span> 与 <span class="math inline">\(\lambda_k\)</span> 一视同仁, 把 <span class="math inline">\(\lambda_k\)</span> 也看作优化变 量, 共有 <span class="math inline">\((n+l)\)</span> 个优化变量。</p>
<h5><span id="1写成约束优化问题的基本型">（1）写成约束优化问题的基本型</span></h5>
<p><span class="math display">\[
\begin{array}{ll}
\min _{w, b} &amp; \frac{1}{2} w^{\top} w \\
\text { s.t. } &amp; 1-y_{i}\left(w^{\top} x_{i}+b\right) \leq 0, \quad
i=1,2, \ldots, m
\end{array}
\]</span></p>
<h5><span id="2-构建基本型的拉格朗日函数">（2） 构建基本型的拉格朗日函数</span></h5>
<p><span class="math display">\[
\mathcal{L}(w, b, \alpha):=\frac{1}{2} w^{\top} w+\sum_{i=1}^{m}
\alpha_{i}\left(1-y_{i}\left(w^{\top} x_{i}+b\right)\right)
\]</span></p>
<h5><span id="3交换min-max顺序">（3）交换min, max顺序</span></h5>
<blockquote>
<p><strong>解得最优解 <span class="math inline">\(u^{\star}\)</span>
。这样两层优化问题将变为一层最大化（max）问题, 问题难度大大降低,
称为对偶问题 (Dual Problem)
:</strong>【<strong>对偶问题是原问题的下界</strong>】</p>
<ul>
<li><p><span class="math display">\[
\max _{\alpha}, \beta \min _{u} \mathcal{L}(u, \alpha, \beta) \leq \min
_{u} \max _{\alpha}, \beta \mathcal{L}(u, \alpha, \beta)
\]</span></p></li>
<li><p>硬间隔线性SVM满足<strong>Slater条件</strong>，
<strong>因此原问题和对偶问题等价</strong></p></li>
</ul>
</blockquote>
<p><span class="math display">\[
\begin{array}{cl}
\max _{\alpha} \min _{w, b} &amp; \frac{1}{2} w^{\top} w+\sum_{i=1}^{m}
\alpha_{i}\left(1-y_{i}\left(w^{\top} x_{i}+b\right)\right) \\
\text { s.t. } &amp; \alpha_{i} \geq 0, \quad i=1,2, \ldots, m .
\end{array}
\]</span></p>
<p>首先计算 <span class="math inline">\(w\)</span> 的最优值, 令 <span class="math inline">\(\frac{\partial \mathcal{L}}{\partial
w}=\mathbf{0}\)</span> <span class="math display">\[
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial w} &amp;=\frac{\partial}{\partial
w}\left(\frac{1}{2} w^{\top} w+\sum_{i=1}^{m}
\alpha_{i}\left(1-y_{i}\left(w^{\top} x_{i}+b\right)\right)\right) \\
&amp;=w+\sum_{i=1}^{m} \alpha_{i}\left(-y_{i} x_{i}\right) \\
&amp;=w-\sum_{i=1}^{m} \alpha_{i} y_{i} x_{i} \\
&amp;=\mathbf{0}
\end{aligned}
\]</span></p>
<p>可以解得最优值<span class="math inline">\(w\)</span> <span class="math display">\[
w^{\star}=\sum_{i=1}^{m} \alpha_{i} y_{i} x_{i}
\]</span> 然后计算 <span class="math inline">\(b\)</span> 的最优值, 令
<span class="math inline">\(\frac{\partial \mathcal{L}}{\partial
b}=0\)</span> <span class="math display">\[
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial b} &amp;=\frac{\partial}{\partial
b}\left(\frac{1}{2} w^{\top} w+\sum_{i=1}^{m}
\alpha_{i}\left(1-y_{i}\left(w^{\top} x_{i}+b\right)\right)\right) \\
&amp;=\sum_{i=1}^{m} \alpha_{i}\left(-y_{i}\right) \\
&amp;=-\sum_{i=1}^{m} \alpha_{i} y_{i} \\
&amp;=0
\end{aligned}
\]</span> 可以得到一个等式 <span class="math inline">\(b^{\star}\)</span> <span class="math display">\[
\sum_{i=1}^{m} \alpha_{i} y_{i}=0
\]</span> 注意到这里并没有给出最优值 <span class="math inline">\(b^{\star}\)</span> 应该是多少, 而是一个等式,
该等式是一个约束项, 而最优值通过后面的 <strong>KKT
条件</strong>的互补松弛可以计算得到。</p>
<h5><span id="硬性间隔线性svm的对偶型"><strong><font color="red">
硬性间隔线性SVM的对偶型：</font></strong></span></h5>
<p><span class="math display">\[
\begin{array}{ll}
\min _{\alpha} &amp; \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m}
\alpha_{i} \alpha_{j} y_{i} y_{j} x_{i}^{\top} x_{j}-\sum_{i=1}^{m}
\alpha_{i} \\
\text { s.t. } &amp; \alpha_{i} \geq 0, \quad i=1,2, \ldots, m \\
&amp; \sum_{i=1}^{m} \alpha_{i} y_{i}=0
\end{array}
\]</span></p>
<h5><span id="4利用kkt条件得到主问题的最优解">（4）利用KKT条件得到主问题的最优解</span></h5>
<p><strong>KKT
条件是指优化问题在最优处（包括基本型的最优值，对偶问题的最优值）必须满足的条件</strong>。</p>
<p>线性支持向量机的 <strong>KKT 条件</strong>: -
<strong>主问题可行</strong>: <span class="math inline">\(g_{i}\left(u^{\star}\right)=1-y_{i}\left(w^{\star
\top} x_{i}+b^{\star}\right) \leq 0\)</span> ； -
<strong>对偶问题可行</strong>: <span class="math inline">\(\alpha_{i}^{\star} \geq 0\)</span>; -
<strong>主变量最优</strong>: <span class="math inline">\(w^{\star}=\sum_{i=1}^{m} \alpha_{i} y_{i} x_{i},
\sum_{i=1}^{m} \alpha_{i} y_{i}=0\)</span>; - <font color="red">
<strong>互补松弛</strong>: <span class="math inline">\(\alpha_{i}^{\star}
g_{i}\left(u^{\star}\right)=\alpha_{i}^{\star}\left(1-y_{i}\left(w^{\star
\top} x_{i}+b^{\star}\right)\right)=0\)</span> ；</font></p>
<p><strong>根据 KKT 条件中的 <span class="math inline">\(\alpha_{i}^{\star} \geq 0\)</span>, 我们可以根据
<span class="math inline">\(\alpha_{i}^{\star}\)</span> 的取值将训练集
<span class="math inline">\(D\)</span> 中所有的样本分成两类</strong>, 如
图 17 所示。</p>
<ul>
<li>如果 <span class="math inline">\(\alpha_{i}^{\star}&gt;0\)</span>,
<strong>对应的样本称为支持向量 (Support Vector)</strong>, 根据 <span class="math inline">\(\alpha_{i}^{\star}\left(1-y_{i}\left(w^{\star
\top} x_{i}+b^{\star}\right)\right)=0\)</span> , 那么一定有 <span class="math inline">\(y_{i}\left(w^{\star \top}
x_{i}+b^{\star}\right)=1\)</span>, 该样本是距离划分超平面最近的样本,
位于最大间隔边界 （见第 <span class="math inline">\(2.3\)</span>
节）;</li>
<li>如果 <span class="math inline">\(\alpha_{i}^{\star}=0\)</span>,
对应的样本不是非支持向量, 那么有 <span class="math inline">\(y_{i}\left(w^{\star \top} x_{i}+b^{\star}\right)
\geq 1\)</span>, 该样本不一定是距离 划分超平面最近的样本,
<strong>位于最大间隔边界或之外</strong>。</li>
</ul>
<p><img src="https://s2.loli.net/2023/04/17/Gkx9AygPfvXmheq.png" alt="image-20220409212350705" style="zoom:50%;"></p>
<p><strong>结论</strong>：</p>
<ul>
<li><strong><font color="red"> 参数 w， b
仅由支持向量决定，与训练集的其他样本无关；</font></strong></li>
<li><strong><font color="red"> 对偶性是非参数模型，预测阶段不仅需要<span class="math inline">\(\alpha_{i}\)</span>参数，还支持向量；</font></strong></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp;h(x):=\operatorname{sign}\left(w^{\star \top} x+b^{\star}\right)
\quad \text { （硬间隔线性 SVM 的基本型的假设函数） }\\
&amp;=\operatorname{sign}\left(\sum_{i \in S V} \alpha_{i}^{\star} y_{i}
x_{i}^{\top} x+b^{\star}\right) \text {.(硬间隔线性 SVM
的对偶型的假设函数） }
\end{aligned}
\]</span></p>
<h4><span id="22-svm优化方法">2.2 SVM优化方法</span></h4>
<p>SMO算法求解</p>
<p>我们可以看出来这是一个二次规划问题, 问题规模正比于训练样本数,
我们常用 SMO(Sequential Minimal Optimization) 算法求解。</p>
<p><font color="red"> SMO(Sequential Minimal Optimization),
序列最小优化算法【基于坐标下降算法】, 其核心思想非常简单:
每次只优化一个参数, 其他参数先固定住,
仅求当前这个优化参数的极值。我们来看一下 SMO 算法在 SVM 中的
应用。</font></p>
<p>我们刚说了 SMO 算法每次只优化一个参数, 但我们的优化目标有约束条件:
<span class="math inline">\(\sum_{i=1}^n \lambda_i y_i=0\)</span>,
没法一次只变动一个
参数。所以我们选择了一次选择两个参数。具体步骤为：</p>
<ol type="1">
<li>选择两个需要更新的参数 <span class="math inline">\(\lambda_i\)</span> 和 <span class="math inline">\(\lambda_j\)</span>,
固定其他参数。于是我们有以下约束: 这样约束就变成了:</li>
</ol>
<p><span class="math display">\[
\lambda_i y_i+\lambda_j y_j=c \quad \lambda_i \geq 0, \lambda_j \geq 0
\]</span></p>
<p>其中 <span class="math inline">\(c=-\sum_{k \neq i, j} \lambda_k
y_k\)</span>, 由此可以得出 <span class="math inline">\(\lambda_j=\frac{c-\lambda_i y_i}{y_j}\)</span>
，也就是说我们可以用 <span class="math inline">\(\lambda_i\)</span>
的表达式代替 <span class="math inline">\(\lambda_j\)</span> 。这样就相当
于把目标问题转化成了仅有一个约束条件的最优化问题, 仅有的约束是 <span class="math inline">\(\lambda_i \geq 0\)</span> 。</p>
<ol start="2" type="1">
<li>对于仅有一个约束条件的最优化问题, 我们完全可以在 <span class="math inline">\(\lambda_i\)</span> 上对优化目标求偏导, 令导数为零,
从而求出变量 值 <span class="math inline">\(\lambda_{i_{\text {new
}}}\)</span> ，然后根据 <span class="math inline">\(\lambda_{\text {inew
}}\)</span> 求出 <span class="math inline">\(\lambda_{j_{\text {new
}}}\)</span> 。</li>
<li>多次迭代直至收敛。通过 SMO 求得最优解 <span class="math inline">\(\lambda^*\)</span> 。</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>支持向量机</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>支持向量机</tag>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机（3）核函数</title>
    <url>/posts/A9Y29H/</url>
    <content><![CDATA[<p><strong><font color="red">SVM
是一个非常优雅的算法，具有完善的数学理论，虽然如今工业界用到的不多，但还是决定花点时间去写篇文章整理一下。</font></strong></p>
<p><strong>本质：SVM
想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</strong>为了对数据中的噪声有一定的容忍能力。<strong>以几何的角度，在丰富的数据理论的基础上，简化了通常的分类和回归问题。</strong></p>
<p><strong>几何意义</strong>：找到一个超平面将特征空间的正负样本分开，最大分隔（对噪音有一定的容忍能力）；</p>
<p><strong>间隔表示</strong>：划分超平面到属于不同标记的最近样本的距离之和；</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191157912.jpg" alt="【机器学习】支持向量机 SVM（非常详细）" style="zoom: 33%;"></p>
<span id="more"></span>
<h3><span id="一-核函数">一、核函数</span></h3>
<h4><span id="11-线性不可分">1.1 线性不可分</span></h4>
<blockquote>
<p><strong>对于在有限维度向量空间中线性不可分的样本，我们将其映射到更高维度的向量空间里，再通过间隔最大化的方式，学习得到支持向量机，就是非线性
SVM。</strong></p>
</blockquote>
<p>我们刚刚讨论的<strong>硬间隔</strong>和<strong>软间隔</strong>都是在说样本的完全线性可分或者大部分样本点的线性可分。</p>
<p>但我们可能会碰到的一种情况是样本点不是线性可分的，比如：</p>
<p><img src="https://s2.loli.net/2023/04/17/BpDe2wT9zZQrJVn.jpg" alt="img" style="zoom:50%;"></p>
<p>这种情况的解决方法就是：将<strong>二维线性不可分样本映射到高维空间中，让样本点在高维空间线性可分</strong>，比如：</p>
<p><img src="https://s2.loli.net/2023/04/17/JhEDzmfuGyPK7A6.jpg" alt="img" style="zoom:50%;"></p>
<p>对于在有限维度向量空间中线性不可分的样本，我们将其映射到更高维度的向量空间里,
再通过间隔最大化的方 式，学习得到支持向量机，就是非线性 SVM。 我们用
<span class="math inline">\(\mathrm{x}\)</span> 表示原来的样本点, 用
<span class="math inline">\(\phi(x)\)</span> 表示 <span class="math inline">\(\mathrm{x}\)</span>
映射到特征新的特征空间后到新向量。那么分割超平面可以表示为: <span class="math inline">\(f(x)=w \phi(x)+b\)</span> 。 对于非线性 SVM
的对偶问题就变成了： <span class="math display">\[
\begin{aligned}
&amp; \min _\lambda\left[\frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \lambda_i
\lambda_j y_i y_j\left(\phi\left(x_i\right) \cdot
\phi\left(x_j\right)\right)-\sum_{j=1}^n \lambda_i\right] \\
&amp; \text { s.t. } \quad \sum_{i=1}^n \lambda_i y_i=0, \quad \lambda_i
\geq 0, \quad C-\lambda_i-\mu_i=0
\end{aligned}
\]</span> 可以看到与线性 SVM 唯一的不同就是：之前的 <span class="math inline">\(\left(x_i \cdot x_j\right)\)</span> 变成了 <span class="math inline">\(\left(\phi\left(x_i\right) \cdot
\phi\left(x_j\right)\right)\)</span> 。</p>
<h4><span id="12-核函数的作用">1.2 核函数的作用</span></h4>
<p>我们不禁有个疑问：只是做个内积运算, 为什么要有核函数的呢?</p>
<p>这是因为<font color="red"> 低维空间映射到高维空间后维度可能会很大,
如果将全部样本的点乘全部计算好, 这样的计算量太大了。</font></p>
<p>但如果我们有这样的一核函数 <span class="math inline">\(k(x,
y)=(\phi(x), \phi(y)) ， \quad x_i\)</span> 与 <span class="math inline">\(x_j\)</span>
在特征空间的内积等于它们在原始样本空间中通 过函数 <span class="math inline">\(k(x, y)\)</span> 计算的结果,
我们就不需要计算高维甚至无穷维空间的内积了。
举个例子：假设我们有一个多项式核函数： <span class="math display">\[
k(x, y)=(x \cdot y+1)^2
\]</span> 带进样本点的后: <span class="math display">\[
k(x, y)=\left(\sum_{i=1}^n\left(x_i \cdot y_i\right)+1\right)^2
\]</span> 而它的展开项是: <span class="math display">\[
\sum_{i=1}^n x_i^2 y_i^2+\sum_{i=2}^n \sum_{j=1}^{i-1}\left(\sqrt{2} x_i
x_j\right)\left(\sqrt{2} y_i y_j\right)+\sum_{i=1} n\left(\sqrt{2}
x_i\right)\left(\sqrt{2} y_i\right)+1
\]</span> 如果没有核函数，我们则需要把向量映射成: <span class="math display">\[
x^{\prime}=\left(x_1^2, \ldots, x_n^2, \ldots \sqrt{2} x_1, \ldots,
\sqrt{2} x_n, 1\right)
\]</span> 然后在进行内积计算,
才能与多项式核函数达到相同的效果。可见核函数的引入一方面减少了我们计算量,
另一方面也减少了我们存储数据的内存使用量。</p>
<h4><span id="13-常见核函数">1.3 常见核函数</span></h4>
<p>我们常用核函数有: <strong>线性核函数</strong>【无映射】 <span class="math display">\[
k\left(x_i, x_j\right)=x_i^T x_j
\]</span> - 优点: 有加速算法库、没有特征映射、过拟合风险低 -
缺点：只能处理线性</p>
<p><strong>多项式核函数【映射，超参数】</strong> <span class="math display">\[
k\left(x_i, x_j\right)=\left(x_i^T x_j\right)^d
\]</span> <strong>高斯核函数【映射，超参数】</strong> <span class="math display">\[
k\left(x_i, x_j\right)=\exp \left(-\frac{\left\|x_i-x_j\right\|}{2
\delta^2}\right)
\]</span></p>
<ul>
<li><strong>表示能力强，但容易过拟合</strong></li>
<li><strong>高斯核没有多项核不稳定的问题</strong></li>
<li><strong>只有一个超参数</strong></li>
</ul>
<h4><span id="14-如何选择核函数">1.4 <strong>如何选择核函数？</strong></span></h4>
<blockquote>
<p><strong>其他核函数：拉普拉斯、sigmod、卡方、直方图交叉</strong></p>
<p>可自定义和组合核函数</p>
</blockquote>
<ul>
<li>如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM；</li>
<li>如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数；</li>
<li>如果特征的数量小，而样本的数量很大，则需要手工添加一些特征从而变成第一种情况。</li>
</ul>
<p><img src="https://s2.loli.net/2023/04/17/uFims1jZcWSPBRx.png" alt="image-20220331203905843" style="zoom:50%;"></p>
<h4><span id="15-核方法">1.5 核方法</span></h4>
<h5><span id="核化lr-非线性-正类-y-1负类-y-1">核化LR [非线性] 正类: y = +1
负类 y= -1</span></h5>
<p><span class="math display">\[
\min _{\boldsymbol{w}, b} \frac{1}{m} \sum_{i=1}^m \log \left(1+\exp
\left(-y_i\left(\boldsymbol{w}^{\top}
\boldsymbol{x}_i+b\right)\right)\right)+\frac{\lambda}{2}\|\boldsymbol{w}\|^2
\]</span> 在本文由于通篇使用 <span class="math inline">\(\pm 1\)</span>
表示正负类, 因此我们采用上述第二种记号方法。目前已经有对数几率回
归模型的实现, 比如 <strong>sklearn.
linear_model.LogisticRegression</strong>。为了使得对数几率回归能解决非线性问题,
参考 SVM 的做法, 我们可以进行特征映射, 在特
征映射后的空间使用对数几率回归, 称为核化对数几率回归 (Kernel Logistic
Regression), 其属 于正类的概率为: <span class="math display">\[
\operatorname{Pr}(y=1 \mid
\boldsymbol{x}):=\operatorname{sigm}\left(\boldsymbol{w}^{\top}
\boldsymbol{\phi}(\boldsymbol{x})+b\right)=\frac{1}{1+\exp
\left(-\left(\boldsymbol{w}^{\top}
\boldsymbol{\phi}(\boldsymbol{x})+b\right)\right)} \in[0,1] .
\]</span> 相应地优化目标改写为 <span class="math display">\[
\min _{\boldsymbol{w}, b} \frac{1}{m} \sum_{i=1}^m \log \left(1+\exp
\left(-y_i\left(\boldsymbol{w}^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)+b\right)\right)\right)+\frac{\lambda}{2}\|\boldsymbol{w}\|^2
\]</span> 和原优化目标（公式 148）的区别在于 <span class="math inline">\(\boldsymbol{x} \in \mathbb{R}^d\)</span>
变为了特征映射后的向量 <span class="math inline">\(\boldsymbol{\phi}(\boldsymbol{x}) \in
\mathbb{R}^{\tilde{d}}\)</span>, 相应地核化对 数几率回归的参数 <span class="math inline">\(\boldsymbol{w} \in \mathbb{R}^{\tilde{d}}\)</span>
的维度也提高至 <span class="math inline">\(\tilde{d}\)</span> 。
注意到核化对数几率回归的目标函数满足表示定理, 因此参数的最优值 <span class="math inline">\(\boldsymbol{w}^{\star}\)</span> 是特征映射后样本
的线性组合 <span class="math display">\[
\boldsymbol{w}^{\star}=\sum_{i=1}^m \alpha_i
\phi\left(\boldsymbol{x}_i\right)
\]</span> 其中线性组合系数 <span class="math inline">\(\left\{\alpha_i\right\}_{i=1}^m\)</span> 待定,
将其代入公式 150 , <span class="math display">\[
\begin{aligned}
\min _{\boldsymbol{w}, b} &amp; \frac{1}{m} \sum_{i=1}^m \log
\left(1+\exp \left(-y_i\left(\boldsymbol{w}^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)+b\right)\right)\right)+\frac{\lambda}{2}\|\boldsymbol{w}\|^2
\\
=\min _{\boldsymbol{\alpha}, b} &amp; \frac{1}{m} \sum_{i=1}^m \log
\left(1+\exp \left(-y_i\left(\left(\sum_{j=1}^m \alpha_j
\boldsymbol{\phi}\left(\boldsymbol{x}_j\right)\right)^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)+b\right)\right)\right) \\
&amp; \left.+\frac{\lambda}{2}\left\|\sum_{i=1}^m \alpha_i
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)\right\|^2\right) \\
=\min _{\boldsymbol{\alpha}, b} &amp; \frac{1}{m} \sum_{i=1}^m \log
\left(1+\exp \left(-y_i\left(\sum_{j=1}^m \alpha_j
\boldsymbol{\phi}\left(\boldsymbol{x}_j\right)^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)+b\right)\right)\right) \\
&amp; +\frac{\lambda}{2} \sum_{i=1}^m \sum_{j=1}^m \alpha_i \alpha_j
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_j\right) \\
= &amp; \frac{1}{m} \sum_{\boldsymbol{\alpha}, b}^m \log \left(1+\exp
\left(-y_i\left(\sum_{j=1}^m \alpha_j
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_j\right)+b\right)\right)\right) \\
&amp; +\frac{\lambda}{2} \sum_{i=1}^m \sum_{j=1}^m \alpha_i \alpha_j
\boldsymbol{\phi}\left(\boldsymbol{x}_i\right)^{\top}
\boldsymbol{\phi}\left(\boldsymbol{x}_j\right) \\
&amp; +\frac{1}{2} \sum_{i=1}^m \log \left(1+\exp \left(-y_i
\sum_{j=1}^m \alpha_j \kappa\left(\boldsymbol{x}_i,
\boldsymbol{x}_j\right)-y_i b\right)\right)
\end{aligned}
\]</span> ##### <strong>梯度下降求解：</strong></p>
<p>核化LR的参数通常都非0，并且几乎用到所有训练的样本，预测效率比较低。</p>
<p><img src="https://s2.loli.net/2023/04/17/8d9UGWZyzBoAhjJ.png" alt="image-20220331212433609" style="zoom:50%;"></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>支持向量机</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>支持向量机</tag>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机（5）总结</title>
    <url>/posts/2NSQX65/</url>
    <content><![CDATA[<h3><span id="一-支持向量机-svm">一、支持向量机 SVM</span></h3>
<p><strong><font color="red"> SVM
是一个非常优雅的算法，具有完善的数学理论，虽然如今工业界用到的不多，但还是决定花点时间去写篇文章整理一下。</font></strong></p>
<p><strong>本质：SVM
想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</strong>为了对数据中的噪声有一定的容忍能力。<strong>以几何的角度，在丰富的数据理论的基础上，简化了通常的分类和回归问题。</strong></p>
<p><strong>几何意义</strong>：找到一个超平面将特征空间的正负样本分开，最大分隔（对噪音有一定的容忍能力）；</p>
<p><strong>间隔表示</strong>：划分超平面到属于不同标记的最近样本的距离之和；</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191157912.jpg" alt="【机器学习】支持向量机 SVM（非常详细）" style="zoom: 33%;"></p>
<span id="more"></span>
<h3><span id="二-优缺点">二、优缺点</span></h3>
<h4><span id="21-优点">2.1 优点</span></h4>
<ul>
<li>有严格的<strong>数学理论支持</strong>，<strong>可解释性强</strong>，<strong>不依靠统计方法</strong>，从而<strong>简化了通常的分类和回归问题</strong>；</li>
<li>能找出对任务至关重要的<strong>关键样本</strong>（即：<strong>支持向量</strong>）；</li>
<li>采用<strong>核技巧</strong>之后，<strong>可以处理非线性分类/回归任务</strong>；</li>
<li><strong>最终决策函数只由少数的支持向量所确定，计算的复杂性取决于支持向量的数目，而不是样本空间的维数，这在某种意义上避免了“维数灾难”。</strong></li>
</ul>
<h4><span id="22-缺点">2.2 缺点</span></h4>
<ul>
<li><strong>训练时间长</strong>：当采用 SMO
算法时，由于每次都需要挑选一对参数，因此时间复杂度为<span class="math inline">\(O(N^2)\)</span> ，其中 N 为训练样本的数量；</li>
<li><strong>存储空间大</strong>：当采用核技巧时，如果需要存储核矩阵，则空间复杂度为<span class="math inline">\(O(N^2)\)</span> ；</li>
<li><strong>预测时间长</strong>：模型预测时，预测时间与支持向量的个数成正比。当支持向量的数量较大时，预测计算复杂度较高。</li>
</ul>
<p><strong>因此支持向量机目前只适合小批量样本的任务，无法适应百万甚至上亿样本的任务。</strong></p>
<h3><span id="三-svm-qampa">三、SVM Q&amp;A</span></h3>
<blockquote>
<p>https://zhuanlan.zhihu.com/p/93715996</p>
</blockquote>
<h4><span id="1-原理">1、原理：</span></h4>
<ul>
<li>简单介绍SVM（详细原理）：从分类平面，到求两类间的最大间隔，到转化为求间隔分之一，等优化问题，然后就是优化问题的解决办法，首先是用拉格拉日乘子把约束优化转化为无约束优化，对各个变量求导令其为零，得到的式子带入拉格朗日式子从而转化为对偶问题，
最后再利用SMO（序列最小优化）来解决这个对偶问题。<strong>svm里面的超参数c有啥用：软间隔SVM去权衡优化目标和少量分错样本的目标。</strong></li>
<li>SVM的推导，解释原问题和对偶问题，<strong>SVM原问题和对偶问题的关系</strong>，<strong>KKT限制条件</strong>，<strong>KKT条件用哪些</strong>，完整描述；软间隔问题，解释支持向量、核函数（哪个地方引入、画图解释高维映射，高斯核可以升到多少维，如何选择核函数），引入拉格朗日的优化方法的原因，最大的特点，损失函数解释
<ul>
<li><strong>KKT限制</strong>：主问题可行、对偶问题可行、主变量最优、<strong>互补松弛</strong></li>
</ul></li>
<li><strong>对偶问题：</strong>因为原问题是凸二次规划问题，转换为对偶问题更加高效。为什么求解对偶问题更加高效？因为只用求解alpha系数，而alpha系数只有支持向量才非0，其他全部为0.alpha系数有多少个？样本点的个数</li>
</ul>
<h4><span id="2-svm与lr最大区别lr和svm对于outlier的敏感程度分析逻辑回归与svm的区别">2、SVM与LR最大区别，LR和SVM对于outlier的敏感程度分析，逻辑回归与SVM的区别？</span></h4>
<h4><span id="3-svm如何解决多分类问题-可以做回归吗怎么做">3、SVM如何解决多分类问题、可以做回归吗，怎么做？</span></h4>
<h4><span id="4-机器学习有很多关于核函数的说法核函数的定义和作用是什么">4、机器学习有很多关于核函数的说法，核函数的定义和作用是什么？</span></h4>
<p>https://www.zhihu.com/question/24627666</p>
<h4><span id="5-linear-svm-和-lr有什么异同">5、Linear SVM 和 LR
有什么异同？</span></h4>
<h5><span id="svm和lr相同点">SVM和LR相同点：</span></h5>
<ul>
<li>SVM和LR都属于机器学习的监督学习中的<strong>判别式模型</strong>（判别式模型对<span class="math inline">\(p(y|x)\)</span>进行建模或直接基于x预测y，生成模型：<span class="math inline">\(p(x|y)\)</span>和<span class="math inline">\(p(y)\)</span>进行建模,预测后验概率）。</li>
<li>SVM和LR都是线性二分类模型，<strong>分类边界为一个超平面</strong>。</li>
<li>线性SVM和对数几率回归都可以基于表示定理和<strong>核技巧处理非线性可分问题</strong>。</li>
<li><strong>SVM的基本型和对数几率函数都属于参数模型。SVM的对偶性和核化对数几率回归都属于非参数模型</strong>。</li>
<li>SVM和LR优化目标都表示成：经验风险+结构风险（正则项）的形式；均是0，1损失的替代函数。风险结构都是L2正则化。</li>
<li><strong>SVM和LR都是凸优化问题，都能收敛到全局最优解。</strong></li>
<li>SVM和对数几率函数的优化目标相似，性能相当。</li>
<li><strong>SVM多分类：多分类SVM；LR多分类：Softmax回归。</strong></li>
</ul>
<h5><span id="svm和lr的区别"><strong><font color="red">
SVM和LR的区别：</font></strong></span></h5>
<table>
<colgroup>
<col style="width: 11%">
<col style="width: 44%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>SVM</th>
<th>LR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>思想</strong></td>
<td><strong>SVM
想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面</strong>。</td>
<td><strong>逻辑回归</strong>是使用线性回归模型的预测值逼近分类任务真实标记的对数几率。</td>
</tr>
<tr class="even">
<td><strong>输出</strong></td>
<td><strong>非概率方法</strong>；</td>
<td><strong>概率方法</strong>；需要对<span class="math inline">\(p(y|x)\)</span>进行假设，具有概率意义。</td>
</tr>
<tr class="odd">
<td><strong>经验损失函数</strong></td>
<td><strong>合页损失函数</strong>；有一段平的零区域、使得SVM的对偶性有稀疏性。</td>
<td><strong>交叉熵损失函数</strong></td>
</tr>
<tr class="even">
<td><strong>训练样本</strong></td>
<td>支持向量（少数样本），SVM的参数和假设函数只和支持向量有关。</td>
<td>全样本</td>
</tr>
<tr class="odd">
<td><strong>优化方法</strong></td>
<td>次梯度下降和坐标梯度下降 【<strong>SMO算法</strong>】</td>
<td><strong>梯度下降</strong></td>
</tr>
<tr class="even">
<td>多分类</td>
<td><strong>多分类SVM</strong></td>
<td><strong>Softmax回归</strong></td>
</tr>
<tr class="odd">
<td><strong>敏感程度</strong></td>
<td>SVM考虑分类边界线附近的样本（决定分类超平面的样本）。在支持向量外添加或减少任何样本点对分类决策面没有任何影响；</td>
<td>LR受所有数据点的影响。直接依赖数据分布，每个样本点都会影响决策面的结果。如果训练数据不同类别严重不平衡。</td>
</tr>
</tbody>
</table>
<p>https://www.zhihu.com/question/26768865</p>
<h4><span id="6-支持向量机svm是否适合大规模数据速度">6、支持向量机(SVM)是否适合大规模数据？【速度】</span></h4>
<p>https://www.zhihu.com/question/19591450</p>
<h4><span id="7-svm和逻辑斯特回归对同一样本a进行训练如果某类中增加一些数据点那么原来的决策边界分别会怎么变化">7、SVM和逻辑斯特回归对同一样本A进行训练，如果某类中增加一些数据点，那么原来的决策边界分别会怎么变化？</span></h4>
<p>https://www.zhihu.com/question/30123068</p>
<h4><span id="8-各种机器学习的应用场景分别是什么例如k近邻贝叶斯决策树svm逻辑斯蒂回归和最大熵模型">8、各种机器学习的应用场景分别是什么？例如，k近邻,贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。</span></h4>
<p>https://www.zhihu.com/question/26726794</p>
<h4><span id="9-svm与感知器的联系和优缺点比较">9、SVM与感知器的联系和优缺点比较</span></h4>
<p><strong>感知机用误分类样本点的几何距离之和</strong>来表示模型的损失函数，用梯度下降算法优化，直至没有误分类点。
<span class="math display">\[
L(w, b)=-\sum_{x^{(i)} \in M} y^{(i)}\left(w^{T} x^{(i)}+b\right)
\]</span></p>
<h5><span id="感知机与svm区别"><strong><font color="red">
感知机与SVM区别</font></strong></span></h5>
<p><strong>SVM可以视为对感知器的二阶改进</strong>：第一阶改进是加入了<strong>松弛系数</strong>获得hinge
loss，从而具备了产生大间隔的潜质；第二阶改进是加入了权向量的L2正则化项，从而避免产生无意义的大函数间隔，而是产生大的几何间隔。</p>
<table>
<colgroup>
<col style="width: 7%">
<col style="width: 46%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>感知机</th>
<th>SVM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>思想</td>
<td>分离超平面基于误分类的损失函数 <span class="math inline">\(\min _{w,
b} \frac{1}{n} \sum_{i=1}^n \max \left(0,-y_i\left(w^T
x_i+b\right)\right.\)</span></td>
<td><span class="math inline">\(\min _{w, b} \frac{1}{n} \sum_{i=1}^n
\max \left(0,1-y_i\left(w^T
x_i+b\right)\right)+\alpha\|w\|_2^2\)</span></td>
</tr>
<tr class="even">
<td>超平面</td>
<td>因采用的初值不同而得到不同的超平面</td>
<td>让离划分超平面最近的样本到划分超平面距离尽可能远</td>
</tr>
<tr class="odd">
<td>关键样本</td>
<td>每步的分错样本</td>
<td><strong>支持向量</strong></td>
</tr>
<tr class="even">
<td>非线性问题</td>
<td>无</td>
<td>核化</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>支持向量机</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>支持向量机</tag>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机（4）支持向量回归 &amp; 多分类</title>
    <url>/posts/3MCYRQP/</url>
    <content><![CDATA[<p><strong><font color="red"> SVM
是一个非常优雅的算法，具有完善的数学理论，虽然如今工业界用到的不多，但还是决定花点时间去写篇文章整理一下。</font></strong></p>
<p><strong>本质：SVM
想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</strong>为了对数据中的噪声有一定的容忍能力。<strong>以几何的角度，在丰富的数据理论的基础上，简化了通常的分类和回归问题。</strong></p>
<p><strong>几何意义</strong>：找到一个超平面将特征空间的正负样本分开，最大分隔（对噪音有一定的容忍能力）；</p>
<p><strong>间隔表示</strong>：划分超平面到属于不同标记的最近样本的距离之和；</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191157912.jpg" alt="【机器学习】支持向量机 SVM（非常详细）" style="zoom: 33%;"></p>
<span id="more"></span>
<h3><span id="一-支持向量回归-svr">一、支持向量回归 SVR</span></h3>
<blockquote>
<p>https://blog.csdn.net/ch18328071580/article/details/94168411</p>
<p><strong>支持向量在隔代之外</strong></p>
</blockquote>
<h4><span id="11-svr与一般线性回归的区别">1.1 SVR与一般线性回归的区别</span></h4>
<table>
<colgroup>
<col style="width: 65%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>SVR</th>
<th>线性回归</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>数据在间隔带内则不计算损失，<strong>当且仅当f(x)与y之间的差距的绝对值大于ϵ才计算损失</strong></td>
<td>只要f(x)与y不相等时，就计算损失</td>
</tr>
<tr class="even">
<td><strong>通过最大化间隔带的宽度与最小化总损失</strong>来优化模型</td>
<td>通过梯度下降之后求均值来优化模型</td>
</tr>
</tbody>
</table>
<p><strong>岭回归：</strong><img src="https://s2.loli.net/2023/04/17/tHg4BJuNZzcX7Yd.png" alt="image-20220401144206172" style="zoom:50%;"></p>
<h5><span id="支持向量回归我们假设fx与y之间最多有一定的偏差大于偏差才计数损失">支持向量回归：我们假设f(x)与y之间最多有一定的偏差，大于偏差才计数损失</span></h5>
<p><span class="math display">\[
\min _{w, b} \frac{1}{2}\|w\|^{2}+C \sum_{i=1}^{m}
l_{\epsilon}\left(f\left(x_{i}\right), y_{i}\right)
\]</span> 其中C为正则化常数, <span class="math inline">\(l_{\epsilon}\)</span> 是图中所示的 <span class="math inline">\(\epsilon\)</span>-不敏感损失 ( <span class="math inline">\(\epsilon\)</span>-insensitive loss)函数: <span class="math display">\[
l_{\epsilon}(\mathrm{z})= \begin{cases}0, &amp; \text { if }|z| \leq
\epsilon \\ |z|-\epsilon, &amp; \text { otherwise }\end{cases}
\]</span> 引入松弛变量 <span class="math inline">\(\xi_{i}\)</span> 和
<span class="math inline">\(\left(\xi_{i}\right)\)</span>, 可将式重写为:
<span class="math display">\[
\begin{array}{ll}
\min _{w, b, \xi_{i}, \xi_{i}} &amp; \frac{1}{2}\|w\|^{2}+C
\sum_{i=1}^{m}\left(\xi_{i}, \widehat{\xi}_{i}\right) \\
\text { s.t. } &amp; f\left(x_{i}\right)-y_{i} \leq \epsilon+\xi_{i} \\
&amp; y_{i}-f\left(x_{i}\right) \leq \epsilon+\widehat{\xi}_{i} \\
&amp; \xi_{i} \geq 0, \hat{\xi}_{i} \geq 0, i=1,2, \ldots m
\end{array}
\]</span> 引入拉格朗日乘子 <span class="math inline">\(\mu_{i}\)</span>,</p>
<p><span class="math inline">\(L(w, b, \alpha, \hat{\alpha}, \xi,
\hat{\xi}, \mu, \hat{\mu})\)</span> <span class="math inline">\(=\frac{1}{2}\|w\|^{2}+C
\sum_{i=1}^{m}\left(\xi_{i}+\widehat{\xi}_{i}\right)-\sum_{i=1}^{m}
\xi_{i} \mu_{i}-\sum_{i=1}^{m} \widehat{\xi}_{i}
\widehat{\mu_{i}}\)</span> <span class="math inline">\(+\sum_{i=1}^{m}
\alpha_{i}\left(f\left(x_{i}\right)-y_{i}-\epsilon-\xi_{i}\right)+\sum_{i=1}^{m}
\widehat{\alpha_{i}}\left(y_{i}-f\left(x_{i}\right)-\epsilon-\widehat{\xi}_{i}\right)\)</span></p>
<p>再令 <span class="math inline">\(L(w, b, a, \hat{a}, \xi, \hat{\xi},
\mu, \mu)\)</span> 对 <span class="math inline">\(w, b, \xi_{i},
\hat{\xi}_{i}\)</span> 的偏导为零可得: <span class="math display">\[
w=\sum_{i=1}^{m}\left(\widehat{\alpha_{i}}-\alpha_{i}\right) x_{i}
\]</span> 上述过程中需满足KKT条件, 即要求: <span class="math display">\[
\left\{\begin{array}{c}
\alpha_{i}\left(f\left(x_{i}\right)-y_{i}-\epsilon-\xi_{i}\right)=0 \\
\widehat{\alpha_{i}}\left(y_{i}-f\left(x_{i}\right)-\epsilon-\widehat{\xi}_{i}\right)=0
\\
\alpha_{i} \widehat{\alpha_{i}}=0, \xi_{i} \widehat{\xi}_{i}=0 \\
\left(C-\alpha_{i}\right) \xi_{i}=0,\left(C-\widehat{\alpha_{i}}\right)
\widehat{\xi}_{i}=0 .
\end{array}\right.
\]</span></p>
<h3><span id="二-多分类-svm">二、多分类 SVM</span></h3>
<h4><span id="21-多分类问题">2.1 多分类问题</span></h4>
<ul>
<li>多分类问题拆解成若干个二分类问题，对于每个二分类训练一个分类器。
<ul>
<li><strong>one vs one 拆解</strong>：K(K-1)/2 个分类器。</li>
<li><strong>one vs Rest 拆解</strong>：K个分类器</li>
</ul></li>
</ul>
<p><img src="https://s2.loli.net/2023/04/17/OJqX539ByWxSDVN.png" alt="image-20220401192909167" style="zoom:50%;"></p>
<h4><span id="22-多分类线性svm">2.2 多分类线性SVM</span></h4>
<ul>
<li><p><strong>层次支持向量机</strong></p></li>
<li><p><strong>回顾二分类</strong></p></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; \min _{\boldsymbol{w}, b} \frac{1}{m} \sum_{i=1}^m \max
\left(1-y_i\left(\boldsymbol{w}^{\top} \boldsymbol{x}_i+b,
0\right)+\frac{\lambda}{2}\|\boldsymbol{w}\|^2\right. \\
= &amp; \min _{\boldsymbol{w}, b} \frac{1}{m} \sum_{i=1}^m \max
\left(1-y_i s\left(\boldsymbol{x}_i\right),
0\right)+\frac{\lambda}{2}\|\boldsymbol{w}\|^2 .
\end{aligned}
\]</span></p>
<ul>
<li><strong>多分类线性SVM</strong></li>
</ul>
<p><span class="math display">\[
\min _{\boldsymbol{W}, \boldsymbol{b}} \frac{1}{m} \sum_{i=1}^m
\sum_{k=1}^K \mathbb{I}\left(k \neq y_i\right) \cdot \max
\left(1-s\left(\boldsymbol{x}_i\right)_{y_i}+s\left(\boldsymbol{x}_i\right)_k,
0\right)+\frac{\lambda}{2}
\sum_{k=1}^K\left\|\boldsymbol{w}_k\right\|^2,
\]</span></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>支持向量机</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>支持向量机</tag>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title>线性模型（1）线性回归</title>
    <url>/posts/3TFM6N7/</url>
    <content><![CDATA[<h2><span id="一-线性回归">一、线性回归</span></h2>
<p><strong>线性回归假设特征和结果满足线性关系。其实线性关系的表达能力非常强大，每个特征对结果的影响强弱可以由前面的参数体现，而且每个特征变量可以首先映射到一个函数，然后再参与线性计算。</strong>这样就可以表达特征与结果之间的非线性关系。</p>
<span id="more"></span>
<p><span class="math display">\[
y=\theta_{0}+\theta_{1} x_{1}+\theta_{2} x_{2}+\cdots+\theta_{n} x_{n}
\]</span></p>
<p>如果令 <span class="math inline">\(x 0=1, y=h \theta(x)\)</span>,
可以将上述模型写成向量形式, 即: <span class="math display">\[
h_\theta(x)=\sum_{i=0}^n \theta_i x_i=\theta^T x
\]</span> 在上述公式中, 假设特征空间与输入空间x相同。准确地讲,
模型表达式要建立的是特征空间与结果之间的关系。 在一些应用场合中,
需要将输入空间映射到特征空间中, 然后建模, 定义映射函数为 <span class="math inline">\(\Phi(x)\)</span>, 因此我们可以把公式写
成更通用的表达公式: <span class="math display">\[
h_\theta(x)=\theta^T \Phi(x)
\]</span> 特征映射相关技术，包括特征哈希、特征学习、Kernel等。</p>
<h3><span id="11-目标函数-损失函数">1.1 目标函数 【损失函数】</span></h3>
<p><strong>损失函数</strong>用的是 <span class="math inline">\(x(i)\)</span> 的预测值 <span class="math inline">\(h \theta(x(i))\)</span> 与真实值 <span class="math inline">\(y(i)\)</span> 之差的平方和,
这时我们需要映入一个函数来衡量 <span class="math inline">\(h
\theta(x)\)</span> 表示 真实值y好坏的程度，该函数称为损失函数（loss
function，也称为错误函数）。数学表示如下: <span class="math display">\[
\begin{gathered}
J(\theta)=\frac{1}{2}
\sum_{i=1}^n\left(\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)\right)^2
\\
\min _\theta J(\theta)
\end{gathered}
\]</span>
一般地，机器学习中不同的模型会有相应的目标函数。而回归模型（尤其是线性回归类）的目标函数通常用平方损失函数来作为优化的目标函数（即真实值与预测值之差的平方和）。<strong>为什么要选用误差平方和作为目标函数呢？答案可以从概率论中的中心极限定理、高斯分布、最大似然估计等知识中找到。</strong></p>
<p>回归模型（尤其是线性回归类）的目标函数通常用平方损失函数来作为优化的目标函数（即真实值与预测值之差的平方和）。为什么要选用<strong>误差平方和作为目标函数呢？</strong></p>
<h3><span id="12-误差平方和平方损失函数">1.2 误差平方和【平方损失函数】</span></h3>
<p><strong>中心极限定理:</strong>
研究【独立随机变量和】的极限分布为【高斯分布】的问题。</p>
<p><strong>高斯分布</strong>：假设给定一个输入样例 <span class="math inline">\(x(i)\)</span> 根据公式得到<strong>预测值 <span class="math inline">\(\theta T x(i)\)</span> 与真实值 <span class="math inline">\(y(i)\)</span> 之间存在误差</strong>, 即为 <span class="math inline">\(\varepsilon(i)\)</span> 。那么,
它们之间的关系表示如下: <span class="math display">\[
y^{(i)}=\theta^T x^{(i)}+\varepsilon^{(i)}
\]</span> AndrewNg 的课程中第一节线性回归的例子中,
根据训练数据建立房屋的面积 <span class="math inline">\(x\)</span>
与房屋的售价 <span class="math inline">\(y\)</span> 之间的函数表达。
它的数据集把房屋面积作为最为主要的变量。除此之外我们还知道房屋所在的地段（地铁、学区、城区、郊区）,
周边交通状况，当地房价、楼层、采光、绿化面积等等诸多因素会影响房价。</p>
<p><font color="red">实际上,
因数据收集问题可能拿不到所有影响房屋售价的变量,
可以假设多个因素变量相互独立, 根据中心极限定 理,
认为变量之和服从高斯分布。</font>那么 <span class="math inline">\(x\)</span> 和 <span class="math inline">\(\mathrm{y}\)</span> 的条件概率可表示为: <span class="math display">\[
p\left(y^{(i)} \mid x^{(i)} ; \theta\right)=\frac{1}{\sqrt{2 \pi}
\sigma} \exp \left(-\frac{\left(y^{(i)}-\theta^T x^{(i)}\right)^2}{2
\sigma^2}\right)
\]</span>
<strong>极大似然估计与损失函数极小化等价</strong>:根据上述公式估计得到一条样本的结果概率，模型的最终目标是希望在全部
样本上预测最准, 也就是概率积最大,
这个概率积就是似然函数。优化的目标函数即为似然函数, 表示如下: <span class="math display">\[
\max _\theta L(\theta)=\prod_{i=1}^m \frac{1}{\sqrt{2 \pi} \sigma} \exp
\left(-\frac{\left(y^{(i)}-\theta^T x^{(i)}\right)^2}{2 \sigma^2}\right)
\]</span> 对 <span class="math inline">\(L(x)\)</span> 取对数,
可得对数似然函数： <span class="math display">\[
\max _\theta l(\theta)=-m \log \sqrt{2 \pi} \sigma-\frac{1}{2 \sigma^2}
\sum_{i=1}^m\left(y^{(i)}-\theta^T x^{(i)}\right)^2
\]</span> 由于 <span class="math inline">\(n, \sigma\)</span>
都为常数，因此上式等价于: <span class="math display">\[
\min _\theta \frac{1}{2} \sum_{i=1}^m\left(y^{(i)}-\theta^T
x^{(i)}\right)^2
\]</span></p>
<p>我们可以发现，经过: <strong>中心极限定理 + 高斯分布 +
最大似然估计</strong>
推导出来的待优化的目标函数与<strong>平方损失函数</strong>是等价的。因此可以得出结论：<strong>线性回归误差平方损失极小化与极大似然估计等价</strong>。其实在概率模型中，目标函数的原函数（或对偶函数）极小化（或极大化）与极大似然估计等价，这是一个带有普遍性的结论。比如在<strong>最大熵</strong>模型中，有对偶函数极大化与极大似然估计等价的结论。</p>
<h3><span id="13-参数估计">1.3 参数估计</span></h3>
<h4><span id="131-最小二乘法">1.3.1 最小二乘法</span></h4>
<p>损失函数定义为 <span class="math inline">\(J(\theta)=\frac{1}{2}(\mathbf{X}
\theta-\mathbf{Y})^T(\mathbf{X} \theta-\mathbf{Y})\)</span>, 其中 <span class="math inline">\(\mathbf{Y}\)</span> 是样本的输出向量, 维度为 <span class="math inline">\(m \times 1 。 \frac{1}{2}\)</span> 在这主要是
为了求导后系数为 1 , 方便计算。</p>
<p>根据最小二乘法的原理, 我们要对这个损失函数对 <span class="math inline">\(\theta\)</span> 向量求导取0。结果如下式: <span class="math display">\[
\frac{\partial}{\partial \theta} J(\theta)=\mathbf{X}^T(\mathbf{X}
\theta-\mathbf{Y})=0
\]</span> 对上述求导等式整理后可得： <span class="math display">\[
\theta=\left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{Y}
\]</span> <font color="red">
最小二乘法的几何意义是高维空间中的一个向量在低维子空间的投影。</font></p>
<h4><span id="132-梯度下降法">1.3.2 梯度下降法</span></h4>
<p>看来我们这个算法会在很大程度上被初始点的选择影响而陷入局部最小点。将梯度下降法应用到线性回归有三种方式：<strong>批处理梯度下降法、随机梯度下降法</strong>。
<span class="math display">\[
\begin{gathered}\frac{\partial}{\partial \theta_j}
J(\theta)=\frac{\partial}{\partial \theta_j}
\frac{1}{2}\left(h_\theta(x)-y\right)^2 \\ =2 \cdot
\frac{1}{2}\left(h_\theta(x)-y\right) \frac{\partial}{\partial
\theta_j}\left(h_\theta(x)-y\right) \\ =\left(h_\theta(x)-y\right)
x_j\end{gathered}
\]</span></p>
<ul>
<li><strong>批量梯度下降法（BGD）</strong></li>
</ul>
<p><strong>参数θ的值每更新一次都要遍历样本集中的所有的样本</strong>，得到新的θj，看是否满足阈值要求，若满足，则迭代结束，根据此值就可以得到；否则继续迭代。【易受极小值影响】</p>
<ul>
<li><h5><span id="随机梯度下降算法sgd单样本增量梯度下降">随机梯度下降算法（SGD）【单样本增量梯度下降】</span></h5></li>
</ul>
<p>每次更新只用到一个训练样本，若根据当前严格不能进行迭代得到一个，此时会得到一个，有新样本进来之后，在此基础上继续迭代，又得到一组新的和，以此类推。</p>
<table>
<colgroup>
<col style="width: 11%">
<col style="width: 44%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>线性回归</th>
<th>逻辑回归</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>思想</td>
<td><strong>线性回归假设特征和结果满足线性关系</strong>；每个特征的强弱可以由参数体现。高斯分布</td>
<td><strong>逻辑回归</strong>是一个假设样本服从<strong>伯努利分布</strong>，利用极大似然估计和梯度下降求解的二分类模型，在分类、CTR预估领域有着广泛的应用。</td>
</tr>
<tr class="even">
<td>应用场景</td>
<td>回归问题</td>
<td>分类问题，【非线性问题】</td>
</tr>
<tr class="odd">
<td>目标函数【原因】</td>
<td><span class="math inline">\(J(\theta)=\frac{1}{2}
\sum_{i=1}^n\left(\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)\right)^2\)</span>
【<strong>平方损失函数</strong>】</td>
<td><span class="math inline">\(J(\theta)=-\frac{1}{m}
\sum_{i=1}^n\left(y^{(i)} \log
h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log
\left(1-h_\theta\left(x^{(i)}\right)\right)\right)\)</span>【<strong>交叉熵损失函数</strong>】</td>
</tr>
<tr class="even">
<td>参数估计</td>
<td><strong>最小二乘法</strong>、梯度下降</td>
<td><strong>梯度下降</strong>、牛顿法</td>
</tr>
<tr class="odd">
<td>并行化</td>
<td>无</td>
<td>对把目标函数<strong>梯度计算</strong>的并行</td>
</tr>
<tr class="even">
<td>样本分布</td>
<td>高斯分布</td>
<td>伯努利分布</td>
</tr>
<tr class="odd">
<td>优势</td>
<td></td>
<td>对数几率回归：无假设分布？得到概率、易求解；线上算法</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>线性模型</category>
      </categories>
      <tags>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习（8）【Nan】CRF</title>
    <url>/posts/1799EFH/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>概率图模型</category>
      </categories>
  </entry>
  <entry>
    <title>线性模型（2）逻辑回归</title>
    <url>/posts/1J1QH0W/</url>
    <content><![CDATA[<p><strong>Logistic Regression</strong>
虽然被称为回归，但其实际上是分类模型，并常用于二分类。Logistic
Regression 因其简单、可并行化、可解释强深受工业界喜爱。<strong>Logistic
回归的本质是：假设数据服从这个Logistic分布，然后使用极大似然估计做参数的估计。</strong></p>
<p><strong>逻辑回归的思路</strong>是，先拟合决策边界(不局限于线性，还可以是多项式)，再建立这个边界与分类的概率联系，从而得到了二分类情况下的概率。</p>
<span id="more"></span>
<p><img src="https://pica.zhimg.com/v2-35393b75f51c81bb3c09774e76a7d91c_1440w.jpg?source=172ae18b" alt="【机器学习】逻辑回归（非常详细）" style="zoom:50%;"></p>
<h2><span id="一-逻辑回归深度学习的组成单元">一、逻辑回归
【深度学习的组成单元】</span></h2>
<h3><span id="11-logistic-分布位置参数-形状参数">1.1 Logistic 分布
[位置参数、形状参数]</span></h3>
<p><strong>分布函数：</strong>
【<strong>Softmax</strong>函数、对数几率函数】 <span class="math display">\[
F(x)=P(X \leq x)=\frac{1}{1+e^{-(x-\mu) / \gamma}}
\]</span></p>
<p><strong>密度函数：</strong> <span class="math display">\[
f(x)=F^{\prime}(X \leq x)=\frac{e^{-(x-\mu) /
\gamma}}{\gamma\left(1+e^{-(x-\mu) / \gamma}\right)^{2}}
\]</span></p>
<p><img src="https://pic2.zhimg.com/80/v2-b15289fd1162a807e11949e5396c7989_1440w.jpg"></p>
<p>其中, <span class="math inline">\(\mu\)</span> 表示位置参数, <span class="math inline">\(\gamma&gt;0\)</span> 为形状参数。</p>
<p><font color="red"> Logistic
分布是由其位置和尺度参数定义的连续分布。Logistic
分布的形状与正态分布的形状相似, 但是 Logistic 分布的尾部更长,
所以我们可以使用 Logistic
分布来建模比正态分布具有更长尾部和更高波峰的数据分布。</font>在深度学习中常用到的
Sigmoid 函数就是 Logistic 的分布函数在 <span class="math inline">\(\mu=0, \gamma=1\)</span> 的特殊形式。</p>
<p>决策边界可以表示为 <span class="math inline">\(w_1 x_1+w_2
x_2+b=0\)</span> ，假设某个样本点 <span class="math inline">\(h_w(x)=w_1
x_1+w_2 x_2+b&gt;0\)</span> 那么可以判断它的 类别为 1 ,
这个过程其实是感知机。</p>
<h3><span id="12-logistic-回归">1.2 Logistic 回归</span></h3>
<p>Logistic 回归还需要加一层, 它要找到分类概率 <span class="math inline">\(P(Y=1)\)</span> 与输入向量 <span class="math inline">\(x\)</span> 的直接关系, 然后通过比较概率值来判断类
别。考虑到 <span class="math inline">\(w^T x+b\)</span> 取值是连续的,
因此它不能拟合离散变量。可以考虑用它来拟合条件概率 <span class="math inline">\(p(Y=1 \mid x)\)</span>, 因
为概率的取值也是连续的。</p>
<p>最理想的是单位阶跃函数：</p>
<p><span class="math display">\[
p(y=1 \mid x)=\left\{\begin{array}{ll}0, &amp; z&lt;0 \\ 0.5, &amp; z=0
\\ 1, &amp; z&gt;0\end{array}, \quad z=w^{T} x+b\right.
\]</span></p>
<p>但是这个阶跃函数不可微, 对数几率函数是一个常用的替代函数： <span class="math display">\[
y=\frac{1}{1+e^{-\left(w^T x+b\right)}}
\]</span></p>
<p><span class="math display">\[
\ln \frac{y}{1-y}=w^{T} x+b
\]</span></p>
<p>我们将 <span class="math inline">\(\mathrm{y}\)</span> 视为 <span class="math inline">\(\mathrm{x}\)</span> 为正例的概率, 则 1- <span class="math inline">\(\mathrm{y}\)</span> 为 <span class="math inline">\(\mathrm{x}\)</span>
为其反例的概率。两者的比值称为几率 (odds), 指该事件发生与不
发生的概率比值, 若事件发生的概率为 <span class="math inline">\(\mathrm{p}\)</span> 。则对数几率: <span class="math display">\[
\ln (o d d s)=\ln \frac{y}{1-y}
\]</span> 将 <span class="math inline">\(\mathrm{y}\)</span>
视为类后验概率估计, 重写公式有: <span class="math display">\[
\begin{aligned}
&amp; w^T x+b=\ln \frac{P(Y=1 \mid x)}{1-P(Y=1 \mid x)} \\
&amp; P(Y=1 \mid x)=\frac{1}{1+e^{-\left(w^T x+b\right)}}
\end{aligned}
\]</span></p>
<p>也就是说，<strong>输出 Y=1 的对数几率是由输入 x
的线性函数表示的模型</strong>，这就是<strong>逻辑回归模型</strong>。当
<span class="math inline">\(w^T x+b\)</span>的值越接近正无穷，<span class="math inline">\(P(Y=1 \mid x)\)</span> 概率值也就越接近
1。因此<font color="red"><strong>逻辑回归的思路是，先拟合决策边界(不局限于线性，还可以是多项式)，再建立这个边界与分类的概率联系，从而得到了二分类情况下的概率。</strong> </font></p>
<p>在这我们思考个问题，我们使用<strong>对数几率（sigmod）的意义在哪？</strong>通过上述推导我们可以看到
<strong>Logistic
回归实际上是使用线性回归模型的预测值逼近分类任务真实标记的对数几率，其优点有：</strong>【无假设分布？得到概率、易求解】</p>
<p><font color="red"> Sigmoid 函数到底起了什么作？</font></p>
<ul>
<li><p><strong>逻辑回归是在线性回归的基础上加了一个 Sigmoid
函数（非线性）映射，使得逻辑回归称为了一个优秀的分类算法。</strong>本质上来说，两者都属于广义线性模型，但他们两个要解决的问题不一样，逻辑回归解决的是分类问题，输出的是离散值，线性回归解决的是回归问题，输出的连续值。</p></li>
<li><p>线性回归是在实数域范围内进行预测，而<strong>分类范围则需要在
[0,1]</strong>，逻辑回归减少了预测范围；<strong>线性回归在实数域上敏感度一致</strong>，而<strong>逻辑回归在
0 附近敏感</strong>，在远离 0
点位置不敏感，这个的好处就是模型更加关注分类边界，可以增加模型的鲁棒性。</p></li>
<li><p><font color="red"><strong>无需实现假设数据分布</strong></font>：直接对<strong>分类的概率</strong>建模，从而避免了假设分布不准确带来的问题（区别于生成式模型）；</p></li>
<li><p>不仅可预测出类别，还能得到该<font color="red">
<strong>预测的概率</strong></font>，这对一些利用概率辅助决策的任务很有用；</p></li>
<li><p><font color="red"><strong>对数几率函数是任意阶可导的凸函数</strong></font>，有许多数值优化算法都可以求出最优解。</p></li>
</ul>
<h3><span id="13-代价函数">1.3 代价函数</span></h3>
<p><strong>逻辑回归模型的数学形式确定后，剩下就是如何去求解模型中的参数。在统计学中，常常使用极大似然估计法来求解，即找到一组参数，使得在这组参数下，我们的数据的似然度（概率）最大。</strong>设：
<span class="math display">\[
\begin{aligned}
&amp; P(Y=1 \mid x)=p(x) \\
&amp; P(Y=0 \mid x)=1-p(x)
\end{aligned}
\]</span> 似然函数： <span class="math display">\[
L(w)=\prod\left[p\left(x_i\right)\right]^{y_i}\left[1-p\left(x_i\right)\right]^{1-y_i}
\]</span> 为了更方便求解，我们对等式两边同取对数，写成对数似然函数：
<span class="math display">\[
\begin{aligned}
L(w) &amp; =\sum\left[y_i \ln p\left(x_i\right)+\left(1-y_i\right) \ln
\left(1-p\left(x_i\right)\right)\right] \\
&amp; =\sum\left[y_i \ln
\frac{p\left(x_i\right)}{1-p\left(x_i\right)}+\ln
\left(1-p\left(x_i\right)\right)\right] \\
&amp; =\sum\left[y_i\left(w \cdot x_i\right)-\ln \left(1+e^{w \cdot
x_i}\right)\right]
\end{aligned}
\]</span> <strong><font color="red">
逻辑回归模型中，我们最大化似然函数和最小化损失函数实际上是等价的。</font></strong>我们对预测结果的概率表示取似然函数，取似然函数就是将模型对样本的概率预测值累乘起来。得到如下的似然函数由于该式比较麻烦涉及连乘法，所以我们对其去对数操作得到<strong>对数似然函数</strong>。</p>
<p><span class="math display">\[
l(\theta)=\log L(\theta)=\sum_{i=1}^m\left(y^{(i)} \log
h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log
\left(1-h_\theta\left(x^{(i)}\right)\right)\right)
\]</span></p>
<p>上述利用的是最大似然估计原理：<strong>极大似然估计就是就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者说什么样的参数才能使我们观测到目前这组数据的概率最大</strong>。</p>
<p>当似然函数求得最大值时，模型能够最大可能的满足当前的样本，求最大值使用梯度向上法，我们可以对似然函数加个负号，通过求等价问题的最小值来求原问题的最大值，这样我们就可以使用极大似然估计法。</p>
<p>令: <span class="math display">\[
J(\theta)=-\frac{1}{m} l(\theta)
\]</span> 这样我们就能得到损失函数的最终形式 <span class="math display">\[
J(\theta)=-\frac{1}{m} \sum_{i=1}^n\left(y^{(i)} \log
h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log
\left(1-h_\theta\left(x^{(i)}\right)\right)\right)
\]</span> 化简得： <span class="math display">\[
=-\frac{1}{m} \sum_{i=1}^m\left[y^{(i)} \theta^T x^{(i)}-\log
\left(1+e^{\theta^T x^{(i)}}\right)\right]
\]</span></p>
<h3><span id="14-求解-梯度下降-和-牛顿法">1.4 求解【 梯度下降 和 牛顿法 】</span></h3>
<p>求解逻辑回归的方法有非常多，我们这里主要聊下<strong>梯度下降</strong>和<strong>牛顿法</strong>。优化的主要目标是找到一个方向，参数朝这个方向移动之后使得损失函数的值能够减小，这个方向往往由一阶偏导或者二阶偏导各种组合求得。<strong>逻辑回归的损失函数</strong>是：</p>
<p><span class="math display">\[
J(w)=-\frac{1}{n}\sum_{i=1}^n\left(y_i \ln
p\left(x_i\right)+\left(1-y_i\right) \ln
\left(1-p\left(x_i\right)\right)\right)
\]</span></p>
<ul>
<li><strong>随机梯度下降</strong></li>
</ul>
<p>梯度下降是通过 <strong>J(w) 对 w
的一阶导数来找下降方向</strong>，并且以迭代的方式来更新参数，更新方式为:
<span class="math display">\[
\begin{gathered}g_i=\frac{\partial J(w)}{\partial
w_i}=\left(p\left(x_i\right)-y_i\right) x_i \\ w_i^{k+1}=w_i^k-\alpha
g_i\end{gathered}
\]</span></p>
<p>其中 k
为迭代次数。每次更新参数后，可以通过比较梯度下降小于阈值或者到达最大迭代次数来停止迭代。</p>
<p>求导：</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \frac{\partial}{\partial \theta_j}
J(\theta)=\frac{\partial}{\partial \theta_j}\left(\frac{1}{m}
\sum_{i=1}^m\left[\log \left(1+e^{\theta^T x^{(i)}}\right)-y^{(i)}
\theta^T x^{(i)}\right]\right) \\
&amp; =\frac{1}{m} \sum_{i=1}^m\left[\frac{\partial}{\partial \theta_j}
\log \left(1+e^{\theta^T x^{(i)}}\right)-\frac{\partial}{\partial
\theta_j}\left(y^{(i)} \theta^T x^{(i)}\right)\right] \\
&amp; =\frac{1}{m} \sum_{i=1}^m\left(\frac{x_j^{(i)} e^{\theta^T
x^{(i)}}}{1+e^{\theta^T x^{(i)}}}-y^{(i)} x_j^{(i)}\right) \\
&amp; =\frac{1}{m}
\sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right) x_j^{(i)}
\\
&amp;
\end{aligned}
\]</span></p>
<p>这就是交叉熵对参数的导数：</p>
<p><span class="math display">\[
\frac{\partial}{\partial \theta_j} J(\theta)=\frac{1}{m}
\sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right) x_j^{(i)}
\]</span></p>
<ul>
<li><strong>牛顿法</strong></li>
</ul>
<p><strong>牛顿法的基本思路是, 在现有极小点估计值的附近对 <span class="math inline">\(f(x)\)</span> 做二阶泰勒展开,
进而找到极小点的下一个估计值</strong>。假设 <span class="math inline">\(w^k\)</span> 为当前的极小值估计值，那么有: <span class="math display">\[
\varphi(w)=J\left(w^k\right)+J^{\prime}\left(w^k\right)\left(w-w^k\right)+\frac{1}{2}
J^{\prime \prime}\left(w^k\right)\left(w-w^k\right)^2
\]</span> 然后令 <span class="math inline">\(\varphi^{\prime}(w)=0\)</span>, 得到了 <span class="math inline">\(w^{k+1}=w^k-\frac{J^{\prime}\left(w^k\right)}{J^{\prime
\prime}\left(w^k\right)}\)</span> 。因此有迭代更新式: <span class="math display">\[
w^{k+1}=w^k-\frac{J^{\prime}\left(w^k\right)}{J^{\prime
\prime}\left(w^k\right)}=w^k-H_k^{-1} \cdot g_k
\]</span> 其中 <span class="math inline">\(H_k^{-1}\)</span> 为海森矩阵:
<span class="math display">\[
H_{m n}=\frac{\partial^2 J(w)}{\partial w_m \partial
w_n}=h_w\left(x^{(i)}\right)\left(1-p_w\left(x^{(i)}\right)\right)
x_m^{(i)} x_n^{(i)}
\]</span> 此外, 这个方法需要目标函数是二阶连续可微的, 本文中的 <span class="math inline">\(J(w)\)</span> 是符合要求的。</p>
<ul>
<li><strong>拟牛顿法</strong></li>
</ul>
<p>为了避免存储海塞矩阵的逆矩阵，通过拟合的方式找到一个近似的海塞矩阵，拟牛顿法的可行性在于严格的近似方法，只要不是差的特别远就能起到相应下调效果。</p>
<blockquote>
<p>DFP、BFGS、L-BFGS:</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304200244353.png" alt="image-20220509171547743" style="zoom:50%;"></p>
</blockquote>
<h4><span id="lr-l1-的梯度下降方式">LR-L1 的梯度下降方式？</span></h4>
<p>OWL-QN：用L-BFCS求解L1正则化的LR</p>
<h3><span id="15-并行化对目标函数梯度计算的并行化"><font color="red"> 1.5 并行化
[对目标函数梯度计算的并行化 ？？？]</font></span></h3>
<blockquote>
<p><strong>面试题解答8：逻辑斯蒂回归的并行化计算方法 - 舟晓南的文章 -
知乎</strong> https://zhuanlan.zhihu.com/p/447482293</p>
</blockquote>
<p>从逻辑回归的求解方法中我们可以看到，无论是随机梯度下降还是牛顿法，或者是没有提到的拟牛顿法，都是需要计算梯度的，因此<strong>逻辑回归的并行化最主要的就是对目标函数梯度计算的并行化</strong>。</p>
<p>我们看到目标函数的梯度向量计算中只需要进行向量间的点乘和相加，可以很容易将每个迭代过程拆分成相互独立的计算步骤，由不同的节点进行独立计算，然后归并计算结果。</p>
<ul>
<li>梯度下降是通过 <strong>J(w) 对 w
的一阶导数来找下降方向</strong>，并且以迭代的方式来更新参数，更新方式为:</li>
</ul>
<p><span class="math display">\[
\begin{gathered}
g_i=\frac{\partial J(w)}{\partial
w_i}=\left(p\left(x_i\right)-y_i\right) x_i \\
w_i^{k+1}=w_i^k-\alpha g_i
\end{gathered}
\]</span> 其中 <span class="math inline">\(\mathrm{k}\)</span>
为迭代次数。每次更新参数后, 可以通过比较 <span class="math inline">\(\left\|J\left(w^{k+1}\right)-J\left(w^k\right)\right\|\)</span>
小于阈值或者到达最大迭代次数来 停止迭代。</p>
<h2><span id="二-模型的对比">二、模型的对比</span></h2>
<h3><span id="21-线性回归">2.1 线性回归</span></h3>
<p><strong>逻辑回归是在线性回归的基础上加了一个 Sigmoid
函数（非线形）映射</strong>，使得逻辑回归称为了一个优秀的分类算法。本质上来说，两者都属于广义线性模型，但他们两个要解决的问题不一样，逻辑回归解决的是<strong>分类问题</strong>，输出的是<strong>离散值</strong>，线性回归解决的是<strong>回归问题</strong>，输出的<strong>连续值</strong>。</p>
<p><strong>我们需要明确 Sigmoid 函数到底起了什么作用？</strong></p>
<ul>
<li>线性回归是在实数域范围内进行预测，而分类范围则需要在
[0,1]，<strong>逻辑回归减少了预测范围</strong>；</li>
<li>线性回归在实数域上敏感度一致，而<strong>逻辑回归在 0
附近敏感</strong>，在远离 0
点位置不敏感，这个的好处就是模型更加关注分类边界，可以增加模型的鲁棒性。</li>
</ul>
<h3><span id="22-最大熵模型">2.2 <strong>最大熵模型</strong></span></h3>
<p>逻辑回归和最大熵模型本质上没有区别，最大熵在解决二分类问题时就是逻辑回归，在解决多分类问题时就是多项逻辑回归。<strong>最大熵原理是概率模型学习的一个准则。其认为在学习概率模型时，熵最大的模型是最好的模型。也可以表述为在满足约束条件的模型集合中选取熵最大的模型。</strong></p>
<h4><span id="最大熵模型的学习推导过程">最大熵模型的学习(推导过程)</span></h4>
<p>最大熵模型推导 - Eccc的文章 - 知乎
https://zhuanlan.zhihu.com/p/47988480</p>
<h3><span id="23-svm">2.3 SVM</span></h3>
<p><strong>相同点：</strong></p>
<ul>
<li><strong>都是分类算法，本质上都是在找最佳分类超平面</strong>；</li>
<li>都是<strong>监督学习算法</strong>；</li>
<li>都是<strong>判别式模型</strong>，判别模型不关心数据是怎么生成的，它只关心数据之间的差别，然后用差别来简单对给定的一个数据进行分类；</li>
<li>都可以增加不同的正则项。</li>
</ul>
<p><strong>不同点：</strong></p>
<ul>
<li>LR 是一个<strong>统计</strong>的方法，SVM
是一个<strong>几何</strong>的方法；</li>
<li>SVM 的处理方法是只考虑 Support
Vectors，也就是<strong>和分类最相关的少数点去学习分类器</strong>。而逻辑回归通过非线性映射减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重；</li>
<li><strong>损失函数</strong>不同：<strong>LR
的损失函数是交叉熵</strong>，<strong>SVM 的损失函数是
HingeLoss</strong>，这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。对
HingeLoss
来说，其零区域对应的正是非支持向量的普通样本，从而所有的普通样本都不参与最终超平面的决定，这是支持向量机最大的优势所在，对训练样本数目的依赖大减少，而且提高了训练效率；</li>
<li><strong>LR 是参数模型，SVM
是非参数模型</strong>，参数模型的前提是假设数据服从某一分布，该分布由一些参数确定（比如正太分布由均值和方差确定），在此基础上构建的模型称为参数模型；非参数模型对于总体的分布不做任何假设，只是知道总体是一个随机变量，其分布是存在的（分布中也可能存在参数），但是无法知道其分布的形式，更不知道分布的相关参数，只有在给定一些样本的条件下，能够依据非参数统计的方法进行推断。所以
LR 受数据分布影响，尤其是样本不均衡时影响很大，需要先做平衡，而 SVM
不直接依赖于分布；</li>
<li>LR 可以产生概率，SVM 不能；</li>
<li>LR 不依赖样本之间的距离，SVM 是基于距离的；</li>
<li>LR
相对来说模型更简单好理解，特别是大规模线性分类时并行计算比较方便。而 SVM
的理解和优化相对来说复杂一些，<strong>SVM
转化为对偶问题后，分类只需要计算与少数几个支持向量的距离</strong>，这个<strong>在进行复杂核函数计算时优势很明显</strong>，能够大大简化模型和计算。</li>
</ul>
<h3><span id="24-gbdt模型">2.4 GBDT模型</span></h3>
<p>先说说LR和GBDT的区别：</p>
<ul>
<li>LR是线性模型，<strong>可解释性强</strong>，<strong>很容易并行化</strong>，但学习能力有限，<strong>需要大量的人工特征工程；</strong></li>
<li>GBDT是非线性模型，具有天然的<strong>特征组合优势</strong>，特征表达能力强，但是树与树之间无法并行训练，而且树模型很容易过拟合；</li>
</ul>
<p>当在高维稀疏特征的场景下，LR的效果一般会比GBDT好。</p>
<h2><span id="三-应用场景">三、应用场景</span></h2>
<ul>
<li>CTR预估/推荐系统的learning to rank/各种分类场景。</li>
<li>某搜索引擎厂的广告CTR预估基线版是LR。</li>
<li>某电商搜索排序/广告CTR预估基线版是LR。</li>
<li>某电商的购物搭配推荐用了大量LR。</li>
<li>某现在一天广告赚1000w+的新闻app排序基线是LR。</li>
</ul>
<h2><span id="四-逻辑回归-qampa">四、逻辑回归 Q&amp;A</span></h2>
<blockquote>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/100763009">【机器学习面试总结】——
LR（逻辑回归）</a></li>
</ul>
</blockquote>
<h4><span id="1-线性回归和逻辑的区别与联系">1、线性回归和逻辑的区别与联系？</span></h4>
<p><strong>逻辑回归是在线性回归的基础上加了一个 Sigmoid
函数（非线形）映射，使得逻辑回归称为了一个优秀的分类算法。</strong>本质上来说，两者都属于广义线性模型，但他们两个要解决的问题不一样，逻辑回归解决的是分类问题，输出的是离散值，线性回归解决的是回归问题，输出的连续值。</p>
<table>
<colgroup>
<col style="width: 11%">
<col style="width: 44%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>线性回归</th>
<th>逻辑回归</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>思想</td>
<td><strong>线性回归假设特征和结果满足线性关系</strong>；每个特征的强弱可以由参数体现。高斯分布</td>
<td><strong>逻辑回归</strong>是一个假设样本服从<strong>伯努利分布</strong>，利用极大似然估计和梯度下降求解的二分类模型，在分类、CTR预估领域有着广泛的应用。</td>
</tr>
<tr class="even">
<td>模型假设</td>
<td><strong><font color="red"> 线性回归假设 <span class="math inline">\(y\)</span> 的残差 <span class="math inline">\(\varepsilon\)</span> 服从正态分布 <span class="math inline">\(N\left(\mu,
\sigma^{2}\right)\)</span></font></strong></td>
<td><strong><font color="red"> 逻辑回归假设 <span class="math inline">\(y\)</span> 服从伯努利分布
(Bernoulli)</font></strong></td>
</tr>
<tr class="odd">
<td>应用场景</td>
<td>回归问题</td>
<td>分类问题，【非线性问题】</td>
</tr>
<tr class="even">
<td>目标函数【原因】</td>
<td><span class="math inline">\(J(\theta)=\frac{1}{2}
\sum_{i=1}^n\left(\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)\right)^2\)</span>
【<strong>平方损失函数</strong>】</td>
<td><span class="math inline">\(J(\theta)=-\frac{1}{m}
\sum_{i=1}^n\left(y^{(i)} \log
h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log
\left(1-h_\theta\left(x^{(i)}\right)\right)\right)\)</span>【<strong>交叉熵损失函数</strong>】</td>
</tr>
<tr class="odd">
<td>参数估计</td>
<td><strong>最小二乘法</strong>、梯度下降</td>
<td><strong>梯度下降</strong>、牛顿法</td>
</tr>
<tr class="even">
<td>并行化</td>
<td>无</td>
<td>对把目标函数<strong>梯度计算</strong>的并行</td>
</tr>
<tr class="odd">
<td>样本分布</td>
<td><strong>高斯分布</strong></td>
<td><strong>伯努利分布</strong></td>
</tr>
<tr class="even">
<td>优势</td>
<td></td>
<td><strong>对数几率</strong>：无假设分布？得到概率、<strong>易求解</strong></td>
</tr>
</tbody>
</table>
<h4><span id="2-线性回归为什么用平方损失函数">2、线性回归为什么用平方损失函数？</span></h4>
<p><strong>中心极限定理 + 高斯分布 + 最大似然估计</strong>
推导出来的待优化的目标函数与<strong>平方损失函数</strong>是等价的。因此可以得出结论：<strong>线性回归误差平方损失极小化与极大似然估计等价</strong>。其实在概率模型中，目标函数的原函数（或对偶函数）极小化（或极大化）与极大似然估计等价，这是一个带有普遍性的结论。比如在最大熵模型中，有对偶函数极大化与极大似然估计等价的结论。</p>
<h4><span id="3-为什么不用平方误差用交叉熵损失w的初始化导数值可能很小梯度消失">3、<strong><font color="red">
为什么不用平方误差，用交叉熵损失【w
的初始化，导数值可能很小：梯度消失】</font></strong></span></h4>
<p>假设目标函数是 <strong>MSE</strong>，即： <span class="math display">\[
\begin{gathered}
L=\frac{(y-\hat{y})^2}{2} \\
\frac{\partial L}{\partial w}=(\hat{y}-y) \sigma^{\prime}(w \cdot x) x
\end{gathered}
\]</span> 这里 Sigmoid 的导数项为: <span class="math display">\[
\sigma^{\prime}(w \cdot x)=w \cdot x(1-w \cdot x)
\]</span> 根据 <strong>w 的初始化，导数值可能很小</strong>（想象一下
Sigmoid
函数在输入较大时的梯度）而导致收敛变慢，而训练途中也可能因为该值过小而提早终止训练（<strong>梯度消失</strong>）。</p>
<p><strong>交叉熵</strong>的梯度如下，当模型输出概率偏离于真实概率时，梯度较大，加快训练速度，当拟合值接近于真实概率时训练速度变缓慢，<strong>没有
MSE 的问题</strong>。 <span class="math display">\[
g^{\prime}=\sum_{i=1}^N x_i\left(y_i-p\left(x_i\right)\right)
\]</span></p>
<ul>
<li>为什么不用平方损失函数？</li>
<li>交叉熵损失函数原理？</li>
</ul>
<h4><span id="4-lr为什么适合离散特征易于迭代-加快计算简化模型和增加泛化能力">4、<strong><font color="red">
LR为什么适合离散特征【易于迭代、加快计算，简化模型和增加泛化能力】</font></strong></span></h4>
<p>我们在使用逻辑回归的时候很少会把数据直接丢给 LR
来训练，我们一般会对特征进行离散化处理，这样做的优势大致有以下几点：</p>
<ol type="1">
<li><strong>离散特征的增加和减少都很容易，易于模型的快速迭代</strong>；</li>
<li><strong>离散后稀疏向量内积乘法运算速度更快</strong>，计算结果也方便存储，容易扩展；</li>
<li>离散后的特征<strong>对异常值更具鲁棒性</strong>，如 age&gt;30 为 1
否则为 0，对于年龄为 200 的也不会对模型造成很大的干扰；</li>
<li>LR
属于广义线性模型，表达能力有限，经过离散化后，<strong>每个变量有单独的权重，这相当于引入了非线性，能够提升模型的表达能力，加大拟合；</strong></li>
<li>离散后特征可以<strong>进行特征交叉</strong>，提升表达能力，由 M+N
个变量编程 M*N 个变量，进一步引入非线形，提升了表达能力；</li>
<li>特征离散后模型更稳定，如用户年龄区间，不会因为用户年龄长了一岁就变化；</li>
<li>特征离散化以后，起到了简化逻辑回归模型的作用，降低了模型过拟合的风险；</li>
</ol>
<p><strong><font color="red">
总的来说，特征离散化以后起到了易于迭代、加快计算，简化模型和增加泛化能力的作用。</font></strong></p>
<h4><span id="5-lr推导伯努利过程极大似然损失函数梯度下降有没有最优解">5、LR推导（伯努利过程，极大似然，损失函数，梯度下降）有没有最优解？</span></h4>
<h4><span id="6-lr可以用来处理非线性问题么">6、LR可以用来处理非线性问题么？</span></h4>
<p>引入kernel：</p>
<p>对特征先进行多项式转换：</p>
<h4><span id="7-lr为什么用sigmoid函数这个函数有什么优点和缺点为什么不用其他函数"><strong><font color="red">
7、LR为什么用sigmoid函数，这个函数有什么优点和缺点？为什么不用其他函数？</font></strong></span></h4>
<p><strong>Sigmoid函数由那个指数族分布，加上二项分布导出来的。损失函数是由最大似然估计求出的。</strong></p>
<blockquote>
<p>逻辑回归认为函数其概率服从伯努利分布,
将其写成指数族分布的形式。因为指数族分布是给定某些统计量
下熵最大的分布，例如伯努利分布就是只有两个取值且给定期望值为 <span class="math inline">\(\mu\)</span> 下的樀最大的分布。 也就是： <span class="math display">\[
  \begin{aligned}
  p(y ; \phi) &amp; =\phi^y(1-\phi)^{1-y} \\
  &amp; =\exp (y \log \phi+(1-y) \log (1-\phi)) \\
  &amp; =\exp \left(\left(\log \left(\frac{\phi}{1-\phi}\right)\right)
y+\log (1-\phi)\right)
  \end{aligned}
  \]</span> 符合: <span class="math inline">\(\quad p(y ; \eta)=b(y)
\exp \left(\eta^T T(y)-\alpha(\eta)\right)\)</span> 其中: <span class="math inline">\(\quad \alpha(\eta)=-\log (1-\phi)\)</span>
能够推导出sigmoid函数的形式。 <span class="math display">\[
  \eta=\log \left(\frac{\phi}{1-\phi}\right)
  \]</span> <span class="math display">\[
  \phi=\frac{e^\eta}{1+e^\eta}
  \]</span></p>
</blockquote>
<p><strong>Sigmoid 函数到底起了什么作用？</strong></p>
<ul>
<li><p><strong>逻辑回归是在线性回归的基础上加了一个 Sigmoid
函数（非线性）映射，使得逻辑回归称为了一个优秀的分类算法。</strong>本质上来说，两者都属于广义线性模型，但他们两个要解决的问题不一样，逻辑回归解决的是分类问题，输出的是离散值，线性回归解决的是回归问题，输出的连续值。</p></li>
<li><p>线性回归是在实数域范围内进行预测，而<strong>分类范围则需要在
[0,1]</strong>，逻辑回归减少了预测范围；<strong>线性回归在实数域上敏感度一致</strong>，而<strong>逻辑回归在
0 附近敏感</strong>，在远离 0
点位置不敏感，这个的好处就是模型更加关注分类边界，可以增加模型的鲁棒性。</p></li>
<li><p><font color="red"><strong>无需实现假设数据分布</strong></font>：直接对<strong>分类的概率</strong>建模，从而避免了假设分布不准确带来的问题（区别于生成式模型）；</p></li>
<li><p>不仅可预测出类别，还能得到该<font color="red">
<strong>预测的概率</strong></font>，这对一些利用概率辅助决策的任务很有用；</p></li>
<li><p><font color="red"><strong>对数几率函数是任意阶可导的凸函数</strong></font>，有许多数值优化算法都可以求出最优解。</p></li>
</ul>
<h4><span id="8-逻辑回归估计参数时的目标函数逻辑回归的值表示概率吗值越大可能性越高但不能说是概率">8、逻辑回归估计参数时的目标函数逻辑回归的值表示概率吗？（值越大可能性越高，但不能说是概率）</span></h4>
<p>https://blog.csdn.net/zhaojc1995/article/details/114462504</p>
<ul>
<li><p><strong><font color="red">
不是概率，概率是可以做加减乘除计算的，但softmax只能比较大小，不能用于计算。</font></strong></p></li>
<li><p>并不完全等同。在多分类中，<a href="https://www.zhihu.com/search?q=softmax&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A%221771152146%22%7D">softmax</a>最终输出的数值，会和<strong>某个类别的样本数有关</strong>。因此它不能直接用作概率，但可以粗略的认为是与概率类似的东西。</p></li>
</ul>
<h4><span id="9-手推逻辑回归目标函数正类是1反类是-1">9、手推逻辑回归目标函数，正类是1，反类是-1</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304200223146.png" alt="image-20220401164913393" style="zoom:50%;"></p>
<h4><span id="10-scikit-learn源码lr的实现">10、scikit-learn源码LR的实现？</span></h4>
<h4><span id="11-为什么lr需要归一化或者取对数为什么lr把特征离散化后效果更好为什么把特征组合之后还能提升">11、为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好，为什么把特征组合之后还能提升？</span></h4>
<ul>
<li><p><strong>为什么LR需要归一化或者取对数?</strong>
符合假设、利于分析、归一化也有利于梯度下降。</p></li>
<li><p>LR 特征离散化</p></li>
</ul>
<h4><span id="12-naivebayessvm和logistic-regression的区别">12、Naive
bayes，SVM和logistic regression的区别？</span></h4>
<h4><span id="13-为什么lr可以用来做ctr预估场景">13、为什么LR可以用来做CTR预估？【场景】</span></h4>
<p><strong>简单应用</strong>
预测用户在未来某个时间段是否会购买某个品类，如果把会购买标记为1，不会购买标记为0，就转换为一个二分类问题。我们用到的特征包括用户在美团的浏览，购买等历史信息，见下表</p>
<figure>
<img src="https://pic1.zhimg.com/v2-1d4dd37a5e63e40fb4c5a25a6067e7dc_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>其中提取的特征的时间跨度为30天，标签为2天。生成的训练数据大约在7000万量级（美团一个月有过行为的用户），我们人工把相似的小品类聚合起来，最后有18个较为典型的品类集合。如果用户在给定的时间内购买某一品类集合，就作为正例。哟了训练数据后，使用Spark版的LR算法对每个品类训练一个二分类模型，迭代次数设为100次的话模型训练需要40分钟左右，平均每个模型2分钟，测试集上的AUC也大多在0.8以上。训练好的模型会保存下来，用于预测在各个品类上的购买概率。预测的结果则会用于推荐等场景。</p>
<p>由于不同品类之间正负例分布不同，有些品类正负例分布很不均衡，我们还尝试了不同的采样方法，最终目标是提高下单率等线上指标。经过一些参数调优，品类偏好特征为推荐和排序带来了超过1%的下单率提升。</p>
<p>此外，由于LR模型的简单高效，易于实现，可以为后续模型优化提供一个不错的baseline，我们在排序等服务中也使用了LR模型。</p>
<h4><span id="14-了解其他的分类模型吗问lr缺点lr怎么推导当时我真没准备好写不出来写lr目标函数目标函数怎么求最优解也不会讲讲lr的梯度下降梯度下降有哪几种逻辑函数是啥">14、了解其他的分类模型吗，问LR缺点，LR怎么推导（当时我真没准备好，写不出来）写LR目标函数，目标函数怎么求最优解（也不会）讲讲LR的梯度下降，梯度下降有哪几种，逻辑函数是啥？</span></h4>
<p>由于该极大似然函数无法直接求解，我们一般通过对该函数进行<strong>梯度下降</strong>来不断逼急最优解。在这个地方其实会有个加分的项，考察你对其他优化方法的了解。因为就梯度下降本身来看的话就有<strong>随机梯度下降</strong>，<strong>批梯度下降</strong>，<strong>small
batch
梯度下降</strong>三种方式，面试官可能会问这三种方式的优劣以及如何选择最合适的梯度下降方式。</p>
<p>（1）<strong>批梯度下降</strong>会获得全局最优解，缺点是在更新每个参数的时候需要遍历所有的数据，计算量会很大，并且会有很多的冗余计算，导致的结果是当数据量大的时候，每个参数的更新都会很慢。
（2）<strong>随机梯度下降</strong>是以高方差频繁更新，优点是使得sgd会跳到新的和潜在更好的局部最优解，缺点是使得收敛到局部最优解的过程更加的复杂。
（3）<strong><font color="red"> 小批量梯度下降结合了sgd和batch
gd的优点，每次更新的时候使用n个样本。减少了参数更新的次数，可以达到更加稳定收敛结果，一般在深度学习当中我们采用这种方法。</font></strong></p>
<table style="width:100%;">
<colgroup>
<col style="width: 11%">
<col style="width: 20%">
<col style="width: 51%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>梯度下降</th>
<th>批梯度下降</th>
<th>随机梯度下降</th>
<th>小批量梯度</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>样本</td>
<td>遍历所有的数据</td>
<td>1个样本</td>
<td>使用n个样本</td>
</tr>
<tr class="even">
<td>解</td>
<td>全局最优解</td>
<td>sgd会跳到新的和潜在更好的局部最优解</td>
<td>局部最优解</td>
</tr>
</tbody>
</table>
<p><strong>其实这里还有一个隐藏的更加深的加分项，看你了不了解诸如Adam，动量法等优化方法。因为上述方法其实还有两个致命的问题。</strong></p>
<h4><span id="学习率">学习率？</span></h4>
<p>（1）<strong>第一个是如何对模型选择合适的学习率</strong>。自始至终保持同样的学习率其实不太合适。因为一开始参数刚刚开始学习的时候，此时的参数和最优解隔的比较远，需要保持一个较大的学习率尽快逼近最优解。但是学习到后面的时候，参数和最优解已经隔的比较近了，你还保持最初的学习率，容易越过最优点，在最优点附近来回振荡，通俗一点说，就很容易学过头了，跑偏了。
（2）<strong>第二个是如何对参数选择合适的学习率</strong>。在实践中，对每个参数都保持的同样的学习率也是很不合理的。有些参数更新频繁，那么学习率可以适当小一点。有些参数更新缓慢，那么学习率就应该大一点。</p>
<h4><span id="15-lr如何做回归预测回归任务"><strong>15、LR
如何做回归预测？【回归任务】</strong>?????</span></h4>
<p>logistic regression是这么假设的：数据服从概率为p的二项分布，并且
logit(p)是特征的线性组合。</p>
<p>二项分布的取值就是两个，0,1，所以如果不修改假设，<strong>直接就把logistic
regression用于连续值的预测肯定是不合理的</strong>，因为没有哪个正常的连续取值的东西是服从二项分布的……</p>
<h4><span id="16-当在高维稀疏特征的场景下lr的效果一般会比gbdt好"><strong><font color="red">
16、当在高维稀疏特征的场景下，LR的效果一般会比GBDT好？</font></strong></span></h4>
<blockquote>
<p>高维稀疏特征 - 黄志超的文章 - 知乎
https://zhuanlan.zhihu.com/p/271055971</p>
<p>LR,gbdt,libfm这三种模型分别适合处理什么类型的特征,为了取得较好效果他们对特征有何要求？
- 凯菜的回答 - 知乎
https://www.zhihu.com/question/35821566/answer/225291663</p>
</blockquote>
<ul>
<li><p><strong>高维稀疏特征</strong>：向量表示了一个样本（或一个数据点）的<a href="https://www.zhihu.com/search?q=特征向量&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22271055971%22%7D">特征向量</a>
，我们可以看到向量中存在着许多0，或者说0的数量&gt;&gt;其他值的数量。</p>
<ul>
<li><strong>产生的原因</strong>：数据特征的缺失；<strong>数据不恰当的处理（过多类别特征的one-hot）</strong></li>
</ul></li>
<li><h5><span id="高维稀疏特征对模型训练带来哪些影响呢">高维稀疏特征对模型训练带来哪些影响呢？</span></h5>
<ul>
<li><strong>LR</strong>：低维的稠密特征映射到了高维空间，低维线性不可分就转到高维空间；LR的目标就是找到一个<a href="https://www.zhihu.com/search?q=超平面&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22271055971%22%7D">超平面</a>对样本是的正负样本位于两侧，<strong>由于这个模型够简单，不会出现gbdt上过拟合的问题。</strong></li>
<li><strong>GBDT</strong>：树模型是以列为单位切分样本集的，当稀疏时，每一列的特征就会存在大量的0，切分的意义不大，且特征过于细时，容易过拟合<strong>（如年龄每一岁占一列特征）</strong></li>
</ul></li>
<li><h5><span id="高维稀疏特征解决方案">高维稀疏特征解决方案？</span></h5>
<ul>
<li><strong>embedding</strong></li>
<li>FM</li>
</ul></li>
</ul>
<h4><span id="17-svm和logistic回归分别在什么情况下使用">17、SVM和logistic回归分别在什么情况下使用？</span></h4>
<p><strong>n是feature的数量 m是样本数；</strong></p>
<p>1、如果n相对于m来说很大（n远大于m，n=10000，m=10-1000），则使用LR算法或者不带核函数的SVM（线性分类）</p>
<p>2、如果n很小，m的数量适中（n=1-1000，m=10-10000）：使用带有核函数的SVM算法</p>
<p>3、如果n很小，m很大（n=1-1000，m=50000+）：增加更多的feature然后使用LR算法或者不带核函数的SVM</p>
<h4><span id="18-什么是广义线性模型"><strong><font color="red"> 18、
什么是广义线性模型？</font></strong></span></h4>
<p><strong>线性回归和逻辑回归都是广义线性模型的一种特殊形式</strong>，介绍广义线性模型的一般求解步骤。
利用广义线性模型推导 出 <strong>多分类的Softmax
Regression</strong>。</p>
<p><strong>线性回归中我们假设：</strong></p>
<p><img src="https://pic2.zhimg.com/v2-7b24efc290bf6503e5ae8f2255c36121_b.png" alt="img" style="zoom: 67%;"></p>
<p><strong>逻辑回归中我们假设：</strong></p>
<p><img src="https://pic1.zhimg.com/v2-e321aeb2cacf2215b1a9e75f5154dcf8_b.png" alt="img" style="zoom:67%;"></p>
<p>其实它们都只是 广义线性模型 (GLMs)
的特例。提前透露：<strong>有了广义线性模型下 我们只需要把
符合指数分布的一般模型 的参数
转换成它对应的广义线性模型参数</strong>，然后按照广义线性模型的求解步骤即可轻松求解问题。</p>
<figure>
<img src="https://pic3.zhimg.com/v2-02c43a6ba09360753ee62c4c0871e2aa_b.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>指数分布族（ The exponential family）</strong></p>
<blockquote>
<p><strong>将拉格朗日乘数法应用于求解最大熵问题等同于求解对应的指数族分布问题。</strong></p>
<p>结合定理1和定理2，<strong>可以看到指数族分布的联合分布的统计量充分完备统计量，再构造其无偏估计则为UMVUE。这也是指数族分布应用广泛的原因。</strong></p>
</blockquote>
<p>首先我们定义一下什么是<strong>指数分布族</strong>, 它有如下形式:
<span class="math display">\[
p(y ; \eta)=b(y) \exp \left(\eta^T T(y)-a(\eta)\right)
\]</span> 简单介绍下其中的参数 (看不懂没关系）</p>
<ul>
<li><span class="math inline">\(\eta\)</span> 是 自然参数 ( natural
parameter)</li>
<li><span class="math inline">\(T(y)\)</span> 是充分统计量 (sufficient
statistic ) (一般情况下 <span class="math inline">\(T(y)=y\)</span>
)</li>
<li><span class="math inline">\(a(\eta)\)</span> 是 log partition
function <span class="math inline">\(\left(e^{-a(\eta)}\right.\)</span>
充当正规化常量的角色, 保证 <span class="math inline">\(\sum p(y ;
\eta)=1\)</span> )</li>
</ul>
<p>也就是所 <span class="math inline">\(\mathrm{T}, \mathrm{a},
\mathrm{b}\)</span> 确定了一种分布, <span class="math inline">\(\eta\)</span> 是 该分布的参数。 <strong>选择合适的
<span class="math inline">\(T, a, b\)</span> 我们可以得到 高斯分布 和
Bernoulli 分布。</strong></p>
<h5><span id="bernoulli分布的指数分布族形式"><strong><font color="red">
Bernoulli分布的指数分布族形式:</font></strong></span></h5>
<p><span class="math display">\[
p(y=1 ; \phi)=\phi ; p(y=0 ; \phi)=1-\phi
\]</span> <span class="math inline">\(=&gt;\)</span> <span class="math display">\[
\begin{aligned}
p(y ; \phi) &amp;=\phi^{y}(1-\phi)^{1-y} \\
&amp;=\exp (y \log \phi+(1-y) \log (1-\phi)) \\
&amp;=\exp \left(\left(\log \left(\frac{\phi}{1-\phi}\right)\right)
y+\log (1-\phi)\right)
\end{aligned}
\]</span> 即: 在如下参数下广义线性模型是 Bernoulli 分布 <span class="math display">\[
\begin{aligned}
\eta=\log (\phi /(1-\phi)) \Rightarrow \phi=1 /\left(1+e^{-\eta}\right)
\\
\\
T(y) &amp;=y \\
a(\eta) &amp;=-\log (1-\phi) \\
&amp;=\log \left(1+e^{\eta}\right) \\
b(y) &amp;=1
\end{aligned}
\]</span> ##### <strong><font color="red"> Gaussian
分布的指数分布族形式:</font></strong></p>
<p>在线性回归中, <span class="math inline">\(\sigma\)</span>
对于模型参数 <span class="math inline">\(\theta\)</span> 的选择没有影响,
为了推导方便我们将其设为 1 : <span class="math display">\[
\begin{aligned}
p(y ; \mu) &amp;=\frac{1}{\sqrt{2 \pi}} \exp
\left(-\frac{1}{2}(y-\mu)^{2}\right) \\
&amp;=\frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{1}{2} y^{2}\right) \cdot
\exp \left(\mu y-\frac{1}{2} \mu^{2}\right)
\end{aligned}
\]</span> 得到 对应的参数: <span class="math display">\[
\begin{aligned}
\eta &amp;=\mu \\
T(y) &amp;=y \\
a(\eta) &amp;=\mu^{2} / 2 \\
&amp;=\eta^{2} / 2 \\
b(y) &amp;=(1 / \sqrt{2 \pi}) \exp \left(-y^{2} / 2\right)
\end{aligned}
\]</span></p>
<h4><span id="19-lr的训练方">19、LR的训练方</span></h4>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><p><strong>逻辑回归：入门到精通</strong>：http://www.tianyancha.com/research/LR_intro.pdf</p></li>
<li><p>美团技术团队《Logistic Regression
模型简介》https://tech.meituan.com/intro_to_logistic_regression.html</p></li>
<li><p>SVM和logistic回归分别在什么情况下使用？https://www.zhihu.com/question/21704547</p></li>
<li><p>逻辑斯蒂回归能否解决非线性分类问题？https://www.zhihu.com/question/29385169</p></li>
<li><p>为什么LR可以用来做CTR预估？https://www.zhihu.com/question/23652394</p></li>
<li><p><strong><font color="red">
评分卡基础—逻辑回归算法理解</font></strong> - 求是汪在路上的文章 - 知乎
https://zhuanlan.zhihu.com/p/111260930</p></li>
<li><p><strong>多分类</strong>：https://www.heywhale.com/mw/project/5ed755db946a0e002cb803f7</p></li>
</ul>
<blockquote>
<ul>
<li>LR推导（伯努利过程，极大似然，损失函数，梯度下降）有没有最优解？</li>
<li>LR可以用来处理非线性问题么？（还是lr啊 只不过是加了核的lr
这里加核是显式地把特征映射到高维
然后再做lr）怎么做？可以像SVM那样么？为什么？</li>
<li>为什么LR需要归一化或者取对数，<strong>为什么LR把特征离散化后效果更好</strong>，<strong>为什么把特征组合之后还能提升</strong>，反正这些基本都是增强了特征的表达能力，或者说更容易线性可分吧</li>
<li>美团技术团队《Logistic Regression
模型简介》https://tech.meituan.com/intro_to_logistic_regression.html</li>
<li><strong>SVM和logistic回归分别在什么情况下使用？</strong>https://www.zhihu.com/question/21704547</li>
<li><strong>逻辑斯蒂回归能否解决非线性分类问题？</strong>https://www.zhihu.com/question/29385169</li>
<li>为什么LR可以用来做CTR预估？https://www.zhihu.com/question/23652394</li>
<li>逻辑回归估计参数时的目标函数
（就是极大似然估计那部分），逻辑回归估计参数时的目标函数
（呵呵，第二次） 逻辑回归估计参数时的目标函数
如果加上一个先验的服从高斯分布的假设，会是什么样（天啦。我不知道，其实就是在后面乘一个东西，取log后就变成加一个东西，实际就变成一个正则项）</li>
<li>逻辑回归估计参数时的目标函数逻辑回归的值表示概率吗？（值越大可能性越高，但不能说是概率）</li>
<li>手推逻辑回归目标函数，正类是1，反类是-1，这里挖了个小坑，一般都是正例是1，反例是0的，他写的时候我就注意到这个坑了，然而写的太快又给忘了，衰，后来他提醒了一下，改了过来，就是极大似然函数的指数不一样，然后说我这里的面试就到这了。</li>
<li>看没看过scikit-learn源码LR的实现？（回头看了一下是调用的liblinear，囧）</li>
<li>为什么LR需要归一化或者取对数，为什么LR把特征离散化后效果更好，为什么把特征组合之后还能提升，反正这些基本都是增强了特征的表达能力，或者说更容易线性可分吧</li>
<li>naive bayes和logistic
regression的区别http://m.blog.csdn.net/blog/muye5/19409615</li>
<li>LR为什么用sigmoid函数。这个函数有什么优点和缺点？为什么不用其他函数？sigmoid函数由那个指数族分布，加上二项分布导出来的。损失函数是由最大似然估计求出的。</li>
<li>了解其他的分类模型吗，问LR缺点，LR怎么推导（当时我真没准备好，写不出来）写LR目标函数，目标函数怎么求最优解（也不会）讲讲LR的梯度下降，梯度下降有哪几种，逻辑函数是啥</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>线性模型</category>
      </categories>
      <tags>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习（14）【Nan】LDA(主题模型)</title>
    <url>/posts/322BXWN/</url>
    <content><![CDATA[<h2><span id="ldalatentdirichlet-allocation-主题模型"></span></h2>
<p><strong>同一个主题，在不同的文章中，他出现的比例(概率)是不同的</strong>，看到这里，读者可能已经发现，文档和主题之间的关系和主题和词汇的关系是多么惊人的类似！</p>
<blockquote>
<p>LDA于2003年由 David Blei, Andrew Ng和 Michael I.
Jordan提出，因为模型的简单和有效，掀起了主题模型研究的波浪。虽然说LDA模型简单，但是它的数学推导却不是那么平易近人，一般初学者会深陷数学细节推导中不能自拔。于是牛人们看不下去了，纷纷站出来发表了各种教程。国内方面rickjin有著名的《<a href="https://link.zhihu.com/?target=http%3A//www.52nlp.cn/author/rickjin">LDA数学八卦</a>》，国外的Gregor
Heinrich有著名的《<a href="https://link.zhihu.com/?target=https%3A//users.soe.ucsc.edu/~amichelo/docs/text-est2.pdf">Parameter
estimation for text
analysis</a>》。其实有了这两篇互补的通俗教程，大家沉住心看个4、5遍，基本就可以明白LDA为什么是简单的了。那么其实也没我什么事了，然而心中总有一种被大牛点播的豁然开朗的快感，实在是不吐不快啊。</p>
</blockquote>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>概率图模型</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（8）【Nan】马尔可夫模型</title>
    <url>/posts/16VDGF1/</url>
    <content><![CDATA[<h2><span id="马尔可夫模型">马尔可夫模型</span></h2>
<blockquote>
<p>如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？ -
Scofield的回答 - 知乎
https://www.zhihu.com/question/35866596/answer/236886066</p>
</blockquote>
<h3><span id="一-概念">一、概念</span></h3>
<h4><span id="11-随机过程">1.1 随机过程</span></h4>
<p><strong>随机过程就是一些统计模型，利用这些统计模型可以对自然界的一些事物进行预测和处理</strong>，比如天气预报，比如股票，比如市场分析，比如人工智能。它的应用还真是多了去了。</p>
<h4><span id="12-马尔可夫链-markov-chain">1.2 马尔可夫链 （Markov Chain）</span></h4>
<blockquote>
<p>马尔可夫链 （Markov Chain）是什么鬼 - 车卡门的文章 - 知乎
https://zhuanlan.zhihu.com/p/26453269</p>
</blockquote>
<p>马尔可夫链就是这样一个任性的过程，它将来的状态分布只取决于现在，跟过去无关！实际上就是一个随机变量随时间按照Markov性进行变化的过程。</p>
<h4><span id="13-马尔可夫模型hiddenmarkov-models">1.3 马尔可夫模型（Hidden
Markov Models）</span></h4>
<p>既是马尔可夫模型，就一定存在<a href="https://www.zhihu.com/search?q=马尔可夫链&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A%2264187492%22%7D">马尔可夫链</a>，该马尔可夫链服从马尔可夫性质：即无记忆性。也就是说，这一时刻的状态，受且只受前一时刻的影响，而不受更往前时刻的状态的影响。在这里我们仍然使用非常简单的天气模型来做说明。</p>
<p><img src="https://picx.zhimg.com/80/648a55725e67d718d97d6a475891d70b_1440w.png" alt="img" style="zoom:50%;"></p>
<p>在这个马尔可夫模型中，存在三个状态，Sunny， Rainy，
Cloudy，同时图片上标的是各个状态间的转移概率（如果不明白什么是转移概率，那建议先去学习什么是马尔可夫再来看HMM）。</p>
<p><strong><font color="red"> 现在我们要说明什么是
HMM。既是隐形，说明这些状态是观测不到的，相应的，我们可以通过其他方式来『猜测』或是『推断』这些状态，这也是
HMM 需要解决的问题之一。</font></strong></p>
<blockquote>
<p>举个例子，我女朋友现在在北京工作，而我还在法国读书。每天下班之后，她会根据天气情况有相应的活动：或是去商场购物，或是去公园散步，或是回家收拾房间。我们有时候会通电话，她会告诉我她这几天做了什么，而闲着没事的我呢，则要通过她的行为猜测这几天对应的天气最有可能是什么样子的。</p>
<p>以上就是一个简单的
HMM，天气状况属于状态序列，而她的行为则属于观测序列。天气状况的转换是一个马尔可夫序列。而根据天气的不同，有相对应的概率产生不同的行为。在这里，为了简化，把天气情况简单归结为晴天和雨天两种情况。雨天，她选择去散步，购物，收拾的概率分别是0.1，0.4，0.5，
而如果是晴天，她选择去散步，购物，收拾的概率分别是0.6，0.3，0.1。而天气的转换情况如下：这一天下雨，则下一天依然下雨的概率是0.7，而转换成晴天的概率是0.3；这一天是晴天，则下一天依然是晴天的概率是0.6，而转换成雨天的概率是0.4.
同时还存在一个初始概率，也就是第一天下雨的概率是0.6，
晴天的概率是0.4.</p>
<p><img src="https://pic4.zhimg.com/80/792e033ff9b0418b3b6c9bbaef30fd83_1440w.png" alt="img" style="zoom:50%;"></p>
</blockquote>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>概率图模型</category>
      </categories>
  </entry>
  <entry>
    <title>线性模型（3）正则化</title>
    <url>/posts/2N1XDRQ/</url>
    <content><![CDATA[<h3><span id="一-正则化l1和l2"><strong><font color="red">一、正则化
L1和L2</font></strong></span></h3>
<blockquote>
<ul>
<li><strong>本质其实是为了模型参数服从某一分布</strong>；</li>
<li><strong>正则化之所以能够降低过拟合的原因在于，正则化是结构风险最小化的一种策略实现；</strong></li>
</ul>
<p><strong>为什么希望参数具有稀疏性？</strong></p>
<p>相当于对模型进行了一次特征选择，只留下比较重要的特征，提高模型的泛化能力；</p>
</blockquote>
<p><strong><font color="red">
正则化是一个通用的算法和思想，所以会产生过拟合现象的算法都可以使用正则化来避免过拟合。在经验风险最小化的基础上（也就是训练误差最小化），尽可能采用简单的模型，可以有效提高泛化预测精度。</font></strong>如果模型过于复杂，变量值稍微有点变动，就会引起预测精度问题。正则化之所以有效，就是因为其降低了特征的权重，使得模型更为简单。</p>
<p>正则化一般会采用 L1 范式或者 L2 范式, 其形式分别为 <span class="math inline">\(\Phi(w)=\|x\|_1\)</span> 和 <span class="math inline">\(\Phi(w)=\|x\|_2 。\)</span></p>
<p><img src="https://pic3.zhimg.com/80/v2-a352bc374e80df1299a4d63d39ce4606_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="11-l1-正则化零均值拉普拉斯分布">1.1 <strong>L1 正则化</strong>
【零均值拉普拉斯分布】</span></h4>
<p><strong>LASSO 回归, 相当于为模型添加了这样一个先验知识</strong>：
<span class="math inline">\(\mathbf{w}\)</span>
服从<strong>零均值拉普拉斯分布</strong>。首先看看拉普拉斯分布长什
么样子: <span class="math display">\[
f(w \mid \mu, b)=\frac{1}{2 b} \exp \left(-\frac{|w-\mu|}{b}\right)
\]</span> 由于引入了先验知识, 所以似然函数这样写: <span class="math display">\[
\begin{aligned}
L(w) &amp; =P(y \mid w, x) P(w) \\
&amp; =\prod_{i=1}^N
p\left(x_i\right)^{y_i}\left(1-p\left(x_i\right)\right)^{1-y_i}
\prod_{j=1}^d \frac{1}{2 b} \exp
\left(-\frac{\left|w_j\right|}{b}\right)
\end{aligned}
\]</span> 取 <span class="math inline">\(\log\)</span>
再取负，得到目标函数: <span class="math display">\[
-\ln L(w)=-\sum_i\left[y_i \ln p\left(x_i\right)+\left(1-y_i\right) \ln
\left(1-p\left(x_i\right)\right)\right]+\frac{1}{2 b^2}
\sum_j\left|w_j\right|
\]</span> 等价于原始损失函数的后面加上了 L1 正则, 因此 L1
正则的本质其实是为模型增加了“模型参数服从零均值拉普拉
斯分布"这一先验知识。</p>
<h4><span id="12-l2正则化零均值正态分布"><strong>1.2 L2
正则化</strong>【零均值正态分布】</span></h4>
<p>Ridge 回归, 相当于为模型添加了这样一个先验知识： <span class="math inline">\(w\)</span> 服从<strong>零均值正态分布</strong>。
首先看看正态分布长什么样子: <span class="math display">\[
f(w \mid \mu, \sigma)=\frac{1}{\sqrt{2 \pi} \sigma} \exp
\left(-\frac{(w-\mu)^2}{2 \sigma^2}\right)
\]</span> 由于引入了先验知识, 所以似然函数这样写: <span class="math display">\[
\begin{aligned}
L(w) &amp; =P(y \mid w, x) P(w) \\
&amp; =\prod_{i=1}^N
p\left(x_i\right)^{y_i}\left(1-p\left(x_i\right)\right)^{1-y_i}
\prod_{j=1}^d \frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{w_j^2}{2
\sigma^2}\right) \\
&amp; =\prod_{i=1}^N
p\left(x_i\right)^{y_i}\left(1-p\left(x_i\right)\right)^{1-y_i}
\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{w^T w}{2
\sigma^2}\right)
\end{aligned}
\]</span> 取 In 再取负，得到目标函数: <span class="math display">\[
-\ln L(w)=-\sum_i\left[y_i \ln p\left(x_i\right)+\left(1-y_i\right) \ln
\left(1-p\left(x_i\right)\right)\right]+\frac{1}{2 \sigma^2} w^T w
\]</span> 等价于原始的损失函数后面加上了 <span class="math inline">\(L
2\)</span> 正则, 因此 <span class="math inline">\(L 2\)</span>
正则的本质其实是为模型增加了““<strong>模型参数服从零均值正态分
布</strong>"这一先验知识。</p>
<h4><span id="13-l1-和-l2-的区别">1.3 L1 和 L2 的区别</span></h4>
<blockquote>
<ul>
<li><strong><font color="red"> 解空间约束条件 ： KKT条件【互斥松弛条件 +
约束条件大于0】</font></strong></li>
<li><strong><font color="red">
函数叠加：（0点成为最值的可能）导数为0的可能性</font></strong></li>
<li><strong><font color="red"> 贝叶斯先验：分布图像</font></strong></li>
</ul>
</blockquote>
<p><strong>L1 正则化</strong>增加了所有权重 w
参数的绝对值之和<strong>逼迫更多 w 为零</strong>，也就是变稀疏（ L2
因为其导数也趋 0, 奔向零的速度不如 L1
给力了）。对<strong>稀疏规则趋之若鹜</strong>的一个关键原因在于它能<strong>实现特征的自动选择</strong>。L1
正则化的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些无用的特征，也就是把这些特征对应的权重置为
0。</p>
<p><strong>L2 正则化</strong>中增加所有权重 w 参数的平方之和，逼迫所有
<strong>w 尽可能趋向零但不为零</strong>（L2 的导数趋于零）。因为在未加入
L2
正则化发生过拟合时，拟合函数需要顾忌每一个点，最终形成的拟合函数波动很大，在某些很小的区间里，函数值的变化很剧烈，也就是某些
w 值非常大。为此，L2 正则化的加入就惩罚了权重变大的趋势。</p>
<h4><span id="14l1正则化使得模型参数具有稀疏性的原理"><strong><font color="red"> 1.4
L1正则化使得模型参数具有稀疏性的原理？</font></strong></span></h4>
<h5><span id="1解空间约束条件-kkt条件互斥松弛条件-约束条件大于0">(1)
解空间约束条件 ： KKT条件【互斥松弛条件 + 约束条件大于0】</span></h5>
<p><strong>KKT
条件是指优化问题在最优处（包括基本型的最优值，对偶问题的最优值）必须满足的条件</strong>。</p>
<blockquote>
<p><strong>参考线性支持向量机的 KKT 条件:</strong></p>
<ul>
<li><strong>主问题可行</strong>: <span class="math inline">\(g_{i}\left(u^{\star}\right)=1-y_{i}\left(w^{\star
\top} x_{i}+b^{\star}\right) \leq 0\)</span> ；</li>
<li><strong><font color="red"> 对偶问题可行: <span class="math inline">\(\alpha_{i}^{\star} \geq
0\)</span></font></strong>;</li>
<li><strong>主变量最优</strong>: <span class="math inline">\(w^{\star}=\sum_{i=1}^{m} \alpha_{i} y_{i} x_{i},
\sum_{i=1}^{m} \alpha_{i} y_{i}=0\)</span>;</li>
<li><strong><font color="red"> 互补松弛: <span class="math inline">\(\alpha_{i}^{\star}
g_{i}\left(u^{\star}\right)=\alpha_{i}^{\star}\left(1-y_{i}\left(w^{\star
\top} x_{i}+b^{\star}\right)\right)=0\)</span> ；</font></strong></li>
</ul>
</blockquote>
<p><strong>原函数曲线等高线（同颜色曲线上，每一组<span class="math inline">\(w_1,w_2\)</span>带入后值都相同)</strong>：</p>
<p><img src="https://pic4.zhimg.com/80/v2-efc752bd6d1ce09dbf2e18b9766570eb_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>当加入 L1 正则化的时候, 我们先画出 <span class="math inline">\(\left|w_1\right|+\left|w_2\right|=F\)</span>
的图像, 也就是一个菱形, 代表这些曲线上的点算出来的
要使得这个菱形越小越好 ( <span class="math inline">\(F\)</span>
越小越好)。那么还和原来一样的话, 过中心紫色圈圈的那个菱形明显很大,
因此我 们要取到一个恰好的值。那么如何求值呢?</p>
<ol type="1">
<li>以同一条原曲线目标等高线来说, 现在以最外圈的红色等高线为例,
我们看到, 对于红色曲线上的每个点都可 做一个菱形, 根据上图可知,
当这个菱形与某条等高线相切（仅有一个交点）的时候, 这个菱形最小, 上图相
割对比较大的两个菱形对应的 L1 范数更大。用公式说这个时候能使得在相同的
<span class="math inline">\(\frac{1}{N} \sum_{i=1}^N\left(y_i-w^T
x_i\right)^2\)</span>, 由于 相切的时候的 <span class="math inline">\(C||
w \|_1\)</span> 小, 即 <span class="math inline">\(\left|w_1\right|+\left|w_2\right|\)</span>
所以能够使得 <span class="math inline">\(\frac{1}{N} \sum
i=1^N\left(y_i-w^T x_i\right)^2+C|| w \|_1\)</span> 更小;</li>
<li>有了第一条的说明我们可以看出, 最终加入 <span class="math inline">\(L
1\)</span> 范数得到的解一定是某个菱形和某条原函数等高线的切点。现
在有个比较重要的结论来了, <font color="red"> 我们经过观察可以看到,
几乎对于很多原函数等高曲线, 和某个菱形相交的时 候及其容易相交在坐标轴
(比如上图) , 也就是说最终的结果, 解的某些维度及其容易是 0,
比如上图最终解 是 <span class="math inline">\(w=(0, x)\)</span>
，这也就是我们所说的 L1 更容易得到稀疏解（解向量中 0
比较多)的原因;</font></li>
<li>当加入 <span class="math inline">\(L 2\)</span> 正则化的时候, 分析和
<span class="math inline">\(L 1\)</span> 正则化是类似的,
也就是说我们仅仅是从菱形变成了圆形而已, 同样还
是求原曲线和圆形的切点作为最终解。<strong>当然与 <span class="math inline">\(L 1\)</span> 范数比, 我们这样求的 <span class="math inline">\(L 2\)</span> 范数的从图上来看, 不容易交在
坐标轴上, 但是仍然比较靠近坐标轴。因此这也就是我们老说的, L2
范数能让解比较小 (靠近 0), 但是比 较平滑（不等于 0)。</strong></li>
</ol>
<h5><span id="2函数叠加0点成为最值的可能导数为0的可能性">(2)
函数叠加：（0点成为最值的可能)导数为0的可能性</span></h5>
<p>我们接下来从更严谨的方式来证明,
简而言之就是假设现在我们是一维的情况下 <span class="math inline">\(h(w)=f(w)+C|w|\)</span>, 其中 <span class="math inline">\(h(w)\)</span> 是目标函数, <span class="math inline">\(f(w)\)</span> 是没加 <span class="math inline">\(\mathrm{L} 1\)</span> 正则化项前的目标函数, <span class="math inline">\(C|w|\)</span> 是 <span class="math inline">\(\mathrm{L}\)</span> 正则项, 要使得 0
点成为最值可能的点, <strong>虽然在 0 点不可导, 但是我们只需要让 0
点左右的导数异号, 即 <span class="math inline">\(h_l^{\prime}(0)
h_r^{\prime}(0)=\left(f^{\prime}(0)+C\right)\left(f^{\prime}(0)-C\right)&lt;0\)</span>
即可也就 是 <span class="math inline">\(C&gt;\left|f^{\prime}(0)\right|\)</span> 的情况下,
0 点都是可能的最值点</strong>。相反, L2正则项在原点处的导数是0,
只要原目标函数在原点 处导数不为 0 , 那么最小值点就不会在原点, 所以 <span class="math inline">\(L 2\)</span> 只有减小w最对值的作用,
对解空间的稀疏性没有贡献。</p>
<h5><span id="3-贝叶斯先验分布图像">(3) 贝叶斯先验：分布图像</span></h5>
<p><img src="https://pic3.zhimg.com/80/v2-a352bc374e80df1299a4d63d39ce4606_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p><strong>从贝叶斯加入先验分布的角度解释，L1正则化相当于对模型参数引入拉普拉斯先验，L2正则化相当于与引入了高斯先验。高斯分布在0点是平滑的，拉普拉斯在0点处是一个尖峰。</strong></p>
<h4><span id="15-简单总结">1.5 <strong>简单总结</strong></span></h4>
<table>
<colgroup>
<col style="width: 12%">
<col style="width: 59%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>正则化</th>
<th>L1 正则化</th>
<th>L2 正则化</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>服从分布</td>
<td>零均值拉普拉斯分布</td>
<td>零均值正态分布</td>
</tr>
<tr class="even">
<td>损失函数变化</td>
<td><span class="math inline">\(\frac{1}{2 b^2} \sum_j\left
|w_j\right|\)</span></td>
<td><span class="math inline">\(\frac{1}{2 \sigma^2} w^T w\)</span></td>
</tr>
<tr class="odd">
<td>模型参数w效果</td>
<td>逼迫更多 w 为零，【稀疏解】<strong><font color="red">
（解空间约束条件、函数叠加、贝叶斯先验）</font></strong></td>
<td>趋向零但不为零【平滑】</td>
</tr>
<tr class="even">
<td>作用</td>
<td>【特征选择】【降低模型复杂度】</td>
<td>【降低模型复杂度】</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>线性模型</category>
      </categories>
      <tags>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯分类器（1）朴素贝叶斯</title>
    <url>/posts/3KD4010/</url>
    <content><![CDATA[<p>朴素贝叶斯（Naive
Bayes）是基于<strong>贝叶斯定理</strong>与<strong>特征条件假设</strong>的<strong>分类</strong>方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入、输出的联合分布；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。朴素贝叶斯是<strong>选出各个分类类别后验概率最大</strong>的作为最终分类。</p>
<ul>
<li><strong>优点</strong>：对小规模的数据表现很好，适合多分类任务，<strong>适合增量式训练</strong>。</li>
<li><strong>缺点</strong>：对输入数据的表达形式很敏感<strong>（离散、连续，值极大极小之类的）。</strong></li>
</ul>
<span id="more"></span>
<h3><span id="一-朴素贝叶斯的学习与分类">一、朴素贝叶斯的学习与分类</span></h3>
<h4><span id="11贝叶斯定理">1.1贝叶斯定理</span></h4>
<p><strong>条件概率:</strong></p>
<p><span class="math inline">\(P(A \mid B)\)</span>
表示事件B已经发生的前提下, 事件B已经发生的前提下, 事件A发生的概率,
叫做事件 <span class="math inline">\(B\)</span> 发生下事件 <span class="math inline">\(A\)</span> 的条件概率。其基本求解公式为 <span class="math display">\[
P(A \mid B)=\frac{P(A B)}{P(B)}
\]</span> <font color="red"> 贝叶斯定理便是基于条件概率, 通过 <span class="math inline">\(P(A \mid B)\)</span> 来求 <span class="math inline">\(P(B \mid A)\)</span>
：【通过先验概率计算后验概率】</font> <span class="math display">\[
P(B \mid A)=\frac{P(A \mid B) \cdot P(B)}{P(A)}
\]</span> 顺便提一下, 上式中的分母, 可以根据全概率公式分解为: <span class="math display">\[
P(A)=\sum_{i=1}^n P\left(B_i\right) P\left(A \mid B_i\right)
\]</span></p>
<h4><span id="12-特征条件独立假设">1.2 特征条件独立假设</span></h4>
<p>这一部分开始朴素贝叶斯的理论推导，从中你会深刻地理解什么是特征条件<strong>独立假设</strong>。给定训练数据集<span class="math inline">\((X,Y)\)</span>，其中每个样本<span class="math inline">\(X\)</span>都包括 <span class="math inline">\(n\)</span> 维特征，即<span class="math inline">\(x=(x1,x2,···,xn)\)</span>，类标记集合含有<span class="math inline">\(K\)</span>种类别，即<span class="math inline">\(y=(y1,y2,···,yk)\)</span>.</p>
<p>如果现在来了一个新样本 <span class="math inline">\(x\)</span>
我们要怎么判断它的类别?从概率的角度来看，这个问题就是给定<span class="math inline">\(x\)</span>，它属于哪个类别的概率更大。那么问题就转化为求解
<span class="math inline">\(P(y1|x),P(y2|x),P(yk|x)P(y1|x),P(y2|x),P(yk|x)\)</span>
中最大的那个，即求<strong>后验概率最大</strong>的输出：<span class="math inline">\(arg max_{y_k}P(y_k|x)\)</span></p>
<p>根据全概率公式，可以进一步分解上式中的分母: <span class="math display">\[
P\left(y_k \mid x\right)=\frac{P\left(x \mid y_k\right) \cdot
P\left(y_k\right)}{\sum_{i=1}^n P\left(x \mid y_k\right)
P\left(y_k\right)}
\]</span></p>
<ul>
<li><span class="math inline">\(P\left(y_k\right)\)</span> :
先验概率【训练集计算】</li>
<li><span class="math inline">\(P\left(x \mid y_k\right)=P\left(x_1,
x_2, \cdots, x_n \mid y_k\right)\)</span> : 条件概率,
它的参数规模是指数数量级别的。假设第 <span class="math inline">\(\mathrm{S}\)</span> 维特征 <span class="math inline">\(\mathrm{i}\)</span> 可取值的个数 有 <span class="math inline">\(\mathrm{Si}\)</span> 个, 类别取值个数为 <span class="math inline">\(\mathrm{k}\)</span> 个, 那么参数个数为 <span class="math inline">\(k \prod S_j\)</span> 。</li>
<li>独立性的假设: 通俗地讲就是说假设各个维度的特征互相独立,
这样参数规模就降到了 <span class="math inline">\(\sum S_i k\)</span>
，【积-&gt;和】</li>
</ul>
<p><span class="math display">\[
P\left(x \mid y_i\right)=P\left(x_1, x_2, \cdots, x_n \mid
y_i\right)=\prod_{i=1}^n P\left(x_i \mid y_i\right)
\]</span></p>
<ul>
<li>代入公式1得出:</li>
</ul>
<p><span class="math display">\[
P\left(y_k \mid x\right)=\frac{P\left(y_k\right) \prod_{i=1}^n
P\left(x_i \mid y_k\right)}{\sum_k P\left(y_k\right) \prod_{i=1}^n
P\left(x_i \mid y_k\right)}
\]</span></p>
<ul>
<li>于是朴素贝叶斯分类器可表示为:</li>
</ul>
<p><span class="math display">\[
f(x)=\arg \max _{y_k} P\left(y_k \mid x\right)=\arg \max _{y_k}
\frac{P\left(y_k\right) \prod_{i=1}^n P\left(x_i \mid y_k\right)}{\sum_k
P\left(y_k\right) \prod_{i=1}^n P\left(x_i \mid y_k\right)}
\]</span></p>
<ul>
<li>由于分母值都是一样的：极大后验概率估计</li>
</ul>
<p><span class="math display">\[
f(x)=\arg \max _{y_k} P\left(y_k\right) \prod_{i=1}^n P\left(x_i \mid
y_k\right)
\]</span></p>
<h4><span id="13朴素贝叶斯法的参数估计求解">1.3
朴素贝叶斯法的参数估计【求解】</span></h4>
<p>朴素贝叶斯要学习的东西就是: <span class="math inline">\(P\left(Y=c_k\right)\)</span> 和 <span class="math inline">\(\mid P\left(X^j=a_{j l} \mid Y=c_k\right)\)</span>
【极大似然函数 + 拉格朗日乘数法】</p>
<ul>
<li><strong>先验概率</strong> <span class="math inline">\(P(Y=c
k)\)</span> 的极大似然估计是, 样本在 <span class="math inline">\(c_k\)</span> 出现的次数除以样本容量:</li>
</ul>
<p><span class="math display">\[
P\left(Y=c_k\right)=\frac{\sum_{i=1}^N I\left(y_i=c_k\right)}{N}, k=1,2,
\cdots, K
\]</span></p>
<ul>
<li>设第 <span class="math inline">\(j\)</span> 个特征 <span class="math inline">\(x(j)\)</span> 可能取值的集合为 <span class="math inline">\(a_{j 1}, a_{j 2}, \cdots, a_{j l}\)</span>,
条件概率 <span class="math inline">\(P\left(X_j=a_{j l} \mid Y=c
k\right)\)</span> 的极大似然估计是:</li>
</ul>
<p><span class="math display">\[
P\left(X^{(j)}=a_{j l} \mid Y=c_k\right)=\frac{\sum_{i=1}^N
I\left(x_i^{(j)}=a_{j l}, y_{i=} c_k\right)}{\sum_{i=1}^N
I\left(y_i=c_k\right)}
\]</span></p>
<h4><span id="14贝叶斯估计缺失值处理拉普拉斯平滑">1.4
贝叶斯估计【缺失值处理】【拉普拉斯平滑】</span></h4>
<p><strong>先验概率</strong>的贝叶斯估计: <span class="math display">\[
P_\lambda\left(Y=c_k\right)=\frac{\sum_{i=1}^N
I\left(y_i=c_k\right)+\lambda}{N+K \lambda}
\]</span>
<strong>条件概率</strong>的贝叶斯估计：<strong>【离散型】</strong> <span class="math display">\[
P_\lambda\left(X^{(j)}=a_{j l} \| Y=c_k\right)=\frac{\sum_{i=1}^N
I\left(x_i^{(j)}=a_{j l}, y_{i=} c_k\right)+\lambda}{\sum_{i=1}^N
I\left(y_i=c_k\right)+S_j \lambda}
\]</span></p>
<h4><span id="15朴素贝叶斯有什么优缺点"><strong><font color="red"> 1.5
朴素贝叶斯有什么优缺点？</font></strong></span></h4>
<h5><span id="优点数学理论-缺失异常不敏感-快-增量式训练">优点：【数学理论、缺失异常不敏感、快、增量式训练】</span></h5>
<ol type="1">
<li>朴素贝叶斯模型<strong>发源于古典数学理论</strong>，有稳定的分类效率。</li>
<li><strong>对缺失数据和异常数据不太敏感</strong>，算法也比较简单，常用于文本分类。</li>
<li><strong>分类准确度高，速度快</strong>。</li>
<li><strong>对小规模的数据表现很好，能处理多分类任务，适合增量式训练，当数据量超出内存时，我们可以一批批的去增量训练</strong>(朴素贝叶斯在训练过程中只需要计算各个类的概率和各个属性的类条件概率，这些概率值可以快速地根据增量数据进行更新，无需重新全量计算)。</li>
</ol>
<h5><span id="缺点">缺点：</span></h5>
<ol type="1">
<li><strong>对输入数据的表达形式很敏感（离散、连续，值极大极小之类的）</strong>。</li>
<li><strong>对训练数据的依赖性很强</strong>，如果训练数据误差较大，那么预测出来的效果就会不佳。</li>
<li>理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。
但是在实际中，因为朴素贝叶斯“朴素，”的特点，<strong>导致在属性个数比较多或者属性之间相关性较大时，分类效果不好。</strong>而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。</li>
<li>需要知道<strong>先验概率</strong>，且先验概率很多时候是基于假设或者已有的训练数据所得的，这在某些时候可能会因为假设先验概率的原因出现分类决策上的错误。</li>
</ol>
<h3><span id="二-高斯贝叶斯模型">二、高斯贝叶斯模型</span></h3>
<blockquote>
<p>classifier = naive_bayes.MultinomialNB()</p>
</blockquote>
<h4><span id="21-朴素贝叶斯连续型数据处理">2.1 朴素贝叶斯(连续型数据处理)</span></h4>
<ul>
<li>每一个连续的<strong>数据离散化</strong>，然后用相应的离散区间替换连续数值。这种方法对于划分离散区间的粒度要求较高，不能太细，也不能太粗。</li>
<li>假设<strong>连续数据服从某个概率分布</strong>，<strong>使用训练数据估计分布参数</strong>，通常我们用<strong>高斯分布</strong>来表示<strong>连续数据的类条件概率分布</strong>。</li>
</ul>
<p><strong>GaussianNB
的条件概率密度计算：其中均值和方差可以通过极大似然估计得出。</strong>
<span class="math display">\[
\begin{aligned}
&amp;p\left(X^{(j)}=a_{j l} \mid y=c_{k}\right)=\frac{1}{\sqrt{2 \pi}
\sigma_{j k}} e^{-\frac{\left(a_{j l}-\mu_{j k}\right)^{2}}{2 \sigma_{j
k}^{2}}}
\end{aligned}
\]</span></p>
<h3><span id="三-贝叶斯网络">三、贝叶斯网络</span></h3>
<h4><span id="31-概率图模型">3.1 概率图模型</span></h4>
<p>概率图模型分为<strong>贝叶斯网络（Bayesian
Network）和马尔可夫网络（Markov
Network）</strong>两大类。贝叶斯网络可以用一个有向图结构表示，马尔可夫网络可以表示成一个无向图的网络结构。更详细地说，<strong>概率图模型包括了朴素贝叶斯模型、最大熵模型、隐马尔可夫模型、条件随机场、主题模型</strong>等，在机器学习的诸多场景中都有着广泛的应用。</p>
<ul>
<li><strong>贝叶斯网络</strong> --
结点与结点之间是以有向箭头相连接，代表是这个结点会影响下一个结点</li>
<li><strong>马尔可夫网络</strong> --
结点与结点之间是以无向箭头相连接，代表是结点与结点之间会相互影响</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>贝叶斯分类器</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>生成式模型</tag>
        <tag>贝叶斯</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯分类器（3）总结</title>
    <url>/posts/1RM9XFV/</url>
    <content><![CDATA[<h3><span id="朴素贝叶斯-qampa">朴素贝叶斯 Q&amp;A</span></h3>
<blockquote>
<ul>
<li>朴素贝叶斯分类器原理以及公式，出现估计概率值为 0
怎么处理（拉普拉斯平滑），缺点；</li>
<li>解释贝叶斯公式和朴素贝叶斯分类。</li>
<li>贝叶斯分类，这是一类分类方法，主要代表是朴素贝叶斯，朴素贝叶斯的原理，重点在假设各个属性类条件独立。然后能根据贝叶斯公式具体推导。考察给你一个问题，如何利用朴素贝叶斯分类去分类，比如：给你一个人的特征，判断是男是女，比如身高，体重，头发长度等特征的的数据，那么你要能推到这个过程。给出最后的分类器公式。</li>
<li>那你说说贝叶斯怎么分类啊？<strong>比如说看看今天天气怎么样？</strong>我：blabla，，，利用天气的历史数据，可以知道天气类型的先验分布，以及每种类型下特征数据（比如天气数据的特征：温度啊，湿度啊）的条件分布，这样我们根据贝叶斯公式就能求得天气类型的后验分布了。。。。面试官：en（估计也比较满意吧）<strong>那你了解关于求解模型的优化方法吗？一般用什么优化方法来解？</strong></li>
<li>贝叶斯分类器的优化和特殊情况的处理</li>
</ul>
</blockquote>
<h4><span id="1-朴素贝叶斯-svm和lr的区别"><strong><font color="red">
1、朴素贝叶斯、SVM和LR的区别？</font></strong></span></h4>
<p><strong>朴素贝叶斯是生成模型</strong>，根据已有样本进行贝叶斯估计学习出先验概率P(Y)和条件概率P(X|Y)，进而求出联合分布概率P(XY),最后利用贝叶斯定理求解P(Y|X)。</p>
<p><strong>LR是判别模型</strong>，根据极大化对数似然函数直接求出条件概率P(Y|X)；朴素贝叶斯是基于很强的条件独立假设（在已知分类Y的条件下，各个特征变量取值是相互独立的），而LR则对此没有要求；<strong>朴素贝叶斯适用于数据集少的情景，而LR适用于大规模数据集。</strong></p>
<table>
<colgroup>
<col style="width: 8%">
<col style="width: 30%">
<col style="width: 30%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>SVM</th>
<th>LR</th>
<th>朴素贝叶斯</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>思想</strong></td>
<td><strong>想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面</strong>。</td>
<td>使用线性回归模型的预测值逼近分类任务真实标记的对数几率。</td>
<td>基于<strong>贝叶斯定理</strong>与<strong>特征条件假设</strong>的<strong>分类</strong>方法。选出各个分类类别后验概率最大的作为最终分类。</td>
</tr>
<tr class="even">
<td><strong>输出</strong></td>
<td>判别模型、<strong>非概率方法</strong>；</td>
<td><strong>概率方法</strong>；需要对<span class="math inline">\(p(y|x)\)</span>进行假设，具有概率意义。</td>
<td>生成模型</td>
</tr>
<tr class="odd">
<td><strong>经验损失函数</strong></td>
<td><strong>合页损失函数</strong>；有一段平的零区域、使得SVM的对偶性有稀疏性。</td>
<td><strong>交叉熵损失函数</strong></td>
<td><strong>后验概率最大</strong></td>
</tr>
<tr class="even">
<td><strong>训练样本</strong></td>
<td><strong>支持向量</strong>（少数样本），SVM的参数和假设函数只和支持向量有关。</td>
<td>全样本</td>
<td>全样本</td>
</tr>
<tr class="odd">
<td><strong>优化方法</strong></td>
<td>次梯度下降和坐标梯度下降 【<strong>SMO算法</strong>】</td>
<td><strong>梯度下降</strong></td>
<td>无</td>
</tr>
<tr class="even">
<td>多分类</td>
<td><strong>多分类SVM</strong></td>
<td><strong>Softmax回归</strong></td>
<td>后验概率最大</td>
</tr>
<tr class="odd">
<td><strong>敏感程度</strong></td>
<td><strong>SVM考虑分类边界线附近的样本</strong>（决定分类超平面的样本）。在支持向量外添加或减少任何样本点对分类决策面没有任何影响；【不敏感】</td>
<td><strong>LR受所有数据点的影响</strong>。直接依赖数据分布，每个样本点都会影响决策面的结果。如果训练数据不同类别严重不平衡。【敏感】</td>
<td><strong>特征值是基于频数进行统计的。</strong>一个值的异常（变成了别的数），<strong>只是贝叶斯公式里的计算概率的分子或者分母发生微小的变化，整体结果影响不大</strong>，不敏感【概率排序】</td>
</tr>
</tbody>
</table>
<h4><span id="2-朴素贝叶斯朴素在哪里">2、<strong><font color="red">
朴素贝叶斯“朴素”在哪里？</font></strong></span></h4>
<p>简单来说：它假定<strong>所有的特征在数据集中的作用是同样重要和独立的</strong>，正如我们所知，这个假设在现实世界中是很不真实的，因此，说朴素贝叶斯真的很“朴素”。</p>
<p>利用贝叶斯定理求解联合概率<span class="math inline">\(P(XY)\)</span>时，需要计算条件概率<span class="math inline">\(P(X|Y)\)</span>。在计算<span class="math inline">\(P(X|Y)\)</span>时，朴素贝叶斯做了一个很强的条件独立假设（当Y确定时，X的各个分量取值之间相互独立），即<span class="math inline">\(P(X1=x1,X2=x2,…Xj=xj|Y=yk) =
P(X1=x1|Y=yk)…*P(Xj=xj|Y=yk)\)</span>。
多个特征全是独立的，需要分别相乘。</p>
<h4><span id="3-在估计条件概率pxy时出现概率为0的情况怎么办">3、<strong>在估计条件概率P(X|Y)时出现概率为0的情况怎么办？</strong></span></h4>
<p><strong>拉普拉斯平滑法</strong>是朴素贝叶斯中处理零概率问题的一种修正方式。在进行分类的时候，可能会出现某个属性在训练集中没有与某个类同时出现过的情况，如果直接基于朴素贝叶斯分类器的表达式进行计算的话就会出现<strong>零概率现象</strong>。</p>
<p>为了避免其他属性所携带的信息被训练集中未出现过的属性值“抹去”，所以才使用拉普拉斯估计器进行修正。具体的方法是：<strong>在分子上加1,对于先验概率，在分母上加上训练集中label的类别数；对于特征i
在label下的条件概率，则在分母上加上第i个属性可能的取值数（特征 i
的unique()）</strong></p>
<p>先验概率的贝叶斯估计: <span class="math display">\[
P_\lambda\left(Y=c_k\right)=\frac{\sum_{i=1}^N
I\left(y_i=c_k\right)+\lambda}{N+K \lambda}
\]</span> 条件概率的贝叶斯估计：【离散型】 <span class="math display">\[
P_\lambda\left(X^{(j)}=a_{j l} \| Y=c_k\right)=\frac{\sum_{i=1}^N
I\left(x_i^{(j)}=a_{j l}, y_{i=} c_k\right)+\lambda}{\sum_{i=1}^N
I\left(y_i=c_k\right)+S_j \lambda}
\]</span></p>
<h4><span id="4-先验概率和后验概率都是">4、<strong>先验概率和后验概率都是？</strong></span></h4>
<p><strong>先验概率是指根据以往经验和分析得到的概率</strong>,如全概率公式,它往往作为"由因求果"问题中的"因"出现.<strong>后验概率是基于新的信息，修正原来的先验概率后所获得的更接近实际情况的概率估计。</strong></p>
<p><strong>先验概率和后验概率是相对的。</strong>如果以后还有新的信息引入，更新了现在所谓的后验概率，得到了新的概率值，那么这个新的概率值被称为后验概率。</p>
<h4><span id="5-朴素贝叶斯算法的前提假设是什么">5、<strong>朴素贝叶斯算法的前提假设是什么？</strong></span></h4>
<ol type="1">
<li>特征之间相互独立</li>
<li>每个特征同等重要</li>
</ol>
<h4><span id="6-面试的时候怎么标准回答朴素贝叶斯呢">6、<strong>面试的时候怎么标准回答朴素贝叶斯呢？</strong></span></h4>
<p>首先朴素贝斯是一个<strong>生成模型（很重要）</strong>，其次它通过学习已知样本，计算出联合概率，再求条件概率。</p>
<h5><span id="生成模式和判别模式的区别常见"><strong>生成模式和判别模式的区别(常见)：</strong></span></h5>
<p><strong>生成模式</strong>：由数据学得<strong>联合概率分布，求出条件概率分布P(Y|X)的预测模型</strong>；<strong>比较在乎数据是怎么生成的</strong>；常见的生成模型有：朴素贝叶斯、隐马尔可夫模型、高斯混合模型、文档主题生成模型（LDA）、限制玻尔兹曼机。</p>
<p><strong>判别模式</strong>：由数据学得<strong>决策函数或条件概率分布作为预测模型</strong>，<strong>要关注在数据的差异分布上，而不是生成</strong>；常见的判别模型有：K近邻、SVM、决策树、感知机、线性判别分析（LDA）、线性回归、传统的神经网络、逻辑斯蒂回归、boosting、条件随机场。</p>
<h4><span id="7-为什么属性独立性假设在实际情况中很难成立但朴素贝叶斯仍能取得较好的效果排序能力">7、<strong>为什么属性独立性假设在实际情况中很难成立，但朴素贝叶斯仍能取得较好的效果?</strong>【排序能力】</span></h4>
<p>首先独立性假设在实际中不存在，确实会导致朴素贝叶斯不如一些其他算法，但是就算法本身而言，朴素贝叶斯也会有不错的分类效果，原因是：</p>
<ul>
<li><strong>分类问题看中的是类别的条件概率的排序</strong>，而不是具体的概率值，所以这里面对精准概率值的计算是有一定的容错的。</li>
<li>如果特征属性之间的依赖对所有类别影响相同，或依赖关系的影响能相互抵消，则属性条件独立性假设在降低计算开销的同时不会对性能产生负面影响。</li>
</ul>
<h4><span id="8-朴素贝叶斯中概率计算的下溢问题如何解决"><strong><font color="red">
8、朴素贝叶斯中概率计算的下溢问题如何解决？</font></strong></span></h4>
<p><strong>在朴素贝叶斯的计算过程中，需要对特定分类中各个特征出现的概率进行连乘</strong>，小数相乘，越乘越小，这样就造成下溢出。在程序中，在相应小数位置进行四舍五入，计算结果可能就变成0了。</p>
<p>为了解决这个问题，<strong>对乘积结果取自然对数</strong>。将小数的乘法操作转化为取对数后的加法操作，规避了变为0的风险同时并不影响分类结果。</p>
<h4><span id="9-朴素贝叶斯分类器对异常值和缺失值敏感吗">9、<strong>朴素贝叶斯分类器对异常值和缺失值敏感吗？</strong></span></h4>
<p>回想朴素贝叶斯的计算过程，它在推理的时候，输入的某个特征组合，<strong>他们的特征值在训练的时候在贝叶斯公式中都是基于频数进行统计的。</strong>所以一个值的异常（变成了别的数），<strong>只是贝叶斯公式里的计算概率的分子或者分母发生微小的变化，整体结果影响不大</strong>，就算微微影响最终概率值的获得，由于<strong>分类问题只关注概率的排序而不关注概率的值，所以影响不大</strong>，保留异常值还可以提高模型的泛化性能。</p>
<p>缺失值也是一样，如果一个数据实例缺失了一个属性的数值，在建模的时将被忽略，不影响类条件概率的计算，在预测时，计算数据实例是否属于某类的概率时也将忽略缺失属性，不影响最终结果。</p>
<h4><span id="10-朴素贝叶斯中有没有超参数可以调">10、<strong>朴素贝叶斯中有没有超参数可以调？</strong></span></h4>
<p><strong>朴素贝叶斯是没有超参数可以调的，所以它不需要调参</strong>，朴素贝叶斯是根据训练集进行分类，分类出来的结果基本上就是确定了的，拉普拉斯估计器不是朴素贝叶斯中的参数，不能通过拉普拉斯估计器来对朴素贝叶斯调参。</p>
<h4><span id="11-朴素贝叶斯有哪三个模型">11、<strong>朴素贝叶斯有哪三个模型？</strong></span></h4>
<ul>
<li><strong>多项式模型对应于离散变量</strong>，其中离散变量指的是category型变量，也就是类别变量，比如性别；连续变量一般是数字型变量，比如年龄，身高，体重。</li>
<li><strong>高斯模型 对应于连续变量</strong>（每一维服从正态分布）</li>
<li><strong>伯努利模型</strong> <strong>对应于文本分类</strong>
（特征只能是0或者1）</li>
</ul>
<h4><span id="12-朴素贝叶斯为什么适合增量计算"><strong><font color="red">
12、朴素贝叶斯为什么适合增量计算？</font></strong></span></h4>
<p>朴素贝叶斯在训练过程中实际上需要<strong>计算出各个类别的概率和各个特征的条件概率</strong>，这些概率以频数统计比值（对于多项式模型而言）的形式产生概率值，<strong>可以快速根据增量数据进行更新，无需重新全量训练，所以其十分适合增量计算。</strong></p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><p>https://scikit-learn.org/dev/modules/naive_bayes.html#naive-bayes</p></li>
<li><p><a href="https://plushunter.github.io/2017/02/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%8810%EF%BC%89%EF%BC%9A%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/">FREE
WILL 机器学习算法系列（10）：朴素贝叶斯</a></p></li>
<li><h5><span id="最大似然估计-最大后验估计-贝叶斯估计的对比">最大似然估计、最大后验估计、贝叶斯估计的对比</span></h5>
<ul>
<li><h5><span id="httpswwwcnblogscomjiangxinyangp9378535html">https://www.cnblogs.com/jiangxinyang/p/9378535.html</span></h5></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>贝叶斯分类器</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>总结</tag>
        <tag>生成式模型</tag>
        <tag>贝叶斯</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯分类器（2）贝叶斯估计</title>
    <url>/posts/8R7RKW/</url>
    <content><![CDATA[<h3><span id="一-最大似然估计-最大后验估计-贝叶斯估计的对比">一、最大似然估计、最大后验估计、贝叶斯估计的对比</span></h3>
<h4><span id="11-贝叶斯公式">1.1 <strong>贝叶斯公式</strong></span></h4>
<p>这三种方法都和贝叶斯公式有关，所以我们先来了解下贝叶斯公式：</p>
<p><span class="math display">\[
p(\theta \mid X)=\frac{p(X \mid \theta) p(\theta)}{p(X)}
\]</span> 每一项的表示如下: <span class="math display">\[
\text { posterior }=\frac{\text { likehood } * \text { prior }}{\text {
evidence }}
\]</span> + posterior: 通过样本X得到参数 <span class="math inline">\(\theta\)</span> 的概率, 也就是后验概率。 +
likehood: 通过参数 <span class="math inline">\(\theta\)</span>
得到样本X的概率, 似然函数, 通常就是我们的数据集的表现。 + prior: 参数
<span class="math inline">\(\theta\)</span> 的先验概率,
一般是根据人的先验知识来得出的。</p>
<h4><span id="12-极大似然估计-mle">1.2 极大似然估计 (MLE)</span></h4>
<p>极大似然估计的核心思想是:
认为当前发生的事件是概率最大的事件。<strong>因此就可以给定的数据集,
使得该数据集发生的概率最大来求得模型中的参数</strong>。似然函数如下:
<span class="math display">\[
p(X \mid \theta)=\prod_{x 1}^{x n} p(x i \mid \theta)
\]</span> 为了便于计算, 我们对似然函数两边取对数,
生成新的对数似然函数（因为对数函数是单调增函数, 因此求似然函数最大化就可
以转换成对数似然函数最大化）： <span class="math display">\[
p(X \mid \theta)=\prod_{x 1}^{x n} p(x i \mid \theta)=\sum_{x 1}^{x n}
\log p(x i \mid \theta)
\]</span> 求对数似然函数最大化, 可以通过导数为 0
来求解。<strong><font color="red"> 极大似然估计只关注当前的样本,
也就是只关注当前发生的事情,
不考虑事情的先验情况</font></strong>。由于计算简单, 而且不需要关注先验
知识, 因此在机器学习中的应用非常广, 最常见的就是逻辑回归。</p>
<h4><span id="13-最大后验估计-map">1.3 最大后验估计 (MAP)</span></h4>
<p>和最大似然估计不同的是,
最大后验估计中引入了<strong>先验概率</strong>（先验分布属于贝叶斯学派引入的,
像L1, L2正则化就是对参数引入 了拉普拉斯先验分布和高斯先验分布）,
而且最大后验估计要求的是 <span class="math inline">\(p(\theta \mid
X)\)</span></p>
<p>最大后验估计可以写成下面的形式: <span class="math display">\[
\operatorname{argmaxp}(\theta \mid X)=\operatorname{argmax} \frac{p(X
\mid \theta) p(\theta)}{p(X)}=\operatorname{argmax}\left(\prod_{x 1}^{x
n} p(x i \mid \theta)\right) p(\theta)
\]</span> 在求最大后验概率时, 可以忽略分母 <span class="math inline">\(p(x)\)</span>, 因为该值不影响对 <span class="math inline">\(\theta\)</span> 的估计。同样为了便于计算,
对两边取对数, 后验概率最大化就变成了: <span class="math display">\[
\operatorname{argmax}\left(\sum_{x 1}^{x n} \operatorname{logp}(x i \mid
\theta)+\log p(\theta)\right)
\]</span> <strong><font color="red">
最大后验估计不只是关注当前的样本的情况，还关注已经发生过的先验知识。在朴素贝叶斯中会有最大后验概率的应用，但并没有用上最大后验估计来求参数（因为朴素贝叶斯中的θ其实就是分类的类别）。</font></strong></p>
<p><strong>最大后验估计和最大似然估计的区别：</strong>最大后验估计允许我们把先验知识加入到估计模型中，<strong>这在样本很少的时候是很有用的（因此朴素贝叶斯在较少的样本下就能有很好的表现）</strong>，因为样本很少的时候我们的观测结果很可能出现偏差，此时先验知识会把估计的结果“拉”向先验，实际的预估结果将会在先验结果的两侧形成一个顶峰。通过调节先验分布的参数，比如beta分布的α，β，我们还可以调节把估计的结果“拉”向先验的幅度，α，β越大，这个顶峰越尖锐。这样的参数，我们叫做预估模型的“超参数”。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>贝叶斯分类器</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>生成式模型</tag>
        <tag>贝叶斯估计</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯分类器（4）EM算法</title>
    <url>/posts/1FJMY6C/</url>
    <content><![CDATA[<h2><span id="em期望最大-概率模型">EM——期望最大 [概率模型]</span></h2>
<p><strong>EM 算法通过引入隐含变量，使用
MLE（极大似然估计）进行迭代求解参数。通常引入隐含变量后会有两个参数，EM
算法首先会固定其中的第一个参数，然后使用 MLE
计算第二个变量值；接着通过固定第二个变量，再使用 MLE
估测第一个变量值，依次迭代，直至收敛到局部最优解。</strong></p>
<p><strong><font color="red"> EM 算法，全称 Expectation Maximization
Algorithm。期望最大算法是一种迭代算法，用于含有隐变量（Hidden
Variable）的概率参数模型的最大似然估计或极大后验概率估计。</font></strong></p>
<p>本文思路大致如下：先简要介绍其思想，然后举两个例子帮助大家理解，有了感性的认识后再进行严格的数学公式推导。</p>
<h3><span id="1-思想">1. 思想</span></h3>
<p>EM 算法的核心思想非常简单，分为两步：<strong>Expection-Step</strong>
和 <strong>Maximization-Step</strong>。<strong>E-Step
主要通过观察数据和现有模型来估计参数</strong>，然后用这个估计的参数值来计算似然函数的期望值；而
M-Step
是寻找似然函数最大化时对应的参数。由于算法会保证在每次迭代之后<strong>似然函数都会增加</strong>，所以函数最终会收敛。</p>
<p><font color="red"> <span class="math inline">\(E M\)</span>
算法一句话总结就是: <span class="math inline">\(E\)</span> 步固定 <span class="math inline">\(\theta\)</span> 优化 <span class="math inline">\(Q, M\)</span> 步固定 <span class="math inline">\(Q\)</span> 优化 <span class="math inline">\(\theta\)</span> 。</font></p>
<h3><span id="2-例子">2 例子</span></h3>
<h4><span id="21-例子-a">2.1 例子 A</span></h4>
<p>假设有两枚硬币 <span class="math inline">\(\mathrm{A}\)</span> 和
<span class="math inline">\(B\)</span>,
他们的随机抛郑的结果如下图所示:</p>
<p><img src="https://pic4.zhimg.com/80/v2-4e19d89b47e21cf284644b0576e9af0f_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>我们很容易估计出两枚硬币抛出正面的概率： <span class="math display">\[
\begin{aligned}
&amp; \theta_A=24 / 30=0.8 \\
&amp; \theta_B=9 / 20=0.45
\end{aligned}
\]</span> 现在我们加入隐变量, 抺去每轮投郑的硬币标记:</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221558453.jpg" alt="img" style="zoom:50%;"></p>
<p>碰到这种情况, 我们该如何估计 <span class="math inline">\(\theta_A\)</span> 和 <span class="math inline">\(\theta_B\)</span> 的值?</p>
<p>我们多了一个隐变量 <span class="math inline">\(Z=\left(z_1, z_2, z_3,
z_4, z_5\right)\)</span>, 代表每一轮所使用的硬币,
我们需要知道每一轮抛郑所使用的硬币这样才能估计 <span class="math inline">\(\theta_A\)</span> 和 <span class="math inline">\(\theta_B\)</span> 的值, 但是估计隐变量 <span class="math inline">\(\mathrm{Z}\)</span> 我们又需要知道 <span class="math inline">\(\theta_A\)</span> 和 <span class="math inline">\(\theta_B\)</span> 的值,
才能用极大似然估计法去估计出 Z。这就陷入了一个鸡生蛋和蛋生鸡的问题。</p>
<p>其解决方法就是先随机初始化 <span class="math inline">\(\theta_A\)</span> 和 <span class="math inline">\(\theta_B\)</span>, 然后用去估计 <span class="math inline">\(Z\)</span>, 然后基于 <span class="math inline">\(Z\)</span> 按照最大似然概率去估计新的 <span class="math inline">\(\theta_A\)</span> 和 <span class="math inline">\(\theta_B\)</span> , 循环至收敛。</p>
<h5><span id="212-计算"><strong>2.1.2 计算</strong></span></h5>
<p>随机初始化 <span class="math inline">\(\theta_A=0.6\)</span> 和 <span class="math inline">\(\theta_B=0.5\)</span></p>
<p>对于第一轮来说, 如果是硬币 <span class="math inline">\(A\)</span>,
得出的 5 正 5 反的概率为: <span class="math inline">\(0.6^5 *
0.4^5\)</span>; 如果是硬币 <span class="math inline">\(B\)</span>,
得出的 5 正 5 反的概率为: <span class="math inline">\(0.5^5 *
0.5^5\)</span> 。我们可以算出使用是硬币 <span class="math inline">\(A\)</span> 和硬币 <span class="math inline">\(B\)</span> 的概率 分别为: <span class="math display">\[
\begin{aligned}
&amp; P_A=\frac{0.6^5 * 0.4^5}{\left(0.6^5 * 0.4^5\right)+\left(0.5^5 *
0.5^5\right)}=0.45 \\
&amp; P_B=\frac{0.5^5 * 0.5^5}{\left(0.6^5 * 0.4^5\right)+\left(0.5^5 *
0.5^5\right)}=0.55
\end{aligned}
\]</span> <img src="https://pic4.zhimg.com/80/v2-b325de65a5bcac196fc0939f346410d7_1440w.jpg" alt="img"></p>
<p>从期望的角度来看, 对于第一轮抛郑, 使用硬币 <span class="math inline">\(A\)</span> 的概率是 0.45 , 使用硬币 <span class="math inline">\(B\)</span> 的概率是 0.55。同理其他轮。这一
步我们实际上是估计出了 Z 的概率分布，这部就是 E-Step。</p>
<p>结合硬币 <span class="math inline">\(A\)</span> 的概率和上一张结果,
我们利用期望可以求出硬币 <span class="math inline">\(A\)</span> 和硬币
<span class="math inline">\(B\)</span> 的贡献。以第二轮硬币 <span class="math inline">\(A\)</span> 为例子, 计算方式为: <span class="math display">\[
\begin{aligned}
&amp; H: 0.80 * 9=7.2 \\
&amp; T: 0.80 * 1=0.8
\end{aligned}
\]</span> 于是我们可以得到：</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-9b6e8c50c0761c6ac19909c26e0a71d4_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>然后用极大似然估计来估计新的 <span class="math inline">\(\theta_A\)</span> 和 <span class="math inline">\(\theta_B\)</span> 。 <span class="math display">\[
\begin{aligned}
\theta_A &amp; =\frac{21.3}{21.3+8.6}=0.71 \\
\theta_B &amp; =\frac{11.7}{11.7+8.4}=0.58
\end{aligned}
\]</span></p>
<p>这步就对应了
M-Step，重新估计出了参数值。如此反复迭代，我们就可以算出最终的参数值。</p>
<p>上述讲解对应下图：</p>
<p><img src="https://pic3.zhimg.com/v2-6cac968d6500cbca58fc90347c288466_r.jpg" alt="preview" style="zoom:50%;"></p>
<h4><span id="22-例子-b">2.2 例子 B</span></h4>
<p>如果说例子 A 需要计算你可能没那么直观, 那就举更一个简单的例子:</p>
<p>现在一个班里有 50 个男生和 50
个女生，且男女生分开。我们假定男生的身高服从正态分布： <span class="math inline">\(N\left(\mu_1, \sigma_1^2\right)\)</span> ,
女生的身高则服从另一个正态分布： <span class="math inline">\(N\left(\mu_2, \sigma_2^2\right)\)</span>
。这时候我们可以用 极大似然法 (MLE) , 分别通过这 50 个男生和 50
个女生的样本来估计这两个正态分布的参数。</p>
<p>但现在我们让情况复杂一点, 就是这 50 个男生和 50
个女生混在一起了。我们拥有 100 个人的身高数据, 却不知 道这 100
个人每一个是男生还是女生。</p>
<p>这时候情况就有点箩尬, 因为通常来说,
我们只有知道了精确的男女身高的正态分布参数我们才能知道每一个人更
有可能是男生还是女生。但从另一方面去考量,
我们只有知道了每个人是男生还是女生才能尽可能准确地估计男女
各自身高的正态分布的参数。</p>
<p>这个时候有人就想到我们必须从某一点开始,
并用迭代的办法去解决这个问题：<strong>我们先设定男生身高和女生身高分
布的几个参数（初始值）, 然后根据这些参数去判断每一个样本
(人）是男生还是女生, 之后根据标注后的样本再
反过来重新估计参数。之后再多次重复这个过程，直至稳定。这个算法也就是 EM
算法。</strong></p>
<h3><span id="3-推导">3. 推导</span></h3>
<p>给定数据集, 假设样本间相互独立, 我们想要拟合模型 <span class="math inline">\(p(x ; \theta)\)</span>
到数据的参数。根据分布我们可以 得到如下似然函数: <span class="math display">\[
\begin{aligned}
L(\theta) &amp; =\sum_{i=1}^n \log p\left(x_i ; \theta\right) \\
&amp; =\sum_{i=1}^n \log \sum_z p\left(x_i, z ; \theta\right)
\end{aligned}
\]</span></p>
<p>第一步是<strong>对极大似然函数取对数</strong>，第二步是对每个样本的每个可能的类别
z 求<strong>联合概率分布之和</strong>。如果这个 z
是已知的数，那么使用极大似然法会很容易。但如果 z 是隐变量，我们就需要用
EM
算法来求。<strong>事实上，隐变量估计问题也可以通过梯度下降等优化算法，但事实由于求和项将随着隐变量的数目以指数级上升，会给梯度计算带来麻烦；而
EM 算法则可看作一种非梯度优化方法。</strong></p>
<h4><span id="31-求解含有隐变量的概率模型">3.1 求解含有隐变量的概率模型</span></h4>
<p>为了求解含有隐变量 <span class="math inline">\(z\)</span> 的概率模型
<span class="math inline">\(\hat{\theta}=\underset{\theta}{\arg \max }
\sum_{i=1}^m \log \sum_{z^{(i)}} p\left(x^{(i)}, z^{(i)} ;
\theta\right)\)</span> 需要一些特殊的技巧, 通过引入隐变量<span class="math inline">\(z^{(i)}\)</span> 的概率分布为 <span class="math inline">\(Q_i\left(z^{(i)}\right)\)</span>, 因为 <span class="math inline">\(\log (x)\)</span>
是凹函数故结合凹函数形式下的詹森不等式进行放缩处理 <span class="math display">\[
\begin{aligned}
\sum_{i=1}^m \log \sum_{z^{(i)}} p\left(x^{(i)}, z^{(i)} ; \theta\right)
&amp; =\sum_{i=1}^m \log \sum_{z^{(i)}} Q_i\left(z^{(i)}\right)
\frac{p\left(x^{(i)}, z^{(i)} ; \theta\right)}{Q_i\left(z^{(i)}\right)}
\\
&amp; =\sum_{i=1}^m \log \mathbb{E}\left(\frac{p\left(x^{(i)}, z^{(i)} ;
\theta\right)}{Q_i\left(z^{(i)}\right)}\right) \\
&amp; \left.\geq \sum_{i=1}^m \mathbb{E}\left[\log \frac{p\left(x^{(i)},
z^{(i)} ; \theta\right)}{Q_i\left(z^{(i)}\right)}\right)\right] \\
&amp; =\sum_{i=1}^m \sum_{z^{(i)}} Q_i\left(z^{(i)}\right) \log
\frac{p\left(x^{(i)}, z^{(i)} ; \theta\right)}{Q_i\left(z^{(i)}\right)}
\end{aligned}
\]</span> 其中由概率分布的充要条件 <span class="math inline">\(\sum_{z^{(i)}} Q_i\left(z^{(i)}\right)=1 、
Q_i\left(z^{(i)}\right) \geq 0\)</span> 可看成下述关于 <span class="math inline">\(z\)</span> 函数分布列的形式:</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221618376.jpg" alt="img" style="zoom:50%;"></p>
<p>这个过程可以看作是对 <span class="math inline">\(\mathcal{L}(\theta)\)</span> 求了下界, 假设 <span class="math inline">\(\theta\)</span> 已经给定那么 <span class="math inline">\(\mathcal{L}(\theta)\)</span> 的值就取决于 <span class="math inline">\(Q_i\left(z^{(i)}\right)\)</span> 和 <span class="math inline">\(p\left(x^{(i)}, z^{(i)}\right)\)</span> 了, 因
此可以通过调整这两个概率使下界不断上升, 以逼近 <span class="math inline">\(\mathcal{L}(\theta)\)</span> 的真实值,
当不等式变成等式时说明调整后的概率能够 等价于 <span class="math inline">\(\mathcal{L}(\theta)\)</span>
，所以必须找到使得等式成立的条件, 即寻找 <span class="math display">\[
\left.\mathbb{E}\left[\log \frac{p\left(x^{(i)}, z^{(i)} ;
\theta\right)}{Q_i\left(z^{(i)}\right)}\right)\right]=\log
\mathbb{E}\left[\frac{p\left(x^{(i)}, z^{(i)} ;
\theta\right)}{Q_i\left(z^{(i)}\right)}\right]
\]</span> 由期望得性质可知当 <span class="math display">\[
\frac{p\left(x^{(i)}, z^{(i)} ;
\theta\right)}{Q_i\left(z^{(i)}\right)}=C, \quad C \in \mathbb{R}
\quad(*)
\]</span> 等式成立，对上述等式进行变形处理可得 <span class="math display">\[
\begin{aligned}
&amp; p\left(x^{(i)}, z^{(i)} ; \theta\right)=C Q_i\left(z^{(i)}\right)
\\
&amp; \Leftrightarrow \sum_{z^{(i)}} p\left(x^{(i)}, z^{(i)} ;
\theta\right)=C \sum_{z^{(i)}} Q_i\left(z^{(i)}\right)=C \\
&amp; \Leftrightarrow \sum_{z^{(i)}} p\left(x^{(i)}, z^{(i)} ;
\theta\right)=C
\end{aligned}
\]</span> 把 <span class="math inline">\((* *)\)</span> 式带入 <span class="math inline">\((*)\)</span> 化简可知 <span class="math display">\[
\begin{aligned}
Q_i\left(z^{(i)}\right) &amp; =\frac{p\left(x^{(i)}, z^{(i)} ;
\theta\right)}{\sum_{z^{(i)}} p\left(x^{(i)}, z^{(i)} ; \theta\right)}
\\
&amp; =\frac{p\left(x^{(i)}, z^{(i)} ; \theta\right)}{p\left(x^{(i)} ;
\theta\right)} \\
&amp; =p\left(z^{(i)} \mid x^{(i)} ; \theta\right)
\end{aligned}
\]</span> 至此, 可以推出在固定参数 <span class="math inline">\(\theta\)</span> 后, <span class="math inline">\(Q_i\left(z^{(i)}\right)\)</span>
的计算公式就是后验概率, 解决了 <span class="math inline">\(Q_i\left(z^{(i)}\right)\)</span>
如何选择得问题。这一步 称为 <span class="math inline">\(E\)</span> 步,
建立 <span class="math inline">\(\mathcal{L}(\theta)\)</span> 得下界;
接下来得 <span class="math inline">\(M\)</span> 步, 就是在给定 <span class="math inline">\(Q_i\left(z^{(i)}\right)\)</span> 后, 调整 <span class="math inline">\(\theta\)</span> 去极大化 <span class="math inline">\(\mathcal{L}(\theta)\)</span> 的下界即 <span class="math display">\[
\begin{aligned}
&amp; \underset{\theta}{\arg \max } \sum_{i=1}^m \log p\left(x^{(i)} ;
\theta\right) \\
&amp; \Leftrightarrow \underset{\theta}{\arg \max } \sum_{i=1}^m
\sum_{z^{(i)}} Q_i\left(z^{(i)}\right) \log \frac{p\left(x^{(i)},
z^{(i)} ; \theta\right)}{Q_i\left(z^{(i)}\right)} \\
&amp; \Leftrightarrow \underset{\theta}{\arg \max } \sum_{i=1}^m
\sum_{z^{(i)}} Q_i\left(z^{(i)}\right)\left[\log p\left(x^{(i)}, z^{(i)}
; \theta\right)-\log Q_i\left(z^{(i)}\right)\right] \\
&amp; \Leftrightarrow \underset{\theta}{\arg \max } \sum_{i=1}^m
\sum_{z^{(i)}} Q_i\left(z^{(i)}\right) \log p\left(x^{(i)}, z^{(i)} ;
\theta\right)
\end{aligned}
\]</span> 因此EM算法的迭代形式为：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221619542.jpg" alt="img" style="zoom:50%;"></p>
<p><img src="https://pic3.zhimg.com/80/v2-2f7fc5ca144d2f85f14d46e88055dd86_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>这张图的意思就是: 首先我们固定 <span class="math inline">\(\theta\)</span>, 调整 <span class="math inline">\(Q(z)\)</span> 使下界 <span class="math inline">\(J(z, Q)\)</span> 上升至与 <span class="math inline">\(L(\theta)\)</span> 在此点 <span class="math inline">\(\theta\)</span> 处相等 (绿色曲线到 蓝色曲线) ,
然后固定 <span class="math inline">\(Q(z)\)</span>, 调整 <span class="math inline">\(\theta\)</span> 使下界 <span class="math inline">\(J(z, Q)\)</span> 达到最大值 <span class="math inline">\(\left(\theta_t\right.\)</span> 到 <span class="math inline">\(\left.\theta_{t+1}\right)\)</span> ，然后再固定
<span class="math inline">\(\theta\)</span>, 调整 <span class="math inline">\(Q(z)\)</span> , 一直到收敛到似然函数 <span class="math inline">\(L(\theta)\)</span> 的最大值处的 <span class="math inline">\(\theta\)</span> 。</p>
<p><strong><font color="red"> EM 算法通过引入隐含变量，使用
MLE（极大似然估计）进行迭代求解参数。通常引入隐含变量后会有两个参数，EM
算法首先会固定其中的第一个参数，然后使用 MLE
计算第二个变量值；接着通过固定第二个变量，再使用 MLE
估测第一个变量值，依次迭代，直至收敛到局部最优解。</font></strong></p>
<h4><span id="32-em算法的收敛性">3.2 EM算法的收敛性</span></h4>
<p>不妨假设 <span class="math inline">\(\theta^{(k)}\)</span> 和 <span class="math inline">\(\theta^{(k+1)}\)</span> 是EM算法第 <span class="math inline">\(k\)</span> 次迭代和第 <span class="math inline">\(k+1\)</span> 次迭代的结果, 要确保 <span class="math inline">\(E M\)</span> 算法收敛那么等价于证明 <span class="math inline">\(\mathcal{L}\left(\theta^{(k)}\right) \leq
\mathcal{L}\left(\theta^{(k+1)}\right)\)</span>
也就是说极大似然估计单调增加,
那么算法最终会迭代到极大似然估计的最大值。在选定 <span class="math inline">\(\theta^{(k)}\)</span> 后可以得到 <span class="math inline">\(E\)</span> 步 <span class="math inline">\(Q_i^{(k)}\left(z^{(i)}\right)=p\left(z^{(i)} \mid
x^{(i)} ; \theta^{(k)}\right)\)</span>, 这一步保证了在给定 <span class="math inline">\(\theta^{(k)}\)</span> 时, 詹森不等式中的等式成立即
<span class="math inline">\(\mathcal{L}\left(\theta^{(k)}\right)=\sum_{i=1}^m
\sum_{z^{(i)}} Q_i^{(k)}\left(z^{(i)}\right) \log \frac{p\left(x^{(i)},
z^{(i)} ; \theta^{(k)}\right)}{Q_i\left(z^{(i)}\right)}\)</span></p>
<p>然后再进行 <span class="math inline">\(M\)</span> 步, 固定 <span class="math inline">\(Q_i^{(k)}\left(z^{(i)}\right)\)</span> 并将 <span class="math inline">\(\theta^{(k)}\)</span> 视作变量, 对上式 <span class="math inline">\(\mathcal{L}\left(\theta^{(k)}\right)\)</span>
求导后得到 <span class="math inline">\(\theta^{(k+1)}\)</span>
因此有如下式子成立 <span class="math display">\[
\begin{aligned}
\mathcal{L}\left(\theta^{(k)}\right) &amp; =\sum_{i=1}^m \sum_{z^{(i)}}
Q_i^{(k)}\left(z^{(i)}\right) \log \frac{p\left(x^{(i)}, z^{(i)} ;
\theta^{(k)}\right)}{Q_i\left(z^{(i)}\right)} \\
&amp; \leq \sum_{i=1}^m \sum_{z^{(i)}} Q_i^{(k)}\left(z^{(i)}\right)
\log \frac{p\left(x^{(i)}, z^{(i)} ;
\theta^{(k)}\right)}{Q_i\left(z^{(i)}\right)} \\
&amp; \leq \mathcal{L}\left(\theta^{(k+1)}\right)
\end{aligned}
\]</span> 首先 (a) 式是前面 <span class="math inline">\(E\)</span>
步所保证詹森不等式中的等式成立的条件, (a) 到 (b) 是 <span class="math inline">\(M\)</span> 步的定义, (b) 到 (c) 对任意 参数都成立,
而其等式的条件是固定 <span class="math inline">\(\theta\)</span>
并调整好 <span class="math inline">\(Q\)</span> 时成立, <span class="math inline">\((b)\)</span> 到 <span class="math inline">\((c)\)</span> 只是固定 <span class="math inline">\(Q\)</span> 调整 <span class="math inline">\(\theta\)</span>, 在得到 <span class="math inline">\(\theta^{(k+1)}\)</span> 时, 只是最大化 <span class="math inline">\(\mathcal{L}\left(\theta^{(k)}\right)\)</span>,
也就是 <span class="math inline">\(\mathcal{L}\left(\theta^{(k+1)}\right)\)</span>
的一个下界而没有使等式成立。</p>
<h3><span id="4-另一种理解">4. 另一种理解</span></h3>
<p>坐标上升法（Coordinate ascent）：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221621244.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>途中直线为迭代优化路径，因为每次只优化一个变量，所以可以看到它没走一步都是平行与坐标轴的。</p>
<p>EM 算法类似于坐标上升法，E 步：固定参数，优化 Q；M 步：固定
Q，优化参数。交替将极值推向最大。</p>
<h3><span id="5-应用">5. 应用</span></h3>
<p>EM 的应用有很多，比如、混合高斯模型、聚类、HMM 等等。其中 <strong>EM
在 K-means 中的用处</strong>，我将在介绍 K-means 中的给出。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ol type="1">
<li><p><a href="https://www.zhihu.com/question/27976634">怎么通俗易懂地解释 EM
算法并且举个例子?</a></p></li>
<li><p><a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/zouxy09/article/details/8537620">从最大似然到
EM 算法浅解</a></p></li>
<li><h5><span id="em算法"></span></h5></li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>贝叶斯分类器</category>
      </categories>
      <tags>
        <tag>生成式模型、贝叶斯</tag>
      </tags>
  </entry>
  <entry>
    <title>聚类（3）HDBSCAN</title>
    <url>/posts/X8CSWX/</url>
    <content><![CDATA[<h3><span id="一-hdbscan聚类">一、HDBSCAN聚类</span></h3>
<p><strong>HDBSCAN 是由 Campello、Moulavi 和 Sander
开发的聚类算法。它通过将 DBSCAN
转换为层次聚类算法，然后用一种稳定的聚类技术提取出一个扁平的聚类来扩展
DBSCAN</strong>。这篇文章的目标是让你大致了解这个算法的工作原理及其背后的动机。与
HDBSCAN 的原论文不一样，我们这里将不将 DBSCAN
进行对照分析。作者这里更倾向将这算法类比成一种扁平聚类提取方法（ Robust
Single Linkage ）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets <span class="keyword">as</span> data</span><br><span class="line">%matplotlib inline</span><br><span class="line">sns.set_context(<span class="string">&#x27;poster&#x27;</span>)</span><br><span class="line">sns.set_style(<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">sns.set_color_codes()</span><br><span class="line">plot_kwds = &#123;<span class="string">&#x27;alpha&#x27;</span> : <span class="number">0.5</span>, <span class="string">&#x27;s&#x27;</span> : <span class="number">80</span>, <span class="string">&#x27;linewidths&#x27;</span>:<span class="number">0</span>&#125;</span><br><span class="line"></span><br><span class="line">moons, _ = data.make_moons(n_samples=<span class="number">50</span>, noise=<span class="number">0.05</span>)</span><br><span class="line">blobs, _ = data.make_blobs(n_samples=<span class="number">50</span>, centers=[(-<span class="number">0.75</span>,<span class="number">2.25</span>), (<span class="number">1.0</span>, <span class="number">2.0</span>)], cluster_std=<span class="number">0.25</span>)</span><br><span class="line">test_data = np.vstack([moons, blobs])</span><br><span class="line">plt.scatter(test_data.T[<span class="number">0</span>], test_data.T[<span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, **plot_kwds)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hdbscan</span><br><span class="line">clusterer = hdbscan.HDBSCAN(min_cluster_size=<span class="number">5</span>, gen_min_span_tree=<span class="literal">True</span>)</span><br><span class="line">clusterer.fit(test_data)</span><br></pre></td></tr></table></figure>
<p><strong>现在我们已经对数据聚类完了——但实际发生了什么我们还不知道。我们将拆解成下面5个步骤来进行分析：</strong></p>
<ol type="1">
<li>根据 密度/稀疏度 进行<strong>空间转换</strong>。</li>
<li>构建基于加权距离图的最小生成树。</li>
<li>构建组件之间的层次簇结构。</li>
<li>用最小簇大小压缩层次聚类。</li>
<li>利用压缩好的生成树进行分类。</li>
</ol>
<h4><span id="11-空间转换">1.1 空间转换</span></h4>
<p><strong>聚类时我们希望在稀疏带噪声的数据中找到密度更高的族类——噪声的假设很重要</strong>：因为在真实情况下，数据都比较复杂，会有异常值的、缺失的数据和噪声等情况。算法的核心是单链聚类，它对噪声非常敏感：如果噪声数据点放在两个岛屿之间，可能就会将它们连在一起（也就是本来是两个族类的被分成一个）。显然，我们希望我们的算法对噪声具有鲁棒性，因此我们需要在运行单链算法之前找到一种方法来减少噪声。（作者用岛屿来比喻族类，海洋来表示噪声，下面“海洋”和“岛屿”代表这个意思。）</p>
<p><strong>我们要如何在不进行聚类的情况下找出“海洋”和“岛屿”？</strong>只要我们能够估算出样本集的密度，我们就可以认为密度较低的点都是“海洋”。要注意的是这里的目标不是完全区分出“海洋”和“岛屿”——现在只是聚类的初始步骤，并不是最终的输出——现在只是为了使我们的聚类中心对噪声更加鲁棒。因此，要识别出“海洋”的话，我们可以降低海平面（也就是加大容错范围）。出于实际目的，这意味着使每个“海洋”之间以及“海洋”与“岛屿”之间的距离会增加。</p>
<p>当然这只是直觉。它在实际中是如何工作的？我们需要一个计算量少的密度估计方式，简单到只要计算
k 个最近邻点的距离就可以。<strong><font color="red">
我们可以直接从一个距离矩阵（不管怎样后面都要生成的）中地读取到这个距离；或者，如果我们的指标支持（并且维度较低），用
<a href="https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/neighbors.html%23k-d-tree">kd-trees</a>
来做这种检索就很适合。</font></strong>下面正式将点 x 的参数 k
定义为<strong>核心距离, 并表示为 <span class="math inline">\(\operatorname{core}_k(x)\)</span> (与DBSCAN、LOF
和 HDBSCAN 文献一样）。现在我们需要一种降维方法来拉开点之
间的距离（相对高维距离）。简单的方法是定义一种新距离公式，我们将其称为（与论文一样)相互可达距离
(mutual reachability distance)</strong>。相互可达距离的定义如下: <span class="math display">\[
d_{\mathrm{mreach}-k}(a, b)=\max \left\{\operatorname{core}_k(a),
\operatorname{core}_k(b), d(a, b)\right\}
\]</span> <strong>其中 d(a,b) 是 a 和 b
之间的原始距离</strong>。在这个度量下，密集点（具有低核心距离）之间的距离保持不变，但稀疏的点与其他点的距离被拉远到用core距离来计算。这有效地“降低了海平面”，减少稀疏的“海”点，同时使“陆地”保持原状。需要注意的是，显然
k 取值很关键；较大的 k
值将更多的点圈到“海”中。下面用图片来解析更容易理解，先让k=5。然后对于给定的点，我们可以为核心距离绘制一个圆刚好圈到第六个临近点（包括点本身），如下所示：</p>
<p><img src="https://pic2.zhimg.com/80/v2-dbf4559853b0d81f1c5ae2205a7b97a9_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p><strong>再选择另一个点</strong>，进行同样的操作，这次选到另一组临近点集合（其中一些点可能是上一组的临近点）。</p>
<p><img src="https://pic3.zhimg.com/80/v2-308c1bb09e8f779232aac217bee2507e_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p>我们再选一个点再做一遍，得到第三组临近点。</p>
<p><img src="https://pic4.zhimg.com/80/v2-0e0e83ecf594b202cea6d3c208e45f0f_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>如果我们现在想知道蓝绿两组之间的相互可达距离，我们可以像下图，先画一个箭头连接蓝绿两个圆心：它穿过蓝色圆心，但不穿过绿色圆圈——绿色的核心距离大于蓝色和绿色之间的距离。<strong>因此，我们认为蓝色和绿色之间的相互可达距离更大——也就是绿色圆圈的半径（如果我们将一端设在绿色点上，则最容易想象）。</strong></p>
<p>实际上，有<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1506.06422v2.pdf">基础理论</a>可以证明<strong>相互可达距离</strong>作为一种变换，在允许单链接聚类的情况下，更接近层次水平上的真实密度分布。</p>
<h4><span id="12-构建最小生成树"><strong>1.2 构建最小生成树</strong></span></h4>
<p><strong>为了从密集的数据集上找到“岛屿”，现在我们有了新的指标：相互可达性</strong>。当然密集区是相对的，不同的“岛屿”可能会有不同的密度。<strong><font color="red">
理论上，我们要做的是：将数据当成是一个加权图，以数据点作为顶点，任意两点之间的边的权重等于这些点的相互可达距离。</font></strong></p>
<p>现在考虑一个阈值，一开始很高，然后逐渐变小。丢弃权重高于该阈值的任何边。我们删除边的同时，连接的组件从图里断开。最终，我们将拥有不同阈值级别的连接元件（从完全连接到完全断开）的层次结构。</p>
<p>实际当中，这样操纵非常耗时：有 <a href="https://zhuanlan.zhihu.com/p/412918565/edit#">n^2</a>
条边，我们不想多次计算连通组件算法。正确的做法是找到最小的边集，从这个集合中删除任何边都会导致组件的连接断开。但是我们还需要找到更多这样的边，使得找不到更小的边来连接组件。幸运的是，图论为我们提供了这样的东西：<strong>图的最小生成树</strong>。</p>
<p>我们可以<strong>通过 Prim
的算法非常有效地构建最小生成树</strong>——我们一次构建一条边，每次都把当前最小权重的边去连接一个尚未加入到树中的节点。可以看到下面HDBSCAN构造的树
；请注意，这是相互可达距离的最小生成树，与图中的纯距离不同。在这种情况下，我们的
k 值为 5。 在这个例子中，存在一种更快的方法，例如用 <strong>Dual Tree
Boruvka 来构建最小生成树。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">clusterer.minimum_spanning_tree_.plot(edge_cmap=<span class="string">&#x27;viridis&#x27;</span>, </span><br><span class="line">                                      edge_alpha=<span class="number">0.6</span>, </span><br><span class="line">                                      node_size=<span class="number">80</span>, </span><br><span class="line">                                      edge_linewidth=<span class="number">2</span>)   </span><br></pre></td></tr></table></figure>
<p><img src="https://pic2.zhimg.com/80/v2-a4b387ac9c43b1f681589529c82fe68d_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="13-构建层次聚类">1.3 <strong>构建层次聚类</strong></span></h4>
<p><strong>给定最小生成树，下一步是将其转换为层次结构的组件</strong>。这最容易以相反的顺序完成：按距离（按递增顺序）对树的边进行排序，然后迭代，为每条边新建一个合并后的簇。这里唯一困难是识别每条边将连接在哪两个簇上，但这通过联合查找数据结构很容易。我们可以将结果视为树状图，如下所示：</p>
<p><img src="https://pic1.zhimg.com/80/v2-33a8cb27ae3ea0009e1ad77b438cf458_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>这图可以告诉我们这个鲁棒的单一链接会在哪挺下来。我们想知道；层次结构结构的聚类虽好，但我们想要的是一个扁平的聚类。我们可以通过在上图中画一条水平线并选择它穿过的聚类，来做到这一点。这实际上是
DBSCAN
里用到的操作（将只能切割成单一集群的作为噪声）。<strong>问题是，我们怎么知道在哪里画这条线？
DBSCAN 只是把它作为一个（非常不直观的）参数</strong>。</p>
<p>更糟糕的是，我们真的要用来处理可变密度的聚类，并希望任何切割线都是通过相互可达距离选出来的，并且今后固定在一个密度水平上。理想情况下，我们希望能够在不同的地方切割树，来选择我们的聚类。这是
HDBSCAN 下一步开始的地方，并与鲁棒的单一链接产生差异。</p>
<h4><span id="14-压缩聚类树">1.4 <strong>压缩聚类树</strong></span></h4>
<p>压缩聚类的第一步是将庞大而复杂的聚类层次结构压缩成一个较小的树，每个节点附加更多的数据。正如您在上面的层次结构中看到的那样，簇分裂通常是从一个簇中分离出一个或两个点；这就是关键点——与其将其视为一个聚类分裂成两个新聚类，不如将其视为一个“有损”的单个持久聚类。</p>
<p><strong>为了具体化，我们需要一个最小簇大小的概念，作为 HDBSCAN
的参数</strong>。一旦我们有了最小簇大小的值，我们现在可以遍历层次结构，并在每次拆分时询问拆分创建的新簇之一是否比最小簇大小少。如果我们的点数少于最小簇大小，我们将其声明为“离群点”，并让较大的簇保留父级的簇标识，标记哪些点“离群”
，以及需要的距离值。另一方面，如果要分裂成两个簇，每个簇至少与最小簇大小一样大才能进行分割。</p>
<p>在遍历整个层次结构并执行此操作后，我们最终得到了一个更小节点的树，每个节点都有关于该节点处的簇大小如何随距离变化而减小的数据。我们可以将其可视化为类似于上面的树状图——同样，我们可以让线的宽度代表簇中的点数。对于我们使用最小簇大小
5 的数据，结果如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">clusterer.condensed_tree_.plot()</span><br></pre></td></tr></table></figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221714234.jpeg" alt="img" style="zoom:50%;"></p>
<p>这更容易观察和处理，尤其像我们当前测试数据一样简单的时候。然而，我们仍然需要挑出选聚类来用作平面聚类。上面的图应该会给你启发。</p>
<h4><span id="15-聚类抽取">1.5 <strong>聚类抽取</strong></span></h4>
<p>直觉上, 我们希望选择的簇持久且具有更长的生命周期;
短暂的簇最终可能只是单一链接方法的产 物。可以再看看之前的图, 我们可以说,
我们想要选择图中具有最大墨水面积的那些簇。为了进行 平面聚类,
我们需要添加进一步的要求：即如果您选择了一个簇,
则您不能选择它的任何它子簇。 当然我们需要明确下HDBSCAN实际的算法。首先,
我们需要将它转成一个具体的算法。首先, 我
们需要一个与距离不同的度量来衡量簇的持久性;</p>
<p>我们定义 <span class="math inline">\(\lambda=\frac{1}{\text {
distance }}\)</span> 。对于给定的簇, 我们可 以定义值 <span class="math inline">\(\lambda_{b i r t h}\)</span> and <span class="math inline">\(\lambda_{\text {death }}\)</span>
分别是对应笶分裂并成为自己的笟时的 <span class="math inline">\(\lambda\)</span> ，以及簇分裂成更小的簇时的 <span class="math inline">\(\lambda\)</span> 值 (如果有）。反过来,
对于给定的簇, 对于该簇中的每个点 <span class="math inline">\(\mathrm{p}\)</span>, 我们可以将值 <span class="math inline">\(\lambda_p\)</span> 定义为该点“离 群"的 lambda 值,
这是一个介于 <span class="math inline">\(\lambda_{b i r t h}\)</span> 和
<span class="math inline">\(\lambda_{\text {death }}\)</span> 之间的值,
因为离群点要么在簇生命周期的某个 时刻离开簇,
或者在簇分裂成两个较小的簇时离开簇。现在, 对于每个簇计算稳定性为 <span class="math display">\[
\sum_{p \in \text { cluster }}\left(\lambda_p-\lambda_{\text {birth
}}\right)
\]</span>
将所有叶节点声明为选定的簇。现在遍历树（反向拓扑排序）。如果子簇的稳定性之和大于笶的稳
定性, 那么我们将簇的稳定性设置为子笶的稳定性之和。另一方面,
如果簇的稳定性大于其子笶的 总和, 则我们将簇固定为一个簇,
并取消选择其所有子簇。一旦我们到达根节点, 我们将当前选定
的簇集称为我们的平面聚类并返回它。</p>
<p>好的, 解析了这么多,
但它实际上只是根据前面我们提到的“选择图中总墨水面积最大的簇"规则来
进行选择。我们可以通过这个算法在压缩树树图中选择簇,
最终会的到你想要的:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">clusterer.condensed_tree_.plot(select_clusters=<span class="literal">True</span>, selection_palette=sns.color_palette())</span><br></pre></td></tr></table></figure>
<p><strong>现在我们有了聚类, 用 sklearn API
可以很容易给每个簇打上标签</strong>。任何不在所选聚类中的点都只是一个噪声点（标为
-1）。不过, 我们可以做更多：对于每个簇, 我们有该笶中每个点 <span class="math inline">\(p\)</span> 的 <span class="math inline">\(\lambda
\_p\)</span> 值; 如果我们简单地将这些值归一化（它们的取值范围从 0 到
1），那么我们就可以衡量簇中每个 点的属于该笶的概率。</p>
<p>hdbscan
库将此作为分类对象的probabilities_属性返回。有了标签和对应的概率，我们就可以画个图,
不同的颜色代表不同的分类, 并根据概率大小降低该颜色的饱和度
（离群的点为纯灰色）。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221716022.jpeg" alt="img" style="zoom:50%;"></p>
<p>这就是 HDBSCAN
的工作原理。这可能看起来有些复杂——算法有相当多的部分——但实际上每个部分都非常简单，并可以容易掌握。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ol type="1">
<li><strong>图解HDBSCANS - Mr.g的文章</strong> - 知乎
https://zhuanlan.zhihu.com/p/412918565</li>
<li><font color="blue">原文: <a href="https://link.zhihu.com/?target=https%3A//nbviewer.jupyter.org/github/scikit-learn-contrib/hdbscan/blob/master/notebooks/How%20HDBSCAN%20Works.ipynb">How
HDBSCAN works</a></font></li>
<li>聚类算法(Clustering Algorithms)之层次聚类(Hierarchical Clustering) -
小玉的文章 - 知乎 https://zhuanlan.zhihu.com/p/363879425</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>聚类</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>聚类</tag>
        <tag>HDBSCAN</tag>
      </tags>
  </entry>
  <entry>
    <title>聚类（1）K-means</title>
    <url>/posts/2DSARR9/</url>
    <content><![CDATA[<h3><span id="一-k-means">一、K-means</span></h3>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211326577.jpg" alt="【机器学习】K-means（非常详细）" style="zoom:51%;"></p>
<p>K-means 聚类的迭代算法实际上是 EM 算法。EM
算法解决的是在概率模型中含有无法观测的隐含变量情况下的参数估计问题。在
K-means
中的隐变量是每个类别所属类别。k近邻法中，当<strong>训练集</strong>、<strong>距离度量</strong>、<strong>K值</strong>以及<strong>分类决策规则</strong>确定后，对于任何一个新的输入实例，它所属的类唯一地确定。这相当于根据上述要素将特征空间划分为一些子空间，确定子空间里的每个点所属的类。</p>
<p><strong>K-均值是一个迭代算法，假设我们想要将数据聚类成 n
个组，其方法为:</strong></p>
<ul>
<li>首先选择𝐾个<strong>随机</strong>的点，称为<strong>聚类中心</strong>（cluster
centroids）；</li>
<li>对于数据集中的每一个数据，按照<strong>距离𝐾个中心点的距离</strong>，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类。</li>
<li>计算每一个组的平均值，将该组所<strong>关联的中心点移动到平均值</strong>的位置。</li>
<li>重复步骤，直至中心点不再变化。</li>
</ul>
<p>K-均值算法也可以很便利地用于将数据分为许多不同组，即使在没有非常明显区分的组群的情况下也可以。下图所示的数据集包含身高和体重两项特征构成的，利用
K-均值算法将数据分为三类，用于帮助确定将要生产的 T-恤衫的三种尺寸。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221641204.jpeg" alt="img" style="zoom: 50%;"></p>
<h4><span id="11-损失函数">1.1 损失函数</span></h4>
<p><strong>K-均值最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和</strong>，因此
<strong>K-均值的代价函数（又称畸变函数 Distortion
function）为</strong>： <span class="math display">\[
J\left(c^{(1)}, c^{(2)}, \ldots, c^{(m)}, u_1, \ldots,
u_k\right)=\frac{1}{m} \sum_{i=1}^m\left\|X^{(1)}-u_{c^{(i)}}\right\|^2
\]</span> 其中 <span class="math inline">\(u_{c^{(i)}}\)</span> 代表与
<span class="math inline">\(x^{(i)}\)</span>
最近的聚类中心点。我们的的优化目标便是找出使得代价函数最小的 <span class="math inline">\(c^{(1)}, c^{(2)}, \ldots, c^{(m)}\)</span> 和
<span class="math inline">\(u_1, u_2, \ldots, u_k\)</span> 。</p>
<h4><span id="12-k值的选择-肘部法则">1.2 k值的选择 【肘部法则】</span></h4>
<p>在运行
K-均值算法的之前，我们首先要随机初始化所有的聚类中心点，下面介绍怎样做：</p>
<ol type="1">
<li>我们应该选择𝐾 &lt;
𝑚，即聚类中心点的个数要小于所有训练集实例的数量。</li>
<li>随机选择𝐾个训练实例，然后令𝐾个聚类中心分别与这𝐾个训练实例相等K-均值的一个问题在于，它有可能会<strong>停留在一个局部最小值</strong>处，而这取决于初始化的情况。</li>
</ol>
<p>为了解决这个问题，我们通常需要多次运行
K-均值算法，每一次都重新进行随机初始化，最后再比较多次运行
K-均值的结果，选择代价函数最小的结果。这种方法在𝐾较小的时候（2--10）还是可行的，<strong>但是如果𝐾较大，这么做也可能不会有明显地改善。</strong></p>
<p>没有所谓最好的选择聚类数的方法，通常是需要根据不同的问题，人工进行选择的。选择的时候思考我们运用
K-均值算法聚类的动机是什么。有一个可能会谈及的方法叫作<strong>“肘部法则”</strong>。关
于“肘部法则”，我们所需要做的是改变𝐾值，也就是聚类类别数目的总数。我们用一个聚类来运行
K
均值聚类方法。这就意味着，所有的数据都会分到一个聚类里，然后<strong>计算成本函数或者计算畸变函数</strong>𝐽。𝐾代表聚类数字。</p>
<p>[<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221641692.jpeg" alt="img"></p>
<p>我们可能会得到一条类似于这样的曲线。像一个人的肘部。这就是“肘部法则”所做的，让我们来看这样一个图，看起来就好像有一个很清楚的肘在那儿。你会发现这种模式，它的畸变值会迅速下降，从
1 到 2，从 2 到 3 之后，你会在 3
的时候达到一个肘点。在此之后，畸变值就下降的非常慢，看起来就像使用 3
个聚类来进行聚类是正确的，<strong>这是因为那个点是曲线的肘点，畸变值下降得很快，𝐾
= 3之后就下降得很慢，那么我们就选𝐾 =
3。</strong>当你应用“肘部法则”的时候，如果你得到了一个像上面这样的图，那么这将是一种用来选择聚类个数的合理方法。</p>
<h4><span id="13-knn与k-means区别">1.3 KNN与K-means区别？</span></h4>
<p>K最近邻(k-Nearest
Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。</p>
<h5><span id="区别">区别：</span></h5>
<table>
<colgroup>
<col style="width: 6%">
<col style="width: 46%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>KNN</th>
<th>K-Means</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>类别</td>
<td>1.KNN是<strong>分类</strong>算法 2.属于<strong>监督学习</strong>
3.训练数据集是带label的数据</td>
<td>1.K-Means是<strong>聚类</strong>算法
2.属于<strong>非监督学习</strong>
3.训练数据集是无label的数据，是杂乱无章的，经过聚类后变得有序，先无序，后有序。</td>
</tr>
<tr class="even">
<td>训练模式</td>
<td>没有明显的前期训练过程，属于memory based learning</td>
<td>有明显的前期训练过程</td>
</tr>
<tr class="odd">
<td>k值的含义</td>
<td>K的含义：一个样本x，对它进行分类，就从训练数据集中，<strong>在x附近找离它最近的K个数据点</strong>，这K个数据点，类别c占的个数最多，就把x的label设为c。</td>
<td>K的含义：<strong>K是人工固定好的数字，假设数据集合可以分为K个蔟</strong>，那么就利用训练数据来训练出这K个分类。</td>
</tr>
</tbody>
</table>
<h5><span id="相似点"><strong>相似点</strong>：</span></h5>
<p>都包含这样的过程，给定一个点，在数据集中找离它最近的点。即二者都用到了NN(Nears
Neighbor)算法思想。</p>
<h4><span id="14-k-means优缺点及改进">1.4 K-Means优缺点及改进</span></h4>
<p>k-means：在大数据的条件下，<strong>会耗费大量的时间和内存</strong>。
优化k-means的建议：</p>
<ol type="1">
<li><p>减少聚类的数目K。因为，每个样本都要跟类中心计算距离。</p></li>
<li><p>减少样本的特征维度。比如说，<strong>通过PCA等进行降维</strong>。</p></li>
<li><p>考察其他的聚类算法，通过选取toy数据，去测试不同聚类算法的性能。</p></li>
<li><p><strong>hadoop集群</strong>，K-means算法是很容易进行并行计算的。</p></li>
<li><p>算法可能找到局部最优的聚类，而不是全局最优的聚类。使用改进的二分k-means算法。</p>
<p>二分k-means算法：首先将整个数据集看成一个簇，然后进行一次k-means（k=2）算法将该簇一分为二，并计算每个簇的误差平方和，选择平方和最大的簇迭代上述过程再次一分为二，直至簇数达到用户指定的k为止，此时可以达到的全局最优。</p></li>
</ol>
<h3><span id="二-k-means的调优与改进">二、K - means的调优与改进</span></h3>
<p>针对 K-means
算法的缺点，我们可以有很多种调优方式：如<strong>数据预处理</strong>（去除异常点），<strong>合理选择
K 值</strong>，<strong>高维映射</strong>等。以下将简单介绍：</p>
<h4><span id="21-数据预处理">2.1 数据预处理</span></h4>
<p>K-means
的本质是基于欧式距离的数据划分算法，均值和方差大的维度将对数据的聚类产生决定性影响。所以<strong>未做归一化处理和统一单位的数据是无法直接参与运算和比较</strong>的。常见的数据预处理方式有：<strong>数据归一化，数据标准化</strong>。</p>
<p>此外，离群点或者噪声数据会对均值产生较大的影响，导致中心偏移，因此我们还需要对数据进行异常点检测。</p>
<h4><span id="22-合理选择-k-值">2.2 合理选择 K 值</span></h4>
<p>K 值的选取对 K-means 影响很大，这也是 K-means 最大的缺点，常见的选取
K 值的方法有：<strong>手肘法、Gap statistic 方法</strong>。</p>
<p><strong>【手肘法】</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-5ca4a5fe0b06b25a2b97262abb401a16_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>当 K &lt; 3 时，曲线急速下降；当 K &gt; 3
时，曲线趋于平稳，通过手肘法我们认为拐点 3 为 K 的最佳值。</p>
<p>【<strong>Gap statistic</strong>】</p>
<p><span class="math display">\[
G a p(K)=\mathrm{E}\left(\log D_k\right)-\log D_k
\]</span> 其中 <span class="math inline">\(D_k\)</span> 为损失函数, 这里
<span class="math inline">\(E\left(\log D_k\right)\)</span> 指的是 <span class="math inline">\(\log D_k\)</span>
的期望。这个数值通常通过蒙特卡洛模拟产生, <strong>我们在样本
里所在的区域中按照均匀分布随机产生和原始样本数一样多的随机样本,
并对这个随机样本做 K-Means, 从而得到一个 <span class="math inline">\(D_k\)</span> 。如此往复多次, 通常 20 次,
我们可以得到 20 个 <span class="math inline">\(\log
D_k\)</span></strong> 。对这 20 个数值求平均值, 就得到了 <span class="math inline">\(E\left(\log D_k\right)\)</span>
的近似值。最终可以计算 Gap Statisitc。而 Gap statistic
取得最大值所对应的 K 就是最佳的 K。</p>
<p><img src="https://pic3.zhimg.com/80/v2-9a39a8dad143e5dd52a506d83c2cbb36_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>由图可见，当 K=3 时，Gap(K) 取值最大，所以最佳的簇数是 K=3。</p>
<p>Github 上一个项目叫 <a href="https://link.zhihu.com/?target=https%3A//github.com/milesgranger/gap_statistic">gap_statistic</a>
，可以更方便的获取建议的类簇个数。</p>
<h4><span id="23-采用核函数">2.3 采用核函数</span></h4>
<p><strong>基于欧式距离的 K-means
假设了了各个数据簇的数据具有一样的的先验概率并呈现球形分布</strong>，但这种分布在实际生活中并不常见。面对非凸的数据分布形状时我们可以引入核函数来优化，这时算法又称为核
K-means
算法，是核聚类方法的一种。<strong>核聚类方法的主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的特征空间中进行聚类。</strong>非线性映射增加了数据点线性可分的概率，从而在经典的聚类算法失效的情况下，通过引入核函数可以达到更为准确的聚类结果。</p>
<h4><span id="24-k-means">2.4 K-means++</span></h4>
<p><strong>K-means++
就是选择离已选中心点最远的点</strong>。这也比较符合常理,
聚类中心当然是互相离得越远越好。我们知道 初始值的选取对结果的影响很大,
对初始值选择的改进是很重要的一部分。在所有的改进算法中, K-means++ 最
有名。 K-means++ 算法步骤如下所示：</p>
<ol type="1">
<li>随机选取一个中心点 <span class="math inline">\(a_1\)</span>;</li>
<li>计算数据到之前 <span class="math inline">\(\mathrm{n}\)</span>
个聚类中心最远的距离 <span class="math inline">\(D(x)\)</span>,
并以一定概率 <span class="math inline">\(\frac{D(x)^2}{\sum
D(x)^2}\)</span> 选择新中心点 <span class="math inline">\(a_i\)</span>;</li>
<li>重复第二步。</li>
</ol>
<p>简单的来说, 就是 <strong>K-means++
就是选择离已选中心点最远的点</strong>。这也比较符合常理,
聚类中心当然是互相离得越 远越好。 但是这个算法的缺点在于,
难以并行化。所以 k-means II 改变取样策略, 并非按照 k-means++
那样每次遍历只取 样一个样本, 而是每次遍历取样 <span class="math inline">\(\mathrm{k}\)</span> 个, 重复该取样过程 <span class="math inline">\(\log (n)\)</span> 次, 则得到 <span class="math inline">\(k \log (n)\)</span> 个样本点组成的集合, 然后从
这些点中选取 k 个。当然一般也不需要 <span class="math inline">\(\log
(n)\)</span> 次取样, 5 次即可。</p>
<h4><span id="25-isodata">2.5 ISODATA</span></h4>
<p>ISODATA 的全称是<strong>迭代自组织数据分析法</strong>。它解决了 K
的值需要预先人为的确定这一缺点。而当遇到高维度、海量的数据集时，人们往往很难准确地估计出
K 的大小。ISODATA
就是针对这个问题进行了改进，它的思想也很直观：当属于某个类别的样本数过少时把这个类别去除，当属于某个类别的样本数过多、分散程度较大时把这个类别分为两个子类别。</p>
<h3><span id="三-收敛证明em算法">三、 收敛证明【EM算法】</span></h3>
<p>我们先来看一下 K-means
算法的步骤：先随机选择初始节点，然后计算每个样本所属类别，然后通过类别再跟新初始化节点。这个过程有没有想到之前介绍的
<a href="https://zhuanlan.zhihu.com/p/78311644">EM 算法</a> 。</p>
<p>我们需要知道的是 K-means 聚类的迭代算法实际上是 EM 算法。EM
算法解决的是在概率模型中含有无法观测的隐含变量情况下的参数估计问题。在
<strong>K-means 中的隐变量是每个样本所属类别</strong>。</p>
<p>K-means 算法迭代步骤中的每次确认中心点以后重新进行标记对应 EM
算法中的 <strong>E 步</strong>：<strong>求当前参数条件下的
Expectation</strong>。而根据标记重新求中心点 对应 EM 算法中的 <strong>M
步</strong>：<strong>求似然函数最大化时（损失函数最小时）对应的参数
。</strong></p>
<p>首先我们看一下损失函数的形式: <span class="math display">\[
J=\sum_{i=1}^C \sum_{j=1}^N r_{i j} \cdot \nu\left(x_j, \mu_i\right)
\]</span> 其中: <span class="math display">\[
\nu\left(x_j, \mu_i\right)=\left\|x_j-\mu_i\right\|^2, \quad r_{n k}=
\begin{cases}1 &amp; \text { if } x_n \in k \\ 0 &amp; \text { else
}\end{cases}
\]</span> 为了求极值，我们令损失函数求偏导数且等于 0 : <span class="math display">\[
\frac{\partial J}{\partial \mu_k}=2 \sum_{i=1}^N r_{i
k}\left(x_i-\mu_k\right)=0
\]</span> <span class="math inline">\(\mathrm{k}\)</span> 是指第 <span class="math inline">\(\mathrm{k}\)</span> 个中心点, 于是我们有: <span class="math display">\[
\mu_k=\frac{\sum_{i=1}^N r_{i k} x_i}{\sum_{i=1}^N r_{i k}}
\]</span> 可以看出，新的中心点就是所有该类的<strong>质心</strong>。</p>
<p><strong>EM 算法的缺点就是，容易陷入局部极小值，这也是 K-means
有时会得到局部最优解的原因。</strong></p>
<h3><span id="四-高斯混合模型gmm">四、高斯混合模型(GMM)</span></h3>
<h4><span id="41-gmm的思想">4.1 GMM的思想</span></h4>
<p>高斯混合模型（Gaussian Mixed
Model，GMM）也是一种常见的聚类算法，与K均值算法类似，同样使用了EM算法进行迭代计算。<strong>高斯混合模型假设每个簇的数据都是符合高斯分布（又叫正态分布）的</strong>，当前<strong>数据呈现的分布就是各个簇的高斯分布叠加在一起的结果。</strong></p>
<p>第一张图是一个数据分布的样例，如果只用一个高斯分布来拟合图中的数据，图
中所示的椭圆即为高斯分布的二倍标准差所对应的椭圆。直观来说，图中的数据
明显分为两簇，因此只用一个高斯分布来拟和是不太合理的，需要推广到用多个
高斯分布的叠加来对数据进行拟合。第二张图是用两个高斯分布的叠加来拟合得到的结果。<strong>这就引出了高斯混合模型，即用多个高斯分布函数的线形组合来对数据分布进行拟合。</strong>理论上，高斯混合模型可以拟合出任意类型的分布。</p>
<p>高斯混合模型的核心思想是, 假设数据可以看作从多个高斯分布中生成出来
的。在该假设下, 每个单独的分模型 都是标准高斯模型, 其均值 <span class="math inline">\(u_i\)</span> 和方差 <span class="math inline">\(\sum_i\)</span> 是待估计的参数。此外,
每个分模型都还有一个参数 <span class="math inline">\(\pi_i\)</span>,
可以理解为权 重或生成数据的概率。高斯混合模型的公式为: <span class="math display">\[
p(x)=\sum_{i=1}^k \pi_i N\left(x \mid u_i, \sum_i\right)
\]</span> 通常我们并不能直接得到高斯混合模型的参数,
而是观察到了一系列数据点, 给出一个类别的数量K后, 希望求得最佳的 <span class="math inline">\(K\)</span>
个高斯分模型。<strong>因此，高斯混合模型的计算，便成了最佳的均值 <span class="math inline">\(\mu\)</span>, 方差 <span class="math inline">\(\Sigma 、\)</span> 权重 <span class="math inline">\(\pi\)</span> 的寻找, 这类问题通常
通过最大似然估计来求解。遗憾的是, 此问题中直接使用最大似然估计,
得到的是一个复杂的非凸函数, 目标函数 是和的对数,
难以展开和对其求偏导。</strong></p>
<p><strong>在这种情况下，可以用EM算法。
</strong>EM算法是在最大化目标函数时，先固定一个变量使整体函数变为凸优化函数，求导得到最值，然后利用最优参数更新被固定的变量，进入下一个循环。具体到高
斯混合模型的求解，EM算法的迭代过程如下。</p>
<p>首先，初始随机选择各参数的值。然后，重复下述两步，直到收敛。</p>
<ul>
<li>E步骤。根据当前的参数，计算每个点由某个分模型生成的概率。</li>
<li>M步骤。使用E步骤估计出的概率，来改进每个分模型的均值，方差和权重。</li>
</ul>
<p>高斯混合模型是一个生成式模型。可以这样理解数据的生成过程，假设一个最简单的情况，即只有两个一维标准高斯分布的分模型<em>N</em>(0,1)和<em>N</em>(5,1)，其权重分别为0.7和0.3。那么，在生成第一个数据点时，先按照权重的比例，随机选择一个分布，比如选择第一个高斯分布，接着从<em>N</em>(0,1)中生成一个点，如−0.5，便是第一个数据点。在生成第二个数据点时，随机选择到第二个高斯分布<em>N</em>(5,1)，生成了第二个点4.7。如此循环执行，便生成出了所有的数据点。</p>
<p>也就是说，我们并不知道最佳的K个高斯分布的各自3个参数，也不知道每个
数据点究竟是哪个高斯分布生成的。所以每次循环时，先固定当前的高斯分布不
变，获得每个数据点由各个高斯分布生成的概率。然后固定该生成概率不变，根据数据点和生成概率，获得一个组更佳的高斯分布。循环往复，直到参数的不再变化，或者变化非常小时，便得到了比较合理的一组高斯分布。</p>
<h4><span id="42-gmm与k-means相比">4.2 GMM与K-Means相比</span></h4>
<p>高斯混合模型与K均值算法的相同点是：</p>
<ul>
<li><strong>都需要指定K值</strong>；</li>
<li><strong>都是使用EM算法来求解</strong>；</li>
<li>都往往只能收敛于局部最优。</li>
</ul>
<p>而它相比于K
均值算法的优点是，可以给出一个样本属于某类的<strong>概率</strong>是多少；不仅仅可以用于聚类，还可以用于概率密度的估计；<strong>并且可以用于生成新的样本点</strong>。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/20463356">K-means
笔记（三）数学原理</a></li>
<li><a href="https://link.zhihu.com/?target=http%3A//sofasofa.io/forum_main_post.php%3Fpostid%3D1000282">K-means
怎么选 K?</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/161733843">K-Means：隐变量、聚类、EM</a></li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>聚类</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>聚类</tag>
        <tag>K-means</tag>
        <tag>高斯混合模型</tag>
      </tags>
  </entry>
  <entry>
    <title>聚类（2）DBSCAN</title>
    <url>/posts/1YHD4BN/</url>
    <content><![CDATA[<h3><span id="一-dbscan算法基于密度">一、DBSCAN算法【基于密度】</span></h3>
<blockquote>
<p>（3）聚类算法之DBSCAN算法 - GISer.Wang的文章 - 知乎
https://zhuanlan.zhihu.com/p/77043965</p>
</blockquote>
<p>密度聚类方法的指导思想是，只要样本点的密度大于某阈值，则将该样本添加到最近的簇中。这类算法能克服基于距离的算法只能发现“类圆”（凸）的聚类的缺点，可发现任意形状的聚类，且对噪声数据不敏感。但计算密度单元的计算复杂度大，需要建立空间索引来降低计算量。其代表算法为<strong>DBSCAN算法</strong>和<strong>密度最大值</strong>算法。</p>
<h4><span id="21-dbscan算法原理">2.1 DBSCAN算法原理</span></h4>
<p><strong><font color="red"> DBCSAN（Density-Based Spatial Clustering
of Applications with
Noise）是一个比较有代表性的基于密度的聚类算法。</font></strong>与划分和层次聚类方法不同，它将簇定义为密度相连的点的最大集合，能够把具有足够高密度的区域划分为簇，并<strong>可在有“噪声”的数据中发现任意形状的聚类</strong>。</p>
<h4><span id="22-若干概念">2.2 若干概念</span></h4>
<p><strong>DBSCAN是基于一组邻域来描述样本集的紧密程度的, 参数 <span class="math inline">\((\epsilon, M i n P t s)\)</span>
用来描述邻域的样本分布紧密程度。其 中, <span class="math inline">\(\epsilon\)</span> 描述了某一数据点的邻域距离阈值
(半径)</strong>, MinPts 描述了数据点半径为 <span class="math inline">\(\epsilon\)</span> 的邻域中数据点个数的最
小个数。下面是与密度聚类相关的定义 (假设我的样本集是 <span class="math inline">\(D=\left\{x_1, x_2, \ldots, x_m\right\}\)</span>
):</p>
<ul>
<li><p><strong>对象的 <span class="math inline">\(\varepsilon\)</span>
领域</strong>：给定对象在半径 <span class="math inline">\(\varepsilon\)</span> 内的区域; 对于 <span class="math inline">\(x_j \in D\)</span>, 其 <span class="math inline">\(\epsilon\)</span>-邻域包含样本集 <span class="math inline">\(D\)</span> 中与 <span class="math inline">\(x_j\)</span> 的距离不大于 <span class="math inline">\(\epsilon\)</span> 的子样本集。即 <span class="math inline">\(N_\epsilon\left(x_j\right)=\left\{x_i \in D \mid
\operatorname{distance}\left(x_i, x_j\right) \leq
\epsilon\right\}\)</span> ，这个子样本集的个数记为 <span class="math inline">\(\left|N_\epsilon\left(x_j\right)\right|\)</span>
。 <span class="math inline">\(\epsilon\)</span>-邻域是
一个集合</p></li>
<li><p><strong>核心对象</strong>: 对于任一样本 <span class="math inline">\(x_j \in D\)</span>, 如果其 <span class="math inline">\(\epsilon\)</span>-邻域对应的 <span class="math inline">\(N_\epsilon\left(x_j\right)\)</span> 至少包含
MinPts 个样本, 即如果 <span class="math inline">\(\left|N_\epsilon\left(x_j\right)\right|
\geq\)</span> MinPts ，则 <span class="math inline">\(x_j\)</span>
是核心对象。</p></li>
<li><p><strong>直接密度可达</strong>: 如果 <span class="math inline">\(x_i\)</span> 位于 <span class="math inline">\(x_j\)</span> 的 <span class="math inline">\(\epsilon\)</span>-邻域中, 且 <span class="math inline">\(x_j\)</span> 是核心对象, 则称 <span class="math inline">\(x_i\)</span> 由 <span class="math inline">\(x_j\)</span> 密度直达。反之不一定成 立,
即此时不能说 <span class="math inline">\(x_j\)</span> 由 <span class="math inline">\(x_i\)</span> 密度直达，除非 <span class="math inline">\(x_i\)</span> 也是核心对象,
即<strong>密度直达不满足对称性</strong>。如图 <span class="math inline">\(\varepsilon=1, \mathrm{~m}=5, \mathrm{q}\)</span>
是一个核心对象, 从对象q出发到对象p是直接密度可达的。</p></li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221648998.jpg" alt="2019-05-18-061126.jpg" style="zoom:50%;"></p>
<ul>
<li>*密度可达<strong>: 对于 <span class="math inline">\(x_i\)</span> 和
<span class="math inline">\(x_j\)</span> ，如果存在样本样本序列 <span class="math inline">\(p_1, p_2, \ldots, p_T\)</span> ，满足 <span class="math inline">\(p 1=x_i, p_T=x_j\)</span> ，且 <span class="math inline">\(p_{t+1}\)</span> 由 <span class="math inline">\(p_t\)</span> 密度 直达, 则称 <span class="math inline">\(x_j\)</span> 由 <span class="math inline">\(x_i\)</span> 密度可达。也就是说,
密度可达满足传递性。此时序列中的传递样本 <span class="math inline">\(p_1, p_2, \ldots, p_{T-1}\)</span> 均 为核心对象,
因为只有核心对象才能使其他样本密度直达。</strong>密度可达也不满足对称性**,
这个可以由密度直达的 不对称性得出。</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221648520.jpg" alt="2019-05-18-061154.jpg" style="zoom:50%;"></p>
<ul>
<li><strong>密度相连</strong>：对于 <span class="math inline">\(x_i\)</span> 和 <span class="math inline">\(x_j\)</span> ，如果存在核心对象样本 <span class="math inline">\(x_k\)</span>, 使 <span class="math inline">\(x_i\)</span> 和 <span class="math inline">\(x_j\)</span> 均由 <span class="math inline">\(x_k\)</span> 密度可达, 则称 <span class="math inline">\(x_i\)</span> 和 <span class="math inline">\(x_j\)</span> 密度
相连。密度相连关系满足对称性。</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221648223.jpg" alt="2019-05-18-061202.jpg" style="zoom:50%;"></p>
<ul>
<li><p><strong>簇</strong>：一个基于密度的簇是最大的密度相连对象的集合。</p></li>
<li><p><strong>噪声</strong>：不包含在任何簇中的对象称为噪声。</p></li>
</ul>
<p>从下图可以很容易看出理解上述定义，图中 MinPts <span class="math inline">\(=5\)</span> ，红色的点都是核心对象, 因为其 <span class="math inline">\(\epsilon\)</span>-邻域至少有 5 个
样本。黑色的样本是非核心对象。所有核心对象密度直达的样本在以红色核心对象为中心的圆内,
如果不在圆内,
则不能密度直达。图中用绿色箭头连起来的核心对象组成了密度可达的样本序列，此序列是一个簇集。在这些密度
可达的样本序列的 <span class="math inline">\(\epsilon\)</span>-邻域内所有的样本相互都是密度相连的
(<strong>注意, 此图中有两个簇集</strong>)。</p>
<p><img src="https://pic2.zhimg.com/80/v2-7d15fc871942e0287be42a12d6d615dd_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<h4><span id="23-dbscan密度聚类思想">2.3 DBSCAN密度聚类思想</span></h4>
<p><strong>DBSCAN的聚类定义很简单：由密度可达关系导出的最大密度相连的样本集合,
即为我们最终聚类的一个类别,
或者说一个簇。（注意是密度相连的集合）</strong>,
簇里面可以有一个或者多个核心对象。<strong>如果只有一个核心对象,
则簇里其他的非核心对象样本都在这个核心对象的 <span class="math inline">\(\epsilon\)</span>-邻域里; 如果有多个核心对象,
则簇里的任意一个核心对象的 <span class="math inline">\(\epsilon\)</span>
-邻域中一定有一个其他的核心对象,
否则这两个核心对象无法密度可达</strong>。这些核心对象的 <span class="math inline">\(\epsilon\)</span>-邻域里所有的样本的
集合组成的一个DBSCAN聚类笶。</p>
<p>那么怎么才能找到这样的簇样本集合呢？DBSCAN使用的方法很简单，它任意选择一个没有类别的核心对象作为种子，然后找到所有这个核心对象能够<strong>密度可达</strong>的样本集合，即为一个聚类簇。接着继续选择另一个没有类别的核心对象去寻找<strong>密度可达</strong>的样本集合，这样就得到另一个聚类簇
<strong>（这样的得到都肯定是密度相连的）</strong>。一直运行到<strong>所有核心对象都有类别为止。</strong></p>
<p>基本上这就是DBSCAN算法的主要内容了，是不是很简单？<strong>但是我们还是有三个问题没有考虑。</strong></p>
<ul>
<li><strong>异常点问题：</strong>一些异常样本点或者说少量游离于簇外的样本点，这些点不在任何一个核心对象在周围，在DBSCAN中，我们一般将这些样本点标记为噪音点。</li>
<li><strong>距离度量问题</strong>：<strong><font color="red">
即如何计算某样本和核心对象样本的距离</font></strong>。在DBSCAN中，一般采用最近邻思想，采用某一种距离度量来衡量<strong>样本距离，比如欧式距离、曼哈顿距离</strong>等。</li>
<li><strong>数据点优先级分配问题</strong>：例如某些样本可能到两个核心对象的距离都小于
<span class="math inline">\(\epsilon\)</span>,
但是这两个核心对象由于不是 密度直达, 又不属于同一个聚类笶,
那么如果界定这个样本的类别呢? 一般来说, 此时 DBSCAN采用先来后 到,
先进行聚类的类别簇会标记这个样本为它的类别。也就是说<strong>DBSCAN的算法不是完全稳定的算法</strong>。</li>
</ul>
<h4><span id="24-算法步骤">2.4 算法步骤</span></h4>
<p><strong>输入: 样本集</strong> <span class="math inline">\(D=\left\{x_1, x_2, \ldots, x_m\right\}\)</span>,
<strong>邻域参数</strong> <span class="math inline">\((\epsilon\)</span>, MinPts <span class="math inline">\()\)</span></p>
<ol type="1">
<li>初始化核心对象集合 <span class="math inline">\(\Omega=\emptyset\)</span>, 初始化类别 <span class="math inline">\(k=0\)</span></li>
<li>遍历 <span class="math inline">\(D\)</span> 的元素, 如果是核心对象,
则将其加入到核心对象集合 <span class="math inline">\(\Omega\)</span>
中</li>
<li>如果核心对象集合 <span class="math inline">\(\Omega\)</span>
中元素都已经被访问, 则算法结束, 否则转入步骤4.</li>
<li>在核心对象集合 <span class="math inline">\(\Omega\)</span> 中,
随机选择一个末访问的核心对象 <span class="math inline">\(o\)</span>,
首先将 <span class="math inline">\(o\)</span> 标记为已访问, 然后将 <span class="math inline">\(o\)</span> 标记类别 <span class="math inline">\(k\)</span> , 最后将 <span class="math inline">\(o\)</span> 的 <span class="math inline">\(\epsilon\)</span>-邻域中末访问的数据，存放到种子集合
Seeds 中。</li>
<li>如果种子集合 <span class="math inline">\(S e e d
s=\emptyset\)</span>, 则当前聚类簇 <span class="math inline">\(C_k\)</span> 生成完毕，且 <span class="math inline">\(k=k+1\)</span>, 跳转到3。否则, 从种子集合 <span class="math inline">\(S e e d s\)</span> 中挑选一个种子点 seed,
首先将其标记为已访问、标记类别 <span class="math inline">\(k\)</span>,
然后判断 seed 是否为核心对象, 如果是将 seed
中末访问的种子点加入到种子集合中, 跳转到 5 。</li>
</ol>
<p><strong>从上述算法可知：</strong></p>
<ul>
<li><strong>每个簇至少包含一个核心对象</strong>；</li>
<li>非核心对象可以是簇的一部分，构成了簇的边缘（edge）；</li>
<li>包含过少对象的簇被认为是噪声；</li>
</ul>
<h4><span id="25-总结">2.5 总结</span></h4>
<h5><span id="优点">优点</span></h5>
<ol type="1">
<li><strong>可以对任意形状的稠密数据集进行聚类</strong>，相对的，K-Means之类的聚类算法一般只适用于凸数据集。</li>
<li><strong>可以在聚类的同时发现异常点</strong>，对数据集中的异常点不敏感。</li>
<li>聚类结果没有偏倚，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。</li>
</ol>
<h5><span id="缺点">缺点</span></h5>
<ol type="1">
<li><strong>不能处理密度差异过大（密度不均匀）的聚类</strong>：如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合。</li>
<li>如果样本集较大时，聚类收敛时间较长;<strong>此时可以对搜索最近邻时建立的KD树或者球树进行规模限制来改进；</strong></li>
<li>调参相对于传统的K-Means之类的聚类算法稍复杂，<strong>主要需要对距离阈值ϵ，邻域样本数阈值MinPts联合调参，不同的参数组合对最后的聚类效果有较大影响</strong>。【OPTICS算法】</li>
<li><strong>边界点不完全确定性</strong></li>
</ol>
<h4><span id="26-optics算法">2.6 OPTICS算法</span></h4>
<p><strong>OPTICS主要针对输入参数 <span class="math inline">\(\epsilon\)</span> 过敏感做的改进</strong>,
OPTICS和DBSCNA的输入参数一样 ( <span class="math inline">\(\epsilon\)</span> 和 MinPts ), 虽然
OPTICS算法中也需要两个输入参数, 但该算法对 <span class="math inline">\(\epsilon\)</span> 输入不敏感（一般将 <span class="math inline">\(\epsilon\)</span> 固定为无穷大）,
同时该算法中并不显式的生成数据聚类, 只是对数据集合中的对象进行排序,
得到一个有序的对象列表, 通过该有序列表, 可以得到 一个决策图,
通过决策图可以不同 <span class="math inline">\(\epsilon\)</span>
参数的数据集中检测笶集, 即: 先通过固定的 MinPts 和无穷大的 <span class="math inline">\(\epsilon\)</span>
得到有序列表，然后得到决策图，通过决策图可以知道当 <span class="math inline">\(\epsilon\)</span> 取特定值时（比如 <span class="math inline">\(\epsilon=3\)</span> ) 数据的聚类情况。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>聚类</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>聚类</tag>
        <tag>DBSCAN</tag>
      </tags>
  </entry>
  <entry>
    <title>理论基础（2）损失函数</title>
    <url>/posts/1QZMAVB/</url>
    <content><![CDATA[<h2><span id="损失函数">损失函数</span></h2>
<p>机器学习中的监督学习本质上是给定一系列训练样本 <span class="math inline">\(\left(x_i, y_i\right)\)</span>, 尝试学习 <span class="math inline">\(x \rightarrow y\)</span> 的映射关系, 使得给定一个
<span class="math inline">\(x\)</span> , 即便这个 <span class="math inline">\(x\)</span> 不在训练样本中, 也能够得到尽量接近真实
<span class="math inline">\(y\)</span> 的输出 <span class="math inline">\(\hat{y}\)</span> 。而损失函数 (Loss Function)
则是这 个过程中关键的一个组成部分, 用来衡量模型的输出 <span class="math inline">\(\hat{y}\)</span> 与真实的 <span class="math inline">\(y\)</span> 之间的差距, 给模型的优化指明方向。</p>
<p>本文将介绍机器学习、深度学习中分类与回归常用的几种损失函数,
包括<strong>均方差损失 Mean Squared Loss、平 均绝对误差损失 Mean
Absolute Error Loss、Huber Loss、分位数损失 Quantile
Loss、交叉樀损失函数 Cross Entropy Loss、Hinge 损失 Hinge
Loss</strong>。主要介绍各种损失函数的基本形式、原理、特点等方面。</p>
<p><img src="https://s2.loli.net/2023/04/17/GA3Y4CvZ1PlLOup.png" alt="img" style="zoom: 67%;"></p>
<h3><span id="前言">前言</span></h3>
<p>在正文开始之前, 先说下关于 Loss Function、Cost Function 和 Objective
Function 的区别和联系。在机器学习 的语境下这三个术语经常被交叉使用。</p>
<ul>
<li><strong>损失函数</strong> Loss Function
通常是<strong>针对单个训练样本而言,</strong> 给定一个模型输出 <span class="math inline">\(\hat{y}\)</span> 和一个真实 <span class="math inline">\(y\)</span>, 损失函数输 出一个实值损失 <span class="math inline">\(L=f\left(y_i, \hat{y_i}\right)\)</span></li>
<li><strong>代价函数</strong> Cost Function
通常是<strong>针对整个训练集</strong>（或者在使用 mini-batch gradient
descent 时一个 minibatch）的总损失 <span class="math inline">\(J=\sum_{i=1}^N f\left(y_i,
\hat{y}_i\right)\)</span></li>
<li><strong>目标函数</strong> Objective Function 是一个更通用的术语,
表示任意希望被优化的函数, 用于机器学习领域和非机 器学习领域
(比如运筹优化)</li>
</ul>
<p>一句话总结三者的关系就是：<font color="red"> <strong>A loss function
is a part of a cost function which is a type of an objective
function.</strong></font></p>
<p>由于损失函数和代价函数只是在针对样本集上有区别，因此在本文中统一使用了损失函数这个术语，但下文的相关公式实际上采用的是代价函数
Cost Function 的形式，请读者自行留意。</p>
<h4><span id="结构风险函数">结构风险函数</span></h4>
<p>损失函数（loss function）是用来估量模型的预测值f(x)与真实值<span class="math inline">\(Y\)</span>不一致的程度，它是一个非负实数值函数，通常使用<span class="math inline">\(L(Y,f(x))\)</span>来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数的重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下的式子：</p>
<p><img src="https://s2.loli.net/2023/04/17/mEXD8ocy2UtFlbN.png" alt="image-20220821223950768" style="zoom:50%;"></p>
<p>前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的Φ是正则化项（regularizer）或者叫惩罚项（penalty
term）,它可以是L1，也可以是L2等其他的正则函数。整个式子表示的意思是找到使目标函数最小时的θ值。下面列出集中常见的损失函数。</p>
<h3><span id="一-对数损失函数逻辑回归mle-交叉熵损失函数">一、
对数损失函数（逻辑回归）MLE 【交叉熵损失函数】</span></h3>
<blockquote>
<p>https://zhuanlan.zhihu.com/p/52100927</p>
<p><a href="https://blog.csdn.net/tsyccnh/article/details/79163834">一文搞懂交叉熵在机器学习中的使用，透彻理解交叉熵背后的直觉</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/35709485">损失函数｜交叉熵损失函数</a></p>
</blockquote>
<p>有些人可能觉得逻辑回归的损失函数就是平方损失，其实并不是。<strong>平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到</strong>，而逻辑回归得到的并不是平方损失。在逻辑回归的推导中，<strong>它假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数</strong>，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：</p>
<p><strong>最小化负的似然函数</strong>（即<span class="math inline">\(maxF(y,f(x))—&gt;min−F(y,f(x))\)</span>)。从损失函数的视角来看，它就成了<strong>log损失函数了。</strong></p>
<h4><span id="原理解释1条件概率下方便计算极大似然估计">原理解释1：<strong>==条件概率下方便计算极大似然估计==</strong></span></h4>
<p>Log损失函数的标准形式：</p>
<p><span class="math inline">\(L(Y,P(Y|X))=−logP(Y|X)\)</span></p>
<p>刚刚说到，<strong>取对数是为了方便计算极大似然估计</strong>，因为在MLE中，直接求导比较困难，所以通常都是先取对数再求导找极值点。损失函数<span class="math inline">\(L(Y.P(Y|X))\)</span>表达的是样本在分类<span class="math inline">\(Y\)</span>的情况下，使概率<span class="math inline">\(P(Y|X)\)</span>达到最大值（换言之，就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者什么样的参数才能使我们观测到目前这组数据的概率最大）。因为log函数是单调递增的，所以<span class="math inline">\(logP(Y|X)\)</span>也会达到最大值，因此在前面加上负号之后，最大化<span class="math inline">\(P(Y|X)\)</span>就等价于最小化<span class="math inline">\(L\)</span>了。</p>
<p><strong>logistic回归</strong>的<span class="math inline">\(P(y|x)\)</span>表达式如下（为了将类别标签y统一为1和0，下面将表达式分开表示）：</p>
<p><img src="https://s2.loli.net/2023/04/17/2aLAcdN97nRS8QV.png" alt="image-20220322202521355" style="zoom:50%;"></p>
<p>将上面的公式合并在一起，可得到第i个样本正确预测的概率：</p>
<p><img src="https://s2.loli.net/2023/04/17/ebZvW8hzNMuED3d.png" alt="image-20220322202548296" style="zoom:50%;"></p>
<p>上式是对一个样本进行建模的数据表达。对于所有的样本，假设每条样本生成过程独立，在整个样本空间中（N个样本）的概率分布为：</p>
<p><img src="https://s2.loli.net/2023/04/17/2hZLDVKEaSQMPys.png" alt="image-20220322202618734" style="zoom:50%;"></p>
<p>将上式代入到对数损失函数中，得到最终的损失函数为：</p>
<p><img src="https://s2.loli.net/2023/04/17/ZLaI9mACg5pojqv.png" alt="image-20220322202653661" style="zoom:50%;"></p>
<h4><span id="原理解释2相对熵kl散度推理">原理解释2：相对熵（KL散度）推理</span></h4>
<blockquote>
<p>相对熵又称KL散度,如果我们对于同一个随机变量 x 有两个单独的概率分布
P(x) 和 Q(x)，我们可以使用 KL 散度（Kullback-Leibler (KL)
divergence）来衡量这两个分布的差异.<span class="math inline">\(DKL\)</span>的值越小，表示q分布和p分布越接近.</p>
</blockquote>
<h5><span id="相对熵">相对熵:</span></h5>
<p><img src="https://s2.loli.net/2023/04/17/y8ulY5HqIKrJRZW.png" alt="image-20220330133351613" style="zoom:50%;"></p>
<h5><span id="相对熵-信息熵-交叉熵">相对熵 = 信息熵 + 交叉熵 ：</span></h5>
<p><img src="https://s2.loli.net/2023/04/17/ZiDJTfWudUFmwx7.png" alt="image-20220330134202064" style="zoom:50%;"></p>
<p><strong>【对数损失函数（Log loss
function）】和【交叉熵损失函数（Cross-entroy loss
funtion）】在很多文献内是一致的，因为他们的表示式的本质是一样的。</strong></p>
<h3><span id="二-平方损失函数线性回归gbdt最小二乘法ordinary-leastsquaresmse">二、
平方损失函数（线性回归，GBDT，最小二乘法，Ordinary Least
Squares）MSE</span></h3>
<p>最小二乘法是线性回归的一种，OLS
将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（为什么假设成高斯分布呢？其实这里隐藏了一个小知识点，就是中心极限定理，可以参考【central
limit
theorem】），最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。换言之，OLS是基于<strong>距离</strong>的，而这个距离就是我们用的最多的欧几里得距离。为什么它会选择使用欧式距离作为误差度量呢（即Mean
squared error， MSE），主要有以下几个原因：</p>
<ul>
<li>简单，计算方便；</li>
<li>欧氏距离是一种很好的相似性度量标准；</li>
<li>在不同的表示域变换后特征性质不变。</li>
</ul>
<p>平方损失（Square loss）的标准形式如下：<span class="math inline">\(L(Y,f(X))=(Y−f(x))^2\)</span>当样本个数为n时，此时的损失函数变为：</p>
<p><img src="https://s2.loli.net/2023/04/17/NfeyG4SLkFhJBwt.png" alt="image-20220322202912962" style="zoom:50%;"></p>
<p><span class="math inline">\(Y−f(X)\)</span>
表示的是<strong>残差</strong>，整个式子表示的是残差的平方和，而我们的目的就是最小化这个目标函数值（注：该式子未加入正则项），也就是最小化残差的平方和（residual
sum of squares，RSS）。</p>
<p>而在实际应用中，通常会使用<strong>均方差</strong>（MSE）作为一项衡量指标，公式如下：</p>
<p><img src="https://s2.loli.net/2023/04/17/9CsrcO3pPXwHoKZ.png" alt="image-20220322202957484" style="zoom:50%;"></p>
<h3><span id="三-指数损失函数adaboost">三、 指数损失函数（Adaboost）</span></h3>
<blockquote>
<p>Adaboost训练误差以指数下降。所以说，指数损失本身并没有带来优化上的特殊，优点在于计算和表达简单。</p>
</blockquote>
<p>学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。在Adaboost中，经过m此迭代之后，可以得到<span class="math inline">\(fm(x)\)</span>:</p>
<p><img src="https://s2.loli.net/2023/04/17/2FKCHj4EDLwxob3.png" alt="image-20220322203050695" style="zoom:50%;"></p>
<p><strong>Adaboost</strong>每次迭代时的目的是为了找到最小化下列式子时的参数
<span class="math inline">\(a\)</span> 和 <span class="math inline">\(G\)</span>：</p>
<p><img src="https://s2.loli.net/2023/04/17/XIEqZ21U8ikoOt4.png" alt="image-20220322203141435" style="zoom:50%;"></p>
<p>而指数损失函数(exp-loss）的标准形式如下:</p>
<p><img src="https://s2.loli.net/2023/04/17/wDyvbnklec61FYp.png" alt="image-20220322203221432" style="zoom:50%;"></p>
<p>可以看出，Adaboost的目标式子就是指数损失，在给定N个样本的情况下，Adaboost的损失函数为：</p>
<p><img src="https://s2.loli.net/2023/04/17/6t2QfviewSNLbzV.png" alt="image-20220322203238853" style="zoom:50%;"></p>
<h3><span id="四-hinge合页损失函数svmadvgan">四、 ==Hinge
合页损失函数==（SVM，advGAN）</span></h3>
<p><img src="https://s2.loli.net/2023/04/17/EgYO37JubfLwke8.png" alt="image-20220401165315551" style="zoom:50%;"></p>
<p>线性支持向量机学习除了原始最优化问题，还有另外一种解释，就是最优化以下目标函数：</p>
<p><img src="https://s2.loli.net/2023/04/17/kMKy9zPi5hmITxL.png" alt="image-20220322205741804" style="zoom:50%;"></p>
<p>目标函数的第一项是经验损失或经验风险函数：</p>
<p><img src="https://s2.loli.net/2023/04/17/uJzUqdVDQMf7kCb.png" alt="image-20220322205801232" style="zoom:50%;"></p>
<p>称为<strong>合页损失函数</strong>（hinge loss
function）。下标”+”表示以下取正值的函数：</p>
<p><img src="https://s2.loli.net/2023/04/17/w6VqUnRyaLfETKh.png" alt="image-20220322205844003" style="zoom:50%;"></p>
<p>这就是说，当样本点<span class="math inline">\((xi,yi)\)</span>被正确分类且函数间隔（确信度）<span class="math inline">\(yi(w·xi+b)\)</span>大于1时，损失是0，否则损失是<span class="math inline">\(1−yi(w·xi+b)\)</span>。目标函数的第二项是系数为
<span class="math inline">\(λ\)</span> 的 <span class="math inline">\(w\)</span> 的 <span class="math inline">\(L2\)</span> 范数，是正则化项。</p>
<p>接下来证明线性支持向量机原始最优化问题：</p>
<p><img src="https://s2.loli.net/2023/04/17/jDeMzx3QAoZaPw2.png" alt="image-20220322210000477" style="zoom:50%;"></p>
<p><img src="https://s2.loli.net/2023/04/17/qKU6kzHTI21BmLV.png" alt="image-20220322210121285" style="zoom:50%;"></p>
<p>先令<span class="math inline">\([1−yi(w·xi+b)]+=ξi\)</span>，则<span class="math inline">\(ξi≥0\)</span>，第二个约束条件成立；由<span class="math inline">\([1−yi(w·xi+b)]+=ξi\)</span>，当<span class="math inline">\(1−yi(w·xi+b)&gt;0\)</span>时，有<span class="math inline">\(yi(w·xi+b)=1−ξi\)</span>;当<span class="math inline">\(1−yi(w·xi+b)≤0\)</span>时，<span class="math inline">\(ξi=0\)</span>，有<span class="math inline">\(yi(w·xi+b)≥1−ξi\)</span>，所以第一个约束条件成立。所以两个约束条件都满足，最优化问题可以写作</p>
<p><img src="https://s2.loli.net/2023/04/17/gi1eSxGrA7MYTQh.png" alt="image-20220322210943775" style="zoom:50%;"></p>
<p>若取 <span class="math inline">\(λ=1/2C\)</span> 则:</p>
<p><img src="https://s2.loli.net/2023/04/17/8Q6BU1lkfF4S3Dd.png" alt="image-20220322211012150" style="zoom:50%;"></p>
<h3><span id="五-softmax函数和sigmoid函数的区别与联系">五、Softmax函数和Sigmoid函数的区别与联系</span></h3>
<blockquote>
<p>https://zhuanlan.zhihu.com/p/356976844</p>
</blockquote>
<h4><span id="51-分类任务">5.1 分类任务</span></h4>
<h4><span id="sigmoid">sigmoid</span></h4>
<blockquote>
<p>Sigmoid
=<strong>==多标签分类问题==</strong>=多个正确答案=非独占输出（例如胸部X光检查、住院）。构建分类器，解决有多个正确答案的问题时，用Sigmoid函数分别处理各个原始输出值。</p>
</blockquote>
<blockquote>
<p>Softmax
=<strong>多类别分类问题</strong>=只有一个正确答案=互斥输出（例如手写数字，鸢尾花）。构建分类器，解决只有唯一正确答案的问题时，用Softmax函数处理各个原始输出值。Softmax函数的分母综合了原始输出值的所有因素，这意味着，Softmax函数得到的不同概率之间相互关联。</p>
</blockquote>
<p><strong>Sigmoid函数</strong>是一种logistic函数，它将任意的值转换到
<img src="https://www.zhihu.com/equation?tex=%5B0%2C+1%5D" alt="[公式]"> 之间，如图1所示，函数表达式为： <img src="https://www.zhihu.com/equation?tex=Sigmoid%28x%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-x%7D%7D" alt="[公式]"> 。</p>
<p>它的导函数为： <img src="https://www.zhihu.com/equation?tex=Sigmoid%5E%7B%27%7D%28x%29%3DSigmoid%28x%29%5Ccdot+%281-Sigmoid%28x%29%29" alt="[公式]"> 。</p>
<figure>
<img src="https://s2.loli.net/2023/04/17/i1SyjnQTHW7pYRA.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>优点</strong>：</p>
<ol type="1">
<li>Sigmoid函数的输出在(0,1)之间，输出范围有限，优化稳定，可以用作<strong>输出层</strong>。</li>
<li>连续函数，便于<strong>求导</strong>。</li>
</ol>
<p><strong>缺点</strong>：</p>
<ol type="1">
<li>最明显的就是<strong>饱和性</strong>，从上图也不难看出其两侧导数逐渐趋近于0，容易造成<strong>梯度消失</strong>。</li>
</ol>
<p>2.激活函数的偏移现象。Sigmoid函数的输出值均大于0，使得输出不是0的均值，这会导致后一层的神经元将得到上一层非0均值的信号作为输入，这会对梯度产生影响。</p>
<ol start="3" type="1">
<li>计算复杂度高，因为Sigmoid函数是指数形式。</li>
</ol>
<h4><span id="softmax">Softmax</span></h4>
<p><strong>Softmax函数</strong>，又称<strong>归一化指数函数</strong>，函数表达式为：
<img src="https://www.zhihu.com/equation?tex=Softmax%28x%29%3D%5Cfrac%7Be%5E%7Bx_%7Bi%7D%7D%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%7Be%5E%7Bx_%7Bj%7D%7D%7D%7D" alt="[公式]"> 。</p>
<p><img src="https://s2.loli.net/2023/04/17/tuUkTdM47K6jVXx.jpg" alt="img" style="zoom: 67%;"></p>
<p><strong>Softmax函数是二分类函数Sigmoid在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。</strong>如图2所示，Softmax直白来说就是将原来输出是3,1,-3通过Softmax函数一作用，就映射成为(0,1)的值，而这些值的累和为1（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标。</p>
<p>由于Softmax函数先拉大了输入向量元素之间的差异（通过指数函数），然后才归一化为一个概率分布，在应用到分类问题时，它使得各个类别的概率差异比较显著，最大值产生的概率更接近1，这样输出分布的形式更接近真实分布。</p>
<p><strong>Softmax可以由三个不同的角度来解释。从不同角度来看softmax函数，可以对其应用场景有更深刻的理解：</strong></p>
<ol type="1">
<li><strong>softmax可以当作argmax的一种平滑近似</strong>，与arg
max操作中暴力地选出一个最大值（产生一个one-hot向量）不同，softmax将这种输出作了一定的平滑，即将one-hot输出中最大值对应的1按输入元素值的大小分配给其他位置。</li>
<li><strong>softmax将输入向量归一化映射到一个类别概率分布</strong>，即
<img src="https://www.zhihu.com/equation?tex=n" alt="[公式]">
个类别上的概率分布（前文也有提到）。这也是为什么在深度学习中常常将softmax作为MLP的最后一层，并配合以交叉熵损失函数（对分布间差异的一种度量)。</li>
<li>从<strong>概率图模型</strong>的角度来看，softmax的这种形式可以理解为一个概率无向图上的联合概率。因此你会发现，条件最大熵模型与softmax回归模型实际上是一致的，诸如这样的例子还有很多。由于概率图模型很大程度上借用了一些热力学系统的理论，因此也可以从物理系统的角度赋予softmax一定的内涵。</li>
</ol>
<h4><span id="52-总结">5.2 总结</span></h4>
<ol type="1">
<li>如果模型输出为非互斥类别，且可以同时选择多个类别，则采用Sigmoid函数计算该网络的原始输出值。</li>
<li>如果模型输出为<strong>互斥类别</strong>，且只能选择一个类别，则采用Softmax函数计算该网络的原始输出值。</li>
<li><strong>Sigmoid函数</strong>可以用来解决<strong>多标签问题</strong>，<strong>Softmax</strong>函数用来解决<strong>单标签问题</strong>。</li>
<li>对于某个分类场景，当Softmax函数能用时，Sigmoid函数一定可以用。</li>
</ol>
<h3><span id="6-损失函数qampa">6 损失函数Q&amp;A</span></h3>
<h4><span id="平方误差损失函数和交叉熵损失函数分别适合什么场景">==平方误差损失函数和交叉熵损失函数分别适合什么场景？==</span></h4>
<p>一般还说，平方损失函数更适合输出为连续，并且最后一层不含sigmod或softmax激活函数的神经网络；交叉熵损失函数更适合二分类或多分类的场景。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>聚类（4）总结</title>
    <url>/posts/1P85MAS/</url>
    <content><![CDATA[<h3><span id="一-聚类算法">一、聚类算法</span></h3>
<blockquote>
<p>常用聚类算法 - 小胡子的文章 - 知乎
https://zhuanlan.zhihu.com/p/104355127</p>
<p><strong>K-means, K-medians, K-mediods and K-centers</strong> -
仲基的文章 - 知乎 https://zhuanlan.zhihu.com/p/398600714</p>
</blockquote>
<p>什么是聚类算法？聚类是一种机器学习技术，它涉及到数据点的分组。给定一组数据点，我们可以使用聚类算法将每个数据点划分为一个特定的组。理论上，同一组中的数据点应该具有相似的属性和/或特征，而不同组中的数据点应该具有高度不同的属性和/或特征。<strong>聚类是一种无监督学习的方法</strong>，是许多领域中常用的统计数据分析技术。</p>
<p><strong>聚类算法主要包括以下五类：</strong></p>
<ul>
<li><strong>基于分层的聚类（hierarchical methods）</strong></li>
</ul>
<p>这种方法对给定的数据集进行逐层，直到某种条件满足为止。具体可分为合并型的“自下而上”和分裂型的“自下而上”两种方案。如在“自下而上”方案中，初始时每一个数据记录都组成一个单独的组，在接下来的迭代中，它把那些相互邻近的组合并成一个组，直到所有的记录组成一个分组或者某个条件满足为止。<strong>代表算法有：<em>BIRCH算法</em>（1996）、<em>CURE算法</em>、CHAMELEON算法等。</strong></p>
<blockquote>
<p>层次聚类通过计算不同类别数据点间的相似度来创建一棵有层次的嵌套聚类树。在聚类树中，不同类别的原始数据点是树的最低层，树的顶层是一个聚类的根节点。</p>
<p><strong>最小距离的层次聚类算法</strong>通过自下而上合并创建聚类树，合并算法通过计算两类数据点间的欧式距离来计算不同类别数据点间的相似度，对所有数据点中最为相似的两个数据点进行组合，组合后，最小距离（Single
Linkage）的计算方法是将两个组合数据点中距离最近的两个数据点间的距离作为这两个组合数据点的距离。并反复迭代这一过程。</p>
</blockquote>
<ul>
<li><strong>基于划分的聚类（partitioning methods）</strong></li>
</ul>
<p>给定一个有N个记录的数据集，分裂法将构造K个分组，每一个分组就代表一个聚类，K&lt;N,而且这K个分组满足下列条件：（1）每一个分组至少包含一个数据记录；（2）每一个数据记录属于且仅属于一个分组（咋某些模糊聚类算法中可以放宽条件）。对于给定的K，算法首先给出一个初始的分组方法，以后通过反复迭代的方法改变分组，使得每一次改进之后的分组方案都较前一次好，而所谓好的标准是：同一分组中的记录越近越好，而不同分组中的记录越远越好。使用这个基本思想的算法有：<strong><em>K-means算法</em>、<em>K-medoids算法</em>、<em>CLARANS算法</em></strong></p>
<ul>
<li><strong>基于密度的聚类（density-based methods）</strong></li>
</ul>
<p>基于密度的方法和其他方法的一个根本区别是：它不是基于各种各样的距离的，而是基于魔都的，这样就能克服基于距离的算法只能发现“类圆形”的聚类的缺点。这个方法的指导思想为：只要一个区域的点的密度大过某个阈值，就把它加到与之相近的聚类中去，代表算法有<strong>：<em>DBSCAN（Density-Based
Spatial Clustering of Applic with
Noise）算法（1996）</em>、<em>OPTICS（Ordering Points to Identify
Clustering
Structure）算法（1999）</em>、<em>DENCLUE算法（1998）</em>、<em>WaveCluster算法（1998，具有O（N）时间复杂性，但只适用于低维数据）</em></strong></p>
<ul>
<li><strong>基于网格的聚类（grid-based methods）</strong></li>
</ul>
<p>这种方法首先将数据空间划分成为有限个单元（cell）的网络结构，所有的处理都是以单个的单元为对象的。这么处理的一个突出的优点就是处理速度很快，通常这是与目标数据库中记录的个数无关，它只与把数据空间分成多少个单元有关。代表算法有：<strong><em>STING（Statistical
Information Grid）</em>、<em>CLIQUE（Clustering In
Quest）算法（1998）</em>、<em>WaveCluster算法</em>。</strong>其中STRING算法把数据空间层次地划分为单元格，依赖于存储在网格单元中的统计信息进行聚类；CLIQUE算法结合了密度和网格的方法。</p>
<ul>
<li><strong>基于模型的聚类（model-based methods）</strong></li>
</ul>
<p>基于模型的方法给每一个聚类假定一个模型，然后去寻找能够很好地满足这个模型的数据集。这样一个模型可能是数据点在空间中的密度分布函数或者其它。它的一个潜在的假定就是：目标数据集是由一系列的概率分布所决定的。通常有两种尝试方向：统计的方案和神经网络的方案。</p>
<h3><span id="二-聚类评估">二、聚类评估</span></h3>
<p>由于数据以及需求的多样性，没有一种算法能够适用于所有的数据类型、数据簇或应用场景，似乎每种情况都可能需要一种不同的评估方法或度量标准。例
如，K均值聚类可以用<strong>误差平方</strong>和来评估，但是基于密度的数据簇可能不是球形，
误差平方和则会失效。在许多情况下，判断聚类算法结果的好坏强烈依赖于主观解释。尽管如此，聚类算法的评估还是必需的，它是聚类分析中十分重要的部分之一。</p>
<p>聚类评估的任务是估计在数据集上进行聚类的可行性，以及聚类方法产生结
果的质量。这一过程又分为三个子任务。</p>
<ol type="1">
<li><p><strong>估计聚类趋势。</strong></p>
<p>这一步骤是检测数据分布中是否存在非随机的簇结构。如果数据是基本随机
的，那么聚类的结果也是毫无意义的。我们可以观察聚类误差是否随聚类类别数
量的增加而单调变化，如果数据是基本随机的，即不存在非随机簇结构，那么聚
类误差随聚类类别数量增加而变化的幅度应该较不显著，并且也找不到一个合适
的K对应数据的真实簇数。</p></li>
<li><p><strong>判定数据簇数。</strong></p>
<p>确定聚类趋势之后，我们需要找到与真实数据分布最为吻合的簇数，据此判定聚类结果的质量。数据簇数的判定方法有很多，例如<strong>手肘法</strong>和<strong>Gap
Statistic</strong>方
法。需要说明的是，用于评估的最佳数据簇数可能与程序输出的簇数是不同的。
例如，有些聚类算法可以自动地确定数据的簇数，但可能与我们通过其他方法确定的最优数据簇数有所差别。</p></li>
<li><p><strong>测定聚类质量。</strong></p>
<p>在无监督的情况下，我们可以通过考察簇的分离情况和簇的紧凑情况来评估聚类的效果。定义评估指标可以展现面试者实际解决和分析问题的能力。事实上测量指标可以有很多种，以下列出了几种常用的度量指标，更多的指标可以阅读相关文献。</p></li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>聚类</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>总结</tag>
        <tag>聚类</tag>
      </tags>
  </entry>
  <entry>
    <title>理论基础（3）参数估计</title>
    <url>/posts/1CZDQSE/</url>
    <content><![CDATA[<h3><span id="机器学习优化方法optimization">机器学习优化方法
(Optimization)</span></h3>
<blockquote>
<p>机器学习与优化基础（Machine Learning and
Optimization）:https://zhuanlan.zhihu.com/p/169835477</p>
<p>最优化方法复习笔记：https://github.com/LSTM-Kirigaya/OptimizeNote</p>
<p><strong>FreeWill</strong>：<a href="https://plushunter.github.io/2017/07/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%8825%EF%BC%89%EF%BC%9A%E6%9C%80%E9%80%9F%E4%B8%8B%E9%99%8D%E6%B3%95%E3%80%81%E7%89%9B%E9%A1%BF%E6%B3%95%E3%80%81%E6%8B%9F%E7%89%9B%E9%A1%BF%E6%B3%95/">机器学习算法系列（25）：最速下降法、牛顿法、拟牛顿法</a></p>
</blockquote>
<h3><span id="一-什么是凸优化">一、什么是凸优化</span></h3>
<p><strong>凸函数</strong>的严格定义为, 函数 <span class="math inline">\(L(\cdot)\)</span>
是凸函数当且仅当对定义域中的任意两点 <span class="math inline">\(x,
y\)</span> 和任意实数 <span class="math inline">\(\lambda
\in[0,1]\)</span> 总有: <span class="math display">\[
L(\lambda x+(1-\lambda) y) \leq \lambda L(x)+(1-\lambda) L(y)
\]</span> 该不等式的一个直观解释是, 凸函数曲面上任意两点连接而成的线段,
其上的任 意一点都不会处于该函数曲面的 下方，如下图所示所示。</p>
<p>该不等式的一个直观解释是，凸函数曲面上任意两点连接而成的线段，其上的任
意一点都不会处于该函数曲面的下方，如下图所示所示。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304252130605.jpeg" alt="img" style="zoom:67%;"></p>
<p>凸优化问题的例子包括支持向量机、线性回归等
线性模型，非凸优化问题的例子包括低秩模型（如矩阵分解）、深度神经网络模型等。</p>
<h3><span id="二-正则化项">二、正则化项</span></h3>
<p>使用正则化项，也就是给loss
function加上一个参数项，正则化项有<strong>L1正则化、L2正则化、ElasticNet</strong>。加入这个正则化项好处：</p>
<ul>
<li>控制参数幅度，不让模型“无法无天”。</li>
<li>限制参数搜索空间</li>
<li>解决欠拟合与过拟合的问题。</li>
</ul>
<h3><span id="三-常见的几种最优化方法">三、常见的几种最优化方法</span></h3>
<p><font color="red">下面以线性模型损失函数为例：</font></p>
<h4><span id="31-梯度下降法"><strong>3.1 梯度下降法</strong></span></h4>
<p>梯度下降法是最早最简单，也是最为常用的最优化方法。梯度下降法实现简单，当<strong>目标函数是凸函数时，梯度下降法的解是全局解</strong>。一般情况下，其解不保证是全局最优解，梯度下降法的速度也未必是最快的。
<span class="math display">\[
\begin{gathered}\frac{\partial}{\partial \theta_j}
J(\theta)=\frac{\partial}{\partial \theta_j}
\frac{1}{2}\left(h_\theta(x)-y\right)^2 \\ =2 \cdot
\frac{1}{2}\left(h_\theta(x)-y\right) \frac{\partial}{\partial
\theta_j}\left(h_\theta(x)-y\right) \\ =\left(h_\theta(x)-y\right)
x_j\end{gathered}
\]</span>
梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向，所以也被称为是”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢。梯度下降法的搜索迭代示意图如下图所示：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304252127619.png" alt="img" style="zoom: 67%;"></p>
<ul>
<li><strong>批量梯度下降法（BGD）</strong></li>
</ul>
<p><strong>参数θ的值每更新一次都要遍历样本集中的所有的样本</strong>，得到新的θj，看是否满足阈值要求，若满足，则迭代结束，根据此值就可以得到；否则继续迭代。【易受极小值影响】</p>
<ul>
<li><h5><span id="随机梯度下降算法sgd单样本增量梯度下降">随机梯度下降算法（SGD）【单样本增量梯度下降】</span></h5></li>
</ul>
<p>每次更新只用到一个训练样本，若根据当前严格不能进行迭代得到一个，此时会得到一个，有新样本进来之后，在此基础上继续迭代，又得到一组新的和，以此类推。</p>
<p>缺点：靠近极小值时收敛速度减慢；直线搜索时可能会产生一些问题；可能会“之字形”地下降。</p>
<h4><span id="32-牛顿法">3.2 牛顿法</span></h4>
<p>牛顿法是一种在实数域和复数域上近似求解方程的方法。方法使用函数 <span class="math inline">\(\mathrm{f}(\mathrm{x})\)</span>
的泰勒级数的前面几项来寻找方程 <span class="math inline">\((x)=0\)</span>
的根。牛顿法最大的特点就在于它的收敛速度很快。具体步骤：</p>
<ul>
<li>首先, 选择一个接近函数 <span class="math inline">\(f(x)\)</span>
零点的 <span class="math inline">\(x 0\)</span>, 计算相应的 <span class="math inline">\(f(x 0)\)</span> 和切线斜率 <span class="math inline">\(f^{\prime}(x 0)\)</span> (这里 <span class="math inline">\(f^{\prime}\)</span> 表示函数 <span class="math inline">\(f\)</span> 的导 数)</li>
<li>然后我们计算穿过点 <span class="math inline">\((x 0, f(x
0))\)</span> 并且斜率为 <span class="math inline">\(f^{\prime}(x
0)\)</span> 的直线和 <span class="math inline">\(x\)</span> 轴的交点的
<span class="math inline">\(x\)</span> 坐标, 也就是求如下方程的解: <span class="math inline">\(x *
f^{\prime}\left(x_0\right)+f\left(x_0\right)-x_0 *
f^{\prime}\left(x_0\right)=0\)</span></li>
<li>我们将新求得的点的 <span class="math inline">\(x\)</span> 坐标命名为
<span class="math inline">\(x 1\)</span>, 通常 <span class="math inline">\(x 1\)</span> 会比 <span class="math inline">\(x
0\)</span> 更接近方程 <span class="math inline">\(f(x)=0\)</span>
的解。因此我们现在可以利用 <span class="math inline">\(x 1\)</span>
开始下一轮迭代。</li>
</ul>
<p>由于牛顿法是基于当前位置的切线来确定下一次的位置，所以牛顿法又被很形象地称为是"切线法"。牛顿法搜索动态示例图：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304252126567.gif" alt="img" style="zoom: 67%;"></p>
<p>从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。<strong>缺点：</strong></p>
<ul>
<li>牛顿法是一种迭代算法，每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。
<ul>
<li>在高维情况下这个矩阵非常大，计算和存储都是问题。</li>
</ul></li>
<li>在小批量的情况下，牛顿法对于二阶导数的估计噪声太大。
<ul>
<li>目标函数非凸的时候，牛顿法容易受到鞍点或者最大值点的吸引。</li>
</ul></li>
</ul>
<h4><span id="33-拟牛顿法">3.3 拟牛顿法</span></h4>
<p>拟牛顿法是求解非线性优化问题最有效的方法之一，<strong>本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。</strong>拟牛顿法和梯度下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于梯度下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。</p>
<p><strong>DFP、BFGS、L-BFGS:</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261133926.png" alt="image-20220509171547743" style="zoom:50%;"></p>
<h4><span id="34-共轭梯度法">3.4 共轭梯度法</span></h4>
<p>共轭梯度法是介于梯度下降法与牛顿法之间的一个方法，它仅需利用一阶导数信息，但克服了梯度下降法收敛慢的缺点，又避免了牛顿法需要存储和计算Hesse矩阵并求逆的缺点，共轭梯度法不仅是解决大型线性方程组最有用的方法之一，也是解大型非线性最优化最有效的算法之一。
在各种优化算法中，共轭梯度法是非常重要的一种。其优点是所需存储量小，具有步收敛性，稳定性高，而且不需要任何外来参数。</p>
<p>具体的实现步骤请参加wiki百科<a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method#Example_code_in_MATLAB">共轭梯度法</a>。下图为共轭梯度法和梯度下降法搜索最优解的路径对比示意图：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304252126043.jpeg" alt="img" style="zoom:67%;"></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>理论基础（1）模型定义</title>
    <url>/posts/15NJNGM/</url>
    <content><![CDATA[<h1><span id="机器学习理论">机器学习理论</span></h1>
<h3><span id="一-机器学习中参数模型和非参数模型理解"><strong>一、 <a href="https://blog.csdn.net/FrankieHello/article/details/94022594">机器学习中参数模型和非参数模型理解</a></strong></span></h3>
<p><strong>参数模型通常假设总体服从某个分布，这个分布可以由一些参数确定，如正态分布由均值和标准差确定，在此基础上构建的模型称为参数模型</strong>；非参数模型对于总体的分布不做任何假设或者说是数据分布假设自由，只知道其分布是存在的，所以就无法得到其分布的相关参数，只能通过非参数统计的方法进行推断。</p>
<p><strong>参数模型</strong>：线性回归、逻辑回归、感知机、基本型的SVM</p>
<p><strong>非参数模型</strong>：决策树、对偶型的SVM、朴素贝叶斯、神经网络</p>
<h3><span id="二-判别模型-vs-生成模型">二、 判别模型 VS 生成模型</span></h3>
<blockquote>
<p>判别模型与生成模型，概率模型与非概率模型、参数模型与非参数模型总结 -
Eureka的文章 - 知乎 https://zhuanlan.zhihu.com/p/37821985</p>
<p><strong>机器学习中的判别式模型和生成式模型</strong> -
Microstrong的文章 - 知乎 https://zhuanlan.zhihu.com/p/74586507</p>
</blockquote>
<p><img src="https://s2.loli.net/2023/04/17/AYyZUiraIdN5Dn1.png" alt="image-20230417171758407" style="zoom:50%;"></p>
<p><img src="v2-9b345d3e93a81dc4e7a88fccff3720b3_b.png" alt="img" style="zoom: 67%;"></p>
<h5><span id="判别模型感知机-逻辑斯特回归-支持向量机-神经网络-k近邻都属于判别学习模型">判别模型：感知机、逻辑斯特回归、支持向量机、神经网络、k近邻都属于判别学习模型。</span></h5>
<p><strong>判别模型分为两种:</strong></p>
<ul>
<li>直接对输入空间到输出空间的映射进行建模, 也就是学习函数 <span class="math inline">\(h\)</span> :</li>
</ul>
<p><span class="math display">\[
h: X \rightarrow Y, s . t . y=h(x)
\]</span></p>
<ul>
<li>对条件概率 <span class="math inline">\(P(y \mid x)\)</span>
进行建模, 然后根据贝叶斯风险最小化的准则进行分类: 【</li>
</ul>
<p><span class="math display">\[
y=\arg \max _{y \in\{-1,1\}} P(y \mid x)
\]</span></p>
<h5><span id="生成模型">生成模型：</span></h5>
<p>生成模型是间接地, 先对 <span class="math inline">\(P(x, y)\)</span>
进行建模, 再根据贝叶斯公式: <span class="math display">\[
P(y \mid x)=\frac{P(x \mid y) P(y)}{P(x)}
\]</span> 算出 <span class="math inline">\(P(y \mid x)\)</span>,
最后根据 <span class="math inline">\(\arg \max _{y \in\{-1,1\}} P(y \mid
x)\)</span> 来做分类 (由此可知, 判别模型实际上不需要对 <span class="math inline">\(P(x, y)\)</span> 进行建模)。</p>
<h3><span id="三-非概率模型-vs-概率模型">三、 非概率模型 VS 概率模型</span></h3>
<p>两者的本质区别在于是否涉及到概率分布。</p>
<h4><span id="概率模型"><strong>概率模型</strong></span></h4>
<blockquote>
<p><strong>线性回归（高斯分布）、LR（伯努利分布）、高斯判别分析、朴素贝叶斯</strong></p>
</blockquote>
<p><strong>概率模型指出了学习的目的是学出 <span class="math inline">\(P(x, y)\)</span> 或 <span class="math inline">\(P(y \mid x)\)</span>, 但最后都是根据 <span class="math inline">\(\arg \max _{y \in\{-1,1\}} P(y \mid x)\)</span>
来做判别归类。</strong>对于 <span class="math inline">\(P(x, y)\)</span>
的估计, 一般是根据乘法公式 <span class="math inline">\(P(x, y)=P(x \mid
y) P(y)\)</span> 将其拆解成 <span class="math inline">\(P(x \mid y),
P(y)\)</span> 分别进行估计。无论是对 <span class="math inline">\(P(x
\mid y), P(y)\)</span> 还是 <span class="math inline">\(P(y \mid
x)\)</span> 的估计, 都是会先假设分布的形式, 例如逻辑斯特回归就假设了
<span class="math inline">\(Y \mid X\)</span> 服从伯努利分
布。分布形式固定以后,
剩下的就是分布参数的估计问题。<strong>常用的估计有极大似然估计(MLE)和极大后验概率估计
(MAP) 等</strong>。其中, 极大后验概率估计涉及到分布参数的先验概率,
这为我们注入先验知识提供了途径。逻辑斯特回归、高斯判别分析、朴素贝叶斯都属于概率模型。</p>
<p>在一定的条件下，非概率模型与概率模型有以下对应关系:</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232129434.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="非概率模型">非概率模型</span></h4>
<blockquote>
<p><strong>感知机、支持向量机、神经网络、k近邻都属于非概率模型</strong>。线性支持向量机可以显式地写出损失函数——hinge损失。神经网络也可以显式地写出损失函数——平方损失。</p>
</blockquote>
<p><font color="red">非概率模型指的是直接学习输入空间到输出空间的映射
<span class="math inline">\(h\)</span>,
学习的过程中基本不涉及概率密度的估计, 概率密度 的积分等操作,
问题的关键在于最优化问题的求解。</font>通常, 为了学习假设 <span class="math inline">\(h(x)\)</span>, 我们会先根据一些先验知识 (prior
knowledge) 来选择一个特定的假设空间 <span class="math inline">\(H(x)\)</span> (函数空间),
例如一个由所有线性函数构成的空间, 然后在
这个空间中找出泛化误差最小的假设出来, <span class="math display">\[
h^*=\arg \min _{h \in H} \varepsilon(h)=\arg \min _{h \in H} \sum_{x, y}
l(h(x), y) P(x, y)
\]</span> 其中 <span class="math inline">\(l(h(x), y)\)</span>
是我们选取的损失函数, 选择不同的损失函数,
得到假设的泛化误差就会不一样。由于我们并不知 道 <span class="math inline">\(P(x, y)\)</span>, 所以即使我们选好了损失函数,
也无法计算出假设的泛化误差, 更别提找到那个给出最小泛化误差的 假设。于是,
我们转而去找那个使得经验误差最小的假设, <span class="math display">\[
g=\arg \min _{h \in H} \hat{\varepsilon}(h)=\arg \min _{h \in H}
\frac{1}{m} \sum_{i=1}^{m} l\left(h\left(x^{(i)}\right), y^{(i)}\right)
\]</span> <strong><font color="red">
这种学习的策略叫经验误差最小化(ERM)，理论依据是大数定律：当训练样例无穷多的时候，假设的经验误差会依概率收敛到假设的泛化误差。</font></strong>要想成功地学习一个问题，必须在学习的过程中注入先验知识。前面，我们根据先验知识来选择假设空间，其实，在选定了假设空间后，先验知识还可以继续发挥作用，这一点体现在为我们的优化问题加上正则化项上，例如常用的<span class="math inline">\(L1\)</span>正则化， <span class="math inline">\(L2\)</span>正则化等。 <span class="math display">\[
g=\arg \min _{h \in H} \hat{\varepsilon}(h)=\arg \min _{h \in H}
\frac{1}{m} \sum_{i=1}^{m} l\left(h\left(x^{(i)}\right),
y^{(i)}\right)+\lambda \Omega(h)
\]</span></p>
<h3><span id="四-过拟合和欠拟合">四、 过拟合和欠拟合</span></h3>
<blockquote>
<p>欠拟合、过拟合及如何防止过拟合 - G-kdom的文章 - 知乎
https://zhuanlan.zhihu.com/p/72038532</p>
</blockquote>
<h4><span id="41-欠拟合">4.1 欠拟合</span></h4>
<p><strong>欠拟合是指模型不能在训练集上获得足够低的误差</strong>。换句换说，就是模型复杂度低，模型在训练集上就表现很差，没法学习到数据背后的规律。</p>
<h4><span id="42-欠拟合解决方法">4.2 欠拟合解决方法</span></h4>
<p>欠拟合基本上都会发生在训练刚开始的时候，经过不断训练之后欠拟合应该不怎么考虑了。但是如果真的还是存在的话，可以通过<strong>增加网络复杂度</strong>或者在模型中<strong>增加特征</strong>，这些都是很好解决欠拟合的方法。</p>
<h4><span id="43-过拟合">4.3 过拟合</span></h4>
<p>过拟合是指训练误差和测试误差之间的差距太大。换句换说，就是模型复杂度高于实际问题，<strong>模型在训练集上表现很好，但在测试集上却表现很差</strong>。模型对训练集"死记硬背"（记住了不适用于测试集的训练集性质或特点），没有理解数据背后的规律，<strong>泛化能力差</strong>。</p>
<p>造成原因主要有以下几种：
1、<strong>训练数据集样本单一，样本不足</strong>。如果训练样本只有负样本，然后那生成的模型去预测正样本，这肯定预测不准。所以训练样本要尽可能的全面，覆盖所有的数据类型。
2、<strong>训练数据中噪声干扰过大</strong>。噪声指训练数据中的干扰数据。过多的干扰会导致记录了很多噪声特征，忽略了真实输入和输出之间的关系。
3、<strong>模型过于复杂。</strong>模型太复杂，已经能够“死记硬背”记下了训练数据的信息，但是遇到没有见过的数据的时候不能够变通，泛化能力太差。我们希望模型对不同的模型都有稳定的输出。模型太复杂是过拟合的重要因素。</p>
<h4><span id="44-如何防止过拟合">4.4 如何防止过拟合</span></h4>
<p>要想解决过拟合问题，就要显著减少测试误差而不过度增加训练误差，从而提高模型的泛化能力。</p>
<h5><span id="1-使用正则化regularization方法">1、<strong>使用正则化（Regularization）方法。</strong></span></h5>
<p>那什么是<a href="https://www.zhihu.com/search?q=正则化&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%2272038532%22%7D">正则化</a>呢？<strong>正则化是指修改学习算法，使其降低泛化误差而非训练误差</strong>。</p>
<p>常用的正则化方法根据具体的使用策略不同可分为：（1）直接提供正则化约束的参数正则化方法，如L1/L2正则化；（2）通过工程上的技巧来实现更低泛化误差的方法，如提前终止(Early
stopping)和Dropout；（3）不直接提供约束的隐式正则化方法，如数据增强等。</p>
<p><strong>L2正则化起到使得权重参数<span class="math inline">\(w\)</span>变小的效果，为什么能防止过拟合呢？</strong>因为更小的权重参数<span class="math inline">\(w\)</span>意味着模型的复杂度更低，对训练数据的拟合刚刚好，不会过分拟合训练数据，从而提高模型的泛化能力。</p>
<h5><span id="2-获取和使用更多的数据数据集增强解决过拟合的根本性方法">2、<strong>获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法</strong></span></h5>
<p>让机器学习或深度学习模型泛化能力更好的办法就是使用更多的数据进行训练。但是，在实践中，我们拥有的数据量是有限的。解决这个问题的一种方法就是<strong>创建“假数据”并添加到训练集中——数据集增强</strong>。通过增加训练集的额外副本来增加训练集的大小，进而改进模型的泛化能力。</p>
<p>我们以图像数据集举例，能够做：旋转图像、缩放图像、随机裁剪、加入随机噪声、平移、镜像等方式来增加数据量。另外补充一句，在物体分类问题里，<strong>CNN在图像识别的过程中有强大的“不变性”规则，即待辨识的物体在图像中的形状、姿势、位置、图像整体明暗度都不会影响分类结果</strong>。我们就可以通过图像平移、翻转、缩放、切割等手段将数据库成倍扩充。</p>
<h5><span id="3采用合适的模型控制模型的复杂度"><strong>3.
采用合适的模型（控制模型的复杂度）</strong></span></h5>
<p>过于复杂的模型会带来过拟合问题。对于模型的设计，目前公认的一个深度学习规律"deeper
is
better"。国内外各种大牛通过实验和竞赛发现，对于CNN来说，层数越多效果越好，但是也更容易产生过拟合，并且计算所耗费的时间也越长。</p>
<p>根据<strong>奥卡姆剃刀法则</strong>：在同样能够解释已知观测现象的假设中，我们应该挑选“最简单”的那一个。对于模型的设计而言，我们应该<strong>选择简单、合适的模型解决复杂的问题</strong>。</p>
<h5><span id="4-降低特征的数量"><strong>4. 降低特征的数量</strong></span></h5>
<p>对于一些特征工程而言，可以降低特征的数量——删除冗余特征，人工选择保留哪些特征。这种方法也可以解决过拟合问题。</p>
<h5><span id="5-dropout"><strong>5. Dropout</strong></span></h5>
<p>Dropout是在训练网络时用的一种技巧（trike），相当于在隐藏单元增加了噪声。<strong>Dropout
指的是在训练过程中每次按一定的概率（比如50%）随机地“删除”一部分隐藏单元（神经元）。</strong>所谓的“删除”不是真正意义上的删除，其实就是将该部分神经元的激活函数设为0（激活函数的输出为0），让这些神经元不计算而已。</p>
<h5><span id="dropout为什么有助于防止过拟合呢"><strong>Dropout为什么有助于防止过拟合呢？</strong></span></h5>
<p>（a）在训练过程中会产生不同的训练模型，不同的训练模型也会产生不同的的计算结果。随着训练的不断进行，计算结果会在一个范围内波动，但是均值却不会有很大变化，因此可以把最终的训练结果看作是不同模型的平均输出。</p>
<p>（b）它消除或者减弱了神经元节点间的联合，降低了网络对单个神经元的依赖，从而增强了泛化能力。</p>
<h5><span id="6-earlystopping提前终止"><strong>6. Early
stopping（提前终止）</strong></span></h5>
<p>对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如<a href="https://www.zhihu.com/search?q=梯度下降&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%2272038532%22%7D">梯度下降</a>（Gradient
descent）。<strong>Early
stopping是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合</strong>。</p>
<p>为了获得性能良好的神经网络，训练过程中可能会经过很多次<a href="https://www.zhihu.com/search?q=epoch&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%2272038532%22%7D">epoch</a>（遍历整个数据集的次数，一次为一个epoch）。如果epoch数量太少，网络有可能发生欠拟合；如果epoch数量太多，则有可能发生过拟合。Early
<a href="https://www.zhihu.com/search?q=stopping&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%2272038532%22%7D">stopping</a>旨在解决epoch数量需要手动设置的问题。具体做法：<strong>每个epoch（或每N个epoch）结束后，在验证集上获取测试结果，随着epoch的增加，如果在验证集上发现测试误差上升，则停止训练，将停止之后的权重作为网络的最终参数。</strong></p>
<p><strong>为什么能防止过拟合？</strong>当还未在神经网络运行太多迭代过程的时候，w参数接近于0，因为随机初始化<a href="https://www.zhihu.com/search?q=w值&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%2272038532%22%7D">w值</a>的时候，它的值是较小的随机值。当你开始迭代过程，w的值会变得越来越大。到后面时，w的值已经变得十分大了。所以early
stopping要做的就是在中间点停止迭代过程。我们将会得到一个中等大小的w参数，会得到与L2正则化相似的结果，选择了w参数较小的神经网络。</p>
<p><strong>Early
Stopping缺点：没有采取不同的方式来解决优化损失函数和过拟合这两个问题</strong>，而是用一种方法同时解决两个问题
，结果就是要考虑的东西变得更复杂。之所以不能独立地处理，因为如果你停止了优化损失函数，你可能会发现损失函数的值不够小，同时你又不希望过拟合。</p>
<h3><span id="五-损失函数loss与评价指标metric的区别">五、损失函数(loss)与评价指标(metric)的区别？</span></h3>
<p><strong>当建立一个学习算法时，我们希望最大化一个给定的评价指标matric（比如说准确度），但算法在学习过程中会尝试优化一个不同的损失函数loss（比如说MSE/Cross-entropy）。</strong></p>
<h4><span id="那为什么不把评价指标matric作为学习算法的损失函数loss呢">那为什么不把评价指标matric作为学习算法的损失函数loss呢？</span></h4>
<ul>
<li><p>一般来说，我认为你应该尝试优化一个与你最关心的评价指标相对应的损失函数。例如，在做分类时，我认为你需要给我一个很好的理由，让我不要优化交叉熵。也就是说，交叉熵并不是一个非常直观的指标，所以一旦你完成了训练，你可能还想知道你的分类准确率有多高，以了解你的模型是否真的能在现实世界中发挥作用，总之，在每个epoch训练完后，你都会有多个评估指标。这样作的主要原因是为了了解你的模型在做什么。这意味着你想要最大化指标A，以便得到一个接近最大化指标B的解决方案。</p></li>
<li><p>通常情况下，MSE/交叉熵比精度更容易优化，因为它们对模型参数是可微的，在某些情况下甚至是凸的，这使得它更容易。</p></li>
</ul>
<h3><span id="六-标准化和归一化">六、标准化和归一化</span></h3>
<blockquote>
<p>PCA、k-means、SVM、回归模型、<strong>神经网络</strong></p>
</blockquote>
<h4><span id="定义">定义</span></h4>
<p><strong>归一化和标准化</strong>都是对<strong>数据做变换</strong>的方式，将原始的一列数据转换到某个范围，或者某种形态，具体的：</p>
<blockquote>
<p><strong>归一化(Normalization)</strong>：将一列数据变化到某个固定区间(范围)中，通常，这个区间是[0,
1]，广义的讲，可以是各种区间，比如映射到[0，1]一样可以继续映射到其他范围，图像中可能会映射到[0,255]，其他情况可能映射到[-1,1]；</p>
<p><strong>标准化(Standardization)</strong>：将数据变换为均值为0，标准差为1的分布切记，<strong>并非一定是正态的；</strong></p>
<p><strong>中心化</strong>：另外，还有一种处理叫做中心化，也叫零均值处理，就是将每个原始数据减去这些数据的均值。</p>
</blockquote>
<h4><span id="差异">差异</span></h4>
<blockquote>
<p><strong>归一化：对处理后的数据范围有严格要求;</strong></p>
<p><strong>标准化: 数据不为稳定，存在极端的最大最小值;
涉及距离度量、协方差计算的时候;</strong></p>
</blockquote>
<ul>
<li><strong>归一化会严格的限定变换后数据的范围</strong>，比如按之前最大最小值处理的，它的范围严格在[
0 , 1
]之间；而<strong>标准化</strong>就没有严格的区间，变换后的数据没有范围，只是其均值是0，标准差为1。</li>
<li><strong>归一化的缩放比例仅仅与极值有关</strong>，容易受到异常值的影响。</li>
</ul>
<h4><span id="用处">用处</span></h4>
<ul>
<li>回归模型，自变量X的量纲不一致导致了<strong>回归系数无法直接解读</strong>或者错误解读；需要将X都处理到统一量纲下，这样才可比；</li>
<li>机器学习任务和统计学任务中有很多地方要用到<strong>“距离”的计算</strong>，比如PCA，比如KNN，比如kmeans等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果；</li>
<li>参数估计时使用<strong>梯度下降</strong>，在使用梯度下降的方法求解最优化问题时，
归一化/标准化后可以加快梯度下降的求解速度，即<strong>提升模型的收敛速度</strong>。</li>
</ul>
<p>其他：log、sigmod、softmax 变换</p>
<h3><span id="七-回归-vs-分类">七、回归 vs 分类</span></h3>
<p>回归问题可以理解为是定量输出的问题，是一个连续变量预测；分类问题可以理解为是定性输出的问题，是一个离散变量预测。</p>
<p><font color="red">如何理解回归与分类？</font></p>
<h3><span id="八-常见损失函数求导">八、常见损失函数求导</span></h3>
<h4><span id="sigmod-交叉熵求导">sigmod 交叉熵求导</span></h4>
<p>交叉熵损失函数为：</p>
<p><span class="math display">\[
J(\theta)=-\frac{1}{m} \sum_{i=1}^m y^{(i)} \log
\left(h_\theta\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log
\left(1-h_\theta\left(x^{(i)}\right)\right)
\]</span> 其中: <span class="math display">\[
\begin{gathered}
\log h_\theta\left(x^{(i)}\right)=\log \frac{1}{1+e^{-\theta^T
x^{(i)}}}=-\log \left(1+e^{-\theta^T x^{(i)}}\right), \\
\log \left(1-h_\theta\left(x^{(i)}\right)\right)=\log
\left(1-\frac{1}{1+e^{-\theta^T x^{(i)}}}\right)=\log
\left(\frac{e^{-\theta^T x^{(i)}}}{1+e^{-\theta^T x^{(i)}}}\right) \\
=\log \left(e^{-\theta^T x^{(i)}}\right)-\log \left(1+e^{-\theta^T
x^{(i)}}\right)=-\theta^T x^{(i)}-\log \left(1+e^{-\theta^T
x^{(i)}}\right)
\end{gathered}
\]</span> 由此, 得到: <span class="math display">\[
\begin{gathered}
J(\theta)=-\frac{1}{m} \sum_{i=1}^m\left[-y^{(i)}\left(\log
\left(1+e^{-\theta^T
x^{(i)}}\right)\right)+\left(1-y^{(i)}\right)\left(-\theta^T
x^{(i)}-\log \left(1+e^{-\theta^T x^{(i)}}\right)\right)\right] \\
=-\frac{1}{m} \sum_{i=1}^m\left[y^{(i)} \theta^T x^{(i)}-\theta^T
x^{(i)}-\log \left(1+e^{-\theta^T x^{(i)}}\right)\right] \\
=-\frac{1}{m} \sum_{i=1}^m\left[y^{(i)} \theta^T x^{(i)}-\log
e^{\theta^T x^{(i)}}-\log \left(1+e^{-\theta^T x^{(i)}}\right)\right] \\
=-\frac{1}{m} \sum_{i=1}^m\left[y^{(i)} \theta^T x^{(i)}-\left(\log
e^{\theta^T x^{(i)}}+\log \left(1+e^{-\theta^T
x^{(i)}}\right)\right)\right]\\
=-\frac{1}{m} \sum_{i=1}^m\left[y^{(i)} \theta^T x^{(i)}-\log
\left(1+e^{\theta^T x^{(i)}}\right)\right]
\end{gathered}
\]</span> 由此, 得到: <span class="math display">\[
\begin{aligned}
&amp; J(\theta)=-\frac{1}{m} \sum_{i=1}^m {\left[-y^{(i)}\left(\log
\left(1+e^{-\theta^T
x^{(i)}}\right)\right)+\left(1-y^{(i)}\right)\left(-\theta^T
x^{(i)}-\log \left(1+e^{-\theta^T x^{(i)}}\right)\right)\right] } \\
&amp;=-\frac{1}{m} \sum_{i=1}^m\left[y^{(i)} \theta^T x^{(i)}-\theta^T
x^{(i)}-\log \left(1+e^{-\theta^T x^{(i)}}\right)\right] \\
&amp;=-\frac{1}{m} \sum_{i=1}^m\left[y^{(i)} \theta^T x^{(i)}-\log
e^{\theta^T x^{(i)}}-\log \left(1+e^{-\theta^T x^{(i)}}\right)\right] \\
&amp;=-\frac{1}{m} \sum_{i=1}^m\left[y^{(i)} \theta^T x^{(i)}-\left(\log
e^{\theta^T x^{(i)}}+\log \left(1+e^{-\theta^T
x^{(i)}}\right)\right)\right] \\
&amp;=-\frac{1}{m} \sum_{i=1}^m\left[y^{(i)} \theta^T x^{(i)}-\log
\left(1+e^{\theta^T x^{(i)}}\right)\right]
\end{aligned}
\]</span> 求导: <span class="math display">\[
\begin{aligned}
&amp; \frac{\partial}{\partial \theta_j}
J(\theta)=\frac{\partial}{\partial \theta_j}\left(\frac{1}{m}
\sum_{i=1}^m\left[\log \left(1+e^{\theta^T x^{(i)}}\right)-y^{(i)}
\theta^T x^{(i)}\right]\right) \\
&amp; =\frac{1}{m} \sum_{i=1}^m\left[\frac{\partial}{\partial \theta_j}
\log \left(1+e^{\theta^T x^{(i)}}\right)-\frac{\partial}{\partial
\theta_j}\left(y^{(i)} \theta^T x^{(i)}\right)\right] \\
&amp; =\frac{1}{m} \sum_{i=1}^m\left(\frac{x_j^{(i)} e^{\theta^T
x^{(i)}}}{1+e^{\theta^T x^{(i)}}}-y^{(i)} x_j^{(i)}\right) \\
&amp; =\frac{1}{m}
\sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right) x_j^{(i)}
\\
&amp;
\end{aligned}
\]</span> 这就是交叉熵对参数的导数： <span class="math display">\[
\frac{\partial}{\partial \theta_j} J(\theta)=\frac{1}{m}
\sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right) x_j^{(i)}
\]</span></p>
<h4><span id="平方损失函数绝对值-hubor损失为例gbdt残差"><strong>平方损失函数</strong>【绝对值、hubor损失】为例（GBDT
残差）：</span></h4>
<blockquote>
<p><span class="math display">\[
  \begin{aligned}
  &amp;g_{i}=\frac{\partial\left(\hat{y}^{t-1}-y_{i}\right)^{2}}{\partial
\hat{y}^{t-1}}=2\left(\hat{y}^{t-1}-y_{i}\right) \\
  &amp;h_{i}=\frac{\partial^{2}\left(\hat{y}^{t-1}-y_{i}\right)^{2}}{\hat{y}^{t-1}}=2
  \end{aligned}
  \]</span></p>
</blockquote>
<h4><span id="softmax-函数求导">softmax 函数求导</span></h4>
<p>softmax 回归的参数矩阵 <span class="math inline">\(\theta\)</span>
可以记为 <span class="math display">\[
\theta=\left[\begin{array}{c}
\theta_{1}^{T} \\
\theta_{2}^{T} \\
\vdots \\
\theta_{k}^{T}
\end{array}\right]
\]</span> 定义 softmax 回归的代价函数 <span class="math display">\[
L(\theta)=-\frac{1}{m}\left[\sum_{i=1}^{m} \sum_{j=1}^{k}
1\left\{y_{i}=j\right\} \log \frac{e^{\theta_{j}^{T}
x_{i}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x_{i}}}\right]
\]</span> 其中, 1{:}是示性函数, 即 <span class="math inline">\(1\{\)</span> 值为真的表达式 <span class="math inline">\(\}=1 ， 1\{\)</span> 值为假的表达式 <span class="math inline">\(\}=0\)</span> 。跟 logistic 函数一样,
利用梯度下降法最小化代价函数, 下面 求解 <span class="math inline">\(\theta\)</span> 的梯度。 <span class="math inline">\(L(\theta)\)</span> 关于 <span class="math inline">\(\theta_{j}\)</span> 的梯度求解为 <span class="math display">\[
\begin{aligned}
\frac{\partial L(\theta)}{\partial \theta_{j}} &amp;=-\frac{1}{m}
\frac{\partial}{\partial \theta_{j}}\left[\sum_{i=1}^{m} \sum_{j=1}^{k}
1\left\{y_{i}=j\right\} \log \frac{e^{\theta_{j}^{T}
x_{i}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x_{i}}}\right] \\
&amp;=-\frac{1}{m} \frac{\partial}{\partial
\theta_{j}}\left[\sum_{i=1}^{m} \sum_{j=1}^{k}
1\left\{y_{i}=j\right\}\left(\theta_{j}^{T} x_{i}-\log \sum_{l=1}^{k}
e^{\theta_{l}^{T} x_{i}}\right)\right] \\
&amp;=-\frac{1}{m}\left[\sum_{i=1}^{m}
1\left\{y_{i}=j\right\}\left(x_{i}-\sum_{j=1}^{k}
\frac{e^{\theta_{j}^{T} x_{i}} \cdot x_{i}}{\sum_{l=1}^{k}
e^{\theta_{l}^{T} x_{i}}}\right)\right] \\
&amp;=-\frac{1}{m}\left[\sum_{i=1}^{m} x_{i}
1\left\{y_{i}=j\right\}\left(1-\sum_{j=1}^{k} \frac{e^{\theta_{j}^{T}
x_{i}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x_{i}}}\right)\right] \\
&amp;=-\frac{1}{m}\left[\sum_{i=1}^{m}
x_{i}\left(1\left\{y_{i}=j\right\}-\sum_{j=1}^{k}
1\left\{y_{i}=j\right\} \frac{e^{\theta_{j}^{T} x_{i}}}{\sum_{l=1}^{k}
e^{\theta_{l}^{T} x_{i}}}\right)\right] \\
&amp;=-\frac{1}{m}\left[\sum_{i=1}^{m}
x_{i}\left(1\left\{y_{i}=j\right\}-\frac{e^{\theta_{j}^{T}
x_{i}}}{\sum_{l=1}^{k} e^{\theta_{l}^{T} x_{i}}}\right)\right] \\
&amp;=-\frac{1}{m}\left[\sum_{i=1}^{m}
x_{i}\left(1\left\{y_{i}=j\right\}-p\left(y_{i}=j \mid x_{i} ;
\theta\right)\right)\right]
\end{aligned}
\]</span></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>理论基础（4）回归评价指标</title>
    <url>/posts/510TZM/</url>
    <content><![CDATA[<h3><span id="一-回归问题评价指标">一、回归问题评价指标</span></h3>
<blockquote>
<p><strong>均方差损失 Mean Squared Loss、平均绝对误差损失 Mean Absolute
Error Loss、Huber Loss、分位数损失 Quantile Loss</strong></p>
</blockquote>
<p>机器学习中的监督学习本质上是给定一系列训练样本 <span class="math inline">\(\left(x_i, y_i\right)\)</span>, 尝试学习 <span class="math inline">\(x \rightarrow y\)</span> 的映射关系, 使得给定一个
<span class="math inline">\(x\)</span>, 即便这个 <span class="math inline">\(x\)</span> 不在训练样本中, 也能够得到尽量接近真实
<span class="math inline">\(y\)</span> 的输出 <span class="math inline">\(\hat{y}\)</span> 。而损失函数 (Loss Function)
则是这个过 程中关键的一个组成部分, 用来<strong>衡量模型的输出 <span class="math inline">\(\hat{y}\)</span> 与真实的 <span class="math inline">\(y\)</span> 之间的差距</strong>,
给模型的优化指明方向。</p>
<h4><span id="11-均方差损失-mse-l2-loss">1.1 均方差损失 MSE、L2 loss</span></h4>
<h5><span id="111-基本形式与原理">1.1.1 <strong>基本形式与原理</strong></span></h5>
<p><strong>均方差Mean Squared Error
(MSE)损失是机器学习、深度学习回归任务中最常用的一种损失函数, 也称为 L2
Loss</strong>。其基本形式如下: <span class="math display">\[
J_{M S E}=\frac{1}{N} \sum_{i=1}^N\left(y_i-\hat{y_i}\right)^2
\]</span> 从直觉上理解均方差损失，这个损失函数的最小值为 0
（当预测等于真实值时），最大值为无穷大。下图是对于真 实值 <span class="math inline">\(y=0\)</span>, 不同的预测值 <span class="math inline">\([-1.5,1.5]\)</span>
的均方差损失的变化图。横轴是不同的预测值, 纵轴是均方差损失, 可以
看到随着预测与真实值绝对误差 <span class="math inline">\(|y-\hat{y}|\)</span> 的增加,
均方差损失呈二次方地增加。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232145431.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h5><span id="112-背后的假设">1.1.2 背后的假设</span></h5>
<p><strong>【独立同分布-中心极限定理】</strong>： 如果 <span class="math inline">\(\left\{X_n\right\}\)</span> 独立同分布, 且 <span class="math inline">\(\mathbb{E} X=\mu, \mathbb{D}
X=\sigma^2&gt;0\)</span> ，则 <span class="math inline">\(\mathrm{n}\)</span> 足够大时 <span class="math inline">\(\bar{X}_n\)</span> 近似服从正态分布 <span class="math inline">\(N\left(\mu, \frac{\sigma^2}{n}\right)\)</span> 即
<span class="math display">\[
\lim _{n \rightarrow \infty} P\left(\frac{\bar{X}_n-\mu}{\sigma /
\sqrt{n}}&lt;a\right)=\Phi(a)=\int_{-\infty}^a \frac{1}{\sqrt{2 \pi}}
e^{-t^2 / 2} d t
\]</span> 实际上在一定的假设下,
我们可以使用最大化似然得到均方差损失的形式。假设<strong>模型预测与真实值之间的误差服从标准高斯分布</strong>
<span class="math inline">\((\mu=0, \sigma=1)\)</span> ，则给定一个
<span class="math inline">\(x_i\)</span> 模型输出真实值 <span class="math inline">\(y_i\)</span> 的概率为 <span class="math display">\[
p\left(y_i \mid x_i\right)=\frac{1}{\sqrt{2 \pi}} \exp
\left(-\frac{\left(y_i-\hat{y}_i\right)^2}{2}\right)
\]</span> <strong>进一步我们假设数据集中 <span class="math inline">\(\mathrm{N}\)</span> 个样本点之间相互独立,
则给定所有 <span class="math inline">\(x\)</span> 输出所有真实值 <span class="math inline">\(y\)</span> 的概率, 即似然 Likelihood</strong>,
为所有 <span class="math inline">\(p\left(y_i \mid x_i\right)\)</span>
的累乘 <span class="math display">\[
L(x, y)=\prod_{i=1}^N \frac{1}{\sqrt{2 \pi}} \exp
\left(-\frac{\left(y_i-\hat{y}_i\right)^2}{2}\right)
\]</span> 通常为了计算方便，我们通常最大化对数似然Log-Likelihood <span class="math display">\[
L L(x, y)=\log (L(x, y))=-\frac{N}{2} \log 2 \pi-\frac{1}{2}
\sum_{i=1}^N\left(y_i-\hat{y_i}\right)^2
\]</span> 去掉与 <span class="math inline">\(\hat{y_i}\)</span>
无关的第一项, 然后转化为最小化负对数似然 Negative Log-Likelihood <span class="math display">\[
N L L(x, y)=\frac{1}{2} \sum_{i=1}^N\left(y_i-\hat{y}_i\right)^2
\]</span>
可以看到这个实际上就是均方差损失的形式。<strong>也就是说在模型输出与真实值的误差服从高斯分布的假设下,
最小化均方差损失函数与极大似然估计本质上是一致的</strong>,
因此在这个假设能被满足的场景中（比如回归）,
均方差损失是一个很好的损失函数选择；当这个假设没能被满足的场景中（比如分类），均方差损失不是一
个好的选择。</p>
<h5><span id="hulu-百面机器学习-平方根误差的意外"><strong><font color="red">
hulu 百面机器学习 —— 平方根误差的”意外“</font></strong></span></h5>
<p><strong>95%的时间区间效果很好，RMSE指标居高不下的原因？</strong>
<span class="math display">\[
J_{M S E}=\frac{1}{N} \sum_{i=1}^N\left(y_i-\hat{y_i}\right)^2
\]</span>
一般情况下RSME能反应预测值与真实值的偏离程度，但是<strong>易受离群点</strong>的影响；</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>数据预处理将噪音去掉</li>
<li>将离群点的产生机制建模进去</li>
<li>更鲁棒的模型评估指标：<strong>平均绝对百分比误差</strong>（MAPE），<strong>分位数损失</strong></li>
</ul>
<h4><span id="12-平均绝对误差-mae">1.2 <strong>平均绝对误差 MAE</strong></span></h4>
<h5><span id="121-基本形式与原理">1.2.1 <strong>基本形式与原理</strong></span></h5>
<p><strong>平均绝对误差 Mean Absolute Error (MAE)
是另一类常用的损失函数, 也称为 L1 Loss</strong>。其基本形式如下 <span class="math display">\[
J_{M A E}=\frac{1}{N} \sum_{i=1}^N\left|y_i-\hat{y_i}\right|
\]</span> 同样的我们可以对这个损失函数进行可视化如下图, MAE
损失的最小值为 0 (当预测等于真实值时），最大值为
无穷大。可以看到随着预测与真实值绝对误差 <span class="math inline">\(|y-\hat{y}|\)</span> 的增加, MAE
损失呈线性增长。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232148454.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h5><span id="122-背后的假设">1.2.2 背后的假设</span></h5>
<p>同样的我们可以在一定的假设下通过最大化似然得到 MAE 损失的形式,
假设模型预测与真实值之间的误差服 从拉普拉斯分布 Laplace distribution
<span class="math inline">\((\mu=0, b=1)\)</span>, 则给定一个 <span class="math inline">\(x_i\)</span> 模型输出真实值 <span class="math inline">\(y_i\)</span> 的概率为 <span class="math display">\[
p\left(y_i \mid x_i\right)=\frac{1}{2} \exp
\left(-\left|y_i-\hat{y_i}\right|\right)
\]</span> 与上面推导 MSE 时类似, 我们可以得到的负对数似然实际上就是 MAE
损失的形式 <span class="math display">\[
\begin{gathered}
L(x, y)=\prod_{i=1}^N \frac{1}{2} \exp
\left(-\left|y_i-\hat{y}_i\right|\right) \\
L L(x, y)=N \ln \frac{1}{2}-\sum_{i=1}^N\left|y_i-\hat{y}_i\right| \\
N L L(x, y)=\sum_{i=1}^N\left|y_i-\hat{y}_i\right|
\end{gathered}
\]</span></p>
<h4><span id="13-mae-与-mse-区别">1.3 MAE 与 MSE 区别</span></h4>
<p>MAE 和 MSE 作为损失函数的主要区别是：<strong>MSE 损失相比 MAE
通常可以更快地收敛，但 MAE 损失对于 outlier
更加健壮</strong>，即更加不易受到 outlier 影响。</p>
<ul>
<li><p><strong>MSE 通常比 MAE
可以更快地收敛</strong>。当使用梯度下降算法时, MSE 损失的梯度为 <span class="math inline">\(-\hat{y}_i\)</span>, 而 MAE 损失的梯度为 <span class="math inline">\(\pm 1\)</span> , 即 MSE 的梯度的 scale
会随误差大小变化, 而 MAE 的梯度的 scale 则一直保持为 1 , 即便在绝对误 差
<span class="math inline">\(\left|y_i-\hat{y}_i\right|\)</span>
很小的时候 MAE 的梯度 scale 也同样为 1 ,
这实际上是非常不利于模型的训练的。当然你可以通
过在训练过程中动态调整学习率缓解这个问题, 但是总的来说,
损失函数梯度之间的差异导致了 MSE 在大部 分时候比 MAE
收敛地更快。这个也是 MSE 更为流行的原因。</p></li>
<li><p><strong>MAE 对于异常值（outlier） 更加
robust</strong>。我们可以从两个角度来理解这一点：</p>
<ul>
<li><p>第一个角度是直观地理解，下图是 MAE 和 MSE
损失画到同一张图里面，由于MAE 损失与绝对误差之间是线性关系，MSE
损失与误差是平方关系，当误差非常大的时候，MSE 损失会远远大于 MAE
损失。<strong>因此当数据中出现一个误差非常大的 outlier 时，MSE
会产生一个非常大的损失，对模型的训练会产生较大的影响</strong>。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232151110.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure></li>
<li><p>第二个角度是从两个损失函数的假设出发，MSE
假设了误差服从高斯分布，MAE
假设了误差服从拉普拉斯分布。拉普拉斯分布本身对于 outlier 更加
robust。参考下图（来源：<a href="https://link.zhihu.com/?target=https%3A//www.cs.ubc.ca/~murphyk/MLbook/">Machine
Learning: A Probabilistic Perspective</a> 2.4.3 The Laplace distribution
Figure 2.8），当右图右侧出现了 outliers
时，拉普拉斯分布相比高斯分布受到的影响要小很多。因此以拉普拉斯分布为假设的
MAE 对 outlier 比高斯分布为假设的 MSE 更加
robust。<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232151431.jpg" alt="img" style="zoom: 67%;"></p></li>
</ul></li>
</ul>
<h4><span id="14-huber-loss">1.4 Huber Loss</span></h4>
<blockquote>
<ul>
<li>在误差接近 0 时使用 MSE，使损失函数可导并且梯度更加稳定</li>
<li>在误差较大时使用 MAE 可以降低 outlier 的影响，使训练对 outlier
更加健壮。</li>
</ul>
</blockquote>
<p>上文我们分别介绍了 MSE 和 MAE 损失以及各自的优缺点, MSE
损失收玫快但容易受 outlier 影响, MAE 对 outlier 更加健壮但是收玫慢,
Huber LosS 则是一种将 MSE 与 MAE 结合起来, 取两者优点的损失函数,
也被称作 Smooth Mean Absolute Error Loss 。其原理很简单, 就是在误差接近
0 时使用 MSE, 误差较大时使用 MAE, 公 式为 <span class="math display">\[
J_{\text {huber }}=\frac{1}{N} \sum_{i=1}^N
\mathbb{I}_{\left|y_i-\hat{y_i}\right| \leq \delta}
\frac{\left(y_i-\hat{y_i}\right)^2}{2}+\mathbb{I}_{\left|y_i-\hat{y}_i\right|&gt;\delta}\left(\delta\left|y_i-\hat{y_i}\right|-\frac{1}{2}
\delta^2\right)
\]</span> 上式中 <span class="math inline">\(\delta\)</span> 是 Huber
Loss 的一个超参数, <span class="math inline">\(\delta\)</span> 的值是
MSE 和 MAE 两个损失连接的位置。上式等号右边第一项是 MSE 的部分, 第二项是
MAE 部分, 在 MAE 的部分公式为 <span class="math inline">\(\delta\left|y_i-\hat{y_i}\right|-\frac{1}{2}
\delta^2\)</span> 是为了保证误差 <span class="math inline">\(|y-\hat{y}|= \pm \delta\)</span> 时 MAE 和 MSE
的取值一致，进而保证 Huber Loss 损失连续可导。</p>
<p>下图是 <span class="math inline">\(\delta=1.0\)</span> 时的 Huber
Loss, 可以看到在 <span class="math inline">\([-\delta, \delta]\)</span>
的区间内实际上就是 MSE 损失, 在 <span class="math inline">\((-\infty,
\delta)\)</span> 和 <span class="math inline">\((\delta,
\infty)\)</span> 区 间内为 MAE损失。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232151667.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="15-分位数损失-quantile-loss">1.5 分位数损失 Quantile Loss</span></h4>
<blockquote>
<p><strong>MAE
中分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong></p>
</blockquote>
<p><strong>分位数回归 Quantile Regression
是一类在实际应用中非常有用的回归算法</strong>，通常的回归算法是拟合目标值的期望或者中位数，而分位数回归可以通过给定不同的分位点，<strong>拟合目标值的不同分位数</strong>。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232151641.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>分位数回归是通过使用分位数损失 Quantile Loss 来实现这一点的,
分位数损失形式如下, 式中的 r 分位数系数</strong>。 <span class="math display">\[
J_{\text {quant }}=\frac{1}{N} \sum_{i=1}^N \mathbb{I}_{\hat{y}_i \geq
y_i}(1-r)\left|y_i-\hat{y_i}\right|+\mathbb{I}_{\hat{y}_i&lt;y_i}
r\left|y_i-\hat{y_i}\right|
\]</span> 我们如何理解这个损失函数呢? 这个损失函数是一个分段的函数, 将
<span class="math inline">\(\hat{y}_i \geq y_i \quad\)</span> (高估) 和
<span class="math inline">\(\hat{y}_i&lt;y_i \quad\)</span> (低估) 两种
情况分开来, 并分别给予不同的系数。当 <span class="math inline">\(r&gt;0.5\)</span> 时,
低估的损失要比高估的损失更大, 反过来当 <span class="math inline">\(r&lt;0.5\)</span> 时, 高估的损失比低估的损失大;
分位数损失实现了<strong>分别用不同的系数控制高估和低估的损失,
进而实现分位数回归</strong>。 特别地, 当 <span class="math inline">\(r=0.5\)</span> 时, 分位数损失退化为 MAE 损失,
从这里可以看出 MAE 损失实际上是分位数损失的一个特 例 一 中位数回归。</p>
<p>下图是取不同的分位点 <span class="math inline">\(0.2 、 0.5 、
0.6\)</span> 得到的三个不同的分位损失函数的可视化，可以看到 0.2 和 0.6
在高估和低 估两种情况下损失是不同的, 而 0.5 实际上就是 MAE。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232152365.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="16-平均绝对百分误差-mape">1.6 平均绝对百分误差 MAPE</span></h4>
<p>虽然平均绝对误差能够获得一个评价值,
但是你并不知道这个值代表模型拟合是优还是劣, 只有通过对比才能达到
效果。当需要以相对的观点来衡量误差时, 则使用MAPE。
平均绝对百分误差（Mean Absolute Percentage Error, MAPE）是对 MAE
的一种改进, 考虑了绝对误差相对 真实值的比例。 -
优点：考虑了预测值与真实值的误差。考虑了误差与真实值之间的比例。 <span class="math display">\[
M A P E=\frac{100}{m}
\sum_{i=1}^m\left|\frac{y_i-f\left(x_i\right)}{y_i}\right|
\]</span> 在某些场景下, 如房价从 <span class="math inline">\(5
K\)</span> 到 <span class="math inline">\(50 K\)</span> 之间, <span class="math inline">\(5 K\)</span> 预测成 <span class="math inline">\(10
K\)</span> 与 <span class="math inline">\(50 K\)</span> 预测成 <span class="math inline">\(45 K\)</span> 的差别是非常大的, 而平均
绝对百分误差考虑到了这点。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>理论基础（4）分类评价指标</title>
    <url>/posts/1PQETBX/</url>
    <content><![CDATA[<h3><span id="一-二分类问题">一、二分类问题</span></h3>
<blockquote>
<p><strong>阈值调节问题？</strong></p>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232135565.png" alt="image-20220421165422230" style="zoom:50%;"></p>
<ul>
<li><strong>准确率 (Accuracy)</strong>：<strong>预测正确的概率</strong>
【<strong>(TP+TN)/(TP+TN+FP+FN)</strong>】</li>
<li><strong>精确率（查准率 Precision
)：预测为正的样本中实际为正的样本的概率</strong>
【<strong>TP/(TP+FP)</strong>】</li>
<li>错误发现率（FDR）= 1 - 精确率 = 预测为正的样本中实际为负的样本的概率
【<strong>FP/(TP+FP)</strong>】</li>
<li><strong>召回率（查全率）-
Recall</strong>：<strong>实际为正的样本中被预测为正样本的概率</strong>【<strong>TP/(TP+FN)</strong>】</li>
<li><strong>真正率（TPR） = 灵敏度（召回率） =</strong>
<strong>TP/(TP+FN)</strong></li>
<li><strong>假正率（FPR） = 1- 特异度 =</strong>
<strong>FP/(FP+TN)</strong></li>
<li><strong>F1=是准确率和召回率的调和平均值
(2×Precision×Recall)/（Precision+Recall）</strong></li>
<li>G-mean <span class="math inline">\((\mathrm{GM})=\)</span>
是准确率和召回率的几何平均值 <span class="math inline">\(G-\)</span>
mean <span class="math inline">\(=\sqrt{\text { Recall } \cdot \text {
Precision }}\)</span></li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232135401.png" alt="image-20220421165436795" style="zoom:50%;"></p>
<h4><span id="11-f1">1.1 <strong>F1</strong></span></h4>
<p>精确率（Precision）和召回率（Recall）之间的关系用图来表达，就是下面的PR曲线。可以发现他们俩的关系是「两难全」的关系。为了综合两者的表现，在两者之间找一个平衡点，就出现了一个
F1分数。</p>
<p><strong>F1=(2×Precision×Recall) /（Precision+Recall）</strong></p>
<p>P意义类似于每通过准确预测得到TP个正例需要TP+FP个预测类别为正例的样本。</p>
<p>R意义类似于每通过成功召回得到TP个正例需要TP+FN个真实类别为正例的样本。</p>
<p>F1度量了给定一批样本，对这一批样本进行预测与召回，最终得到的正例的多少。<strong>其中一半的正例是通过预测得到的，一半的正例是通过召回得到的。</strong></p>
<p>有一种把预测所需的预测类别为正例的样本和召回所需的真实类别为正例的样本看作原料，而我们的目标正例样本看作产品的感觉。<strong>所以也能解释为什么P跟R其中一者比较低的时候，F1会偏低。因为跟算术平均数不一样，两者不能互相替代，两部分各负责一半。那么加权调和平均Fbeta也可以很好的理解了。</strong></p>
<p><span class="math display">\[
\frac{1}{F_\beta}=\frac{1}{1+\beta^2}
\cdot\left(\frac{1}{P}+\frac{\beta^2}{R}\right)
\]</span></p>
<p>各自负责的比例不一样了。因此beta越大，Fbeta越着重考虑召回能力。</p>
<h4><span id="12-rocauc的概念">1.2 ROC/AUC的概念</span></h4>
<h5><span id="1灵敏度特异度真正率假正率">（1）<strong>灵敏度，特异度，真正率，假正率</strong></span></h5>
<p>在正式介绍ROC/AUC之前，我们还要再介绍两个指标，<strong>这两个指标的选择也正是ROC和AUC可以无视样本不平衡的原因。</strong>
这两个指标分别是：<strong>灵敏度和（1-特异度），也叫做真正率（TPR）和假正率（FPR）</strong>。其实我们可以发现<strong>灵敏度和召回率是一模一样的，只是名字换了而已</strong>。由于我们比较关心正样本，所以需要查看有多少负样本被错误地预测为正样本，所以使用（1-特异度），而不是特异度。</p>
<p><strong>真正率（TPR） = 灵敏度（召回率） =</strong>
<strong>TP/(TP+FN)</strong></p>
<p><strong>假正率（FPR） = 1- 特异度 =</strong>
<strong>FP/(FP+TN)</strong></p>
<p>下面是真正率和假正率的示意，我们发现<strong>TPR和FPR分别是基于实际表现1和0出发的，也就是说它们分别在实际的正样本和负样本中来观察相关概率问题。</strong></p>
<blockquote>
<p>正因为如此，所以无论样本是否平衡，都不会被影响。还是拿之前的例子，总样本中，90%是正样本，10%是负样本。我们知道用准确率是有水分的，但是用TPR和FPR不一样。这里，TPR只关注90%正样本中有多少是被真正覆盖的，而与那10%毫无关系，同理，FPR只关注10%负样本中有多少是被错误覆盖的，也与那90%毫无关系，</p>
</blockquote>
<p><strong>如果我们从实际表现的各个结果角度出发，就可以避免样本不平衡的问题了，这也是为什么选用TPR和FPR作为ROC/AUC的指标的原因。</strong></p>
<h5><span id="2roc接受者操作特征曲线">（2）ROC（接受者操作特征曲线）</span></h5>
<blockquote>
<p>ROC（Receiver Operating
Characteristic）曲线，又称接受者操作特征曲线。该曲线最早应用于雷达信号检测领域，用于区分信号与噪声。后来人们将其用于评价模型的预测能力，ROC曲线是基于<strong>混淆矩阵</strong>得出的。</p>
</blockquote>
<p>ROC曲线中的主要两个指标就是<strong>真正率</strong>和<strong>假正率，</strong>
上面也解释了这么选择的好处所在。其中<strong>横坐标为假正率（FPR），纵坐标为真正率（TPR）</strong>，下面就是一个标准的ROC曲线图。</p>
<h5><span id="3auc的缺陷">（3）AUC的缺陷？</span></h5>
<p><strong>优点</strong>：目前普遍认为接收器工作特性曲线（ROC）曲线下的面积—AUC是评估分类模型准确性的标准方法。<strong>它避免了在阈值选择过程中假定的主观性</strong>，当连续的概率得到的分数被转换为二分类标签时，通过总结整体模型表现，其衡量模型区分正负样本的性能优于通过阈值来判断的其他方法（比如准确率、召回率等）。</p>
<ul>
<li><strong>忽略了预测的概率值和模型的拟合优度</strong></li>
<li><strong>AUC反应了太过笼统的信息。无法反应召回率、精确率等在实际业务中经常关心的指标</strong></li>
<li><font color="red">
<strong>对FPR和TPR两种错误的代价同等看待</strong></font></li>
<li>它没有给出模型误差的空间分布信息</li>
<li>最重要的一点，AUC的misleading的问题</li>
</ul>
<p><strong>auc仅反应模型的排序能力，无法反应模型的拟合优度；auc很多时候无法直接反应细粒度的和业务目标更相关的metric信息，例如
top
k的准确率，召回率等等（例如同auc的模型在不同的区间的预测能力是存在差别的）；</strong></p>
<h4><span id="13-k-s曲线">1.3、K-S曲线</span></h4>
<p><strong>K-S曲线, 又称作洛伦兹曲线</strong>。实际上,
K-S曲线的数据来源以及本质和ROC曲线是一致的, 只是ROC曲线是把真 正率 <span class="math inline">\((T P R)\)</span> 和假正率 <span class="math inline">\((F P R)\)</span> 当作横纵轴,
<strong>而K-S曲线是把真正率 <span class="math inline">\((T P R)\)</span>
和假正率 <span class="math inline">\((F P R\)</span> ) 都当作是
纵轴，横轴则由选定的阈值来充当。从 K-S 曲线就能衍生出 <span class="math inline">\(K S\)</span> 值, <span class="math inline">\(K
S=\max (T P R-F P R)\)</span> ，即是两条曲线
之间的最大间隔距离。</strong></p>
<p><strong>K-S曲线的画法:</strong></p>
<ol type="1">
<li><strong>排序</strong>: 对于二元分类器来说,
模型训练完成之后每个样本都会得到一个类概率值, 把样本按这个类概率值从大
到小进行排序；</li>
<li><strong>找阈值</strong>: 取排序后前 <span class="math inline">\(10
\% \times k(k=1,2,3, \ldots, 9)\)</span> 处的值（概率值）作为阈值,
分别计算出不同的 <span class="math inline">\(T P R\)</span> 和 <span class="math inline">\(F P R\)</span> 值, 以 <span class="math inline">\(10 \% \times k(k=1,2,3, \ldots, 9)\)</span>
为横坐标, 分别以 <span class="math inline">\(T P R\)</span> 和 <span class="math inline">\(F P R\)</span> 值为纵坐标, 就可以画出两个曲
线，这就是K-S曲线，类似于下图。</li>
<li><strong>KS值</strong>:从 K-S 曲线就能衍生出 <span class="math inline">\(K S\)</span> 值, <span class="math inline">\(K
S=\max (T P R-F P R)\)</span> ，即是两条曲线之间的最大间隔距离。KS值越大
表示模型 的区分能力越强。</li>
</ol>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232137558.jpg" alt="img" style="zoom: 50%;"></p>
<h4><span id="14-lift曲线">1.4 Lift曲线</span></h4>
<p><strong>Lift曲线它衡量的是，与不利用模型相比，模型的预测能力“变好”了多少，lift(提升指数)越大，模型的运行效果越好。实质上它强调的是投入与产出比</strong>。</p>
<p><strong>tip:</strong>理解<strong>Lift</strong>可以先看一下Quora上的一篇文章：<strong><a href="https://link.zhihu.com/?target=https%3A//www.quora.com/Whats-Lift-curve">What's
Lift curve?</a></strong></p>
<p><strong>Lift计算公式：</strong>先介绍几个相关的指标，以免混淆：</p>
<ul>
<li>准确率 (accuracy, ACC) :</li>
</ul>
<p><span class="math display">\[
A C C=\frac{T P+T N}{F P+F N+T P+T N}
\]</span></p>
<ul>
<li>正确率(Precision, PRE), 查准率:</li>
</ul>
<p><span class="math display">\[
P R E=\frac{T P}{T P+F P}
\]</span></p>
<ul>
<li>真阳性率(True Positive Rate,
TPR)，灵敏度(Sensitivity)，召回率(Recall):</li>
</ul>
<p><span class="math display">\[
T P R=\frac{T P}{T P+F N}
\]</span></p>
<ul>
<li>假阳性率(False Positice Rate, FPR), 误诊率( = 1 - 特异度):</li>
</ul>
<p><span class="math display">\[
F P R=\frac{F P}{F P+T N}
\]</span></p>
<p><strong>Lift计算公式：</strong> <span class="math display">\[
L i f t=\frac{\frac{T P}{T P+F P}}{\frac{T P+F N}{T P+F P+T N+F
N}}=\frac{P R E}{\text { 正例占比 }}
\]</span> 根据以上公式可知, <font color="red">Lift指标可以这样理解:
在不使用模型的情况下, 我们用先验概率估计正例的比例, 即上式子分母部分,
以此作为正例的命中率;</font> 利用模型后,
我们不需要从整个样本中来挑选正例, 只需要从我们预测为正例
的那个样本的子集 <span class="math inline">\(T P+F P\)</span>
中挑选正例, 这时正例的命中率为 <span class="math inline">\(P R
E\)</span>, 后者除以前者即可得提升值Lift 。</p>
<h5><span id="lift曲线">Lift曲线:</span></h5>
<p>为了作出LIft曲线，首先引入 depth 的概念: <span class="math display">\[
\operatorname{depth}=\frac{T P+F P}{T P+F P+T N+F N}
\]</span> 从公式可以看出, depth
代表的是预测为正例的样本占整个样本的比例。</p>
<p>当阈值为 0 时, 所有的样本都被预测为正例, 因此 <span class="math inline">\(\operatorname{depth}=1\)</span>, 于是 <span class="math inline">\(L i f t=1\)</span>, 模型末起提升作用。随着阈值逐
渐增大, 被预测为正例的样本数逐渐减少, depth 减小,
而较少的预测正例样本中的真实正例比例逐渐增大。当阈 值增大至1时,
没有样本被预测为正例, 此时 depth <span class="math inline">\(=0\)</span>, 而 Lift <span class="math inline">\(=0\)</span> 。由此可见, Lift 与 depth 存在相反方
向变化的关系。在此基础上作出 Lift 图:</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232138374.jpg" alt="img" style="zoom: 50%;"></p>
<p>一般要求, 在尽量大的 depth 下得到尽量大的 Lift, 所以 Lift
曲线的右半部分应该尽量陡峭。</p>
<h4><span id="15-p-r曲线">1.5 <strong>P-R曲线</strong></span></h4>
<ul>
<li><p><strong>精确率（查准率）- Precision
：预测为正的样本中实际为正的样本的概率</strong>
【<strong>TP/(TP+FP)</strong>】</p></li>
<li><p><strong>召回率（查全率）-
Recall</strong>：<strong>实际为正的样本中被预测为正样本的概率</strong>【<strong>TP/(TP+FN)</strong>】</p></li>
</ul>
<p>P-R曲线刻画<strong>查准率</strong>和<strong>查全率（召回率）</strong>之间的关系，查准率指的是在所有预测为正例的数据中，真正例所占的比例，查全率是指预测为真正例的数据占所有正例数据的比例。查准率和查全率是一对矛盾的度量，一般来说，查准率高时，查全率往往偏低，查全率高时，查准率往往偏低。</p>
<p>在很多情况下，我们可以根据学习器的预测结果对样例进行排序，排在前面的是学习器认为最可能是正例的样本，排在后面的是学习器认为最不可能是正例的样本，按此顺序逐个把样本作为正例进行预测，则每次可计算当前的查全率和查准率，以查准率为y轴，以查全率为x轴，可以画出下面的P-R曲线。</p>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/v2-dc6abbb24e2dfbfefe4777408d2a8e5c_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>如果一个学习器的P-R曲线被另一个学习器的P-R曲线完全包住，则可断言后者的性能优于前者，当然我们可以根据曲线下方的面积大小来进行比较，但更常用的是<strong>平衡点</strong>或者是F1值。</p>
<ul>
<li><strong>平衡点（BEP）</strong>是查准率=查全率时的取值，如果这个值较大，则说明学习器的性能较好。F1值越大，我们可以认为该学习器的性能较好。</li>
<li><font color="red">
<strong>F1度量</strong>：<strong>BEP过于简单，这个平衡点是建立在”查准率=查全率“的前提下，无法满足实际不同场景的应用。</strong></font></li>
</ul>
<p>我们先来引入加权调和平均: <span class="math inline">\(F_\beta\)</span> : <span class="math display">\[
\frac{1}{F_\beta}=\frac{1}{1+\beta^2}\left(\frac{1}{P}+\frac{\beta^2}{R}\right)
\text { 公式 }(1)
\]</span> <strong>加权调和平均与算术平均 <span class="math inline">\(\frac{P+R}{2}\)</span> 和几何平均 <span class="math inline">\(\sqrt{P+R}\)</span> 相比,
调和平均更重视较小值（这可以从倒数上看出 来）</strong>。当 <span class="math inline">\(\beta=1\)</span>,
即F1是基于查准率和查全率的调和平均定义的, <span class="math inline">\(\mathrm{F} 1\)</span> 的公式如下: <span class="math display">\[
\frac{1}{F_1}=\frac{1}{2}\left(\frac{1}{P}+\frac{1}{R}\right)
\]</span> 我们把公式求倒数，即可得： <span class="math display">\[
F 1=\frac{2 * P * R}{P+R}
\]</span> 在一些应用中,
对查准率和查全率的重视程度不同。例如在商品推荐中, 为了尽可能少打扰用户,
更希望推荐的内 容确实是用户感兴趣的, 此时查准率更重要;
而在罪犯信息检索或者病人检查系统中, 更希望尽可能少的漏判, 此
时查全率更重要。F1度量的一般形式是 <span class="math inline">\(F_\beta\)</span>
，能让我们自定义对查准率/查全率的不同偏好: <span class="math display">\[
F_\beta=\frac{\left(1+\beta^2\right) * P * R}{\left(\beta^2 *
P\right)+R}
\]</span> <strong>其中, <span class="math inline">\(\beta&gt;0\)</span>
度量了查全率对查准率的相对重要性 (不明白的同学可以回看公式1）， <span class="math inline">\(\beta=1\)</span> 时退化为标准F1, <span class="math inline">\(\beta&gt;1\)</span> 时查全率有更大影响; <span class="math inline">\(\beta&lt;1\)</span> 时,
查准率有更大影响。</strong></p>
<h4><span id="16-对数损失log-loss">1.6 <strong>对数损失(Log Loss)</strong></span></h4>
<p><strong>AUC
ROC考虑用于确定模型性能的预测概率</strong>。<font color="red">然而, AUC
ROC存在问题, 它只考虑概率的顺序,
因此没有考虑模型预测更可能为正样本的更高概率的能力(即考虑了大小,
但没有考虑更高精度)。</font>在这种情况下, 我们可以使用对数损失,
即每个实例的正例预测概率的对数的负平均值。</p>
<p>对数损失 (Logistic Loss, logloss)
是对预测概率的似然估计，其标准形式为： <span class="math display">\[
\log \operatorname{loss}=\log P(Y \mid X)
\]</span> 对数损失最小化本质是上利用样本中的已知分布,
求解拟合这种分布的最佳模型参数, 使这种分布出现概率最大。</p>
<p>对数损失对应的二分类的计算公式为： <span class="math display">\[
\log \operatorname{loss}=-\frac{1}{N} \sum_{i=1}^N\left(y_i \log
\hat{y}_i+\left(1-y_i\right) \log \left(1-\hat{y}_i\right)\right), \quad
y \in[0,1]
\]</span> 其中 <span class="math inline">\(\mathrm{N}\)</span> 为样本数,
<span class="math inline">\(\hat{y}_i\)</span> 为预测为 1
的概率。对数损失在多分类问题中也可以使用，其计算公式为: <span class="math display">\[
\log \operatorname{loss}=-\frac{1}{N} \frac{1}{C} \sum_{i=1}^N
\sum_{j=1}^C\left(y_{i j} \log \hat{y_{i j}}\right), \quad y \in[0,1]
\]</span> 其中, <span class="math inline">\(\mathrm{N}\)</span>
为样本数, C为类别数, logloss衡量的是预测概率分布和真实概率分布的差异性,
取值越小越好。</p>
<h4><span id="17-多分类">1.7 多分类</span></h4>
<p>很多时候我们有多个<strong>二分类混洧矩阵</strong>，例如进行多次训练测试，每次得到一个混淆矩阵；或是在多个数据集上进
行训练测试，希望估计算法的全局性能; 或者是执行分类任务,
每两两类别的组合都对应一个混淆矩阵; 总之是在 <strong><span class="math inline">\(\mathrm{n}\)</span>
个分类混淆矩阵上综合考察查准率和查全率</strong>。</p>
<ul>
<li><strong>宏观:</strong> 在各个混淆军阵上分别计算出查准率和查全率,
记为 <span class="math inline">\((P 1, R 1),(P 2, R 2),
\ldots(\mathrm{Pn}, \mathrm{Rn})\)</span>,
在<strong>计算平均值</strong>, 这样 就得到“宏观查准率"(macro-P),
“宏观查全率”(macro-R)、“宏观F1"(macro-F1):</li>
</ul>
<p><span class="math display">\[
\begin{gathered}
\text { macro }-P=\frac{1}{n} \sum_{i=1}^n P_i \\
\text { macro }-R=\frac{1}{n} \sum_{i=1}^n R_i \\
\text { macro }-F 1=\frac{2 * \text { macro }-P * \text { macro
}-R}{\text { macro }-P+\text { macro }-R}
\end{gathered}
\]</span></p>
<ul>
<li><strong>微观：</strong>将个混淆矩阵对应的元素进行平均,
得到TP、FP、TN、FN的平均值, 分别记为 <span class="math inline">\(\overline{T P} 、 \overline{F P} 、 \overline{F
N}\)</span> 、 <span class="math inline">\(\overline{T N}\)</span>,
再基于这些平均值计算出“微观查准率"(micro-P),
“微观查全率”(micro-R)、“微观F1"(micro-F1):</li>
</ul>
<p><span class="math display">\[
\begin{gathered}
\text { micro }-P=\frac{\overline{T P}}{\overline{T P}+\overline{F P}}
\\
\text { micro }-R=\frac{\overline{T P}}{\overline{T P}+\overline{F N}}
\\
\text { micro }-F 1=\frac{2 * \text { micro }-P * \text { micro
}-R}{\text { micro }-P+\text { micro }-R}
\end{gathered}
\]</span></p>
<h3><span id="二-评分总结sklearn">二、评分总结（sklearn）</span></h3>
<blockquote>
<p>sklearn.metrics -
回归/分类模型的评估方法:https://zhuanlan.zhihu.com/p/408078074</p>
</blockquote>
<h4><span id="21-分类模型">2.1 分类模型</span></h4>
<h5><span id="accuracy_score"><strong>accuracy_score</strong></span></h5>
<p><strong>分类准确率分数是指所有分类正确的百分比</strong>。分类准确率这一衡量分类器的标准比较容易理解，但是它不能告诉你响应值的潜在分布，并且它也不能告诉你分类器犯错的类型。所以在使用的时候，一般需要搭配matplotlib等数据可视化工具来观察预测的分类情况，与实际的结果做更加直观的比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score  </span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>]  </span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]  </span><br><span class="line">accuracy_score(y_true, y_pred)  <span class="comment"># 默认normalization = True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.5</span></span><br><span class="line">accuracy_score(y_true, y_pred, normalize=<span class="literal">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">2</span></span><br></pre></td></tr></table></figure>
<h5><span id="recall_score"><strong>recall_score</strong></span></h5>
<p>召回率 =<strong>提取出的正确信息条数
/样本中的信息条数</strong>。通俗地说，就是所有准确的条目有多少被检索出来了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">recall_score(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>,average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">参数average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br></pre></td></tr></table></figure>
<p>将一个二分类matrics拓展到多分类或多标签问题时，我们可以将数据看成多个二分类问题的集合，每个类都是一个二分类。接着，我们可以通过跨多个分类计算每个二分类metrics得分的均值，这在一些情况下很有用。你可以使用<strong>average参数</strong>来指定。</p>
<ul>
<li>macro：计算二分类metrics的均值，为每个类给出相同权重的分值。</li>
<li>weighted:对于不均衡数量的类来说，计算二分类metrics的平均，通过在每个类的score上进行加权实现。</li>
<li>micro：给出了每个样本类以及它对整个metrics的贡献的pair（sample-weight），而非对整个类的metrics求和，它会每个类的metrics上的权重及因子进行求和，来计算整个份额。</li>
<li>samples：应用在multilabel问题上。它不会计算每个类，相反，它会在评估数据中，通过计算真实类和预测类的差异的metrics，来求平均（sample_weight-weighted）</li>
<li>average：average=None将返回一个数组，它包含了每个类的得分.</li>
</ul>
<h5><span id="roc_curve"><strong>roc_curve</strong></span></h5>
<p>ROC曲线指受试者工作特征曲线/接收器操作特性(receiver operating
characteristic，ROC)曲线,是<strong>反映灵敏性和特效性连续变量的综合指标</strong>,是用构图法揭示敏感性和特异性的相互关系，它通过将连续变量设定出多个不同的临界值，从而计算出一系列敏感性和特异性。ROC曲线是根据一系列不同的二分类方式（分界值或决定阈），<strong>以真正例率（也就是灵敏度）（True
Positive Rate,TPR）为纵坐标，假正例率（1-特效性）（False Positive
Rate,FPR）为横坐标</strong>绘制的曲线。</p>
<p>通过ROC我们可以观察到模型正确识别的正例的比例与模型错误地把负例数据识别成正例的比例之间的权衡。TPR的增加以FPR的增加为代价。ROC曲线下的面积是模型准确率的度量，<strong>AUC</strong>（Area
under roc curve）。</p>
<p><strong>TPR</strong> = TP /（TP + FN）
（正样本<strong>预测数</strong> / 正样本<strong>实际数</strong>）</p>
<p><strong>FPR</strong> = FP /（FP + TN）
（负样本<strong>预测数</strong> /负样本<strong>实际数</strong>）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics  </span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>])  </span><br><span class="line">scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=<span class="number">2</span>)  </span><br><span class="line">fpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.</span> ,  <span class="number">0.5</span>,  <span class="number">0.5</span>, <span class="number">1.</span> ])  </span><br><span class="line">tpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.5</span>,  <span class="number">0.5</span>,  <span class="number">1.</span> , <span class="number">1.</span> ])  </span><br><span class="line">thresholds  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.8</span> ,  <span class="number">0.4</span> ,  <span class="number">0.35</span>, <span class="number">0.1</span> ])  </span><br><span class="line"></span><br><span class="line"><span class="comment"># check auc score</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> auc   </span><br><span class="line">metrics.auc(fpr, tpr)   </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以直接根据预测值+真实值来计算出auc值，略过roc的计算过程</span></span><br><span class="line">‘’‘</span><br><span class="line">sklearn.metrics.roc_auc_score(y_true, y_score, average=<span class="string">&#x27;macro&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br><span class="line">’‘’</span><br><span class="line"><span class="comment"># 真实值（必须是二值）、预测值（可以是0/1,也可以是proba值）</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score  </span><br><span class="line">y_true = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])  </span><br><span class="line">y_scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">roc_auc_score(y_true, y_scores)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>  </span><br></pre></td></tr></table></figure>
<h5><span id="confusion-metric"><strong>confusion metric</strong></span></h5>
<p>混淆矩阵（confusion
matrix），又称为可能性表格或是错误矩阵。它是一种特定的矩阵用来呈现算法性能的可视化效果。其每一列代表预测值，每一行代表的是实际的类别。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">confusion_matric(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>, average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h5><span id="precision_score"><strong>precision_score</strong></span></h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">precision_score(y_true, y_pred, labels=None, pos_label=1, average=&#x27;binary&#x27;)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232157475.jpg" alt="preview">
<figcaption aria-hidden="true">preview</figcaption>
</figure>
<h3><span id="三-评价指标qampa">三、评价指标Q&amp;A</span></h3>
<h5><span id="精度指标存在的问题"><strong>精度指标存在的问题</strong>？</span></h5>
<ul>
<li>有倾向性的问题。比如，判断空中的飞行物是导弹还是其他飞行物，很显然为了减少损失，我们更倾向于相信是导弹而采用相应的防护措施。此时判断为导弹实际上是其他飞行物与判断为其他飞行物实际上是导弹这两种情况的重要性是不一样的；</li>
<li>样本类别数量严重不均衡的情况。比如银行客户样本中好客户990个，坏客户10个。如果一个模型直接把所有客户都判断为好客户，得到精度为99%，但这显然是没有意义的。</li>
</ul>
<h5><span id="为什么-roc和-auc-都能应用于非均衡的分类问题"><strong>为什么 ROC
和 AUC 都能应用于非均衡的分类问题？</strong></span></h5>
<p><strong>ROC曲线只与横坐标 (FPR) 和 纵坐标 (TPR) 有关系</strong>
。我们可以发现TPR只是正样本中预测正确的概率，而FPR只是负样本中预测错误的概率，和正负样本的比例没有关系。因此
ROC
的值与实际的正负样本比例无关，因此既可以用于均衡问题，也可以用于非均衡问题。而
AUC 的几何意义为ROC曲线下的面积，因此也和实际的正负样本比例无关。</p>
<h4><span id="参考文献">参考文献</span></h4>
<ul>
<li>一文看懂机器学习指标：准确率、精准率、召回率、F1、ROC曲线、AUC曲线:https://zhuanlan.zhihu.com/p/93107394</li>
<li><strong>机器学习-最全面的评价指标体系:
https://zhuanlan.zhihu.com/p/359997979</strong></li>
<li><a href="https://github.com/HaoMood/homepage/blob/master/files/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8-03-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0.pdf">机器学习工程师面试宝典-03-模型评估</a></li>
<li><strong><a href="http://www.china-nb.cn/gongsidongtai/17-85.html">分类模型评估指标——准确率、精准率、召回率、F1、ROC曲线、AUC曲线</a></strong></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>理论基础（4）其他评价指标</title>
    <url>/posts/2WWJ575/</url>
    <content><![CDATA[<h3><span id="一-相似性度量指标">一、相似性度量指标</span></h3>
<blockquote>
<p>机器学习中的相似性度量方法 - 天下客的文章 - 知乎
https://zhuanlan.zhihu.com/p/411876558</p>
</blockquote>
<p>描述样本之间相似度的方法有很多种，一般来说常用的有相关系数和欧式距离。本文对机器学习中常用的相似性度量方法进行了总结。<strong>在做分类时，常常需要估算不同样本之间的相似性度量（Similarity
Measurement），</strong>这时通常采用的方法就是计算样本间的“距离”（distance）。采用什么样的方法计算距离是很讲究的，甚至关系到分类的正确与否。</p>
<ul>
<li><strong>欧式距离</strong>：k-means</li>
<li><strong>曼哈顿距离</strong>：</li>
<li><strong>切比雪夫距离</strong>：</li>
<li>闵可夫斯基距离</li>
<li>标准化欧氏距离</li>
<li>马氏距离</li>
<li><a href="https://www.zhihu.com/search?q=夹角余弦&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%2255493039%22%7D">夹角余弦</a></li>
<li><strong>汉明距离</strong>：simhash</li>
<li><strong>杰卡德距离&amp;杰卡德相似系数</strong>:
<strong>杰卡德相似系数是衡量两个集合的相似度一种指标。</strong></li>
<li>相关系数&amp;相关距离</li>
<li>信息熵</li>
</ul>
<h3><span id="二-推荐算法评价指标">二、推荐算法评价指标</span></h3>
<ul>
<li>推荐算法评价指标 - 一干正事就犯困的文章 - 知乎
https://zhuanlan.zhihu.com/p/359528909</li>
</ul>
<h4><span id="21-ap">2.1 AP</span></h4>
<p><code>AP</code> 衡量的是训练好的模型在每个类别上的好坏；</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232155563.jpg" alt="img" style="zoom: 67%;"></p>
<p><strong>AP总结了一个精确召回曲线，作为在每个阈值处获得的精度的加权平均值,
并且与以前的阈值相比, 召回率的增 加用作权重</strong>: <span class="math display">\[
A P=\sum_n\left(R_n-R_{(n-1))} P_n)\right.
\]</span> 其中和分别是第 <span class="math inline">\(\mathrm{n}\)</span>
个阈值 1 时的精度和召回率。此实现末进行揷值,
并且与使用梯形规则计算精确调用曲线下的面
积有所不同，后者使用线性揷值并且可能过于乐观。</p>
<h4><span id="22-map">2.2 MAP</span></h4>
<p><strong>MAP (Mean Average Precision)
常用于排序任务，MAP的计算涉及另外两个指标：Precision和Recall</strong></p>
<ul>
<li><strong>Precision和Precision@k</strong>,
推荐算法中的精度precision计算如下：</li>
</ul>
<p><span class="math display">\[
\text { precision }=\frac{\text { 算法结果中相关的item数量 }}{\text {
推荐的item总数量 }}
\]</span></p>
<p>可以看出Precision的计算没有考虑结果列表中item的顺序，Precision@k则通过切片的方式将顺序隐含在结果
中。Precision@k表示列表前k项的Precision, 随着k的变化,
可以得到一系列precision值, 用 <span class="math inline">\(P(k)\)</span>
表示。</p>
<ul>
<li><strong>Recall和Recall@k</strong>,
推荐算法中的召回率recall计算如下：</li>
</ul>
<p><span class="math display">\[
\text { recall }=\frac{\text { 算法结果中相关的 } i t e m \text { 数量
}}{\text { 所有相关的item数量 }}
\]</span></p>
<p>与Precision@kk相似, recall@k表示结果列表前k项的recall, 随着k的变化,
可以得到一系列的recall值, 用 <span class="math inline">\(r(k)\)</span>
表示。</p>
<ul>
<li><strong>AP@N</strong>, AP (Average Precision)
平均精度的计算以Precision@k为基础, 可以体现出结果列表中item顺序的重要性,
其 计算过程如下:</li>
</ul>
<p><span class="math display">\[
A P @ N=\frac{1}{m} \sum_{k=1}^N(P(k) \quad \text { if kth item is
relevant })=\frac{1}{m} \sum_{k=1}^N P(k) \cdot r e l(k)
\]</span></p>
<p>其中, <span class="math inline">\(\mathrm{N}\)</span> 表示要求推荐的
<span class="math inline">\(\mathrm{N}\)</span> 个item, <span class="math inline">\(\mathrm{m}\)</span> 表示所有相关的item总数, <span class="math inline">\(r e l(k)\)</span> 表示第 <span class="math inline">\(k\)</span> 个item是否相关, 相关为 1 , 反 之为
0</p>
<p>AP@N的值越大，表示推荐列表中相关的item数量越多以及相关item的排名越靠前</p>
<ul>
<li><strong>MAP@N</strong></li>
</ul>
<p><strong>AP@N评价了算法对单个用户的性能，MAP@N则是算法对多个用户的平均值，是平均数的平均，其计算过程如下</strong>：
<span class="math display">\[
M A P @ N=\frac{1}{|U|} \sum_{u=1}^{|U|}(A P @ N) u=\frac{1}{|U|} \sum
u=1^{|U|}\left(\frac{1}{m} \sum_{k=1}^N P_u(k) \cdot r e l_u(k)\right)
\]</span></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>关联规则（1）概述</title>
    <url>/posts/1E0CW4H/</url>
    <content><![CDATA[<h3><span id="一-关联规则概述">一、关联规则概述</span></h3>
<p><font color="red">关联规则-策略挖掘中必不可少的算法。</font></p>
<p>1993年，Agrawal等人在首先提出关联规则概念，迄今已经差不多30年了，在各种算法层出不穷的今天，这算得上是老古董了，比很多人的年纪还大，往往是数据挖掘的入门算法，但深入研究的不多，尤其在风控领域，有着极其重要的应用潜力，是一个被低估的算法。</p>
<span id="more"></span>
<h4><span id="11-关联评价">1.1 关联评价</span></h4>
<p>关联规则有三个核心概念需要理解：<strong>支持度、置信度、提升度</strong>，下面用最经典的啤酒-尿不湿案例给大家举例说明这三个概念，假如以下是几名客户购买订单的商品列表：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271442867.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p><strong><font color="red">（1）支持度</font></strong></p>
<p><strong>支持度
(Support)：</strong>指某个<strong>商品组合出现的次数</strong>与<strong>总订单数</strong>之间的比例。</p>
<p>在这个例子中，我们可以看到“牛奶”出现了 4 次，那么这 5
笔订单中“牛奶”的支持度就是 4/5=0.8。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271443574.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>同样“牛奶 + 面包”出现了 3 次，那么这 5 笔订单中“牛奶 +
面包”的支持度就是 3/5=0.6</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271443641.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>这样理解起来是不是非常简单了呢，大家可以动动手计算下
<strong>'尿不湿+啤酒'</strong>的支持度是多少？</p>
<h5><span id="2置信度">（2）置信度</span></h5>
<p><strong>置信度 (Confidence)：</strong>指的就是当你购买了商品
A，会有多大的概率购买商品
B，在包含A的子集中，B的支持度，也就是包含B的订单的比例。</p>
<p>置信度（牛奶→啤酒）=
3/4=0.75，代表购买了牛奶的订单中，还有多少订单购买了啤酒，如下面的表格所示。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271443708.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>置信度（啤酒→牛奶）=
3/4=0.75，代表如果你购买了啤酒，有多大的概率会购买牛奶？</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271443782.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>置信度（啤酒→尿不湿）=
4/4=1.0，代表如果你购买了啤酒，有多大的概率会买尿不湿，下面的表格看出来是100%。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271443851.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>由上面的例子可以看出，置信度其实就是个条件概念，就是说在 A
发生的情况下，B
发生的概率是多大。如果仅仅知道这两个概念，很多情况下还是不够用，需要用到提升度的概念。比如A出现的情况下B出现的概率为80%，那到底AB是不是有关系呢，不一定，人家B本来在大盘中的比例95%。你的A出现，反而减少了B出现的概率。</p>
<p><strong>（3）提升度</strong></p>
<p><strong>提升度
(Lift)：</strong>我们在做商品推荐或者风控策略的时候，重点考虑的是提升度，因为提升度代表的是A
的出现，对B的出现概率提升的程度。</p>
<p><strong>提升度 (A→B) = 置信度 (A→B) / 支持度 (B)</strong></p>
<p>所以提升度有三种可能：</p>
<ul>
<li><p>提升度 (A→B)&gt;1：代表有提升；</p></li>
<li><p>提升度 (A→B)=1：代表有没有提升，也没有下降；</p></li>
<li><p>提升度 (A→B)&lt;1：代表有下降。</p></li>
</ul>
<p>提升度 (啤酒→尿不湿) =置信度 (啤酒→尿不湿) /支持度 (尿不湿) = 1.0/0.8
= 1.25，可见啤酒对尿不湿是有提升的，提升度为1.25，大于1。</p>
<p><strong>可以简单理解为：在全集的情况下，尿不湿的概率为80%，而在包含啤酒这个子集中，尿不湿的概率为100%，因此，子集的限定，提高了尿不湿的概率，啤酒的出现，提高了尿不湿的概率。</strong></p>
<p><strong>（4）频繁项集</strong></p>
<p><strong>频繁项集(frequent itemset)
：</strong>就是支持度大于等于最小支持度 (Min Support)
阈值的项集，所以小于最小值支持度的项目就是非频繁项集，而大于等于最小支持度的的项集就是频繁项集，项集可以是单个商品，也可以是组合。</p>
<p><strong>频繁集挖掘面临的最大难题就是项集的组合爆炸</strong>，如下图：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271449952.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>随着商品数量增多，这个网络的规模将变得特别庞大，我们不可能根据传统方法进行统计和计算，为了解决这个问题，Apriori算法提出了两个核心思想：</p>
<ul>
<li><p><strong><font color="red">某个项集是频繁的，那么它的所有子集也是频繁的</font></strong>
{Milk, Bread, Coke} 是频繁的 → {Milk, Coke} 是频繁的</p></li>
<li><p><strong><font color="red">如果一个项集是非频繁项集，那么它的所有超集也是非频繁项集</font></strong>
{Battery} 是非频繁的 → {Milk, Battery} 也非平凡</p></li>
</ul>
<p>如下图，如果我们已知<strong>B</strong>不频繁，那么可以说图中所有绿色的项集都不频繁，搜索时就要这些项避开，减少计算开销。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271449043.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>同理，如果下图所示，{A,B}这个项集是非频繁的，那虚线框后面的都不用计算了。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271451871.png" alt="图片" style="zoom: 33%;"></p>
<p><strong>需要注意的是：</strong></p>
<p>1）如果支持度和置信度阈值过高，虽然可以在一定程度上减少数据挖掘的时间，但是一些隐含在数据中的非频繁特征项容易被忽略掉，难以发现足够有用的规则；</p>
<p>2）如果支持度和置信度阈值过低，可能会导致大量冗余和无效的规则产生，导致较大计算量负荷。</p>
<h4><span id="12-应用场景">1.2 应用场景</span></h4>
<p><strong>（1）电商行业</strong></p>
<p>著名的“啤酒尿布”案例，通过分析历史用户的支付订单记录，挖掘出比如中年男人会同时购买啤酒和尿布两种商品，后续可以在商品陈列、打折促销组合、交叉营销发送优惠券等场景中应用。穿⾐搭配推荐穿⾐搭配是服饰鞋包</p>
<p>导购中⾮常重要的课题，基于搭配专家和达⼈⽣成的搭配组合数据，百万级别的商品的⽂本和图像数据，以及⽤户的⾏为数据。期待能从以上⾏为、⽂本和图像数据中挖掘穿⾐搭配模型，为⽤户提供个性化、优质的、专业的穿⾐搭配⽅案，预测给定商品的搭配商品集合。</p>
<p><strong>（2）社会民生</strong></p>
<ul>
<li>互联⽹情绪指标和⽣猪价格的关联关系挖掘和预测</li>
<li>⽓象关联分析</li>
<li>交通事故成因分析</li>
</ul>
<p><strong>（3）金融行业</strong></p>
<ul>
<li>银⾏客户交叉销售分析</li>
<li>银⾏营销⽅案推荐</li>
</ul>
<p><strong>（4）文娱体育</strong></p>
<ul>
<li>影视演员组合</li>
<li>球员最优组合</li>
</ul>
<p><strong>（5）网络安全</strong></p>
<ul>
<li><strong>自动化规则生成</strong></li>
</ul>
<h4><span id="13-常见算法">1.3 常见算法</span></h4>
<p><strong>（1）算法</strong></p>
<ul>
<li><strong>关联规则算法</strong>：<font color="red">典型如Apriori，PySpark中为FP-Growth；</font></li>
</ul>
<p>关联规则算法是挖掘频繁项集的算法，1993年由Rakesh Agrawal
和Ramakrishnan Skrikant提出，并应用于IBM的业务场景。</p>
<ul>
<li><strong>序列模式算法</strong>：典型算法如Apriori-All，PySpark中为PrefixSpan；</li>
</ul>
<p>与关联规则算法类似，不同点在于序列模式会考虑频繁项集中的时序先后关系</p>
<p><strong>（2）优化</strong></p>
<p>大部分的算法都是<strong>先频繁模式再关联规则流</strong>，<font color="red">算法的优化目的都是减少数据扫描的时间成本</font>。</p>
<ul>
<li><strong>树基算法</strong>：FP-Growth, PrePost,
CFP-Growth算法等，<strong>核心要义是把原始事务数据转换为树状数据结构，减少扫描事务的成本。</strong></li>
<li><strong>二进制向量算法</strong>：BitTableFI,
IndexBitTableFI等，<strong>核心要义是把原始数据转换为二进制向量，用逻辑运算与矩阵运算来代替数据扫描，加快速度。</strong></li>
<li><strong>可靠采样流派</strong>：中心极限定理等，<strong>核心要义是通过采样来减少数据规模来加速</strong>。<font color="red">支持度就是频率，频率与其对应概率的差根据中心极限定理服从期望为0的正态分布。以此为理论基础，可以在频繁模式支持度误差可控的情况下，推导出合理的样本规模。</font></li>
<li><strong>渐进采样流派</strong>：Progressive
sampling，不推公式（当然有些算法用到了齐夫定理，但是鉴于Zipf定理是经验定理，不算很严谨），慢慢增加样本，然后选取几个代表性的项集，以其两个样本规模间的支持度变化量来决定采样是否足够。当变化足够小时，说明样本够了。</li>
</ul>
<h3><span id="二-参考文献">二、参考文献</span></h3>
<ul>
<li><a href="https://www.zhihu.com/question/52145607/answer/198035075">目前流行的<em>关联规则</em>算法有哪些？</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzA4OTAwMjY2Nw==&amp;mid=2650188496&amp;idx=1&amp;sn=b6b9f65ee6ba40457b23fc0e35c8f4e7&amp;chksm=88238d14bf540402e7049e41aca6bfea2f2870827a134d770eb716eed9582dbbde65d50d9b7f&amp;scene=21#wechat_redirect">关联规则-策略挖掘中必不可少的算法</a></li>
<li>关联规则挖掘在实际中的应用有哪些? - 李小翰的回答 - 知乎
https://www.zhihu.com/question/62342815/answer/2616887115</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>关联规则</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>关联规则</tag>
        <tag>频繁项集</tag>
      </tags>
  </entry>
  <entry>
    <title>理论基础（6）模型融合</title>
    <url>/posts/1A55BTN/</url>
    <content><![CDATA[<h3><span id="模型融合">模型融合</span></h3>
<p>没有哪个机器学习模型可以常胜，如何找到当前问题的最优解是一个永恒的问题。</p>
<p>幸运的是，<strong>结合/融合/整合 (integration/ combination/
fusion)多个机器学习模型往往可以提高整体的预测能力。</strong>这是一种非常有效的提升手段，在多分类器系统(multi-classifier
system)和集成学习(ensemble learning)中，融合都是最重要的一个步骤。</p>
<p>一般来说，<strong>模型融合或多或少都能提高的最终的预测能力，且一般不会比最优子模型差</strong>。举个实用的例子，Kaggle比赛中常用的stacking方法就是模型融合，通过结合多个各有所长的子学习器，我们实现了更好的预测结果。基本的理论假设是：<strong>不同的子模型在不同的数据上有不同的表达能力，我们可以结合他们擅长的部分，得到一个在各个方面都很“准确”的模型</strong>。当然，最基本的假设是子模型的误差是互相独立的，这个一般是不现实的。但即使子模型间的误差有相关性，适当的结合方法依然可以各取其长，从而达到提升效果。</p>
<p>我们今天介绍几种简单、有效的模型结合方法。</p>
<h3><span id="一-案例分析">一、案例分析</span></h3>
<p>让我们给出一个简单的分析。假设我们有天气数据X和对应的标签 <span class="math inline">\(\mathrm{y}\)</span>,
现在希望实现一个可以预测明天天气的模型 <span class="math inline">\(\psi\)</span> 。但我们并不知道用什么算法效果最好,
于是尝试了十种算法, 包括</p>
<ul>
<li>算法1: 逻辑回归- <span class="math inline">\(C_1\)</span></li>
<li>算法2: 支持向量机 (SVM) - <span class="math inline">\(C_2\)</span></li>
<li>...</li>
<li>算法10: 随机森林 - <span class="math inline">\(C_{10}\)</span></li>
</ul>
<p>结果发现他们表现都一般，在验证集上的误分率比较高。我们现在期待找到一种方法，可以有效提高最终预测结果。</p>
<h3><span id="二-平均法投票法"><strong>二、 平均法/投票法</strong></span></h3>
<p>一种比较直白的方法就是对让 10 个算法模型同时对需要预测的数据进行预测,
并对结果取平均数/众数。假设 10 个 分类器对于测试数据 <span class="math inline">\(X_t\)</span> 的预测结果是 <span class="math inline">\(\left[C_1\left(X_t\right), C_2\left(X_t\right),
\ldots, C_{10}\left(X_t\right)\right]=[0,1,1,1,1,1,0,1,1,0]\)</span>
，那很显然少数服 从多数, 我们应该选择1作为 <span class="math inline">\(X_t\)</span>
的预测结果。如果取平均值的话也可以那么会得到 0.7 , 高于阈值 0.5 ,
因此是等 价的。</p>
<p>但这个时候需要有几个注意的地方：</p>
<p><strong>首先，不同分类器的输出结果取值范围不同</strong>，不一定是[0,1]，而可以是无限定范围的值。举例，逻辑回归的输出范围是0-1（概率），而k-近邻的输出结果可以是大于0的任意实数，其他算法的输出范围可能是负数。<strong>因此整合多个分类器时，需要注意不同分类器的输出范围，并统一这个取值范围</strong>。</p>
<ul>
<li>比如可以先转化为如<strong>二分类结果</strong>，把输出的范围统一后再进行整合。但这种方法的问题在于我们丢失了很多信息，0.5和0.99都会被转化为1，但明显其可靠程度差别很大。</li>
<li>也可以转化为排序（ranking），再对不同的ranking进行求平均。</li>
<li>更加稳妥的方法是对每个分类器的输出结果做标准化，也就是调整到正态分布上去。之后就可以对多个调整后的结果进行整合。同理，用归一化也可以有类似的效果。</li>
</ul>
<p><strong>其次，就是整合稳定性的问题</strong>。采用平均法的另一个风险在于可能被极值所影响。正态分布的取值是
<span class="math inline">\([-\infty,+\infty]\)</span>
，在少数情况下平均值会受到少数极值的影响。一个常见的解决方法是，用中位数（median)来代替平均数进行整合。</p>
<p><strong>同时，模型整合面临的另一个问题是子模型良莠不齐</strong>。如果10个模型中有1个表现非常差，那么会拖累最终的效果，适得其反。<font color="red">因此，简单、粗暴的把所有子模型通过平均法整合起来效果往往一般。</font></p>
<h3><span id="三-寻找优秀的子模型准而不同">三、寻找优秀的子模型准而不同</span></h3>
<p>不难看出，一个较差的子模型会拖累整体的集成表现，那么这就涉及到另一个问题？什么样的子模型是优秀的。</p>
<p>一般来说，我们希望子模型：<strong>准而不同 -&gt; accurate but
diversified</strong>。好的子模型应该首先是准确的，这样才会有所帮助。其次不同子模型间应该有差别，比如独立的误差，这样作为一个整体才能起到<strong>互补作用</strong>。</p>
<p>因此，如果想实现良好的结合效果，就必须对子模型进行筛选，去粗取精。在这里我们需要做出一点解释，我们今天说的融合方法和bagging还有boosting中的思路不大相同。<font color="red">bagging和boosting中的子模型都是<strong>很简单的且基数庞大</strong>，而我们今天的模型融合是<strong>结合少量但较为复杂的模型</strong>。</font></p>
<h3><span id="四-筛选方法赋予不同子模型不同的权重"><strong>四、筛选方法：赋予不同子模型不同的权重</strong></span></h3>
<p>因此我们不能再简单的取平均了,
而应该给优秀的子模型更大的权重。在这种前提下, 一个比较直白的方法就是根
据子<strong>模型的准确率给出一个参考权重</strong> <span class="math inline">\(w\)</span> ，子模型越准确那么它的权重就更大,
对于最终预测的影响就更强: <span class="math inline">\(w_i=\frac{A c
c\left(C_i\right)}{\sum_1^{10} A c c\left(C_j\right)}\)</span>
。简单取平均是这个方法的一个特例, 即假设子模型准确率一致。</p>
<h3><span id="五-更进一步学习分类器权重"><strong>五、更进一步：学习分类器权重</strong></span></h3>
<p>在4中提到的方法在一定程度上可以缓解问题，但效果有限。那么另一个思路是，我们是否可以学习每个分类器的权重呢？</p>
<p>答案是肯定，这也就是Stacking的核心思路。通过增加一层来学习子模型的权重。</p>
<figure>
<img src="https://pic3.zhimg.com/v2-13396e65c2bcc1c270ca536310686d07_720w.jpg?source=d16d100b" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>图片来源</strong>：https://www.quora.com/What-is-stacking-in-machine-learning</p>
<p>更多有关于stacking的讨论可以参考我最近的文章：<font color="blue">集成学习总结-Stacking和神经网络</font>。简单来说，就是加一层逻辑回归或者SVM，把子模型的输出结果当做训练数据，来自动赋予不同子模型不同的权重。</p>
<p><font color="red"><strong>一般来看，这种方法只要使用得当，效果应该比简单取平均值、或者根据准确度计算权重的效果会更好。</strong></font></p>
<h3><span id="参考文献">参考文献</span></h3>
<p><a href="https://zhuanlan.zhihu.com/p/33589222">「融合」机器学习模型：一种提升预测能力的方法</a></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>理论基础（5）模型评估</title>
    <url>/posts/2624Z0W/</url>
    <content><![CDATA[<h3><span id="一-ab-测试"><font color="red">一、A/B 测试</font></span></h3>
<blockquote>
<p>【AB测试最全干货】史上最全知识点及常见面试题（上篇） -
数据分析狗一枚的文章 - 知乎 https://zhuanlan.zhihu.com/p/375902281</p>
</blockquote>
<h4><span id="引言">引言</span></h4>
<p>科学家门捷列夫说「没有测量，就没有科学」，在AI场景下我们同样需要定量的数值化指标来指导我们更好地应用模型对数据进行学习和建模。</p>
<p>事实上，在机器学习领域，对模型的测量和评估至关重要。选择与问题相匹配的评估方法，能帮助我们快速准确地发现在模型选择和训练过程中出现的问题，进而对模型进行优化和迭代。本文我们系统地讲解一下机器学习模型评估相关知识。</p>
<h4><span id="11-模型评估的目标">1.1 模型评估的目标</span></h4>
<p><strong>模型评估的目标是选出泛化能力强的模型完成机器学习任务</strong>。实际的机器学习任务往往需要进行大量的实验，经过反复调参、使用多种模型算法（甚至多模型融合策略）来完成自己的机器学习问题，并观察哪种模型算法在什么样的参数下能够最好地完成任务。</p>
<p>但是我们无法提前获取「未知的样本」，因此我们会基于已有的数据进行切分来完成模型训练和评估，借助于切分出的数据进行评估，可以很好地判定模型状态（过拟合
or 欠拟合），进而迭代优化。</p>
<p>在建模过程中，为了获得泛化能力强的模型，我们需要一整套方法及评价指标。</p>
<ul>
<li><strong>评估方法</strong>：为保证客观地评估模型，对数据集进行的有效划分实验方法。</li>
<li><strong>性能指标</strong>：量化地度量模型效果的指标。</li>
</ul>
<h4><span id="12-离线与在线实验方法">1.2 离线与在线实验方法</span></h4>
<p>进行评估的实验方法可以分为「离线」和「在线」两种。</p>
<h5><span id="离线实验方法">离线实验方法：</span></h5>
<blockquote>
<p>在<strong>离线评估</strong>中，经常使用<strong>准确率（Accuracy）、查准率（Precision）、召回率（Recall）、ROC、AUC、PRC</strong>等指标来评估模型。</p>
</blockquote>
<p><strong>模型评估通常指离线试验</strong>。原型设计（Prototyping）阶段及离线试验方法，包含以下几个过程：</p>
<ul>
<li>使用历史数据训练一个适合解决目标任务的一个或多个机器学习模型。</li>
<li>对模型进行验证（Validation）与离线评估（Offline Evaluation）。</li>
<li>通过评估指标选择一个较好的模型。</li>
</ul>
<h5><span id="在线实验方法">在线实验方法：</span></h5>
<blockquote>
<p><strong>在线评估</strong>与离线评估所用的评价指标不同，一般使用一些商业评价指标，如<strong>用户生命周期值（Customer
Lifetime value）、广告点击率（Click Through
Rate）、用户流失率</strong>（Customer Churn Rate）等标。</p>
</blockquote>
<p>除了离线评估之外，其实还有一种在线评估的实验方法。由于模型是在老的模型产生的数据上学习和验证的，而线上的数据与之前是不同的，因此离线评估并不完全代表线上的模型结果。因此我们需要在线评估，来验证模型的有效性。</p>
<p><span class="math inline">\(A/B Test\)</span>
是目前在线测试中最主要的方法。 <span class="math inline">\(A/B
Test\)</span> 是为同一个目标制定两个方案让一部分用户使用 <span class="math inline">\(A\)</span> 方案, 另一部分用户使用 <span class="math inline">\(B\)</span> 方案, 记录下用户的使用情况,
看哪个方案更符合设计目标。如果不做AB实验直接上
线新方案，新方案甚至可能会毁掉你的产品。</p>
<h4><span id="13模型离线评估后为什么要进行ab测试"><strong><font color="red"> 1.3
模型离线评估后，为什么要进行ab测试？</font></strong></span></h4>
<ul>
<li><strong>离线评估无法消除过拟合的影响</strong>，因此离线评估结果无法代替线上的评估效果</li>
<li><strong>离线评估过程中无法模拟线上的真实环境，例如数据丢失、样本反馈延迟</strong></li>
<li>线上的<strong>某些商业指标例如收益、留存等无法通过离线计算</strong></li>
</ul>
<h4><span id="14如何进行线上ab测试">1.4
<strong>如何进行线上ab测试？</strong></span></h4>
<p>进行ab测试的主要手段时对用户进行分桶，即将<strong>用户分成实验组和对照组</strong>。实验组使用新模型，对照组使用base模型。<strong>分桶过程中需要保证样本的独立性和采样的无偏性</strong>，确保每个用户只划分到一个桶中，分桶过程中需要保证user
id是一个<a href="https://www.zhihu.com/search?q=随机数&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22440144351%22%7D">随机数</a>，才能保证数据无偏的。</p>
<h3><span id="二-模型评估">二、模型评估</span></h3>
<h4><span id="21-holdout">2.1 holdout</span></h4>
<p><strong>留出法是机器学习中最常见的评估方法之一，它会从训练数据中保留出验证样本集，这部分数据不用于训练，而用于模型评估</strong>。</p>
<h4><span id="22-交叉验证">2.2 交叉验证</span></h4>
<p><strong>留出法的数据划分，可能会带来偏差</strong>。在机器学习中，另外一种比较常见的评估方法是交叉验证法——
<span class="math inline">\(K\)</span> <strong>折交叉验证对<span class="math inline">\(K\)</span>
个不同分组训练的结果进行平均来减少方差</strong>。</p>
<h4><span id="23-自助法">2.3 自助法</span></h4>
<p>Bootstrap
是一种用小样本估计总体值的一种非参数方法，在进化和生态学研究中应用十分广泛。<strong>Bootstrap通过有放回抽样生成大量的伪样本，通过对伪样本进行计算，获得统计量的分布，从而估计数据的整体分布</strong>。</p>
<h3><span id="三-超参数调优">三、超参数调优</span></h3>
<p>神经网咯是有许多超参数决定的，例如网络深度，学习率，正则等等。如何寻找最好的超参数组合，是一个老人靠经验，新人靠运气的任务。</p>
<h4><span id="31-网格搜索">3.1 网格搜索</span></h4>
<h4><span id="32-随机搜索">3.2 随机搜索</span></h4>
<h4><span id="33-贝叶斯优化">3.3 贝叶斯优化</span></h4>
<h5><span id="贝叶斯优化什么黑盒优化">贝叶斯优化什么?【黑盒优化】</span></h5>
<p>求助 gradient-free
的优化算法了，这类算法也很多了，<strong>贝叶斯优化就属于无梯度优化算法</strong>中的一种，它希望在尽可能少的试验情况下去尽可能获得优化命题的全局最优解。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232211987.jpg" alt="img" style="zoom: 33%;"></p>
<ul>
<li>目标函数 <span class="math inline">\(f(x)\)</span> 及其导数末知,
否则就可以用梯度下降等方法求解。</li>
<li>计算目标函数时间成本大, 意味着像蚁群算法、遗传算法这种方法也失效了,
因为计算一次要花费很多时间。</li>
</ul>
<h5><span id="概述">概述</span></h5>
<p>贝叶斯优化,
是一种使用<strong>贝叶斯定理来指导搜索以找到目标函数的最小值或最大值的方法</strong>,
就是在每次迭代的时 候, 利用之前观测到的历史信息 (先验知识)
来进行下一次优化, 通俗点讲, <strong>就是在进行一次迭代的时候,
先回顾下之前的迭代结果, 结果太差的 <span class="math inline">\(x\)</span> 附近就不去找了, 尽量往结果好一点的
<span class="math inline">\(x\)</span> 附近去找最优解</strong>,
这样一来搜索的效率就大大提高了, 这其实和人的思维方式也有点像,
每次在学习中试错, 并且在下次的时候根据这些经验来找到最 优的策略。</p>
<h5><span id="贝叶斯优化过程">贝叶斯优化过程</span></h5>
<p>首先，假设有一个这样的函数<span class="math inline">\(c(x)\)</span>，我们需要找到他的最小值，如下图所示，这也是我们所需要优化的目标函数，但是我们并不能够知道他的具体形状以及表达形式是怎么样的。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232211373.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>贝叶斯优化是通过一种叫做代理优化的方式来进行的，就是不知道真实的目标函数长什么样，我们就用一个<strong>代理函数（surrogate
function）来代替目标函数</strong>，<strong>而这个代理函数就可以通过先采样几个点，再通过这几个点来给他拟合出来</strong>，如下图虚线所示：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232211592.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>基于构造的代理函数,
<strong>我们就可以在可能是最小值的点附近采集更多的点</strong>,
或者在还没有采样过的区域来采集更多
的点，有了更多点，就可以<font color="red">更新代理函数</font>，使之更逼近真实的目标函数的形状，这样的话也更容易找到目标函数的
最小值, 这个采样的过程同样可以通过构建一个采集函数来表示,
也就是知道了当前代理函数的形状, 如何选择下 一个 <span class="math inline">\(x\)</span> 使得收益最大。</p>
<p><strong>然后重复以上过程，最终就可以找到函数的最小值点了，这大致就是贝叶斯优化的一个过程:</strong></p>
<ol type="1">
<li><strong>初始化一个代理函数的先验分布</strong></li>
<li><strong>选择数据点 <span class="math inline">\(x\)</span>,
使得采集函数 <span class="math inline">\(a(x)\)</span>
取最大值</strong></li>
<li><strong>在目标函数 <span class="math inline">\(c(x)\)</span>
中评估数据点 <span class="math inline">\(x\)</span> 并获取其结果 <span class="math inline">\(y\)</span></strong></li>
<li><strong>使用新数据 <span class="math inline">\((x, y)\)</span>
更新代理函数，得到一个后验分布 (作为下一步的先验分布)</strong></li>
<li>重复2-4步，直到达到最大迭代次数</li>
</ol>
<p>举个例子, 如图所示, 一开始只有两个点 <span class="math inline">\((\mathrm{t}=2)\)</span>,
代理函数的分布是紫色的区域那块, 然后根据代理函数算出一
个采集函数（绿色线), 取采集函数的最大值所在的 <span class="math inline">\(x\)</span> (红色三角处), 算出 <span class="math inline">\(y\)</span>, 然后根据新的点 <span class="math inline">\((x, y)\)</span> 更新 代理函数和采集函数 <span class="math inline">\((\mathrm{t}=3)\)</span>
，继续重复上面步骤，选择新的采集函数最大值所在的 <span class="math inline">\(x\)</span>, 算出 <span class="math inline">\(y\)</span>, 再更新代理函 数和采集函数,
然后继续迭代。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232211302.jpg" alt="img" style="zoom: 67%;"></p>
<p>问题的核心就在于代理函数和采集函数如何构建，常用的代理函数有：</p>
<ol type="1">
<li><strong>高斯过程（Gaussian processes）</strong></li>
<li><strong>Tree Parzer Estimator</strong></li>
<li><strong>概率随机森林：针对类别型变量</strong></li>
</ol>
<p>采集函数则需要兼顾两方面的性质：</p>
<ol type="1">
<li>利用当前已开发的区域（Exploitation）：即在当前最小值附近继续搜索</li>
<li>探索尚未开发的区域（Exploration）：即在还没有搜索过的区域里面搜索，可能那里才是全局最优解</li>
</ol>
<p><strong>常用的采集函数有：</strong></p>
<ol type="1">
<li>Probability of improvement（PI）</li>
<li>Expected improvement（EI）</li>
<li>Confidence bound criteria，包括LCB和UCB</li>
</ol>
<h4><span id="34-hyperopt">3.4 Hyperopt</span></h4>
<p>Hyperopt 是一个强大的 Python 库，用于超参数优化，由 jamesbergstra
开发。Hyperopt
使用贝叶斯优化的形式进行参数调整，允许你为给定模型获得最佳参数。它可以在大范围内优化具有数百个参数的模型。</p>
<h3><span id="参考文献">参考文献</span></h3>
<p><a href="https://zhuanlan.zhihu.com/p/390373572"><em>贝叶斯优化</em>(原理+代码解读)</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/27916208">LightGBM调参指南(带贝叶斯优化代码)</a></p>
<ul>
<li>贝叶斯调参采用高斯过程，考虑之前的参数信息，不断地更新先验；网格搜索未考虑之前的参数信息</li>
<li>贝叶斯调参迭代次数少，速度快；网格搜索速度慢,参数多时易导致维度爆炸</li>
<li>贝叶斯调参针对非凸问题依然稳健；网格搜索针对非凸问题易得到局部最优</li>
</ul>
<h4><span id="可用的贝叶斯优化框架">可用的贝叶斯优化框架</span></h4>
<ol type="1">
<li>BayesianOptimization：<a href="https://link.zhihu.com/?target=https%3A//github.com/fmfn/BayesianOptimization">https://github.com/fmfn/BayesianOptimization</a></li>
<li>清华开源的openbox：<a href="https://link.zhihu.com/?target=https%3A//open-box.readthedocs.io/zh_CN/latest/index.html">https://open-box.readthedocs.io/zh_CN/latest/index.html</a></li>
<li>华为开源的HEBO：<a href="https://link.zhihu.com/?target=https%3A//github.com/huawei-noah/HEBO">https://github.com/huawei-noah/HEBO</a></li>
<li><strong>Hyperopt</strong>：<a href="https://link.zhihu.com/?target=http%3A//hyperopt.github.io/hyperopt/">http://hyperopt.github.io/hype</a></li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>理论基础（4）聚类评价指标</title>
    <url>/posts/2Z6ZKRX/</url>
    <content><![CDATA[<h3><span id="一-聚类算法评价指标">一、聚类算法评价指标</span></h3>
<blockquote>
<p>https://zhuanlan.zhihu.com/p/343667804</p>
<p>十分钟掌握聚类算法的评估指标：https://juejin.cn/post/6997913127572471821</p>
</blockquote>
<h4><span id="前言-外部评估-内部指标">前言 【外部评估】+ 【内部指标】</span></h4>
<p>如同之前介绍的其它算法模型一样，对于聚类来讲我们同样会通过一些评价指标来衡量聚类算法的优与劣。在聚类任务中，常见的评价指标有：<strong>纯度（Purity）</strong>、<strong>兰德系数（Rand
Index,
RI）</strong>、<strong>F值（F-score）</strong>和<strong>调整兰德系数（Adjusted
Rand
Index,ARI）</strong>。同时，这四种评价指标也是聚类相关论文中出现得最多的评价方法。下面，我们就来对这些算法一一进行介绍。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232157697.jpg" alt="img" style="zoom: 67%;"></p>
<p>好的聚类算法，一般要求类簇具有：</p>
<ul>
<li><strong>簇内 (intra-cluster) 相似度高</strong></li>
<li><strong>簇间 (inter-cluster) 相似度底</strong></li>
</ul>
<p>一般来说，评估聚类质量有两个标准，内部评估评价指标和外部评估指标。内部评估指标主要基于数据集的集合结构信息从紧致性、分离性、连通性和重叠度等方面对聚类划分进行评价。即基于数据聚类自身进行评估的。</p>
<h4><span id="11聚类纯度-聚类的准确率"><strong>1.1聚类纯度</strong> -
聚类的准确率</span></h4>
<p><strong>在聚类结果的评估标准中,
一种最简单最直观的方法就是计算它的聚类纯度
(purity)</strong>，别看纯度听起来很陌生,
但实际上和<strong>分类问题中的准确率有着异曲同工之妙</strong>。<strong>因为聚类纯度的总体思想也用聚类正确的样本数除以总的样本
数,
因此它也经常被称为聚类的准确率</strong>。只是对于聚类后的结果我们并不知道每个簇所对应的真实类别,
因此需要 取每种情况下的最大值。具体的，纯度的计算公式定义如下： <span class="math display">\[
P=(\Omega, \mathbb{C})=\frac{1}{N} \sum_k \max _j\left|\omega_k \cap
c_j\right|
\]</span> 其中 <span class="math inline">\(N\)</span> 表示总的样本数;
<span class="math inline">\(\Omega=\left\{\omega_1, \omega_2, \ldots,
\omega_K\right\}\)</span> 表示一个个聚类后的簇, 而 <span class="math inline">\(\mathbb{C}=\left\{c_{1,2}, \ldots
c_J\right\}\)</span> 表示正确的类别; <span class="math inline">\(\omega_k\)</span> 表示聚类后第 <span class="math inline">\(k\)</span> 个簇中的所有样本, <span class="math inline">\(c_j\)</span> 表示第 <span class="math inline">\(j\)</span> 个类别中真实的样本。在这里 <span class="math inline">\(P\)</span> 的取值范围为 <span class="math inline">\([0,1]\)</span> ，越大表示 聚类效果越好。</p>
<h4><span id="12-兰德系数与f值同簇混淆矩阵"><strong>1.2 兰德系数与F值</strong>
[同簇混淆矩阵]</span></h4>
<p>在介绍完了纯度这一评价指标后，我们再来看看兰德系数（Rand
Index）和F值。虽然兰德系数听起来是一个陌生 的名词,
但它的计算过程却也与准确率的计算过程类似。同时,
虽然这里也有一个叫做值的指标, 并且它的计算 过程也和分类指标中的F值类似,
但是两者却有着本质的差别。说了这么多, 那这两个指标到底该怎么算呢? 同分
类问题中的沘淆矩阵类似，这里我们也要先定义四种情况进行计数，然后再进行指标的计算。</p>
<p><strong>为了说明兰德系数背后的思想，我们还是以图1中的聚类结果为例进行说明（为了方便观察，我们再放一张图在这
里):</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232158691.jpg" alt="img" style="zoom: 67%;"></p>
<ul>
<li><span class="math inline">\(T P\)</span> :
表示两个同类样本点在同一个簇（布袋）中的情况数量;</li>
<li><span class="math inline">\(F P\)</span> :
表示两个非同类样本点在同一个簇中的情况数量;</li>
<li><span class="math inline">\(T N\)</span> :
表示两个非同类样本点分别在两个簇中的情况数量;</li>
<li><span class="math inline">\(F N\)</span> :
表示两个同类样本点分别在两个簇中的情况数量;</li>
</ul>
<p>由此，我们便能得到如下所示的对<strong>混淆矩阵（Pair Confusion
Matrix）</strong>：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232158915.png" alt="img" style="zoom:75%;"></p>
<p>有了上面各种情况的统计值，我们就可以定义出兰德系数和F值的计算公式：
<span class="math display">\[
Precision =\frac{T P}{T P+F P}
\]</span></p>
<p><span class="math display">\[
Recall =\frac{T P}{T P+F N}
\]</span></p>
<p><span class="math display">\[
R I  =\frac{T P+T N}{T P+F P+F N+T N}
\]</span></p>
<p><span class="math display">\[
F_\beta  =\left(1+\beta^2\right) \frac{\text { Precision } \cdot \text {
Recall }}{\beta^2 \cdot \text { Precision }+ \text { Recall }}
\]</span></p>
<p>从上面的计算公式来看, (3)(4)
从形式上看都非常像分类问题中的准确率与F值, 但是有着本质的却别。同时, 在
这里 <span class="math inline">\(R I\)</span> 和 <span class="math inline">\(F_\beta\)</span> 的取值范围均为 <span class="math inline">\([0,1]\)</span> ，越大表示聚类效果越好。</p>
<h4><span id="13调整兰德系数adjusted-rand-index归一化">1.3
调整兰德系数（Adjusted Rand index）【归一化】</span></h4>
<p>对于随机结果，RI并不能保证分数接近零。<strong>为了实现“在聚类结果随机产生的情况下，指标应该接近零”</strong>，调整兰德系数（Adjusted
rand index）被提出，它具有更高的区分度。</p>
<p>其公式为： <span class="math display">\[
\mathrm{ARI}=\frac{\mathrm{RI}-E[\mathrm{RI}]}{\max
(\mathrm{RI})-E[\mathrm{RI}]}
\]</span> <span class="math inline">\(A R\)</span> 取值范围为 <span class="math inline">\([-1,1]\)</span>,
值越大意味着聚类结果与真实情况越吻合。从广义的角度来讲,
ARI衡量的是两个数据分布 的吻合程度。</p>
<p>优点:</p>
<ul>
<li>对任意数量的聚类中心和样本数, 随机聚类的ARI都非常接近于 0 。</li>
<li>取值在 <span class="math inline">\([-1,1]\)</span> 之间,
负数代表结果不好, 越接近于1越好。</li>
<li>对簇的结构不需作出任何假设：可以用于比较聚类算法。</li>
</ul>
<p>缺点:</p>
<ul>
<li>ARI 需要 ground truth classes 的相关知识, ARI需要真实标签,
而在实践中几乎不可用, 或者需要人工 标注者
手动分配（如在监督学习环境中）。</li>
</ul>
<h4><span id="14-标准化互信息nmi-normalized-mutualinformation">1.4
<strong><font color="red"> 标准化互信息（NMI, Normalized Mutual
Information）</font></strong></span></h4>
<p>互信息是用来衡量两个数据分布的吻合程度。它也是一有用的信息度量，它是指两个事件集合之间的相关性。互信息越大，词条和类别的相关程度也越大。</p>
<h4><span id="15-轮廓系数silhouette-coefficient">1.5 <strong><font color="red">
轮廓系数（Silhouette Coefficient）</font></strong></span></h4>
<p><strong>轮廓系数适用于实际类别信息末知的情况。</strong>对于单个样本,
设 <span class="math inline">\(a\)</span>
是与它同类别中其他样本的平均距离, <span class="math inline">\(b\)</span>
是与它距离最近不同类别中样本的平均距离, 其轮廓 系数为: <span class="math display">\[
s=\frac{b-a}{\max (a, b)}
\]</span> 对于一个样本集合,
它的轮廓系数是所有样本轮廓系数的平均值。轮廓系数的取值范围是 <span class="math inline">\([-1,1]\)</span>, 同类别样本距离 越相近,
不同类别样本距离越远, 值越大。当值为负数时, 说明聚类效果很差。</p>
<h4><span id="16calinski-harabaz指数calinski-harabaz-index">1.6
Calinski-Harabaz指数（Calinski-Harabaz Index）</span></h4>
<p>在真实的分群label不知道的情况下，Calinski-Harabasz可以作为评估模型的一个指标。</p>
<p>Calinski-Harabasz指数通过<strong>计算类中各点与类中心的距离平方和来度量类内的紧密度</strong>，通过<strong>计算各类中心点与数据集中心点距离平方和来度量数据集的分离度</strong>，CH指标<strong>由分离度与紧密度的比值得到</strong>。从而，CH越大代表着类自身越紧密，类与类之间越分散，即更优的聚类结果。</p>
<p><strong>优点</strong></p>
<ul>
<li>当簇的密集且分离较好时，分数更高。</li>
<li>得分计算很快，与轮廓系数的对比，最大的优势：快！相差几百倍！毫秒级。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>凸的簇的CH指数通常高于其他类型的簇。例如，通过 DBSCAN
获得基于密度的簇；所以，不适合基于密度的聚类算法（DBSCAN）。</li>
</ul>
<h4><span id="17-戴维森堡丁指数dbidavies-bouldin-index">1.7 戴维森堡丁指数（DBI,
Davies-Bouldin Index）</span></h4>
<p><strong>DB指数是计算任意两类别的类内距离平均距离之和除以两聚类中心距离求最大值</strong>。DB越小，意味着类内距
离越小同时类间距离越大。<strong>零是可能的最低值,
接近零的值表示更好的分区</strong>。 <span class="math display">\[
\begin{gathered}
R_{i j}=\frac{s_{i}+s_{j}}{d_{i j}} \\
D B=\frac{1}{k} \sum_{i=1}^{k} \max _{i \neq j} R_{i j}
\end{gathered}
\]</span> 其中, <span class="math inline">\(s_{i}\)</span>
表示簇的每个点与该簇的质心之间的平均距离, 也称为簇直径。 <span class="math inline">\(d_{i j}\)</span> 表示聚类和的质心之间的距 离。
算法生成的聚类结果越是朝着簇内距离最小（类内相似性最大）和笶间距离最大（类间相似性最小）变化，
那么Davies-Bouldin指数就会越小。 <strong>缺点</strong>:</p>
<ul>
<li>因使用欧式距离, 所以对于环状分布聚类评测很差。</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>关联规则（2）Apriori</title>
    <url>/posts/3BJBSQZ/</url>
    <content><![CDATA[<h3><span id="一-apriori算法">一、﻿Apriori算法</span></h3>
<p>﻿Apriori算法是常用的用于挖掘出数据关联规则的算法，它用来找出数据值中频繁出现的数据集合，找出这些集合的模式有助于我们做一些决策。</p>
<ul>
<li><p><strong>支持度</strong>：关联规则A-&gt;B的支持度support=P(AB)，指的是事件A和事件B同时发生的概率；</p></li>
<li><p><strong>置信度</strong>：指的是发生事件A的基础上发生事件B的概率；</p></li>
<li><p><strong>频繁k项集</strong>：频繁项集表示的就是在数据集中频繁出现的项集（可以是一个，也可以是多个）。如果事件A中包含k个元素，那么称这个事件A为k项集，并且事件A满足最小支持度阈值的事件称为频繁k项集；</p></li>
</ul>
<span id="more"></span>
<h4><span id="11-背景">1.1 背景</span></h4>
<p>对于Apriori算法，我们使用支持度来作为我们判断频繁项集的标准。Apriori算法的目标是找到最大的K项频繁集。</p>
<p>记 <span class="math inline">\(\mathcal{I}=\left\{I_1, I_2, \ldots,
I_m\right\}\)</span> 为一个项集, 其中的 <span class="math inline">\(I_k(k=0,1, \ldots, m)\)</span>
代表所有可能出现的子项。</p>
<p><strong>举例：</strong></p>
<p>比如你作为一家大型连锁超市的数据分析师，你发现前台给你发的大量顾客的购物清单数据中，鸡蛋+面包+牛奶这样的组合是清单中的常客，且符合一些不可言喻的约束条件，那么鸡蛋、面包和牛奶这三样商品经常一起出现这样一个规律就算是购物清单数据中的频繁模式。其中，鸡蛋，面包，牛奶这样一个集合我们就称为一个<strong>频繁项集</strong>（frequent
itemset）。</p>
<table>
<thead>
<tr class="header">
<th>TID</th>
<th>transaction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>T1</td>
<td>鸡蛋，牙膏，牛排，牛奶，面包</td>
</tr>
<tr class="even">
<td>T2</td>
<td>鸡蛋，亚麻籽，橄榄油，牛奶，面包</td>
</tr>
<tr class="odd">
<td>T3</td>
<td>鸡蛋，泡芙，奶油，牛奶，面包</td>
</tr>
<tr class="even">
<td>T4</td>
<td>鸡蛋，低筋面粉，糖粉，黄油，牛奶</td>
</tr>
</tbody>
</table>
<p>TID是每一个顾客的账单的编号，上述表格中我们有4个顾客的交易记录。</p>
<ol type="1">
<li>给定事务集 <span class="math inline">\(D\)</span>,
找出一组关联规则(association rule) <span class="math inline">\(A
\subseteq \mathcal{I} \wedge B \subseteq \mathcal{I} \wedge A
\Rightarrow B\)</span> 。它的意思 是 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> 相关联, 由 <span class="math inline">\(A\)</span> 可以推出 <span class="math inline">\(B\)</span> 。比如 <span class="math inline">\(A=\{\)</span> 鸡蛋, 牛奶 <span class="math inline">\(\}, B=\{\)</span> 面包 <span class="math inline">\(\}\)</span>, 那么 <span class="math inline">\(A
\Rightarrow B\)</span>
可以认为是买了鸡蛋和牛奶的顾客有大概率也会去买面包。这个过程我们称为<strong>关联规则挖掘(association
rule mining)</strong></li>
<li>给定事务集 <span class="math inline">\(D\)</span>,
找出蕴含其中的频繁项集。比如通过example1中的表格,
我们挖掘出了用户喜欢鸡蛋+面包+牛奶这样的模式。这个过程我们称为<strong>频繁模式挖掘(frequent
pattern mining)</strong></li>
</ol>
<h4><span id="12-关联规则挖掘">1.2 关联规则挖掘</span></h4>
<p>为了后续的度量, 需要引入两个相当相当简单的概念,
<strong>support</strong>和<strong>confidence</strong>。记 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> 是 <span class="math inline">\(\mathcal{I}\)</span> 中的两个子集, 那么则 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> 在 <span class="math inline">\(D\)</span> 中同时发生的概率称为support: <span class="math display">\[
\operatorname{support}(A \Rightarrow B)=P(A \cup B)
\]</span> <span class="math inline">\(A\)</span> 发生的前提下， <span class="math inline">\(B\)</span> 在 <span class="math inline">\(D\)</span> 发生的概率称为confidence: <span class="math display">\[
\text { confidence }(A \Rightarrow B)=\frac{P(A \cup
B)}{P(A)}=\frac{\operatorname{support}(A \cup
B)}{\operatorname{support}(A)}
\]</span> <strong>事实上, 书上对support的定义有点模糊,
我的理解是support就是一个很简单的频度度量, 所以 <span class="math inline">\(\operatorname{support}(A)\)</span> 就代表 <span class="math inline">\(A\)</span> 在 <span class="math inline">\(D\)</span> 出现的频率。</strong></p>
<p>还有一点，定义在 <span class="math inline">\(D\)</span>
上的<strong>频度</strong>的计算公式如下： <span class="math display">\[
P(A)=\frac{1}{|D|} \sum_{i=1}^{|D|} \mathbb{I}\left(A \subseteq
T_i\right)
\]</span> 其中 <span class="math inline">\(\mathbb{I}(c)\)</span>
为指示函数, <span class="math inline">\(c\)</span> 为真，则返回 <span class="math inline">\(1 ; c\)</span> 为假，则返回0。</p>
<p><strong>很明显, 对于计算出的值, 我们需要设置人为的阈值才能判定 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span>
是否为一个关联规则</strong>。假定我们设置了两个阈值 <span class="math inline">\(s\)</span> 和 <span class="math inline">\(c\)</span> 。那么如果 <span class="math inline">\(\operatorname{support}(A \Rightarrow B) \geq s
\wedge \operatorname{confidence}(A \Rightarrow B) \geq c\)</span> ,
我们就说 <span class="math inline">\(A \Rightarrow B\)</span>
是一条关联规则。它的实际意义可是买了{鸡蛋,牛奶} 很有可能还会去买
{面包}。</p>
<p>这就是关联规则挖掘的最简单的做法, 由此,
我们可以用两步来总结关联规则挖掘的步骤:</p>
<ol type="1">
<li><font color="red">找出所有可能的频繁项集。频繁项集的定义为support在事务集中出现频率大于设定阈值min_sup的项集。</font></li>
<li><font color="red">在找出的频繁项集中生成强关联规则。符合强相关联规则的频繁项集对需要满足其support和
confidence都分别大于预先设定好的阈值。</font></li>
</ol>
<p>Ha , 所以我们需要先找出事务集中所有可能的频繁项集。我们发现,
在support度量意义下的频繁项集的定义很简单,
只需要出现频率大于设定阈值的项集就算是频繁项集。<strong>但是我们找频繁项集的搜索空间是什么,
是总项集<span class="math inline">\(\mathcal{I}\)</span> 的幂集耶,
这玩意儿的大小为<span class="math inline">\(2^{|\mathcal{I}|-1}=2^{m-1}\)</span>
。</strong></p>
<p>那么我们的dummy算法时间复杂度直接升天, 光是最外层的搜索就已经是指数
级的复杂度了, 显然这不是一个有效的算法。</p>
<p>而当我们找到有限个频繁项集后,
只需要通过计算所有的频繁项集中两两是否满足confidence和
support分别大于预先设定的值就行了,
这一步的时间复杂度不会很大。所以重点还是在于如何设计出找到频繁项集的有效算法。</p>
<p>所以于此,
我们需要引入一些有意思的频繁项集的搜索算法。其中最简单的就是1994年提出的
Apriori算法了。</p>
<h4><span id="13-apriori算法">1.3 Apriori算法</span></h4>
<p><strong>由于频繁项集的搜索空间是指数级别的，所以我们需要想办法来缩减搜索空间大小</strong>。<font color="red">Apriori提供了一种以连接剪枝为一个迭代循环的算法来有效减小了搜索空间。</font>之所以取名为Apriori，因为算法使用了项集本身的一些<strong>先验信息</strong>（prio
[ˈpraɪə(r)] ），加上作者之一是Agrawal，故取名为Apriori。</p>
<p>Apriori到底在干什么，一般而言，我们在搜索空间找东西可以分成两种——<strong>自上而下搜索</strong>和<strong>自下而上搜索</strong>。自下而上搜索应该是大部分人熟悉的搜索方法，一般我们会从一个随机点出发，然后根据任务和空间本身的特点找到符合要求的值或者集合，比如你丢了一块橡皮，通过橡皮滚落的大致轨迹去寻找橡皮的下落，这是属于自下而上的搜索方式。而自上而下的搜索方式则是类似于排除法，它会根据任务和搜索空间本身的特点去排除搜索空间中肯定不是目标的子空间，不断排除，直到停止，那么剩余的空间就是搜索答案，有点类似于收网捕鱼。</p>
<p><strong>Apriori的搜索方式就属于自上而下的搜索方式。</strong>虽然
<span class="math inline">\(\mathcal{I}\)</span> 的幂集的大小大得离谱,
但是也是有章可循的, 我们可以按照项集元素的数量将总的搜索空间给它切成
<span class="math inline">\(m\)</span> 份（只有一个元素的项集,
只有两个元素的项集，......, 有m个元素的项集），它们的大小分别为 <span class="math inline">\(\left(\begin{array}{c}m \\
1\end{array}\right),\left(\begin{array}{c}m \\ 2\end{array}\right),
\ldots,\left(\begin{array}{c}m \\ m\end{array}\right)\)</span>
。然后从只有一个元素的项集出发, 不断削减搜索空间, 得到1-频繁项集,
并根据一定的准则根据1-频繁项集推出若干个有两个元素的项集集合,
从而进行迭代。</p>
<blockquote>
<p>含有k个元素的项集被称为k-项集(k-itemset)，同理，如果该项集恰好又是频繁项集，那么该项集又可称为k-频繁项集</p>
</blockquote>
<h5><span id="1-算法流程">(1) 算法流程</span></h5>
<p>Apriori的做法是从大小为1的项集集合, 该集合被我们称为候选集 <span class="math inline">\(C_1\)</span> 。我们从候选集 <span class="math inline">\(C_1\)</span> 出发, 然后通过䇘选得到1-频繁项集
<span class="math inline">\(L_1\)</span>, 连接, 减枝的方法得到大小为 2
候选集 <span class="math inline">\(C_2\)</span>, 其中的䇘选和减枝
两步都能有效缩减搜索空间。</p>
<ul>
<li><p>直接从事务集 <span class="math inline">\(D\)</span>
中提取所有的transaction, 然后找出里面所有不相同的元素就行,记 <span class="math inline">\(\mathcal{I}=\left\{I_1, I_2, \ldots,
I_m\right\}\)</span> 。</p></li>
<li><p>然后, 我们需要初始化第一个候选集, 也就是 <span class="math inline">\(C_1 。 C_1\)</span> 就是 <span class="math inline">\(\mathcal{I}\)</span> 本身, 对 <span class="math inline">\(C_1\)</span> 中的每个元素, 计算其在 <span class="math inline">\(D\)</span> 中的频率,
如果频率小于min_sup，那就删除，最终留下的元素构成集合 <span class="math inline">\(L_1\)</span> ，这就是我们的1-频繁项集。</p></li>
<li><p>接下来我们就需要迭代向前了，让我们的搜索空间从1-项集集合跳到2-项集集合,
这跳跃的过程通过连接完成。</p></li>
</ul>
<p>为了方便后续描述, 假设我们已经得到了k-频繁项集的集合 <span class="math inline">\(L_k\)</span> 了。首先我们需要保证 <span class="math inline">\(L_k\)</span>
中每个频繁项集内部都已经按照字典序排序了,
然后所有的频繁项集之间两两比较, 如果这两个项集前 <span class="math inline">\(k-1\)</span> 项全部相同 ( <span class="math inline">\(L_k\)</span> 也是集合，所以 <span class="math inline">\(L_k\)</span> 中的所有频繁项集都是两两不同的, 前
<span class="math inline">\(k-1\)</span>
项全部相同意味着它们的最后一个元素一定不一样），那么将这两个项集取并集然后加入集
合 <span class="math inline">\(C_{k+1}\)</span> 中。这样一来,
我们就获得了 <span class="math inline">\(\mathrm{k}+1\)</span>-项集的待选集合了,
但是这个集合由于经过了 <span class="math inline">\(\left(\begin{array}{c}\left|L_k\right| \\
2\end{array}\right)\)</span> 次组合挑选, 所以大小可能会很大, 因此,
在连接完成后, 我们有必要进行裁剪来缩小下一轮迭代的搜索空间。</p>
<p>这个地方就需要用到Apriori算法中提出的一个假设了—一个频繁项集的任意子集都是步繁项集，由于我们下一轮迭代的目标就是得到
<span class="math inline">\(k+1\)</span>-频繁项集，所以我们可以在这里直接把不是频繁项集的项集去除。根据这个假设,
那么那些存在子集为非频繁项集的项集就是非频繁项集，那 么我将其从 <span class="math inline">\(C_{k+1}\)</span>
中去除。当我们全部去除后，那么裁剪步骤完成，我们得到了下一轮迭代需要用
到的搜索需要用到的候选集 <span class="math inline">\(C_{k+1}\)</span>
。进入下一个循环。</p>
<p><strong>最终说明一下终止条件：</strong></p>
<ul>
<li>如果当前轮次得到的频繁项集为空, break</li>
<li>如果当前轮次得到的频繁项集只有一个元素, 存入结果, break</li>
<li>如果候选集筛选后为空, break</li>
<li>如果连接后的候选集裁剪后, 为空, break</li>
</ul>
<p><strong>循环结束或者终止后 (假设迭代了 <span class="math inline">\(n\)</span> 次），将集合 <span class="math inline">\(\left\{L_1, L_2, L_3, \ldots, L_n\right\}\)</span>
返回。</strong></p>
<h5><span id="2-样例">(2) 样例</span></h5>
<p>当前的事务集如下：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271616186.png" style="zoom: 67%;"></p>
<p>那么请算出各个level的频繁项集。其中，筛选步骤的min_sup为 29
，也就是只要出现2次以下就筛去。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271615548.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="14-缺点">1.4 缺点</span></h4>
<p>虽然Apriori算法能够有效计算频繁项集, 但是其缺点依旧存在：</p>
<ul>
<li><strong>需要多次扫描数据集</strong>：Apriori算法中间有许多步骤都需要对某一个大集合（比如
<span class="math inline">\(D, L_k\)</span> ）
进行遍历扫描，如果数据量庞大，那么遍历扫描仍然会占据大量的时间。</li>
<li><strong>可能会产生庞大的候选集</strong>：由于第 <span class="math inline">\(k\)</span> 迭代的连接过程仍然需要进行 <span class="math inline">\(\left(\begin{array}{c}\left|L_k\right| /\
2\end{array}\right)\)</span> 次比较操作,
所以Apriori算法中途产生的候选集的数量依然巨大。</li>
</ul>
<p><font color="red">针对Apriori算法的性能瓶颈问题，2000年Jiawei
Han等人提出了基于FP树生成频繁项集的FP-growth算法。</font></p>
<h3><span id="二-参考文献">二、参考文献</span></h3>
<ul>
<li><a href="https://www.zhihu.com/question/19912364/answer/963934469"><em>Apriori算法</em>是什么？适用于什么情境？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/410019734"><font color="blue">数据挖掘随笔（一）频繁模式挖掘与关联规则挖掘以及Apriori算法（python实现）</font></a></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>关联规则</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>关联规则</tag>
        <tag>频繁项集</tag>
        <tag>Apriori</tag>
      </tags>
  </entry>
  <entry>
    <title>关联规则（3）FP-growth</title>
    <url>/posts/806NJ2/</url>
    <content><![CDATA[<h3><span id="一-fp-growth">一、FP-growth</span></h3>
<h4><span id="前言apriori算法的缺陷">前言——Apriori算法的缺陷</span></h4>
<p>虽然Apriori算法能够有效计算频繁项集, 但是其缺点依旧存在：</p>
<ul>
<li><strong>需要多次扫描数据集</strong>：Apriori算法中间有许多步骤都需要对某一个大集合（比如
<span class="math inline">\(D, L_k\)</span> ）
进行遍历扫描，如果数据量庞大，那么遍历扫描仍然会占据大量的时间。</li>
<li><strong>可能会产生庞大的候选集</strong>：由于第 <span class="math inline">\(k\)</span> 迭代的连接过程仍然需要进行 <span class="math inline">\(\left(\begin{array}{c}\left|L_k\right| /\
2\end{array}\right)\)</span> 次比较操作,
所以Apriori算法中途产生的候选集的数量依然巨大。</li>
</ul>
<p><font color="red">所以为什么一定要产生候选集？是否可以不通过产生候选集的方式来完成频繁模式挖掘呢？频繁模式增长(frequent
pattern growth，
简称FP-growth)就是一种该方向的尝试。</font>【原始事务数据转换为树状数据结构，减少扫描事务的成本】</p>
<span id="more"></span>
<h4><span id="11-算法流程">1.1 算法流程</span></h4>
<p><strong>FP-growth主要采用一种分治的策略来解决该问题，我们可以用几个步骤来描述一下这种分治策略的大概步骤。</strong></p>
<ol type="1">
<li>压缩数据集来表征每一个项，这个步骤一般是通过建立<strong>频繁模式树</strong>(frequent
pattern
tree，简称FP-tree)来实现的（其实就是字典树，很明显这是一种无损压缩方式）</li>
<li><strong>统计每一个项在原数据集中出现的次数，并根据预先设定的support
count去除低频项</strong>，然后根据出现次数对剩余项进行升序排序；从第一位项开始扫描频繁模式树的叶子节点，通过回溯得到每一个项对应的条件模式基(Condition
Pattern Base，实则为叶子节点对应的路径集合)</li>
<li>根据条件模式基构建出条件频繁项集树(Conditional
FP-tree，步骤和第一步完全一样，也就是根据条件模式基构建出一颗字典树)</li>
<li>根据条件FP-tree和support count得到最终的频繁项集</li>
</ol>
<p>事务集如下：</p>
<table>
<thead>
<tr class="header">
<th>TID</th>
<th>itemset list</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>T100</td>
<td>I1, I2, I5</td>
</tr>
<tr class="even">
<td>T200</td>
<td>I2, I4</td>
</tr>
<tr class="odd">
<td>T300</td>
<td>I2, I3</td>
</tr>
<tr class="even">
<td>T400</td>
<td>I1, I2, I4</td>
</tr>
<tr class="odd">
<td>T500</td>
<td>I1, I3</td>
</tr>
<tr class="even">
<td>T600</td>
<td>I2, I3</td>
</tr>
<tr class="odd">
<td>T700</td>
<td>I1, I3</td>
</tr>
<tr class="even">
<td>T800</td>
<td>I1, I2, I3, I5</td>
</tr>
<tr class="odd">
<td>T900</td>
<td>I1, I2, I3</td>
</tr>
</tbody>
</table>
<h5><span id="1建立模式频繁树">（1）建立模式频繁树</span></h5>
<p>我们首先需要建立一颗模式频繁树，做法很简单，也就是直接建立一颗字典树。在建立之前，我们需要先对每一个项进行统计，并去除出现次数小于support
count的项，然后排序。对于上表，这么做后的结果如下：</p>
<table>
<thead>
<tr class="header">
<th>item</th>
<th>count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>I2</td>
<td>7</td>
</tr>
<tr class="even">
<td>I1</td>
<td>6</td>
</tr>
<tr class="odd">
<td>I3</td>
<td>6</td>
</tr>
<tr class="even">
<td>I4</td>
<td>2</td>
</tr>
<tr class="odd">
<td>I5</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>此处我们选择的support count为2，所以所有的项都被保留了下来。</p>
<p>然后我们需要对保留下来的项压缩成一个字典树，为了保证这颗字典树尽可能小，我们需要对事务集中的每一个项集进行排序，结果如下：</p>
<table>
<thead>
<tr class="header">
<th>TID</th>
<th>itemset list</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>T100</td>
<td>I2, I1, I5</td>
</tr>
<tr class="even">
<td>T200</td>
<td>I2, I4</td>
</tr>
<tr class="odd">
<td>T300</td>
<td>I2, I3</td>
</tr>
<tr class="even">
<td>T400</td>
<td>I2, I1, I4</td>
</tr>
<tr class="odd">
<td>T500</td>
<td>I1, I3</td>
</tr>
<tr class="even">
<td>T600</td>
<td>I2, I3</td>
</tr>
<tr class="odd">
<td>T700</td>
<td>I1, I3</td>
</tr>
<tr class="even">
<td>T800</td>
<td>I2, I1, I3, I5</td>
</tr>
<tr class="odd">
<td>T900</td>
<td>I2, I1, I3</td>
</tr>
</tbody>
</table>
<p><strong>字典树的根节点设为null，然后我们可以开始从第一条数据开始建立字典树</strong>，需要说明的是，这颗字典树的每个节点还需要维护一个count，这个count的含义是当前该节点被“经过”了多少次。下面的图中，<strong>每个结点被我标注为Ik
: n的样子，代表当前节点名为Ik，count为n。</strong></p>
<p>我们先加入T100：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271641823.png" style="zoom: 50%;"></p>
<p>然后加入T200：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271641579.png" alt="img" style="zoom:50%;"></p>
<p>在频繁模式树建立完后，我们需要按照第一步中获取的表的顺序来遍历每一个项，由于我们之前获取的表中频数最小的项是I5，所以我们接下来先获取I5的条件模式基。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271644036.png" alt="image-20230427164444928" style="zoom:50%;"></p>
<table>
<thead>
<tr class="header">
<th>item</th>
<th>conditional pattern base</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>I5</td>
<td>{I2, I1 : 1}, {I2, I1, I3 : 1}</td>
</tr>
<tr class="even">
<td>I4</td>
<td>{I2, I1 : 1}, {I2 : 1}</td>
</tr>
<tr class="odd">
<td>I3</td>
<td>{I2, I1 : 2}, {I2 : 2}, {I1 : 2}</td>
</tr>
<tr class="even">
<td>I1</td>
<td>{I2 : 4}</td>
</tr>
</tbody>
</table>
<blockquote>
<p>由于I2不存在叶子节点上，所以I2不存在条件模式基</p>
</blockquote>
<p>而fp-growth算法中的分治思想就体现在下面。可以看到，每个项对应的条件模式基本质就是一个项集，所以它们可以看成一个新的事务集。因此，原问题的总事务集就转换成了每个item对应的子事务集，而我们最终的频繁项集分别从每一个item对应的子事务集中产生，问题就被各个item分而治之了。</p>
<h5><span id="3从条件模式基中获取频繁项集">（3）从条件模式基中获取频繁项集</span></h5>
<p>我们之前使用了字典树来压缩表征原事务集，那么对于我们的子事务集，我们也完全可以采用相同的步骤。不过需要注意，<strong>建立子事务集的频繁模式树之前，需要进行统计和基于support
count的项的裁剪。比如对于I5的子事务集（也就是条件模式基），我们需要先统计，得到{I2
: 2, I1 : 2, I3 : 1}。由于我们的support
count为2，所以我们需要去除count只为1的I3</strong>，然后排序得到I2,
I1，剩下的事务集重构为{I2, I1 : 1}, {I2, I1 :
1}，很明显这两个前缀可以合并为{I2, I1 :
2}，然后我们画出这个裁剪后的子事务集的频繁模式树：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271648837.png" alt="img" style="zoom: 67%;"></p>
<p>然后找出这棵频繁模式树的所有路径，可以看到上面的这棵频繁模式树只有一条路径，然后我们找出这条路径上节点所有可能的组合，也就是{I2,
I1}, {I2}, {I1}，这也就是{I2,
I1}的幂集。然后对于每一个组合类型，我们再加上I5，于是就得到了这条路径上得到的频繁项集：{I2,
I1, I5}, {I2, I5}, {I1,
I5}。所有路径上的频繁项集合并起来就是I5对应的频繁项集。</p>
<p>我们再举一个例子，就举I3吧。首先统计项得到 {I2 : 4, I1 :
4}都大于2，不需要裁剪，排序后得到的子事务集不变，还是{I2, I1 : 2}, {I2 :
2}, {I1 : 2}，构建该子数据集的频繁模式树：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304271649435.png" alt="img" style="zoom: 67%;"></p>
<p>然后找出FP-tree的所有路径：{I2, I1}和{I1}。对于路径{I2,
I1}在，找出所有的组合{I2, I1}, {I2}和{I1}，加上I3得到{I2, I1, I3}, {I2,
I3}, {I1, I3}；对于路径{I1}，找出所有的组合{I1}，加上I3得到{I1,
I3}。</p>
<p>遍历完所有路径后，将得到的频繁项集集合取并集，得到{I2, I1, I3}, {I2,
I3}, {I1, I3}。所以I3对应的频繁项集就是{I2, I1, I3}, {I2, I3}, {I1,
I3}。</p>
<h5><span id="4整合每个项的频繁项集就是答案啦">（4）整合每个项的频繁项集，就是答案啦</span></h5>
<p>其余的两个项也是同样的操作过程，最终的每个项对应的频繁项集如下表所示：</p>
<table>
<thead>
<tr class="header">
<th>item</th>
<th>frequent itemsets</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>I5</td>
<td>{I2, I1, I5}, {I2, I5}, {I1, I5}</td>
</tr>
<tr class="even">
<td>I4</td>
<td>{I2, I4}</td>
</tr>
<tr class="odd">
<td>I3</td>
<td>{I2, I3}, {I1, I3}, {I2, I1}</td>
</tr>
<tr class="even">
<td>I1</td>
<td>{I2, I1}</td>
</tr>
</tbody>
</table>
<p>至此FP-growth算法执行结束。可以看到，由于采用了分治的方法，所以FP-growth得到的结果是根据项进行分层的，也就是说结果对于特定的某一个项有很强的指向作用。比如我们只想要研究哪些值和I5最频繁出现，我们可以只看I5产生的频繁项集。</p>
<h4><span id="12-pyspark-demo实现">1.2 Pyspark demo实现</span></h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.fpm <span class="keyword">import</span> FPGrowth</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">&quot;reduceByKey&quot;</span>).getOrCreate()</span><br><span class="line"><span class="comment"># 创建DataFrame</span></span><br><span class="line">data = spark.createDataFrame([</span><br><span class="line">    (<span class="number">1</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>]),</span><br><span class="line">    (<span class="number">2</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>]),</span><br><span class="line">    (<span class="number">3</span>, [<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">], [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;items&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化FPGrowth模型</span></span><br><span class="line">fp = FPGrowth(itemsCol=<span class="string">&quot;items&quot;</span>, minSupport=<span class="number">0.5</span>, minConfidence=<span class="number">0.6</span>)</span><br><span class="line"><span class="comment"># 训练FPGrowth模型</span></span><br><span class="line">model = fp.fit(data)</span><br><span class="line"><span class="comment"># 展示频繁项集</span></span><br><span class="line">model.freqItemsets.show()</span><br></pre></td></tr></table></figure>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>数据挖掘随笔（二）FP-growth算法——一种用于频繁模式挖掘的模式增长方式(Python实现)：https://zhuanlan.zhihu.com/p/411594391</li>
<li><code>pyspark.ml.fpm.``FPGrowth</code>:https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.fpm.FPGrowth.html</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>关联规则</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>关联规则</tag>
        <tag>频繁项集</tag>
        <tag>Apriori</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习（2）Adaboost</title>
    <url>/posts/36WS4DK/</url>
    <content><![CDATA[<h3><span id="一-adaboost-boosting">一、Adaboost (Boosting)</span></h3>
<p>AdaBoost（Adaptive
Boosting，自适应增强），其自适应在于：<strong>前一个基本分类器分错的样本会得到加强，加权后的全体样本再次被用来训练下一个基本分类器。同时，在每一轮中加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数。</strong></p>
<h4><span id="11-思想">1.1 思想</span></h4>
<p><strong>Adaboost 迭代算法有三步：</strong></p>
<ul>
<li>初始化训练样本的权值分布，每个样本具有相同权重；</li>
<li>训练弱分类器，如果样本分类正确，则在构造下一个训练集中，它的权值就会被降低；反之提高。用更新过的样本集去训练下一个分类器；</li>
<li>将所有弱分类组合成强分类器，各个弱分类器的训练过程结束后，<strong>加大分类误差率小的弱分类器的权重，降低分类误差率大的弱分类器的权重</strong>。</li>
</ul>
<h4><span id="12-细节">1.2 细节</span></h4>
<h5><span id="121-损失函数"><strong>1.2.1 损失函数 </strong></span></h5>
<p>Adaboost
模型是<strong>加法模型</strong>，学习算法为<strong>前向分步学习算法</strong>，损失函数为<strong>指数函数的分类问题</strong>。</p>
<p><strong>加法模型</strong>：最终的强分类器是由若干个弱分类器<strong>加权平均</strong>得到的。</p>
<p><strong>前向分布学习算法</strong>：算法是通过一轮轮的弱学习器学习，<strong>利用前一个弱学习器的结果来更新后一个弱学习器的训练集权重</strong>。第
k 轮的强学习器为： <span class="math display">\[
F_{k}(x)=\sum_{i=1}^{k} \alpha_{i} f_{i}(x)=F_{k-1}(x)+\alpha_{k}
f_{k}(x)
\]</span></p>
<p><strong>定义损失函数为 <span class="math inline">\(\mathbf{n}\)</span>
个样本的指数损失函数：</strong> <span class="math display">\[
L(y, F)=\sum_{i=1}^n \exp \left(-y_i F_k\left(x_i\right)\right)
\]</span> 利用前向分布学习算法的关系可以得到： <span class="math display">\[
\begin{aligned}
L(y, F) &amp; =\sum_{i=1}^m \exp
\left[\left(-y_i\right)\left(F_{k-1}\left(x_i\right)+\alpha_k
f_k\left(x_i\right)\right)\right] \\
&amp; =\sum_{i=1}^m \exp \left[-y_i F_{k-1}\left(x_i\right)-y_i \alpha_k
f_k\left(x_i\right)\right] \\
&amp; =\sum_{i=1}^m \exp \left[-y_i F_{k-1}\left(x_i\right)\right] \exp
\left[-y_i \alpha_k f_k\left(x_i\right)\right]
\end{aligned}
\]</span> <strong>因为 <span class="math inline">\(F_{k-1}(x)\)</span>
已知, 所以令 <span class="math inline">\(w_{k, i}=\exp \left(-y_i
F_{k-1}\left(x_i\right)\right)\)</span>
，随着每一轮迭代而将这个式子带入损失函数, 损失函数转 化为:</strong>
<span class="math display">\[
L(y, F(x))=\sum_{i=1}^m w_{k, i} \exp \left[-y_i \alpha_k
f_k\left(x_i\right)\right]
\]</span> 我们求 <span class="math inline">\(f_k(x)\)</span> ，可以得到:
<span class="math display">\[
f_k(x)=\operatorname{argmin} \sum_{i=1}^m w_{k, i} I\left(y_i \neq
f_k\left(x_i\right)\right)
\]</span> 将 <span class="math inline">\(f_k(x)\)</span> 带入损失函数,
并对 <span class="math inline">\(\alpha\)</span> 求导, 使其等于
0，则就得到了: <span class="math display">\[
\alpha_k=\frac{1}{2} \log \frac{1-e_k}{e_k}
\]</span> 其中, <span class="math inline">\(e_k\)</span>
即为我们前面的<strong>分类误差率</strong>。 <span class="math display">\[
e_k=\frac{\sum_{i=1}^m w_{k i}^{\prime} I\left(y_i \neq
f_k\left(x_i\right)\right)}{\sum_{i=1}^m w_{k i}^{\prime}}=\sum_{i=1}^m
w_{k i} I\left(y_i \neq f_k\left(x_i\right)\right)
\]</span> 最后看样本权重的更新。利用 <span class="math inline">\(F_k(x)=F_{k-1}(x)+\alpha_k f_k(x)\)</span> 和
<span class="math inline">\(w_{k+1, i}=w_{k, i} e x p\left[-y_i \alpha_k
f_k(x, i)\right]\)</span>, 即可得: <span class="math display">\[
w_{k+1, i}=w_{k i} \exp \left[-y_i \alpha_k f_k\left(x_i\right)\right]
\]</span> 这样就得到了样本权重更新公式。</p>
<h5><span id="122-正则化">1.2.2 正则化</span></h5>
<p><strong>为了防止 Adaboost
过拟合，我们通常也会加入正则化项，这个正则化项我们通常称为步长（learning
rate)</strong> 。 对于前面的弱学习器的迭代,加上正则化项 <span class="math inline">\(\mu\)</span> 我们有: <span class="math display">\[
F_k(x)=F_{k-1}(x)+\mu \alpha_k f_k(x)
\]</span> <span class="math inline">\(\mu\)</span> 的取值范围为 <span class="math inline">\(0&lt;\mu \leq 1\)</span>
。对于同样的训练集学习效果, 较小的 <span class="math inline">\(\mu\)</span> 意味着我们需要更多的弱学习器的迭代次
数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。</p>
<h4><span id="13-优缺点">1.3 优缺点</span></h4>
<h5><span id="131-优点"><strong>1.3.1 优点</strong></span></h5>
<ol type="1">
<li>分类精度高；</li>
<li>可以<strong>用各种回归分类模型来构建弱学习器，非常灵活</strong>；</li>
<li>不容易发生过拟合。</li>
</ol>
<h5><span id="132-缺点"><strong>1.3.2 缺点</strong></span></h5>
<ol type="1">
<li>对异常点敏感，异常点会获得较高权重。</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
        <tag>集成学习</tag>
        <tag>Adaboost</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习（1）Random Forest</title>
    <url>/posts/3RD5TWZ/</url>
    <content><![CDATA[<h3><span id="一-random-forestbagging">一 、Random Forest（Bagging）</span></h3>
<p><strong>Random Forest（随机森林），用随机的方式建立一个森林。RF
算法由很多决策树组成，每一棵决策树之间没有关联。建立完森林后，当有新样本进入时，每棵决策树都会分别进行判断，然后基于投票法给出分类结果。</strong></p>
<p>对于分类问题，其输出的类别是由个别树输出的众数所决定的。在回归问题中，把每一棵决策树的输出进行平均得到最终的回归结果。</p>
<ol type="1">
<li>随机森林具有<strong>防止过拟合能力</strong>，精度比大多数单个算法要好；</li>
<li>随机森林分类器可以<strong>处理缺失值</strong>；</li>
<li><strong>于有袋外数据(OOB)，可以在模型生成过程中取得真实误差的无偏估计，且不损失训练数据量在训练过程中，能够检测到feature间的互相影响，且可以得出feature的重要性，具有一定参考意义；</strong></li>
<li>每棵树可以独立、同时生成，容易做成<strong>并行化方法</strong>；</li>
<li>具有一定的特征选择能力。</li>
</ol>
<h4><span id="11-思想">1.1 思想</span></h4>
<p><strong>Random Forest (随机森林）是 Bagging 的扩展变体,
它在以决策树为基学习器构建 Bagging 集成的基础上, 进
一步在决策树的训练过程中引入了随机特征选择，因此可以概括 RF
包括四个部分</strong>：</p>
<ul>
<li><strong>样本随机</strong>：假设训练数据集共有 <span class="math inline">\(M\)</span> 个对象的数据,
从样本数据中采取有放回（Boostrap) 随机抽取 <span class="math inline">\(N\)</span> 个 样本 (因为是有放回抽取,
有些数据可能被选中多次, 有些数据可能不被选上), 每一次取出的样本不完全相
同，这些样本组成了决策树的训练数据集；</li>
<li><strong>特征随机</strong>：假设每个样本数据都有 <span class="math inline">\(K\)</span> 个特征, 从所有特征中随机地选取 <span class="math inline">\(k(k&lt;=K)\)</span> 个特征, 选择最佳分割
属性作为节点建立CART决策树, 决策树成长期间 <span class="math inline">\(k\)</span>
的大小始终不变（<strong>在Python中构造随机森林模型的时
候，默认取特征的个数 <span class="math inline">\(k\)</span> 是 <span class="math inline">\(K\)</span> 的平方根, 即 <span class="math inline">\(\sqrt{K}\)</span></strong> );</li>
<li>重复前面的步骤, 建立 <span class="math inline">\(m\)</span>
棵CART树, 这些树都要完全的成长且不被修剪, 这些树形成了森林;</li>
<li>根据这些树的预测结果进行投票,
决定样本的最后预测类别。（针对回归模型, 是根据这些决策树模型的平均
值来获取最终的结果)</li>
</ul>
<p>随机选择样本和 Bagging 相同，采用的是 Bootstrap
自助采样法；<strong>随机选择特征是指在每个节点在分裂过程中都是随机选择特征的</strong>（区别与每棵树随机选择一批特征）。</p>
<blockquote>
<p>这种随机性导致随机森林的偏差会有稍微的增加（相比于单棵不随机树），但是由于随机森林的“平均”特性，会使得它的方差减小，而且方差的减小补偿了偏差的增大，因此总体而言是更好的模型。</p>
</blockquote>
<p>随机采样由于引入了两种采样方法保证了随机性，所以每棵树都是最大可能的进行生长就算不剪枝也不会出现过拟合。</p>
<h4><span id="12-处理缺失值的方法">1.2 处理缺失值的方法</span></h4>
<ul>
<li>方法一（na.roughfix）简单粗暴，对于训练集,同一个class下的数据，如果是<strong>分类变量(categorical
var)缺失，用众数补上</strong>，如果是<strong>连续型变量(numerical
var)缺失，用中位数补</strong>。</li>
<li>方法二（rfImpute）这个方法计算量大，至于比方法一好坏？不好判断。先用na.roughfix补上缺失值，然后构建森林并计算proximity
matrix，再回头看缺失值，如果是分类变量，则用没有缺失的观测实例的proximity中的权重进行投票。如果是连续型变量，则用<strong>proximity矩阵进行加权平均的方法补缺失值</strong>。然后迭代4-6次，这个补缺失值的思想和KNN有些类似。</li>
</ul>
<h4><span id="13-优缺点">1.3 优缺点</span></h4>
<h5><span id="优点"><strong>优点</strong>：</span></h5>
<ol type="1">
<li><p><strong>模型准确率高</strong>：随机森林既可以处理分类问题，也可以处理回归问题，即使存在部分数据缺失的情况，随机森林也能保持很高的分类精度。</p></li>
<li><p><strong>能够处理数量庞大的高维度的特征</strong>，且不需要进行降维（因为特征子集是随机选择的）；</p></li>
<li><p><strong>易于并行化</strong>，在大数据集上有很大的优势；</p></li>
<li><p><strong>可解释性</strong>：可以生成树状结构，判断各个特征的重要性；</p>
<blockquote>
<p>在sklearn中，随机森林<strong>基于每棵树分裂时的GINI指数下降量</strong>来判断各个特征的重要性。但是这种方法存在一个问题：当特征是连续的时候或者是类别很多的离散特征时，该方法会将这些特征的重要性增加。</p>
<p>解决方法：对特征编码，使得特征的取值数量相近。</p>
</blockquote></li>
<li><p><strong>对异常值、缺失值不敏感；</strong></p></li>
<li><p><strong>随机森林有袋外数据（OOB），因此不需要单独划分交叉验证集</strong>。</p></li>
</ol>
<h5><span id="缺点">缺点：</span></h5>
<ul>
<li>随机森林解决回归问题的效果不如分类问题；（因为它的预测不是天生连续的，在解决回归问题时，随机森林并不能为训练数据以外的对象给出答案）</li>
<li><strong>树之间的相关性越大，错误率就越大</strong>；</li>
<li><strong>当训练数据噪声较大时，容易产生过拟合现象。</strong></li>
</ul>
<h4><span id="14-基学习期的选择">1.4 基学习期的选择？</span></h4>
<h5><span id="为什么集成学习的基分类器通常是决策树还有什么">为什么集成学习的基分类器通常是决策树？还有什么？</span></h5>
<p>基分类器通常是决策树：样本权重、方便调节、随机性；</p>
<ul>
<li><strong>决策树可以较方便地将样本权重整合到训练过程中，而不需要通过过采样来调整样本权重。</strong></li>
<li>树的表达能力和泛化能力，<strong>方便调节</strong>（可以通过树的层数来调节）</li>
<li>样本的扰动对决策树的影响较大，<strong><font color="red">
因此不同子样本集合生成的决策树基分类器随机性较大。这样的不稳定的分类器更适合作为基分类器。</font></strong>此外树节点分类时随机选择一个特征子集，从中找出最优分裂属性，很好地引入了随机性。</li>
</ul>
<h5><span id="可以将随机森林的基分类器由决策树替换成线性分类器或k-nn吗">可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？</span></h5>
<p>Bagging主要好处是集成后的方差，比基分类器小。bagging采用的基分类，最好是本身对样本分布较为敏感。而线性分类器和K-NN都是较为稳定的分类器（参数模型？）甚至<strong>可能因为采样，而导致他们再训练中更难收敛，从而增大了集成分类器的偏差。</strong></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
        <tag>集成学习</tag>
        <tag>Random Forest</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习（3）GBDT</title>
    <url>/posts/F4BZ62/</url>
    <content><![CDATA[<h3><span id="一-gradient-boostingdecision-tree">一、Gradient Boosting
Decision Tree</span></h3>
<blockquote>
<p>https://www.cnblogs.com/modifyrong/p/7744987.html</p>
</blockquote>
<p><strong>GBDT（Gradient Boosting Decision
Tree）是一种迭代的决策树算法，该算法由多棵决策树组成，从名字中我们可以看出来它是属于
Boosting 策略。GBDT 是被公认的泛化能力较强的算法。</strong></p>
<h4><span id="11-思想">1.1 思想</span></h4>
<p><strong>GBDT是boosting算法的一种，按照boosting的思想，在GBDT算法的每一步，用一棵决策树去拟合当前学习器的残差，获得一个新的弱学习器。将这每一步的决策树组合起来，就得到了一个强学习器</strong>。GBDT
由三个概念组成：Regression Decision Tree（即 DT）、Gradient Boosting（即
GB），和 Shrinkage（一个重要演变）</p>
<h5><span id="111-回归树regressiondecision-tree">1.1.1 回归树（Regression
Decision Tree）</span></h5>
<p>如果认为 GBDT
由很多分类树那就大错特错了（虽然调整后也可以分类）。对于分类树而言，其值加减无意义（如性别），而对于回归树而言，其值加减才是有意义的（如说年龄）。GBDT
的核心在于累加所有树的结果作为最终结果，所以 GBDT
中的树都是<strong>回归树</strong>，不是分类树，这一点相当重要。</p>
<p><strong><font color="red">
回归树在分枝时会穷举每一个特征的每个阈值以找到最好的分割点，衡量标准是最小化均方误差。</font></strong></p>
<h5><span id="112-梯度迭代gradientboosting"><strong>1.1.2 梯度迭代（Gradient
Boosting）</strong></span></h5>
<p>上面说到 GBDT 的核心在于累加所有树的结果作为最终结果，GBDT
的每一棵树都是以之前树得到的<strong>残差【负梯度】</strong>来更新目标值，这样每一棵树的<strong>值加起来</strong>即为
GBDT 的预测值。</p>
<p>模型的预测值可以表示为： <span class="math display">\[
F_{k}(x)=\sum_{i=1}^{k} f_{i}(x)
\]</span> <span class="math inline">\(f_i(x)\)</span>
为基模型与其权重的乘积, 模型的训练目标是使预测值 <span class="math inline">\(F_k(x)\)</span> 逼近真实值 <span class="math inline">\(\mathrm{y}\)</span>,
也就是说要让每个基模型的预测值逼近各自要预测的部分真实值。贪心的解决手段：每次只训练一个基模型。那么,
现在改写整体模型为迭代式: <span class="math display">\[
F_{k}(x)=F_{k-1}(x)+f_{k}(x)
\]</span>
其实很简单，其<strong>残差其实是最小均方损失函数关于预测值的反向梯度(划重点)</strong>：<strong>用负梯度的解作为样本新的真实值</strong>。基于残差
GBDT 容易对异常值敏感。 <span class="math display">\[
-\frac{\partial\left(\frac{1}{2}\left(y-F_{k}(x)\right)^{2}\right)}{\partial
F_{k}(x)}=y-F_{k}(x)
\]</span> 很明显后续的模型会对第 4
个值关注过多，这不是一种好的现象，所以一般回归类的损失函数会用<strong>绝对损失或者
Huber 损失函数</strong>来代替平方损失函数。 <span class="math display">\[
L(y, F)=|y-F|
\]</span></p>
<p><span class="math display">\[
L(y, F)= \begin{cases}\frac{1}{2}(y-F)^{2} &amp; |y-F| \leq \delta \\
\delta(|y-F|-\delta / 2) &amp; |y-F|&gt;\delta\end{cases}
\]</span></p>
<p>GBDT 的 Boosting 不同于 Adaboost 的 Boosting，<strong>GBDT
的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于
0</strong>，这样后面的树就能专注于那些被分错的样本。</p>
<blockquote>
<p><strong><font color="red">
最后补充一点拟合残差的问题，无论损失函数是什么形式，每个决策树拟合的都是负梯度。只有当损失函数是均方损失时，负梯度刚好是残差</font></strong>，也就是说<strong>拟合残差只是针对均方损失的特例</strong>，并不能说GBDT的迭代的过程是拟合残差。</p>
</blockquote>
<h5><span id="113缩减shrinkage添加权重-基数增大"><strong>1.1.3
缩减（Shrinkage）</strong>添加权重、基数增大</span></h5>
<blockquote>
<p><strong><font color="red">
gbdt中的步长和参数中的学习率作用是什么？详细讲一讲？</font></strong></p>
<ul>
<li>参数中的学习率用于梯度下降</li>
</ul>
</blockquote>
<p>Shrinkage
的思想认为，每走一小步逐渐逼近结果的效果要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它并不是完全信任每一棵残差树。</p>
<p>Shrinkage
不直接用残差修复误差，而是只修复一点点，把大步切成小步。<strong>本质上
Shrinkage 为每棵树设置了一个 weight，累加时要乘以这个 weight，当 weight
降低时，基模型数会配合增大</strong>。</p>
<h4><span id="12-优缺点">1.2 优缺点</span></h4>
<h5><span id="优点"><strong>优点</strong></span></h5>
<ol type="1">
<li>可以自动进行特征组合，拟合非线性数据；在稠密数据集上泛化能力和表达能力很好。</li>
<li>可以灵活处理各种类型的数据，不需要对数据预处理和归一化。</li>
<li>预测可以并行，计算数据很快。</li>
</ol>
<h5><span id="缺点"><strong>缺点</strong></span></h5>
<ol type="1">
<li>对异常点敏感。</li>
</ol>
<h4><span id="13-gbdt-与-adaboost-的对比">1.3 GBDT 与 Adaboost 的对比</span></h4>
<h4><span id="相同"><strong>相同：</strong></span></h4>
<ol type="1">
<li>都是 Boosting 家族成员，使用弱分类器；</li>
<li>都使用前向分布算法；</li>
</ol>
<h4><span id="不同"><strong>不同：</strong></span></h4>
<ol type="1">
<li><strong>迭代思路不同</strong>：Adaboost
是通过提升错分数据点的权重来弥补模型的不足（利用错分样本），而 GBDT
是通过算梯度来弥补模型的不足（利用残差）；</li>
<li><strong>损失函数不同</strong>：AdaBoost
采用的是<strong>指数损失</strong>，GBDT
使用的是<strong>绝对损失</strong>或者 <strong>Huber
损失函数</strong>；</li>
</ol>
<h4><span id="14gbdt算法用于分类问题"><strong><font color="red"> 1.4
GBDT算法用于分类问题</font></strong></span></h4>
<blockquote>
<p>https://zhuanlan.zhihu.com/p/46445201</p>
</blockquote>
<p>将GBDT应用于回归问题，相对来说比较容易理解。因为<strong>回归问题的损失函数一般为平方差损失函数</strong>，这时的残差，恰好等于预测值与实际值之间的差值。每次拿一棵决策树去拟合这个差值，使得残差越来越小，这个过程还是比较intuitive的。</p>
<p><strong><font color="red">
将GBDT用于分类问题，类似于逻辑回归、FM模型用于分类问题，其实是在用一个线性模型或者包含交叉项的非
线性模型, 去拟合所谓的对数几率 <span class="math inline">\(\ln
\frac{p}{1-p}\)</span> 。</font></strong>而GBDT也是一样,
只是用一系列的梯度提升树去拟合这个对数几 率,
实际上最终得到的是一系列CART回归树。其分类模型可以表达为： <span class="math display">\[
P(y=1 \mid x)=\frac{1}{1+e^{-\sum_{m=0}^M h_m(x)}}
\]</span> 其中 <span class="math inline">\(h_m(x)\)</span>
就是学习到的决策树。清楚了这一点之后, 我们便可以参考逻辑回归, 单样本
<span class="math inline">\(\left(x_i, y_i\right)\)</span> 的损失函数可
以表达为<strong>交叉熵</strong>： <span class="math display">\[
\operatorname{loss}\left(x_i, y_i\right)=-y_i \log
\hat{y_i}-\left(1-y_i\right) \log \left(1-\hat{y_i}\right)
\]</span> 假设第 <span class="math inline">\(\mathrm{K}\)</span>
步迭代之后当前学习器为 <span class="math inline">\(F(x)=\sum_{m=0}^k
h_m(x)\)</span>, 将 <span class="math inline">\(\hat{y}_i\)</span>
的表达式带入之后, 可将损失函数写为: <span class="math display">\[
\operatorname{loss}\left(x_i, y_i \mid F(x)\right)=y_i \log
\left(1+e^{-F\left(x_i\right)}\right)+\left(1-y_i\right)\left[F\left(x_i\right)+\log
\left(1+e^{-F\left(x_i\right)}\right)\right]
\]</span> <strong>可以求得损失函数相对于当前学习器的负梯度为</strong>：
<span class="math display">\[
-\left.\frac{\partial l o s s}{\partial F(x)}\right|_{x_i,
y_i}=y_i-\frac{1}{1+e^{-F\left(x_i\right)}}=y_i-\hat{y_i}
\]</span> 可以看到, 同回归问题很类似, 下一棵决策树的训练样本为: <span class="math inline">\(\left\{x_i,
y_i-\hat{y}_i\right\}_{i=1}^n\)</span>, 其所需要拟合的残差为真实标签
与预测概率之差。于是便有下面GBDT应用于二分类的算法：</p>
<ul>
<li><span class="math inline">\(F_0(x)=h_0(x)=\log
\frac{p_1}{1-p_1}\)</span>, 其中 <span class="math inline">\(p_1\)</span> 是训练样本中 <span class="math inline">\(\mathrm{y}=1\)</span> 的比例,
利用先验信息来初始化学习器</li>
<li>For <span class="math inline">\(m=1,2, \ldots, M\)</span> :
<ul>
<li>计算 <span class="math inline">\(g_i=\hat{y}_i-y_i\)</span>,
并使用训练集 <span class="math inline">\(\left\{\left(x_i,-g_i\right)\right\}_{i=1}^n\)</span>
<strong>训练一棵回归树</strong> <span class="math inline">\(t_m(x)\)</span>, 其中 <span class="math inline">\(\hat{y}_i=\frac{1}{1+e^{-F_{m-1}(x)}}\)</span></li>
<li>通过一维最小化损失函数找到树的最优权重: <span class="math inline">\(\quad
\rho_m=\underset{\rho}{\operatorname{argmin}} \sum_i l o s s\left(x_i,
y_i \mid F_{m-1}(x)+\rho t_m(x)\right)\)</span></li>
</ul></li>
<li><strong>考虑shrinkage,</strong> 可得这一轮迭代之后的学习器 <span class="math inline">\(F_m(x)=F_{m-1}(x)+\alpha \rho_m t_m(x),
\alpha\)</span> 为学习率</li>
<li>得到最终学习器为： <span class="math inline">\(F_M(x)\)</span></li>
</ul>
<p>以上就是将GBDT应用于二分类问题的算法流程。类似地, 对于多分类问题,
则需要考虑以下softmax模型： <span class="math display">\[
\begin{array}{r}
P(y=1 \mid x)=\frac{e^{F_1(x)}}{\sum_{i=1}^k e^{F_i(x)}} \\
P(y=2 \mid x)=\frac{e^{F_2(x)}}{\sum_{i=1}^k e^{F_i(x)}} \\
\ldots \cdots \\
P(y=k \mid x)=\frac{e^{F_k(x)}}{\sum_{i=1}^k e^{F_i(x)}}
\end{array}
\]</span> <strong>其中 <span class="math inline">\(F_1 ... F_k\)</span>
是 <span class="math inline">\(k\)</span> 个不同的tree
ensemble。每一轮的训练实际上是训练了 <span class="math inline">\(k\)</span> 棵树去拟合softmax的每一个分支
模型的负梯度</strong>【one-hot中的一维】。softmax模型的单样本损失函数为:
<span class="math display">\[
\text { loss }=-\sum_{i=1}^k y_i \log P\left(y_i \mid
x\right)=-\sum_{i=1}^k y_i \log \frac{e^{F_i(x)}}{\sum_{j=1}^k
e^{F_j(x)}}
\]</span> 这里的 <span class="math inline">\(y_i(i=1 \ldots k)\)</span>
是样本label在 <span class="math inline">\(\mathbf{k}\)</span>
个类别上作one-hot编码之后的取值, 只有一维为 1 , 其余都是 <span class="math inline">\(\mathbf{0}\)</span> 。由以上表 达式不难推导: <span class="math display">\[
-\frac{\partial l o s s}{\partial
F_q}=y_q-\frac{e^{F_q(x)}}{\sum_{j=1}^k e^{F_j(x)}}=y_q-\hat{y_q}
\]</span> 可见, 这k棵树同样是拟合了样本的真实标签与预测概率之差,
与二分类的过程非常类似。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
        <tag>集成学习</tag>
        <tag>GBDT</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习（5）LightGBM</title>
    <url>/posts/3VQ3FZD/</url>
    <content><![CDATA[<h2><span id="一-lightgbm">一、LightGBM</span></h2>
<blockquote>
<ul>
<li>《<a href="https://www.zhihu.com/search?q=Lightgbm%3A+A+highly+efficient+gradient+boosting+decision+tree&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22165627712%22%7D">Lightgbm:
A highly efficient gradient boosting decision tree</a>》</li>
<li>《A communication-efficient <a href="https://www.zhihu.com/search?q=parallel+algorithm+for+decision+tree&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22165627712%22%7D">parallel
algorithm for decision tree</a>》</li>
</ul>
</blockquote>
<p>LightGBM 由微软提出，主要用于解决 GDBT
在海量数据中遇到的问题，以便其可以更好更快地用于工业实践中。从 LightGBM
名字我们可以看出其是轻量级（Light）的梯度提升机（GBM），其相对 XGBoost
具有<strong>训练速度快、内存占用低</strong>的特点。下图分别显示了
XGBoost、XGBoost_hist（利用梯度直方图的 XGBoost） 和 LightGBM
三者之间针对不同数据集情况下的内存和训练时间的对比：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304212057167.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>那么 LightGBM
到底如何做到<strong>更快的训练速度和更低的内存</strong>使用的呢？</p>
<p><strong><font color="red"> LightGBM
为了解决这些问题提出了以下几点解决方案：</font></strong></p>
<ol type="1">
<li><p><strong>【减小内存、最优分类点】直方图算法</strong>；【特征离散化
+ 内存占用 + 方差减少】</p></li>
<li><p><strong>【样本维度】 单边梯度抽样算法</strong>；</p>
<ul>
<li><p>【根据样本梯度来对梯度小的这边样本进行采样，一部分大梯度和随机分布】</p></li>
<li><p>一方面算法将更多的注意力放在训练不足的样本上，另一方面通过乘上权重来防止采样对原始数据分布造成太大的影响。</p></li>
</ul></li>
<li><p><strong>【特征维度】互斥特征捆绑算法</strong>；【特征稀疏行优化
+分箱 】</p></li>
<li><p><strong>【分裂算法】基于最大深度的 Leaf-wise
的垂直生长算法</strong>；【深度限制的最大分裂收益的叶子】</p></li>
<li><p><strong>类别特征最优分割</strong>；</p></li>
<li><p><strong>特征并行和数据并行</strong>；</p></li>
<li><p><strong>缓存优化。</strong></p></li>
</ol>
<h3><span id="11-数学原理">1.1 数学原理</span></h3>
<h4><span id="111-直方图算法"><strong>1.1.1 直方图算法</strong></span></h4>
<h5><span id="1-直方图算法"><strong>(1) 直方图算法</strong></span></h5>
<p><strong><font color="red"> 直方图算法的基本思想是将连续的特征离散化为
k （默认256, 1字节）个离散特征，同时构造一个宽度为 k
的直方图用于统计信息（含有 k 个
bin）。利用直方图算法我们无需遍历数据，只需要遍历 k 个 bin
即可找到最佳分裂点。</font></strong></p>
<p>我们知道特征离散化的具有很多优点，如存储方便、运算更快、鲁棒性强、模型更加稳定等等。对于直方图算法来说最直接的有以下两个优点（以
k=256 为例）：</p>
<ul>
<li><strong>内存占用更小：</strong>XGBoost 需要用 32
位的浮点数去存储特征值，并用 32 位的整形去存储排序索引，而 LightGBM
只需要用 8 位去存储直方图，相当于减少了 1/8；</li>
<li><strong>计算代价更小：</strong>计算特征分裂增益时，XGBoost
需要遍历一次数据找到最佳分裂点，而 LightGBM 只需要遍历一次 k
次，直接将时间复杂度从代价是O( feature *
distinct_values_of_the_feature); 而 histogram 只需要计算 bins次, 代价是(
feature * bins)。distinct_values_of_the_feature &gt;&gt; bins</li>
</ul>
<p><strong>（2）直方图优化算法流程:</strong></p>
<ol type="1">
<li><strong>直方图优化算法需要在训练前预先把特征值转化为bin
value</strong>，也就是对每个特征的取值做个分段函数，将所有样本在该特征上的取值划分到某一段（bin）中。最终把特征取值从连续值转化成了离散值。需要注意得是：feature
value对应的bin value在整个训练过程中是不会改变的。</li>
<li><strong>最外面的 for
循环表示的意思是对当前模型下所有的叶子节点处理</strong>，需要遍历所有的特征，来找到增益最大的特征及其划分值，以此来分裂该叶子节点。</li>
<li>在某个叶子上，第二个 for
循环就开始遍历所有的特征了。<strong>对于每个特征，首先为其创建一个直方图
(new Histogram()
)</strong>。这个直方图存储了两类信息，分别是<strong><font color="red">
每个bin中样本的梯度之和 <span class="math inline">\(H[ f.bins[i]
].g\)</span>
</font></strong>，还有就是<strong>每个bin中样本数量</strong><span class="math inline">\(（H[f.bins[i]].n）\)</span></li>
<li>第三个 for
循环遍历所有样本，累积上述的两类统计值到样本所属的bin中。即直方图的每个
bin 中包含了一定的样本，在此计算每个 bin 中的样本的梯度之和并对 bin
中的样本记数。</li>
<li>最后一个for循环, 遍历所有bin, 分别以当前bin作为分割点,
累加其左边的bin至当前bin的梯度和（ <span class="math inline">\(\left.S_{L}\right)\)</span> 以及样本数量 <span class="math inline">\(\left(n_{L}\right)\)</span>,
并与父节点上的总梯度和 <span class="math inline">\(\left(S_{p}\right)\)</span> 以及总样本数量 <span class="math inline">\(\left(n_{p}\right)\)</span> 相减, 得到右边
所有bin的梯度和 <span class="math inline">\(\left(S_{R}\right)\)</span>
以及样本数量 <span class="math inline">\(\left(n_{R}\right)\)</span>,
带入公式, 计算出增益, 在遍历过程中取最大的增 益,
以此时的特征和bin的特征值作为分裂节点的特征和分裂特征取值。</li>
</ol>
<h5><span id="3-源码分析">(3) 源码分析</span></h5>
<blockquote>
<p>https://blog.csdn.net/anshuai_aw1/article/details/83040541</p>
<p><strong><font color="red">
『我爱机器学习』集成学习（四）LightGBM</font></strong>：https://www.hrwhisper.me/machine-learning-lightgbm/</p>
</blockquote>
<p>问题一：<strong>如何将特征映射到bin呢？即如何分桶？对于连续特征和类别特征分别怎么样处理？</strong></p>
<p>问题二：<strong>如何构建直方图？直方图算法累加的g是什么？难道没有二阶导数h吗？</strong></p>
<h5><span id="特征分桶">特征分桶：</span></h5>
<blockquote>
<p><strong>特征分桶的源码</strong>在<strong>bin.cpp</strong>文件和<strong>bin.h</strong>文件中。由于LGBM可以处理类别特征，因此对连续特征和类别特征的处理方式是不一样的。</p>
</blockquote>
<h5><span id="连续特征">连续特征:</span></h5>
<p>在<strong>bin.cpp</strong>中，我们可以看到<strong>GreedyFindBin</strong>函数和<strong>FindBinWithZeroAsOneBin</strong>函数，这两个函数得到了数值型特征取值（负数，0，正数）的各个bin的切分点，即bin_upper_bound。</p>
<h5><span id="greedyfindbin数值型根据特征不同取值的个数划分类别型">GreedyFindBin:
数值型根据特征不同取值的个数划分，类别型？？</span></h5>
<ul>
<li><em>特征取值计数的数组</em>、<em>特征的不同的取值的数组</em>、<em>特征有多少个不同的取值</em></li>
<li><strong>bin_upper_bound就是记录桶分界的数组</strong></li>
<li>特征取值数比max_bin数量少，直接取distinct_values的中点放置</li>
<li>特征取值数比max_bin来得大，说明几个特征值要共用一个bin
<ul>
<li>如果一个特征值的数目比mean_bin_size大，那么这些特征需要单独一个bin</li>
<li>剩下的特征取值的样本数平均每个剩下的bin：mean size for one bin</li>
</ul></li>
</ul>
<h5><span id="构建直方图">构建直方图：</span></h5>
<p>给定一个特征的值，我们现在已经可以转化为对应的bin了。现在我们就可以构建直方图了。</p>
<h5><span id="constructhistogram"><strong>ConstructHistogram</strong>：</span></h5>
<ul>
<li><strong>累加了一阶、二阶梯度和还有个数</strong></li>
<li>当然还有其它的版本，当is_constant_hessianis_constant_hessian为true的时候是不用二阶梯度的</li>
</ul>
<h5><span id="寻找最优切分点-缺失值处理-gain和xgb一样">寻找最优切分点 :
缺失值处理 + Gain和XGB一样</span></h5>
<h5><span id="4直方图算法优点"><strong><font color="red">
（4）直方图算法优点：</font></strong></span></h5>
<ul>
<li><p><strong>内存消耗降低</strong>。预排序算法需要的内存约是训练数据的两倍（2x样本数x维度x4Bytes），它需要用32位浮点来保存特征值，并且对每一列特征，都需要一个额外的排好序的索引，这也需要32位的存储空间。对于
直方图算法，则只需要(1x样本数x维
度x1Bytes)的内存消耗，仅为预排序算法的1/8。因为直方图算法仅需要存储特征的
bin
值(离散化后的数值)，不需要原始的特征值，也不用排序，而bin值用8位整型存储就足够了。</p></li>
<li><p><strong>算法时间复杂度大大降低</strong>。决策树算法在节点分裂时有两个主要操作组成，一个是“寻找分割点”，另一个是“数据分割”。从算法时间复杂度来看，在“寻找分割点”时，预排序算法对于深度为<span class="math inline">\(k\)</span>的树的时间复杂度：对特征所有取值的排序为<span class="math inline">\(O(NlogN)\)</span>，<span class="math inline">\(N\)</span>为样本点数目，若有<span class="math inline">\(D\)</span>维特征，则<span class="math inline">\(O(kDNlogN)\)</span>，而直方图算法需要<span class="math inline">\(O(kD \times bin)\)</span> (bin是histogram
的横轴的数量，一般远小于样本数量<span class="math inline">\(N\)</span>)。</p></li>
<li><p><strong>直方图算法还可以进一步加速</strong>【<strong>两个维度</strong>】。一个容易观察到的现象：<strong>一个叶子节点的直方图可以直接由父节点的直方图和兄弟节点的直方图做差得到（分裂时左右集合）</strong>。通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的<span class="math inline">\(k\)</span>个bin。利用这个方法，LightGBM可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。</p></li>
<li><p><strong>缓存优化</strong>：上边说到 XGBoost
的预排序后的特征是通过索引给出的样本梯度的统计值，因其索引访问的结果并不连续，XGBoost
提出缓存访问优化算法进行改进。<strong><font color="red"> LightGBM
所使用直方图算法对 Cache
天生友好所有的特征都采用相同的方法获得梯度，构建直方图时bins字典同步记录一阶导、二阶导和个数，大大提高了缓存命中</font></strong>；因为<strong>不需要存储特征到样本的索引</strong>，降低了存储消耗，而且也不存在
Cache Miss的问题。</p></li>
<li><p><strong>数据并行优化</strong>，用 histgoram
可以大幅降低通信代价。用 pre-sorted
算法的话，通信代价是非常大的（几乎是没办法用的）。所以 xgoobst
在并行的时候也使用 histogram 进行通信。</p></li>
</ul>
<h5><span id="5直方图算法缺点">（5）直方图算法缺点：</span></h5>
<p><strong>当然，直方图算法并不是完美的。由于特征被离散化后，找到的并不是很精确的分割点，所以会对结果产生影响。</strong>但在不同的数据集上的结果表明，离散化的分割点对最终的精度影响并不是很大，甚至有时候会更好一点。原因是决策树本来就是弱模型，分割点是不是精确并不是太重要；<strong>较粗的分割点也有正则化的效果，可以有效地防止过拟合</strong>；即使单棵树的训练误差比精确分割的算法稍大，但在梯度提升（GradientBoosting）的框架下没有太大的影响。</p>
<h4><span id="112-单边梯度抽样算法"><strong>1.1.2 单边梯度抽样算法</strong></span></h4>
<p><font color="red">
<strong>直方图算法仍有优化的空间</strong>，建立直方图的复杂度为O(<strong>feature
×
data</strong>)，如果能<strong>降低特征数</strong>或者<strong>降低样本数</strong>，训练的时间会大大减少。</font></p>
<p><strong>GBDT
算法的梯度大小可以反应样本的权重，梯度越小说明模型拟合的越好，单边梯度抽样算法</strong>（Gradient-based
One-Side Sampling,
GOSS）利用这一信息对样本进行抽样，减少了大量梯度小的样本，在接下来的计算锅中只需关注梯度高的样本，极大的减少了计算量。</p>
<ol type="1">
<li>根据<strong>梯度的绝对值</strong>将样本进行<strong>降序</strong>排序</li>
<li>选择前a×100%的样本，这些样本称为A</li>
<li>剩下的数据(1−a)×100的数据中，随机抽取b×100%的数据，这些样本称为B</li>
<li>在计算增益的时候，放大样本B中的梯度 (1−a)/b 倍</li>
<li>关于g，在具体的实现中是一阶梯度和二阶梯度的乘积，见Github的实现（LightGBM/src/boosting/goss.hpp）</li>
</ol>
<blockquote>
<p>a%（大梯度）+ (1-a)/ b * b % 的大梯度</p>
</blockquote>
<p><strong>使用GOSS进行采样,
使得训练算法更加的关注没有充分训练(under-trained)的样本,
并且只会稍微的改变原有的数据分布</strong>。原有的在特征值为 <span class="math inline">\(\mathrm{d}\)</span> 处分数据带来的增益可以定义为：
<span class="math display">\[
V_{j \mid O}(d)=\frac{1}{n_{O}}\left(\frac{\left(\sum_{x_{i} \in O: x_{i
j} \leq d} g_{i}\right)^{2}}{n_{l \mid
O}^{j}(d)}+\frac{\left(\sum_{x_{i} \in O: x_{i j}&gt;d}
g_{i}\right)^{2}}{n_{r \mid O}^{j}(d)}\right)
\]</span> 其中: - O为在决策树待分裂节点的训练集 - <span class="math inline">\(n_{o}=\sum I\left(x_{i} \in O\right)\)</span> -
<span class="math inline">\(n_{l \mid O}^{j}(d)=\sum I\left[x_{i} \in O:
x_{i j} \leq d\right]\)</span> and <span class="math inline">\(n_{r \mid
O}^{j}(d)=\sum I\left[x_{i} \in O: x_{i j}&gt;d\right]\)</span></p>
<p><strong>而使用GOSS后, 增益定义为：</strong> <span class="math display">\[
V_{j \mid O}(d)=\frac{1}{n_{O}}\left(\frac{\left(\sum_{x_{i} \in A_{l}}
g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{l}}
g_{i}\right)^{2}}{n_{l}^{j}(d)}+\frac{\left(\sum_{x_{i} \in A_{r}}
g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{l}}
g_{r}\right)^{2}}{n_{r}^{j}(d)}\right)
\]</span> 其中: - <span class="math inline">\(A_{l}=\left\{x_{i} \in A:
x_{i j} \leq d\right\}, A_{r}=\left\{x_{i} \in A: x_{i
j}&gt;d\right\}\)</span> - <span class="math inline">\(B_{l}=\left\{x_{i} \in B: x_{i j} \leq d\right\},
B_{r}=\left\{x_{i} \in B: x_{i j}&gt;d\right\}\)</span></p>
<p>实验表明，该做法并没有降低模型性能，反而还有一定提升。究其原因，应该是采样也会增加弱学习器的多样性，从而潜在地提升了模型的泛化能力，稍微有点像深度学习的dropout。</p>
<h4><span id="113互斥特征捆绑算法冲突小的特征可能与多个特征包组合特征集合"><strong>1.1.3
互斥特征捆绑算法</strong>【冲突小的特征可能与多个特征包组合】[特征集合]</span></h4>
<blockquote>
<p><strong>互斥指的是一些特征很少同时出现非0值</strong>【<strong>类似one-hot特征</strong>】</p>
<p><a href="https://zhuanlan.zhihu.com/p/366234433">详解LightGBM两大利器：基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）</a></p>
</blockquote>
<p><strong><font color="red"> 互斥特征捆绑算法（Exclusive Feature
Bundling,
EFB）指出如果将一些特征进行合并，则可以降低特征数量。</font></strong>高维特征往往是稀疏的，而且特征间可能是相互排斥的（如两个特征不同时取非零值），如果两个特征并不完全互斥（如只有一部分情况下是不同时取非零值），可以用互斥率表示互斥程度。</p>
<p><strong>1）首先介绍如何判定哪些特征应该捆绑在一起？</strong></p>
<p>EFB算法采用<strong>构图（build
graph）</strong>的思想，将特征作为节点，不互斥的特征之间进行连边，然后从图中找出所有的捆绑特征集合。其实学过数据结构里的图算法就了解过，这个问题基本就是<a href="https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%9B%BE%E7%9D%80%E8%89%B2%E9%97%AE%E9%A2%98/8928655%3Ffr%3Daladdin">图着色问题</a>。但是图着色问题是一个<strong>NP-hard问题</strong>，不可能在多项式时间里找到最优解。</p>
<p>因此EFB采用了一种近似的贪心策略解决办法。<strong>它允许特征之间存在少数的样本点并不互斥（比如某些对应的样本
点之间并不同时为非 0 ）</strong>, 并设置一个最大冲突阈值 <span class="math inline">\(K\)</span> 。我们选择合适的 <span class="math inline">\(K\)</span> 值, 可以在准确度和训绩效率上获
得很好的trade-off (均衡)。</p>
<p><strong>下面给出EFB的特征捆绑的贪心策略流程：</strong></p>
<blockquote>
<p>（1）将特征作为图的顶点，对于<strong>不互斥的特征进行相连</strong>（存在同时不为0的样本），特征同时不为0的样本个数作为边的权重；
（2）根据顶点的度对特征进行降序排序，度越大表明特征与其他特征的冲突越大（越不太可能与其他特征进行捆绑）；【<strong>入度排序，转化为非零值个数排序</strong>】
（3）设置<strong>最大冲突阈值K</strong>，外层循环先对每一个上述排序好的特征，遍历已有的特征捆绑簇，如果发现该特征加入到该特征簇中的冲突数不会超过最大阈值K，则将该特征加入到该簇中。否则新建一个特征簇，将该特征加入到新建的簇中。</p>
</blockquote>
<p><img src="https://pic4.zhimg.com/80/v2-743681d9fd6cebee11f0dcc607f2f687_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p>上面时间的复杂度为 <span class="math inline">\(O(N^2)\)</span>，n为特征的数量，时间其实主要花费在建图上面，两两特征计算互斥程度的时间较长（2层for循环）。对于百万级别的特征数量来说，该复杂度仍是<strong>不可行的</strong>。为了提高效率，可以不再构建图，将特征直接按照非零值个数排序，将特征<strong>非零值个数</strong>类比为节点的度（即冲突程度)，因为更多的非零值更容易引起冲突。只是改进了排序策略，不再构建图，下面的for循环是一样的。</p>
<p><strong>2）如何将特征捆绑簇里面的所有特征捆绑（合并）为一个特征？</strong>【<strong>直方图偏移</strong>】</p>
<p>如何进行合并，最关键的是如何能将原始特征从合并好的特征进行分离出来。EFB采用的是加入一个<strong>偏移常量</strong>（offset）来解决。</p>
<blockquote>
<p>举个例子，我们绑定两个特征A和B，A取值范围为[0, 10)，B取值范围为[0,
20)。则我们可以加入一个偏移常量10，即将B的取值范围变为[10,30），然后合并后的特征范围就是[0,
30)，并且能很好的分离出原始特征~</p>
</blockquote>
<p>因为lgb中<strong>直方图算法</strong>对特征值进行了<strong>分桶</strong>（bin）操作，导致合并互斥特征变得更为简单。从上面伪码看到偏移常量offset直接对每个特征桶的数量累加就行，然后放入偏移常数数组（binRanges）中。</p>
<h4><span id="114-带深度限制的leaf-wise-算法"><strong>1.1.4 带深度限制的
Leaf-wise 算法</strong></span></h4>
<h5><span id="level-wise">Level-wise</span></h5>
<p>大多数GBDT框架使用的按层生长 (level-wise)
的决策树生长策略，Level-wise遍历一次数据可以同时分裂同一层的叶子，容易进行<strong>多线程优化</strong>，也好<strong>控制模型复杂度，不容易过拟合</strong>。但实际上Level-wise是一种低效的算法，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销，因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。</p>
<h5><span id="leaf-wise">Leaf-wise</span></h5>
<p>Leaf-wise则是一种更为高效的策略，每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环。因此同Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度。Leaf-wise的缺点是可能会长出比较深的决策树，产生过拟合。因此LightGBM在Leaf-wise之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-76f2f27dd24fc452a9a65003e5cdd305_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="115lightgbm类别特征最优分割"><strong>1.1.5
LightGBM类别特征最优分割</strong></span></h4>
<blockquote>
<p>LightGBM中只需要提前将类别映射到非负整数即可(<code>integer-encoded categorical features</code>)</p>
</blockquote>
<p><strong>我们知道，LightGBM可以直接处理类别特征，而不需要对类别特征做额外的one-hot
encoding。那么LGB是如何实现的呢？</strong></p>
<p>类别特征的使用在实践中是很常见的。且为了解决one-hot编码处理类别特征的不足,
LightGBM优化了对类别特征的支持，可以直接输入类别特征，不需要额外的0/1展开。<strong>LightGBM
采用 many-vs-many
的切分方式将类别特征分为两个子集，实现类别特征的最优切分</strong>。假设某维
特征有 k 个类别，则有<span class="math inline">\(2^k - 1\)</span>种可能,
时间复杂度为<span class="math inline">\(o(2^k)\)</span> ,LightGBM 基于
Fisher的 《<a href="https://www.zhihu.com/search?q=On+Grouping+For+Maximum+Homogeneity&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22165627712%22%7D">On
Grouping For Maximum Homogeneity</a>》论文实现了 O(klogk) 的<a href="https://www.zhihu.com/search?q=时间复杂度&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22165627712%22%7D">时间复杂度</a>。</p>
<p><strong>算法流程如下图所示</strong>，在枚举分割点之前，先把直方图按照每个类别对应的label均值进行排序;
然后按照排序的结果依次枚举最优分割点。从下图可以看到, <span class="math inline">\(\frac{\operatorname{Sum}(y)}{\operatorname{Count}(y)}\)</span>为类别的均值。当然，这个方法很容易过拟合，所以LightGBM里面还增加了很多对于这个方法的约束和正则化。</p>
<p><img src="https://pic1.zhimg.com/v2-0f1b7024e9da8f09c75b7f8e436a5d24_b.jpg" alt="img" style="zoom:67%;"></p>
<p><strong>在Expo数据集上的实验结果表明，相比0/1展开的方法，使用LightGBM支持的类别特征可以使训练速度加速8倍，并且精度一致。</strong>更重要的是，LightGBM是第一个直接支持类别特征的GBDT工具。</p>
<h3><span id="12-工程实现-并行计算">1.2 工程实现 - 并行计算</span></h3>
<h4><span id="121-特征并行优化最优划分点"><strong>1.2.1 特征并行</strong>【优化
最优划分点】</span></h4>
<p>传统的特征并行算法在于对数据进行垂直划分，然后使用<strong>不同机器找到不同特征的最优分裂点</strong>，<strong>基于通信整合得到最佳划分点</strong>，然后基于通信告知其他机器划分结果。在本小节中，<strong>工作的节点称为worker</strong></p>
<h5><span id="传统"><strong>传统：</strong></span></h5>
<ul>
<li>垂直划分数据<strong>（对特征划分）</strong>，<strong>不同的worker有不同的特征集</strong></li>
<li>每个workers找到局部最佳的切分点{feature, threshold}</li>
<li>workers使用点对点通信，找到全局最佳切分点</li>
<li><strong>具有全局最佳切分点的worker进行节点分裂，然后广播切分后的结果</strong>（<strong>左右子树的instance
indices</strong>）</li>
<li>其它worker根据收到的instance indices也进行划分</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-b0d10c5cd832402e4503e2c1220f7376_r.jpg" alt="preview" style="zoom: 67%;"></p>
<p><strong>传统的特征并行方法有个很大的缺点</strong>：</p>
<ul>
<li><strong>需要告知每台机器最终划分结果，增加了额外的复杂度</strong>（因为对数据进行垂直划分，每台机器所含数据不同，划分结果需要通过通信告知）；</li>
<li>无法加速split的过程，该过程复杂度为O(#data)O(#data)，当数据量大的时候效率不高；</li>
</ul>
<h5><span id="lightgbm"><strong>LightGBM</strong></span></h5>
<p><strong>LightGBM
则不进行数据垂直划分，每台机器都有训练集完整数据</strong>，在得到最佳划分方案后可在本地执行划分而减少了不必要的通信。</p>
<ul>
<li>每个workers找到局部最佳的切分点{feature, threshold}</li>
<li>workers使用点对点通信，找到全局最佳切分点</li>
<li>每个worker根据全局最佳切分点进行节点分裂</li>
</ul>
<h5><span id="缺点">缺点：</span></h5>
<ul>
<li>split过程的复杂度仍是O(#data)，当数据量大的时候效率不高</li>
<li><strong>每个worker保存所有数据，存储代价高</strong></li>
</ul>
<h4><span id="122-数据并行"><strong>1.2.2 数据并行</strong></span></h4>
<h5><span id="传统方法">传统方法：</span></h5>
<p>数据并行目标是并行化整个决策学习的过程：</p>
<ul>
<li>水平切分数据，<strong>不同的worker拥有部分数据</strong></li>
<li>每个worker根据本地数据构建局部直方图</li>
<li>合并所有的局部直方图得到全部直方图</li>
<li>根据全局直方图找到最优切分点并进行分裂</li>
</ul>
<figure>
<img src="https://www.hrwhisper.me/images/machine-learning-lightgbm/LightGBM-data-parallelization.png" alt="LightGBM-data-parallelization">
<figcaption aria-hidden="true">LightGBM-data-parallelization</figcaption>
</figure>
<p>在第3步中，有两种合并的方式：</p>
<ul>
<li>采用点对点方式(point-to-point communication
algorithm)进行通讯，每个worker通讯量为$O(machine * feature * bin
$)。</li>
<li>采用collective communication algorithm(如“All
Reduce”)进行通讯（相当于有一个中心节点，通讯后在返回结果），每个worker的通讯量为$O(machine
* feature * bin $)。</li>
</ul>
<h5><span id="lightgbm中的数据并行">LightGBM中的数据并行</span></h5>
<ol type="1">
<li><strong>使用“Reduce
Scatter”将不同worker的不同特征的直方图合并，然后workers在局部合并的直方图中找到局部最优划分，最后同步全局最优划分。</strong></li>
<li>前面提到过，可以通过直方图作差法得到兄弟节点的直方图，因此只需要通信一个节点的直方图。</li>
</ol>
<p>传统的数据并行策略主要为水平划分数据，然后本地构建直方图并整合成全局直方图，最后在全局直方图中找出最佳划分点。这种数据划分有一个很大的缺点：通讯开销过大。如果使用点对点通信，一台机器的通讯开销大约为
$O(machine * feature * bin $); 如果使用集成的通信, 则通讯开销为 <span class="math inline">\(O(2 * feature * b i n)\)</span>.</p>
<p><strong>LightGBM 采用分散规约（Reduce
scatter）的方式将直方图整合的任务分摊到不同机器上，从而降低通信代价，并通过直方图做差进一步降低不同机器间的通信。</strong></p>
<h4><span id="123-投票并行"><strong>1.2.3 投票并行</strong></span></h4>
<p>LightGBM采用一种称为<strong>PV-Tree</strong>的算法进行投票并行(Voting
Parallel)，其实这本质上也是一种<strong>数据并行</strong>。PV-Tree和普通的决策树差不多，只是在寻找最优切分点上有所不同。</p>
<p>其算法伪代码描述如下：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304212108095.png" alt="LightGBM-pv-tree" style="zoom:50%;"></p>
<ol type="1">
<li>水平切分数据，不同的worker拥有部分数据。</li>
<li>Local voting:
<strong>每个worker构建直方图，找到top-k个最优的本地划分特征。</strong></li>
<li>Global voting:
<strong>中心节点聚合得到最优的top-2k个全局划分特征（top-2k是看对各个worker选择特征的个数进行计数，取最多的2k个）。</strong></li>
<li><strong>Best Attribute Identification</strong>：
<strong>中心节点向worker收集这top-2k个特征的直方图，并进行合并，然后计算得到全局的最优划分。</strong></li>
<li>中心节点将全局最优划分广播给所有的worker，worker进行本地划分。</li>
</ol>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304212107125.png" alt="LightGBM-voting-parallelization" style="zoom: 50%;"></p>
<p><strong>可以看出，PV-tree将原本需要 $O(machine * feature * bin $)
变为了 <span class="math inline">\(O(2 * feature * b i
n)\)</span>，通信开销得到降低。此外，可以证明，当每个worker的数据足够多的时候，top-2k个中包含全局最佳切分点的概率非常高。</strong></p>
<h4><span id="124-缓存优化"><strong>1.2.4 缓存优化</strong></span></h4>
<p>上边说到 XGBoost
的预排序后的特征是通过索引给出的样本梯度的统计值，因其索引访问的结果并不连续，XGBoost
提出缓存访问优化算法进行改进。</p>
<p>而 LightGBM 所使用直方图算法对 Cache 天生友好：</p>
<ol type="1">
<li>首先，<strong>所有的特征都采用相同的方法获得梯度</strong>（区别于不同特征通过不同的索引获得梯度），只需要对梯度进行排序并可实现连续访问，大大提高了缓存命中；</li>
<li>其次，因为<strong>不需要存储特征到样本的索引</strong>，降低了存储消耗，而且也不存在
Cache Miss的问题。</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
        <tag>集成学习</tag>
        <tag>LightGBM</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习（6）CatBoost</title>
    <url>/posts/160TFHT/</url>
    <content><![CDATA[<h2><span id="深入理解catboost">深入理解CatBoost</span></h2>
<blockquote>
<p>深入理解CatBoost - Microstrong的文章 - 知乎
https://zhuanlan.zhihu.com/p/102540344</p>
</blockquote>
<p><strong>本文主要内容概览：</strong></p>
<p><img src="https://pic1.zhimg.com/v2-f6a9520c6db0ba77ad620800cb36c054_b.jpg" alt="img" style="zoom: 67%;"></p>
<h3><span id="一-catboost简介"><strong>一、CatBoost简介</strong></span></h3>
<p>CatBoost是俄罗斯的搜索巨头Yandex在2017年开源的机器学习库，是Boosting族算法的一种。CatBoost和XGBoost、LightGBM并称为GBDT的三大主流神器，都是在GBDT算法框架下的一种改进实现。XGBoost被广泛的应用于工业界，LightGBM有效的提升了GBDT的计算效率，而Yandex的CatBoost号称是比XGBoost和LightGBM在算法准确率等方面表现更为优秀的算法。</p>
<p>CatBoost是一种基于对称决策树（oblivious
trees）为基学习器实现的参数较少、支持类别型变量和高准确性的GBDT框架，主要解决的痛点是高效合理地处理类别型特征，这一点从它的名字中可以看出来，<strong>CatBoost是由Categorical和Boosting组成。此外，CatBoost还解决了梯度偏差（Gradient
Bias）以及预测偏移（Prediction
shift）的问题，从而减少过拟合的发生，进而提高算法的准确性和泛化能力。</strong></p>
<p><strong>与XGBoost、LightGBM相比，CatBoost的创新点有：</strong></p>
<ul>
<li><strong>嵌入了自动将类别型特征处理为数值型特征的创新算法。首先对categorical
features做一些统计，计算某个类别特征（category）出现的频率，之后加上超参数，生成新的数值型特征（numerical
features）。</strong></li>
<li><strong>Catboost还使用了组合类别特征，可以利用到特征之间的联系，这极大的丰富了特征维度</strong>。</li>
<li>采用排序提升的方法对抗训练集中的噪声点，从而避免梯度估计的偏差，进而解决预测偏移的问题。</li>
<li>采用了<strong>完全对称树作为基模型</strong>。</li>
</ul>
<h3><span id="二-类别型特征">二、<strong>类别型特征</strong></span></h3>
<p><strong>所谓类别型特征，即这类特征不是数值型特征，而是离散的集合</strong>，比如省份名（山东、山西、河北等），城市名（北京、上海、深圳等），学历（本科、硕士、博士等）。在梯度提升算法中，最常用的是将这些类别型特征转为数值型来处理，一般类别型特征会转化为一个或多个数值型特征。</p>
<p><strong>类别型特征基数比较低（low-cardinality
features）</strong>，即该特征的所有值去重后构成的集合元素个数比较少，一般利用One-hot编码方法将特征转为数值型。One-hot编码可以在数据预处理时完成，也可以在模型训练的时候完成，从训练时间的角度，后一种方法的实现更为高效，CatBoost对于基数较低的类别型特征也是采用后一种实现。</p>
<p><strong>高基数类别型特征（high cardinality
features）</strong>当中，比如
<code>user ID</code>，这种编码方式会产生大量新的特征，造成维度灾难。一种折中的办法是可以将类别分组成有限个的群体再进行One-hot编码。<strong>一种常被使用的方法是根据目标变量统计（Target
Statistics，以下简称TS）进行分组</strong>，目标变量统计用于估算每个类别的目标变量期望值。甚至有人直接用TS作为一个新的数值型变量来代替原来的类别型变量。<strong><font color="red">
重要的是，可以通过对TS数值型特征的阈值设置，基于对数损失、基尼系数或者均方差，得到一个对于训练集而言将类别一分为二的所有可能划分当中最优的那个。</font></strong></p>
<p>在LightGBM当中，类别型特征用每一步梯度提升时的梯度统计（Gradient
Statistics，以下简称GS）来表示。虽然为建树提供了重要的信息，但是这种方法有以下两个缺点：</p>
<ul>
<li>增加计算时间，因为需要对每一个类别型特征，在迭代的每一步，都需要对GS进行计算；</li>
<li>增加存储需求，对于一个类别型变量，需要存储每一次分离每个节点的类别；</li>
</ul>
<p><strong>为了克服这些缺点，LightGBM以损失部分信息为代价将所有的长尾类别归为一类</strong>，作者声称这样处理高基数类别型特征时比One-hot编码还是好不少。不过如果采用TS特征，那么对于每个类别只需要计算和存储一个数字。</p>
<p>因此，采用TS作为一个新的数值型特征是最有效、信息损失最小的处理类别型特征的方法。TS也被广泛应用在点击预测任务当中，这个场景当中的类别型特征有用户、地区、广告、广告发布者等。接下来我们着重讨论TS，暂时将One-hot编码和GS放一边。</p>
<h4><span id="21-目标变量统计targetstatistics">2.1 <strong>目标变量统计（Target
Statistics）</strong></span></h4>
<p><strong><font color="red">
CatBoost算法的设计初衷是为了更好的处理GBDT特征中的categorical
features</font></strong>。在处理 GBDT特征中的categorical
features的时候，最简单的方法是用 categorical feature
对应的标签的平均值来替换。在决策树中，标签平均值将作为节点分裂的标准。<strong>这种方法被称为
Greedy Target-based Statistics , 简称 Greedy
TS</strong>，用公式来表达就是： <span class="math display">\[
\hat{x}_k^i=\frac{\sum_{j=1}^n\left[x_{j, k}=x_{i, k}\right] \cdot
Y_i}{\sum_{j=1}^n\left[x_{j, k}=x_{i, k}\right]}
\]</span></p>
<p>这种方法有一个显而易见的缺陷，就是通常特征比标签包含更多的信息，<strong><font color="red">
如果强行用标签的平均值来表示特征的话，当训练数据集和测试数据集数据结构和分布不一样的时候会出条件偏移问题。</font></strong></p>
<p>一个标准的改进 Greedy
TS的方式是添加先验分布项，这样可以减少噪声和低频率类别型数据对于数据分布的影响：</p>
<p><span class="math display">\[
\hat{x}_k^i=\frac{\sum_{j=1}^{p-1}\left[x_{\sigma_{j, k}}=x_{\sigma_{p,
k}}\right] Y_{\sigma_j}+a \cdot p}{\sum_{j=1}^{p-1}\left[x_{\sigma_{j,
k}}=x_{\sigma_{p, k}}\right]+a}
\]</span></p>
<p>其中<span class="math inline">\(p\)</span>是添加的先验项， <span class="math inline">\(a\)</span>通常是大于 0
的权重系数。添加先验项是一个普遍做法，针对类别数较少的特征，它可以减少噪声数据。对于回归问题，一般情况下，先验项可取数据集label的均值。对于二分类，先验项是正例的先验概率。利用多个数据集排列也是有效的，但是，如果直接计算可能导致过拟合。CatBoost利用了一个比较新颖的计算叶子节点值的方法，这种方式(oblivious
trees，对称树)可以避免多个数据集排列中直接计算会出现过拟合的问题。</p>
<p>当然，在论文《CatBoost: unbiased boosting with categorical
features》中，还提到了其它几种改进Greedy TS的方法，分别有：Holdout
TS、Leave-one-out TS、Ordered
TS。我这里就不再翻译论文中的这些方法了，感兴趣的同学可以自己翻看一下原论文。</p>
<h4><span id="22-特征组合">2.2 <strong>特征组合</strong></span></h4>
<p>值得注意的是几个类别型特征的任意组合都可视为新的特征。例如，在音乐推荐应用中，我们有两个类别型特征：用户ID和音乐流派。如果有些用户更喜欢摇滚乐，将用户ID和音乐流派转换为数字特征时，根据上述这些信息就会丢失。结合这两个特征就可以解决这个问题，并且可以得到一个新的强大的特征。然而，组合的数量会随着数据集中类别型特征的数量成指数增长，因此不可能在算法中考虑所有组合。为当前树构造新的<a href="https://www.zhihu.com/search?q=分割点&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22102540344%22%7D">分割点</a>时，CatBoost会采用贪婪的策略考虑组合。对于树的第一次分割，不考虑任何组合。对于下一个分割，CatBoost将当前树的所有组合、类别型特征与数据集中的所有类别型特征相结合，并将新的组合类别型特征动态地转换为数值型特征。CatBoost还通过以下方式生成数值型特征和类别型特征的组合：树中选定的所有分割点都被视为具有两个值的类别型特征，并像类别型特征一样被进行组合考虑。</p>
<h4><span id="23catboost处理categorical-features总结">2.3
<strong>CatBoost处理Categorical features总结</strong></span></h4>
<ul>
<li><strong>首先计算一些数据的statistics。计算某个category出现的频率，加上超参数，生成新的numerical
features</strong>。这一策略要求同一标签数据不能排列在一起（即先全是0之后全是1这种方式），训练之前需要打乱数据集。</li>
<li>使用数据的不同排列（实际上是4个）。在每一轮建立树之前，先扔一轮骰子，决定使用哪个排列来生成树。</li>
<li>考虑使用categorical
features的不同组合。例如颜色和种类组合起来，可以构成类似于blue
dog这样的特征。当需要组合的categorical
features变多时，CatBoost只考虑一部分<a href="https://www.zhihu.com/search?q=combinations&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22102540344%22%7D">combinations</a>。在选择第一个节点时，只考虑选择一个特征，例如A。在生成第二个节点时，考虑A和任意一个categorical
feature的组合，选择其中最好的。就这样使用贪心算法生成combinations。</li>
<li><strong>除非向gender这种维数很小的情况，不建议自己生成One-hot编码向量，最好交给算法来处理。</strong></li>
</ul>
<h3><span id="三-catboostqampa">三、CatboostQ&amp;A</span></h3>
<h4><span id="31catboost与xgboost-lightgbm的联系与区别">3.1
<strong>CatBoost与XGBoost、LightGBM的联系与区别？</strong></span></h4>
<p>（1）2014年3月XGBoost算法首次被<a href="https://www.zhihu.com/search?q=陈天奇&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22102540344%22%7D">陈天奇</a>提出，但是直到2016年才逐渐著名。2017年1月微软发布LightGBM第一个稳定版本。2017年4月Yandex开源CatBoost。自从XGBoost被提出之后，很多文章都在对其进行各种改进，CatBoost和LightGBM就是其中的两种。</p>
<p>（2）<strong>CatBoost处理类别型特征十分灵活，可直接传入类别型特征的列标识，模型会自动将其使用One-hot编码，还可通过设置
one_hot_max_size参数来限制One-hot特征向量的长度</strong>。如果不传入类别型特征的列标识，那么CatBoost会把所有列视为数值特征。对于One-hot编码超过设定的one_hot_max_size值的特征来说，CatBoost将会使用一种高效的encoding方法，与mean
encoding类似，但是会降低过拟合。处理过程如下：</p>
<ul>
<li>将输入样本集随机排序，并生成多组随机排列的情况；</li>
<li>将浮点型或属性值标记转化为整数；</li>
<li>将所有的类别型特征值结果都根据以下公式，转化为数值结果；</li>
</ul>
<p><span class="math display">\[
avg_target =\frac{\text { countInClass }+ \text { prior }}{\text {
totalCount }+1}
\]</span></p>
<p>其中 countInClass
表示在当前类别型特征值中有多少样本的标记值是1；prior
是分子的初始值，根据初始参数确定。totalCount
是在所有样本中（包含当前样本）和当前样本具有相同的类别型特征值的样本数量。</p>
<p>LighGBM 和 CatBoost
类似，也可以通过使用特征名称的输入来处理类别型特征数据，它没有对数据进行独热编码，因此速度比独热编码快得多。LighGBM
使用了一个特殊的算法来确定属性特征的分割值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_data = lgb.Dataset(data, label=label, feature_name=[<span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>], categorical_feature=[<span class="string">&#x27;c3&#x27;</span>])</span><br><span class="line"><span class="comment"># 注意，在建立适用于 LighGBM 的数据集之前，需要将类别型特征变量转化为整型变量，此算法不允许将字符串数据传给类别型变量参数。</span></span><br></pre></td></tr></table></figure>
<p>（3）XGBoost 和 CatBoost、 LighGBM 算法不同，XGBoost
本身无法处理类别型特征，而是像随机森林一样，只接受数值数据。因此在将类别型特征数据传入
XGBoost
之前，必须通过各种编码方式：例如序号编码、独热编码和二进制编码等对数据进行处理。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
  </entry>
  <entry>
    <title>集成学习（7）总结</title>
    <url>/posts/SMMBFY/</url>
    <content><![CDATA[<h2><span id="一-集成学习">一、集成学习</span></h2>
<p>常见的集成学习框架有三种：Bagging，Boosting 和
Stacking。三种集成学习框架在基学习器的产生和综合结果的方式上会有些区别，我们先做些简单的介绍。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211722979.jpg" alt="【机器学习】决策树（中）——Random Forest、Adaboost、GBDT （非常详细）" style="zoom: 67%;"></p>
<p>本文主要介绍基于集成学习的决策树，其主要通过不同学习框架生产基学习器，并综合所有基学习器的预测结果来改善单个基学习器的识别率和泛化性。</p>
<p><strong><font color="red">
模型的准确度可由偏差和方差共同决定：</font></strong> <span class="math display">\[
\text { Error }=\text { bias }^{2}+\operatorname{var}+\xi
\]</span></p>
<p><strong>模型总体期望：</strong> <span class="math display">\[
\begin{aligned}
E(F) &amp;=E\left(\sum_{i}^{m} r_{i} f_{i}\right) \\
&amp;=\sum_{i}^{m} r_{i} E\left(f_{i}\right)
\end{aligned}
\]</span> <strong>模型总体方差</strong>: <span class="math display">\[
\begin{aligned}
\operatorname{Var}(F) &amp;=\operatorname{Var}\left(\sum_{i}^{m} r_{i}
f_{i}\right) \\
&amp;=\sum_{i}^{m} \operatorname{Var}\left(r_{i} f_{i}\right)+\sum_{i
\neq j}^{m} \operatorname{Cov}\left(r_{i} f_{i}, r_{j} f_{j}\right) \\
&amp;=\sum_{i}^{m} r_{i}{ }^{2}
\operatorname{Var}\left(f_{i}\right)+\sum_{i \neq j}^{m} \rho r_{i}
r_{j} \sqrt{\operatorname{Var}\left(f_{i}\right)}
\sqrt{\operatorname{Var}\left(f_{j}\right)} \\
&amp;=m r^{2} \sigma^{2}+m(m-1) \rho r^{2} \sigma^{2} \\
&amp;=m r^{2} \sigma^{2}(1-\rho)+m^{2} r^{2} \sigma^{2} \rho
\end{aligned}
\]</span></p>
<table>
<colgroup>
<col style="width: 4%">
<col style="width: 31%">
<col style="width: 31%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>集成学习</th>
<th>Bagging</th>
<th>Boosting</th>
<th>Stacking</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>思想</td>
<td>对训练集进行<strong>有放回抽样</strong>得到子训练集</td>
<td>基模型的训练是有<strong>顺序</strong>的，每个基模型都会在前一个基模型学习的基础上进行学习；基于贪心策略的前向加法</td>
<td><strong>预测值</strong>将作为训练样本的特征值，进行训练得到最终预测结果。</td>
</tr>
<tr class="even">
<td>样本抽样</td>
<td>有放回地抽取数据集</td>
<td>训练集不变</td>
<td></td>
</tr>
<tr class="odd">
<td>样本权重</td>
<td>样本权重相等</td>
<td>不断调整样本的权重</td>
<td></td>
</tr>
<tr class="even">
<td>优化目标</td>
<td>减小的是方差</td>
<td>减小的是偏差</td>
<td></td>
</tr>
<tr class="odd">
<td>基模型</td>
<td><strong>强模型（偏差低，方差高）</strong></td>
<td><strong>弱模型（偏差高，方差低）</strong>而整体模型的偏差由基模型累加而成，故基模型需要为弱模型。</td>
<td><strong>强模型（偏差低，方差高）</strong></td>
</tr>
<tr class="even">
<td>相关性</td>
<td></td>
<td>对于 Boosting
来说，由于基模型共用同一套训练集，所以基模型间具有强相关性，故模型间的相关系数近似等于
1</td>
<td></td>
</tr>
<tr class="odd">
<td>模型偏差</td>
<td><strong>整体模型的偏差与基模型近似</strong>。(<span class="math inline">\(\mu\)</span>)</td>
<td>基于贪心策略的前向加法，随着基模型数的增多，偏差减少。</td>
<td></td>
</tr>
<tr class="even">
<td>模型方差</td>
<td>随着<strong>模型的增加可以降低整体模型的方差</strong>，故其基模型需要为强模型；(<span class="math inline">\(\frac{\sigma^{2}(1-\rho)}{m}+\sigma^{2}
\rho\)</span>)</td>
<td><strong>整体模型的方差与基模型近似</strong>（<span class="math inline">\(\sigma^{2}\)</span>）</td>
<td></td>
</tr>
</tbody>
</table>
<h4><span id="11-bagging">1.1 Bagging</span></h4>
<p>Bagging 全称叫 <strong>Bootstrap
aggregating</strong>，，每个基学习器都会对训练集进行<strong>有放回抽样</strong>得到子训练集，比较著名的采样法为
0.632
自助法（<strong>Bootstrap</strong>）。每个基学习器基于不同子训练集进行训练，并综合所有基学习器的预测值得到最终的预测结果。Bagging
常用的综合方法是<strong>投票法</strong>，票数最多的类别为预测类别。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211727148.jpg" alt="img" style="zoom: 50%;"></p>
<h4><span id="12-boosting">1.2 Boosting</span></h4>
<p><strong>Boosting
训练过程为阶梯状，基模型的训练是有顺序的，每个基模型都会在前一个基模型学习的基础上进行学习，最终综合所有基模型的预测值产生最终的预测结果</strong>，用的比较多的综合方式为加权法。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211727241.jpg" alt="img" style="zoom: 33%;"></p>
<h4><span id="13-stacking">1.3 Stacking</span></h4>
<p><strong>Stacking
是先用全部数据训练好基模型，然后每个基模型都对每个训练样本进行的预测，其预测值将作为训练样本的特征值，最终会得到新的训练样本，然后基于新的训练样本进行训练得到模型，然后得到最终预测结果。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211728902.jpg" alt="img" style="zoom: 33%;"></p>
<p><font color="red">
那么，为什么集成学习会好于单个学习器呢？原因可能有三：</font></p>
<ul>
<li><p>训练样本可能无法选择出最好的单个学习器，由于没法选择出最好的学习器，所以干脆结合起来一起用；</p></li>
<li><p>假设能找到最好的学习器，但由于算法运算的限制无法找到最优解，只能找到次优解，采用集成学习可以弥补算法的不足；</p></li>
<li><p>可能算法无法得到最优解，而集成学习能够得到近似解。比如说最优解是一条对角线，而单个决策树得到的结果只能是平行于坐标轴的，但是集成学习可以去拟合这条对角线。</p></li>
</ul>
<h4><span id="14stacking-vs-神经网络"><font color="red"> <strong>1.4
Stacking</strong> vs <strong>神经网络</strong></font></span></h4>
<blockquote>
<ul>
<li>https://zhuanlan.zhihu.com/p/32896968</li>
</ul>
<p><strong>本文的核心观点是提供一种对于stacking的理解，即与神经网络对照来看。</strong>当然，在<a href="https://www.zhihu.com/question/59769987/answer/269367049">阿萨姆：为什么做stacking之后，准确率反而降低了？</a>中我已经说过stacking不是万能药，但往往很有效。通过与神经网络的对比，读者可以从另一个角度加深对stacking的理解。</p>
</blockquote>
<h5><span id="141stacking是一种表示学习representation-learning">1.4.1
Stacking是一种表示学习(representation learning)</span></h5>
<p><strong>表示学习指的是模型从原始数据中自动抽取有效特征的过程</strong>，比如深度学习就是一种表示学习的方法。关于表示学习的理解可以参考：<a href="https://www.zhihu.com/question/264417928/answer/283087276">阿萨姆：人工智能（AI）是如何处理数据的？</a></p>
<p>原始数据可能是杂乱无规律的。在stacking中，通过第一层的多个学习器后，有效的特征被学习出来了。从这个角度来看，stacking的第一层就是特征抽取的过程。在[1]的研究中，上排是未经stacking的数据，下排是经过stacking(多个无监督学习算法)处理后的数据，我们显著的发现红色和蓝色的数据在下排中分界更为明显。<strong>数据经过了压缩处理。这个小例子说明了，有效的stacking可以对原始数据中的特征有效的抽取</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211729620.jpg" alt="img" style="zoom: 50%;"></p>
<h5><span id="142stacking和神经网络从某种角度看有异曲同工之妙神经网络也可以被看作是集成学习">1.4.2
<strong>Stacking和神经网络从某种角度看有异曲同工之妙，神经网络也可以被看作是集成学习</strong></span></h5>
<p>承接上一点，stacking的学习能力主要来自于对于特征的表示学习，这和神经网络的思路是一致的。这也是为什么我说“第一层”，“最后一层”。</p>
<p>而且神经网络也可以被看做是一种集成学习，主要取决于不同神经元、层对于不同特征的理解不同。从浅层到深层可以理解为一种从具体到抽象的过程。</p>
<p><strong>Stacking中的第一层可以等价于神经网络中的前
n-1层，而stacking中的最终分类层可以类比于神经网络中最后的输出层。</strong>不同点在于，<strong>stacking中不同的分类器通过异质来体现对于不同特征的表示</strong>，神经网络是从同质到异质的过程且有分布式表示的特点(distributed
representation)。Stacking中应该也有分布式的特点，主要表现在多个分类器的结果并非完全不同，而有很大程度的相同之处。</p>
<p>但同时这也提出了一个挑战，多个分类器应该尽量在保证效果好的同时尽量不同，stacking集成学习框架的对于基分类器的两个要求：</p>
<ul>
<li>差异化(diversity)要大</li>
<li>准确性(accuracy)要高</li>
</ul>
<h5><span id="143-stacking的输出层为什么用逻辑回归"><strong>1.4.3 Stacking
的输出层为什么用逻辑回归？</strong></span></h5>
<blockquote>
<p><strong>表示学习的过拟合问题</strong>：</p>
<ul>
<li>仅包含学习到的特征</li>
<li>交叉验证</li>
<li>简单模型：<strong>逻辑回归</strong></li>
</ul>
</blockquote>
<p>如果你看懂了上面的两点，你应该可以理解stacking的有效性主要来自于特征抽取。<strong>而表示学习中，如影随形的问题就是过拟合，试回想深度学习中的过拟合问题。</strong></p>
<p>在[3]中，周志华教授也重申了stacking在使用中的过拟合问题。因为第二层的特征来自于对于第一层数据的学习，那么第二层数据中的特征中不该包括原始特征，<strong>以降低过拟合的风险</strong>。举例：</p>
<ul>
<li>第二层数据特征：仅包含学习到的特征</li>
<li>第二层数据特征：包含学习到的特征 + 原始特征</li>
</ul>
<p>另一个例子是，stacking中一般都用交叉验证来避免过拟合，足可见这个问题的严重性。</p>
<p>为了降低过拟合的问题，第二层分类器应该是较为简单的分类器，广义线性如逻辑回归是一个不错的选择。<strong>在特征提取的过程中，我们已经使用了复杂的非线性变换，因此在输出层不需要复杂的分类器</strong>。这一点可以对比神经网络的激活函数或者输出层，都是很简单的函数，一点原因就是不需要复杂函数并能控制复杂度。</p>
<h5><span id="144stacking是否需要多层第一层的分类器是否越多越好"><strong>1.4.4
Stacking是否需要多层？第一层的分类器是否越多越好？</strong></span></h5>
<p>通过以上分析，stacking的表示学习不是来自于多层堆叠的效果，而是<strong>来自于不同学习器对于不同特征的学习能力</strong>，并有效的结合起来。一般来看，2层对于stacking足够了。多层的stacking会面临更加复杂的过拟合问题，且收益有限。</p>
<p>第一层分类器的数量对于特征学习应该有所帮助，<strong>经验角度看越多的基分类器越好。即使有所重复和高依赖性，我们依然可以通过特征选择来处理</strong>，问题不大。</p>
<h3><span id="二-偏差与方差">二、偏差与方差</span></h3>
<p>上节介绍了集成学习的基本概念，这节我们主要介绍下如何从偏差和方差的角度来理解集成学习。</p>
<h4><span id="21-集成学习的偏差与方差">2.1 集成学习的偏差与方差</span></h4>
<p><font color="red">
偏差（Bias）描述的是预测值和真实值之差；方差（Variance）描述的是预测值作为随机变量的离散程度。</font>放一场很经典的图：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211727341.jpg" alt="img" style="zoom: 50%;"></p>
<p><strong>模型</strong>的<strong>偏差</strong>与<strong>方差</strong></p>
<ul>
<li><strong>偏差：</strong>描述样本拟合出的模型的预测结果的期望与样本真实结果的差距，要想偏差表现的好，就需要复杂化模型，增加模型的参数，但这样容易过拟合，过拟合对应上图的
High
Variance，点会很分散。低偏差对应的点都打在靶心附近，所以喵的很准，但不一定很稳；</li>
<li><strong>方差：</strong>描述样本上训练出来的模型在测试集上的表现，要想方差表现的好，需要简化模型，减少模型的复杂度，但这样容易欠拟合，欠拟合对应上图
High
Bias，点偏离中心。低方差对应就是点都打的很集中，但不一定是靶心附近，手很稳，但不一定瞄的准。</li>
</ul>
<p>我们常说集成学习中的基模型是弱模型，通常来说弱模型是偏差高（在训练集上准确度低）方差小（防止过拟合能力强）的模型，<strong>但并不是所有集成学习框架中的基模型都是弱模型</strong>。<strong>Bagging
和 Stacking 中的基模型为强模型（偏差低，方差高），而Boosting
中的基模型为弱模型（偏差高，方差低）</strong>。</p>
<h4><span id="22-bagging-的偏差与方差">2.2 Bagging 的偏差与方差</span></h4>
<ul>
<li><strong>整体模型的期望等于基模型的期望，这也就意味着整体模型的偏差和基模型的偏差近似。</strong></li>
<li><strong>整体模型的方差小于等于基模型的方差，当且仅当相关性为 1
时取等号，随着基模型数量增多，整体模型的方差减少，从而防止过拟合的能力增强，模型的准确度得到提高。</strong>但是，模型的准确度一定会无限逼近于
1
吗？并不一定，当基模型数增加到一定程度时，方差公式第一项的改变对整体方差的作用很小，防止过拟合的能力达到极限，这便是准确度的极限了。</li>
</ul>
<h4><span id="23-boosting-的偏差与方差">2.3 Boosting 的偏差与方差</span></h4>
<ul>
<li>整体模型的方差等于基模型的方差，如果基模型不是弱模型，其方差相对较大，这将导致整体模型的方差很大，即无法达到防止过拟合的效果。因此，Boosting
框架中的基模型必须为弱模型。</li>
<li>此外 Boosting
框架中采用基于贪心策略的前向加法，整体模型的期望由基模型的期望累加而成，所以随着基模型数的增多，整体模型的期望值增加，整体模型的准确度提高。</li>
</ul>
<h4><span id="24-小结">2.4 小结</span></h4>
<ul>
<li>我们可以使用<strong>模型的偏差和方差来近似描述模型的准确度</strong>；</li>
<li>对于 Bagging
来说，整体模型的偏差与基模型近似，而随着模型的增加可以降低整体模型的方差，故其基模型需要为强模型；</li>
<li>对于 Boosting
来说，整体模型的方差近似等于基模型的方差，而整体模型的偏差由基模型累加而成，故基模型需要为弱模型。</li>
</ul>
<h3><span id="三-gbdt-xgboost-lightgbm">三、GBDT、XGBoost、LIghtGBM</span></h3>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304212131924.jpg" alt="img" style="zoom: 50%;"></p>
<table style="width:100%;">
<colgroup>
<col style="width: 10%">
<col style="width: 29%">
<col style="width: 29%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th>Boosting 算法</th>
<th>GBDT</th>
<th>XGBoost</th>
<th>LightGBM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>思想</strong></td>
<td>回归树、梯度迭代、缩减;<strong>GBDT
的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于
0</strong></td>
<td><strong>二阶导数、线性分类器、正则化</strong>、缩减、<strong>列抽样、并行化</strong></td>
<td><strong>更快的训练速度和更低的内存使用</strong></td>
</tr>
<tr class="even">
<td>目标函数</td>
<td><span class="math inline">\(y-F_{k}(x)\)</span></td>
<td><span class="math inline">\(\Omega\left(f_{t}\right)=\gamma
T+\frac{1}{2} \lambda \sum_{j=1}^{T} w_{j}^{2}\)</span></td>
<td><span class="math inline">\(\Omega\left(f_{t}\right)=\gamma
T+\frac{1}{2} \lambda \sum_{j=1}^{T} w_{j}^{2}\)</span></td>
</tr>
<tr class="odd">
<td>损失函数</td>
<td>最小均方损失函数、<strong>绝对损失或者 Huber 损失函数</strong></td>
<td>【线性】最小均方损失函数、sigmod和softmax</td>
<td>-</td>
</tr>
<tr class="even">
<td>基模型</td>
<td>CART模型</td>
<td>CART模型/ 回归模型</td>
<td>-</td>
</tr>
<tr class="odd">
<td>抽样算法</td>
<td>无</td>
<td><strong>列抽样</strong>：借鉴了<strong>随机森林</strong>的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</td>
<td><strong>单边梯度抽样算法；</strong>根据样本梯度来对梯度小的这边样本进行采样，一部分大梯度和随机分布</td>
</tr>
<tr class="even">
<td><strong>切分点算法</strong></td>
<td>CART模型</td>
<td><strong>预排序</strong>、<strong>贪心算法</strong>、<strong>近似算法（</strong>加权分位数缩略图<strong>）</strong></td>
<td><strong>直方图算法</strong>：内存消耗降低，计算代价减少；（不需要记录特征到样本的索引）</td>
</tr>
<tr class="odd">
<td><strong>缺失值算法</strong></td>
<td>CART模型</td>
<td><strong>稀疏感知算法</strong>：选择增益最大的枚举项即为最优<strong>缺省方向</strong>。【<strong><font color="red">
稀疏数据优化不足</font></strong>】【<strong>gblinear 补0</strong>】</td>
<td><strong>互斥特征捆绑算法</strong>：<strong>互斥</strong>指的是一些特征很少同时出现非0值。<strong>稀疏感知算法</strong>；【<strong>gblinear
补0</strong>】</td>
</tr>
<tr class="even">
<td><strong>建树策略</strong></td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Leaf-wise</strong>：每次分裂增益最大的叶子节点，直到达到停止条件。</td>
</tr>
<tr class="odd">
<td><strong>正则化</strong></td>
<td>无</td>
<td>L1 和 L2 正则化项</td>
<td>L1 和 L2 正则化项</td>
</tr>
<tr class="even">
<td><strong>Shrinkage（缩减）</strong></td>
<td>有</td>
<td>有</td>
<td>有</td>
</tr>
<tr class="odd">
<td>类别特征优化</td>
<td>无</td>
<td>无</td>
<td><strong>类别特征最优分割</strong>：<strong>many-vs-many</strong></td>
</tr>
<tr class="even">
<td>并行化设计</td>
<td>无</td>
<td><strong>块结构设计</strong>、</td>
<td><strong>特征并行</strong>、
<strong>数据并行</strong>、<strong>投票并行</strong></td>
</tr>
<tr class="odd">
<td><strong>缓存优化</strong></td>
<td>无</td>
<td>为每个线程分配一个连续的缓存区、<strong>“核外”块计算</strong></td>
<td>1、所有的特征都采用相同的方法获得梯度；2、其次，因为不需要存储特征到样本的索引，降低了存储消耗</td>
</tr>
<tr class="even">
<td><strong>缺点</strong></td>
<td>对异常点敏感；</td>
<td><strong>预排序</strong>：仍需要遍历数据集；<font color="red">
不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引，相当于消耗了两倍的内存。</font></td>
<td><strong>内存更小</strong>： 索引值、特征值边bin、互斥特征捆绑;
<strong>速度更快</strong>：遍历直方图；单边梯度算法过滤掉梯度小的样本；基于
Leaf-wise
算法的增长策略构建树，减少了很多不必要的计算量；特征并行、数据并行方法加速计算</td>
</tr>
</tbody>
</table>
<h3><span id="四-集成学习qampa">四、集成学习Q&amp;A</span></h3>
<h4><span id="41为什么gbdt和随机森林稍好点都不太适用直接用高维稀疏特征训练集"><strong><font color="red"> 4.1
为什么gbdt和随机森林(稍好点)都不太适用直接用高维稀疏特征训练集？</font></strong></span></h4>
<h5><span id="原因">原因：</span></h5>
<p>gbdt这类boosting或者rf这些bagging集成分类器模型的算法，是典型的贪心算法，在当前节点总是选择对当前数据集来说最好的选择</p>
<p>一个6层100树的模型，要迭代2^(5 4 3 2 1
0)*100次<strong>,每次都根据当前节点最大熵或者最小误差分割来选择变量</strong></p>
<p><strong>那么，高维稀疏数据集里很多“小而美”的数据就被丢弃了</strong>，因为它对当前节点来说不是最佳分割方案(比如，关联分析里，支持度很低置信度很高的特征)</p>
<p>但是高维数据集里面，对特定的样本数据是有很强预测能力的，比如你买叶酸，买某些小的孕妇用品品类，对应这些人6个月后买奶粉概率高达40%，但叶酸和孕妇用品销量太小了，用户量全网万分之一都不到，这种特征肯定是被树算法舍弃的，哪怕这些特征很多很多。。它仍是被冷落的份。。。</p>
<h5><span id="方法lightgbm-互斥捆绑算法">方法：【LightGBM 互斥捆绑算法】</span></h5>
<h5><span id="选择svm和lr这种能提供最佳分割平面的算法可能会更好">选择svm和lr这种能提供最佳分割平面的算法可能会更好；</span></h5>
<p>但如果top.特征已经能够贡献很大的信息量了，比如刚才孕妇的案例，你用了一个孕妇用品一级类目的浏览次数购买金额购买次数这样的更大更强的特征包含了这些高维特征的信息量，那可能gbdt会更好</p>
<p>实际情况的数据集是，在数据仓库里的清洗阶段，你可以选择把它做成高维的特征，也可以选择用算法把它做成低维的特征，一般有</p>
<p>1-在数据清洗阶段，或用类目升级(三级类目升级到二三级类目)范围升级的方式来做特征，避免直接清洗出来高维特征</p>
<p>2-在特征生成后，<strong>利用数据分析结论简单直接的用多个高维特征合并</strong>(<a href="https://www.zhihu.com/search?q=加减乘除&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A574865175%7D">加减乘除</a>逻辑判断都行，随你合并打分)的方式来做特征，前提你hold得住工作量判断量，但这个如果业务洞察力强效果有可能特别好</p>
<p>3-在特征工程的特征处理阶段，我们可以用<strong>PCA因子构建等降维算法做特征整合</strong>，对应训练集，也这么搞，到时候回归或预测的时候，就用这个因子或者主成分的值来做特征</p>
<h4><span id="41为什么集成学习的基分类器通常是决策树还有什么">4.1
为什么集成学习的基分类器通常是决策树？还有什么？</span></h4>
<p>基分类器通常是决策树：样本权重、方便调节、随机性；</p>
<ul>
<li><strong>决策树可以较方便地将样本权重整合到训练过程中，而不需要通过过采样来调整样本权重。</strong></li>
<li>树的表达能力和泛化能力，<strong>方便调节</strong>（可以通过树的层数来调节）</li>
<li>样本的扰动对决策树的影响较大，<strong><font color="red">
因此不同子样本集合生成的决策树基分类器随机性较大。这样的不稳定的分类器更适合作为基分类器。</font></strong>此外树节点分类时随机选择一个特征子集，从中找出最优分裂属性，很好地引入了随机性。</li>
</ul>
<h4><span id="42可以将随机森林的基分类器由决策树替换成线性分类器或k-nn吗">4.2
可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？</span></h4>
<p>Bagging主要好处是集成后的方差，比基分类器小。bagging采用的基分类，最好是本身对样本分布较为敏感。而线性分类器和K-NN都是较为稳定的分类器（参数模型？）甚至可能因为采样，而导致他们再训练中更难收敛，从而增大了集成分类器的偏差。</p>
<h4><span id="43为什么可以利用gbdt算法实现特征组合和筛选gbdtlr"><strong><font color="red"> 4.3
为什么可以利用GBDT算法实现特征组合和筛选？【GBDT+LR】</font></strong></span></h4>
<p>GBDT模型是有一组有序的树模型组合起来的，前面的树是由对大多数样本有明显区分度的特征分裂构建而成，经过前面的树，仍然存在少数残差较大的样本，后面的树主要由能对这些少数样本有区分度的特征分裂构建。优先选择对整体有区分度的特征，然后再选择对少数样本有区分度的特征，这样才更加合理，所以<strong>GBDT子树节点分裂是一个特征选择的过程，而子树的多层结构则对特征组合的过程，最终实现特征的组合和筛选。</strong></p>
<p><strong>GBDT+LR融合方案：</strong></p>
<p>（1）利用GBDT模型训练数据，最终得到一系列弱分类器的cart树。</p>
<p>（2）<strong>生成新的训练数据。将原训练数据重新输入GBDT模型，对于每一个样本，都会经过模型的一系列树，对于每棵树，将样本落到的叶子节点置为1，其他叶子为0，然后将叶子节点的数字从左至右的拼接起来，形成该棵树的特征向量，最后将所有树的特征向量拼接起来，形成新的数据特征，之后保留原样本标签形成新的训练数据。</strong></p>
<p>（3）将上一步得到的训练数据作为输入数据输入到LR模型中进行训练</p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><p><font color="red"> 【机器学习】决策树（中）——Random
Forest、Adaboost、GBDT
（非常详细）</font>:https://zhuanlan.zhihu.com/p/86263786</p></li>
<li><p>https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble</p></li>
<li><p>机器学习算法中GBDT与Adaboost的区别与联系是什么？ -
Frankenstein的回答 - 知乎
https://www.zhihu.com/question/54626685/answer/140610056</p></li>
<li><p>GBDT学习笔记 - 许辙的文章 - 知乎
https://zhuanlan.zhihu.com/p/169382376</p></li>
<li><p>GBDT - 王多鱼的文章 - 知乎
https://zhuanlan.zhihu.com/p/38057220</p></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
      <tags>
        <tag>决策树</tag>
        <tag>集成学习</tag>
        <tag>Adaboost</tag>
        <tag>Random Forest</tag>
        <tag>GBDT</tag>
      </tags>
  </entry>
  <entry>
    <title>降维（1）PCA</title>
    <url>/posts/3BS4T2Z/</url>
    <content><![CDATA[<p>数据降维算法: https://www.zhihu.com/column/c_1194552337170214912</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221528241.jpg" alt="【机器学习】降维——PCA（非常详细）" style="zoom: 50%;"></p>
<h2><span id="一-pca">一、 PCA</span></h2>
<p><strong><font color="red"> 降维问题的优化目标：将一组 <span class="math inline">\(\mathrm{N}\)</span> 维向量降为 <span class="math inline">\(\mathrm{K}\)</span> 维，其目标是选择 <span class="math inline">\(\mathrm{K}\)</span>
个单位正交基，使得原始数据变换到这组基上 后，各变量两两间协方差为 0
，而变量方差则尽可能大（在正交的约束下，取最大的 <span class="math inline">\(\mathrm{K}\)</span> 个方差）。</font></strong></p>
<p>要找的 <span class="math inline">\(\mathbf{P}\)</span>
是能让<strong>原始协方差矩阵对角化</strong>的 <span class="math inline">\(\mathbf{P}\)</span> 。换句话说,
优化目标变成了寻找一个矩阵 <span class="math inline">\(\mathbf{P}\)</span>, <strong>满足 <span class="math inline">\(P C P^T\)</span> 是一个对
角矩阵，并且对角元素按从大到小依次排列，那么 <span class="math inline">\(P\)</span> 的前 <span class="math inline">\(K\)</span> 行就是要寻找的基，用 <span class="math inline">\(P\)</span> 的前 <span class="math inline">\(K\)</span> 行组成的矩阵乘以 <span class="math inline">\(X\)</span> 就使得 X 从 N 维降到了 K
维并满足上述优化条件。</strong></p>
<p><strong>PCA (Principal Component Analysis) 是一种常见的数据分析方式,
常用于高维数据的降维，可用于提取数 据的主要特征分量。</strong>PCA
的数学推导可以从<strong>最大可分型</strong>和<strong>最近重构性</strong>两方面进行,
前者的优化条件为划分后方差 最大,
后者的优化条件为点到划分平面距离最小，这里我将从最大可分性的角度进行证明。</p>
<h3><span id="1-向量表示与基变换">1. 向量表示与基变换</span></h3>
<p>我们先来介绍些线性代数的基本知识。</p>
<h4><span id="111-内积">1.1.1 内积</span></h4>
<p><strong>两个向量的 A 和 B 内积</strong>我们知道形式是这样的： <span class="math display">\[
\left(a_1, a_2, \cdots, a_n\right) \cdot\left(b_1, b_2, \cdots,
b_n\right)^{\top}=a_1 b_1+a_2 b_2+\cdots+a_n b_n
\]</span>
内积运算将两个向量映射为实数，其计算方式非常容易理解，但我们无法看出其物理含义。接下来我们从几何角度
来分析，为了简单起见，我们假设 <span class="math inline">\(A\)</span> 和
<span class="math inline">\(B\)</span> 均为二维向量，则： <span class="math display">\[
A=\left(x_1, y_1\right), \quad B=\left(x_2, y_2\right) A \cdot B=|A||B|
\cos (\alpha)
\]</span> 其几何表示见下图：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221530907.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>我们看出 <span class="math inline">\(A\)</span> 与 <span class="math inline">\(B\)</span> 的内积等于 <span class="math inline">\(A\)</span> 到 <span class="math inline">\(B\)</span> 的投影长度乘以 <span class="math inline">\(B\)</span> 的模。</p>
<p>如果假设 <span class="math inline">\(\mathrm{B}\)</span> 的模为 1 ，
即让 <span class="math inline">\(|B|=1\)</span> ，那么就变成了: <span class="math display">\[
A \cdot B=|A| \cos (a)
\]</span> 也就是说, <strong>A 与 <span class="math inline">\(B\)</span>
的内积值等于 A 向 <span class="math inline">\(B\)</span>
所在直线投影的标量大小。</strong></p>
<h4><span id="12-基">1.2 基</span></h4>
<p>在我们常说的坐标系种, 向量 <span class="math inline">\((3,2)\)</span>
其实隐式引入了一个定义：以 <span class="math inline">\(x\)</span> 轴和
<span class="math inline">\(y\)</span> 轴上正方向长度为 1
的向量为标准。向 量 <span class="math inline">\((3,2)\)</span>
实际是说在 <span class="math inline">\(x\)</span> 轴投影为 3 而 <span class="math inline">\(y\)</span> 轴的投影为 2。注意投影是一个标量,
所以可以为负。</p>
<p>所以, 对于向量 <span class="math inline">\((3,2)\)</span> 来说,
如果我们想求它在 <span class="math inline">\((1,0),(0,1)\)</span>
这组基下的坐标的话, 分别内积即可。当然, 内积完 了还是 <span class="math inline">\((3,2)\)</span> 。</p>
<p>所以, 我们大致可以得到一个结论, 我们<strong>要准确描述向量,
首先要确定一组基, 然后给出在基所在的各个直线上的 投影值,
就可以了</strong>。为了方便求坐标, 我们希望这组基向量模长为
1。因为向量的内积运算, 当模长为 1 时, 内积
可以直接表示投影。然后还需要这组基是线性无关的, 我们一般用正交基,
非正交的基也是可以的, 不过正交基有 较好的性质。</p>
<h4><span id="13-基变换的矩阵表示">1.3 基变换的矩阵表示</span></h4>
<p>这里我们先做一个练习：对于向量 <span class="math inline">\((3,2)\)</span> 这个点来说, 在 <span class="math inline">\(\left(\frac{1}{\sqrt{2}},
\frac{1}{\sqrt{2}}\right)\)</span> 和 <span class="math inline">\(\left(-\frac{1}{\sqrt{2}},
\frac{1}{\sqrt{2}}\right)\)</span> 这组基下的坐标是多少? 我们拿 <span class="math inline">\((3,2)\)</span> 分别与之内积, 得到 <span class="math inline">\(\left(\frac{5}{\sqrt{2}},-\frac{1}{\sqrt{2}}\right)\)</span>
这个新坐标。</p>
<p>我们可以用矩阵相乘的形式简洁的表示这个变换： <span class="math display">\[
\left(\begin{array}{cc}
1 / \sqrt{2} &amp; 1 / \sqrt{2} \\
-1 / \sqrt{2} &amp; 1 / \sqrt{2}
\end{array}\right)\left(\begin{array}{l}
3 \\
2
\end{array}\right)=\left(\begin{array}{c}
5 / \sqrt{2} \\
-1 / \sqrt{2}
\end{array}\right)
\]</span> 左边矩阵的两行分别为两个基, 乘以原向量,
其结果刚好为新基的坐标。推广一下, 如果我们有 <span class="math inline">\(m\)</span> 个二维向量,
只要将二维向量按列排成一个两行 <span class="math inline">\(m\)</span>
列矩阵, 然后用“基矩阵”乘以这个矩阵就可以得到了所有这些向量在新基下
的值。例如对于数据点 <span class="math inline">\((1,1),(2,2),(3,3)\)</span> 来说,
想变换到刚才那组基上, 则可以这样表示: <span class="math display">\[
\left(\begin{array}{cc}
1 / \sqrt{2} &amp; 1 / \sqrt{2} \\
-1 / \sqrt{2} &amp; 1 / \sqrt{2}
\end{array}\right)\left(\begin{array}{lll}
1 &amp; 2 &amp; 3 \\
1 &amp; 2 &amp; 3
\end{array}\right)=\left(\begin{array}{ccc}
2 / \sqrt{2} &amp; 4 / \sqrt{2} &amp; 6 / \sqrt{2} \\
0 &amp; 0 &amp; 0
\end{array}\right)
\]</span> 我们可以把它写成通用的表示形式： <span class="math display">\[
\left(\begin{array}{c}
p_1 \\
p_2 \\
\vdots \\
p_R
\end{array}\right)\left(\begin{array}{llll}
a_1 &amp; a_2 &amp; \cdots &amp; a_M
\end{array}\right)=\left(\begin{array}{cccc}
p_1 a_1 &amp; p_1 a_2 &amp; \cdots &amp; p_1 a_M \\
p_2 a_1 &amp; p_2 a_2 &amp; \cdots &amp; p_2 a_M \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
p_R a_1 &amp; p_R a_2 &amp; \cdots &amp; p_R a_M
\end{array}\right)
\]</span> 其中 <span class="math inline">\(p_i\)</span> 是一个行向量,
表示第 <span class="math inline">\(\mathrm{i}\)</span> 个基, <span class="math inline">\(a_j\)</span> 是一个列向量, 表示第 <span class="math inline">\(\mathrm{j}\)</span>
个原始数据记录。实际上也就是做了一个向 量矩阵化的操作。</p>
<p><font color="red"> 上述分析给矩阵相乘找到了一种物理解释:
两个矩阵相乘的意义是将右边矩阵中的每一列向量 <span class="math inline">\(a_i\)</span> 变换到左边矩阵
中以每一行行向量为基所表示的空间中去。也就是说一个矩阵可以表示一种线性变换。</font></p>
<h3><span id="2-最大可分性">2. 最大可分性</span></h3>
<p>上面我们讨论了选择不同的基可以对同样一组数据给出不同的表示,
<strong>如果基的数量少于向量本身的维数, 则可以达
到降维的效果。</strong></p>
<p><strong>但是我们还没回答一个最关键的问题:
如何选择基才是最优的。或者说, 如果我们有一组 <span class="math inline">\(\mathbf{N}\)</span> 维向量, 现在要将其 降到 K
维（K 小于 N），那么我们应该如何选择 <span class="math inline">\(\mathrm{K}\)</span>
个基才能最大程度保留原有的信息？</strong></p>
<p>一种直观的看法是： <font color="red"> 希望投影后的投影值尽可能分散,
因为如果重叠就会有样本消失。当然这个也可以从樀的角
度进行理解，樀越大所含信息越多。</font></p>
<h4><span id="21-方差">2.1 方差</span></h4>
<p>我们知道数值的分散程度,
可以用数学上的方差来表述。<strong>一个变量的方差可以看做是每个元素与变量均值的差的平
方和的均值</strong>, 即: <span class="math display">\[
\operatorname{Var}(a)=\frac{1}{m} \sum_{i=1}^m\left(a_i-\mu\right)^2
\]</span> <strong>为了方便处理，我们将每个变量的均值都化为 0</strong> ,
因此方差可以直接用每个元素的平方和除以元素个数表示: <span class="math display">\[
\operatorname{Var}(a)=\frac{1}{m} \sum_{i=1}^m a_i^2
\]</span>
于是上面的问题被形式化表述为：<strong>寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，方差值最大</strong>。</p>
<h4><span id="22-协方差">2.2 协方差</span></h4>
<p>在一维空间中我们可以用方差来表示数据的分散程度。而对于高维数据，我们用协方差进行约束，<strong>协方差可以表示两个变量的相关性</strong>。<strong><font color="red">
为了让两个变量尽可能表示更多的原始信息，我们希望它们之间不存在线性相关性</font></strong>，因为相关性意味着两个变量不是完全独立，必然存在重复表示的信息。</p>
<p>协方差公式为：</p>
<p><span class="math display">\[
\operatorname{Cov}(a, b)=\frac{1}{m-1}
\sum_{i=1}^m\left(a_i-\mu_a\right)\left(b_i-\mu_b\right)
\]</span></p>
<p>由于均值为 0，所以我们的协方差公式可以表示为：</p>
<p><span class="math display">\[
\operatorname{Cov}(a, b)=\frac{1}{m} \sum_{i=1}^m a_i b_i
\]</span> 当样本数较大时，不必在意其是 m 还是
m-1，为了方便计算，我们分母取 m。</p>
<p><strong><font color="red"> 协方差为 0
时，表示两个变量完全不相关</font></strong>。为了让协方差为
0，我们选择第二个基时只能在与第一个基正交的方向上进行选择，因此最终选择的两个方向一定是正交的。</p>
<p>（<strong>补充</strong>：协方差为 0
时，两个变量只是线性不相关。完全独立是有问题的，才疏学浅，还望见谅。）</p>
<p><strong><font color="red"> 至此，我们得到了降维问题的优化目标：将一组
N 维向量降为 K 维，其目标是选择 K
个单位正交基，使得原始数据变换到这组基上后，各变量两两间协方差为
0，而变量方差则尽可能大（在正交的约束下，取最大的 K
个方差）。</font></strong></p>
<h4><span id="23-协方差矩阵">2.3 协方差矩阵</span></h4>
<p>针对我们给出的优化目标，接下来我们将从数学的角度来给出优化目标。我们看到，最终要达到的目的与<strong>变量内方差及变量间协方差</strong>有密切关系。因此我们希望能将两者统一表示，仔细观察发现，两者均可以表示为内积的形式，而内积又与矩阵相乘密切相关。于是我们有：</p>
<p>假设我们只有 <span class="math inline">\(\mathrm{a}\)</span> 和 <span class="math inline">\(\mathrm{b}\)</span> 两个变量,
那么我们将它们按行组成矩阵 <span class="math inline">\(\mathrm{X}\)</span> : <span class="math display">\[
X=\left(\begin{array}{cccc}
a_1 &amp; a_2 &amp; \cdots &amp; a_m \\
b_1 &amp; b_2 &amp; \cdots &amp; b_m
\end{array}\right)
\]</span> 然后: <span class="math display">\[
\frac{1}{m} X X^{\top}=\left(\begin{array}{cc}
\frac{1}{m} \sum_{i=1}^m a_i^2 &amp; \frac{1}{m} \sum_{i=1}^m a_i b_i \\
\frac{1}{m} \sum_{i=1}^m a_i b_i &amp; \frac{1}{m} \sum_{i=1}^m b_i^2
\end{array}\right)=\left(\begin{array}{cc}
\operatorname{Cov}(a, a) &amp; \operatorname{Cov}(a, b) \\
\operatorname{Cov}(b, a) &amp; \operatorname{Cov}(b, b)
\end{array}\right)
\]</span> 我们可以看到这个矩阵对角线上的分别是两个变量的方差,
而其它元素是 <span class="math inline">\(a\)</span> 和 <span class="math inline">\(b\)</span> 的协方差。两者被统一到了一个
矩阵里。</p>
<p>设我们有 <span class="math inline">\(\mathrm{m}\)</span> 个 <span class="math inline">\(\mathrm{n}\)</span> 维数据记录, 将其排列成矩阵
<span class="math inline">\(X_{n, m}\)</span>, 设 <span class="math inline">\(C=\frac{1}{m} X X^T\)</span>, 则 <span class="math inline">\(\mathrm{C}\)</span> 是一个对称矩阵, 其对角线分别
对应各个变量的方差, 而第 <span class="math inline">\(\mathrm{i}\)</span>
行 <span class="math inline">\(\mathrm{j}\)</span> 列和 <span class="math inline">\(\mathrm{j}\)</span> 行 <span class="math inline">\(\mathrm{i}\)</span> 列元素相同, 表示 <span class="math inline">\(\mathrm{i}\)</span> 和 <span class="math inline">\(\mathrm{j}\)</span> 两个变量的协方差。</p>
<h4><span id="24-矩阵对角化">2.4 矩阵对角化</span></h4>
<p>根据我们的优化条件，<strong>我们需要将除对角线外的其它元素化为
0，并且在对角线上将元素按大小从上到下排列（变量方差尽可能大）</strong>，这样我们就达到了优化目的。这样说可能还不是很明晰，我们进一步看下原矩阵与基变换后矩阵协方差矩阵的关系。</p>
<p>设原始数据矩阵 <span class="math inline">\(X\)</span>
对应的协方差矩阵为 <span class="math inline">\(C\)</span>, 而 <span class="math inline">\(P\)</span> 是一组基按行组成的矩阵, 设 <span class="math inline">\(Y=P X\)</span>, 则 <span class="math inline">\(Y\)</span> 为 <span class="math inline">\(X\)</span> 对 <span class="math inline">\(P\)</span> 做基变换后的 数据。设 <span class="math inline">\(Y\)</span> 的协方差矩阵为 <span class="math inline">\(D\)</span>, 我们推导一下 <span class="math inline">\(D\)</span> 与 <span class="math inline">\(C\)</span> 的关系: <span class="math display">\[
\begin{aligned}
D &amp; =\frac{1}{m} Y Y^T \\
&amp; =\frac{1}{m}(P X)(P X)^T \\
&amp; =\frac{1}{m} P X X^T P^T \\
&amp; =P\left(\frac{1}{m} X X^T\right) P^T \\
&amp; =P C P^T
\end{aligned}
\]</span> 这样我们就看清楚了, 我们要找的 <span class="math inline">\(\mathrm{P}\)</span> 是能让原始协方差矩阵对角化的
<span class="math inline">\(\mathrm{P}\)</span> 。换句话说,
优化目标变成了<strong>寻找一个矩 阵 <span class="math inline">\(\mathbf{P}\)</span>, 满足 <span class="math inline">\(P C P^T\)</span>
是一个对角矩阵，并且对角元素按从大到小依次排列，那么 <span class="math inline">\(\mathbf{P}\)</span> 的前 <span class="math inline">\(\mathbf{K}\)</span> 行就是要寻找的基, 用 <span class="math inline">\(\mathbf{P}\)</span> 的前 <span class="math inline">\(\mathrm{K}\)</span> 行组成的矩阵乘以 <span class="math inline">\(\mathrm{X}\)</span> 就使得 <span class="math inline">\(\mathrm{X}\)</span> 从 <span class="math inline">\(\mathrm{N}\)</span> 维降到了 <span class="math inline">\(\mathrm{K}\)</span>
维并满足上述优化条件。</strong></p>
<p>至此, 我们离 PCA 还有仅一步之遥, 我们还需要完成对角化。</p>
<p><strong>由上文知道，协方差矩阵 C
是一个是对称矩阵，在线性代数中实对称矩阵有一系列非常好的性质:</strong></p>
<ol type="1">
<li>实对称矩阵不同特征值对应的特征向量必然正交。</li>
<li>设特征向量 <span class="math inline">\(\lambda\)</span> 重数为 <span class="math inline">\(r\)</span>, 则必然存在 <span class="math inline">\(r\)</span> 个线性无关的特征向量对应于 <span class="math inline">\(\lambda\)</span> ，因此可以将这 <span class="math inline">\(r\)</span> 个特征向量单位正 交化。</li>
</ol>
<p>由上面两条可知, 一个 <span class="math inline">\(\mathrm{n}\)</span>
行 <span class="math inline">\(\mathrm{n}\)</span>
列的实对称矩阵一定可以找到 <span class="math inline">\(\mathrm{n}\)</span> 个单位正交特征向量, 设这 <span class="math inline">\(\mathrm{n}\)</span> 个特征向量为 <span class="math inline">\(e_1, e_2, \cdots, e_n\)</span>,
我们将其按列组成矩阵: <span class="math inline">\(E=\left(e_1, e_2,
\cdots, e_n\right)\)</span> 。</p>
<p>则对协方差矩阵 C 有如下结论: <span class="math display">\[
E^T C E=\Lambda=\left(\begin{array}{llll}
\lambda_1 &amp; &amp; &amp; \\
&amp; \lambda_2 &amp; &amp; \\
&amp; &amp; \ddots &amp; \\
&amp; &amp; &amp; \lambda_n
\end{array}\right)
\]</span> 其中 <span class="math inline">\(\Lambda\)</span> 为对角矩阵,
其对角元素为各特征向量对应的特征值（可能有重复）。到这里,
我们发现我们已经找到了 需要的矩阵 P: <span class="math inline">\(P=E^{\top}\)</span> 。</p>
<p><strong><span class="math inline">\(P\)</span>
是协方差矩阵的特征向量单位化后按行排列出的矩阵</strong>，其中每一行都是
<span class="math inline">\(C\)</span> 的一个特征向量。如果设 <span class="math inline">\(P\)</span> 按照 <span class="math inline">\(\Lambda\)</span> 中 特征值的从大到小,
将特征向量从上到下排列, 则用 <span class="math inline">\(P\)</span> 的前
<span class="math inline">\(K\)</span> 行组成的矩阵乘以原始数据矩阵
<span class="math inline">\(X\)</span>, 就得到了我们
需要的降维后的数据矩阵 <span class="math inline">\(Y\)</span> 。</p>
<blockquote>
<p><strong>拉格朗日乘子法证明</strong>:<strong>方差就是协方差矩阵的特征值</strong></p>
</blockquote>
<h4><span id="25-最近重构性-思路">2.5 最近重构性-思路</span></h4>
<p>以上的证明思路主要是基于最大可分性的思想，<strong>通过一条直线使得样本点投影到该直线上的方差最大</strong>。除此之外，我们还可以<strong>将其转换为线型回归问题，其目标是求解一个线性函数使得对应直线能够更好地拟合样本点集合</strong>。这就<strong>使得我们的优化目标从方差最大转化为平方误差最小</strong>，因为映射距离越短，丢失的信息也会越小。区别于最大可分性，这是从最近重构性的角度进行论证。</p>
<h3><span id="3-求解步骤">3. 求解步骤</span></h3>
<p><strong>总结一下 PCA 的算法步骤：设有 <span class="math inline">\(m\)</span> 条 <span class="math inline">\(n\)</span> 维数据。</strong></p>
<ol start="3" type="1">
<li>将原始数据按列组成 <span class="math inline">\(\mathbf{n}\)</span>
行 <span class="math inline">\(\mathbf{m}\)</span> 列矩阵 <span class="math inline">\(\mathbf{X}\)</span>;</li>
<li>将 <span class="math inline">\(\mathrm{X}\)</span>
的每一行进行零均值化，即减去这一行的均值；【零均值化】【方差、协方差好计算】</li>
<li>求出协方差矩阵 <span class="math inline">\(C=\frac{1}{m} X
X^{\top}\)</span>;</li>
<li>求出协方差矩阵的特征值及对应的特征向量;</li>
<li>将特征向量按对应特征值大小从上到下按行排列成矩阵，取前 <span class="math inline">\(\mathbf{k}\)</span> 行组成矩阵 <span class="math inline">\(\mathbf{P}\)</span>;</li>
<li><span class="math inline">\(Y=P X\)</span> 即为降维到 <span class="math inline">\(\mathbf{k}\)</span> 维后的数据。</li>
</ol>
<h3><span id="4性质维度灾难-降噪-过拟合-特征独立">4.
性质【维度灾难、降噪、过拟合、特征独立】</span></h3>
<ol type="1">
<li><strong>缓解维度灾难</strong>：PCA
算法通过舍去一部分信息之后能使得样本的采样密度增大（因为维数降低了），这是缓解维度灾难的重要手段；</li>
<li><strong>降噪</strong>：当数据受到噪声影响时，最小特征值对应的特征向量往往与噪声有关，将它们舍弃能在一定程度上起到降噪的效果；</li>
<li><strong>过拟合</strong>：PCA
保留了主要信息，但这个主要信息只是针对训练集的，而且这个主要信息未必是重要信息。有可能舍弃了一些看似无用的信息，但是这些看似无用的信息恰好是重要信息，只是在训练集上没有很大的表现，所以
PCA 也可能加剧了过拟合；</li>
<li><strong>特征独立</strong>：PCA
不仅将数据压缩到低维，它也使得<strong>降维之后的数据各特征相互独立</strong>；</li>
</ol>
<h3><span id="5-细节">5. 细节</span></h3>
<h4><span id="51-零均值化">5.1 零均值化</span></h4>
<p>当对训练集进行 PCA
降维时，也需要对验证集、测试集执行同样的降维。而<strong>对验证集、测试集执行零均值化操作时，均值必须从训练集计算而来</strong>，不能使用验证集或者测试集的中心向量。</p>
<p>其原因也很简单，因为我们的训练集时可观测到的数据，测试集不可观测所以不会知道其均值，而验证集再大部分情况下是在处理完数据后再从训练集中分离出来，一般不会单独处理。如果真的是单独处理了，不能独自求均值的原因是和测试集一样。</p>
<p>另外我们也需要保证一致性，我们拿训练集训练出来的模型用来预测测试集的前提假设就是两者是独立同分布的，如果不能保证一致性的话，会出现
Variance Shift 的问题。</p>
<h4><span id="52-svd-的对比">5.2 SVD 的对比</span></h4>
<p>这是两个不同的数学定义。我们先给结论：<strong>特征值和特征向量是针对方阵</strong>才有的，而<strong>对任意形状的矩阵都可以做奇异值分解</strong>。</p>
<p><strong>PCA</strong>：<strong>方阵的特征值分解</strong>，对于一个方阵
A。其中，Q 是这个矩阵 A 的特征向量组成的矩阵， <span class="math inline">\(\Lambda\)</span>
是一个对角矩阵，每一个对角线元素就是一个特征值，里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变化方向（从主要的变化到次要的变化排列)。也就是说矩阵
A 的信息可以由其特征值和特征向量表示。</p>
<p><strong>SVD：矩阵的奇异值分解其实就是对于矩阵 <span class="math inline">\(\mathrm{A}\)</span> 的协方差矩阵 <span class="math inline">\(A^T A\)</span> 和 <span class="math inline">\(A
A^T\)</span> 做特征值分解推导出来的</strong>: <span class="math display">\[
A_{m, n}=U_{m, m} \Lambda_{m, n} V_{n, n}^T \approx U_{m, k} \Lambda_{k,
k} V_{k, n}^T
\]</span> 其中: <span class="math inline">\(U，V\)</span> 都是正交矩阵,
有 <span class="math inline">\(U^T U=I_m, V^T V=I_n\)</span>
。这里的约等于是因为 <span class="math inline">\(\Lambda\)</span> 中有
<span class="math inline">\(\mathrm{n}\)</span> 个奇异值, 但是由于排在
后面的很多接近 0, 所以我们可以仅保留比较大的 <span class="math inline">\(\mathrm{k}\)</span> 个奇异值。 <span class="math display">\[
\begin{aligned}
&amp; A^T A=\left(U \Lambda V^T\right)^T U \Lambda V^T=V \Lambda^T U^T U
\Lambda V^T=V \Lambda^2 V^T \\
&amp; A A^T=U \Lambda V^T\left(U \Lambda V^T\right)^T=U \Lambda V^T V
\Lambda^T U^T=U \Lambda^2 U^T
\end{aligned}
\]</span> 所以, <span class="math inline">\(V \cup\)</span>
两个矩阵分别是 <span class="math inline">\(A^T A\)</span> 和 <span class="math inline">\(A A^T\)</span> 的特征向量,
中间的矩阵对角线的元素是 <span class="math inline">\(A^T A\)</span> 和
<span class="math inline">\(A A^T\)</span> 的特征值。我 们也很容易看出
<span class="math inline">\(\mathrm{A}\)</span> 的奇异值和 <span class="math inline">\(A^T A\)</span> 的特征值之间的关系。</p>
<p>PCA 需要对协方差矩阵 <span class="math inline">\(C=\frac{1}{m} X
X^T\)</span> 。进行特征值分解; SVD 也是对 <span class="math inline">\(A^T A\)</span> 进行特征值分解。如果取 <span class="math inline">\(A=\frac{X^T}{\sqrt{m}}\)</span>
则两者基本等价。所以 PCA 问题可以转换成 SVD 求解。</p>
<p><strong>而实际上 Sklearn 的 PCA 就是用 SVD
进行求解的</strong>，原因有以下几点：</p>
<ol type="1">
<li>当样本维度很高时，协方差矩阵计算太慢；</li>
<li>方阵特征值分解计算效率不高；</li>
<li><strong>SVD
除了特征值分解这种求解方式外，还有更高效更准确的迭代求解方式，避免了<span class="math inline">\(A^T A\)</span>的计算；</strong></li>
<li><strong>其实 PCA 与 SVD 的右奇异向量的压缩效果相同</strong>。</li>
</ol>
<h3><span id="参考链接">参考链接</span></h3>
<ol type="1">
<li>《机器学习》周志华</li>
<li><a href="https://link.zhihu.com/?target=https%3A//blog.codinglabs.org/articles/pca-tutorial.html">PCA
的数学原理</a></li>
<li><a href="https://link.zhihu.com/?target=http%3A//web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm">Singular
Value Decomposition (SVD) tutorial</a></li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.cnblogs.com/LeftNotEasy/archive/2011/01/08/lda-and-pca-machine-learning.html">机器学习中的数学（4）——线性判别分析（LDA）,
主成分分析（PCA）</a></li>
<li><a href="https://link.zhihu.com/?target=https%3A//my.oschina.net/findbill/blog/535044">从SVD到PCA——奇妙的数学游戏</a></li>
<li>scikit-learn：降维算法PCA和SVD
https://blog.csdn.net/HHG20171226/article/details/102981822</li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>降维与度量学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>降维</tag>
        <tag>PCA</tag>
      </tags>
  </entry>
  <entry>
    <title>降维（2）LDA</title>
    <url>/posts/2Y0FFGH/</url>
    <content><![CDATA[<h2><span id="一-线性判别分析lda监督">一、线性判别分析（LDA）【监督】</span></h2>
<blockquote>
<p><strong>“投影后类内方差最小，类间方差最大”</strong></p>
<ul>
<li>https://blog.csdn.net/liuweiyuxiang/article/details/78874106</li>
</ul>
</blockquote>
<h3><span id="11-概念">1.1 概念</span></h3>
<p><strong>线性判别分析（Linear Discriminant
Analysis，LDA）是一种经典的降维方法。和主成分分析PCA不考虑样本类别输出的无监督降维技术不同，LDA是一种监督学习的降维技术，数据集的每个样本有类别输出。</strong></p>
<p><strong>LDA分类思想简单总结如下：</strong></p>
<ol type="1">
<li>多维空间中，数据处理分类问题较为复杂，LDA算法将多维空间中的数据投影到一条直线上，将d维数据转化成1维数据进行处理。</li>
<li>对于训练数据，设法将多维数据投影到一条直线上，<strong>同类数据的投影点尽可能接近，异类数据点尽可能远离</strong>。</li>
<li>对数据进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定样本的类别。</li>
</ol>
<p><strong><font color="red">
如果用一句话概括LDA思想，即“投影后类内方差最小，类间方差最大”。</font></strong></p>
<p>假设有红、蓝两类数据，这些数据特征均为二维，如下图所示。我们的目标是将这些数据投影到一维，让每一类相近的数据的投影点尽可能接近，不同类别数据尽可能远，即图中红色和蓝色数据中心之间的距离尽可能大。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221634387.png" alt="image-20220526135646769"></p>
<p>从上图直观看出，右图红色数据和蓝色数据在各自的区域来说相对集中，根据数据分布直方图也可看出，所以右图的投影效果好于左图，左图中间直方图部分有明显交集。
以上例子是基于数据是二维的，分类后的投影是一条直线。如果原始数据是多维的，则投影后的分类面是一低维的超平面。</p>
<h3><span id="12-原理">1.2 原理</span></h3>
<p>LDA的原理是，将带上标签的数据（点），通过投影的方法，投影到维度更低的空间中，使得投影后的点，会形成按类别区分，一簇一簇的情况，相同类别的点，将会在投影后的空间中更接近。要说明白LDA，首先得弄明白线性分类器(<a href="http://en.wikipedia.org/wiki/Linear_classifier">Linear
Classifier</a>)：因为LDA是一种线性分类器。对于<strong>K-分类的一个分类问题，会有K个线性函数</strong>：</p>
<p><span class="math display">\[
y_k(x)=w_k^T x+w_{k 0}
\]</span></p>
<p>当满足条件：对于所有的j，都有Yk &gt;
Yj,的时候，我们就说x属于类别k。对于每一个分类，都有一个公式去算一个分值，在所有的公式得到的分值中，找一个最大的就是所属的分类了。</p>
<p>上式实际上就是一种投影，是将一个高维的点投影到一条高维的直线上，LDA最求的目标是，给出一个标注了类别的数据集，投影到了一条直线之后，能够使得点尽量的按类别区分开，当k=2即二分类问题的时候，如下图所示：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221635862.gif" alt="clip_image002" style="zoom:67%;"></p>
<p>红色的方形的点为0类的原始点、蓝色的方形点为1类的原始点，经过原点的那条线就是投影的直线，从图上可以清楚的看到，红色的点和蓝色的点被<strong>原点</strong>明显的分开了，这个数据只是随便画的，如果在高维的情况下，看起来会更好一点。下面我来推导一下二分类LDA问题的公式：假设用来区分二分类的直线（投影函数)为：
<span class="math display">\[
y_k(x)=w_k^T x+w_{k 0}
\]</span> 当满足条件：对于所有的j, 都有 <span class="math inline">\(Y
k&gt;Y j\)</span>,的时候, 我们就说 <span class="math inline">\(x\)</span> 属于类别 <span class="math inline">\(k\)</span> 。对于每一个分类, 都有一个公式去算一个
分值，在所有的公式得到的分值中, 找一个最大的就是所属的分类了。</p>
<p>上式实际上就是一种投影, 是将一个高维的点投影到一条高维的直线上,
LDA最求的目标是, 给出一个标注了类别 的数据集, 投影到了一条直线之后,
能够使得点尽量的按类别区分开, 当 <span class="math inline">\(k=2\)</span> 即二分类问题的时候, 如下图所示:</p>
<p>红色的方形的点为 0 类的原始点、蓝色的方形点为 1
类的原始点，经过原点的那条线就是投影的直线，从图上可以 清楚的看到,
红色的点和蓝色的点被原点明显的分开了, 这个数据只是随便画的,
如果在高维的情况下, 看起来会
更好一点。下面我来推导一下二分类LDA问题的公式：假设用来区分二分类的直线（投影函数)为：
<span class="math display">\[
y=w^T x
\]</span> <strong>LDA分类的一个目标是使得不同类别之间的距离越远越好,
同一类别之中的距离越近越好</strong>, 所以我们需要定义几 个关键的值。</p>
<ul>
<li><strong>类别的原始中心点为</strong>：(Di表示属于类别的点)</li>
</ul>
<p><span class="math display">\[
m_i=\frac{1}{n_i} \sum_{x \in D_i} x
\]</span></p>
<ul>
<li>类别投影后的中心点为:</li>
</ul>
<p><span class="math display">\[
\widetilde{m_i}=w^T m_i
\]</span></p>
<ul>
<li><strong>衡量类别i投影后, 类别点之间的分散程度 (方差)
为</strong>:</li>
</ul>
<p><span class="math display">\[
\tilde{s_i}=\sum_{y \in Y_i}\left(y-\tilde{m_i}\right)^2
\]</span></p>
<ul>
<li><strong>最终我们可以得到一个下面的公式,
表示LDA投影到w后的损失函数</strong>:</li>
</ul>
<p><span class="math display">\[
J(w)=\frac{\left|\widetilde{m_1}-\widetilde{m_2}\right|^2}{\widetilde{s}_1^2+\widetilde{s}_2^2}
\]</span></p>
<p>我们<strong>分类的目标是，使得类别内的点距离越近越好（集中），类别间的点越远越好。</strong>分母表示每一个类别内的方差之和，方差越大表示一个类别内的点越分散，分子为两个类别各自的中心点的距离的平方，我们最大化J(w)就可以求出最优的w了。想要求出最优的w，可以使用拉格朗日乘子法，但是现在我们得到的J(w)里面，w是不能被单独提出来的，我们就得想办法将w单独提出来。</p>
<p>我们定义一个<strong>投影前的各类别分散程度的矩阵</strong>，这个矩阵看起来有一点麻烦，其实意思是，如果某一个分类的<strong>输入点集Di里面的点距离这个分类的中心店mi越近</strong>，则Si里面元素的值就越小，如果分类的点都紧紧地围绕着mi，则Si里面的元素值越更接近0.
<span class="math display">\[
S_{i}=\sum_{x \in D_{i}}\left(x-m_{i}\right)\left(x-m_{i}\right)^{T}
\]</span> 带入 <span class="math inline">\(\mathrm{Si}\)</span>, 将
<span class="math inline">\(\mathrm{J}(\mathrm{w})\)</span>
分母化为:</p>
<p><span class="math inline">\(\tilde{s}_{i}=\sum_{x \in
D_{i}}\left(w^{T} x-w^{T} m_{i}\right)^{2}=\sum_{x \in D_{i}}
w^{T}\left(x-m_{i}\right)\left(x-m_{i}\right)^{T} w=w^{T} S_{i}
w\)</span></p>
<p><span class="math display">\[{\tilde{S_{1}}}^{2}+{\tilde{S_{2}}}^{2}=w^{T}\left(S_{1}+S_{2}\right)
w=w^{T} S_{w} w\]</span></p>
<p>同样的将 <span class="math inline">\(\mathrm{J}(\mathrm{w})\)</span>
分子化为: <span class="math display">\[
\left|\widetilde{m_{1}}-\widetilde{m_{2}}\right|^{2}=w^{T}\left(m_{1}-m_{2}\right)\left(m_{1}-m_{2}\right)^{T}
w=w^{T} S_{B} w
\]</span> 这样<strong>损失函数</strong>可以化成下面的形式: <span class="math display">\[
J(w)=\frac{w^{T} S_{B} w}{w^{T} S_{w} w}
\]</span> 这样就可以用最喜欢的<strong>拉格朗日乘子法</strong>了,
但是还有一个问题, 如果分子、分母是都可以取任意值的, 那就会 使得有无穷解,
我们将分母限制为长度为 1, 并作为拉格朗日乘子法的限制条件, 带入得到:
<span class="math display">\[
\begin{aligned}
&amp;c(w)=w^{T} S_{B} w-\lambda\left(w^{T} S_{w} w-1\right) \\
&amp;\Rightarrow \frac{d c}{d w}=2 S_{B} w-2 \lambda S_{w} w=0 \\
&amp;\Rightarrow S_{B} w=\lambda S_{w} w
\end{aligned}
\]</span> <strong>这样的式子就是一个求特征值的问题了。</strong> 对于
<span class="math inline">\(N(N&gt;2)\)</span> 分类的问题,
我就直接写出下面的结论了: <span class="math display">\[
\begin{aligned}
&amp;S_{W}=\sum_{i=1}^{c} S_{i} \\
&amp;S_{B}=\sum_{i=1}^{c}
n_{i}\left(m_{i}-m\right)\left(m_{i}-m\right)^{T} \\
&amp;S_{B} w_{i}=\lambda S_{w} w_{i}
\end{aligned}
\]</span>
这同样是一个求特征值的问题，我们求出的第i大的特征向量，就是对应的Wi了。</p>
<blockquote>
<p>这里想多谈谈特征值，特征值在纯数学、量子力学、固体力学、计算机等等领域都有广泛的应用，特征值表示的是矩阵的性质，当我们取到矩阵的前N个最大的特征值的时候，我们可以说提取到的矩阵主要的成分（这个和之后的PCA相关，但是不是完全一样的概念）。在机器学习领域，不少的地方都要用到特征值的计算，比如说图像识别、pagerank、LDA、还有之后将会提到的PCA等等。</p>
</blockquote>
<p><strong>优缺点</strong></p>
<table>
<colgroup>
<col style="width: 9%">
<col style="width: 90%">
</colgroup>
<thead>
<tr class="header">
<th>优缺点</th>
<th>简要说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>优点</td>
<td>1. 可以使用类别的先验知识； 2.
以标签、类别衡量差异性的有监督降维方式，相对于PCA的模糊性，其目的更明确，更能反映样本间的差异；</td>
</tr>
<tr class="even">
<td>缺点</td>
<td>1. LDA不适合对非高斯分布样本进行降维； 2.
<strong>LDA降维最多降到分类数k-1维</strong>； 3.
LDA在样本分类信息依赖方差而不是均值时，降维效果不好； 4.
LDA可能过度拟合数据。</td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>降维与度量学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>降维</tag>
        <tag>LDA</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习（4）XGBoost</title>
    <url>/posts/21JWWCP/</url>
    <content><![CDATA[<h3><span id="一-xgboost">一、XGBoost</span></h3>
<p>XGBoost 是大规模并行 boosting tree 的工具，它是目前最快最好的开源
boosting tree 工具包，比常见的工具包快 10 倍以上。Xgboost 和 GBDT
两者都是 boosting
方法，除了工程实现、解决问题上的一些差异外，最大的不同就是<strong>目标函数</strong>的定义。故本文将从数学原理和工程实现上进行介绍，并在最后介绍下
Xgboost 的优点。</p>
<h3><span id="11-数学原理">1.1 数学原理</span></h3>
<h4><span id="111-目标函数"><strong>1.1.1 目标函数</strong></span></h4>
<p>我们知道 XGBoost 是由<span class="math inline">\(k\)</span>个基模型组成的一个加法运算式： <span class="math display">\[
\hat{y}_{i}=\sum_{t=1}^{k} f_{t}\left(x_{i}\right)
\]</span> <strong>损失函数：</strong> <span class="math display">\[
L=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}\right)
\]</span>
我们知道模型的预测精度由模型的<strong>偏差</strong>和<strong>方差</strong>共同决定，损失函数代表了模型的偏差，想要方差小则需要简单的模型，所以目标函数由模型的<strong>损失函数<span class="math inline">\(L\)</span></strong>与抑<strong>制模型复杂度的正则项
<span class="math inline">\(\Omega\)</span></strong>组成。支持<strong>决策树</strong>也支持<strong>线性模型</strong>。
<span class="math display">\[
O b j=\sum_{i=1}^{n} l\left(\hat{y}_{i}, y_{i}\right)+\sum_{t=1}^{k}
\Omega\left(f_{t}\right)
\]</span> <strong>Boosting模型是向前加法：</strong> <span class="math display">\[
\hat{y}_{i}^{t}=\hat{y}_{i}^{t-1}+f_{t}\left(x_{i}\right)
\]</span> 目标函数就可以写成： <span class="math display">\[
\begin{aligned}
O b j^{(t)} &amp;=\sum_{i=1}^{n} l\left(y_{i},
\hat{y}_{i}^{t}\right)+\sum_{i=1}^{t} \Omega\left(f_{i}\right) \\
&amp;=\sum_{i=1}^{n} l\left(y_{i},
\hat{y}_{i}^{t-1}+f_{t}\left(x_{i}\right)\right)+\sum_{i=1}^{t}
\Omega\left(f_{i}\right)
\end{aligned}
\]</span> 求此时最优化目标函数，就相当于求解 <span class="math display">\[f_{t}\left(x_{i}\right)\]</span>。根据泰勒展开式：
<span class="math display">\[
f(x+\Delta x) \approx f(x)+f^{\prime}(x) \Delta x+\frac{1}{2} f^{\prime
\prime}(x) \Delta x^{2}
\]</span> <font color="red"> 我们把<span class="math inline">\(\hat{y}_{i}^{t-1}\)</span>,视为x， <span class="math inline">\(f_{t}\left(x_{i}\right)\)</span>视为<span class="math inline">\(\Delta x\)</span>，故可以将目标函数写成：</font>
<span class="math display">\[
O b j^{(t)}=\sum_{i=1}^{n}\left[l\left(y_{i},
\hat{y}_{i}^{t-1}\right)+g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i}
f_{t}^{2}\left(x_{i}\right)\right]+\sum_{i=1}^{t}
\Omega\left(f_{i}\right)
\]</span>
由于<strong>第一项为常数，对优化没有影响，所以我们只需要求出每一步损失函数的一阶导和二阶导的值</strong>【前t-1的结果和标签求】，然后最优化目标函数，就可以得到每一步的f(x),最后根据加法模型得到一个整体模型。
<span class="math display">\[
O b j^{(t)} \approx \sum_{i=1}^{n}\left[g_{i}
f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i}
f_{t}^{2}\left(x_{i}\right)\right]+\sum_{i=1}^{t}
\Omega\left(f_{i}\right)
\]</span></p>
<blockquote>
<p>以<strong>平方损失函数</strong>【绝对值、hubor损失】为例（GBDT
残差）：</p>
<p><span class="math display">\[
  \sum_{i=1}^n\left(y_i-\left(\hat{y}_i^{t-1}+f_t\left(x_i\right)\right)\right)^2
  \]</span></p>
<p>其中 <span class="math inline">\(g_i\)</span> 为损失函数的一阶导,
<span class="math inline">\(h_i\)</span> 为损失函数的二阶导,
注意这里的导是对 <span class="math inline">\(\hat{y}_i^{t-1}\)</span>
求导。 <span class="math display">\[
  \begin{aligned}
  g_i &amp; =\frac{\partial\left(\hat{y}^{t-1}-y_i\right)^2}{\partial
\hat{y}^{t-1}}=2\left(\hat{y}^{t-1}-y_i\right) \\
  h_i &amp;
=\frac{\partial^2\left(\hat{y}^{t-1}-y_i\right)^2}{\hat{y}^{t-1}}=2
  \end{aligned}
  \]</span></p>
</blockquote>
<h4><span id="112基于决策树的目标函数"><strong>1.1.2
基于决策树的目标函数</strong></span></h4>
<p>我们知道 <strong>Xgboost
的基模型不仅支持决策树，还支持线性模型</strong>，这里我们主要介绍基于决策树的目标函数。</p>
<p>我们可以将决策树定义为 <span class="math inline">\(f_t(x)=w_{q(x)}\)</span>, <span class="math inline">\(x\)</span> 为某一样本, 这里的 <span class="math inline">\(q(x)\)</span> 代表了该样本在哪个叶子结点上, 而
<span class="math inline">\(w_q\)</span> 则 代表了叶子结点取值 <span class="math inline">\(w\)</span>, 所以 <span class="math inline">\(w_{q(x)}\)</span> 就代表了每个样本的取值 <span class="math inline">\(w\)</span> (即预测值)。</p>
<p><strong>决策树的复杂度可由叶子数 <span class="math inline">\(T\)</span> 组成</strong>, 叶子节点越少模型越简单,
此外叶子节点也不应该含有过高的权重 <span class="math inline">\(w\)</span> (类 比 <span class="math inline">\(L
R\)</span> 的每个变量的权重), 所以目标函数的正则项可以定义为: <span class="math display">\[
\Omega\left(f_{t}\right)=\gamma T+\frac{1}{2} \lambda \sum_{j=1}^{T}
w_{j}^{2}
\]</span>
即<strong>决策树模型的复杂度</strong>由生成的所有<strong>决策树的叶子节点数量</strong>，和所有<strong>节点权重所组成的向量的<span class="math inline">\(L2\)</span>范式</strong>共同决定。</p>
<p><img src="https://pic1.zhimg.com/80/v2-e0ab9287990a6098e4cdbc5a8cff4150_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>我们设 <span class="math inline">\(I_j=\left\{i \mid
q\left(x_i\right)=j\right\}\)</span> 为第 <span class="math inline">\(j\)</span> 个叶子节点的样本集合,
故我们的目标函数可以写成: <span class="math display">\[
\begin{aligned}
O b j^{(t)} &amp; \approx \sum_{i=1}^n\left[g_i
f_t\left(x_i\right)+\frac{1}{2} h_i
f_t^2\left(x_i\right)\right]+\Omega\left(f_t\right) \\
&amp; =\sum_{i=1}^n\left[g_i w_{q\left(x_i\right)}+\frac{1}{2} h_i
w_{q\left(x_i\right)}^2\right]+\gamma T+\frac{1}{2} \lambda \sum_{j=1}^T
w_j^2 \\
&amp; =\sum_{j=1}^T\left[\left(\sum_{i \in I_j} g_i\right)
w_j+\frac{1}{2}\left(\sum_{i \in I_j} h_i+\lambda\right)
w_j^2\right]+\gamma T
\end{aligned}
\]</span> 第二步是遍历所有的样本后求每个样本的损失函数,
但样本最终会落在叶子节点上, 所以我们也可以遍历叶子节 点,
然后获取叶子节点上的样本集合, 最后在求损失函数。即我们之前样本的集合,
现在都改写成叶子结点的集 合, 由于一个叶子结点有多个样本存在, 因此才有了
<span class="math inline">\(\sum_{i \in I_j} g_i\)</span> 和 <span class="math inline">\(\sum_{i \in I_j} h_i\)</span> 这两项, <span class="math inline">\(w_j\)</span> 为第 <span class="math inline">\(j\)</span> 个叶子节点取值。 <span class="math display">\[
O b j^{(t)}=\sum_{j=1}^T\left[G_j
w_j+\frac{1}{2}\left(H_j+\lambda\right) w_j^2\right]+\gamma T
\]</span> <font color="red"> 这里我们要注意 <span class="math inline">\(G_j\)</span> 和 <span class="math inline">\(H_j\)</span> 是前 <span class="math inline">\(t-1\)</span> 步得到的结果, 其值已知可视为常数,
只有最后一棵树的叶子节点 <span class="math inline">\(w_j\)</span> 不
确定，那么将目标函数对 <span class="math inline">\(w_j\)</span>
求一阶导，并令其等于 0 ，则可以求得叶子结点 <span class="math inline">\(j\)</span> 对应的权值：</font> <span class="math display">\[
w_j^*=-\frac{G_j}{H_j+\lambda}
\]</span> 所以<strong>目标函数可以化简为</strong>: <span class="math display">\[
\text { Obj }=-\frac{1}{2} \sum_{j=1}^T \frac{G_j^2}{H_j+\lambda}+\gamma
T
\]</span>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304212034506.jpg" alt="img" style="zoom: 67%;"></p>
<p>上图给出目标函数计算的例子, 求每个节点每个样本的一阶导数 <span class="math inline">\(g_i\)</span> 和二阶导数 <span class="math inline">\(h_i\)</span>, 然后针对每个节点对所含样
本求和得到的 <span class="math inline">\(G_j\)</span> 和 <span class="math inline">\(H_j\)</span>,
最后遍历决策树的节点即可得到目标函数。</p>
<h4><span id="113最优切分点划分算法"><strong>1.1.3
最优切分点划分算法</strong></span></h4>
<p><strong><font color="red"> 在决策树的生长过程中,
一个非常关键的问题是如何找到叶子的节点的最优切分点</font>,</strong>
Xgboost 支持两种分裂节点 的方法一一贪心算法和近似算法。</p>
<p><strong>1）贪心算法</strong></p>
<ol type="1">
<li><strong>从深度为 0 的树开始,
对每个叶节点枚举所有的可用特征;</strong></li>
<li>针对每个特征，把属于该节点的训练样本根据该特征值进行升序排列,
通过线性扫描的方式来决定该特征的最
佳分裂点，并记录该特征的分裂收益;</li>
<li>选择收益最大的特征作为分裂特征, 用该特征的最佳分裂点作为分裂位置,
在该节点上分裂出左右两个新的叶 节点, 并为每个新节点关联对应的样本集?
?</li>
<li>回到第 1 步, 递归执行到满足特定条件为止。（树的深度、gamma）</li>
</ol>
<p><strong>那么如何计算每个特征的分裂收益呢?</strong></p>
<p>假设我们在某一节点完成特征分裂，则分列前的目标函数可以写为: <span class="math display">\[
O b
j_1=-\frac{1}{2}\left[\frac{\left(G_L+G_R\right)^2}{H_L+H_R+\lambda}\right]+\gamma
\]</span> 分裂后的目标函数为: <span class="math display">\[
O b
j_2=-\frac{1}{2}\left[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}\right]+2
\gamma
\]</span> 则对于目标函数来说，分裂后的收益为：<strong>MAX【obj1 -
obj2（分裂后越小越好）】</strong> <span class="math display">\[
\text { Gain
}=\frac{1}{2}\left[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{\left(G_L+G_R\right)^2}{H_L+H_R+\lambda}\right]-\gamma
\]</span> 注意该特征收益也可作为特征重要性输出的重要依据。</p>
<p>我们可以发现对于所有的分裂点 <span class="math inline">\(a\)</span>,
我们只要做一遍从左到右的扫描就可以枚举出所有分割的梯度和 <span class="math inline">\(G_L\)</span> 和 <span class="math inline">\(G_R\)</span>
。然后用上面的公式计算每个分割方案的分数就可以了。<strong><font color="red">
观察分裂后的收益, 我们会发现节点划分不一定会使得结 果变好,
因为我们有一个引入新叶子的偍罚项（gamma),
也就是说引入的分割带来的增益如果小于一个阀值的 时候,
我们可以剪掉这个分割。</font></strong></p>
<p><strong>2）近似算法</strong>【<strong>加权分位划分点</strong>】</p>
<p><strong>贪婪算法可以的到最优解，但当数据量太大时则无法读入内存进行计算</strong>，近似算法主要针对贪婪算法这一缺点给出了近似最优解。</p>
<p>对于每个特征，只考察分位点可以减少计算复杂度。该算法会首先根据<strong>特征分布的分位数提出候选划分点，然后将连续型特征映射到由这些候选点划分的桶中</strong>，然后聚合统计信息找到所有区间的最佳分裂点。在提出候选切分点时有两种策略：</p>
<ul>
<li><strong>Global</strong>：<strong>学习每棵树前就提出候选切分点，并在每次分裂时都采用这种分割</strong>；</li>
<li><strong>Local</strong>：每次分裂前将重新提出候选切分点。</li>
</ul>
<p><strong>下图给出近似算法的具体例子，以三分位为例：</strong></p>
<p><img src="https://pic2.zhimg.com/80/v2-5d1dd1673419599094bf44dd4b533ba9_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>根据样本特征进行排序，然后基于分位数进行划分，并统计三个桶内的<span class="math inline">\(G, H\)</span> 值，最终求解节点划分的增益。</p>
<h4><span id="114加权分位数缩略图xgboost-直方图算法"><strong>1.1.4
加权分位数缩略图</strong>[XGBoost 直方图算法]</span></h4>
<ul>
<li>第一个 for 循环：对特征 <span class="math inline">\(k\)</span>
根据该特征分布的分位数找到切割点的候选集合【直方图】 <span class="math inline">\(S_k=\left\{s_{k 1}, s_{k 2}, \ldots, s_{k
l}\right\}\)</span> 。XGBoost 支持 Global 策略和 Local 策略。</li>
<li>第二个 for 循环：针对每个特征的候选集合,
将样本映射到由该特征对应的候选点集构成的分桶区间中, 即 <span class="math inline">\(s_{k, v} \geq x_{j k}&gt;s_{k, v-1}\)</span> ，
对每个桶统计 <span class="math inline">\(G, H\)</span> 值,
最后在这些统计量上寻找最佳分裂点。</li>
</ul>
<p><img src="https://pic1.zhimg.com/80/v2-161382c979557b8bae1563a459cd1ed4_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>事实上， <strong>XGBoost
不是简单地按照样本个数进行分位，而是以二阶导数值<span class="math inline">\(h_{i}\)</span>作为样本的权重进行划分</strong>，如下：</p>
<p><img src="https://pic4.zhimg.com/80/v2-5f16246289eaa2a3ae72f971db198457_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<h5><span id="那么问题来了为什么要用h_i进行样本加权">那么问题来了：为什么要用
<span class="math inline">\(h_{i}\)</span>进行样本加权？</span></h5>
<p>我们知道模型的目标函数为: <span class="math display">\[
O b j^{(t)} \approx \sum_{i=1}^n\left[g_i
f_t\left(x_i\right)+\frac{1}{2} h_i
f_t^2\left(x_i\right)\right]+\sum_{i=1}^t \Omega\left(f_i\right)
\]</span> 我们稍作整理，便可以看出 <span class="math inline">\(h_i\)</span> 有对 loss 加权的作用。 <span class="math display">\[
\begin{aligned}
O b j^{(t)} &amp; \approx \sum_{i=1}^n\left[g_i
f_t\left(x_i\right)+\frac{1}{2} h_i
f_t^2\left(x_i\right)\right]+\sum_{i=1}^t \Omega\left(f_i\right) \\
&amp; =\sum_{i=1}^n\left[g_i f_t\left(x_i\right)+\frac{1}{2} h_i
f_t^2\left(x_i\right)+\frac{1}{2}
\frac{g_i^2}{h_i}\right]+\Omega\left(f_t\right)+C \\
&amp; =\sum_{i=1}^n \frac{1}{2}
h_i\left[f_t\left(x_i\right)-\left(-\frac{g_i}{h_i}\right)\right]^2+\Omega\left(f_t\right)+C
\end{aligned}
\]</span> 其中 <span class="math inline">\(\frac{1}{2}
\frac{g_i^2}{h_i}\)</span> 与 <span class="math inline">\(C\)</span>
皆为常数。我们可以看到 <span class="math inline">\(h_i\)</span>
就是平方损失函数中样本的权重。</p>
<p>对于样本权值相同的数据集来说，找到候选分位点已经有了解决方案（GK
算法），但是当样本权值不一样时，该如何找到候选分位点呢？（作者给出了一个
Weighted Quantile Sketch 算法，这里将不做介绍。）</p>
<h5><span id="xgboost的近似直方图算法也类似于lightgbm这里的直方图算法为什么慢"><strong><font color="red">
xgboost的近似直方图算法也类似于lightgbm这里的直方图算法?
为什么慢？</font></strong></span></h5>
<ul>
<li><strong>xgboost在每一层都动态构建直方图</strong>，
因为<strong>xgboost的直方图算法不是针对某个特定的feature</strong>，而是所有feature共享一个直方图(每个样本的权重是二阶导),所以每一层都要重新构建直方图，而<strong>lightgbm中对每个特征都有一个直方图</strong>，所以构建一次直方图就够了。</li>
<li><strong>lightgbm有一些工程上的cache优化</strong></li>
</ul>
<h4><span id="115稀疏感知算法缺失值的处理"><strong>1.1.5
稀疏感知算法</strong>【<strong>缺失值的处理</strong>】</span></h4>
<blockquote>
<ul>
<li><strong>特征值缺失的样本无需遍历只需直接分配到左右节点</strong></li>
<li><strong>如果训练中没有数据缺失，预测时出现了数据缺失，则默认被分类到右节点.</strong>？
<ul>
<li>看c++源码是默认向左方向</li>
</ul></li>
</ul>
</blockquote>
<p>在决策树的第一篇文章中我们介绍 CART
树在应对数据缺失时的分裂策略【<strong>缺失代理</strong>】，XGBoost
也给出了其解决方案。XGBoost
在构建树的节点过程中只考虑非缺失值的数据遍历，而为每个节点增加了一个缺省方向，当样本相应的特征值缺失时，可以被归类到缺省方向上，最优的缺省方向可以从数据中学到。</p>
<p><strong>XGBoost提出的是在计算分割后的分数时，遇到缺失值，分别将缺失值带入左右两个分割节点，然后取最大值的方向为其默认方向。</strong>至于如何学到缺省值的分支，其实很简单，<strong>分别枚举特征缺省的样本归为左右分支后的增益，选择增益最大的枚举项即为最优缺省方向。</strong></p>
<p>在构建树的过程中需要枚举特征缺失的样本，乍一看该算法的计算量增加了一倍，但其实该算法在构建树的过程中只考虑了特征未缺失的样本遍历，而<strong>特征值缺失的样本无需遍历只需直接分配到左右节点</strong>，故算法所需遍历的样本量减少，下图可以看到稀疏感知算法比
basic 算法速度块了超过 50 倍。</p>
<p><img src="https://pic1.zhimg.com/80/v2-e065bea4b424ea2d13b25ed2e7004aa8_1440w.jpg" alt="img" style="zoom:67%;"></p>
<h4><span id="116-缩减与列采样"><strong>1.1.6 缩减与列采样</strong></span></h4>
<p>除了在目标函数中引入正则项，为了防止过拟合，XGBoost还引入了缩减(shrinkage)和列抽样（column
subsampling），通过在每一步的boosting中引入缩减系数，降低每个树和叶子对结果的影响；列采样是借鉴随机森林中的思想，根据反馈，列采样有时甚至比行抽样效果更好，同时，通过列采样能加速计算。</p>
<h3><span id="12-工程实现">1.2 工程实现</span></h3>
<h4><span id="121-块结构设计"><strong>1.2.1 块结构设计</strong></span></h4>
<p>我们知道，决策树的学习<strong>最耗时的一个步骤就是在每次寻找最佳分裂点是都需要对特征的值进行排序</strong>。而
<strong><font color="red"> XGBoost
在训练之前对根据特征对数据进行了排序，然后保存到块结构中，并在每个块结构中都采用了稀疏矩阵存储格式（Compressed
Sparse Columns
Format，CSC）进行存储，后面的训练过程中会重复地使用块结构，可以大大减小计算量。</font></strong></p>
<blockquote>
<p>预排序 + 块设计【独立】 + 稀疏矩阵存储</p>
</blockquote>
<ul>
<li><strong>每一个块结构包括一个或多个已经排序好的特征</strong>；</li>
<li><strong>缺失特征值将不进行排序</strong>；</li>
<li>每个特征会存储指向<strong>样本梯度统计值</strong>的索引，方便计算一阶导和二阶导数值；</li>
</ul>
<p>这种块结构存储的特征之间相互独立，方便计算机进行并行计算。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个<strong>特征的增益计算可以同时进行</strong>，这也是
Xgboost 能够实现分布式或者多线程计算的原因。</p>
<h4><span id="122缓存访问优化算法索引访问梯度统计-gt-缓存空间不连续"><strong>1.2.2
缓存访问优化算法</strong>【索引访问梯度统计 -&gt; 缓存空间不连续】</span></h4>
<p>块结构的设计可以减少节点分裂时的计算量，但<strong>特征值通过索引访问样本梯度统计值的设计会导致访问操作的内存空间不连续</strong>，这样会造成缓存命中率低，从而影响到算法的效率。</p>
<p>为了解决缓存命中率低的问题，XGBoost
提出了缓存访问优化算法：为每个线程分配一个连续的缓存区，将需要的梯度信息存放在缓冲区中，这样就是实现了非连续空间到连续空间的转换，提高了算法效率。此外适当调整块大小，也可以有助于缓存优化。</p>
<p>于exact greedy算法中, 使用<strong>缓存预取（cache-aware
prefetching）</strong>。具体来说，<strong>对每个线程分配一个连续的buffer</strong>，读取梯度信息并存入Buffer中（这样就实现了非连续到连续的转化）</p>
<h4><span id="123-核外块计算"><strong>1.2.3 “核外”块计算</strong></span></h4>
<p>当数据量过大时无法将数据全部加载到内存中，只能先将无法加载到内存中的数据暂存到硬盘中，直到需要时再进行加载计算，而这种操作必然涉及到因内存与硬盘速度不同而造成的资源浪费和性能瓶颈。为了解决这个问题，<strong>XGBoost
独立一个线程专门用于从硬盘读入数据，以实现处理数据和读入数据同时进行</strong>。</p>
<p>此外，XGBoost 还用了两种方法来降低硬盘读写的开销：</p>
<ul>
<li><strong>块压缩：</strong>对 Block
进行按列压缩，并在读取时进行解压；</li>
<li><strong>块拆分：</strong>将每个块存储到不同的磁盘中，从多个磁盘读取可以增加吞吐量。</li>
</ul>
<h4><span id="124-xgboost损失函数">1.2.4 <strong>XGBoost损失函数</strong></span></h4>
<blockquote>
<p><a href="https://blog.csdn.net/qq_32103261/article/details/106664227">不平衡处理：xgboost
中scale_pos_weight、给样本设置权重weight、 自定义损失函数 和
简单复制正样本的区别</a></p>
</blockquote>
<p><strong>损失函数</strong>：损失函数描述了预测值和真实标签的差异，通过对损失函数的优化来获得对学习任务的一个近似求解方法。boosting类算法的损失函数的作用：
Boosting的框架, 无论是GBDT还是Adaboost, 其在每一轮迭代中,
<strong>根本没有理会损失函数具体是什么,
仅仅用到了损失函数的一阶导数通过随机梯度下降来参数更新</strong>。XGBoost是用了牛顿法进行的梯度更新。通过对损失进行分解得到一阶导数和二阶导数并通过牛顿法来迭代更新梯度。</p>
<h5><span id="1自定义损失函数">（1）<strong>自定义损失函数</strong></span></h5>
<p><strong>XGBOOST是一个非常灵活的模型</strong>，允许使用者根据实际使用场景调整<a href="https://so.csdn.net/so/search?q=损失函数&amp;spm=1001.2101.3001.7020">损失函数</a>，对于常见的二分类问题一般使用的binary：logistic损失函数，其形式为：
<span class="math display">\[
J(\theta)=-\frac{1}{m} \sum_{i=1}^n\left(y^{(i)} \log
h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log
\left(1-h_\theta\left(x^{(i)}\right)\right)\right)
\]</span>
这个损失函数对于正类错分和负类错分给予的惩罚时相同的，但是<strong>对于不平衡数据集，或者某些特殊情况（两类错分代价不一样）的时候这样的损失函数就不再合理了。</strong></p>
<p>基于XGBoost的损失函数的分解求导，可以知道XGBoost的除正则项以外的核心影响因子是损失函数的1阶导和2阶导，所以对于任意的学习任务的损失函数，可以对其求一阶导数和二阶导数带入到XGBoost的自定义损失函数范式里面进行处理。
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">custom_obj</span>(<span class="params">pred, dtrain</span>):<span class="comment"># pred 和 dtrain 的顺序不能弄反</span></span><br><span class="line">    <span class="comment"># STEP1 获得label</span></span><br><span class="line">    label = dtrain.get_label()</span><br><span class="line">    <span class="comment"># STEP2 如果是二分类任务，需要让预测值通过sigmoid函数获得0～1之间的预测值</span></span><br><span class="line">    <span class="comment"># 如果是回归任务则下述任务不需要通过sigmoid</span></span><br><span class="line">    <span class="comment"># 分类任务sigmoid化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line">    sigmoid_pred = sigmoid(原始预测值)</span><br><span class="line">    <span class="comment">#回归任务</span></span><br><span class="line">    pred = 原始预测值</span><br><span class="line">    <span class="comment"># STEP3 一阶导和二阶导</span></span><br><span class="line">    grad = 一阶导</span><br><span class="line">    hess = 二阶导</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> grad, hess</span><br></pre></td></tr></table></figure></p>
<p>非平衡分类学习任务，例如首笔首期30+的风险建模任务，首期30+的逾期率比例相对ever30+的逾期率为1/3左右，<strong>通过修正占比少的正样本权重来对影响正样本对损失函数的贡献度，可以进一步提升模型的效果</strong>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">weighted_binary_cross_entropy</span>(<span class="params">pred, dtrain,imbalance_alpha=<span class="number">10</span></span>):</span><br><span class="line">    <span class="comment"># retrieve data from dtrain matrix</span></span><br><span class="line">    label = dtrain.get_label()</span><br><span class="line">    <span class="comment"># compute the prediction with sigmoid</span></span><br><span class="line">    sigmoid_pred = <span class="number">1.0</span> / (<span class="number">1.0</span> + np.exp(-pred))</span><br><span class="line">    <span class="comment"># gradient</span></span><br><span class="line">    grad = -(imbalance_alpha ** label) * (label - sigmoid_pred)</span><br><span class="line">    hess = (imbalance_alpha ** label) * sigmoid_pred * (<span class="number">1.0</span> - sigmoid_pred)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> grad, hess </span><br></pre></td></tr></table></figure>
<h5><span id="2focal-loss">（2）Focal Loss</span></h5>
<p><strong>Focal Loss for Dense Object Detection 是ICCV2017的Best
student
paper,文章思路很简单但非常具有开拓性意义，效果也非常令人称赞。</strong></p>
<ul>
<li>大家还可以看知乎的讨论：<a href="https://www.zhihu.com/question/63581984">如何评价 Kaiming 的 Focal
Loss for Dense Object Detection？</a></li>
<li>[机器学习] XGBoost
自定义损失函数-FocalLoss：https://blog.csdn.net/zwqjoy/article/details/109311133</li>
</ul>
<p>Focal
Loss的引入主要是为了解决难易样本数量不平衡（注意，有区别于正负样本数量不平衡）的问题，实际可以使用的范围非常广泛，为了方便解释，拿目标检测的应用场景来说明</p>
<p><strong>Focal Loss的主要思想就是改变损失函数.Focal
loss是在交叉熵损失函数基础上进行的修改</strong></p>
<p>单阶段的目标检测器通常会产生高达100k的候选目标，只有极少数是正样本，正负样本数量非常不平衡。我们在计算分类的时候常用的损失——交叉熵。<span class="math inline">\(y&#39;\)</span>是经过激活函数的输出，所以在0-1之间。可见普通的交叉熵对于正样本而言，输出概率越大损失越小。对于负样本而言，输出概率越小则损失越小。此时的损失函数在大量简单样本的迭代过程中比较缓慢且可能无法优化至最优。</p>
<p>为了解决<strong>正负样本不平衡</strong>的问题，我们通常会在交叉熵损失的前面加上一个参数<strong>平衡因子alpha</strong>，用来平衡正负样本本身的比例不均.
文中alpha取0.25，即正样本要比负样本占比小，这是因为负例易分。</p>
<h3><span id="13-优缺点">1.3 优缺点</span></h3>
<h4><span id="131-优点"><strong>1.3.1 优点</strong></span></h4>
<ol type="1">
<li><strong>精度更高：</strong>GBDT
只用到一阶<strong>泰勒展开</strong>，而 XGBoost
对损失函数进行了二阶泰勒展开。<strong>XGBoost
引入二阶导一方面是为了增加精度，另一方面也是为了能够自定义损失函数，二阶泰勒展开可以近似大量损失函数</strong>；</li>
<li><strong>灵活性更强：</strong>GBDT 以 CART
作为<strong>基分类器</strong>，XGBoost 不仅支持 CART
还支持线性分类器，（使用线性分类器的 <strong>XGBoost 相当于带 L1 和 L2
正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）</strong>）。此外，XGBoost
工具支持自定义损失函数，只需函数支持一阶和二阶求导；</li>
<li><strong>正则化：</strong>XGBoost
在目标函数中加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、叶子节点权重的
L2
范式。正则项降低了模型的方差，使学习出来的模型更加简单，有助于防止过拟合；</li>
<li><strong>Shrinkage（缩减）：</strong>相当于学习速率。XGBoost
在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间；</li>
<li><strong>列抽样：</strong>XGBoost
借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</li>
<li><strong>缺失值处理：</strong>XGBoost
采用的稀疏感知算法极大的加快了节点分裂的速度；</li>
<li><strong>可以并行化操作：</strong>块结构可以很好的支持并行计算。</li>
</ol>
<h4><span id="132-缺点"><strong>1.3.2 缺点</strong></span></h4>
<ol type="1">
<li>虽然利用<strong>预排序</strong>和<strong>近似算法</strong>可以降低寻找最佳分裂点的计算量，但在节点分裂过程中仍需要<strong>遍历数据集</strong>；</li>
<li>预排序过程的空间复杂度过高，不仅需要存储特征值，还需要<strong>存储特征对应样本的梯度统计值的索引</strong>，相当于消耗了两倍的内存。</li>
</ol>
<h3><span id="二-xgboost常用参数">二、XGBoost常用参数</span></h3>
<h5><span id="xgboost的参数一共分为三类">XGBoost的参数一共分为三类：</span></h5>
<p><a href="https://xgboost.apachecn.org/#/">完整参数请戳官方文档</a></p>
<p>1、<strong>通用参数</strong>：宏观函数控制。</p>
<p>2、<strong>Booster参数</strong>：控制每一步的booster(tree/regression)。booster参数一般可以调控模型的效果和计算代价。我们所说的调参，很这是大程度上都是在调整booster参数。</p>
<p>3、<strong>学习目标参数</strong>：控制训练目标的表现。我们对于问题的划分主要体现在学习目标参数上。比如我们要做分类还是回归，做二分类还是多分类，这都是目标参数所提供的。</p>
<h5><span id="通用参数">通用参数</span></h5>
<ol type="1">
<li><strong>booster</strong>：我们有两种参数选择，<code>gbtree</code>、<code>dart</code>和<code>gblinear</code>。gbtree、dart是采用树的结构来运行数据，而gblinear是基于线性模型。</li>
<li><strong>silent</strong>：静默模式，为<code>1</code>时模型运行不输出。</li>
<li><strong>nthread</strong>:
使用线程数，一般我们设置成<code>-1</code>,使用所有线程。如果有需要，我们设置成多少就是用多少线程。</li>
</ol>
<h5><span id="booster参数">Booster参数</span></h5>
<ol type="1">
<li><p><strong>n_estimator</strong>:
也作<code>num_boosting_rounds</code>这是生成的<strong>最大树的数目</strong>，也是最大的迭代次数。</p></li>
<li><p><strong>learning_rate</strong>:
有时也叫作<code>eta</code>，系统默认值为<code>0.3</code>,。<strong>每一步迭代的步长</strong>，很重要。太大了运行准确率不高，太小了运行速度慢。我们一般使用比默认值小一点，<code>0.1</code>左右就很好。</p></li>
<li><p><strong>gamma</strong>：系统默认为<code>0</code>,我们也常用<code>0</code>。在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。<code>gamma</code>指定了节点分裂所需的<strong>最小损失函数下降值</strong>。
这个参数的值越大，算法越保守。因为<code>gamma</code>值越大的时候，损失函数下降更多才可以分裂节点。所以树生成的时候更不容易分裂节点。范围:
<code>[0,∞]</code></p></li>
<li><p><strong>subsample</strong>：系统默认为<code>1</code>。这个参数控制对于每棵树，<strong>随机采样的比例</strong>。减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。
典型值：<code>0.5-1</code>，<code>0.5</code>代表平均采样，防止过拟合.
范围: <code>(0,1]</code>，<strong>注意不可取0</strong></p></li>
<li><p><strong>colsample_bytree</strong>：系统默认值为1。我们一般设置成0.8左右。用来控制每棵<strong>随机采样的列数的占比</strong>(每一列是一个特征)。
典型值：<code>0.5-1</code>范围: <code>(0,1]</code></p></li>
<li><p><strong>colsample_bylevel</strong>：默认为1,我们也设置为1.这个就相比于前一个更加细致了，它指的是每棵树每次节点分裂的时候列采样的比例</p></li>
<li><p><strong>max_depth</strong>：
系统默认值为<code>6</code>，我们常用<code>3-10</code>之间的数字。这个值为<strong>树的最大深度</strong>。这个值是用来控制过拟合的。<code>max_depth</code>越大，模型学习的更加具体。设置为<code>0</code>代表没有限制，范围:
<code>[0,∞]</code></p></li>
<li><p><strong>max_delta_step</strong>：默认<code>0</code>,我们常用<code>0</code>.这个参数限制了<strong>每棵树权重改变的最大步长</strong>，如果这个参数的值为<code>0</code>,则意味着没有约束。如果他被赋予了某一个正值，则是这个算法更加保守。通常，这个参数我们不需要设置，但是<strong>当个类别的样本极不平衡的时候，这个参数对逻辑回归优化器是很有帮助的。</strong></p></li>
<li><p><strong>lambda</strong>:也称<code>reg_lambda</code>,默认值为<code>0</code>。<strong>权重的L2正则化项</strong>。(和Ridge
regression类似)。这个参数是用来控制XGBoost的正则化部分的。这个参数在减少过拟合上很有帮助。</p></li>
<li><p><strong>alpha</strong>:也称<code>reg_alpha</code>默认为<code>0</code>,权重的L1正则化项。(和Lasso
regression类似)。
可以应用在很高维度的情况下，使得算法的速度更快。</p></li>
<li><p><strong>scale_pos_weight</strong>：默认为<code>1</code>在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛。通常可以将其设置为<strong>负样本的数目与正样本数目的比值</strong>。<strong>xgboost中scale_pos_weight、对样本进行weight设置和简单复制正样本得到的结果是一样的，本质上都是改变了训练的损失函数。通过自定义设置损失函数可得到验证。实际上基本思想都是通过过采样的方法处理不平衡数据。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (label  <span class="number">1.0</span>f) &#123;</span><br><span class="line">    w *= scale_pos_weight;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 见源码 src/objective/regression_obj.cu</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>在DMatrix里边设置每个样本的weight 是
怎样改变训练过程的呢，其实是改变训练的损失函数，源代码里的代码如下，可以看到对不同的样本赋予不同的权重实际上是影响了该样本在训练过程中贡献的损失，进而改变了一阶导和二阶导。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_out_gpair[_idx] = GradientPair(Loss::FirstOrderGradient(p, label) * w,</span><br><span class="line">                   Loss::SecondOrderGradient(p, label) * w);</span><br><span class="line"><span class="comment"># 见源码 src/objective/regression_obj.cu</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h5><span id="学习目标参数">学习目标参数</span></h5>
<h5><span id="objective-缺省值reglinear">objective [缺省值=reg:linear]</span></h5>
<ul>
<li><code>reg:linear</code>– <strong>线性回归</strong></li>
<li><code>reg:logistic</code> – <strong>逻辑回归</strong></li>
<li><code>binary:logistic</code> – 二分类逻辑回归，输出为概率</li>
<li><code>binary:logitraw</code> – 二分类逻辑回归，输出的结果为wTx</li>
<li><code>count:poisson</code> –
计数问题的poisson回归，输出结果为poisson分布。在poisson回归中，max_delta_step的缺省值为0.7
(used to safeguard optimization)</li>
<li><code>multi:softmax</code> – 设置 XGBoost
使用softmax目标函数做多分类，需要设置参数num_class（类别个数）</li>
<li><code>multi:softprob</code> –
如同softmax，但是输出结果为ndata*nclass的向量，其中的值是每个数据分为每个类的概率。</li>
</ul>
<h5><span id="eval_metric缺省值通过目标函数选择">eval_metric
[缺省值=通过目标函数选择]</span></h5>
<ul>
<li><code>rmse</code>: <strong>均方根误差</strong></li>
<li><code>mae</code>: <strong>平均绝对值误差</strong></li>
<li><code>logloss</code>: negative log-likelihood</li>
<li><code>error</code>:
二分类错误率。其值通过错误分类数目与全部分类数目比值得到。对于预测，预测值大于0.5被认为是正类，其它归为负类。
error@t: 不同的划分阈值可以通过 ‘t’进行设置</li>
<li><code>merror</code>: 多分类错误率，计算公式为(wrong cases)/(all
cases)</li>
<li><code>mlogloss</code>: 多分类log损失</li>
<li><code>auc</code>: 曲线下的面积</li>
<li><code>ndcg</code>: Normalized Discounted Cumulative Gain</li>
<li><code>map</code>: 平均正确率</li>
</ul>
<p>一般来说，我们都会使用<code>xgboost.train(params, dtrain)</code>函数来训练我们的模型。这里的<code>params</code>指的是<code>booster</code>参数。</p>
<h3><span id="三-xgboostqampa">三、XGBoostQ&amp;A</span></h3>
<ul>
<li>推荐收藏 |
又有10道XGBoost面试题送给你：https://cloud.tencent.com/developer/article/1518305</li>
</ul>
<h4><span id="1-xgboost模型如果过拟合了怎么解决"><strong>1、XGBoost模型如果过拟合了怎么解决?</strong></span></h4>
<ul>
<li><strong>正则项</strong>：叶子结点的数目和叶子结点权重的L2模的平方</li>
<li><strong>列抽样</strong>：训练的时候只用一部分特征，不仅可以降低过拟合，还可以加速</li>
<li><strong>子采样</strong>：每轮计算可以不使用全部样本</li>
<li><strong>shrinkage</strong>:
步长(学习率)，消弱训练出的每棵树的影响，让后面的训练有更大的学习空间</li>
</ul>
<p>当出现过拟合时，有两类参数可以缓解：</p>
<p>第一类参数：用于<strong>直接控制模型的复杂度</strong>。包括<code>max_depth,min_child_weight,gamma</code>
等参数</p>
<p>第二类参数：用于<strong>增加随机性</strong>，从而使得模型在训练时对于噪音不敏感。包括<code>subsample,colsample_bytree</code></p>
<p>还有就是直接减小<code>learning rate</code>，但需要同时增加<code>estimator</code>
参数。</p>
<h4><span id="2-怎么理解决策树-xgboost能处理缺失值而有的模型svm对缺失值比较敏感呢">2、怎么理解决策树、xgboost能处理缺失值？而有的模型(svm)对缺失值比较敏感呢?</span></h4>
<blockquote>
<p>微调的回答 - 知乎
https://www.zhihu.com/question/58230411/answer/242037063</p>
<p>XGBoost是一种<strong>boosting</strong>的集成学习模型：支持的弱学习器（即单个的学习器，也称基学习器）有<strong>树模型</strong>和<strong>线性模型</strong>（<strong>gblinear</strong>），默认为<strong>gbtree</strong>。</p>
<ul>
<li><p><strong>gblinear</strong>，<strong>由于线性模型不支持缺失值，会将缺失值填充为0</strong>；</p></li>
<li><p><strong>gbtree</strong>或者<strong>dart</strong>，则支持缺失值；</p></li>
</ul>
</blockquote>
<ul>
<li>工具包自动处理数据缺失<strong>不代表</strong>具体的算法可以<strong>处理缺失项</strong></li>
<li>对于有缺失的数据：以<a href="https://www.zhihu.com/search?q=决策树&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A242037063%7D">决策树</a>为原型的模型<strong>优于</strong>依赖距离度量的模型</li>
</ul>
<h4><span id="3-histogram-vs-pre-sorted">3、 Histogram VS Pre-sorted</span></h4>
<h5><span id="pre-sorted">Pre-sorted</span></h5>
<p><strong>预排序还是有一定优点的，如果不用预排序的话，在分裂节点的时候，选中某一个特征后，需要对A按特征值大小进行排序，然后计算每个阈值的增益，这个过程需要花费很多时间</strong>。</p>
<p>预排序算法在计算最优分裂时，各个特征的增益可以并行计算，并且能精确地找到分割点。但是<strong>预排序后需要保存特征值及排序后的索引，因此需要消耗两倍于训练数据的内存，时间消耗大</strong>。另外预排序后，<strong>特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化，时间消耗也大</strong>。最后，在每一层，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样。</p>
<h5><span id="historgram">Historgram</span></h5>
<p>首先需要指出的是，XGBoost在寻找树的分裂节点的也是支持直方图算法的，就是论文中提到的近视搜索算法（Approximate
Algorithm）。<strong>只是，无论特征值是否为0，直方图算法都需要对特征的分箱值进行索引，因此对于大部分实际应用场景当中的稀疏数据优化不足。</strong></p>
<p>回过头来，为了能够发挥直方图算法的优化威力，LightGBM提出了另外两个新技术：<strong>单边梯度采样（Gradient-based
One-Side Sampling</strong>）和<strong>互斥特征合并（Exclusive Feature
Bundling）</strong>，<strong><font color="red">
在减少维度和下采样上面做了优化以后才能够将直方图算法发挥得淋漓尽致。</font></strong></p>
<h5><span id="4-xgboost中的树如何剪枝">4、<strong>Xgboost中的树如何剪枝？</strong></span></h5>
<p><strong>在loss中增加了正则项</strong>：使用叶子结点的数目和叶子结点权重的L2模的平方，控制树的复杂度在每次分裂时，如果分裂后增益小于设置的阈值，则不分裂，则对应于Gain需要大于0才会分裂。(预剪枝)</p>
<p>则对于目标函数来说，分裂后的收益为：<strong>MAX</strong>【<strong>obj1
- obj2 （分裂后越小越好）</strong>】</p>
<p><span class="math display">\[
\text { Gain
}=\frac{1}{2}\left[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{\left(G_L+G_R\right)^2}{H_L+H_R+\lambda}\right]-\gamma
\]</span> 注意该特征收益也可作为特征重要性输出的重要依据。</p>
<p>我们可以发现对于所有的分裂点 <span class="math inline">\(a\)</span>,
我们只要做一遍从左到右的扫描就可以枚举出所有分割的梯度和 <span class="math inline">\(G_L\)</span> 和 <span class="math inline">\(G_R\)</span>
。然后用上面的公式计算每个分割方案的分数就可以了。<font color="red">观察分裂后的收益，我们会发现节点划分不一定会使得结果变好，因为我们有一个引入<strong>新叶子的惩罚项（gamma)</strong>，也就是说引入的分割带来的<strong>增益如果小于一个阀值</strong>的时候，我们可以剪掉这个分割。
</font></p>
<ul>
<li>当一次分裂后，计算新生成的左、右叶子节点样本权重和。如果任一个叶子结点的样本权重低于某一个阈值（最小样本权重和），也会收回此次分裂。</li>
<li>完成完整一棵树的分裂之后，再从底到顶反向检查是否有不满足分裂条件的结点，进行回溯剪枝。</li>
</ul>
<h4><span id="5-xgboost采样是有放回还是无放回的">5、<strong>Xgboost采样是有放回还是无放回的？</strong></span></h4>
<p>xgboost时基于boosting的方法，样本是不放回的 ，每轮样本不重复。</p>
<h4><span id="6-xgboost在工程上有哪些优化为什么要做这些工程化优化">6、<strong>Xgboost在工程上有哪些优化？为什么要做这些工程化优化？</strong></span></h4>
<h5><span id="61-块结构设计"><strong>6.1 块结构设计</strong></span></h5>
<p>我们知道，决策树的学习<strong>最耗时的一个步骤就是在每次寻找最佳分裂点是都需要对特征的值进行排序</strong>。而
<strong><font color="red"> XGBoost
在训练之前对根据特征对数据进行了排序，然后保存到块结构中，并在每个块结构中都采用了稀疏矩阵存储格式（Compressed
Sparse Columns
Format，CSC）进行存储，后面的训练过程中会重复地使用块结构，可以大大减小计算量。</font></strong></p>
<blockquote>
<p>预排序 + 块设计【独立】 + 稀疏矩阵存储</p>
</blockquote>
<ul>
<li><strong>每一个块结构包括一个或多个已经排序好的特征</strong>；</li>
<li><strong>缺失特征值将不进行排序</strong>；</li>
<li>每个特征会存储指向<strong>样本梯度统计值</strong>的索引，方便计算一阶导和二阶导数值；</li>
</ul>
<p>这种块结构存储的特征之间相互独立，方便计算机进行并行计算。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个<strong>特征的增益计算可以同时进行</strong>，这也是
Xgboost 能够实现分布式或者多线程计算的原因。</p>
<h5><span id="62缓存访问优化算法索引访问梯度统计-gt-缓存空间不连续"><strong>6.2
缓存访问优化算法</strong>【索引访问梯度统计 -&gt; 缓存空间不连续】</span></h5>
<p>块结构的设计可以减少节点分裂时的计算量，但<strong>特征值通过索引访问样本梯度统计值的设计会导致访问操作的内存空间不连续</strong>，这样会造成缓存命中率低，从而影响到算法的效率。</p>
<p>为了解决缓存命中率低的问题，XGBoost
提出了缓存访问优化算法：为每个线程分配一个连续的缓存区，将需要的梯度信息存放在缓冲区中，这样就是实现了非连续空间到连续空间的转换，提高了算法效率。此外适当调整块大小，也可以有助于缓存优化。</p>
<p>于exact greedy算法中, 使用<strong>缓存预取（cache-aware
prefetching）</strong>。具体来说，<strong>对每个线程分配一个连续的buffer</strong>，读取梯度信息并存入Buffer中（这样就实现了非连续到连续的转化）</p>
<h5><span id="63-核外块计算"><strong>6.3 “核外”块计算</strong></span></h5>
<p>当数据量过大时无法将数据全部加载到内存中，只能先将无法加载到内存中的数据暂存到硬盘中，直到需要时再进行加载计算，而这种操作必然涉及到因内存与硬盘速度不同而造成的资源浪费和性能瓶颈。为了解决这个问题，<strong>XGBoost
独立一个线程专门用于从硬盘读入数据，以实现处理数据和读入数据同时进行</strong>。</p>
<p>此外，XGBoost 还用了两种方法来降低硬盘读写的开销：</p>
<ul>
<li><strong>块压缩：</strong>对 Block
进行按列压缩，并在读取时进行解压；</li>
<li><strong>块拆分：</strong>将每个块存储到不同的磁盘中，从多个磁盘读取可以增加吞吐量。</li>
</ul>
<h4><span id="7-xgboost与gbdt有什么联系和不同基模型-算法-工程设计">7、<strong>Xgboost与GBDT有什么联系和不同？</strong>【基模型、算法、工程设计】</span></h4>
<ol type="1">
<li><strong>基分类器</strong>：GBDT 以 CART
作为基分类器，而Xgboost的基分类器不仅支持CART决策树，还支持线性分类器，此时Xgboost相当于带L1和L2正则化项的Logistic回归（分类问题）或者线性回归（回归问题）。</li>
<li><strong>导数信息</strong>：GBDT只用了一阶导数信息，Xgboost中对损失函数进行二阶泰勒展开，引入二阶导数信息，并且XGBoost还支持自定义损失函数，只要损失函数一阶和二阶可导即可。</li>
<li><strong>正则项</strong>：Xgboost的目标函数加入正则项(叶子结点的数目和叶子结点权重的L2模的平方)，相当于分裂预剪枝过程，降低过拟合。</li>
<li><strong>列抽样</strong>：Xgboost支持列采样，与随机森林类似，用于防止过拟合且加速。(列采样就是训练的时候随机使用一部分特征)，也同时支持子采样，即每轮迭代计算可以不使用全部样本，对样本数据进行采样。</li>
<li><strong>缺失值处理</strong>：Xgboost可以处理缺失值(具体，查看上方问答)</li>
<li><strong>并行化</strong>：Xgboost可以在特征维度进行并行化，在训练前预先将每个特征按照特征值大小进行预排序，按块的形式存储，后续可以重复使用这个结构，减小计算量，分裂时可以用多线程并行计算每个特征的增益，最终选增益最大的那个特征去做分裂，提高训练速度。</li>
</ol>
<h4><span id="8-xgboost特征重要性">8、<strong><font color="red">
XGBoost特征重要性</font></strong></span></h4>
<blockquote>
<p><strong>何时使用shap value分析特征重要性？</strong> - 知乎
https://www.zhihu.com/question/527570173/answer/2472253431</p>
</blockquote>
<p>这一思路，通常被用来做<strong>特征筛选</strong>。剔除贡献度不高的尾部特征，增强模型的<a href="https://www.zhihu.com/search?q=鲁棒性&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22355884348%22%7D">鲁棒性</a>的同时，起到特征降维的作用。另一个方面，则是用来做<strong>模型的可解释性</strong>。我们期望的结果是：重要的特征是符合业务直觉的；符合业务直觉的特征排名靠前。</p>
<h5><span id="xgb内置的三种特征重要性计算方法">XGB内置的三种特征重要性计算方法</span></h5>
<ul>
<li><strong>weight</strong>：<code>xgb.plot_importance</code>,<strong>子树模型分裂时，用到的特征次数。这里计算的是所有的树。</strong></li>
<li><strong>gain</strong>:<code>model.feature_importances_</code>,信息增益的泛化概念。这里是指，<strong>节点分裂时，该特征带来信息增益（目标函数）优化的平均值。</strong></li>
<li><strong>cover</strong>:<code>model = XGBRFClassifier(importance_type = 'cover')</code>
这个计算方法，需要在定义模型时定义。之后再调用<code>model.feature_importances_</code>
得到的便是基于<code>cover</code>得到的贡献度。<strong>树模型在分裂时，特征下的叶子结点涵盖的样本数除以特征用来分裂的次数。分裂越靠近根部，cover
值越大。</strong></li>
</ul>
<h5><span id="其他重要性计算方法">其他重要性计算方法</span></h5>
<ul>
<li><strong>permutation</strong>:<strong>如果这个特征很重要，那么我们打散所有样本中的该特征，则最后的优化目标将折损。这里的折损程度，就是特征的重要程度。</strong></li>
<li><strong>shap</strong>:<strong>轮流去掉每一个特征，算出剩下特征的贡献情况，以此来推导出被去除特征的边际贡献。该方法是目前唯一的逻辑严密的特征解释方法</strong></li>
</ul>
<h4><span id="9-xgboost增量训练">9、XGBoost增量训练</span></h4>
<p><strong>XGBoost</strong>：XGBoost提供两种增量训练的方式，一种是在当前迭代树的基础上增加新树，原树不变；另一种是当前迭代树结构不变，重新计算叶节点权重，同时也可增加新树。</p>
<h4><span id="10-xgboost线性模型">10、XGBoost线性模型</span></h4>
<p><strong>线性模型</strong>：Xgboost通过泰勒公式的二阶展开迭代的残差是1导/2导，线性回归迭代的是标签，xgboost需要串行多个线性回归，预测结果为多个象形线性回归的累积值......，除了用到了线性回归的原理方程式，他们两的损失函数，下降梯度都不一样，几乎没有什么共同点</p>
<h4><span id="11-xgboost用泰勒展开优势在哪">11、XGBoost
用泰勒展开优势在哪？</span></h4>
<p>https://www.zhihu.com/question/61374305</p>
<ul>
<li><strong>xgboost是以mse为基础推导出来的</strong>，在mse的情况下，xgboost的目标函数展开就是一阶项+二阶项的形式，而其他类似logloss这样的目标函数不能表示成这种形式。为了后续推导的统一，所以将<strong>目标函数进行二阶泰勒展开，就可以直接自定义损失函数了，只要二阶可导即可，增强了模型的扩展性</strong>。</li>
<li><strong>二阶信息能够让梯度收敛的更快，类似牛顿法比SGD收敛更快</strong>。一阶信息描述梯度变化方向，二阶信息可以描述梯度变化方向是如何变化的。</li>
</ul>
<h3><span id="参考链接">参考链接</span></h3>
<ul>
<li><p><strong>XGBoost官方文档</strong>：https://xgboost.readthedocs.io/en/latest/index.html</p></li>
<li><p>LightGBM算法梳理：https://zhuanlan.zhihu.com/p/78293497</p></li>
<li><p>详解LightGBM两大利器：基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）：https://zhuanlan.zhihu.com/p/366234433</p></li>
<li><p>【机器学习】决策树（下）——XGBoost、LightGBM（非常详细）：https://zhuanlan.zhihu.com/p/87885678</p></li>
<li><p>xgboost面试题整理:
https://xiaomindog.github.io/2021/06/22/xgb-qa/</p></li>
<li><p><strong>深入理解XGBoost</strong>：https://bailingnan.github.io/post/shen-ru-li-jie-xgboost/</p></li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
        <tag>集成学习</tag>
        <tag>XGBoost</tag>
      </tags>
  </entry>
  <entry>
    <title>降维（3）t-SNE</title>
    <url>/posts/24K7V34/</url>
    <content><![CDATA[<h3><span id="一-t-sne-高维数据可视化">一、t-SNE 高维数据可视化</span></h3>
<blockquote>
<p>高维数据可视化之t-SNE算法🌈:https://zhuanlan.zhihu.com/p/57937096</p>
</blockquote>
<p><strong>T-SNE算法是用于可视化的算法中效果最好的算法之一</strong>，相信大家也对T-SNE算法略有耳闻，本文参考T-SNE作者<strong>Laurens
van der
Maaten</strong>给出的源代码自己实现T-SNE算法代码，以此来加深对T-SNE的理解。先简单介绍一下T-SNE算法，T-SNE将数据点变换映射到概率分布上。</p>
<h4><span id="11-t-sne数据算法的目的">1.1 t-SNE数据算法的目的</span></h4>
<p><strong>主要是将数据从高维数据转到低维数据，并在低维空间里也保持其在高维空间里所携带的信息（比如高维空间里有的清晰的分布特征，转到低维度时也依然存在）。</strong></p>
<p><strong><font color="red">
t-SNE将欧氏距离距离转换为条件概率，来表达点与点之间的相似度，再优化两个分布之间的距离-KL散度，从而保证点与点之间的分布概率不变。</font></strong></p>
<h4><span id="12-sne原理">1.2 SNE原理</span></h4>
<p><span class="math inline">\(S N E\)</span>
是<strong>通过仿射变换将数据点映射到相应概率分布上</strong>,
主要包括下面两个步骤: 1. 通过在高维空间中构建数据点之间的概率分布 <span class="math inline">\(P\)</span>, 使得相似的数据点有更高的概率被选择, 而
不相似的数据点有较低的概率被选择; 2.
然后在低维空间里重构这些点的概率分布 <span class="math inline">\(Q\)</span>, 使得这两个概率分布尽可能相似。</p>
<p>令输入空间是 <span class="math inline">\(X \in
\mathbb{R}^{n}\)</span>, 输出空间为 <span class="math inline">\(Y \in
\mathbb{R}^{t}(t \ll n)\)</span> 。不妨假设含有 <span class="math inline">\(m\)</span> 个样本数据 <span class="math inline">\(\left\{x^{(1)}, x^{(2)}, \cdots,
x^{(m)}\right\}\)</span>, 其中 <span class="math inline">\(x^{(i)} \in
X\)</span>, 降维后的数据为 <span class="math inline">\(\left\{y^{(1)},
y^{(2)}, \cdots, y^{(m)}\right\}, y^{(i)} \in Y\)</span> 。 <span class="math inline">\(S N E\)</span>
是<strong>先将欧几里得距离转化为条件概率来表达点与点之间的相似度</strong>,
即首先是计算条件概 率 <span class="math inline">\(p_{j \mid i}\)</span>,
其正比于 <span class="math inline">\(x^{(i)}\)</span> 和 <span class="math inline">\(x^{(j)}\)</span> 之间的相似度, <span class="math inline">\(p_{j \mid i}\)</span> 的计算公式为: <span class="math display">\[
p_{j \mid i}=\frac{\exp
\left(-\frac{\left\|x^{(i)}-x^{(j)}\right\|^{2}}{2
\sigma_{i}^{2}}\right)}{\sum_{k \neq i} \exp
\left(-\frac{\left\|x^{(i)}-x^{(k)}\right\|^{2}}{2
\sigma_{i}^{2}}\right)}
\]</span> 在这里引入了一个参数 <span class="math inline">\(\sigma_{i}\)</span>, 对于不同的数据点 <span class="math inline">\(x^{(i)}\)</span> 取值亦不相同,
因为我们关注的是不同数据 点两两之间的相似度, 故可设置 <span class="math inline">\(p_{i \mid i}=0\)</span> 。对于低维度下的数据点
<span class="math inline">\(y^{(i)}\)</span>, 通过条件概率 <span class="math inline">\(q_{j \mid i}\)</span> 来 刻画 <span class="math inline">\(y^{(i)}\)</span> 与 <span class="math inline">\(y^{(j)}\)</span> 之间的相似度, <span class="math inline">\(q_{j \mid i}\)</span> 的计算公式为: <span class="math display">\[
q_{j \mid i}=\frac{\exp
\left(-\left\|y^{(i)}-y^{(j)}\right\|^{2}\right)}{\sum_{k \neq i} \exp
\left(-\left\|y^{(i)}-y^{(k)}\right\|^{2}\right)}
\]</span> 同理, 设置 <span class="math inline">\(q_{i \mid i}=0\)</span>
。 如果降维的效果比较好, 局部特征保留完整, 那么有 <span class="math inline">\(p_{i \mid j}=q_{i \mid j}\)</span> 成立,
因此通过优化两个分布之 间的 <strong><span class="math inline">\(K
L\)</span> 散度构造出的损失函数为</strong>: <span class="math display">\[
C\left(y^{(i)}\right)=\sum_{i} K L\left(P_{i} \| Q_{i}\right)=\sum_{i}
\sum_{j} p_{j \mid i} \log \frac{p_{j \mid i}}{q_{j \mid i}}
\]</span> 这里的 <span class="math inline">\(P_{i}\)</span>
表示在给定高维数据点 <span class="math inline">\(x^{(i)}\)</span> 时,
其他所有数据点的条件概率分布; <span class="math inline">\(Q_{i}\)</span>
则表示在给定 低维数据点 <span class="math inline">\(y^{(i)}\)</span> 时,
其他所有数据点的条件概率分布。从损失函数可以看出, 当 <span class="math inline">\(p_{j \mid i}\)</span> 较大 <span class="math inline">\(q_{j \mid i}\)</span> 较小时, 惩罚较高; 而 <span class="math inline">\(p_{j \mid i}\)</span> 较小 <span class="math inline">\(q_{j \mid i}\)</span> 较大时,
惩罚较低。换句话说就是高维空间中两个数据点距 离较近时,
若映射到低维空间后距离较远, 那么将得到一个很高的惩罚; 反之,
高维空间中两个数 据点距离较远时, 若映射到低维空间距离较近,
将得到一个很低的惩罚值。也就是说, <strong><span class="math inline">\(S
N E\)</span> 的 损失函数更关注于局部特征,
而忽视了全局结构</strong>。</p>
<h4><span id="13-目标函数求解">1.3 目标函数求解</span></h4>
<h4><span id="14-对称性-sne">1.4 对称性-SNE</span></h4>
<p><strong>优化 <span class="math inline">\(K L(P \| Q)\)</span>
的一种替换思路是使用联合概率分布来替换条件概率分布</strong>, 即 <span class="math inline">\(P\)</span> 是高维空间里数据点的联合概 率分布,
<span class="math inline">\(Q\)</span>
是低维空间里数据点的联合概率分布，此时的损失函数为: <span class="math display">\[
C\left(y^{(i)}\right)=K L(P \| Q)=\sum_i \sum_j p_{i j} \log \frac{p_{i
j}}{q_{i j}}
\]</span> 同样的 <span class="math inline">\(p_{i i}=q_{i i}=0\)</span>
，这种改进下的 <span class="math inline">\(S N E\)</span> 称为对称 <span class="math inline">\(S N E\)</span> ，因为它的先验假设为对 <span class="math inline">\(\forall i\)</span> 有 <span class="math inline">\(p_{i j}=p_{j i}, q_{i j}=q_{j i}\)</span>
成立，故概率分布可以改写成: <span class="math display">\[
p_{i j}=\frac{\exp \left(-\frac{\left\|x^{(i)}-x^{(j)}\right\|^2}{2
\sigma^2}\right)}{\sum_{k \neq l} \exp
\left(-\frac{\left\|x^{(k)}-x^{(l)}\right\|^2}{2 \sigma^2}\right)} \quad
q_{i j}=\frac{\exp
\left(-\left\|y^{(i)}-y^{(j)}\right\|^2\right)}{\sum_{k \neq l} \exp
\left(-\left\|y^{(k)}-y^{(l)}\right\|^2\right)}
\]</span> 这种改进方法使得表达式简洁很多, 但是容易受到异常点数据的影响,
为了解决这个问题通过对联合概率分布定义修正为： <span class="math inline">\(p_{i j}=\frac{p_{j \mid i}+p_{i \mid
j}}{2}\)</span>, 这保证了 <span class="math inline">\(\sum_j p_{i
j}&gt;\frac{1}{2 m}\)</span> ，使得每个点对于损失函数都会有贡献。对称
<span class="math inline">\(S N E\)</span> 最大的 优点是简化了梯度计算,
梯度公式改写为: <span class="math display">\[
\frac{\partial C\left(y^{(i)}\right)}{\partial y^{(i)}}=4
\sum_j\left(p_{i j}-q_{i j}\right)\left(y^{(i)}-y^{(j)}\right)
\]</span> 研究表明, 对称 <span class="math inline">\(S N E\)</span> 和
<span class="math inline">\(S N E\)</span> 的效果差不多,
有时甚至更好一点。</p>
<h4><span id="15-t-sne">1.5 t-SNE</span></h4>
<p><span class="math inline">\(t-S N E\)</span> 在对称 <span class="math inline">\(S N E\)</span> 的改进是,
首先通过在高维空间中使用高斯分布将距离转换为概率分布，然后<strong>在低维空间
中，使用更加偏重长尾分布的方式来将距离转换为概率分布，使得高维度空间中的中低等距离在映射后能够有一个
较大的距离</strong>。</p>
<p><img src="https://pic4.zhimg.com/80/v2-928a3ada308128f26b719d510a728fbb_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p>从图中可以看到，在没有异常点时, <span class="math inline">\(t\)</span>
分布与高斯分布的拟合结果基本一致。而在第二张图中, 出现了部分异常点,
由于高斯分布的尾部较低, 对异常点比较敏感, 为了照顾这些异常点,
高斯分布的拟合结果偏离了大多数样本所在位置,
方差也较大。<strong>相比之下, <span class="math inline">\(t\)</span>
分布的尾部较高, 对异常点不敏感, 保证了其鲁棒性, 因此拟合结果更为合理,
较好的捕获了数据的全局特征。</strong></p>
<p>使用 <span class="math inline">\(t\)</span> 分布替换高斯分布之后
<span class="math inline">\(q_{i j}\)</span> 的变化如下: <span class="math display">\[
q_{i
j}=\frac{\left(1+\left\|y^{(i)}-y^{(j)}\right\|^2\right)^{-1}}{\sum_{k
\neq l}\left(1+\left\|y^{(i)}-y^{(j)}\right\|^2\right)^{-1}}
\]</span> 此外，随着自由度的逐渐增大, <span class="math inline">\(t\)</span>
分布的密度函数逐渐接近标准正态分布，因此在计算梯度方面会简单很多, 优
化后的梯度公式如下: <span class="math display">\[
\frac{\partial C\left(y^{(i)}\right)}{\partial y^{(i)}}=4
\sum_j\left(p_{i j}-q_{i
j}\right)\left(y^{(i)}-y^{(j)}\right)\left(1+\left\|y^{(i)}-y^{(j)}\right\|^2\right)^{-1}
\]</span> 总的来说, <span class="math inline">\(t-S N E\)</span>
的梯度更新具有以下两个优势： -
<strong>对于低维空间中不相似的数据点，用一个较小的距离会产生较大的梯度让这些数据点排斥开来;</strong>
-
<strong>这种排斥又不会无限大，因此避免了不相似的数据点距离太远。</strong></p>
<h5><span id="t-s-n-e-算法其实就是在-s-n-e-算法的基础上增加了两个改进"><span class="math inline">\(t-S N E\)</span> 算法其实就是在 <span class="math inline">\(S N E\)</span> 算法的基础上增加了两个改进:</span></h5>
<ul>
<li>把 <span class="math inline">\(S N E\)</span> 修正为对称 <span class="math inline">\(S N E\)</span> ，提高了计算效率,
效果稍有提升;</li>
<li>在低维空间中采用了 <span class="math inline">\(t\)</span>
分布替换原来的高斯分布，解决了高维空间映射到低维空间所产生的拥挤问题,
优化 了 <span class="math inline">\(S N E\)</span>
过于关注局部特征而忽略全局特征的问题。</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>降维与度量学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>降维</tag>
        <tag>t-SNE</tag>
      </tags>
  </entry>
  <entry>
    <title>降维（4）AutoEncoder</title>
    <url>/posts/F3RYP7/</url>
    <content><![CDATA[<h3><span id="autoencoder">AutoEncoder</span></h3>
<blockquote>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/80377698">【全】一文带你了解自编码器（<em>AutoEncoder</em>）</a></li>
</ul>
</blockquote>
<p>理解为：（下图）高维数据（左测蓝色）通过某种网络变成低位数据（中间红色）后，又经过某种网络变回高维数据（右侧蓝色）。数据经过该模型前后没有变化，而中间的低维数据完全具有输入输出的高维数据的全部信息，所以可以用低维数据代表高维数据。</p>
<p>之所以叫AutoEncoder，而不叫AutoEncoderDecoder，是因为训练好之后只有encoder部分有用，<a href="https://www.zhihu.com/search?q=decoder&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22157482881%22%7D">decoder</a>部分就不用了。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221552166.jpg" alt="img" style="zoom: 67%;"></p>
<p>进入深度学习的思路之后，编码的网络是开放的，可以自由设计的。一个思路是端到端，将网络的输出设为你任务要的结果（如类别、序列等），<strong>过程中的某层嵌入都可以作为降维的低维结果</strong>。当然，这种低维结果其实是模型的副产品，因为任务已经解决。比如bert模型得到（中文的）字嵌入。</p>
<h4><span id="优点">优点：</span></h4>
<ul>
<li>能够学习到非线性特性</li>
<li>降低数据维度</li>
</ul>
<h4><span id="缺点">缺点：</span></h4>
<ul>
<li>训练的<strong>计算成本高</strong></li>
<li><strong>可解释性较差</strong></li>
<li>背后的数学知识复杂</li>
<li>容易产生<strong>过度拟合</strong>的问题，尽管可以通过引入正则化策略缓解</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>降维与度量学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>降维</tag>
        <tag>AutoEncoder</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐算法（1）FM算法</title>
    <url>/posts/39Y47BA/</url>
    <content><![CDATA[<h3><span id="一-fm-算法">一、FM 算法</span></h3>
<blockquote>
<p>一文读懂FM模型：https://zhuanlan.zhihu.com/p/109980037</p>
<p><strong>FM算法简单梳理</strong>🍈:
https://zhuanlan.zhihu.com/p/73798236</p>
<p>准确得预估ctr，对于提高流量得价值，增加广告收入有重要作用。业界常用得方法：人工特征+LR，gbdt，LR,FM,FFM。这些模型中FM、FFM表现突出，今天我们就来看看学习FM，下一篇我们在学习FFM。</p>
</blockquote>
<p><strong>FM（factor
Machine，因子分解机）算法是一种基于矩阵分解的机器学习算法，是为了解决大规模稀疏矩阵中特征组合问题。</strong></p>
<p><strong>作用</strong>：</p>
<ul>
<li><p>特征组合是许多机器学习建模过程中遇到的问题，如果直接建模，可能忽略特征与特征之间的关联信息，因此，可通通过构建新的交叉特征
这一特征组合方式提高模型效果。其实就是<strong>增加特征交叉项</strong>。</p>
<blockquote>
<p>在一般的线性模型中，是各个特征独立思考的，没有考虑到特征之间的相互关系。但是实际上，大量特征之间是关联。
一般女性用户看化妆品服装之类的广告比较多，而男性更青睐各种球类装备。那很明显，女性这个特征与化妆品类服装类商品有很大的关联性，男性这个特征与球类装备的关联性更为密切。如果我们能将这些有关联的特征找出来，显然是很有意义的。</p>
</blockquote></li>
<li><p>高维的稀疏矩阵是实际工程中常见的问题，并直接会导致计算量过大，<strong>特征权重更新缓慢</strong>。</p>
<blockquote>
<p>而FM的优势，就是在于这两方面问题的处理。首先是特征组合，通过两两特征组合，引入交叉特征，提高模型得分。其次是高维灾难，通过引入隐向量，对特征参数进行估计。</p>
<p>总结FM的优点：可以在非常稀疏的数据中进行合理的参数估计；FM模型的时间复杂度是线性的；FM是一个通用模型，它可以用于任何特征为实值的情况；同时解决了特征组合问题。</p>
</blockquote></li>
</ul>
<p><strong>优势</strong>：</p>
<ul>
<li>可以在非常稀疏的数据中，进行合理的参数估计</li>
<li>FM模型的复杂度是线性的，优化效果好，不需要像svm一样依赖于支持向量</li>
<li>FM是一个通用的模型，他咳哟用于任何特征为实值得情况。而其他得因式分解模型只能用于一些输入数据比较固定得情况。</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-7f85bd0c6cc1210e14d18889b651cd81_1440w.jpg?source=172ae18b" alt="FM算法简单梳理🍈" style="zoom: 50%;"></p>
<h4><span id="11-fm-特征组合">1.1 FM 特征组合</span></h4>
<p><strong>实对称矩阵分解求解</strong>: <span class="math inline">\(F
\mathrm{FM}\)</span> 为每个特征 <span class="math inline">\(\mathrm{i}\)</span> 引入隐向量 <span class="math inline">\(v_i\)</span>,
用两个特征隐向量的内积表示这两个特征的权重, 即 组合特征 <span class="math inline">\(x_i . x_j\)</span> 的权重为 <span class="math inline">\(\left\langle v_i, v_j\right\rangle\)</span> 。</p>
<p>在传统的线性模型中,
各个特征之间都是独立考虑的，并没有涉及到特征与特征之间的交互关系，但实际上大量的
特征之间是相互关联的。如何寻找相互关联的特征, 基于上述思想 <span class="math inline">\(F M\)</span> 算法应运而生。传统的线性模型为：
<span class="math display">\[
y=w_0+\sum_{i=1}^n w_i x_i
\]</span> <strong>在传统的线性模型的基础上中引入特征交叉项</strong>可得
<span class="math display">\[
y=w_0+\sum_{i=1}^n w_i x_i+\sum_{i=1}^{n-1} \sum_{j=i+1}^n w_{i j} x_i
x_j
\]</span> 在数据非常稀疏的情况下很难满足 <span class="math inline">\(x_i
、 x_j\)</span> 都不为 0 , 这样将会导致 <span class="math inline">\(w_{i
j}\)</span> 不能够通过训练得到, 因此无法进行相
应的参数估计。<strong>可以发现参数矩阵 <span class="math inline">\(w\)</span> 是一个实对称矩阵, <span class="math inline">\(w_{i j}\)</span>
可以使用矩阵分解的方法求解，通过引入辅助向量 <span class="math inline">\(V\)</span></strong> 。 <span class="math display">\[
V=\left[\begin{array}{ccccc}
v_{11} &amp; v_{12} &amp; v_{13} &amp; \cdots &amp; v_{1 k} \\
v_{21} &amp; v_{22} &amp; v_{23} &amp; \cdots &amp; v_{2 k} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
v_{n 1} &amp; v_{n 2} &amp; v_{n 3} &amp; \cdots &amp; v_{n k}
\end{array}\right]=\left[\begin{array}{c}
\mathbf{v}_1 \\
\mathbf{v}_2 \\
\vdots \\
\mathbf{v}_n
\end{array}\right]
\]</span> 然后用 <span class="math inline">\(w_{i j}=\mathbf{v}_i
\mathbf{v}_j^T\)</span> 对 <span class="math inline">\(w\)</span>
进行分解 <span class="math display">\[
w=V V^T=\left[\begin{array}{c}
\mathbf{v}_1 \\
\mathbf{v}_2 \\
\vdots \\
\mathbf{v}_n
\end{array}\right]\left[\begin{array}{llll}
\mathbf{v}_1^T &amp; \mathbf{v}_2^T &amp; \ldots &amp; \mathbf{v}_n^T
\end{array}\right]
\]</span> 综上可以发现原始模型的二项式参数为 <span class="math inline">\(\frac{n(n-1)}{2}\)</span> 个, 现在减少为 <span class="math inline">\(k n(k \ll n)\)</span> 个。引入辅助向量 <span class="math inline">\(V\)</span> 最为重要的 一点是使得 <span class="math inline">\(x_t x_i\)</span> 和 <span class="math inline">\(x_i x_j\)</span> 的参数不再相互独立,
这样就能够在样本数据稀疏的情况下合理的估计模型交叉项的参 数 <span class="math display">\[
\begin{aligned}
\left\langle\mathbf{v}_t, \mathbf{v}_i\right\rangle &amp; =\sum_{f=1}^k
\mathbf{v}_{t f} \cdot \mathbf{v}_{i f} \\
\left\langle\mathbf{v}_i, \mathbf{v}_j\right\rangle &amp; =\sum_{f=1}^k
\mathbf{v}_{i f} \cdot \mathbf{v}_{j f}
\end{aligned}
\]</span> <span class="math inline">\(x_t x_i\)</span> 和 <span class="math inline">\(x_i x_j\)</span> 的参数分别为 <span class="math inline">\(\left\langle\mathbf{v}_t,
\mathbf{v}_i\right\rangle\)</span> 和 <span class="math inline">\(\left\langle\mathbf{v}_i,
\mathbf{v}_j\right\rangle\)</span>, 它们之间拥有共同项 <span class="math inline">\(\mathbf{v}_i\)</span>, 即所有包含 <span class="math inline">\(\mathbf{v}_i\)</span> 的非零组合特征的
样本都可以用来学习隐向量 <span class="math inline">\(\mathbf{v}_i\)</span>, 而原始模型中 <span class="math inline">\(w_{t i}\)</span> 和 <span class="math inline">\(w_{i j}\)</span> 却是相互独立的,
这在很大程度上避免了数据稀疏造
成的参数估计不准确的影响。因此原始模型可以改写为最终的FM算法。 <span class="math display">\[
y=w_0+\sum_{i=1}^n w_i x_i+\sum_{i=1}^{n-1}
\sum_{j=i+1}^n\left\langle\mathbf{v}_i, \mathbf{v}_j\right\rangle x_i
x_j
\]</span></p>
<p>由于求解上述式子的时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2%29" alt="[公式]">
，可以看出主要是最后一项计算比较复杂，因此从数学上对该式最后一项进行一些改写可以把时间复杂度降为
<img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28kn%29" alt="[公式]"></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bequation%7D+%5Cbegin%7Baligned%7D+%26+%5Csum_%7Bi%3D1%7D%5E%7Bn-1%7D+%5Csum_%7Bj%3Di%2B1%7D%5E%7Bn%7D%5Cleft%5Clangle%5Cmathbf%7Bv%7D_%7Bi%7D%2C+%5Cmathbf%7Bv%7D_%7Bj%7D%5Cright%5Crangle+x_%7Bi%7D+x_%7Bj%7D+%5C%5C%3D%26+%5Cfrac%7B1%7D%7B2%7D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%5Cleft%5Clangle%5Cmathbf%7Bv%7D_%7Bi%7D%2C+%5Cmathbf%7Bv%7D_%7Bj%7D%5Cright%5Crangle+x_%7Bi%7D+x_%7Bj%7D-%5Cfrac%7B1%7D%7B2%7D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cleft%5Clangle%5Cmathbf%7Bv%7D_%7Bi%7D%2C+%5Cmathbf%7Bv%7D_%7Bi%7D%5Cright%5Crangle+x_%7Bi%7D+x_%7Bi%7D+%5C%5C%3D%26+%5Cfrac%7B1%7D%7B2%7D%5Cleft%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Csum_%7Bj%3D1%7D%5E%7Bn%7D+%5Csum_%7Bf%3D1%7D%5E%7Bk%7D+%5Cmathbf%7Bv%7D_%7Bif%7D+%5Cmathbf%7Bv%7D_%7Bjf%7D+x_%7Bi%7D+x_%7Bj%7D-%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Csum_%7Bf%3D1%7D%5E%7Bk%7D+%5Cmathbf%7Bv%7D_%7Bif%7D+%5Cmathbf%7Bv%7D_%7Bif%7D+x_%7Bi%7D+x_%7Bi%7D%5Cright%29+%5C%5C%3D%26+%5Cfrac%7B1%7D%7B2%7D+%5Csum_%7Bf%3D1%7D%5E%7Bk%7D%5Cleft%28%5Cleft%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Cmathbf%7Bv%7D_%7Bif%7D+x_%7Bi%7D%5Cright%29%5Cleft%28%5Csum_%7Bj%3D1%7D%5E%7Bn%7D+%5Cmathbf%7Bv%7D_%7Bjf%7D+x_%7Bj%7D%5Cright%29-%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Cmathbf%7Bv%7D_%7Bif%7D%5E%7B2%7D+x_%7Bi%7D%5E%7B2%7D%5Cright%29+%5C%5C%3D%26+%5Cfrac%7B1%7D%7B2%7D+%5Csum_%7Bf%3D1%7D%5E%7Bk%7D%5Cleft%28%5Cleft%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Cmathbf%7Bv%7D_%7Bif%7D+x_%7Bi%7D%5Cright%29%5E%7B2%7D-%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Cmathbf%7Bv%7D_%7Bif%7D%5E%7B2%7D+x_%7Bi%7D%5E%7B2%7D%5Cright%29+%5Cend%7Baligned%7D+%5Cend%7Bequation%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>第一步：<strong>对称矩阵中上三角的内积之和等于
整个向量的乘积和减去对角线上元素的和</strong>。</p>
<p>至此, FM算法的公式推导结束了, 为了更直观的了解怎么计算的,
举下面一个例子: 例如 <span class="math display">\[
V=\left[\begin{array}{l}
V 1 \\
V 2 \\
V 3
\end{array}\right]=\left[\begin{array}{lll}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6 \\
7 &amp; 8 &amp; 9
\end{array}\right] \Rightarrow W=V * V^T \Rightarrow
W=\left[\begin{array}{ccc}
14 &amp; 32 &amp; 50 \\
32 &amp; 77 &amp; 122 \\
50 &amp; 122 &amp; 194
\end{array}\right] \Rightarrow W=V * V^T
\]</span> 可推出下面公式: <span class="math display">\[
\begin{gathered}
\sum_i^3 \sum_j^3 w_{i j} * x_i x_j= \\
14 * x_1 x_1+32 * x_1 x_2+50 * x_1 * x_3 \\
32 * x_2 x_1+77 * x_2 x_2+122 * x_2 * x_3 \\
50 * x_3 x_1+122 * x_3 x_2+194 * x_3 * x_3
\end{gathered}
\]</span>
<strong>而FM公式的第二个因子就是以上展开式"上三角“的元素。</strong></p>
<h4><span id="12-参数更新">1.2 参数更新</span></h4>
<p>采用随机梯度下降法SGD求解参数： <span class="math display">\[
\begin{gathered}
\frac{\partial y}{\partial w_0}=1 \\
\frac{\partial y}{\partial w_i}=x_i \\
\frac{\partial y}{\partial v_i f}=x_i \sum_{j=1}^n v_{j, f} x_j-v_{i, f}
x_i^2
\end{gathered}
\]</span> 由上式可知: 参数 <span class="math inline">\(v_{i, f}\)</span>
只需要样本的 <span class="math inline">\(x_i\)</span> 特征非零即可,
因此FM算法适用于稀疏场景, 并且FM算法的训练和预测 都可以在线性时间内完成,
FM是一个非常高效的算法。</p>
<h4><span id="13-fm算法小结">1.3 FM算法小结</span></h4>
<ul>
<li>FM算法提升了参数学习效率和特征交叉后模型预估的能力。</li>
<li>FM算法降低了因数据稀疏，导致特征交叉项参数学习不充分的影响；</li>
<li>模型的组合特征的参数在nk级别，通过公式推导，模型复杂度为<span class="math inline">\(O(nk)\)</span>
，因此模型可以非常高效的进行训练和预测。</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>推荐算法</category>
      </categories>
  </entry>
  <entry>
    <title>推荐算法（2）【draft】从LR到DeepFM</title>
    <url>/posts/3PBRXG4/</url>
    <content><![CDATA[<h3><span id="一-特征交叉-从lr到deepfm">一、特征交叉-从LR到DeepFM</span></h3>
<p><strong>提到LR-&gt;FM-&gt;FFM-&gt;Wide &amp;
Deep-&gt;DeepFM这一发展，必然离不开点击率CTR(click-through
rate)和转化率CVR(conversion rate)。</strong></p>
<p>这里再补充一下从MF到FM，矩阵分解MF(Matrix
Factorization)基本原理：</p>
<p><img src="https://pic4.zhimg.com/v2-bc8928c25ddfd4e6baefccaac8218bcb_b.jpg" alt="img" style="zoom:50%;"></p>
<p><img src="https://pic2.zhimg.com/v2-1600655df8413c5c12c0eb9fe0275461_b.jpg" alt="img" style="zoom:50%;"></p>
<p>主要是将用户-物品矩阵分解为用户矩阵(实质为用户的embedding矩阵)和物品矩阵(实质为物品的embedding矩阵)，有了<strong>用户表征向量</strong>和<strong>物品表征向量</strong>我们就可以计算任意用户和物品之间的联系。</p>
<h4><span id="11-lr-gtfm">1.1 LR-&gt;FM</span></h4>
<p><strong>线性模型：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Ctilde%7By%7D%3Dw_%7B0%7D%2B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7Bw_%7Bi%7Dx_%7Bi%7D%7D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>从公式中我们就可以看出，线性模型中默认假设特征之间是相互独立的，但是在现实中基本不可能存在，因此线性模型会丢失很多组合信息。</p>
<p><strong>多项式模型：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Ctilde%7By%7D%3Dw_%7B0%7D%2B%5Csum_%7Bi%7D%7Bw_%7Bi%7Dx_%7Bi%7D%7D%2B%5Csum_%7Bi%7D%7B%5Csum_%7Bj%3Ci%7D%7Bw_%7Bij%7Dx_%7Bi%7Dx_%7Bj%7D%7D%7D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>多项式模型中增加了特征的组合信息，但是又引入了新的问题，参数爆炸，复杂度太高，在实际推荐中特征可能是上万甚至更高维，单单二阶的特征交叉就是
<img src="https://www.zhihu.com/equation?tex=n%5E%7B2%7D" alt="[公式]">
，更不用说更高阶特征交叉。此外，在CTR任务中，特征是特别稀疏的（如图2），进行特征交叉以后也都是0，这将导致模型训练不能充分。</p>
<figure>
<img src="https://pic4.zhimg.com/v2-9e67de04a67911ec78c8166da0e62153_b.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Ctilde%7By%7D%3Dw_%7B0%7D%2B%5Csum_%7Bi%7D%7Bw_%7Bi%7Dx_%7Bi%7D%7D%2B%5Csum_%7Bi%7D%7B%5Csum_%7Bj%3Ci%7D%7B%3Cv_%7Bi%7D%2C+v_%7Bj%7D%3Ex_%7Bi%7Dx_%7Bj%7D%7D%7D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><strong>FM主要的优化有两个方面：</strong></p>
<p>（1）<strong>将复杂度从 <img src="https://www.zhihu.com/equation?tex=n%5E2" alt="[公式]"> 降到了
<img src="https://www.zhihu.com/equation?tex=kn" alt="[公式]"> <img src="https://www.zhihu.com/equation?tex=%5Cleft%28+k+%5Cll+n+%5Cright%29" alt="[公式]"></strong> ；</p>
<p>（2）可以在稀疏数据中学习到组合特征，甚至是那些数据中没有观测值的组合特征。</p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>推荐算法</category>
      </categories>
  </entry>
  <entry>
    <title>推荐算法（0）【draft】概述</title>
    <url>/posts/2Q49YXX/</url>
    <content><![CDATA[<h2><span id="推荐算法">推荐算法</span></h2>
<blockquote>
<p>百度飞浆，推荐系统：https://paddlepedia.readthedocs.io/en/latest/tutorials/recommendation_system/recommender_system.html#id2</p>
<p><strong>为什么LR可以用来做CTR预估？</strong> - AI牛的回答 - 知乎
https://www.zhihu.com/question/23652394/answer/2352984912</p>
<p><strong>推荐系统中常用的embedding方法</strong> - 十三的文章 - 知乎
https://zhuanlan.zhihu.com/p/476673607</p>
</blockquote>
<h3><span id="一-背景介绍">一、背景介绍</span></h3>
<h4><span id="11-推荐系统的产生">1.1 推荐系统的产生</span></h4>
<p>在网络技术不断发展和电子商务规模不断扩大的背景下，商品数量和种类快速增长，用户需要花费大量时间才能找到自己想买的商品，这就是信息超载问题。为了解决这个难题，个性化推荐系统（Recommender
System）应运而生。</p>
<p><strong>个性化推荐系统是信息过滤系统（Information Filtering
System）的子集</strong>，它可以用在很多领域，如电影、音乐、电商和 Feed
流推荐等。个性化推荐系统通过分析、挖掘用户行为，发现用户的个性化需求与兴趣特点，将用户可能感兴趣的信息或商品推荐给用户。与搜索引擎不同，个性化推荐系统不需要用户准确地描述出自己的需求，而是根据用户的历史行为进行建模，主动提供满足用户兴趣和需求的信息。</p>
<p>1994年明尼苏达大学推出的GroupLens系统一般被认为是个性化推荐系统成为一个相对独立的研究方向的标志。该系统首次提出了基于协同过滤来完成推荐任务的思想，此后，基于该模型的协同过滤推荐引领了个性化推荐系统十几年的发展方向。</p>
<h4><span id="12-推荐系统的方法">1.2 推荐系统的方法</span></h4>
<p>传统的个性化推荐系统方法主要有：</p>
<ul>
<li><strong>协同过滤推荐</strong>（Collaborative Filtering
Recommendation）：该方法是应用最广泛的技术之一，需要收集和分析用户的历史行为、活动和偏好。它通常可以分为两个子类：基于用户
（User-Based）的推荐和基于物品（Item-Based）的推荐。该方法的一个关键优势是它不依赖于机器去分析物品的内容特征，因此它无需理解物品本身也能够准确地推荐诸如电影之类的复杂物品；缺点是对于没有任何行为的新用户存在冷启动的问题，同时也存在用户与商品之间的交互数据不够多造成的稀疏问题。值得一提的是，社交网络或地理位置等上下文信息都可以结合到协同过滤中去。</li>
<li><strong>基于内容过滤推荐</strong>（Content-based Filtering
Recommendation）：该方法利用商品的内容描述，抽象出有意义的特征，通过计算用户的兴趣和商品描述之间的相似度，来给用户做推荐。优点是简单直接，不需要依据其他用户对商品的评价，而是通过商品属性进行商品相似度度量，从而推荐给用户所感兴趣商品的相似商品；缺点是对于没有任何行为的新用户同样存在冷启动的问题。</li>
<li><strong>组合推荐（</strong>Hybrid
Recommendation）：运用不同的输入和技术共同进行推荐，以弥补各自推荐技术的缺点。
近些年来，深度学习在很多领域都取得了巨大的成功。学术界和工业界都在尝试将深度学习应用于个性化推荐系统领域中。深度学习具有优秀的自动提取特征的能力，能够学习多层次的抽象特征表示，并对异质或跨域的内容信息进行学习，可以一定程度上处理个性化推荐系统冷启动问题</li>
</ul>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>推荐算法</category>
      </categories>
  </entry>
  <entry>
    <title>度量学习（1）KNN</title>
    <url>/posts/5BWKZW/</url>
    <content><![CDATA[<h3><span id="一-什么是knnkd树-siftbbf算法">一、什么是KNN【KD树 +
SIFT+BBF算法】</span></h3>
<h4><span id="11-knn的通俗解释">1.1 KNN的通俗解释</span></h4>
<p>何谓K近邻算法，即K-Nearest Neighbor
algorithm，简称KNN算法，单从名字来猜想，可以简单粗暴的认为是：K个最近的邻居，当K=1时，算法便成了最近邻算法，即寻找最近的那个邻居。</p>
<p>用官方的话来说，所谓K近邻算法，即是给定一个训练数据集，对新的输入实例，<strong>在训练数据集中找到与该实例最邻近的K个实例（也就是上面所说的K个邻居），这K个实例的多数属于某个类，就把该输入实例分类到这个类中。</strong></p>
<p>​ <a href="https://camo.githubusercontent.com/f0eabe33161ae7f977f082590a3690be147319df428ad1695c79127ad406729d/68747470733a2f2f6a756c796564752d696d672e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f717565736261736536343135353238333936333437323839353636302e6a7067"><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232118382.jpeg" alt="img"></a></p>
<p>​ <a href="https://camo.githubusercontent.com/a8942eed547ab4f08494126b0d2e5480fdfc795252e4a34a956c2b959cb5c6b8/68747470733a2f2f6a756c796564752d696d672e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f717565736261736536343135353238333936363635343430333634362e706e67"><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304232118849.png" alt="img"></a></p>
<p>如上图所示，有两类不同的样本数据，分别用蓝色的小正方形和红色的小三角形表示，而图正中间的那个绿色的圆所标示的数据则是待分类的数据。也就是说，现在，我们不知道中间那个绿色的数据是从属于哪一类（蓝色小正方形or红色小三角形），KNN就是解决这个问题的。</p>
<p>如果<strong>K=3</strong>，绿色圆点的最近的3个邻居是2个红色小三角形和1个蓝色小正方形，少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于<strong>红色</strong>的三角形一类。</p>
<p>如果<strong>K=5</strong>，绿色圆点的最近的5个邻居是2个红色三角形和3个蓝色的正方形，还是少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于<strong>蓝色</strong>的正方形一类。</p>
<p><strong>于此我们看到，当无法判定当前待分类点是从属于已知分类中的哪一类时，我们可以依据统计学的理论看它所处的位置特征，衡量它周围邻居的权重，而把它归为(或分配)到权重更大的那一类。这就是K近邻算法的核心思想。</strong></p>
<h4><span id="12-近邻的距离度量">1.2 近邻的距离度量</span></h4>
<p>我们看到，K近邻算法的核心在于找到实例点的邻居，这个时候，问题就接踵而至了，如何找到邻居，邻居的判定标准是什么，用什么来度量。这一系列问题便是下面要讲的距离度量表示法。</p>
<p><strong>有哪些距离度量的表示法</strong>(普及知识点，可以跳过)：</p>
<h5><span id="121-欧式距离">1.2.1 欧式距离</span></h5>
<p>欧氏距离, 最常见的两点之间或多点之间的距离表示法,
又称之为欧几里得度量, 它定义于欧几里得空间中, 如点 <span class="math inline">\(x=(x 1, \ldots, x n)\)</span> 和 <span class="math inline">\(y=(y 1, \ldots, y n)\)</span> 之间的距离为: <span class="math display">\[
d(x,
y)=\sqrt{\left(x_1-y_1\right)^2+\left(x_2-y_2\right)^2+\ldots+\left(x_n-y_n\right)^2}=\sqrt{\sum_{i=1}^n\left(x_i-y_i\right)^2}
\]</span> 二维平面上两点 <span class="math inline">\(a(x 1, y
1)\)</span> 与 <span class="math inline">\(b(x 2, y 2)\)</span>
间的欧氏距离: <span class="math display">\[
d_{12}=\sqrt{\left(x_1-x_2\right)^2+\left(y_1-y_2\right)^2}
\]</span> 三维空间两点 <span class="math inline">\(a(x 1, y 1, z
1)\)</span> 与 <span class="math inline">\(b(x 2, y 2, z 2)\)</span>
间的欧氏距离: <span class="math display">\[
d_{12}=\sqrt{\left(x_1-x_2\right)^2+\left(y_1-y_2\right)^2+\left(z_1-z_2\right)^2}
\]</span> 两个n维向量 <span class="math inline">\(a(x 11, \times 12,
\ldots, x 1 n)\)</span> 与 <span class="math inline">\(b(\times 21,
\times 22, \ldots, \times 2 n)\)</span> 间的欧氏距离: <span class="math display">\[
d_{12}=\sqrt{\sum_{k=1}^n\left(x_{1 k}-x_{2 k}\right)^2}
\]</span> 也可以用表示成向量运算的形式:</p>
<h5><span id="122-曼哈顿距离">1.2.2 曼哈顿距离</span></h5>
<p>曼哈顿距离, 我们可以定义曼哈顿距离的正式意义为L1-距离或城市区块距离,
也就是在欧几里得空间的固定
直角坐标系上两点所形成的线段对轴产生的投影的距离总和。例如在平面上, 坐标
<span class="math inline">\((x 1, y 1)\)</span> 的点P1与坐标 <span class="math inline">\((\mathrm{x} 2, \mathrm{y} 2)\)</span>
的点P2的曼哈顿距离为: <span class="math inline">\(\left|x_1-x_2\right|+\left|y_1-y_2\right|\)</span>,
要注意的是, 曼哈顿距离依赖座标系统的转度,
而非系统在座标轴上的平移或映射。</p>
<p>通俗来讲, 想象你在曼哈顿要从一个十字路口开车到另外一个十字路口,
驾驶距离是两点间的直线距离吗? 显 然不是,
除非你能穿越大楼。而实际驾驶距离就是这个“曼哈顿距离”,
此即曼哈顿距离名称的来源, 同时, 曼 哈顿距离也称为城市街区距离(City Block
distance)。</p>
<p>二维平面两点 <span class="math inline">\(a(x 1, y 1)\)</span> 与
<span class="math inline">\(b(x 2, y 2)\)</span> 间的曼哈顿距离 <span class="math display">\[
d_{12}=\left|x_1-x_2\right|+\left|y_1-y_2\right|
\]</span> 两个 <span class="math inline">\(n\)</span> 维向量 <span class="math inline">\(a(x 11, x 12, \ldots, x 1 n)\)</span> 与 <span class="math inline">\(b(x 21, x 22, \ldots, x 2 n)\)</span>
间的曼哈顿距离 <span class="math display">\[
d_{12}=\sum_{k=1}^n\left|x_{1 k}-x_{2 k}\right|
\]</span></p>
<h5><span id="123-切比雪夫距离">1.2.3 切比雪夫距离</span></h5>
<p>切比雪夫距离, 若二个向量或二个点 <span class="math inline">\(\mathrm{p} 、\)</span> and <span class="math inline">\(\mathrm{q}\)</span>, 其座标分别为 <span class="math inline">\(\mathrm{P}\)</span> 及 <span class="math inline">\(\mathrm{qi}\)</span>,
则两者之间的切比雪夫距离定义如 下: <span class="math inline">\(D_{C h e
b y s h e v}(p, q)=\max _i\left(\left|p_i-q_i\right|\right)\)</span></p>
<p>这也等于以下Lp度量的极值： <span class="math inline">\(\lim _{x
\rightarrow \infty}\left(\sum_{i=1}^n\left|p_i-q_i\right|^k\right)^{1 /
k}\)</span>, 因此切比雪夫距离也称为 <span class="math inline">\(\infty\)</span> 度量。</p>
<p>以数学的观点来看, 切比雪夫距离是由一致范数 (uniform norm)
(或称为上确界范数）所衍生的度量, 也 是超凸度量（injective metric
space）的一种。</p>
<p>在平面几何中, 若二点 <span class="math inline">\(\mathrm{p}
\mathrm{q}\)</span> 的直角坐标系坐标为 <span class="math inline">\((x 1,
y 1)\)</span> 及 <span class="math inline">\((x 2, y 2)\)</span>,
则切比雪夫距离为: <span class="math inline">\(D_{C h e s s}=\max
\left(\left|x_2-x_1\right|,\left|y_2-y_1\right|\right)\)</span></p>
<p>玩过国际象棋的朋友或许知道，国王走一步能够移动到相邻的8个方格中的任意一个。那么国王从格子(x1,y1)
走到格子(x2,y2)最少需要多少步? 。你会发现最少步数总是 <span class="math inline">\(\max (|x 2-x 1| ，|y 2-y 1|)\)</span> 步
。有一种类似的 一种距离度量方法叫切比雪夫距离。</p>
<p>二维平面两点 <span class="math inline">\(a(x 1, y 1)\)</span> 与
<span class="math inline">\(b(x 2, y 2)\)</span> 间的切比雪夫距离 :
<span class="math display">\[
d_{12}=\max \left(\left|x_2-x_1\right|,\left|y_2-y_1\right|\right)
\]</span> 两个 <span class="math inline">\(n\)</span> 维向量 <span class="math inline">\(a(x 11, x 12, \ldots, x 1 n)\)</span> 与 <span class="math inline">\(b(x 21, x 22, \ldots, x 2 n)\)</span>
间的切比雪夫距离 : <span class="math display">\[
d_{12}=\max _i\left(\left|x_{1 i}-x_{2 i}\right|\right)
\]</span></p>
<p><strong>简单说来，各种“距离”的应用场景简单概括为：</strong></p>
<ul>
<li><strong>空间：欧氏距离</strong>，</li>
<li><strong>路径：曼哈顿距离，国际象棋国王：切比雪夫距离</strong>，</li>
<li>以上三种的统一形式:闵可夫斯基距离，</li>
<li>加权：标准化欧氏距离，</li>
<li>排除量纲和依存：马氏距离，</li>
<li>向量差距：夹角余弦，</li>
<li><strong>编码差别：汉明距离</strong>，</li>
<li>集合近似度：杰卡德类似系数与距离，</li>
<li>相关：相关系数与相关距离。</li>
</ul>
<h4><span id="13-k值选择">1.3 K值选择</span></h4>
<ol type="1">
<li>如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，<strong>K值的减小就意味着整体模型变得复杂，容易发生过拟合；</strong></li>
<li>如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且<strong>K值的增大就意味着整体的模型变得简单。</strong></li>
<li>K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的累，模型过于简单，忽略了训练实例中大量有用信息。</li>
</ol>
<p>在实际应用中，K值一般取一个比较小的数值，<strong>例如采用交叉验证法（简单来说，就是一部分样本做训练集，一部分做测试集）来选择最优的K值。</strong></p>
<h4><span id="14-knn最近邻分类算法的过程">1.4 KNN最近邻分类算法的过程</span></h4>
<ol type="1">
<li>计算测试样本和训练样本中每个样本点的距离（常见的距离度量有欧式距离，马氏距离等）；</li>
<li>对上面所有的距离值进行排序；</li>
<li>选前 k 个最小距离的样本；</li>
<li>根据这 k 个样本的标签进行投票，得到最后的分类类别；</li>
</ol>
<h3><span id="关于knn的一些问题">关于KNN的一些问题</span></h3>
<ol type="1">
<li><p>在k-means或kNN，我们是用欧氏距离来计算最近的邻居之间的距离。为什么不用<strong>曼哈顿距离</strong>？</p>
<p><strong>答：</strong>我们不用曼哈顿距离，因为它只计算水平或垂直距离，有维度的限制。另一方面，欧式距离可用于任何空间的距离计算问题。因为，数据点可以存在于任何空间，欧氏距离是更可行的选择。例如：想象一下国际象棋棋盘，象或车所做的移动是由曼哈顿距离计算的，因为它们是在各自的水平和垂直方向的运动。</p></li>
<li><p>KD-Tree相比KNN来进行快速图像特征比对的好处在哪里?</p>
<p>答：极大的节约了时间成本．点线距离如果
&gt;　最小点，无需回溯上一层，如果&lt;,则再上一层寻找。</p></li>
</ol>
<h3><span id="参考文献">参考文献</span></h3>
<ol type="1">
<li><a href="https://www.joinquant.com/view/community/detail/dd60bd4e89761b916fe36dc4d14bb272"><font color="blue">KNN与KD树</font></a></li>
<li><a href="https://zhuanlan.zhihu.com/p/23966698"><font color="blue">【数学】kd
树算法之详细篇 - 椰了的文章 - 知乎</font></a></li>
<li><a href="https://www.zhihu.com/question/475072467/answer/2027766449"><font color="blue"><strong>KNN是生成式模型还是判别式的</strong>，为什么？
- 风控算法小白的回答 - 知乎</font></a></li>
</ol>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>降维与度量学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>度量学习</tag>
        <tag>KNN</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐算法（3）DeepFM模型</title>
    <url>/posts/ZFVYEK/</url>
    <content><![CDATA[<h3><span id="一-deepfm">一、DeepFM</span></h3>
<blockquote>
<p>吃透论文——推荐算法不可不看的DeepFM模型 - 梁唐的文章 - 知乎
https://zhuanlan.zhihu.com/p/343343016</p>
</blockquote>
<p><strong>DeepFM: A Factorization-Machine based Neural Network for CTR
Prediction，翻译过来就是DeepFM：一个基于深度神经网络的FM模型。</strong>这篇paper的作者来自<strong>哈工大和华为</strong>，不得不说在人工智能领域的很多论文都是国产的，作为从业者还是非常欣喜能看到这点的。</p>
<h4><span id="11-简介">1.1 简介</span></h4>
<p>对推荐场景来说，CTR是最关键的指标，除了广告系统会按照CTR x
bid来进行排序之外，推荐系统一般都会<strong>严格地按照预估的CTR进行排序</strong>。所以这其中的关键问题就是准确地预估CTR。</p>
<p>常规的推荐系统当中的特征分为四个部分：</p>
<ul>
<li><strong>用户特征</strong>：关于用户的一些信息。比如是男是女，是否是高收入群体，是否是高消费群体，成为平台的用户多久了，偏好平台当中什么类目的商品等等。</li>
<li><strong>商品特征</strong>：关于item的一些信息，比如价格、类目、折扣、评价等等。</li>
<li><strong>上下文特征</strong>：比如当前的时间，是早上还是晚上，比如item展示的位置等等。</li>
<li><strong>用户实时的行为</strong>：比如用户在浏览这个商品之前还看过哪些其他的商品，他登陆平台多久了，等等。</li>
</ul>
<p>显然用户是否会点击某一个item是由以上这四个部分的信息共同作用的，也就是说<strong>商品的特征和用户的特征之间是存在逻辑上的关联的</strong>，我们一般称为特征的交叉。</p>
<p>这些交叉信息往往是隐式的，也就是我们不能直接描述和形容出来的。<strong>人的喜好是很复杂的，我们很难用固定的规则去描述</strong>。所以这就需要模型能有这样的能力去学习这些特征之间的潜在联系，对这些潜在交叉信息把握越好的模型，一般也都拥有越好的效果。</p>
<blockquote>
<p>比如我们分析了主流的app
store市场之后发现，在饭点的时候，用户经常会下载外卖类的app，这说明了app的类别和时间之间存在交叉关系。再比如我们发现年轻的男生往往喜欢设计类游戏，这说明了app的类别与用户的性别之间也存在交叉关系。像是这样的交叉信息还有很多，从Wide
&amp;
Deep模型的经验当中我们可以学到考虑低维和高维交叉特征之后，模型的效果会更好。</p>
</blockquote>
<h4><span id="12-算法">1.2 算法</span></h4>
<p>训练集当中一共有 <span class="math inline">\(n\)</span> 条样本,
每一条样本可以写成 <span class="math inline">\((\chi, y)\)</span>
。其中的 <span class="math inline">\(\chi\)</span> 是一个 <span class="math inline">\(m\)</span> 个field组成的向量, 包含了用户和
item组成的特征。 <span class="math inline">\(y \in\{0,1\}, y=0\)</span>
表示用户没有点击，相反， <span class="math inline">\(y=1\)</span>
表示用户点击。 - 类别特征：比如性别、地理位置、收入情况等等。 -
连续性特征, 比如平均花费、平均停留时间等等</p>
<p>类别特征 (categorical feature) 一般被表示成一个one-hot之后的向量,
而一个连续特征, 一般就是表示它自 己,
当然也可以离散化成one-hot向量。我们把这些特征全部处理完之后,
整个向量会转化成
得x向量变得非常稀疏。所以我们要做的就是在这样特征比较稀疏的样本上简历一个CTR预测模型。</p>
<h4><span id="13-deepfm">1.3 <strong>DeepFM</strong></span></h4>
<p>我们希望能够设计模型能够更好地学习低维和高维特征之间的交互，基于这点，我们在深度模型的基础上结合了FM，推出了DeepFM模型。它的整体结构如下图：</p>
<p><img src="https://pic1.zhimg.com/v2-85cdb2c1ca2716a0b7ec9581e78fb714_b.jpg" alt="img" style="zoom: 67%;"></p>
<p>这张图看起来可能会有点乱，我们可以先忽略一些局部的细节，先从整体上把握。这个模型可以分成两个部分，分别是<strong>FM部分以及Deep部分</strong>。这两个部分的输入是一样的，并没有像Wide
&amp; Deep模型那样做区分。</p>
<ul>
<li>神经网络也就是Deep的部分用来训练这些特征的一维的关联以及联系</li>
<li>FM模型会通过隐藏向量V的形式来计算特征之间的二维交叉的信息。最后一维和二维的信息汇总到一起，进入sigmoid层，获得最终的结果。</li>
</ul>
<p>用公式来表达的话，大概是这样：</p>
<p><span class="math display">\[
\hat{y}=\operatorname{sigmoid}\left(y_{F M}+y_{D N N}\right)
\]</span></p>
<h4><span id="14-fm部分">1.4 <strong>FM部分</strong></span></h4>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20220708115209319.png" alt="image-20220708115209319" style="zoom: 33%;"></p>
<p>FM部分其实就是因子分解机,
我们在之前的文章当中曾经专门剖析过。FM会考虑所有特征之间两两交叉的情况,
相当于人为对左右特征做了交叉。但是由于 <span class="math inline">\(n\)</span> 个特征交叉的组合是 <span class="math inline">\(n^2\)</span> 这个量级, 所以FM设计了一种新的方案,
对 于每一个特征i训练一个向量 <span class="math inline">\(V_i\)</span>,
当i和 <span class="math inline">\(\mathrm{j}\)</span>
两个特征交叉的时候, <strong>通过 <span class="math inline">\(V_i \cdot
V_j\)</span> 来计算两个特征交叉之后的权重</strong>。这样
大大降低了计算的复杂度。 这当中涉及一些公式的推导和计算,
我们在之前的文章当中已经详细推导过了, 这里就不多㥿述了。最终我们可以
得到这部分的公式: <span class="math display">\[
y_{F M}=&lt;w, x&gt;+\sum_{i=1}^d \sum_{j=i+1}^d&lt;V_i, V_j&gt;x_i
\cdot x_j
\]</span></p>
<h4><span id="15-deep部分">1.5 <strong>Deep部分</strong></span></h4>
<p>Deep部分就是经典的<strong>前馈网络</strong>，用来学习特征之间的高维交叉。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261530821.jpg" alt="img" style="zoom: 67%;"></p>
<p>图3展示的就是模型当中Deep这个部分，从图中我们可以看到，<strong>所有的特征都会被转化成embedding向量</strong>作为Deep部分的输入（<strong><font color="red">
每个01向量对应自己的嵌入层，不同向量的嵌入过程相互独立</font></strong>）。CTR预估的模型和图片以及音频处理的模型有一个很大的不同，就是它的维度会更大，并且特征会非常稀疏，还伴有类别连续、混合、聚合的特点。在这种情况下，使用embedding向量来把原始特征当中的信息压缩到低维的向量就是一种比较好的做法了，这样模型的泛化能力会更强，要比全是01组成的multi-hot输入好得多。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261530723.png" alt="image-20220708115609161" style="zoom: 33%;"></p>
<p>这张图展示了这个部分局部的结构，我们可以看到所有特征转成的embedding向量拥有相同的维度k。并且和FM模型当中的维度也是一样的，并且这个<a href="https://www.zhihu.com/search?q=embedding&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22343343016%22%7D">embedding</a>的初始化也是<strong>借用FM当中的二维矩阵V来实现的</strong>。我们都知道V是一个d
x
k的二维矩阵，而模型原始输入是一个d维的01向量，那么和V相乘了之后，自然就转化成了d
x k的embedding了。</p>
<p>这里要注意的一点是，在一些其他DNN做CTR预估的论文当中，会使用预训练的FM模型来进行Deep部分的向量初始化。但这里的做法略有不同，它不是使用训练好的FM来进行<a href="https://www.zhihu.com/search?q=初始化&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22343343016%22%7D">初始化</a>，而是和FM模型的部分共享同样的V。这样做会有两个非常重要的好处：</p>
<ul>
<li>它可以同时学习到低维以及高维的特征交叉信息，预训练的FM来进行向量初始化得到的embedding当中可能只包含了二维交叉的信息。</li>
<li>这样可以避免像是Wide &amp; Deep那样多余的特征工程。</li>
</ul>
<blockquote>
<p>##### <strong>数据选择</strong></p>
<p>我们选择了两份数据用来评估DeepFM与其他模型的性能，一份是Criteo数据集，其中包含了4500w用户的点击数据，由13个连续型特征以及26个类别特征组成。我们把90%做成训练数据，10%做成测试数据。第二份数据是公司内部（华为）的数据，由连续7天用户在华为app
store游戏中心的点击数据组成训练数据（约10亿条），1天的数据作为测试数据。</p>
<p>##### <strong>评估指标</strong></p>
<p>我们主要评估模型的指标有两个，一个是AUC另一个是Logloss（<a href="https://www.zhihu.com/search?q=交叉熵&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22343343016%22%7D">交叉熵</a>）。从这个评估指标上来看是比较中肯的，没有像有一些paper当中自己定义一种新的评估指标。</p>
</blockquote>
<h3><span id="deepfm-qampa">DeepFM Q&amp;A</span></h3>
<h5><span id="deepfm对连续特征的处理">DeepFM对连续特征的处理?</span></h5>
<p>deepfm原文提到，连续变量可以直接作为单个值输入，或者离散化作为一个向量输入。那么目前可获取的包
<a href="https://www.zhihu.com/search?q=deepctr&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22414694288%22%7D">deepctr</a>中的deepfm是怎样处理的？</p>
<p>这里直接看源码，红色方框：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304261530780.jpg" alt="img" style="zoom:50%;"></p>
<p><strong>可以看到连续特征（dense_value）
直接作为DNN的输入，不参与FM的输入。我们也可以连续变量离散化后，同时作为DNN和FM的输入，这样连续变量也和类别变量有二阶特征交互，或许可以带来更多的信息，增强模型表达。</strong></p>
]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
        <category>推荐算法</category>
      </categories>
  </entry>
  <entry>
    <title>2</title>
    <url>/posts/DDBFGD/</url>
    <content><![CDATA[<h2><span id="leveragingstreaming-based-outlier-detection-and-sliceline-to-stop-heavilydistributed-bot-attacks">Leveraging
Streaming-Based Outlier Detection and SliceLine to Stop Heavily
Distributed Bot Attacks</span></h2>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141133299.png" alt="image-20230514113324227" style="zoom: 25%;"></p>
<p><strong>在本篇文章中我们将讨论DataDome公司<sup>[8]</sup>是如何利用<font color="red">基于流的异常值检测和
SliceLine
来快速安全地生成大量可用于阻止恶意流量的规则/签名。</font></strong>虽然机器学习(ML)的使用变得越来越普遍，但在安全环境中规则仍然很重要。事实上，公司已经投资了大量有效的规则引擎，能够快速评估大量规则。此外，规则通常更方便创建、操作和解释，因此在ML方法之外仍然很有价值。</p>
<p>虽然 SliceLine 最初设计用于识别 ML
模型表现不佳的数据子集，但它的使用可以<strong>适应以无监督方式生成大量与攻击相关的规则，即不使用标记数据</strong>。此外，利用机器人检测问题来说明如何使用
SliceLine 即时生成大量恶意签名。</p>
<p>该研究还将展示优化的 SliceLine Python
开源实现，并展示如何将其用于特定但困难的机器人检测子集：<strong>分布式凭证填充攻击</strong>，<strong>攻击者利用数千个受感染的
IP
地址进行攻击和绕过传统的安全机制，例如速率限制策略</strong>。通过一个真实世界的例子，该研究将首先解释如何使用基于流的检测来检测此类攻击，以及该研究如何使用数据建模在服务器端信号（HTTP
标头、TLS 指纹、IP 地址等）上应用 <strong>SliceLine</strong>
来识别并生成与分布式攻击相关的阻止签名。<font color="red">这种方法使该研究能够在去年阻止
59 位客户超过 2.85 亿次恶意登录尝试。</font></p>
<p>最后，该研究将解释这种方法如何推广到除机器人检测之外的其他安全用例，以及如何在不同的规则引擎中使用它。</p>
<span id="more"></span>
<h3><span id="一-说明">一、说明</span></h3>
<p><strong>机器人检测是指识别和区分人类用户和自动化软件程序(Bot：Program
to automate
actions)的过程</strong>。术语“bot”可以指各种程序，包括搜索引擎爬虫和设计用于进行抢购或拒绝服务攻击的恶意bot。</p>
<p>机器人检测很重要，因为机器人可用于各种目的，其中一些可能是有害或不道德的。例如，<strong>机器人可用于进行欺诈活动，如账户接管或凭证填充，从网站中获取敏感信息，或在社交媒体平台上自动发布垃圾邮件</strong>。</p>
<ul>
<li>凭证填充/账户接管→ 窃取用户帐户;</li>
<li>DDoS攻击→ 使网站/移动应用程序不可用;</li>
<li>Carding→ 测试被盗的信用卡;</li>
<li>操纵投票→ 生成虚假的浏览量，增加点赞、转发等数量。</li>
</ul>
<p>可以使用多种技术和信号进行机器人检测，包括使用ML分析<strong>用户行为模式</strong><sup>[2]</sup>、<strong>浏览器指纹识别</strong><sup>[3][4]</sup>和其他形式的指纹识别，如<strong>TLS指纹识别</strong><sup>[5]</sup>。一些常见的机器人活动指标包括<strong>高频请求、用户行为不一致的模式和使用非标准用户代理或其他识别信息。</strong></p>
<p>有效的机器人检测是维护在线系统和平台安全和完整性的重要组成部分，并被广泛应用于各种组织，包括电子商务网站、社交媒体平台和金融机构。尽管ML技术越来越多地用于机器人检测，但大多数公司仍有高效的规则引擎可与ML算法配合使用。<font color="red">规则的优点是可以立即部署以减轻攻击，并且高度可解释，使它们成为ML机器人检测的良好补充。</font></p>
<p>在本文中，重点关注使用可以在<strong>应用层收集的信息进行机器人检测</strong>，更具体地说是<strong>HTTP头</strong>和<strong>客户端信息</strong>。特别是，该研究将解释如何<strong>使用流算法分析大量流量数据，识别异常事件或异常值</strong>，并<strong>分析底层流量签名以推断规则</strong>。这些技术可以转移到其他机器人检测信号和其他网络安全领域中，其中可以执行行为分析，以识别可疑数据部分，然后使用这些信息提取规则。</p>
<p>越来越多机器人使用的<strong>IP代理+社区驱动的反检测框架</strong>的绕过技术。利用数千个住宅代理分散他们的攻击，不断更改和伪造他们的签名/指纹。</p>
<ul>
<li><strong>使用代理分发攻击</strong>：避免基于IP的速率限制。</li>
<li><strong>使用住宅代理分发攻击</strong>：避免基于信誉的阻止。</li>
<li><strong>使用与目标网站位于同一国家/地区的住宅代理进行分布式攻击</strong>：避免地理阻塞。</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141535180.png" alt="image-20230514153539082" style="zoom:50%;"></p>
<center>
<font color="red">How to block these ever-evolving and distributed
bots?</font>
<center>
<h3><span id="二-手动检测和阻止分布式攻击">二、手动检测和阻止分布式攻击</span></h3>
<h4><span id="21-检测流量峰值">2.1 检测流量峰值</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141554340.png" alt="image-20230514155453228" style="zoom: 33%;"></p>
<h4><span id="22-深入了解不同字段">2.2 深入了解不同字段</span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141555875.png" alt="image-20230514155536782">
<figcaption aria-hidden="true">image-20230514155536782</figcaption>
</figure>
<h4><span id="23-观察一个规则">2.3 观察一个规则</span></h4>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Country=Russia &amp;&amp; User Agent=Mozilla/5.0 (Macintosh;Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36</span><br></pre></td></tr></table></figure>
<blockquote>
<p>指纹解析网站：https://www.useragentstring.com/Chrome99.0.4844.84_id_19983.php</p>
</blockquote>
<center>
<font color="red">How to automate the analysis?</font>
<center>
<h3><span id="三-使用sliceline检测和阻止分布式攻击">三、使用
Sliceline检测和阻止分布式攻击</span></h3>
<p><strong>整体流程概述：</strong></p>
<ul>
<li><p>对登录进行聚合统计【有token实体的内容？】：</p>
<ul>
<li><p>唯一User Agent的数量；</p></li>
<li><p>唯一IP的数量；</p></li>
<li><p>会话数量；</p></li>
</ul></li>
<li><p>使用基于z-score的异常检测算法检测结果时间序列上的异常值【发现异常开始时间】；</p></li>
<li><p>推送描述攻击的事件（客户、开始时间）；</p></li>
<li><p>在流式处理中实施（使用Apache
Flink），使用Sliceline自动化生成规则；</p></li>
</ul>
<h4><span id="31-sliceline-原理解析">3.1 Sliceline 原理解析</span></h4>
<p><strong>Sliceline是由Sagadeeva等人提出的算法<sup>[1]</sup>，可用于ML模型调试</strong>。在训练ML模型时，通常会计算模型在一些保留数据集上的平均性能（模型评估）。Sliceline允许找到特征空间中哪些区域负责非常高的==错误率==。换句话说，它找到<strong>特征切片</strong>，即模型表现低于平均水平的特征空间的子空间。这些切片实际上表示为特征条件的合取式，可以轻松转换为规则。</p>
<p>该算法以数据集和数据集中每个样本的错误作为输入。它要求数据集中的特征是分类的。这适用于机器人检测问题，因为收集的数据大多是分类数据，例如用户代理、国家或有关设备类型的信息(GPU型号等)。请注意，这并不意味着它不能与连续特征一起使用。在连续特征的情况下，我们需要应用预处理来定义不同的间隔并将每个值分配到一个间隔中。这个过程称为二值化，将连续特征转换为分类特征。【<strong>这里应该是指离散化处理</strong>】</p>
<p>我们使用一个简单的例子来说明Sliceline的预期用例：调试ML模型。在下面例子中，考虑一个只有3个特征f1、f2和f3的数据集。此外，假设训练了一个分类模型，并计算了保留数据集中每个样本相关的对数损失（交叉熵损失函数）。</p>
<blockquote>
<p><strong>二分类交叉熵损失函数：</strong>对数损失（log
loss）是一种用于评估分类模型预测结果的损失函数。对数损失通常用于二元分类问题，它测量了模型预测的概率分布与实际标签的差异。对数损失越小，表示模型的预测结果越接近于真实标签，因此模型的性能越好。对数损失的取值范围是0到正无穷，当模型的预测完全准确时，对数损失为0，而当模型的预测完全错误时，对数损失趋近于正无穷。对数损失越大，表示模型的预测与真实标签之间的差异越大，因此模型的性能越差。</p>
</blockquote>
<p><span class="math display">\[
J(\theta)=-\frac{1}{N} \sum_{i=1}^N y^{(i)} \log
\left(h_\theta\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log
\left(1-h_\theta\left(x^{(i)}\right)\right)
\]</span></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141340635.png" alt="image-20230514134017574" style="zoom:50%;"></p>
<center>
图1：具有3个分类特征和相关的每个样本错误的示例数据集
<center>
<p><strong>Sliceline可以通过此输入找到的切片示例有：</strong></p>
<ul>
<li>f1 = b的平均误差为0.9；</li>
<li>f2 = d ∧ f3 = f的平均误差为0.85；</li>
</ul>
<p>这两个切片的误差都高于数据集的平均误差0.38。</p>
<p>原则上，我们寻找的切片可以是许多特征的组合，<strong>可能的切片空间随着特征的数量和基数的增加呈指数级增长</strong>。Sliceline通过使用两种技术来探索这个空间：【<font color="red">本质上是把原始数据转换为二进制向量，用逻辑运算与矩阵运算来代替数据扫描，加快速度</font>】</p>
<ul>
<li>枚举和评估使用<strong>稀疏线性代数</strong>的切片，这可以从现有的高效实现中获益；（Enumerating
and evaluating slices using <strong>sparse linear algebra</strong> that
can profit from existing efficient implementations.）</li>
<li>基于平衡<strong>切片大小</strong>和<strong>平均切片误差</strong>的分数，无需访问数据即可修剪切片候选项。（Pruning
of slice candidates without accessing the data based on a score that
balances between the slice size and the average slice error.）</li>
</ul>
<p>这些技术使算法高效且可扩展，其确切复杂度高度依赖于数据集的细节。</p>
<p>虽然在本文中我们不会详细介绍Sliceline算法的实现细节，但我们希望为读者提供一些有关使用线性代数评估和生成规则的直觉。首先，我们从玩具数据集开始，并进行第一次转换：<strong>独热编码</strong>。独热编码是一种方法，可以通过创建每个特征值的一列来将分类数据编码为数字。在下面的示例中，特征f1有3个值a、b和c，因此为了对其进行编码，我们创建了3个二进制列，如下所示。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141357815.png" alt="image-20230514135737715" style="zoom: 50%;"></p>
<center>
图2：展示如何使用矩阵乘法来查找匹配样本的示例
<center>
<p><strong>同样的转换也允许我们将规则表示为二进制向量：向量将在实施条件的位置包含值1。</strong>例如，对于规则f1
=
b，二进制向量的第二个元素将是1，因为此条件在独热编码空间的第二列中表示。我们可以用这种方式表示所有候选规则，并轻松计算指示哪个样本符合每个规则的掩码。<strong>如果我们将独热编码的特征矩阵F和规则矩阵R表示为F和R，则矩阵乘积FxR的结果正好给出了这一点：一个掩码，其中行对应于样本，列对应于规则。</strong>该矩阵的第i行第j列元素等于1，这意味着样本i与规则j匹配。</p>
<p><strong>有了这个掩码L，我们可以轻松计算每个切片的平均误差，即与某个规则匹配的样本集的平均误差。</strong>这个计算在Sliceline算法中非常重要，因为它允许计算得分，根据这个得分，可以探索可能的切片空间。因此，为了计算平均切片误差，我们首先计算误差向量与掩码L的矩阵乘积，这给出了<strong>切片中的总误差</strong>（E<sup>T</sup>
*
L）。我们也可以计算L与<strong>单位向量</strong>的乘积，有效地计算<strong>匹配每个规则的样本数</strong>。<strong>最后，我们可以逐元素地将总误差和切片大小相除，以获得平均误差。这就是使用线性代数操作评估规则的主要思想。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141424895.png" alt="image-20230514142421803" style="zoom:50%;"></p>
<center>
图3：显示如何使用点积计算平均切片误差的示例
<center>
<p>虽然Sliceline最初是作为一种模型调试技术提出的，但我们可以重新利用它，并将其用于生成针对特定数据组的规则。在网络安全的背景下，我们处于这样一种情况：防御者收集了来自两个数据组的数据：</p>
<ul>
<li>Group 0：一个被认为是正常的群体，主要由非恶意样本组成。</li>
<li>Group 1：另一个数据组，包含恶意和正常流量样本。</li>
</ul>
<p>可以将Group 0分配给正常数据，将Group
1分配给可疑数据。<font color="red">如果我们将该组视为我们提供给Sliceline算法的错误，它将找到针对可疑组的切片，因为它是具有更高误差的一组。</font>我们在下面展示了相同的样例数据集，其中错误被组替换。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141432739.png" alt="image-20230514143215654" style="zoom:50%;"></p>
<center>
图4：具有3个分类特征和相关组的示例数据集
<center>
<p>这种简单的技术允许我们生成针对机器人流量的规则，<strong><font color="red">前提是我们可以定义两组不同的数据。</font></strong></p>
<h5><span id="1sliceline的python开源优化实现">（1）Sliceline的Python开源优化实现</span></h5>
<p>原论文作者<sup>[1]</sup>提供了R和Apache
SystemDS的算法实现。我们决定使用Python实现它，并将其作为一个包开源给社区。<strong>我们首先重新使用Python实现了逻辑，然后实现了一些性能改进，这使得与R实现相比速度提高了1000倍</strong>。这是可能的，<strong>因为我们使用了可用的Python库，如Numpy，这些库利用底层的C++代码和稀疏矩阵</strong>。此外，我们还用矩阵乘法替换了一些for循环结构，进一步提高了速度。该包的源代码可在GitHub上获取<sup>[6]</sup>，与pandas
python库兼容，并遵循scikit-learn API规范。</p>
<h5><span id="2应用sliceline到一个demo-bot检测数据集">（2）应用Sliceline到一个Demo-Bot检测数据集</span></h5>
<p>在本节中，我们将Sliceline应用于一个简单的玩具数据集，该数据集由<strong>HTTP头</strong>和<strong>上下文信息</strong>组成，用于Bot检测问题。为简单起见，我们创建了一个流量数据集，具有人类和Bot的特征。我们使用了来自一个法国电子商务网站的数据。我们收集了来自法语国家的旧会话数据，并将它们分配给Group
0。我们还收集了来自同一网站的来自非法语国家的数据，这些数据使用数据中心IP地址或最近被标记为<strong>代理的IP</strong>，将Group
1分配给可疑流量。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141437571.png" alt="image-20230514143718482">
<figcaption aria-hidden="true">image-20230514143718482</figcaption>
</figure>
<center>
图5：由人类（第0组）和潜在机器人（第1组）流量组成的真实世界电子商务流量数据集示例
<center>
<p>以下Python代码示例展示了我们如何将Sliceline应用于数据集。我们使用pandas数据帧df存储数据集：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sliceline.slicefinder <span class="keyword">import</span> Slicefinder</span><br><span class="line"></span><br><span class="line">sf = Slicefinder(</span><br><span class="line">    alpha = <span class="number">0.80</span>,</span><br><span class="line">    k = <span class="number">4</span>,</span><br><span class="line">    max_l = df.shape[<span class="number">1</span>],</span><br><span class="line">    min_sup = <span class="number">1</span>,</span><br><span class="line">    verbose = <span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">sf.fit(df.drop(<span class="string">&quot;group&quot;</span>, axis=<span class="number">1</span>), df[<span class="string">&quot;group&quot;</span>])</span><br></pre></td></tr></table></figure>
<p><strong>一旦将算法拟合到数据上，我们就可以使用找到的切片来生成最适合我们需求的语法规则。</strong>例如，我们可以这样做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">slice</span>, stats <span class="keyword">in</span> <span class="built_in">zip</span>(sf.top_slices_, sf.top_slices_statistics_):</span><br><span class="line">    rule = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> feat, value <span class="keyword">in</span> <span class="built_in">zip</span>(df.columns, <span class="built_in">slice</span>):</span><br><span class="line">        <span class="keyword">if</span> value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> rule <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">           rule = <span class="string">f&quot;`<span class="subst">&#123;feat&#125;</span>`=`<span class="subst">&#123;value&#125;</span>`&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">        	 rule += <span class="string">f&quot; &amp;&amp; `<span class="subst">&#123;feat&#125;</span>`=`<span class="subst">&#123;value&#125;</span>`&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;rule&#125;</span> | slice size: <span class="subst">&#123;stats[<span class="string">&#x27;slice_size&#x27;</span>]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>在我们的案例中，这段简单的代码给出了以下规则：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`Country`=`Germany` | slice size: 4149.0</span><br><span class="line">`User Agent`=`Chrome` &amp;&amp; `Country`=`Germany` | slice size: 4133.0</span><br><span class="line">`Country`=`Germany` &amp;&amp; `Accept Language`=`en-US,en;q=0.9` | slice size:</span><br><span class="line">4097.0</span><br><span class="line">`User Agent`=`Chrome` &amp;&amp; `Country`=`Germany` &amp;&amp; `Accept</span><br><span class="line">Language`=`en-US,en;q=0.9` | slice size: 4097.0</span><br></pre></td></tr></table></figure>
<p>这意味着，对于这个特定的网站，<strong>攻击来自德国，使用Chrome和特定的接受语言标头</strong>。</p>
<h4><span id="32-分布式攻击的应用">3.2 分布式攻击的应用</span></h4>
<p><strong>Sliceline可以应用于分布式Bot攻击检测问题，通过定义两个不同的流量组</strong>【<font color="red">用攻击前和攻击期间的来标签，使任务做到无监督</font>】：</p>
<ul>
<li><strong>攻击前的流量</strong>：这部分流量仅包含人类数据（Group
0）；</li>
<li><strong>攻击期间的流量</strong>：这部分流量包含人类和Bot流量（Group
1）；</li>
</ul>
<p><font color="red">请注意，在实际情况下，Group
0可能包含一些残留的Bot流量。它如何影响Sliceline生成的规则的质量取决于Group
0中Bot流量的比例以及它与Group 1中也存在的Bot流量的相似程度。</font></p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141446088.png" alt="image-20230514144648991">
<figcaption aria-hidden="true">image-20230514144648991</figcaption>
</figure>
<center>
图6：时间序列图，说明Sliceline使用的2个组：攻击前的人类流量（绿色，Group
0）和混合的Bot和人类流量（红色，Group 1）
<center>
<p>上图中展示了这个想法，假设异常检测算法提供了攻击开始时间，然后稍后触发流量分析。如果我们将攻击前的流量标识为Group
0，将攻击期间的流量标识为Group
1，那么通过应用Sliceline，我们将找到针对Bot流量的规则。</p>
<p>我们提出的检测分布式攻击的方法不依赖于IP或会话的流量分析。<strong>相反，我们分析每个【客户】的全局流量。为此，我们计算几个聚合并分析它们随时间的演变。</strong>我们计算的聚合的示例包括：</p>
<ul>
<li><strong>请求的数量</strong>；</li>
<li><strong>唯一User Agent的数量</strong>；</li>
<li><strong>唯一国家的数量</strong>；</li>
<li><strong>唯一IP地址的数量</strong>；</li>
</ul>
<p><strong>所有聚合都使用Apache
Flink<sup>[7]</sup>在10分钟的窗口中以流式处理方式计算。</strong>请注意，时间窗口的大小可以根据用例进行参数化：</p>
<ul>
<li><strong>较小的时间窗口可以更快地进行检测，但可能会增加误报率；</strong></li>
<li><strong>较大的时间窗口可能会在异常检测中引入滞后，但可以降低误报率的风险；</strong></li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141455725.png"></p>
<center>
图7：四个不同聚合时间序列的示例（请求计数、IP数量、用户代理数量、国家数量）
<center>
<p>我们独立分析每个时间序列，并使用<strong><font color="red">基于z-score的算法检测极高值</font></strong>。滚动窗口允许我们估计正常数据的分布，并基于该分布计算新值的z-score。如果z-score超过一定阈值，则宣布攻击开始，并触发流量分析。</p>
<p>该算法轻量级且可以轻松地以流式处理方式实现。该算法可能会遇到两个不同的问题：</p>
<ul>
<li><strong>误报：</strong>检测到攻击不是由Bot引起的，可能是因为z-score阈值过于敏感，或者因为由于某些特殊事件（突发新闻、限量销售等）导致流量增加。</li>
<li><strong>漏报：</strong>错过本应该检测到的攻击。</li>
</ul>
<p><strong><font color="red">为了解决漏报问题，可以收集示例时间序列并标记需要检测的攻击。这个带标签的数据集可以进一步用于更好地调整阈值。</font></strong></p>
<p>关于误报，随后的规则生成步骤可以防止我们生成针对正常业务的规则。<strong>如果流量激增是由正常业务流量引起的，则Sliceline将不会发现攻击前后流量特征的任何差异，因此将不会生成任何规则</strong>。【有点意思，规则挖掘类似告警聚类，有降误报的能力】</p>
<h4><span id="33案例分析凭据填充攻击被sliceline阻止">3.3
案例分析：凭据填充攻击被Sliceline阻止</span></h4>
<p>为了说明我们的方法，我们展示了一个使用我们的流式异常检测和Sliceline相结合的游戏平台攻击的具体例子。图8展示了4个不同的时间序列：</p>
<ul>
<li><strong>蓝色：</strong>被检测引擎分类为人类的HTTP登录流量（可能包含尚未检测到的Bot流量）。</li>
<li><strong>橙色：</strong>在部署到检测引擎之前与Sliceline生成的规则匹配的流量（攻击的未检测子集）。</li>
<li><strong>绿色：</strong>蓝色-橙色时间序列。在实施Sliceline生成的规则后被认为是人类流量。</li>
<li><strong>红色：</strong>Sliceline生成的规则匹配并被阻止的HTTP登录流量。</li>
</ul>
<p><font color="red">首先：游戏平台的登录流量出现了一个小的峰值（蓝色线），被我们的异常检测算法捕捉到。</font><font color="blue">然后，Sliceline被应用，并生成了一条规则，随后阻止了由红色线表示的所有流量，在一周内总计超过3百万个请求。</font></p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141511200.png" alt="image-20230514151139084">
<figcaption aria-hidden="true">image-20230514151139084</figcaption>
</figure>
<center>
图8：与Slisline在游戏平台登录端点上的应用程序相关的时间序列
<center>
<p>下面显示了相同的阻塞流量，但我们显示的不是请求号，而是不同IP的数量。<strong>超过18.7万个不同的IP被用来分发这次攻击。</strong></p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141514301.png" alt="image-20230514151422173">
<figcaption aria-hidden="true">image-20230514151422173</figcaption>
</figure>
<center>
图9：在游戏平台上进行凭证填充攻击时，IP地址的不同数量/3h
<center>
<p>虽然我们利用Sliceline在不同的ML管道中生成规则，但我们结合基于流式处理的异常检测和Sliceline的方法能够保护登录终端，每个月跨多个客户阻止约220万次恶意登录尝试。</p>
<h3><span id="四-结论">四、结论</span></h3>
<p><font color="red">为了绕过传统的Bot检测技术，如基于IP的速率限制和基于签名的阻止，Bot趋向于在数千个IP地址上分布其攻击，并频繁更改其指纹。</font>我们提出了一种结合基于流式处理的异常检测和Sliceline的方法来检测分布式Bot攻击。</p>
<p>虽然Sliceline最初是作为一种ML模型调试算法提出的，但我们展示了如何使用它来生成与恶意Bot流量活动匹配的规则。这种方法使我们能够每月跨多个客户阻止约220万次恶意登录尝试。</p>
<p>我们实现并开源了Sliceline的优化Python版本。我们重写了部分代码，利用了矩阵乘法和稀疏矩阵，相比R实现，速度提升了1000倍。</p>
<p>在本文中，我们使用分布式Bot攻击检测问题展示了我们的方法。然而，我们的方法完全不依赖于规则引擎，可以应用于其他网络安全设置，只要能够定义正常和异常行为的组。</p>
<h3><span id="参考文献">参考文献</span></h3>
<p>[1] Sagadeeva, Svetlana, and Matthias Boehm. "Sliceline: Fast,
linear-algebra-based slice finding for ml model debugging." Proceedings
of the 2021 International Conference on Management of Data. 2021.</p>
<p>[2] Jacob, Gregoire, Engin Kirda, Christopher Kruegel, and Giovanni
Vigna. "PUBCRAWL: Protecting Users and Businesses from CRAWLers." In
USENIX Security Symposium, pp. 507-522. 2012.</p>
<p>[3] Bursztein, Elie, et al. "Picasso: Lightweight device class
fingerprinting for web clients." Proceedings of the 6th Workshop on
Security and Privacy in Smartphones and Mobile Devices. 2016.</p>
<p>[4] Vastel, Antoine, et al. "FP-Crawlers: studying the resilience of
browser fingerprinting to block crawlers." MADWeb'20-NDSS Workshop on
Measurements, Attacks, and Defenses for the Web. 2020.</p>
<p>[5] Li, Xigao, et al. "Good bot, bad bot: Characterizing automated
browsing activity." 2021 IEEE symposium on security and privacy (sp).
IEEE, 2021.</p>
<p>[6] https://github.com/DataDome/sliceline</p>
<p>[7] https://flink.apache.org/</p>
<p>[8] https://datadome.co/</p>
<h3><span id="相关链接">相关链接</span></h3>
<ul>
<li>https://datadome.co/datadome_events/black-hat-asia-2023-here-we-come/</li>
<li><a href="https://www.blackhat.com/asia-23/briefings/schedule/index.html#leveraging-streaming-based-outlier-detection-and-sliceline-to-stop-heavily-distributed-bot-attacks-30984">Leveraging
Streaming-Based Outlier Detection and SliceLine to Stop Heavily
Distributed Bot Attacks</a></li>
<li><a href="https://mboehm7.github.io/resources/sigmod2021b_sliceline.pdf">SliceLine:
Fast, Linear-Algebra-based Slice Finding for ML Model Debugging</a></li>
<li><a href="https://www.blackhat.com/asia-23/sponsored-sessions/schedule/index.html#war-of-the-bots-learnings-from-thwarting-new-automated-attack-vectors-32031">War
of the Bots: Learnings from Thwarting New Automated Attack
Vectors</a></li>
</ul>
</center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center>]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>API安全</category>
      </categories>
      <tags>
        <tag>工业落地</tag>
        <tag>业务安全</tag>
        <tag>API安全</tag>
        <tag>BlackHat</tag>
        <tag>Distributed Bot Attacks</tag>
      </tags>
  </entry>
  <entry>
    <title>流量反作弊（3）2023 BlackHat：利用基于流的离群值检测和 SliceLine 来阻止分布广泛的机器人攻击</title>
    <url>/posts/2X0D06Q/</url>
    <content><![CDATA[<h2><span id="leveragingstreaming-based-outlier-detection-and-sliceline-to-stop-heavilydistributed-bot-attacks">Leveraging
Streaming-Based Outlier Detection and SliceLine to Stop Heavily
Distributed Bot Attacks</span></h2>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615386.png" alt="image-20230514113324227" style="zoom: 25%;"></p>
<p><strong>在本篇文章中我们将讨论DataDome公司<sup>[8]</sup>是如何利用<font color="red">基于流的异常值检测和
SliceLine
来快速安全地生成大量可用于阻止恶意流量的规则/签名。</font></strong>虽然机器学习(ML)的使用变得越来越普遍，但在安全环境中规则仍然很重要。事实上，公司已经投资了大量有效的规则引擎，能够快速评估大量规则。此外，规则通常更方便创建、操作和解释，因此在ML方法之外仍然很有价值。</p>
<p>虽然 SliceLine 最初设计用于识别 ML
模型表现不佳的数据子集，但它的使用可以<strong>适应以无监督方式生成大量与攻击相关的规则，即不使用标记数据</strong>。此外，利用机器人检测问题来说明如何使用
SliceLine 即时生成大量恶意签名。</p>
<p>该研究还将展示优化的 SliceLine Python
开源实现，并展示如何将其用于特定但困难的机器人检测子集：<strong>分布式凭证填充攻击</strong>，<strong>攻击者利用数千个受感染的
IP
地址进行攻击和绕过传统的安全机制，例如速率限制策略</strong>。通过一个真实世界的例子，该研究将首先解释如何使用基于流的检测来检测此类攻击，以及该研究如何使用数据建模在服务器端信号（HTTP
标头、TLS 指纹、IP 地址等）上应用 <strong>SliceLine</strong>
来识别并生成与分布式攻击相关的阻止签名。<font color="red">这种方法使该研究能够在去年阻止
59 位客户超过 2.85 亿次恶意登录尝试。</font></p>
<p>最后，该研究将解释这种方法如何推广到除机器人检测之外的其他安全用例，以及如何在不同的规则引擎中使用它。</p>
<span id="more"></span>
<h3><span id="一-说明">一、说明</span></h3>
<p><strong>机器人检测是指识别和区分人类用户和自动化软件程序(Bot：Program
to automate
actions)的过程</strong>。术语“bot”可以指各种程序，包括搜索引擎爬虫和设计用于进行抢购或拒绝服务攻击的恶意bot。</p>
<p>机器人检测很重要，因为机器人可用于各种目的，其中一些可能是有害或不道德的。例如，<strong>机器人可用于进行欺诈活动，如账户接管或凭证填充，从网站中获取敏感信息，或在社交媒体平台上自动发布垃圾邮件</strong>。</p>
<ul>
<li>凭证填充/账户接管→ 窃取用户帐户;</li>
<li>DDoS攻击→ 使网站/移动应用程序不可用;</li>
<li>Carding→ 测试被盗的信用卡;</li>
<li>操纵投票→ 生成虚假的浏览量，增加点赞、转发等数量。</li>
</ul>
<p>可以使用多种技术和信号进行机器人检测，包括使用ML分析<strong>用户行为模式</strong><sup>[2]</sup>、<strong>浏览器指纹识别</strong><sup>[3][4]</sup>和其他形式的指纹识别，如<strong>TLS指纹识别</strong><sup>[5]</sup>。一些常见的机器人活动指标包括<strong>高频请求、用户行为不一致的模式和使用非标准用户代理或其他识别信息。</strong></p>
<p>有效的机器人检测是维护在线系统和平台安全和完整性的重要组成部分，并被广泛应用于各种组织，包括电子商务网站、社交媒体平台和金融机构。尽管ML技术越来越多地用于机器人检测，但大多数公司仍有高效的规则引擎可与ML算法配合使用。<font color="red">规则的优点是可以立即部署以减轻攻击，并且高度可解释，使它们成为ML机器人检测的良好补充。</font></p>
<p>在本文中，重点关注使用可以在<strong>应用层收集的信息进行机器人检测</strong>，更具体地说是<strong>HTTP头</strong>和<strong>客户端信息</strong>。特别是，该研究将解释如何<strong>使用流算法分析大量流量数据，识别异常事件或异常值</strong>，并<strong>分析底层流量签名以推断规则</strong>。这些技术可以转移到其他机器人检测信号和其他网络安全领域中，其中可以执行行为分析，以识别可疑数据部分，然后使用这些信息提取规则。</p>
<p>越来越多机器人使用的<strong>IP代理+社区驱动的反检测框架</strong>的绕过技术。利用数千个住宅代理分散他们的攻击，不断更改和伪造他们的签名/指纹。</p>
<ul>
<li><strong>使用代理分发攻击</strong>：避免基于IP的速率限制。</li>
<li><strong>使用住宅代理分发攻击</strong>：避免基于信誉的阻止。</li>
<li><strong>使用与目标网站位于同一国家/地区的住宅代理进行分布式攻击</strong>：避免地理阻塞。</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615490.png" alt="image-20230514153539082" style="zoom:50%;"></p>
<center>
<font color="red">How to block these ever-evolving and distributed
bots?</font>
<center>
<h3><span id="二-手动检测和阻止分布式攻击">二、手动检测和阻止分布式攻击</span></h3>
<h4><span id="21-检测流量峰值">2.1 检测流量峰值</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615644.png" alt="image-20230514155453228" style="zoom: 33%;"></p>
<h4><span id="22-深入了解不同字段">2.2 深入了解不同字段</span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615865.png" alt="image-20230514155536782">
<figcaption aria-hidden="true">image-20230514155536782</figcaption>
</figure>
<h4><span id="23-观察一个规则">2.3 观察一个规则</span></h4>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Country=Russia &amp;&amp; User Agent=Mozilla/5.0 (Macintosh;Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36</span><br></pre></td></tr></table></figure>
<blockquote>
<p>指纹解析网站：https://www.useragentstring.com/Chrome99.0.4844.84_id_19983.php</p>
</blockquote>
<center>
<font color="red">How to automate the analysis?</font>
<center>
<h3><span id="三-使用sliceline检测和阻止分布式攻击">三、使用
Sliceline检测和阻止分布式攻击</span></h3>
<p><strong>整体流程概述：</strong></p>
<ul>
<li><p>对登录进行聚合统计【有token实体的内容？】：</p>
<ul>
<li><p>唯一User Agent的数量；</p></li>
<li><p>唯一IP的数量；</p></li>
<li><p>会话数量；</p></li>
</ul></li>
<li><p>使用基于z-score的异常检测算法检测结果时间序列上的异常值【发现异常开始时间】；</p></li>
<li><p>推送描述攻击的事件（客户、开始时间）；</p></li>
<li><p>在流式处理中实施（使用Apache
Flink），使用Sliceline自动化生成规则；</p></li>
</ul>
<h4><span id="31-sliceline-原理解析">3.1 Sliceline 原理解析</span></h4>
<p><strong>Sliceline是由Sagadeeva等人提出的算法<sup>[1]</sup>，可用于ML模型调试</strong>。在训练ML模型时，通常会计算模型在一些保留数据集上的平均性能（模型评估）。Sliceline允许找到特征空间中哪些区域负责非常高的==错误率==。换句话说，它找到<strong>特征切片</strong>，即模型表现低于平均水平的特征空间的子空间。这些切片实际上表示为特征条件的合取式，可以轻松转换为规则。</p>
<p>该算法以数据集和数据集中每个样本的错误作为输入。它要求数据集中的特征是分类的。这适用于机器人检测问题，因为收集的数据大多是分类数据，例如用户代理、国家或有关设备类型的信息(GPU型号等)。请注意，这并不意味着它不能与连续特征一起使用。在连续特征的情况下，我们需要应用预处理来定义不同的间隔并将每个值分配到一个间隔中。这个过程称为二值化，将连续特征转换为分类特征。【<strong>这里应该是指离散化处理</strong>】</p>
<p>我们使用一个简单的例子来说明Sliceline的预期用例：调试ML模型。在下面例子中，考虑一个只有3个特征f1、f2和f3的数据集。此外，假设训练了一个分类模型，并计算了保留数据集中每个样本相关的对数损失（交叉熵损失函数）。</p>
<blockquote>
<p><strong>二分类交叉熵损失函数：</strong>对数损失（log
loss）是一种用于评估分类模型预测结果的损失函数。对数损失通常用于二元分类问题，它测量了模型预测的概率分布与实际标签的差异。对数损失越小，表示模型的预测结果越接近于真实标签，因此模型的性能越好。对数损失的取值范围是0到正无穷，当模型的预测完全准确时，对数损失为0，而当模型的预测完全错误时，对数损失趋近于正无穷。对数损失越大，表示模型的预测与真实标签之间的差异越大，因此模型的性能越差。</p>
</blockquote>
<p><span class="math display">\[
J(\theta)=-\frac{1}{N} \sum_{i=1}^N y^{(i)} \log
\left(h_\theta\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log
\left(1-h_\theta\left(x^{(i)}\right)\right)
\]</span></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615937.png" alt="image-20230514134017574" style="zoom:50%;"></p>
<center>
图1：具有3个分类特征和相关的每个样本错误的示例数据集
<center>
<p><strong>Sliceline可以通过此输入找到的切片示例有：</strong></p>
<ul>
<li>f1 = b的平均误差为0.9；</li>
<li>f2 = d ∧ f3 = f的平均误差为0.85；</li>
</ul>
<p>这两个切片的误差都高于数据集的平均误差0.38。</p>
<p>原则上，我们寻找的切片可以是许多特征的组合，<strong>可能的切片空间随着特征的数量和基数的增加呈指数级增长</strong>。Sliceline通过使用两种技术来探索这个空间：【<font color="red">本质上是把原始数据转换为二进制向量，用逻辑运算与矩阵运算来代替数据扫描，加快速度</font>】</p>
<ul>
<li>枚举和评估使用<strong>稀疏线性代数</strong>的切片，这可以从现有的高效实现中获益；（Enumerating
and evaluating slices using <strong>sparse linear algebra</strong> that
can profit from existing efficient implementations.）</li>
<li>基于平衡<strong>切片大小</strong>和<strong>平均切片误差</strong>的分数，无需访问数据即可修剪切片候选项。（Pruning
of slice candidates without accessing the data based on a score that
balances between the slice size and the average slice error.）</li>
</ul>
<p>这些技术使算法高效且可扩展，其确切复杂度高度依赖于数据集的细节。</p>
<p>虽然在本文中我们不会详细介绍Sliceline算法的实现细节，但我们希望为读者提供一些有关使用线性代数评估和生成规则的直觉。首先，我们从玩具数据集开始，并进行第一次转换：<strong>独热编码</strong>。独热编码是一种方法，可以通过创建每个特征值的一列来将分类数据编码为数字。在下面的示例中，特征f1有3个值a、b和c，因此为了对其进行编码，我们创建了3个二进制列，如下所示。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615091.png" alt="image-20230514135737715" style="zoom: 50%;"></p>
<center>
图2：展示如何使用矩阵乘法来查找匹配样本的示例
<center>
<p><strong>同样的转换也允许我们将规则表示为二进制向量：向量将在实施条件的位置包含值1。</strong>例如，对于规则f1
=
b，二进制向量的第二个元素将是1，因为此条件在独热编码空间的第二列中表示。我们可以用这种方式表示所有候选规则，并轻松计算指示哪个样本符合每个规则的掩码。<strong>如果我们将独热编码的特征矩阵F和规则矩阵R表示为F和R，则矩阵乘积FxR的结果正好给出了这一点：一个掩码，其中行对应于样本，列对应于规则。</strong>该矩阵的第i行第j列元素等于1，这意味着样本i与规则j匹配。</p>
<p><strong>有了这个掩码L，我们可以轻松计算每个切片的平均误差，即与某个规则匹配的样本集的平均误差。</strong>这个计算在Sliceline算法中非常重要，因为它允许计算得分，根据这个得分，可以探索可能的切片空间。因此，为了计算平均切片误差，我们首先计算误差向量与掩码L的矩阵乘积，这给出了<strong>切片中的总误差</strong>（E<sup>T</sup>
*
L）。我们也可以计算L与<strong>单位向量</strong>的乘积，有效地计算<strong>匹配每个规则的样本数</strong>。<strong>最后，我们可以逐元素地将总误差和切片大小相除，以获得平均误差。这就是使用线性代数操作评估规则的主要思想。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615268.png" alt="image-20230514142421803" style="zoom:50%;"></p>
<center>
图3：显示如何使用点积计算平均切片误差的示例
<center>
<p>虽然Sliceline最初是作为一种模型调试技术提出的，但我们可以重新利用它，并将其用于生成针对特定数据组的规则。在网络安全的背景下，我们处于这样一种情况：防御者收集了来自两个数据组的数据：</p>
<ul>
<li>Group 0：一个被认为是正常的群体，主要由非恶意样本组成。</li>
<li>Group 1：另一个数据组，包含恶意和正常流量样本。</li>
</ul>
<p>可以将Group 0分配给正常数据，将Group
1分配给可疑数据。<font color="red">如果我们将该组视为我们提供给Sliceline算法的错误，它将找到针对可疑组的切片，因为它是具有更高误差的一组。</font>我们在下面展示了相同的样例数据集，其中错误被组替换。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615405.png" alt="image-20230514143215654" style="zoom:50%;"></p>
<center>
图4：具有3个分类特征和相关组的示例数据集
<center>
<p>这种简单的技术允许我们生成针对机器人流量的规则，<strong><font color="red">前提是我们可以定义两组不同的数据。</font></strong></p>
<h5><span id="1sliceline的python开源优化实现">（1）Sliceline的Python开源优化实现</span></h5>
<p>原论文作者<sup>[1]</sup>提供了R和Apache
SystemDS的算法实现。我们决定使用Python实现它，并将其作为一个包开源给社区。<strong>我们首先重新使用Python实现了逻辑，然后实现了一些性能改进，这使得与R实现相比速度提高了1000倍</strong>。这是可能的，<strong>因为我们使用了可用的Python库，如Numpy，这些库利用底层的C++代码和稀疏矩阵</strong>。此外，我们还用矩阵乘法替换了一些for循环结构，进一步提高了速度。该包的源代码可在GitHub上获取<sup>[6]</sup>，与pandas
python库兼容，并遵循scikit-learn API规范。</p>
<h5><span id="2应用sliceline到一个demo-bot检测数据集">（2）应用Sliceline到一个Demo-Bot检测数据集</span></h5>
<p>在本节中，我们将Sliceline应用于一个简单的玩具数据集，该数据集由<strong>HTTP头</strong>和<strong>上下文信息</strong>组成，用于Bot检测问题。为简单起见，我们创建了一个流量数据集，具有人类和Bot的特征。我们使用了来自一个法国电子商务网站的数据。我们收集了来自法语国家的旧会话数据，并将它们分配给Group
0。我们还收集了来自同一网站的来自非法语国家的数据，这些数据使用数据中心IP地址或最近被标记为<strong>代理的IP</strong>，将Group
1分配给可疑流量。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615688.png" alt="image-20230514143718482">
<figcaption aria-hidden="true">image-20230514143718482</figcaption>
</figure>
<center>
图5：由人类（第0组）和潜在机器人（第1组）流量组成的真实世界电子商务流量数据集示例
<center>
<p>以下Python代码示例展示了我们如何将Sliceline应用于数据集。我们使用pandas数据帧df存储数据集：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sliceline.slicefinder <span class="keyword">import</span> Slicefinder</span><br><span class="line"></span><br><span class="line">sf = Slicefinder(</span><br><span class="line">    alpha = <span class="number">0.80</span>,</span><br><span class="line">    k = <span class="number">4</span>,</span><br><span class="line">    max_l = df.shape[<span class="number">1</span>],</span><br><span class="line">    min_sup = <span class="number">1</span>,</span><br><span class="line">    verbose = <span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">sf.fit(df.drop(<span class="string">&quot;group&quot;</span>, axis=<span class="number">1</span>), df[<span class="string">&quot;group&quot;</span>])</span><br></pre></td></tr></table></figure>
<p><strong>一旦将算法拟合到数据上，我们就可以使用找到的切片来生成最适合我们需求的语法规则。</strong>例如，我们可以这样做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">slice</span>, stats <span class="keyword">in</span> <span class="built_in">zip</span>(sf.top_slices_, sf.top_slices_statistics_):</span><br><span class="line">    rule = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> feat, value <span class="keyword">in</span> <span class="built_in">zip</span>(df.columns, <span class="built_in">slice</span>):</span><br><span class="line">        <span class="keyword">if</span> value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> rule <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">           rule = <span class="string">f&quot;`<span class="subst">&#123;feat&#125;</span>`=`<span class="subst">&#123;value&#125;</span>`&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">        	 rule += <span class="string">f&quot; &amp;&amp; `<span class="subst">&#123;feat&#125;</span>`=`<span class="subst">&#123;value&#125;</span>`&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;rule&#125;</span> | slice size: <span class="subst">&#123;stats[<span class="string">&#x27;slice_size&#x27;</span>]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>在我们的案例中，这段简单的代码给出了以下规则：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`Country`=`Germany` | slice size: 4149.0</span><br><span class="line">`User Agent`=`Chrome` &amp;&amp; `Country`=`Germany` | slice size: 4133.0</span><br><span class="line">`Country`=`Germany` &amp;&amp; `Accept Language`=`en-US,en;q=0.9` | slice size:</span><br><span class="line">4097.0</span><br><span class="line">`User Agent`=`Chrome` &amp;&amp; `Country`=`Germany` &amp;&amp; `Accept</span><br><span class="line">Language`=`en-US,en;q=0.9` | slice size: 4097.0</span><br></pre></td></tr></table></figure>
<p>这意味着，对于这个特定的网站，<strong>攻击来自德国，使用Chrome和特定的接受语言标头</strong>。</p>
<h4><span id="32-分布式攻击的应用">3.2 分布式攻击的应用</span></h4>
<p><strong>Sliceline可以应用于分布式Bot攻击检测问题，通过定义两个不同的流量组</strong>【<font color="red">用攻击前和攻击期间的来标签，使任务做到无监督</font>】：</p>
<ul>
<li><strong>攻击前的流量</strong>：这部分流量仅包含人类数据（Group
0）；</li>
<li><strong>攻击期间的流量</strong>：这部分流量包含人类和Bot流量（Group
1）；</li>
</ul>
<p><font color="red">请注意，在实际情况下，Group
0可能包含一些残留的Bot流量。它如何影响Sliceline生成的规则的质量取决于Group
0中Bot流量的比例以及它与Group 1中也存在的Bot流量的相似程度。</font></p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615700.png" alt="image-20230514144648991">
<figcaption aria-hidden="true">image-20230514144648991</figcaption>
</figure>
<center>
图6：时间序列图，说明Sliceline使用的2个组：攻击前的人类流量（绿色，Group
0）和混合的Bot和人类流量（红色，Group 1）
<center>
<p>上图中展示了这个想法，假设异常检测算法提供了攻击开始时间，然后稍后触发流量分析。如果我们将攻击前的流量标识为Group
0，将攻击期间的流量标识为Group
1，那么通过应用Sliceline，我们将找到针对Bot流量的规则。</p>
<p>我们提出的检测分布式攻击的方法不依赖于IP或会话的流量分析。<strong>相反，我们分析每个【客户】的全局流量。为此，我们计算几个聚合并分析它们随时间的演变。</strong>我们计算的聚合的示例包括：</p>
<ul>
<li><strong>请求的数量</strong>；</li>
<li><strong>唯一User Agent的数量</strong>；</li>
<li><strong>唯一国家的数量</strong>；</li>
<li><strong>唯一IP地址的数量</strong>；</li>
</ul>
<p><strong>所有聚合都使用Apache
Flink<sup>[7]</sup>在10分钟的窗口中以流式处理方式计算。</strong>请注意，时间窗口的大小可以根据用例进行参数化：</p>
<ul>
<li><strong>较小的时间窗口可以更快地进行检测，但可能会增加误报率；</strong></li>
<li><strong>较大的时间窗口可能会在异常检测中引入滞后，但可以降低误报率的风险；</strong></li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615368.png"></p>
<center>
图7：四个不同聚合时间序列的示例（请求计数、IP数量、用户代理数量、国家数量）
<center>
<p>我们独立分析每个时间序列，并使用<strong><font color="red">基于z-score的算法检测极高值</font></strong>。滚动窗口允许我们估计正常数据的分布，并基于该分布计算新值的z-score。如果z-score超过一定阈值，则宣布攻击开始，并触发流量分析。</p>
<p>该算法轻量级且可以轻松地以流式处理方式实现。该算法可能会遇到两个不同的问题：</p>
<ul>
<li><strong>误报：</strong>检测到攻击不是由Bot引起的，可能是因为z-score阈值过于敏感，或者因为由于某些特殊事件（突发新闻、限量销售等）导致流量增加。</li>
<li><strong>漏报：</strong>错过本应该检测到的攻击。</li>
</ul>
<p><strong><font color="red">为了解决漏报问题，可以收集示例时间序列并标记需要检测的攻击。这个带标签的数据集可以进一步用于更好地调整阈值。</font></strong></p>
<p>关于误报，随后的规则生成步骤可以防止我们生成针对正常业务的规则。<strong>如果流量激增是由正常业务流量引起的，则Sliceline将不会发现攻击前后流量特征的任何差异，因此将不会生成任何规则</strong>。【有点意思，规则挖掘类似告警聚类，有降误报的能力】</p>
<h4><span id="33案例分析凭据填充攻击被sliceline阻止">3.3
案例分析：凭据填充攻击被Sliceline阻止</span></h4>
<p>为了说明我们的方法，我们展示了一个使用我们的流式异常检测和Sliceline相结合的游戏平台攻击的具体例子。图8展示了4个不同的时间序列：</p>
<ul>
<li><strong>蓝色：</strong>被检测引擎分类为人类的HTTP登录流量（可能包含尚未检测到的Bot流量）。</li>
<li><strong>橙色：</strong>在部署到检测引擎之前与Sliceline生成的规则匹配的流量（攻击的未检测子集）。</li>
<li><strong>绿色：</strong>蓝色-橙色时间序列。在实施Sliceline生成的规则后被认为是人类流量。</li>
<li><strong>红色：</strong>Sliceline生成的规则匹配并被阻止的HTTP登录流量。</li>
</ul>
<p><font color="red">首先：游戏平台的登录流量出现了一个小的峰值（蓝色线），被我们的异常检测算法捕捉到。</font><font color="blue">然后，Sliceline被应用，并生成了一条规则，随后阻止了由红色线表示的所有流量，在一周内总计超过3百万个请求。</font></p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615725.png" alt="image-20230514151139084">
<figcaption aria-hidden="true">image-20230514151139084</figcaption>
</figure>
<center>
图8：与Slisline在游戏平台登录端点上的应用程序相关的时间序列
<center>
<p>下面显示了相同的阻塞流量，但我们显示的不是请求号，而是不同IP的数量。<strong>超过18.7万个不同的IP被用来分发这次攻击。</strong></p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305141615075.png" alt="image-20230514151422173">
<figcaption aria-hidden="true">image-20230514151422173</figcaption>
</figure>
<center>
图9：在游戏平台上进行凭证填充攻击时，IP地址的不同数量/3h
<center>
<p>虽然我们利用Sliceline在不同的ML管道中生成规则，但我们结合基于流式处理的异常检测和Sliceline的方法能够保护登录终端，每个月跨多个客户阻止约220万次恶意登录尝试。</p>
<h3><span id="四-结论">四、结论</span></h3>
<p><font color="red">为了绕过传统的Bot检测技术，如基于IP的速率限制和基于签名的阻止，Bot趋向于在数千个IP地址上分布其攻击，并频繁更改其指纹。</font>我们提出了一种结合基于流式处理的异常检测和Sliceline的方法来检测分布式Bot攻击。</p>
<p>虽然Sliceline最初是作为一种ML模型调试算法提出的，但我们展示了如何使用它来生成与恶意Bot流量活动匹配的规则。这种方法使我们能够每月跨多个客户阻止约220万次恶意登录尝试。</p>
<p>我们实现并开源了Sliceline的优化Python版本。我们重写了部分代码，利用了矩阵乘法和稀疏矩阵，相比R实现，速度提升了1000倍。</p>
<p>在本文中，我们使用分布式Bot攻击检测问题展示了我们的方法。然而，我们的方法完全不依赖于规则引擎，可以应用于其他网络安全设置，只要能够定义正常和异常行为的组。</p>
<h3><span id="参考文献">参考文献</span></h3>
<p>[1] Sagadeeva, Svetlana, and Matthias Boehm. "Sliceline: Fast,
linear-algebra-based slice finding for ml model debugging." Proceedings
of the 2021 International Conference on Management of Data. 2021.</p>
<p>[2] Jacob, Gregoire, Engin Kirda, Christopher Kruegel, and Giovanni
Vigna. "PUBCRAWL: Protecting Users and Businesses from CRAWLers." In
USENIX Security Symposium, pp. 507-522. 2012.</p>
<p>[3] Bursztein, Elie, et al. "Picasso: Lightweight device class
fingerprinting for web clients." Proceedings of the 6th Workshop on
Security and Privacy in Smartphones and Mobile Devices. 2016.</p>
<p>[4] Vastel, Antoine, et al. "FP-Crawlers: studying the resilience of
browser fingerprinting to block crawlers." MADWeb'20-NDSS Workshop on
Measurements, Attacks, and Defenses for the Web. 2020.</p>
<p>[5] Li, Xigao, et al. "Good bot, bad bot: Characterizing automated
browsing activity." 2021 IEEE symposium on security and privacy (sp).
IEEE, 2021.</p>
<p>[6] https://github.com/DataDome/sliceline</p>
<p>[7] https://flink.apache.org/</p>
<p>[8] https://datadome.co/</p>
<h3><span id="相关链接">相关链接</span></h3>
<ul>
<li>https://datadome.co/datadome_events/black-hat-asia-2023-here-we-come/</li>
<li><a href="https://www.blackhat.com/asia-23/briefings/schedule/index.html#leveraging-streaming-based-outlier-detection-and-sliceline-to-stop-heavily-distributed-bot-attacks-30984">Leveraging
Streaming-Based Outlier Detection and SliceLine to Stop Heavily
Distributed Bot Attacks</a></li>
<li><a href="https://mboehm7.github.io/resources/sigmod2021b_sliceline.pdf">SliceLine:
Fast, Linear-Algebra-based Slice Finding for ML Model Debugging</a></li>
<li><a href="https://www.blackhat.com/asia-23/sponsored-sessions/schedule/index.html#war-of-the-bots-learnings-from-thwarting-new-automated-attack-vectors-32031">War
of the Bots: Learnings from Thwarting New Automated Attack
Vectors</a></li>
</ul>
</center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center>]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>API安全</category>
      </categories>
      <tags>
        <tag>工业落地</tag>
        <tag>业务安全</tag>
        <tag>API安全</tag>
        <tag>BlackHat</tag>
        <tag>Distributed Bot Attacks</tag>
      </tags>
  </entry>
  <entry>
    <title>流量反作弊（4）Salt Security-API安全最佳实践</title>
    <url>/posts/231N929/</url>
    <content><![CDATA[<h3><span id="salt-securityapi安全最佳实践">Salt Security
API安全最佳实践</span></h3>
<p><strong>在多数情况下，专门部署的API安全工具可以更容易、更自动化解决API安全问题。此类平台在整个API生命周期中支持一系列功能，并为组织的API业务逻辑提供必要的上下文以阻止攻击和数据暴露。</strong></p>
<p>这份API安全最佳实践将帮助企业弥补API安全策略中的差距，以下是关于如何确定问题范围和活动优先顺序的一些建议：</p>
<ul>
<li>测试API安全性同时，还需要API运行时捕获未经过标准构建更改的API和测试工具不能发现的API。</li>
<li>确保覆盖所有环境和软件供应链，而不仅仅是由API网关或API管理平台管理的API。</li>
<li>如果您不采取API防护措施，可以将重点放在API运行时防护上，将其作为“止血”措施、减缓攻击者的速度并为应用程序和API团队争取时间的一种方式。</li>
</ul>
<p><font color="red">以下内容翻译来至：SaltSecurity
Checklist-API_Security_Best_Practices</font></p>
<span id="more"></span>
<h3><span id="一-api安全设计与开发">一、API安全设计与开发</span></h3>
<p>不需要在安全需求上重新创造轮子，可以参考<strong>OWASP应用程序安全验证标准(ASVS)</strong>，也可以参考安全开发厂商的安全需求自动化推导相关系统，对所有类型的应用程序设计都有用，确保可以进行API集成，并简化API的威胁建模。</p>
<ul>
<li>制定开发和集成API安全方案</li>
<li>在设计评审时增加业务逻辑审查</li>
<li>制定符合当前开发现状的API编码指南和配置基线</li>
</ul>
<h3><span id="二-api文档">二、API文档</span></h3>
<p>不需要在安全需求上重新创造轮子，可以参考<strong>OWASP应用程序安全验证标准(ASVS)</strong>，也可以参考安全开发厂商的安全需求自动化推导相关系统。充分的文档还为一系列活动提供了好处，包括设计审查、安全测试、安全运维和保护。</p>
<ul>
<li>严格遵循API规范，比如owasp OpenAPI(OAS)</li>
<li>将API架构重新用于基本测试方法和保护方法</li>
<li>为API文档差异和API变化制定应急方案</li>
</ul>
<h3><span id="三-api发现和管理"><font color="red">三、API
发现和管理</font></span></h3>
<p>尽管API文档本身是一种最佳实践，可能不会始终如一地完成。<strong>API地址、参数和数据类型的自动发现对所有组织都至关重要。如何创建准确的API清单，以满足公司内部的众多IT需求。</strong></p>
<ul>
<li>尽可能发现API，而不仅仅在生产环境下</li>
<li>包括依赖的API和第三方API</li>
<li>标记并标识API和微服务</li>
</ul>
<h3><span id="四-api安全测试">四、API安全测试</span></h3>
<p>使用传统的安全测试工具来验证API安全风险，例如众所周知的错误配置或漏洞，但安全人员要意识到这些工具有局限性。<strong>没有一个扫描器擅长解析业务逻辑</strong>。</p>
<ul>
<li><strong>静态分析 API 代码，作为版本控制和 CI/CD
的一部分</strong></li>
<li>检查 API 代码中已知的易受攻击的依赖组件</li>
<li>动态分析和模糊测试部署的API</li>
</ul>
<h3><span id="五-前端安全">五、前端安全</span></h3>
<p><strong>保护前端应用程序或API客户端(它们依赖于后端API来提供功能和数据)可以作为分层安全方法的一部分</strong>。这部分包括一些用于保护前端的关键元素，但是要注意客户端设计的缺陷。如<strong>客户端行为分析</strong>和<strong>设备标识</strong>不经意间造成隐私问题。</p>
<ul>
<li>制定前端安全要求，包括JavaScript,Android,iOS</li>
<li>由于客户端容易被攻击和逆向分析，在客户端尽可能存储少量数据或者不存储数据</li>
<li>如果后端API已经加固，可以尝试客户端加固</li>
<li>由于监管要求，对于敏感数据需要进行处理和脱敏</li>
</ul>
<h3><span id="六-日志和监控"><font color="red">六、日志和监控</font></span></h3>
<p>日志记录和监控数据对于构建构成“正常”的基线也很有用，这样就可以快速识别和解决异常事件。</p>
<ul>
<li><strong>必须记录所有架构、应用和API的日志信息</strong></li>
<li>考虑非安全的场景，比如<strong>API的性能，上线时间</strong></li>
<li>为API分配足够的资源，可以考虑增加云资源</li>
</ul>
<h3><span id="七-api的适配和架构"><font color="red">七、API的适配和架构</font></span></h3>
<p><strong>API中间件</strong>将帮助企业加速交付、灵活运维、改进实施能力，特别是在涉及到
API 访问控制时。</p>
<ul>
<li>采用API中间件提高观察和监控能力</li>
<li><strong>采用中间件机制(如：API网关)实施访问控制</strong></li>
<li>采用能够提供深入上下文的API安全工具来增强中间件机制</li>
</ul>
<h3><span id="八-网络安全">八、网络安全</span></h3>
<p><strong>零信任体系架构的一个主要目标是实施最小特权并动态限制网络访问</strong>。但是，API必须具有连接性才能正常工作，而且许多API攻击仍然发生在可信通道和经过身份验证的会话中。</p>
<ul>
<li><strong>启用加密传输来保护API传输的数据</strong></li>
<li>如果API使用者数量较少，请使用IP地址白名单和黑名单列表</li>
<li><strong>寻求动态速率限制，并将静态速率限制作为最后的手段</strong></li>
</ul>
<h3><span id="九-数据安全">九、数据安全</span></h3>
<p><font color="red">数据安全方案旨在提供数据的机密性、完整性和可用性，但85%的组织缺乏信心，他们不知道哪些API会暴露敏感数据。</font>参考这部分可以减少敏感数据的暴露，敏感数据泄露会导致重大的监管处罚、大规模的隐私影响和公司品牌损害。【薮猫科技】</p>
<ul>
<li>启用加密传输以保护API传输的数据</li>
<li>如果API使用者数量较少，请使用IP地址白名单和黑名单列表</li>
<li>寻求动态速率限制，并将静态速率限制作为最后的手段</li>
</ul>
<h3><span id="十-认证和授权">十、认证和授权</span></h3>
<p>在考虑用于身份验证和授权的API安全最佳实践时，需要同时考虑用户和计算机基础设施，尽可能将API访问控制和身份存储外部化，包括API网关、用户和计算机凭证存储、IAM解决方案、密钥管理服务、公钥基础设施和机密管理等安全机制。</p>
<ul>
<li>持续认证和授权API使用者</li>
<li>避免使用API密钥作为身份验证手段</li>
<li>使用带有安全扩展的现代授权协议，如OAuth2</li>
</ul>
<h3><span id="十一-运行时保护"><font color="red">十一、运行时保护</font></span></h3>
<p>任何运行时保护都应该是动态的，并不断学习。识别API基础架构中的错误配置以及诸如凭据填充、暴力破解或恶意爬虫等行为异常。</p>
<ul>
<li>如果可以，<strong>启用API网关和APIM的威胁防护功能</strong></li>
<li>增加API系统 DoS 和 DDoS 防护</li>
<li>超越传统依赖规则的运行时控制，<strong>利用AI/ML和行为分析引擎来检测API攻击</strong></li>
</ul>
<h3><span id="十二-安全运营">十二、安全运营</span></h3>
<p>SoC安全人员必须经常依赖最了解应用程序体系结构和API逻辑的应用程序开发人员和API项目团队。详细的应用程序和业务逻辑在数字取证和事件响应中至关重要。<font color="red">安全管理人员需要更多地强调SecOps的人员和流程方面，而不是技术方面。</font></p>
<ul>
<li><strong>明确API运营体系中涉及的非安全和安全角色</strong></li>
<li>创建以API为中心的<font color="red">事件响应手册</font></li>
<li>显示可操作的API事件和不转储数据，避免SOC资源耗尽</li>
</ul>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>https://hksanduo.github.io/2022/09/08/2022-09-08-salt-api-security-best-practices/</li>
<li>https://salt.security/blog/api-security-best-practices</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>API安全</category>
      </categories>
      <tags>
        <tag>工业落地</tag>
        <tag>业务安全</tag>
        <tag>API安全</tag>
      </tags>
  </entry>
  <entry>
    <title>流量反作弊（5）Gartner-Innovation Insight for API Protection</title>
    <url>/posts/1FRRBGP/</url>
    <content><![CDATA[<p><strong>[Published 10 October 2022]</strong></p>
<p>Web
API流量和攻击的数量和严重程度都在增长。新方法通过特定的API安全功能补充了传统的web应用程序安全措施。安全和风险管理领导者应确定何时寻求这种额外的保护。</p>
<h5><span id="主要发现">主要发现</span></h5>
<ul>
<li>安全领导者正在寻找额外的安全功能来保护他们的API。他们正在扩展现有的API网关（GW）、web应用程序和API保护（WAAP）解决方案，尤其是在具有高安全要求的行业垂直领域。</li>
<li>Gartner客户在询问过程中最关心的问题包括个<strong>人数据盗窃、账户接管和自动内容抓取</strong>。</li>
<li>API保护创新保护web
API免受攻击、滥用、访问违规和拒绝服务（DoS）攻击。</li>
<li>API保护产品提供三种主要类型的功能-<strong>发现、姿态管理和运行时保护</strong>。</li>
</ul>
<h5><span id="推荐">推荐</span></h5>
<p>为了保护其API，安全和风险管理领导者应：</p>
<ul>
<li><strong>从发现和分类您的API开始</strong>。执行威胁建模，以确定减轻风险所需的特定安全机制。</li>
<li>评估当前WAAP或API网关提供的API保护。如果您的风险缓解需要额外的API保护，请调查能够提供额外保护层的API安全专家。</li>
<li>通过使用内部安全操作中心（SOC）或托管服务，解决行为异常检测可能产生的安全分析工作负载。</li>
<li>执行应用程序安全测试（AST）或渗透测试练习，以发现可能隐藏的业务逻辑问题。</li>
</ul>
<span id="more"></span>
<h5><span id="战略规划假设">战略规划假设</span></h5>
<p>到2025年，将管理不到50%的企业API，因为API的爆炸性增长超过了API管理工具的能力。</p>
<p>到2025年，至少70%的组织将只为其生产的公共API部署专门的运行时保护，而其他API则不受监控，缺乏API保护。</p>
<p>到2026年，40%的组织将选择基于高级API保护和web应用程序安全功能的web应用程序和API保护提供商，而今年这一比例不到15%。</p>
<h3><span id="一-说明">一、说明</span></h3>
<p>随着API流量的增长，API安全性越来越受到关注。Web
API互连应用程序，并成为企业数字化转型的核心。在生成和公开web
API时，组织被调用来定义它们与其他实体（如合作伙伴和客户）的通信方式。缺乏使这些通信标准化的最佳做法。组织构建的API通常是导致高可见性漏洞的原因。</p>
<p>许多组织保护API流量的方式与保护其遗留应用程序的方式相同。由于通信量的不同结构（例如，JSON有效负载），或者由于API事务的特性（例如，由于频率高），通用应用程序安全控制可能表现不佳。特别是在安全要求很高的垂直行业，安全领导者正在寻找额外的安全功能来保护他们的API。在这项研究中，我们探索了新兴的API安全创新，这些创新将帮助组织发现其API，识别和解决漏洞，并在运行时保护API。</p>
<h3><span id="二-描述">二、描述</span></h3>
<blockquote>
<p><strong>定义：API保护创新保护web
API免受攻击、滥用、访问违规和拒绝服务（DoS）攻击</strong>。虽然所有类型的API都可以受到保护，但通常组织最初关注的是自主开发的、面向公众的API，并为关键应用程序提供连接。这些解决方案通过结合API参数和有效负载的内容检查、流量管理，以及至少用于异常检测的流量分析，提供API安全性。</p>
</blockquote>
<p>API安全创新主要由新兴的API安全供应商提出。然而，API安全功能可以作为API网关、WAAP和AST供应商扩展产品组合的一部分获得。</p>
<p><strong>根据具体的体系结构，API安全解决方案可以作为服务或本地产品提供，也可以采用混合方法提供</strong>。特别地，该解决方案可能需要收集数据并将数据发送回其云以进行行为异常检测，或者可能需要完全在本地识别异常模式。大多数解决方案都不是联机解决方案。相反，它们通过与企业内的应用程序和基础架构组件集成来获取流量数据和其他信息。</p>
<ul>
<li><p><font color="red">许多API安全产品的一个重要部分是发现API的能力。</font></p></li>
<li><p><font color="red">完整的API安全程序应包括开发和测试阶段的控制。大多数API保护工具都会评估API的配置错误。</font></p></li>
</ul>
<h3><span id="三-优点和用途">三、优点和用途</span></h3>
<p>Gartner客户在询问过程中表达的一些首要担忧包括<strong>个人数据盗窃</strong>（例如，利用Broken
Object Level
Authorization[BOLA]漏洞）、<strong>账户接管</strong>和<strong>自动内容抓取</strong>（例如，价格抓取）。<strong>Gartner客户报告的一种常见情况是由后端团队提供API。其目的是只有某些前端应用程序会使用API，但攻击者绕过允许的前端应用程序，成功地直接访问了后端API。</strong></p>
<p>虽然安全领导者可以使用<strong>WAAP、API
GW和AST工具</strong>中的现有功能来对抗API攻击，但这种方法带来了许多挑战：</p>
<ul>
<li>安全主管通常不拥有由基础设施和操作团队（如API
GW）管理的工具，AST扫描仪正越来越多地将所有权转移给应用程序开发团队。</li>
<li>API
GW和WAAP安全功能可能会受到限制，具体取决于供应商。虽然一些领先的提供商已经包括了更先进的API发现和控制，但许多提供商仍局限于提供节流、安全传输和类似类型的安全策略实施。</li>
<li>高安全性和受监管的垂直行业的安全领导者在询问能够立即提供所需功能的高级解决方案时表达了他们的愿望。</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304291603086.png"></p>
<h4><span id="31-discovery-发现">3.1 Discovery-发现</span></h4>
<p>API保护产品自动创建组织已生产和使用的API的库存。有多种发现方法，但还没有一个既定的最佳实践：</p>
<ul>
<li>许多解决方案混合使用<strong>流量镜像分析和查询现有基础设施</strong>（如API
GW、web应用程序防火墙[WAF]和容器平台）来发现和清点正在使用的API。对于面向公共或合作伙伴的API，初始部署步骤通常包括指示根域名。</li>
<li>一些解决方案检查代码库和<strong>系统开发生命周期（SDLC）</strong>的其他实例。</li>
<li>许多AST提供商使用AST技术发现API，如<strong>交互式应用程序安全测试（IAST）</strong>、网络爬行，甚至移动应用程序代码的静态分析。</li>
<li>大多数工具还能够接收描述文件，如Swagger和GraphQL文件，然后在运行时将流量的真实性与吸收的模式进行比较（请参见注释1）。</li>
</ul>
<h4><span id="32-posturemanagement-状态评估">3.2 Posture
Management-状态评估</span></h4>
<ul>
<li><font color="red">一旦API保护产品清点了API，它就会对其进行错误配置评估</font>。例如，API可以在URL中显示敏感数据，或者在不进行身份验证的情况下返回敏感数据作为响应。OWASP
API安全十大问题列表中有许多最常见的问题。</li>
<li>解决方案越来越多地试图评估每种<strong>错误配置</strong>的风险。这种能力是不成熟的，但在不断发展。我们已经看到了一些解决方案，这些解决方案试图了解API的关键性、API背后的业务逻辑、错误配置的严重性，以及可以指示或多或少风险的各种其他元素。</li>
<li>工具也开始就如何纠正错误配置提供建议。</li>
</ul>
<h4><span id="33-runtimeprotection-实时保护">3.3 Runtime
Protection-实时保护</span></h4>
<p><strong>API安全解决方案的第三个组件侧重于识别恶意行为的指示模式</strong>。一个典型的例子是BOLA攻击，其中传入的请求要求一个帐号的数据与API客户端进行身份验证的帐号不匹配。异常检测引擎通常使用类似攻击的数据集进行训练，并且能够识别攻击。【？】</p>
<p>此外，该解决方案将从API中摄取与非恶意行为相关的数据。大多数解决方案能够在相对较短的数据摄取时间后进行操作。根据解决方案以及设置解决方案的安全领导者希望的入侵程度，产品可以发出补救通知单或直接对基础设施采取行动来阻止攻击者。</p>
<h3><span id="四-风险">四、风险</span></h3>
<p><font color="red">任何使用行为异常检测的创新都将不可避免地出现误报。异常行为并不总是意味着某些东西是恶意的，当前的机器学习只能在确定业务逻辑以对发现进行分类方面走得更远。</font>如果一个组织已经有了一个实质性的SOC，这可能不会带来问题。对于其他组织来说，重要的是要有一个托管服务——无论是来自供应商本身，还是来自第三方托管安全服务提供商（MSSP）。</p>
<p>API安全范围广泛。用例可能会变得复杂，并不是每一个威胁都能以相同的方式得到解决。API保护最常见的用例是保护外部暴露的API。然而，安全领导者需要单独研究大量用例，以确定解决方案。例如：</p>
<ul>
<li>东西向API的内部连接可能受益于微细分；</li>
<li>可能需要应用屏蔽的移动应用场景；</li>
<li>开放银行和其他API集成用例可能在API网关和iPaaS（平台即服务集成）中找到基础，重点是访问控制。</li>
</ul>
<p>安全人员应该进行威胁建模练习，以识别这些用例。</p>
<p>从发现来看，许多API解决方案只发现当前使用的API。某些API可能未与现有API
GW集成，仅在调用时才会在流量中看到，这可能为时已晚，无法识别错误配置。如果不检查代码，API可能会出现漏洞。安全领导人可以集成这些类型的发现，可能使用代码检查和普查练习。</p>
<p>API安全创新可识别可能导致漏洞利用的错误配置。然而，在撰写本文时，我们只看到了一些产品，其中包括传统意义上的API安全测试，包括<strong>静态应用程序安全测试（SAST）、动态应用程序安全性测试（DAST）和模糊化</strong>
<strong>安全主管应始终将API安全功能与开发生命周期中嵌入的真正AST集成在一起。</strong>此外，自动化工具将能够识别某些标准化的业务逻辑问题，但在大多数情况下，只有手动渗透测试或众测试才能发现可能被欺诈攻击者利用的业务逻辑。</p>
<p>在2021 Gartner Enabling Cloud-Native
DevSecOps调查中，75%的受访者表示他们使用WAAP来保护生产中运行的云应用程序。40%的人表示，他们在将成熟工具与创新工具相结合方面面临挑战。引入新工具可能会扰乱日常运营和团队平衡。虽然API安全工具的组织所有权倾向于以安全为中心，但许多成熟的组织开始将安全权限委托给安全团队以外的职能部门。</p>
<p><strong>安全主管通常管理WAF和WAAP</strong>，但API网关通常由API center
of excellence（COE）或API平台团队管理。</p>
<h3><span id="五-选择">五、选择</span></h3>
<p>WAAP是一种与API保护工具有很大重叠的安全工具。云原生应用程序保护平台（CNAPP）也代表了一个可能有一些重叠的新兴领域，尽管这些平台的范围仍在确定中。</p>
<p>安全正在经历一段整合期。我们预计API安全领域将产生数量有限的最佳供应商，这些供应商将保持独立并扩展其产品组合。然后，我们预计许多其他应用程序将成为更广泛的应用程序安全产品的一部分，无论是WAAP还是CNAPP供应商。</p>
<h3><span id="六-建议"><font color="red">六、建议</font></span></h3>
<p>安全和风险管理领导者应：</p>
<ul>
<li><strong>从发现和分类您的API开始。执行威胁建模，以确定您需要哪些特定的安全机制来降低风险。</strong></li>
<li><strong>使用云web应用程序的关键功能和API保护以及API全生命周期管理的关键功能，评估当前WAAP或API网关提供的API保护。如果您的风险缓解需要额外的API保护，请调查能够提供额外保护层的API安全专家。</strong></li>
<li><strong>通过使用内部SOC或托管服务，解决行为异常检测可能产生的安全分析工作负载。</strong></li>
<li><strong>对新的或新修改的API进行渗透测试，以发现在执行自动扫描时可能隐藏的业务逻辑问题。然后对API进行持续的应用程序安全测试。</strong></li>
</ul>
<p><font color="red">代表厂商：</font></p>
<p>42Crunch; <strong>Akamai</strong>; Cequence Security;
<strong>Imperva</strong> (CloudVector); <strong>Neosec</strong>; Noname;
<strong>Salt</strong>; Traceable; Wib.</p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><a href="https://www.gartner.com/doc/reprints?id=1-2BUGX57W&amp;ct=221129&amp;st=sb&amp;aliId=eyJpIjoiakE5cjJLeWNYc0pPVFR1bCIsInQiOiJpVVJhXC80QXFcL29obGxQeitUVmZWcEE9PSJ9">Gartner
Innovation Insight for API Protection</a></li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>API安全</category>
      </categories>
      <tags>
        <tag>工业落地</tag>
        <tag>业务安全</tag>
        <tag>API安全</tag>
        <tag>Gartner</tag>
      </tags>
  </entry>
  <entry>
    <title>流量反作弊（7）Salt Security-What‘s the of use-cases Salt Surity?</title>
    <url>/posts/22PANQ7/</url>
    <content><![CDATA[<h3><span id="whats-the-of-use-casessalt-security">What‘s the of use-cases
Salt Security?</span></h3>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305041503340.svg" alt="img"><span id="more"></span></p>
<h3><span id="一-发现所有apidiscover-allapis">一、发现所有API（Discover all
APIs）</span></h3>
<p><strong>Salt能够自动、持续地发现所有API，捕获有关它们的详细信息，以帮助您消除盲点，评估风险，并在环境不断发展和变化时保护API。</strong></p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031157634.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="11-实现全面可视性">1.1 实现全面可视性</span></h4>
<p><font color="red">自动、连续地发现所有内部、外部和第三方API，包括参数、参数函数和暴露的敏感数据等详细信息，以帮助您了解攻击面并评估风险。Salt平台部署在任何应用程序环境中，无需内联或需要代理即可捕获API流量。</font>API不在您的网关中或记录在OpenAPI规范（又名Swagger）中？没问题，我们会全部找到的。</p>
<h4><span id="12-查找影子和僵尸api">1.2 查找影子和僵尸API</span></h4>
<p><strong>Salt客户发现的API比他们文档中提到的要多40%到800%。这些未知或影子API对组织来说是一个重大风险，因为它们经常暴露PII或其他敏感数据</strong>。僵尸API——该组织认为已被禁用的不推荐使用的API——带来了另一种风险。上传您的文档文件以与Salt的库存进行比较，并下载我们的完整列表以增强您的文档。</p>
<h4><span id="13-维护最新的api库存">1.3 维护最新的API库存</span></h4>
<p>在当今的敏捷和DevOps世界中，API一直在变化，开发人员往往没有及时更新文档。利用Salt平台的连续发现功能，使您的API库存保持最新和准确，尽管这些经常更改。接收新的和更改的API的警报，以便您可以验证从开发/测试到生产的所有API是否符合组织的安全标准。</p>
<h3><span id="二-防止敏感数据泄露preventsensitive-data-exposure">二、防止敏感数据泄露（Prevent
Sensitive Data Exposure）</span></h3>
<p><strong>Salt详细说明了所有API中暴露的敏感数据的每个实例，以降低风险。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031157755.png" alt="img" style="zoom:50%;"></p>
<h4><span id="21-详细暴露的敏感数据">2.1 详细暴露的敏感数据</span></h4>
<p>Salt平台广泛的发现功能记录了发送或使用PII和其他敏感数据的每个端点。该平台表征了每种数据类型，如社会安全号码、IBAN或账户ID，标记敏感信息，并为您提供一个完整的目录，可用于确定任何潜在风险，并作为<strong>合规审计的一部分。</strong></p>
<blockquote>
<p><font color="red">PII，国内隐私保护相关学习</font></p>
</blockquote>
<h4><span id="22-发现常见和专有的敏感数据">2.2 发现常见和专有的敏感数据</span></h4>
<p>敏感数据包括令牌和信息，如持卡人数据、客户专有网络信息（CPNI）、受保护健康信息（PHI）和个人身份信息（PII）。您还可以自定义Salt平台，以识别特定于您的公司或行业的敏感数据。</p>
<h4><span id="23-识别敏感数据暴露的变化">2.3 识别敏感数据暴露的变化</span></h4>
<p>Salt平台会自动更新您的敏感数据暴露详细信息，使您能够在API更改时识别新的暴露点。您将收到暴露的敏感数据的新实例的警报，以便评估风险并与开发团队合作以减少暴露。</p>
<h3><span id="三-阻止-api-攻击">三、阻止 API 攻击</span></h3>
<p><strong>Salt 使用云规模大数据和获得专利的人工智能 (AI)
来并行分析和关联数百万用户的活动，以便及早识别和阻止攻击。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031157853.png" alt="img" style="zoom: 50%;"></p>
<ul>
<li><strong>See all API traffic and maintain a baseline</strong></li>
</ul>
<blockquote>
<p><strong>查看所有 API 流量并维护基线</strong></p>
</blockquote>
<p>Salt使用大数据和专利人工智能来分析所有API流量，并为您独特的API建立详细的合法行为基线。该平台在每个实体或API的100多个典型行为属性上维护状态，包括<strong>参数输入的一致性、访问频率、响应量、敏感数据量、数据类型和响应代码等属性</strong>。在API发生变化时，Salt平台将调整基线，避免误报，同时在快速变化的环境中保护您——无需人工干预。</p>
<ul>
<li><strong>Identify malicious activity, even “low and slow”
attacks</strong></li>
</ul>
<p><strong>Salt平台关联所有用户活动，因此恶意行为可以在攻击者的侦察阶段早期被识别</strong>。通过分析所有API活动，Salt具备揭示攻击者微妙迹象、区分“不同”的行为和“恶意”的行为，并在攻击者成功之前阻止攻击者所需的上下文。</p>
<ul>
<li><strong>Protect against top API threats</strong></li>
</ul>
<p><strong>Salt可以识别并阻止web应用程序防火墙（WAF）和API网关错过的攻击</strong>。这些基于代理的工具无法看到API活动的完整上下文，也无法将不同的事务关联回一个公共实体。在很短的学习时间内，Salt平台为您独特的API创建了行为基准，并保护您的API免受攻击，包括<strong>OWASP
API安全Top 10中概述的威胁</strong>。</p>
<blockquote>
<p><strong><font color="red">GET：OWASP API Top 10
来衡量当前的防御能力状态</font></strong></p>
</blockquote>
<ul>
<li><strong>Stop attackers before they succeed</strong></li>
</ul>
<p><strong>Salt捕获完整的攻击时间线，将其显示在我们的仪表板中，并将信息发送到您的SIEM，供事件响应团队进行分析</strong>。您也可以选择让Salt平台自动阻止攻击。Salt利用与内联工具（<strong>如API网关和防火墙</strong>）的集成，在攻击者成功之前阻止他们。</p>
<blockquote>
<p><strong><font color="red">GET: 告警信息管理SIEM？</font></strong></p>
</blockquote>
<h3><span id="四-防止账户接管-数据泄露">四、防止账户接管、数据泄露</span></h3>
<p>Salt可以检测到不良行为者试图获得未经授权的账户访问权限的微妙操作，因此我们可以阻止攻击者窃取公司和客户数据。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031157920.png" alt="img" style="zoom:50%;"></p>
<h4><span id="41-基准典型数据访问行为">4.1 基准典型数据访问行为</span></h4>
<p>Salt平台创建了一个典型行为的基线，并识别任何偏离基线的活动。我们的平台可以检测偏差，例如数据的异常移动以及试图操作令牌、用户ID或API参数。这些攻击通常来自经过身份验证的用户，因此仅仅依靠访问控制来停止exfiltering并不能保证您的数据安全。</p>
<h4><span id="42-定点攻击者">4.2 定点攻击者</span></h4>
<p>通过分析所有API活动，Salt平台编译了区分“不同”和“恶意”活动所需的上下文。例如，如果API发生变化，所有用户的行为都会发生变化，但只有攻击者才能显示不同的使用模式。Salt平台将给定实体的所有活动关联起来，因此可以查明试图窃取您的数据的攻击者并阻止他们，或向您的安全团队发送警报。</p>
<h4><span id="43-防止ato或未经授权访问数据">4.3 防止ATO或未经授权访问数据</span></h4>
<p>因为Salt平台了解每个实体和API端点的典型行为，所以它会立即检测偏差，例如操作API端点或传输更多数据的位置。您可以将平台配置为自动阻止此类活动，或向事件响应团队发送带有完整攻击时间表的警报，以分析活动并阻止ATO（账户劫持）或数据提取。</p>
<h3><span id="五-左移具有主动api安全性shiftleft-with-proactive-api-security">五、“左移”，具有主动API安全性（“Shift
left" with proactive API security）</span></h3>
<p><strong>Salt支持在构建阶段针对您的API进行API测试和扫描，并结合在运行时学到的修正见解，为开发人员提供强化其API所需的见解。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031157068.jpeg" alt="img" style="zoom:50%;"></p>
<h4><span id="51-api设计分析">5.1 API设计分析</span></h4>
<p>在测试/开发环境中，Salt平台允许您加载OAS或Swagger文件，并提供对任何安全漏洞的完整分析，例如缺少API端点、缺少参数、与参数定义的差异以及其他有价值的见解。</p>
<h4><span id="52-上下文api安全测试">5.2 上下文API安全测试</span></h4>
<p><strong>Salt
Security平台在预生产、开发和运行时环境中提供了强大的攻击模拟</strong>。这些模拟有助于组织在生命周期的早期发现安全漏洞和业务逻辑缺陷，与CI/CD系统的集成意味着开发人员可以在发布或修改API之前解决安全漏洞。Salt裁缝攻击客户在这些环境中学习到的API。</p>
<blockquote>
<p>CI/CD系统是一种软件开发流程，通过自动化测试、构建和部署，使软件开发团队能够更快地交付新功能和修复程序错误。</p>
</blockquote>
<h4><span id="53-api漂移分析">5.3 API漂移分析</span></h4>
<p>Salt平台可以帮助您在暂存/测试环境中针对API运行测试流量。然后，它将这些结果与您的OAS/Swagger文件进行比较，并显示您的文档和实时API流量的分歧。您可以自动导出Salt平台库存的API详细信息，以便轻松保持API文档的最新和准确。</p>
<h4><span id="54-在运行时学到的补救见解">5.4 在运行时学到的补救见解</span></h4>
<p>通过在运行时捕获攻击者活动并与开发人员共享，Salt平台暴露了正在使用的黑客侦察策略，并提供了开发人员可以用来填补安全漏洞的详细补救见解。这些见解增加了开发人员的教育，使他们能够在未来不断提高构建的API的安全性。团队可以直接从Salt平台发送Jira票证、Slack通知和其他开发者通信。</p>
<h4><span id="55-用于构建管道的cicd集成">5.5 用于构建管道的CI/CD集成</span></h4>
<p>Salt提供了内置的集成，因此您可以在构建阶段简化和自动化API漏洞验证。对于Salt确定未达到安全标准的API，您可以选择允许该构建成功，但需要开发人员签署风险声明，或者选择失败构建，在CI/CD系统中直接向开发人员显示所需的修复。Salt发出的工单包括开发团队需要的细节，以便他们可以在发布构建之前解决安全漏洞和风险。</p>
<h3><span id="六-加快事件响应accelerateincident-response">六、加快事件响应（Accelerate
Incident Response）</span></h3>
<p><strong>Salt提供了攻击者活动的完整视图，统一呈现在时间轴上，以减少调查时间，帮助团队自信地应对攻击。</strong></p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031157173.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="61-连接攻击者活动的线索">6.1 连接攻击者活动的线索</span></h4>
<p><font color="red">Salt将同一用户的所有攻击活动相关联到一个攻击时间轴中，为安全团队提供了攻击步骤和顺序的清晰视图。Salt平台能够将分散的活动与单个用户相关联，并识别攻击者使用不同的ID、IP地址和设备来传播攻击的努力。</font></p>
<h4><span id="62-减少警报和误报">6.2 减少警报和误报</span></h4>
<p><font color="red">Salt平台具备大数据和人工智能引擎，同时维护着数百万用户之间典型行为的大规模基线。它可以区分简单的一次性用户错误或API更改与攻击者的模式，避免了误报，使许多安全解决方案无法使用。</font>当恶意活动是罪魁祸首时，Salt平台将活动整合起来，仅针对攻击者发送单个警报，而不是每个攻击者活动都发送一个警报，使安全团队能够快速简单地了解情况并采取行动或利用Salt的自动阻止。</p>
<h4><span id="63-阻止攻击者而不阻止合法流量">6.3 阻止攻击者而不阻止合法流量</span></h4>
<p>Salt平台为每个用户建立和保留上下文，以区分攻击者。它将攻击者的所有活动相关联并编译成一个时间轴视图展示数据。然后，安全团队可以放心地采取行动并阻止攻击者，而不必担心破坏合法流量。</p>
<blockquote>
<p><strong><font color="red">与现有工具和工作流集成</font></strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305041459368.png" alt="image-20230504145944888" style="zoom:50%;"></p>
<p><strong>Salt与您已经使用的工具和工作流配合使用，因此您可以在不引入复杂性或摩擦的情况下开始保护您的API。</strong>有了Salt，您的安全和DevOps团队将：</p>
<ul>
<li>通过向您的SIEM发送警报，包括攻击者活动的完整上下文，自信地应对威胁。</li>
<li>手动或自动使用现有实施点（如API网关或web应用程序防火墙（WAF））阻止攻击者。</li>
<li>通过Jira、PagerDuty和Slack等工具向DevOps团队发送可操作的见解，有效消除漏洞。</li>
</ul>
</blockquote>
<h3><span id="七-提供补救见解provideremediation-insights">七、提供补救见解（Provide
Remediation Insights）</span></h3>
<p><strong>Salt通过在运行时学习的补救见解增强了生产前扫描，以帮助安全和开发团队改进其API的安全状况。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031157404.png" alt="img" style="zoom:50%;"></p>
<h4><span id="71-从攻击者那里学习">7.1 从攻击者那里学习</span></h4>
<p>Salt平台让您将攻击者变成渗透测试员，并从他们探测API漏洞的活动中获得洞察力。该平台将识别其他方法（如渗透测试、安全测试和扫描）无法发现的高优先级漏洞。</p>
<h4><span id="72-为开发人员提供洞察力">7.2 为开发人员提供洞察力</span></h4>
<p><strong>使用Salt平台，您可以轻松为开发人员提供可以用来加强API的洞察力。Salt提供有潜在漏洞的端点、攻击者尝试利用这些漏洞的方式以及修复建议等详细信息。</strong>您可以设置Salt平台将这些洞察力发送给使用现有工作流和工具（如Jira和ServiceNow）的开发团队，以便跟踪漏洞的解决过程。</p>
<h4><span id="73-关注重要的漏洞">7.3 关注重要的漏洞</span></h4>
<p>扫描解决方案仅发现已知威胁，并不能评估您组织的独特API。这些解决方案还发现许多理论威胁，使开发团队不知所措，无法优先考虑。使用Salt，您可以立即获得与您的API独特的高优先级漏洞，以便开发团队可以将有限的资源集中在最大的威胁上，以获得最大的影响。</p>
<h4><span id="74-发布更安全的api">7.4 发布更安全的API</span></h4>
<p><strong>Salt为您的安全和开发团队提供了持续的现实洞察力，这是预生产扫描或测试无法提供的。</strong>Salt
Insights包括您组织的API如何在生产环境中使用以及如何被滥用的独特上下文。这些具体而相关的洞察力有助于开发人员建立他们的安全意识，并改进开发最佳实践，以最小化未来的API漏洞。</p>
<h3><span id="八-简化法规遵从性simplifycompliance">八、简化法规遵从性（Simplify
Compliance）</span></h3>
<p><font color="red">Salt维护所有API的最新、全面和整合的库存，包括详细说明那些暴露敏感数据的API，以帮助您满足法规遵从性要求。</font></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031157461.png" alt="Compliance Use Case" style="zoom:50%;"></p>
<h4><span id="81-保持最新的api清单">8.1 保持最新的API清单</span></h4>
<p>在快速发展的环境中，API经常变化，因此很难保持最新的清单。Salt平台持续分析所有API，并创建一个全面和综合的清单，即使开发人员进行更改，也可以保持最新。<strong>清单包括已知的API、影子API和僵尸API</strong>——所有人都认为已经被废弃的旧API。Salt平台还包括审计人员日益要求的精细参数细节。</p>
<h4><span id="82-报告敏感数据曝露">8.2 报告敏感数据曝露</span></h4>
<p>使用Salt，您可以深入了解每个API，包括敏感数据的曝露位置。使用Salt报告共享或收集敏感数据的确切API端点，以及API如何使用敏感数据的详细信息。</p>
<h4><span id="83-识别api更改">8.3 识别API更改</span></h4>
<p>Salt平台帮助您跟踪更新，因此您知道何时发布新的API或现有API发生更改。深入了解每个API使您能够审计新API端点的添加位置或敏感数据的曝露位置。Salt平台会自动更新这些详细信息，以简化报告。</p>
<h4><span id="84-满足合规要求">8.4 满足合规要求</span></h4>
<p><strong>Salt平台为您提供满足PCI
DSS、PSD2、HIPAA、CCPA、GDPR、LGPD或其他法规的数据保护、数据隐私和其他要求所需的洞察力。</strong>Salt仪表板提供了您所有API的完整视图，您可以导出详细报告，帮助审计员记录您当前的API环境和API共享的敏感数据。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>Salt：https://salt.security/use-cases/discover-all-apis?</li>
<li>https://salt.security/use-cases</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>API安全</category>
      </categories>
      <tags>
        <tag>工业落地</tag>
        <tag>API安全</tag>
        <tag>Salt Security</tag>
        <tag>DDos</tag>
      </tags>
  </entry>
  <entry>
    <title>流量反作弊（6）Salt Security-Blocking a Low-rate-per-bot HTTP DDoS Attack</title>
    <url>/posts/2KH8Z8N/</url>
    <content><![CDATA[<h3><span id="saltcustomer-attack-case-study-blocking-a-low-rate-per-bot-http-ddosattack">Salt
Customer Attack Case Study: Blocking a Low-rate-per-bot HTTP DDoS
Attack</span></h3>
<h3><span id="一-what-is-an-http-ddosattack">一、What is an HTTP DDoS
Attack?</span></h3>
<p>一个HTTP
DDoS攻击是一种恶意企图，旨在通过利用大量设备（称为僵尸网络）向网络服务或中间设备发送高速的请求，从而使其无法为合法用户提供服务。攻击者会利用这些攻击来压倒网络服务的资源，或者中间设备的资源，以阻止它们为合法用户提供服务，从而达到攻击的目的。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031153193.png" alt="img" style="zoom:50%;"></p>
<p><strong>攻击的振幅是通过受害者网络服务接收到的总请求速率来衡量的。</strong>该速率是由僵尸网络的规模和每个僵尸程序的恶意请求速率决定的。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305041511500.png" alt="img" style="zoom:50%;"></p>
<p><strong>每个恶意请求可能看起来合法，或者至少不会与典型的Web应用程序攻击匹配</strong>。要区分恶意请求和合法请求以检测HTTP
DDoS攻击，通常可以采取以下方法：</p>
<ol type="1">
<li><strong>限制每个源客户端的请求数量</strong>。</li>
<li><strong>对源客户端进行指纹识别，以区分恶意请求和合法请求</strong>。</li>
<li>使用一些Web应用程序防火墙（WAF）中包含的预定义签名。</li>
</ol>
<p>这些方法可以帮助检测和缓解HTTP
DDoS攻击，但需要注意的是，攻击者可能会采取措施绕过这些限制和检测方法。因此，还应使用其他安全措施来提高网络服务的安全性。</p>
<span id="more"></span>
<h3><span id="二-detection-andmitigation-for-apis">二、Detection and
Mitigation for APIs</span></h3>
<p>指纹源客户端可以使用web质询来区分恶意流量和合法流量，该质询由受攻击的web服务本身或WAF触发。然后可以阻止受牵连的客户端。这些网络挑战【挑战应答？】可能包括：</p>
<ul>
<li>JavaScript挑战–向web客户端展示JS脚本。合法用户的浏览器可以很容易地渲染并返回其输出，而没有JavaScript渲染功能的客户端则会被定罪。</li>
<li>302重定向挑战–web服务或WAF将web客户端重定向到另一个页面。合法用户的浏览器会被重定向并成功地更新其请求，而没有实现完整HTTP堆栈的客户端会不断发送原始请求，因此会被定罪。</li>
<li>Cookie挑战-网络服务或WAF向网络服务发送Cookie作为响应的一部分。合法用户的浏览器在下一个请求中返回它，而没有实现完整HTTP堆栈的客户端则没有，因此会被定罪。</li>
<li>CAPTCHA–web服务或WAF要求用户插入特定信息。只有人类才能理解它的格式——程序无法理解——因此合法用户可以在自动化工具被淘汰的情况下继续浏览。</li>
</ul>
<p>这些挑战可以阻止缺乏JavaScript渲染功能和完整HTTP堆栈实现的基本恶意自动化工具。<strong>然而，网络挑战（web
challengs）无法抵御包括这些功能在内的高级自动化工具。</strong><font color="red">【挑战应答是容易破解的】</font></p>
<p>此外，网络挑战不能用来保护应用程序编程接口（API）——机器对机器通信的无处不在的接口。API为专用客户端提供服务，这些客户端通常缺乏JavaScript渲染以及完整的HTTP堆栈实现。在这种情况下，网络挑战也会阻止合法客户端。<strong>这一缺点使得请求速率限制和预定义签名成为唯一可用于保护的缓解方法。</strong></p>
<h3><span id="三-the-low-rate-per-botattack-approach">三、The Low-rate-per-bot
Attack Approach</span></h3>
<blockquote>
<p>每个机器人的低速率攻击方法</p>
</blockquote>
<p>问题是不良行为者已经发现传统工具可以识别这些自动化的高速率攻击，并调整了攻击方法。为了避免被传统的安全工具检测到，不良行为者会降低攻击速度，保持在速率限制阈值以下。但是，如果他们降低了攻击的速度，他们怎么还能破坏网络服务呢？答案是简单的数学。他们降低了任何给定的单个机器人的请求发送率，以使其不被发现，但他们添加了越来越多的机器人。因此，进入web服务的总请求率仍然很高——高到足以危及服务可用性。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031153300.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="四-customercase-study-blocking-an-in-the-wild-attack">四、Customer
Case Study – Blocking an In-the-Wild Attack</span></h3>
<blockquote>
<p>客户案例研究——阻止一次疯狂攻击</p>
</blockquote>
<p><strong>那么公司该怎么办呢？如何保护自己免受这些日益复杂的API攻击？<font color="red">您需要一种技术，可以将看似不相关的“用户”的流量模式拼接在一起，以便发现这种攻击。</font></strong>今天的Web应用程序防火墙（WAF）虽然比20年前的同行更智能，但仍然孤立地看待交易和“用户”，不能在总体和长期上看到这种模式。</p>
<p><font color="red">为了挫败这种攻击，您需要跨越更长的时间轴和覆盖数百个“用户”和API交互的视角或上下文。这就是Salt平台的作用。</font></p>
<p>Web应用程序防火墙（WAF）可以在秒和分钟的时间范围内跟踪客户端的请求数量，而Salt
Security API Protection
Platform可以在更长、更多样化的时间轴和持续时间内跟踪客户端请求。通过其云规模的大数据平台以及人工智能（AI）和机器学习（ML）算法，Salt可以轻松识别与合法请求不同的请求。这种动态异常检测使用户能够快速发现低速恶意请求，并具有非常低的误报率。</p>
<p>几周前，Salt
Security的一位客户通知我们的SOC团队，该公司的一个Web服务正受到未知威胁的攻击。同时，Salt平台检测到高入站流量。使用Salt平台，我们的分析师检测到一个由数千个机器人组成的僵尸网络对认证（也称为登录）端点发起的HTTP
DDoS攻击。由于每个单独的机器人只会每分钟发送一个请求，因此云WAF认为此流量是合法的，并让其通过。然而，由于累积负载，合法用户无法对Web服务进行身份验证。</p>
<p>Salt
API发现算法还立即检测到以下异常情况——恶意请求缺少必需的负载字段。Web服务对这些无效请求做出了400
Bad
Request响应代码的响应，Salt平台将其检测为此API端点的异常响应代码，这有助于进一步区分机器人流量和合法的身份验证尝试。</p>
<blockquote>
<p><strong><font color="red">GET：我们要离线发现异常模式，来抵御低数率的分布式攻击；</font></strong></p>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031153314.png" alt="img" style="zoom:50%;"></p>
<p>我们的分析师将这些发现报告给了客户的安全工程师，<strong>他们激活了Salt和云WAF之间已经定义的集成，以阻止整个僵尸网络的源IP</strong>。有了这种自动阻止，web服务的负载显著下降，合法用户能够再次进行身份验证。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031153327.png" alt="img" style="zoom:50%;"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305031153414.png" alt="img" style="zoom:50%;"></p>
<h3><span id="五-automatedor-manual-blocking-the-customers-choice">五、Automated
or Manual Blocking – the Customer’s Choice</span></h3>
<blockquote>
<p>自动或手动阻止–客户的选择</p>
</blockquote>
<p><strong>Salt的客户可以选择在Salt平台检测到攻击时启用自动或手动阻止</strong>。客户通常会从手动阻止开始，这样他们就有机会在采取行动之前调查已确定的攻击。这种按需选项虽然较慢，但可以避免在误报情况下阻止合法用户。</p>
<p>当看到相同的攻击重复出现时，许多客户通常会选择将Salt集成到其内联设备中，并将其设置为自动阻止模式。这种方法有效地将Salt的带外部署（避免了任何应用程序影响）转变为内联保护设备，立即停止攻击流量。具备此种灵活性意味着Salt平台支持一系列客户方法，并随着他们在API安全成熟度模型中的发展而进行相应调整。</p>
<blockquote>
<p><strong><font color="red">GET：很多策略交给业务线或SOC去运营？</font></strong></p>
</blockquote>
<h3><span id="六-总结">六、总结</span></h3>
<p>Web应用程序防火墙（WAF）可以提供对许多仍然普遍存在的传统攻击的有用保护。<strong>然而，由于其代理架构，它们无法在用户和时间跨度上关联活动以检测当今复杂的API攻击。</strong>仅依靠WAF进行API保护是不足够的，会使公司易受攻击。我们在Salt这里并不声称我们的平台是DDoS防护解决方案。然而，通过利用我们的异常检测能力，我们可以捕获您的WAF可能错过的攻击。我们可以与您的WAF集成，提供所需的内联阻止（inline
blocking）以保护您的服务。</p>
<p>要了解Salt屡获殊荣的API安全平台以及如何在您的环境中发现和保护内部开发和第三方API，请联系我们或注册个性化演示。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>https://salt.security/blog/salt-customer-attack-case-study-blocking-a-low-rate-per-bot-http-ddos-attack?</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>API安全</category>
      </categories>
      <tags>
        <tag>工业落地</tag>
        <tag>API安全</tag>
        <tag>Distributed Bot Attacks</tag>
        <tag>Salt Security</tag>
      </tags>
  </entry>
  <entry>
    <title>流量反作弊（2）阿里妈妈-“广告主套利”风控技术分享</title>
    <url>/posts/39YZHBH/</url>
    <content><![CDATA[<h2><span id="阿里妈妈-广告主套利风控技术分享">阿里妈妈-“广告主套利”风控技术分享</span></h2>
<h3><span id="一-背景介绍">一、背景介绍</span></h3>
<h4><span id="11-套利的影响">1.1 套利的影响</span></h4>
<p>由于平台的有效总曝光有限，当套利广告主占据了高质量位置后，真实点击率和成交率低于模型预期，平台产生的总点击、总成交就会相应减少，从而导致该资源位的收入降低。这里我们统一使用<strong>千次展现收益</strong>（Revenue
Per
Mile，以下简称：RPM）来代表地价。即<strong>套利会在一定程度上使对应位置的RPM降低</strong>。</p>
<p>由于现阶段ctr、cvr预估模型有在线更新机制，从长周期来看是具备自愈能力的。但模型的更新有一段时间延迟，在每个模型更新的空窗期内，广告主不会恰好都补单补量至模型的预期水平。最终就导致了模型不断被欺骗又修复的过程。如下图所示。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182020935.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>因此，在与排序模型的博弈中，广告主周期性地实现着套利。随着online模型更新的时效性提升，套利空间在不断被压缩。也导致广告主更加倾向于高频、低程度地进行操作，识别难度进一步增大。</p>
<h4><span id="12-困难与挑战">1.2 困难与挑战</span></h4>
<p>由于<strong>作弊手法千变万化</strong>、<strong>真实标签难以界定</strong>、<strong>作弊Ground-Truth未知</strong>，风控场景很难通过<strong>监督训练</strong>等手段获得<strong>通用解</strong>。具体到广告主套利上，我们还面临着一些其他的问题。</p>
<h5><span id="121-众包人工流量的识别">1.2.1 众包人工流量的识别</span></h5>
<p><strong>相比于以往的无效流量甄别，众包人工流量往往更加贴近平常用户的行为</strong>。难度远超以往的爬虫、机械性攻击。高并发的广告场景，对识别的精度和召回，要求都非常高。而且即使是刷手，也会产出正常的流量。</p>
<p>如何精细化区分刷手的每次行为以及是否是受雇佣的，是极具挑战的一个课题。</p>
<h5><span id="122-精度难评价">1.2.2 精度难评价</span></h5>
<p><strong>由于众包人工流量会有一定比例的成交，不符合0转化假设。</strong>高效评价流量识别模型的精度和召回，是很困难的。此外，套利广告主检测本身也需要找到合适的假设，没有客观高效的评价方式，难以指导模型迭代。</p>
<h5><span id="123-区分主动与被动">1.2.3 区分主动与被动</span></h5>
<p>存在任务流量的广告主，不仅是主动套利的，还有一部分是被其他广告主雇佣的刷手误伤、或者受到人工攻击消耗的。如何无监督、高精度、高召回、鲁棒地挖掘广告主的主动性，也是我们需要重点关注的。</p>
<h3><span id="二-方案概览">二、方案概览</span></h3>
<p>在正式开始介绍方案之前，我们针对1.3节的问题，分别介绍一下思路。为了解决1.3中提到的3个问题，我们针对广告主套利开发了一套同样集<strong>感知</strong>、<strong>洞察</strong>、<strong>处置、评价</strong>于一体的检测框架，其架构图如下图所示。框架理念可以参考这篇文章：<a href="http://mp.weixin.qq.com/s?__biz=Mzg3MDYxODE2Ng==&amp;mid=2247484728&amp;idx=1&amp;sn=3305a981f34fe30e2464c627f3842ec8&amp;chksm=ce8a4061f9fdc977cb18acf91d212352a26d9f060dbae6ead52514102e95b9e31cd32523e564&amp;scene=21#wechat_redirect">《阿里妈妈流量反作弊算法实践》</a>。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182020589.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<ol type="1">
<li><strong>众包流量识别</strong>，分别由统计基线、行为序列、图关系3个模型一起召回，并使用黑话模型的产出评价标准，指导模型迭代；</li>
<li><strong>感知</strong>部分，通过对<strong>RPM的鲁棒预估</strong>，计算广告主实际产生的RPM与平台预期的diff，从而召回RPM偏低的广告主；</li>
<li>通过<strong>洞察</strong>分析平台对列表中的实例进行分析，获取新模式认知的同时进行标注作为验证样本；</li>
<li>将认知抽象为策略或模型（当前为双模型因果推断），产出了套利广告主名单用于区分“主动”与“被动”，最后在下游中进行分类<strong>处置</strong>；</li>
</ol>
<h3><span id="三-众包流量识别">三、众包流量识别</span></h3>
<p>在介绍感知、洞察、处置体系之前，我们首先对挖掘套利广告主的基础能力进行介绍——众包人工流量识别。该流量不满足0成交转化，模型的迭代和监控保障，也显然不能依赖低效的人工抽检。首先需要寻找一种可以批量校验、又和处置严格正交的评价方法。整体方案如下图所示。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182020065.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h4><span id="31-黑话模型">3.1 黑话模型</span></h4>
<p>考虑到直通车场景下，刷手需要高频地进行搜索，从而定位到自己的任务目标，不可能所有的内容都手敲。风控工程团队基于淘宝的搜索记录，对历史文本信息进行了系统地整合，使得黑话凝聚在标准化的文本库中。</p>
<h5><span id="311-特性">3.1.1 特性</span></h5>
<p>黑搜索的文本信息采集，受<strong>设备型号、手滑粘贴、误点搜索的影响</strong>，导致产出上并不稳定，所以没有直接用于召回。但同设备类型、应用、天维度同比是有意义的，可以<strong>作为精度和召回的评价指标</strong>。因此，我们构造了和众包流量构成强相关、但召回有限的黑话模型。</p>
<p><strong>典型的黑话如下所示：</strong></p>
<ul>
<li>"3️⃣看图👆拍苐一个,π下多少仮溃"</li>
</ul>
<p>根据我们的分析显示，黑话具有以下特点：1）文字语序混乱；2）拼音、中、英文混输；3）表情、形近字替代；4）快速迭代、分析低效。这涉及到多种语义的还原，并且新的变种不断产生。基于文本出发的黑话模型开发非常困难。</p>
<h5><span id="312-用户维度-关键词与树">3.1.2 用户维度、关键词与树</span></h5>
<p>综合考虑各个方案的性价比后，我们尝试不完全依赖文本，而是从用户出发，<strong>2段式、半监督地召回黑话。</strong></p>
<ol type="1">
<li>首先构造用户维度的处罚特征，无监督的召回候选人群集；</li>
<li>再以变换后的关键词为目标，天维度更新Cart回归树模型，选择额外80%召回的动态阈值，得到离线样本库；</li>
</ol>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182020453.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h5><span id="313-bert提效">3.1.3 Bert提效</span></h5>
<p>我们基于黑话样本库与大盘可信白样本，训练了基于Bert的2分类模型，用于对全量文本进行打分，从而减轻黑话样本库覆盖度不足的影响。使用召回人群多日黑话得分均值，来作为众包流量识别的精度指数，指导模型快速迭代，并持续以黑话精度作为模型的监控指标。</p>
<h4><span id="32-统计基线">3.2 统计基线</span></h4>
<p>众包人工流量虽然更难以识别，但是我们始终相信黑灰产用户是不可能完美隐藏的。<strong>我们从用户行为角度设计了一系列的异常检测方案。</strong>首先调研了黑灰产平台。发现用户需要通过一系列行为来完成任务的交付（考虑到攻防属性，暂不透出具体行为）。据此我们构造了本质、鲁棒性的统计特征，结合统计异常检测模型，产出了套利识别的基线。在<a href="http://mp.weixin.qq.com/s?__biz=Mzg3MDYxODE2Ng==&amp;mid=2247484728&amp;idx=1&amp;sn=3305a981f34fe30e2464c627f3842ec8&amp;chksm=ce8a4061f9fdc977cb18acf91d212352a26d9f060dbae6ead52514102e95b9e31cd32523e564&amp;scene=21#wechat_redirect">《阿里妈妈流量反作弊算法实践》</a>中介绍过，本质特征更有助于挖掘异常；如用“偏离对应人群的分布的程度”，代替“绝对数量”。</p>
<p>由于统计特征的粒度偏粗，导致我们并不能区分刷手当天的哪部分流量属于众包，哪部分属于正常流量。所以还需要更加精细化的识别能力建设。</p>
<h4><span id="33-行为序列">3.3 行为序列</span></h4>
<p>近期我们一直在尝试，使用更为<strong>细粒度的原始行为序列</strong>、<strong>良好的序列设计</strong>、以及<strong>合理的辅助任务</strong>，训练大规模无监督预训练模型。<strong>Zero-shot</strong>在下游进行应用，实现精细化地捕捉众包流量特点。当前行为序列研究的整体框架如下图所示。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182020951.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h5><span id="331-序列信息">3.3.1 序列信息</span></h5>
<p><strong><font color="red">
首先是通用的行为选择。为了更好地适用于大多数场景，我们只选择了搜索和点击两个行为，并辅以行为的属性与时间信息，共同组成行为序列。</font></strong></p>
<p>为了方便刻画行为模式，我们使用下划线拼接行为和属性，构造类似于NLP中单词概念的行为元素，形式为：()<em>()</em>()_()。例如：<strong>clk_true_3_2
表示为 一次点击 &amp; 是广告点击 &amp; 商品属性为编号3 &amp;
距离上一次行为时间间隔属于分箱编号2。</strong></p>
<p>由于刷手需要接单大量的任务，产品类型、任务目的可能各不相同。通过合理的session划分，将不同的基础行为进行聚合，可以使信息更加凝聚。</p>
<p>结合搜索广告的特点，我们限制一个session必须以搜索开始，时间间隔在一定范围内都同属于一个session。</p>
<h5><span id="332-辅助任务设计">3.3.2 辅助任务设计</span></h5>
<p>为了使模型学习到session排列的模式，我们使用<strong>Transformer结构 +
Cut-paste任务</strong>，对序列整体进行表示。</p>
<p><strong><font color="red">
Cut-paste算法是用于图像异常检测的一种辅助任务。通过对原始图片进行随机地局部剪裁，再随机粘贴至新的位置，原位置以黑色阴影覆盖(向量值均为0)，从而获得大量的负样本，并以大量的数据增强产生正样本。</font></strong>然后通过原图与新图的二分类任务，促使模型学习到剪裁边缘的连续性。算法内容详见[1]。</p>
<p>类似地，根据刷手行为特点，对序列进行Cut-paste衍生，得到大量的样本用于二分类任务，从而得到完整序列表示。最终的预训练网络结构如下所示。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182020120.png" alt="图片" style="zoom:67%;"></p>
<h5><span id="333-异常检测">3.3.3 异常检测</span></h5>
<p>根据序列表示的结果，我们得到了N维的Embedding向量：</p>
<ol type="1">
<li>将序列Embedding与COPOD模型结合，产出Embedding每个维度偏离分布的异常分(1)；</li>
<li>固定基础行为的Embedding层权重，二次训练Seq2Seq模型，将重构误差产出异常分(2)；</li>
</ol>
<p>将2个方案计算的异常分结合，得到下游任务的打分。</p>
<h4><span id="34-图关联挖掘">3.4 图关联挖掘</span></h4>
<p><strong>截止目前，我们通过统计基线 +
行为序列对众包人工流量进行了识别</strong>。在阿里妈妈广告场景下，这些流量会在受害者/套利者维度上呈现出聚集。且因为模型的评估依赖于人工抽检，为了保证精度符合预期，显然单体识别模型的精度与召回都会受限。</p>
<p><strong>因此我们增加了基于图关联的召回。以统计基线为基础节点，用行为序列结果剪枝，最终通过半监督的GAT网络对行为稀疏、但访问宝贝和基础节点重合度高的人工众包流量进行扩召回。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182020148.png" alt="图片" style="zoom: 50%;"></p>
<p>下图是2021年至今为止，最新挖掘的每日人工众包的设备数量趋势（具体数字已隐藏）。除大型节日外外，流量基本趋于稳定。相比于原始统计基线，组合模型可以精细定位到刷手与宝贝的对应关系，目前已额外新增30%的广告点击召回。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182020955.png" alt="图片" style="zoom: 67%;"></p>
<h3><span id="四-套利感知">四、套利感知</span></h3>
<p>为了建立内部自驱循环的异常检测框架，感知系统是必备的。在<a href="http://mp.weixin.qq.com/s?__biz=Mzg3MDYxODE2Ng==&amp;mid=2247484728&amp;idx=1&amp;sn=3305a981f34fe30e2464c627f3842ec8&amp;chksm=ce8a4061f9fdc977cb18acf91d212352a26d9f060dbae6ead52514102e95b9e31cd32523e564&amp;scene=21#wechat_redirect">《阿里妈妈流量反作弊算法实践》</a>文章中我们介绍过：<strong>感知重召回，其理念是召回一切认知之外的异常</strong>。从作弊的结果（果性）出发，才能召回受害者可感知的全部流量。</p>
<p>在广告主套利场景下，受害者是平台。但广告主的手法各不相同，从结果上看，未必会成功。虽然都需要处置，但在感知角度，我们更关注那些成功套利的案例。因此，我们从RPM低于平台预期的广告主的流量出发，<strong>召回套利成功流量的超集</strong>。</p>
<p>除了作为感知手段以外，估准RPM才能计算出该问题究竟为平台带来了多大影响。而且先找到一批RPM低于预期的广告主，才能用于最终，套利广告主名单的精度、召回评价。</p>
<h4><span id="41-评价方案">4.1 评价方案</span></h4>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>API安全</category>
      </categories>
      <tags>
        <tag>工业落地</tag>
        <tag>业务安全</tag>
        <tag>API安全</tag>
      </tags>
  </entry>
  <entry>
    <title>流量反作弊（1）阿里妈妈-流量反作弊算法实践</title>
    <url>/posts/YK4AHN/</url>
    <content><![CDATA[<h2><span id="阿里妈妈-流量反作弊算法实践">阿里妈妈-流量反作弊算法实践</span></h2>
<blockquote>
<p>不光要思考需要哪些技术能推动产品成熟，还要思考一个产品成熟的样本；</p>
</blockquote>
<h3><span id="一-广告风控流程"><strong>一、广告风控流程</strong></span></h3>
<p>下图是广告主投放内容与风控团队、下游业务团队的简易交互流程。广告素材通过<strong>内容风控</strong>审核后，即可以在线上进行<strong>展示</strong>。在展示期间，广告主可能会主动作弊、也可能受到其他广告主攻击。风控团队需要对无效流量进行过滤，保护广告主的利益，维护健康的广告投放环境。本文重点介绍在线展示期间，<strong>流量、淘客交易</strong>场景下的业务风险与算法体系。详细的解决方案在未来的文章中逐一介绍。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019363.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<blockquote>
<p><strong><font color="red">
离线无监督样本库：标签指导（误报率）对准实时进行修正；</font></strong></p>
</blockquote>
<h3><span id="二-无效流量"><strong>二、无效流量</strong></span></h3>
<p><strong>流量反作弊系统</strong>的核心能力就是<strong>清洗、过滤无效流量</strong>。但是<strong>无效流量</strong>并不等价于<strong>作弊流量</strong>。我们将这部分流量的定义分为2个层面：</p>
<p>1）<strong>低质量</strong>：重复点击计费策略、频率控制策略、剧烈波动策略等；</p>
<p>2）<strong>作弊</strong>：转化效果概率为0的流量；</p>
<p>作弊流量转化期望概率一定为0，比如<strong>爬虫</strong>产生的点击流量（<strong>重复traceid</strong>）。但后续实际<strong>频率</strong>为0的流量不一定是作弊。比如新商品累计1万点击后仍没有转化，只能说频率为0。不能直接断定为作弊流量。</p>
<p>常见的无效流量包括：</p>
<p>1）消耗竞争对手；</p>
<p>2）提升自身排名；</p>
<p>3）自然宝贝刷单误伤广告主；</p>
<p>4）非恶意无效流量。如下图所示，一名诚信投放的广告主，可能受到多种维度的影响。</p>
<blockquote>
<p><strong><font color="red">
网约车业务的冒转率可能受到哪些影响？</font></strong></p>
</blockquote>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019652.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h4><span id="21-消耗竞争对手">2.1 消耗竞争对手</span></h4>
<p>广告主在设置投放策略的时候，通常有预算限制。一些广告主，通过构造虚假流量，攻击其他广告主，消耗预算致使广告下架。如原定计划可以投放7日的广告内容，在第2天突然被完全消耗。这种情况下，很容易引起受害广告主的投诉，影响恶劣。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019707.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h4><span id="22-提升自身排名">2.2 提升自身排名</span></h4>
<p>广告排名由出价和质量评分决定。<strong>一些广告主会雇佣黑产刷单，提高广告的转化率</strong>。通过低成本获得靠前的广告排名。这些作弊利益驱动属性也很强，比较容易被平台和相关广告主感知到。对平台的影响也较为恶劣。</p>
<h4><span id="23-自然宝贝刷单"><strong>2.3 自然宝贝刷单</strong></span></h4>
<p><strong>一些广告主通过雇佣黑产提高店铺的成交数、好评数、加购收藏数等。刷手为了更好地隐藏自己，往往会装作“货比三家”，查看多个宝贝信息</strong>。该过程偶尔会误伤了广告展示宝贝。这种作弊对广告生态的影响比较弱。感知程度会偏低一些。此外，人工刷手往往伪装的更好，在流量甄别上难度比较大。</p>
<h4><span id="24-非恶意无效流量">2.4 非恶意无效流量</span></h4>
<p>除上述带有恶意的虚假流量。还有非恶意、非薅羊毛的<strong>无效流量</strong>需要被过滤。<strong>比如一些浏览器在打开淘宝首页时，会预加载所有的宝贝链接后续跳转网页。显然这些是无效流量</strong>。又比如，爬虫或浏览器劫持而产生的流量，不应该计入广告主的费用中。</p>
<h4><span id="25-淘客交易作弊">2.5 淘客交易作弊</span></h4>
<p>淘宝联盟是阿里妈妈平台给淘宝客推广者搭建的推广平台，在淘宝联盟后台可以完成取链、推广和提现等一系列操作。而淘客交易作弊，不满足作弊流量转化概率为0的假设。根据计费方式不同，常见的2种作弊形式为：1）流量劫持；2）黑灰产淘客拉新。</p>
<h5><span id="251-流量劫持"><strong>2.5.1 流量劫持</strong></span></h5>
<p>CPS计费下的主要作弊手法是流量劫持。常见的流量劫持有2种。第一种，是<strong>篡改记录用户流量来源</strong>，将其他淘宝客的拉新流量据为己有。广告主会明显感知到自然流量变少，拉新流量增加。第二种，是<strong>修改用户跳转链接</strong>，使得用户跳转到自己的宝贝页面。会导致用户在不知情的情况下购买了另一家店铺的商品。此时商家会在销量层面有一定感知。</p>
<h5><span id="252-黑灰产淘客拉新">2.5.2 黑灰产淘客拉新</span></h5>
<p>CPA计费下的主要问题是<strong>虚假地址</strong>。常见的CPA通常发生在产品拉新中，如用户注册、用户下单...等。在一些淘宝客拉新场景中，需要拉新用户完成注册、下单等一系列流程。此时一些淘宝客通过批量注册，下单廉价商品来赚取拉新差价。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019823.png" alt="图片" style="zoom: 67%;"></p>
<h4><span id="26-下游任务影响">2.6 下游任务影响</span></h4>
<p>对于阿里妈妈来说，虚假流量不单影响着其他广告主的权益，同时影响着阿里生态的下游业务。<strong>搜索、推荐、广告等业务的收益，强依赖于其基于用户行为数据的在线学习</strong>。如：个性化推荐、点击率预估、流量分发、广告定价等。而当<strong>这些任务中混入虚假流量时，会对其真实线上的精度造成极大影响</strong>。</p>
<blockquote>
<p><strong><font color="red">
虚假的无效流量对下游任务的影响；</font></strong></p>
</blockquote>
<h3><span id="三-算法实践"><strong>三、算法实践</strong></span></h3>
<p>相比于其他正向业务，流量反作弊对于精度的要求尤其高。<strong><font color="red">
多过滤导致平台收益减少、少过滤引起广告主投诉，破坏投放生态。</font></strong>而且业务场景对实时返款的诉求越来越强烈，同时作弊对抗升级，从集中式、大规模转向分布式、稀疏化攻击，识别难度增大。亟需基于高维异常检查的新系统能力。为此，我们建立了集<strong>异常主动感知、人工洞察分析、自动处置过滤、客观评价</strong>高效循环一体的风控系统。</p>
<blockquote>
<p><strong><font color="red"> 1、被动反馈case驱动、领域经验处置 --&gt;
主动感知、洞察分析、标准化的处置体系、成熟的指标大盘</font></strong></p>
<p><strong><font color="red"> 2、领域经验驱动算法迭代 --&gt;
数据驱动算法迭代</font></strong></p>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019092.png" alt="图片" style="zoom: 67%;"></p>
<h4><span id="31-感知">3.1 感知</span></h4>
<p><strong><font color="red">
在历史的风控体系中，往往是Case驱动的。即遇到问题通过滞后的算法或策略迭代来覆盖风险</font></strong>。为了提前发现问题，尽可能减少投诉，净化投放环境，我们引入了感知。通过感知捕捉与常见分布不同的数据，输出异常列表。</p>
<p>我们将可感知异常流量分为:</p>
<ul>
<li><strong>受害者可感知</strong>：业务本身可感知，冒转率，高峰期流量、营销流量不属于；</li>
<li><strong>平台可感知</strong>：接口安全（接入层、风控）、业务安全；</li>
<li><strong>实战攻防可感知</strong>：</li>
<li><strong>假想攻防可感知</strong>：</li>
<li><strong>算法挖掘可感知</strong>：</li>
</ul>
<p><strong><font color="red">
感知是重召回的，但并不是单纯为了更多地召回现有风险，它设计的核心是去感知所有的“异常”</font></strong>。以2020年初为例，由于骑行政策的调整，售卖头盔商家的访问量显著偏高，连带着必然影响到<strong>点击率、转化率</strong>等一系列指标。这些异常是<strong>商铺可感知</strong>的，需要被我们捕捉到。但并不属于作弊流量。所以不会被流量反作弊系统所过滤。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019109.png" alt="图片" style="zoom:67%;"></p>
<p>那感知究竟如何来做呢？以“点击流量反作弊”来说，<strong>作弊一定会导致点击量增加</strong>。如果可以预估出一个商品每天的点击数量。则超出该值的点击一定为作弊。因此流量反作弊感知的核心之一，就是<strong>如何在大盘召回率未知的情况下，精准预估正常流量值</strong>。这部分内容在后续文章中进行介绍。</p>
<blockquote>
<p>接口画像：预估出一个接口每天的点击量，<strong><font color="red">
因此流量反作弊感知的核心之一，就是如何在大盘召回率未知的情况下，精准预估正常流量值</font></strong>。</p>
</blockquote>
<h4><span id="32-洞察">3.2 洞察</span></h4>
<p><strong>为了确认感知到的异常流量哪些属于作弊，分析人员需要进行洞察分析</strong>。<strong><font color="red">
“洞察
”的目的是从“感知”到的异常中将风险抽离出来，进而发现新的风险模式。</font></strong>我们将洞察分为：1）受害者洞察；2）攻击者洞察；3）套利漏洞洞察；4）流量实例洞察。</p>
<p><strong><font color="red">
传统洞察需要人工挑选可疑特征（如停留时长、注册时长、ua、token_str），并与大盘好样本(正常业务曲线)进行比较。</font></strong>如下图。这就对领域经验有强依赖。而领域专家毕竟是少数。<strong>并且随着作弊越发高级，单一维度或少量维度下逐渐难以发现作弊。</strong>为此，我们引入了<strong>高维数据下的可视化洞察分析技术</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019492.png" alt="图片" style="zoom: 50%;"></p>
<p><strong><font color="red">
在洞察环节，首先需要对样本进行高度抽象表示。如何在高维数据中选择合适的子空间投影，是非常具有挑战性的课题。</font></strong>后续文章会展开介绍。确定合适的子空间后，除了和大盘比较，我们还引入了<strong>时间维度的分布同比</strong>，如下图所示。对于分布稳定的某个广告，3月6日降维图中突然出现明显不同的一簇（红圈内），很可能是新的异常模式。（图中“样本库”指最终被识别为作弊的流量，在3.3节进行介绍）</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019579.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p><strong>洞察的难点在于，如何减轻未召回的作弊对正常分布的污染。</strong>比如上图中蓝色线条内部分可能也存在作弊，这时通过同比就无法发现异常。如何跳出既有认知去召回未知异常模式，以及非常棘手的冷启动问题，这些都是后续文章的重点内容。</p>
<h4><span id="33-处置">3.3 处置</span></h4>
<p><strong><font color="red">
处置，指对风险进行处置。对于不同的风险实体、风险类型，会使用不同的处置方法。</font></strong></p>
<h5><span id="331-流量反作弊的处置">3.3.1 流量反作弊的处置</span></h5>
<blockquote>
<p><strong><font color="red">
所有的策略和模型都可以用标准的统计学习方法来描述；</font></strong></p>
</blockquote>
<p><strong><font color="red">
传统的算法迭代模式，是根据洞察分析的结果，指导规则、统计模型为主的无监督过滤系统。</font></strong>对领域经验比较依赖，而且效率低下、难以形成沉淀。因此，对于流量反作弊的处置，我们部署了<strong>实时流式、小时批处理双重防线</strong>。其逻辑如下图所示。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019002.png" alt="图片" style="zoom: 67%;"></p>
<blockquote>
<p><strong><font color="red">
实时有监督过滤系统，依赖数据维度的多样性（场景要区分端、app、小程序和web的数据维度不同）+
低代价特征 + 高效的模型结构；</font></strong></p>
</blockquote>
<p>在线实时过滤系统，综合了<strong>无监督、半监督的特征工程，以及监督的集成（Ensemble）异常检测器</strong>。相比于单条策略的独立决策，集成的容错性更高（召回能力下降，适用于精度高的场景）。例如，<strong>PC端反作弊策略依赖于网页采集的前端行为、鼠标点击行为等，当数据采集出错时，过渡依赖某一策略将导致大面积误差。</strong></p>
<p>同时，<strong><font color="red">
我们会尽可能使用更触及作弊本质、更具有鲁棒性的特征</font></strong>。和正向业务不同，我们不会在特征设计层面，过分聚焦于正样本的区分度。比如绝大部分爬虫流量都是PC端带来的，“是否是PC”就是一个极强的特征。但一旦这种作弊没有继续攻击，模型的效果就大打折扣。因此更多会使用各个维度上计算与Normal分布的偏差、到Normal簇的距离...等。</p>
<p>实时过滤系统基本可以解决90%的问题。<strong>为了更好地拟合高级作弊，我们又引入了小时级别过滤系统，使用开销更大的特征与更复杂的模型。而且广告结算支持事后返款，可以使用小时级结果对实时流模型进行修正，用于结算与展示</strong>。当然，处置能力最终收敛于实时流过滤系统，会是我们更长期的追求。</p>
<blockquote>
<p>小时级的离线策略的意义：能否对准实时修正，</p>
</blockquote>
<p>此外，在线实时过滤系统可以让新同学快速上手迭代其中的组件，将不同同学的产出解耦，更客观的评价业务贡献。</p>
<h5><span id="332-淘客交易反作弊的处置">3.3.2 淘客交易反作弊的处置</span></h5>
<p>对于过滤系统判定作弊的淘客，我们首先<strong>冻结其佣金</strong>。搜集证据后下达处罚结果。并通过“预估佣金”、“异常特征”来对待处罚淘客进行分级处置。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019490.png" alt="图片" style="zoom:50%;"></p>
<p>此外，传统的处罚机制为月结，从媒体开始作弊到下达处罚有一定延迟。一方面不利于及时管控风险，另一方面会导致非主观恶意作弊淘客的强烈反弹，为提升管控的时效，减少淘客的损失，同时提升用户体验，我们在原有的月结机制基础上，<strong>增加周/天的处罚机制</strong>。</p>
<h4><span id="34-评价">3.4 评价</span></h4>
<blockquote>
<p>拦截率和攻击量：相当于对已知攻击的覆盖能力；</p>
<p>准确率和召回率：相当于对全量攻击的防御能力；</p>
</blockquote>
<p>对于整个流量反作弊系统，我们有4部分需要评价：</p>
<ul>
<li>在线有监督精度；</li>
<li>在线有监督召回；</li>
<li>离线无监督精度；</li>
<li>离线无监督召回；</li>
</ul>
<p>因为没有Ground
Truth，为了客观评价在线有监督过滤系统的<strong>精度</strong>与<strong>召回</strong>，我们建立了<strong>离线无监督样本库</strong>。使用离线无监督样本库的最终结果，作为在线有监督系统的Groud
truth，就可以评估其分类效果。但也引入了后面2部分无监督评价问题。</p>
<h5><span id="341-有监督过滤系统的评价">3.4.1 有监督过滤系统的评价</span></h5>
<p>在线与离线2者的关系如下图所示。基于纯无监督的挖掘体系，我们的底线是消灭3.2.1中提到的5种可感知异常流量中的作弊流量，终局则是消灭不可感知的作弊流量。<strong><font color="red">
通过天级别的事后信息引入，以无监督的方式对线上实时系统过滤结果进行修正，并将标签用于后续在线监督系统学习。</font></strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019764.png" alt="图片" style="zoom:67%;"></p>
<p><strong><font color="red">
基于现有标签的AUC、KS、MAX-F1...等指标，会过分高估风控模型效果。</font></strong>例如，实时模型的AUC很容易高于0.99。然而这其中绝大多数的样本都来自于简单的爬虫、或傻瓜式疯狂点击，如下图离散分布的红点。在更高级的作弊上AUC可能不足0.8，如下图红圈中的样本。为了更客观地评价模型，我们引入了“<strong>样本库分级</strong>”，将“简单作弊”与“高级作弊”区分开。并通过结构化采样构造封闭评测集，指导模型迭代。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182019507.jpeg" alt="图片" style="zoom: 50%;"></p>
<h5><span id="342-无监督精准评价">3.4.2 无监督精准评价</span></h5>
<p>无监督系统的精准与召回评价一直是业内的难题。传统的评价方法是通过数据抽样，由专家进行标注进行评估。效率低下且非常主观。为此我们借助淘系生态数据，为无监督系统引入了自动化评价体系。基于无效流量转化概率为0的假设，通过统计推断，得到模型在指定置信度下的精度指数下限。基于区间估计的精度推断方法，在后续专题文章中进行介绍。</p>
<h5><span id="343-无监督召回评价">3.4.3 无监督召回评价</span></h5>
<p>真实环境下的召回评价，是难以定量的。除了大盘抽样巡检外，由于引入了完备的感知、洞察体系。将所有的异常流量，均归纳至一个风险池。无论何时有需要对流量进行处置（临时止血或迭代模型），我们都可以迅速定位到问题根源。于是将安全感最大化。</p>
<h3><span id="四-总-结">四、总 结</span></h3>
<p>高维数据下的<strong>异常检测、大规模图学习、机器学习可解释性、数据可视化方法</strong>等，都是我们的重点研究方向。在我们看来，风控可能是当前机器学习领域，对算法鲁棒性和解释性要求最高、精度要求最极致、系统规模和时效性挑战最大、最能用钱衡量的工业级业务。这就需要我们具备卓越的业务数据洞察能力、工程架构能力，让研究成果转换成坚实的工业级解决方案。</p>
<p>本文重点介绍了我们在流量反作弊场景下所遇到的问题，以及相应的解决方案。希望通过这篇文章，可以让读者理解我们在流量反作弊领域所遇到的问题，以及解决问题的思路。</p>
<h3><span id="当前思路总结">当前思路总结</span></h3>
<ul>
<li><p><strong><font color="red">
离线无监督样本库：标签指导（误报率）对准实时进行修正；</font></strong></p></li>
<li><p><strong><font color="red">
网约车业务的冒转率可能受到哪些影响？</font></strong></p></li>
<li><p><strong><font color="red">
虚假的无效流量对下游任务的影响；</font></strong></p></li>
<li><p><strong><font color="red"> 1、被动反馈case驱动、领域经验处置
--&gt;
主动感知、洞察分析、标准化的处置体系、成熟的指标大盘</font></strong></p>
<p><strong><font color="red"> 2、领域经验驱动算法迭代 --&gt;
数据驱动算法迭代</font></strong></p></li>
<li><p>接口画像：预估出一个接口每天的点击量，<strong><font color="red">
因此流量反作弊感知的核心之一，就是如何在大盘召回率未知的情况下，精准预估正常流量值</font></strong>。</p></li>
<li><p><strong><font color="red">
所有的策略和模型都可以用标准的统计学习方法来描述；</font></strong></p></li>
<li><p><strong><font color="red">
实时有监督过滤系统，依赖数据维度的多样性（场景要区分端、app、小程序和web的数据维度不同）+
低代价特征 + 高效的模型结构；</font></strong></p></li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>API安全</category>
      </categories>
      <tags>
        <tag>工业落地</tag>
        <tag>业务安全</tag>
        <tag>API安全</tag>
      </tags>
  </entry>
  <entry>
    <title>账号安全（2）【TODO】Uncovering Large Groups of Active Malicious Accounts in Online Social Networks</title>
    <url>/posts/2C9003N/</url>
    <content><![CDATA[<h2><span id="uncoveringlarge-groups-of-active-malicious-accounts-in-online-social-networks">Uncovering
Large Groups of Active Malicious Accounts in Online Social Networks</span></h2>
<h3><span id="摘要">摘要</span></h3>
<p>在线社交网络的成功吸引了攻击和利用它们的持续关注。攻击者通常控制恶意账户，包括虚假和被侵犯的真实用户账户，以发起攻击活动，例如<strong>社交垃圾邮件、恶意软件分发和在线评分扭曲</strong>。</p>
<p>为了防御这些攻击，我们设计并实现了一个名为SynchroTrap的恶意账户检测系统。我们观察到，恶意账户通常在各种社交网络环境中执行松散同步的动作。<strong>我们的系统根据用户行动的相似性对用户账户进行聚类，揭示了表现类似、在相同时间持续一段时间的大量恶意账户群体</strong>。我们将SynchroTrap实现为在Hadoop和Giraph上的增量处理系统，以便它能够高效地处理大型在线社交网络中的海量用户活动数据。我们已经在Facebook和Instagram的五个应用程序中部署了我们的系统。在一个月内，SynchroTrap能够揭示超过两百万个恶意账户和1156个大型攻击活动。</p>
<p><strong>关键字：</strong>恶意账号检测；大规模聚类；在线社交网络；</p>
<span id="more"></span>
<h3><span id="一-说明">一、说明</span></h3>
<p>之前的防御这些攻击的工作[1-3,35]大多旨在直接识别攻击者控制的虚假或被侵犯的账户。存在两种广泛的方法。一种方法是使用账户的社交网络连接性[19,41,45,46]来推断它是否为虚假账户。这种方法可以帮助发现与真实社交网络关系少的虚假账户，但无法可靠地识别被侵犯的真实用户账户或已获得许多社交关系的维护良好的虚假账户[44]。另一种广泛应用于实践的方法[20,35,47]是构建机器学习分类器来推断恶意（虚假或被侵犯）账户。这种方法可以有效地分类那些具有已知恶意特征的恶意账户，但可能会错过许多具有未知特征的恶意账户。</p>
<p>受上述挑战的启发，王等人[42]和Beutel等人[16]探索了一种揭示恶意账户的新方法。他们分析社交网络账户的聚合行为模式，以区分恶意账户和合法账户。特别是，王等人分析了虚假账户的http请求与真实用户账户的区别，并将此特征用于识别虚假账户。Beutel等人则表明，恶意账户倾向于在大约相同的时间向欺诈性Facebook页面发布虚假点赞，并设计了CopyCatch来检测这种同步发布。</p>
<p>本文推进了使用聚合行为模式揭示恶意账户的技术水平。受CopyCatch的启发，我们表明恶意账户倾向于在各种社交网络环境中一起行动。除了发布虚假点赞外，他们可能以松散同步的方式登录、安装社交网络应用程序、上传垃圾照片等（§2）。</p>
<p><strong>然后我们介绍了一个名为SynchroTrap的系统，它可以揭示松散同步行动的大量恶意账户群体。</strong>我们在设计SynchroTrap时面临许多独特的挑战（§3），这些挑战使SynchroTrap与此领域的之前工作（即CopyCatch和Clickstream
[42]）区别开来。首先，与CopyCatch不同，我们的目标是为广泛的社交网络应用程序检测松散同步行为。因此，我们不能假设用户只能执行一次恶意操作，即用户只能对特定页面点赞一次。这种目标上的差异极大地增加了SynchroTrap的算法复杂性（§4和§9）。</p>
<p>账户的行为是一个具有挑战性的异常检测问题。恶意行为仅占总用户行为的一小部分。例如，Facebook每天有超过6亿活跃用户[8]，他们每天进行数十亿次操作[34]。相比之下，参与攻击的恶意账户数量通常仅有数千个。如何从大量嘈杂的数据中准确检测出这样一个弱信号呢？第三，我们的目标是在Facebook等真实的在线社交网络上部署我们的系统。因此，我们的检测算法必须能够每天处理数TB的数据，而许多现成的异常检测算法[26]或之前的工作，如Clickstream，无法处理这样规模的数据。</p>
<p>我们开发了几个简单但实用的技术来解决上述设计挑战。<strong>首先，我们将恶意账户检测问题建模为一个聚类问题</strong>（§3.1）。<strong>我们比较某个时间段内的成对用户行为，并将那些在大致相同时间采取类似行动的用户分组，标记一个超过可调阈值的群集为恶意。</strong>这是因为我们从真实的社交网络中观察到，合法的社交网络用户随时间采取各种不同的行动（§2）。其次，为使聚类算法可计算，我们进一步使用攻击者的网络资源限制，例如他控制的IP地址数量，或攻击者的目标，例如一个欺诈性的Instagram账户，来减少成对比较，具体取决于特定的应用上下文。最后，<font color="red">我们将用户行为数据分成小的每日或每小时块。我们设计算法来聚合这些小块之间的比较结果，以检测较长时间段（如一周）内的恶意行为（§4.5）。这种技术使我们能够以增量处理的方式实现SynchroTrap，从而使其可以在大型在线社交网络上实际部署。</font></p>
<p><strong>我们在Facebook和Instagram上部署了SynchroTrap超过十个月（§7）。在对一个月的数据进行详细研究后（§8.1），我们发现它揭示了超过两百万个恶意账户和1156个恶意活动。</strong>我们随机抽样了SynchroTrap捕获的一部分恶意账户，并要求安全专家检查结果的准确性。手动检查表明，我们的系统实现了超过99％的精度。在部署过程中，SynchroTrap平均每周捕获约274K个恶意账户。我们还在Facebook的200台机器集群上评估了SynchroTrap的性能。<strong>性能结果表明，我们的系统能够处理Facebook和Instagram的用户数据。SynchroTrap处理每日数据需要几个小时，处理每周聚合作业需要约15个小时。</strong></p>
<p>不可否认，战略攻击者可能试图扩散恶意账户的行为以逃避SynchroTrap的检测。我们分析了SynchroTrap的安全保障，并展示了SynchroTrap可以有效限制攻击者执行恶意行为的速率，即使攻击者控制无限数量的恶意账户（§6）。此外，我们提供了一组参数，运营商可以调整以达到假阳性和假阴性之间的理想平衡。在严格的设置下，SynchroTrap产生接近于零的假阳性率。</p>
<p><strong>总之，本工作做出了以下主要贡献：</strong></p>
<ul>
<li>我们发现恶意账户在各种社交网络环境中倾向于一起行动。</li>
<li>我们设计、实现并部署了SynchroTrap。我们的设计解决了使用松散同步的行动来揭示恶意社交网络账户的几个实际挑战，包括如何在各种社交网络应用程序中检测这种行为以及在大型嘈杂的数据集中进行检测。</li>
<li>我们对检测到的恶意账户的特征进行了初步分析。这种分析可能为其他基于特征的恶意账户检测系统提供洞见。</li>
</ul>
<h3><span id="二-动机样例">二、动机样例</span></h3>
<p>在本节中，我们研究了两个真实的攻击示例，这些攻击示例激发了SynchroTrap的设计。Beutel等人[16]观察到，恶意账户在大约相同的时间发布虚假的点赞。这两个额外的示例表明：<strong>a）这种攻击模式也出现在其他社交网络应用程序中，例如Instagram的关注功能；b）恶意账户不仅一起行动，而且经常来自一组有限的IP地址。</strong></p>
<h4><span id="21-恶意的facebook照片上传">2.1 恶意的Facebook照片上传</span></h4>
<p>图1比较了恶意用户和正常用户在Facebook上的照片上传活动。图1(a)绘制了450个恶意账户在一周内的上传时间戳。Facebook捕捉到这些账户，因为它们通过上传垃圾照片来推销减肥药。我们可以看到，这些账户使用少量IP地址上传大量垃圾照片。水平的彩色条纹表示它们在一周的时间内在少量IP地址之间切换。</p>
<p>图1(b)显示了450个随机选择的从未被标记为恶意的账户的照片上传活动。我们将这些用户称为正常用户。可以看到，它们的行动时间分布更加分散，并来自一组更加多样化的IP地址。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305051530472.png" alt="image-20230505153020409" style="zoom:50%;"></p>
<h4><span id="22-在instagram上膨胀关注者">2.2 在Instagram上膨胀关注者</span></h4>
<p>Instagram中的恶意用户关注目标用户以增加他们的粉丝数量。图2比较了1,000个恶意用户和1,000个正常用户的用户关注活动。这些恶意账户是从涉及7K账户的攻击活动中抽样的。</p>
<p>在图2(a)中，我们可以看到这些恶意账户协调了一批目标用户进行关注。整个账户组显示出明显的开关式行动模式。在活动期间，它们在大约相同的时间关注相同的一组用户。相比之下，正常用户表现出多样化的用户关注行为。如图2(b)所示，正常用户的用户关注序列中很难找到明显的相关性。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305051530840.png" alt="image-20230505153049749" style="zoom:50%;"></p>
<h4><span id="23-攻击者的经济限制">2.3 攻击者的经济限制</span></h4>
<p>在本小节中，我们推测为什么各种社交网络攻击倾向于松散同步。<strong>我们认为这部分是由于攻击者方面的经济限制所致。</strong></p>
<p><strong>计算和操作资源成本。攻击者具有有限的物理计算资源。</strong>虽然他们可以购买或攻击机器（例如僵尸网络），甚至从云计算服务中租用机器，但这些资源都会产生财务成本。此外，这些计算资源的操作时间也是有限的。这是因为受感染的机器随时可能下线、恢复甚至被隔离[32,
48]，而机器租赁通常是根据消耗的计算资源计费[4]。另一个操作成本是制造虚假或攻击真实账户、以及维护和管理这些账户的人工费用。在这些操作限制下，攻击者通常从一组有限时间内的机器控制他的恶意账户。</p>
<p><strong>严格要求的任务收益。</strong>社交网络攻击者经常深入地根植于地下市场，例如BlackHat-World和自由职业者[33,36,37]。他们的大多数任务都是由特定要求的客户需求驱动的。通常，攻击活动的目标是在社交网络中占据主导地位。<strong>因此，任务要求通常包括客户追求的主导程度以及必须完成任务的严格截止日期。</strong>例如，自由职业者中的许多社交网络任务要求在Y天内获得X个Facebook好友/赞[33]。类似的任务还针对其他社交网络任务，如关注、发布、评论等。这些具有严格时间要求的地下任务迫使攻击者针对受害者服务的某些方面，并在任务截止日期之前提前行动。</p>
<p>我们将计算和操作资源上的限制称为资源限制，将攻击者任务上的严格要求称为任务限制。我们对这些经济限制及其对控制账户活动的后续表现的理解有助于直接攻击攻击者的弱点，使他们难以逃避检测。</p>
<h3><span id="三-系统概述">三、系统概述</span></h3>
<h4><span id="31-高级系统架构">3.1 高级系统架构</span></h4>
<p><font color="red">SynchroTrap是一个通用的可扩展框架，可以有效地限制OSN中的大量恶意账户。SynchroTrap的主要思想是使用聚类分析[26]在规模上检测恶意账户的松散同步行动。具体来说，它测量用户行为的成对相似性，然后使用层次聚类算法[26]将在一段时间内具有相似行为的用户分组在一起。</font></p>
<h4><span id="32-挑战">3.2 挑战</span></h4>
<p>我们在使SynchroTrap成为大规模OSN的实际解决方案方面面临一些挑战。</p>
<p><strong>可扩展性：</strong>一个主要的挑战源自于当今OSN的巨大规模。首先，大量的用户活动数据导致信噪比低，使得高精度检测变得困难。例如，Facebook拥有超过6亿的日活跃用户[8]，而参与攻击活动的恶意账户数量通常在数千个左右。因此，使用综合比较所有用户活动的方法（例如点击流分析[42]）可能会导致低准确度。<font color="red">为应对这一挑战，我们按<strong>OSN应用程序</strong>对用户行动进行分区，并在每个应用程序的基础上进行检测（§4.1）。我们进一步通过与攻击者相关的目标或源对象，例如IP地址、关注者ID和页面ID，对用户行动进行分区，以捕捉攻击者的限制（§4.2）。</font></p>
<p>其次，大量的活动数据使得处理通用动作的实际实现成为不可能。在Facebook规模的服务中，大而复杂的批处理计算需要大量的硬件容量（例如内存），这使得资源共享困难，故障恢复成本高昂。<strong>为了处理Facebook规模的OSN中的海量用户活动，我们采用分而治之的方法。我们沿时间维度将用户比较的计算切片成较小的作业，并使用并行处理来扩展（§4.5）。然后，我们聚合多个小型计算的结果，以获得长时间期内的用户相似性。</strong></p>
<p><strong>准确度：正常用户行为的多样性和恶意活动的隐蔽性妨碍了高准确度的检测。</strong>异常检测方案不可避免地会产生误报和漏报。因此，自动检测系统的目标通常是降低误报和漏报率。为了实现高准确度，我们根据对攻击者经济制约的理解设计了SynchroTrap。<strong>此外，由于误报率和漏报率通常是相互关联的，SynchroTrap在设计中提供了一组可调参数，使操作者能够调整这些参数
(§ 4.6)来实现所需的权衡。</strong></p>
<p><strong>适应新应用：</strong>攻击活动可能针对不同的OSN应用。由于用户行为的属性，如用户与其他OSN对象的关联，在不同的应用中可能会有所不同，为一个应用优化的检测方案可能不适用于其他应用。因此，开发一个能够适应新应用的通用解决方案是具有挑战性的。例如，CopyCatch
[16]
可检测欺诈性页面点赞（一次性行为），但无法用于发现来自相同IP地址的重复垃圾照片上传。与CopyCatch不同的是，<strong><font color="red">在我们的设计中，我们将相似性度量（§
4.3）与聚类算法（§
4.4）分离，这使我们能够处理一次性和其他通用行为。</font></strong>此外，我们使用元组抽象（§
4.2）来表示行为，包括时间戳维度和攻击者约束维度。这种抽象使系统设计独立于SynchroTrap保护的OSN应用。</p>
<h3><span id="四-系统设计">四、系统设计</span></h3>
<p>在本节中，我们详细描述了我们系统的设计。我们根据OSN应用程序对用户行为进行分类（§
4.1），并在每个应用程序上执行检测。<strong>我们为时间戳用户行为定义了一个通用匹配度量（§
4.2），并使用匹配行为的比例来量化用户对的相似性</strong>（§
4.3）。我们使用单链接层次聚类算法（§
4.4）根据用户之间的相似性将用户分组。<font color="red">在§
4.5中，我们并行计算用户对比以解决大数据处理的挑战。</font></p>
<h4><span id="41-将活动数据按应用程序分区">4.1 将活动数据按应用程序分区</span></h4>
<p>OSN通常以OSN应用程序的形式提供许多功能和功能，例如上传照片、页面点赞、消息等。恶意帐户未必在平台允许的所有类型的操作中进行协调。<strong>为了降低操作成本，攻击者可以将任务集中在某些用户行为空间的部分维度上进行攻击，例如上传垃圾照片、推广恶意应用等。因此，使用对用户活动的全面比较的方案可能会错过仅针对特定OSN功能的恶意用户。</strong>这个问题类似于在聚类高维数据时遇到的“维度灾难”
[29]。为了减轻无关行为的影响，我们根据应用程序将用户的行为分类为子集，称为应用上下文。然后，我们在每个应用程序上下文中检测恶意帐户。<strong>例如，我们分别将上传照片和页面点赞应用程序分离，以抑制垃圾照片和欺诈性页面点赞。接下来，我们将描述如何为OSN应用程序聚类用户行为。</strong></p>
<h4><span id="42-比较用户行为">4.2 比较用户行为</span></h4>
<p><strong>在SynchroTrap中，我们将带时间戳的用户行为抽象为元组，每个元组都有一个明确的约束字段，可以表达资源和任务约束。</strong>我们要求在约束字段上进行精确匹配，以捕捉攻击者的约束。从OSN提供商的角度来看，每个用户行为都有一些属性。表1总结了本文中使用的主要属性及其定义。AppID可以包括应用程序层<strong>网络协议</strong>的标识符（例如HTTP），以指示细粒度的应用程序类别。AssocID可以是<strong>相关OSN对象</strong>的标识符（例如照片、页面、用户等）。我们将带时间戳的用户行为的元组抽象表示为<span class="math inline">\(&lt;U，T，C&gt;\)</span>，其中U，T和C分别表示<strong>用户ID、操作时间戳和约束对象</strong>。约束对象可以是某些操作属性的组合，例如AssocID、源IP地址等的连接。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305051610255.png" alt="image-20230505161053021" style="zoom: 50%;"></p>
<p>我们对用户行为进行的元组抽象是具有表现力的。它使SynchroTrap能够快速适应特定应用程序中的攻击，前提是约束字段被正确指定。例如，可以选择关注者标识符（AssocID的一种类型）作为约束字段，以打败Instagram上的恶意用户关注。基于元组抽象，我们定义了操作匹配，表示为"≈"。如果两个不同用户的操作属于相同的约束对象，并且它们的时间戳在预定义长度Tsim（例如1小时）的相同时间窗口内，则它们匹配。也就是说，只有当它们发生在匹配窗口内时，两个用户行为才可能匹配。
<span class="math display">\[
\left\langle U_i, T_i, C_i\right\rangle \approx\left\langle U_j, T_j,
C_j\right\rangle \quad \text { if } C_i=C_j \text { and
}\left|T_i-T_j\right| \leq T_{\text {sim }}
\]</span></p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>账号安全</category>
      </categories>
  </entry>
  <entry>
    <title>账号安全（1）微信UFA-Unveiling Fake Accounts at the Time of Registration: An Unsupervised Approach</title>
    <url>/posts/1E1X3VN/</url>
    <content><![CDATA[<h1><span id="ufa-在注册环节识别虚假账户的无监督检测算法">UFA-在注册环节识别虚假账户的无监督检测算法</span></h1>
<blockquote>
<p><strong>2021 KDD 论文</strong>：<strong>Unveiling Fake Accounts at
the Time of Registration: An Unsupervised Approach</strong></p>
<ul>
<li>https://dl.acm.org/doi/10.1145/3447548.3467094</li>
</ul>
<p><font color="blue">
小伍哥聊风控：https://mp.weixin.qq.com/s/PE4OSByfngPEJOW8UWVkMw</font></p>
</blockquote>
<h3><span id="引言">引言</span></h3>
<p>今天分享一篇腾讯的论文，是一篇非常偏工程化的文章，其中也有很多技术的创新，但是工程上的一些实践感觉还是非常有价值的，<font color="red">
其实在风控业务中，业务的抽象和提取方法，可能远大于算法本身，特别是图学习领域，一个垃圾的图，算法学的越准，错的越离谱。</font></p>
<span id="more"></span>
<h3><span id="一-概述">一、概述</span></h3>
<p>在线社交网络（OSN）充斥着虚假账户。现有的虚假账户检测方法要么需要手动标记的训练集，这既耗时又昂贵，要么依赖于OSN账户的丰富信息，例如内容和行为，这会导致检测虚假账户的显著延迟。在这项工作中，我们提出了UFA（揭开虚假账户的面纱）来在虚假账户以无监督的方式注册后立即检测它们。</p>
<p>首先，通过对真实世界注册数据集上的注册模式的测量研究，我们观察到虚假账户倾向于聚集在异常注册模式上，例如IP和电话号码。然后，我们设计了一种无监督学习算法来学习所有注册账户的权重及其特征，以揭示异常注册模式。</p>
<p><strong>接下来，我们构建了一个注册图来捕捉注册帐户之间的相关性，并通过分析注册图结构，利用社区检测方法来检测虚假帐户</strong>。我们使用真实世界的微信数据集评估UFA。我们的结果表明，UFA在召回率为80%的情况下达到了94%的精度，<strong>而监督变体需要600K手动标签才能获得可比较的性能</strong>。此外，微信已经部署UFA来检测虚假账户一年多了。UFA检测到500𝐾
通过微信安全团队的手动验证，每天伪造账户的准确率平均为93%。</p>
<p><strong>本文主要有四大贡献：</strong></p>
<ol type="1">
<li>本文基于微信数据提出了大规模的<strong>度量学习</strong>的方法，并使用注册数据发现了虚假账号在异常注册模式的聚集趋势</li>
<li>本文基于微信注册数据，提出了非监督UFA模型用以识别虚假账户</li>
<li>系统性的评估了UFA和其他监督和非监督模型的效果</li>
<li>UFA模型在微信已经部署超过一年，在线上取得了很好的效果</li>
</ol>
<h3><span id="二-数据探索">二、<strong>数据探索</strong></span></h3>
<h4><span id="21-ip地址分析">2.1 <strong>IP地址分析</strong></span></h4>
<p>在论文使用的数据集中，总共有895,879个不同的IP地址。我们将使用同一IP地址注册的所有帐户组合在一起。因此，组的大小表示从一致的IP地址注册的帐户数量。图8a
显示了注册给定数量账户计数的IP地址数。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521354.png" alt="图片" style="zoom: 50%;"></p>
<p>当给定的帐户数从0-5增加到5-10时，我们观察到IP地址数会有一个数量级的下降。这表明大多数IP地址注册了少量帐户（少于5个帐户），而少数IP地址注册了大量帐户。此外，假冒帐户更有可能使用相同的IP地址注册。</p>
<p>图8b显示了从IP地址注册的帐户中假冒帐户的比例，该IP地址注册了给定数量的帐户。我们观察到，当一个IP地址注册了少量帐户（例如10个）时，很难仅仅根据这些帐户共享IP地址的事实来判断这些帐户是否为假帐户。但是，当大量（例如100）帐户从同一IP地址注册时，这些帐户更有可能是伪造帐户。（量变引起质变）</p>
<h4><span id="22-手机号码分析">2.2 <strong>手机号码分析</strong></span></h4>
<p>用户在注册微信账号时必须提供电话号码。由于我们只能访问电话号码的前 7
位数字（运营商加区号），因此我们将使用电话号码的前缀来研究假帐户和良性帐户之间的区别。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522297.png" alt="图片" style="zoom: 50%;"></p>
<p>图 9a 显示了注册给定数量账户的电话号码前缀的数量，而图 9b
显示了从注册给定数量账户的电话号码前缀注册的账户中虚假账户的比例。与 IP
地址一样，我们观察到大多数电话前缀只具有少量注册帐户，而少数电话前缀具有大量注册帐户。更具体地说，如果一个电话前缀有超过
30 个注册帐户，这些帐户中的大部分可能是假帐户。</p>
<h4><span id="23-设备的deviceid这里用的imei码">2.3 <strong>设备的device
id（这里用的imei码</strong>）</span></h4>
<p>图10a显示了注册给定数量帐户的设备（由IMEI标识）的数量，图10b显示了注册给定数量帐户的设备中注册的帐户中伪造帐户的比例。我们观察到相似的异常模式，也就是说，伪帐户可能是从相同的设备注册的。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522769.png" alt="图片" style="zoom:50%;"></p>
<h4><span id="24-注册时间">2.4 <strong>注册时间</strong></span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522140.png" alt="图片" style="zoom:50%;"></p>
<p>图11显示了在一天中注册的帐户的注册时间的分布。我们观察到大多数良性用户从早上八点开始注册帐户，到晚上24点左右停止注册，午夜时很少有用户活跃。然而，假账户的数量似乎一整天都没有变化。大多数在午夜注册的账户可能是假账户。</p>
<h4><span id="25-不一致的地理位置"><strong>2.5 不一致的地理位置</strong></span></h4>
<p>IP地址和电话号码都可以映射到一个大概的地理位置。因此，我们可以分析每个注册的用户的两个地理位置是否相同（ip和电话号码可以查询到用户的归属地）。我们观察到65%的假帐户具有不同的基于IP的位置和基于电话号码的位置。一个可能的原因是攻击者利用云服务和从本地获取的电话号码注册假帐户。此外，用户还可以在注册帐户时在配置文件中指定其位置（例如国家）。我们发现96%的伪造账户指定的国家与基于IP的定位不一致。一个可能的原因是这些假账户的目的是攻击来自特定地点的良性账户。</p>
<h4><span id="26-微信和设备的版本"><strong>2.6 微信和设备的版本</strong></span></h4>
<p>我们分析了微信版本和操作系统版本，发现大多数从过时的微信或/和操作系统版本注册的账户都是假账户。例如，从某个过时的Android版本注册的账户只有2K个，其中96.5%是假的。同样的现象也发生在iOS中。例如，我们发现从iOS
8（过期的DOS版本）注册的99%的帐户都是假帐户。一个可能的原因是，攻击者使用脚本自动注册假帐户，其中微信和操作系统版本尚未更新。</p>
<h4><span id="27-道德和隐私"><strong>2.7 道德和隐私</strong></span></h4>
<p>微信在隐私政策中规定，用户注册帐户时将收集用户数据。此外，在提交微信服务器之前，所有注册属性都已匿名，以保护用户隐私。例如，电话号码的客户代码（即最后四位数字）将被删除。IP地址逐段散列，WiFi
MAC和设备ID全部散列。特别是，我们有一个与WeChat合作的实习计划，因此我们可以访问存储在微信服务器上的上述数据。</p>
<h3><span id="三-相关研究">三、相关研究</span></h3>
<p>paper中的related部分其实就类似于我们平常做项目之前的一些解决方案的调研，传统的检测方法：这些方法可以分为基于特征的方法和基于结构的方法。</p>
<h4><span id="31-基于特征的方法">3.1 <strong>基于特征的方法</strong></span></h4>
<p>通常将虚假账户检测的建模转化为为一个二分类问题，并利用机器学习技术进行解决。具体来说，<strong>首先从每个账户的内容（如推特中的URL）、行为（如点击流和喜欢的行为记录）、注册信息（如IP地址和代理）中提取特征</strong>。然后，基于这些提取的特征和标记的训练集（由标记的假账户和标记的良性账户组成）训练监督分类器（如logistic回归），并使用训练的分类器检测假账户。</p>
<h4><span id="32-基于结构的方法">3.2 <strong>基于结构的方法</strong></span></h4>
<p>利用社交图的结构来检测假账户，并且通常基于这样一个观察结果，即如果一个账户与其他假账户相关联，该账户可能也是虚假的账户。这些基于扩展图的机器学习技术的方法，例如<strong>随机行走</strong>和<strong>信念传播</strong>，分析用户之间社交图的结构。</p>
<p><strong><font color="red">
上述传统检测方法的主要局限性在于检测假账户时存在严重延迟，因为这些方法需要获取假账户生成的足够信息进行分析，例如，丰富的内容、行为，和/或社交图。</font></strong>因此，当检测到伪造帐户时，它们可能已经进行了各种恶意活动。</p>
<h3><span id="四-模型的原型设计">四、模型的原型设计</span></h3>
<p>UFA旨在以无监督的方式在注册时检测出虚假账户。图1概述了UFA。它由四个关键部分组成，即<strong>特征提取、无监督的权重学习、注册图的构建和假账户检测</strong>。在特征提取方面，受注册模式测量研究的启发，我们提取了揭示虚假账户异常注册模式的特征。<strong><font color="red">
在无监督的权重学习中，我们首先构建了一个注册-特征大图来捕捉注册账户和特征之间的关系。大图中的每个节点都代表一个注册账户或一个特征，注册节点和特征节点之间的每条边都表示该注册账户具有该特征。</font></strong></p>
<h4><span id="41-整体框架">4.1 整体框架</span></h4>
<p>接下来，我们设计了一种统计方法来初始化大图中每个节点的权重。节点的权重量化了该节点的异常情况。我们的统计方法不需要标记的虚假账户或/和标记的良性账户，因此它是无监督的。这里，初始权重没有考虑特征之间和注册账户之间的关系。为了解决这个问题，我们采用了一种最先进的基于结构的方法，称为线性化信念传播[26]，来传播注册-特征大图中节点的初始权重，并迭代更新每个节点的权重。每个注册账户的最终权重表示该账户被伪造的概率。</p>
<p>UFA主要包括了四个步骤：特征提取、无监督权重学习、注册图构造、虚假账户检测</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191151673.png" alt="图片"></p>
<p>在特征提取中，受之前的数据挖掘部分得到的分析结果的启发，我们提取了可以反应假账户异常注册模式的特征。在无监督权重学习中，我们<strong>首先构造一个注册特征-用户
的二部图来捕捉注册账户和特征之间的关系</strong>。二部图中的每个节点表示注册帐户或特征，注册节点和特征节点之间的每个边表示注册帐户具有该特征。我们初始化Bigraph中每个节点权重使用了基于统计的方法。节点的权重量化了节点的异常。我们的统计方法不需要标记假账户或/和标记良性账户，因此不是有监督的方法。在这里，初始权值不考虑特征和注册账户之间的关系。为了解决这个问题，我们采用了一种最先进的基于结构的方法，称为线性化置信传播（《Structure-based
sybil detection in social networks via local rule-based
propagation》），在注册特征bigraph中传播节点的初始权重，并迭代更新每个节点的权重。每个注册帐户的最终权重表示该帐户被伪造的可能性。</p>
<p>无监督权重学习无法学习注册帐户之间的相关性，因为注册特征-用户的bigraph中注册帐户之间没有边。因此，我们构建了一个图来直接捕获注册帐户之间的相关性。具体来说，我们将注册特征的bigraph映射到一个注册图中，其中每个节点都是注册帐户，如果两个注册帐户之间的相似度高于阈值，则在它们之间添加一条边（还是相似度构图的思路啊。。。）。两个注册帐户之间的相似性定义为两个帐户共享的特征权重之和。在构建的注册图中，假账户可能紧密连接，而真账户可能稀疏连接。最后，由于假账户在注册图中紧密连接，我们使用<strong>社区检测算法</strong>进行社群检测。如果社区中的节点的规模大于阈值，则我们将社区中的所有帐户视为假帐户。</p>
<h4><span id="42-特征提取">4.2 <strong>特征提取</strong></span></h4>
<p>注册阶段的用户特征，当用户注册一个微信账号时，微信会收集该账号的多个注册属性。表1列出了具有代表性的注册属性。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522816.png" alt="图片" style="zoom:50%;"></p>
<p>例如，电话号码是用户用来注册帐户的号码。每个电话号码只能用于注册一个帐户和作为帐户ID。WiFi
MAC是手机用于注册帐户的WiFi路由器的MAC地址，DeviceID是用于注册帐户的手机的IMEI/Adsource。根据数据挖掘部分的分析结果，与良性账户相比，虚假账户倾向于具有异常值注册模式。特别是，假账户可能使用相同的IP，使用相同地区的相同电话号码，从相同的设备注册，在午夜活跃，使用罕见且过时的微信和操作系统版本。一个可能的原因是攻击者的资源有限（例如IP、电话号码和设备），只能使用脚本自动注册假帐户。</p>
<p>那么我们怎么做特征提取呢？我们提取了可以用来反映虚假帐户异常注册模式的特征。<strong>具体来说，我们将每个注册表的属性和属性值解析为一个字符串，格式为“%%FeaturePrefix%%.%%value%%”</strong>。表2中列出了所有特性前缀。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522987.png" alt="图片" style="zoom:50%;"></p>
<p>每个特征前缀只与一个属性相关，并表示该属性的预处理函数；并且每个值都是预处理后生成的结果。为了简单起见，我们只展示如何提取特征前缀为“TimeAbnormal”的特征，因为其他特征可以从其特征前缀和描述中轻松理解：</p>
<p>TimeAbnormal：根据我们的数据挖掘的结果，我们观察到在深夜注册的账户很可能是假账户，而良性账户主要在白天注册。因此，我们定义了一个特征Prefix
TimeAbnormal，它使用时间戳特征。时间异常用于指示帐户的注册时间是否异常。也就是说，如果账户在白天注册，则时间异常值为假，如果账户在午夜晚些时候注册，则时间异常值为真，在我们的工作中，我们将午夜定义为凌晨2点到5点之间。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522169.png" alt="图片" style="zoom:50%;"></p>
<p>这里的意思是根据注册时间构建一个节点，这个节点的id为 timeanomaly
true，如上图。</p>
<p><strong><font color="red">
整体来看，特征提取的思路很简单，其实本质上就是通过将用户的属性转化为节点，从而将单个用户节点分裂为以用户节点为中心的用户-属性的k部图，不过文中用的描述是2部图，其实就是把所有的特征都定义为类型为“特征”的节点，问题不大。</font></strong></p>
<p>在构图之前，对于特征论文中进行统一的string话处理，格式为
"%%FeaturePrefix%%_%%Value%%"，假设我们现在手头有两个用户uid001和uid002，对于特征的处理和图的构建就像下图这样：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">data = <span class="punctuation">&#123;</span></span><br><span class="line">    &#x27;uid001&#x27;<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        &#x27;PHONE&#x27;<span class="punctuation">:</span> <span class="number">123456</span><span class="punctuation">,</span></span><br><span class="line">        &#x27;MAC&#x27; <span class="punctuation">:</span> <span class="string">&quot;abcd&quot;</span><span class="punctuation">,</span></span><br><span class="line">        &#x27;IP&#x27; <span class="punctuation">:</span> &#x27;<span class="number">11.22</span><span class="number">.33</span><span class="number">.44</span>&#x27;</span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    &#x27;uid002&#x27;<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        &#x27;PHONE&#x27; <span class="punctuation">:</span> <span class="number">123456</span><span class="punctuation">,</span></span><br><span class="line">        &#x27;MAC&#x27; <span class="punctuation">:</span> &#x27;dcba&#x27;<span class="punctuation">,</span></span><br><span class="line">        &#x27;IP&#x27;<span class="punctuation">:</span> &#x27;<span class="number">44.33</span><span class="number">.22</span><span class="number">.11</span>&#x27;</span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>构图数据预处理过程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">feature_to_node</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line">    </span><br><span class="line">    result = defaultdict(<span class="built_in">set</span>)</span><br><span class="line">    <span class="keyword">for</span> uid, features <span class="keyword">in</span> data.items():</span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> features:</span><br><span class="line">            node = <span class="string">f&#x27;<span class="subst">&#123;feature&#125;</span>_<span class="subst">&#123;features[feature]&#125;</span>&#x27;</span></span><br><span class="line">            result[uid].add(node)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">feature_to_node(data)</span><br><span class="line">defaultdict(<span class="built_in">set</span>,</span><br><span class="line">            &#123;<span class="string">&#x27;uid001&#x27;</span>: &#123;<span class="string">&#x27;IP_11.22.33.44&#x27;</span>, <span class="string">&#x27;MAC_abcd&#x27;</span>, <span class="string">&#x27;PHONE_123456&#x27;</span>&#125;,</span><br><span class="line">             <span class="string">&#x27;uid002&#x27;</span>: &#123;<span class="string">&#x27;IP_44.33.22.11&#x27;</span>, <span class="string">&#x27;MAC_dcba&#x27;</span>, <span class="string">&#x27;PHONE_123456&#x27;</span>&#125;&#125;)</span><br></pre></td></tr></table></figure>
<h4><span id="43-无监督的权重学习">4.3 <strong>无监督的权重学习</strong></span></h4>
<p><strong>在无监督权重学习中，我们的目标是学习每个提取特征和每个注册帐户的权重。</strong>权重量化异常，范围在0到1之间。较高的权重表示异常的可能性较大。具体来说，我们首先构造一个图来捕获特征和注册帐户之间的关系，其中每个节点表示一个特征或一个注册帐户，两个节点之间的每条边表示注册帐户具有该特征。<strong><font color="red">
我们设计了一种统计方法，以无监督的方式初始化构造图中每个节点的权重，并采用基于结构的方法在构造的图中传播节点的初始权重，并迭代更新每个节点的权重。每个注册节点的最终权重可被视为该注册帐户的伪造概率。</font></strong></p>
<p>我们构造用户-特征的二部图来捕获注册帐户和提取特征之间的关系：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522902.png" alt="图片" style="zoom:50%;"></p>
<p>如上图所示。<strong>具体来说，我们用
（R，F，E）来表示这个图</strong>，其中R表示一组注册节点，就是注册用户的意思，F
表示一组特征节点，就是每个F节点都表示某个特征（当然这里的特征都是离散的，连续特征没法直接作为节点需要离散化之后才能作为节点），E，就表示edge了，（因为注册账户节点和特征节点之间都是
注册账户节点“拥有”特征节点
这么一个抽象的关系，所以edge的权重默认均为1.）注册节点和特征节点之间的边表示注册节点，即注册用户具有这个特征。</p>
<p>例如，在上图中， 节点连接了
如“IP32_10.xxx.xxx.10”、“PN_+861585321xxxx”、“OSV_Android
7.0”这三个特征节点，这意味着
注册时，使用IP地址“10.xxx.xxx.10”、电话号码“+861585321xxxx”和手机操作系统版本“Android
7.0”。</p>
<p>特征节点的权重的初始化策略，（<strong>这篇paper的思路是先通过无监督的方法给特征节点的权重进行初始化，然后通过信念传播的方式给注册账户节点进行权重的传播赋值</strong>）。我们设计了一种统计方法，为每个特征节点和每个注册帐户节点分配初始权重，这个过程无需手动打标虚假账户。我们的统计方法依赖于三个概念：<strong><font color="red">
特征频率、特征比率和特征模式</font></strong>。</p>
<ul>
<li><strong>特征频率</strong>：特征频率表示某个特征有多少个注册账户有，比如有100个注册账户在注册的时候都使用了“IP32_10.xxx.xxx.10”，则“IP32_10.xxx.xxx.10”这个特征节点的特征频率为100；</li>
<li><strong>特征比率</strong>：其实就是同类特征的占比啦。比如说我们的手机号这个特征下有10000个手机号，其中“PN_+861585321xxxx”有5000个，则“PN_+861585321xxxx”这个特征节点的特征比率为0.5.</li>
<li><strong>特征模式：</strong>特征模式不是相对于某个特征节点的，而是对于某个特征下所有的特征节点的，还是举个例子，假设OSV前缀的，即手机系统版本这个特征下有Android
7.0，Android 8.0，Android 9.0，占比分别为0.25，0.25，0.5，则最终我们得到
OSV 这个特征的特征模式为 Android
9.0,其实就是某个特征下某个最大取值对应的特征节点的名字。</li>
</ul>
<p>现在我们可以通过使用上述的特征频率，特征比率和特质模式来定义每个特征的权重。<strong>我们通过定义特征的权重来量化特征的异常。</strong></p>
<p>为了描述清晰，这里还是强调一下，特征频率和特征比率都是针对于特征节点的，而特征模式是针对于某一类特征节点的群体的，以性别为例（因为性别特征就两个取值，比较好理解），性别有男女，则按照上述的思路，我们会有一个
“sex_男”和“sex_女”的这两种特征节点，“sex_男”和“sex_女”的特征频率假设分别60和40，则其特征比率分别为0.6和0.4，性别这个特征的特征模式为0.6.具体地说，是这么做的，首先，我们将所有的特质划分为两个组，一个pre-A，一个pre-B。我们以数据挖掘分析部分的一个case为例：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522966.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>deviceid的共享情况，这个图解释一下，左边的直方图，横轴表示device id
共享的账户的数量，按照直方图的划分可以知道，每一个device
id根据其共享的账户数量打上了标签，分别为“
0～5”，“5～10”.。。。“&gt;=30”，然后我们统计每一种标签下的device的数量，就是纵轴的取值了，可以看到，deviceid这种东西反映出来的趋势是
deviceid 一般情况下不太可能被多个账户共享，大部分的device
所共享的账户很少，极少部分的deivce id
存在大量账户共享的情况，所以我们把device id 这种特征分到 pre-B
组中去；像ip，phone
这些的反应出来的情况都是一样的，所以都放到pre-B中去了，显然，我们可以知道，放到pre-B中的特征都是不太容易产生高账户共享问题的字段。</p>
<p>原文提到了pre-A中的特征有一个是osv，即手机的版本号，比如android 7.0
，ios xxx
这类的。pre-A中的特征就是比较容易产生大量账户共享的，比如手机版本，app的版本，时间上的异常等等（<strong>我以前对于这种容易产生大量账户共享的特征都是删除不拿来建图的，因为容易产生很稠密的图，坏处就是损失了一部分信息，这里给到的思路还可以。</strong>）而对于pre-B中的特征，例如phone
number
手机号这种东西，一般不太容易被大量的账户共享，那么对于手机号这种特征，其特征节点，例如“861585321xxx”
这个号段，如果被大量账户共享，则我们认为这种情况很异常，因为手机号本上就趋向于被很少的账户共享或不被共享。文中的pre-A和pre-B的选择为：Pre_A={
, ℎ , , }andPre_B={ 32, , , }</p>
<p>我们这么来定义特征节点的权重，可以看到，上述的公式应该是很清晰了，对于pre-A中的特征，特征节点的节点权重为1-ratio（x），即这个特征节点共享的账户越多，越正常，节点权重越小；对于pre-B中的特征，特征节点的权重为ratio（x），即这个特征节点共享的账户越多，越不正常，节点权重越大。</p>
<p><strong><font color="red">
然而，有一个严重的问题，上述定义的特征节点的权重，不能用于直接比较不同特征下的不同特征节点的节点权重</font></strong>，例如经过这样的计算，android7.0
这样的特征节点和“861585321xxx”
这样的特征节点没有可比性，比如手机系统版本和手机号这两个特征的特征分布，前者的特征比分布是比较集中的（大部分用户都是集中使用比较新的几个版本），而手机号的特征比分布则比较均匀（用户均匀的分配到不同的手机号段上），这个时候算出来的ratio肯定差别很大的。为了解决这个问题，对上图的公式进行优化和重新定义，使用了一种称为类别特征的“特征匹配”的技术（《Guansong
Pang, Longbing Cao, and Ling Chen. 2016. Outlier Detection inComplex
Categorical Data by Modeling the Feature Value Couplings..
InIJCAI.》），具体来说，是这么做的。</p>
<p>特征节点的节点权重wx的公式转化如下： <span class="math display">\[
w_x=\frac{1}{2}(\operatorname{dev}(x)+\operatorname{base}(x))
\]</span> where <span class="math display">\[
\operatorname{dev}(x)=
\begin{cases}1-\frac{\operatorname{ratio}(x)}{\text { ratio }(\text {
mode }(\text { pre }(x)))} &amp; \text { if } \operatorname{pre}(x) \in
\text { Pre-A } \\ 1-\frac{1-\operatorname{Aatio}(x)}{\text { ratio
}(\text { mode }(\text { pre }(x)))} &amp; \text { if }
\operatorname{pre}(x) \in \text { Pre-B}\end{cases}
\]</span> and <span class="math display">\[
\operatorname{base}(x)=
\begin{cases}1-\operatorname{ratio}(\operatorname{mode}(\operatorname{pre}(x)))
&amp; \text { if } \operatorname{pre}(x) \in \text { Pre-A } \\
\operatorname{ratio}(\operatorname{mode}(\operatorname{pre}(x))) &amp;
\text { if } \operatorname{pre}(x) \in \text { Pre-B }\end{cases}
\]</span> 本质上就是做了一个标准化的操作,
使得不同特征下的特征节点的权重统一到一个量纲下（<strong>对于离散特征的这种权重的处理在图中具有很好的推广作用,
有时间再看看文中提到的这几篇论文, 很不错</strong>) <span class="math inline">\(\operatorname{dev}(\mathrm{x})\)</span>
考虑了特征节点的异常，base <span class="math inline">\((x)\)</span>
考虑了特征的异常。因为 <span class="math inline">\(\operatorname{dev}(x)\)</span>
的取值必然是0~1之间的， base (x)也必然是0~1之间的, 因此,
最终我们的特征节点权重w <span class="math inline">\((x)\)</span>
也必然是0~1之间的。然后,
注册账户节点的初始化权重就是和这个注册账户节点连接的所有的特征节点的权重的平均值。
<span class="math display">\[
w_r=\frac{\sum_{x \in \Gamma(r) w_x}}{|\Gamma(r)|}
\]</span> <strong>初始化了权重之后,
使用线性的信念传播来进行特征节点和注册账户节点的权重的更新迭代,</strong>
<span class="math display">\[
\begin{split} p_u^{(t)}=w_u+2 \sum_{v \in
\Gamma(u)}\left(p_v^{(t-1)}-0.5\right) \cdot\left(h_{v u}-0.5\right)
\end{split}
\]</span></p>
<p>文中提到了，作者做了10次的迭代来更新所有节点的权重。(<strong>信念传播还不太懂,
暂时可以先理解类似于用户自定义初始权重的个性化pagerank</strong>)</p>
<h4><span id="44-注册信息构图">4.4 注册信息构图</span></h4>
<p><strong>我们构建了一个加权图来直接捕捉注册账户之间的关联性。构建的图是由注册-特征图而来的</strong>。具体来说,
对于注册特征图中的每一对注册节点 <span class="math inline">\(u, v \in
\mathbb{R}\)</span>, 我们在 <span class="math inline">\(u\)</span> 和
<span class="math inline">\(v\)</span> 之间创建一条边 <span class="math inline">\((u, v)\)</span> ，只要 <span class="math inline">\(u\)</span> 和 <span class="math inline">\(v\)</span> 的相似度大于阈值。特别是, 我们把 <span class="math inline">\(u\)</span> 和 <span class="math inline">\(v\)</span> 之间的相似性 <span class="math inline">\(\operatorname{sim}(u, v)\)</span> 定义为 <span class="math inline">\(u\)</span> 和 <span class="math inline">\(v\)</span>
的共享特征的最终权重之和。这背后的直觉是，如果两个注册节点共享许多特征,
而且这些特征的最终权重很大（异常概率大），那么这两个注册
账户也有很大的相似性, 倾向于是假账户。如下图: <span class="math display">\[
\operatorname{sim}(u, v)=\sum_{s \in \Gamma(u) \bigcap \Gamma(v)} p_s
\]</span> 此外，我们设置了边的权重<span class="math inline">\((𝑢,𝑣)\)</span> 在新的图中成为相似性<span class="math inline">\(sim(𝑢,𝑣)\)</span>.
我们将构建的加权图称为注册图，因为图中的所有节点都是注册帐户。虚假账户更有可能以较大的边缘权重相互连接，良性账户更有可能通过较小的边缘权重稀疏连接。最终我们将注册账户节点-特征节点的异构图转化为了<strong>注册账户节点-注册账户节点的基于相似度的同构图。</strong></p>
<h4><span id="45-社区发现">4.5 <strong>社区发现</strong></span></h4>
<p>在注册图中，我们注意到虚假账户密集连接，而良性账户稀疏连接。<strong>为了检测欺诈账户，我们需要识别注册图中的密集子图</strong>。自然的选择是利用社区发现算法。我们首先采用社区检测方法，例如<strong>Louvain方法[2]</strong>，将节点分为不同的社区（即密集子图）。其次，我们检测发现出来的社区中的所有注册帐户的数量，如果其大小超过了我们设定的阈值，则认为这个社群中所有的注册账户都是有问题的虚假账户。</p>
<ul>
<li>我们首先采用社区检测方法将节点聚集到不同的社区（即密集子图）。</li>
<li>其次，我们预测社区中所有规模大于阈值的注册账户都是假账户。</li>
</ul>
<h3><span id="五-模型评估">五、模型评估</span></h3>
<h4><span id="51-实验设置">5.1 实验设置</span></h4>
<ul>
<li><strong>数据集</strong></li>
</ul>
<p>我们从微信中获得了七个数据集。每个数据集都包括一天内的注册信息。表3显示了这些数据集的细节。这些标签是由微信安全团队提供的，他们手工验证了这些标签（大厂就是牛逼），并发现这些标签的准确率大于95%。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522980.png" alt="图片" style="zoom:50%;"></p>
<ul>
<li><strong>评价指标</strong></li>
</ul>
<p>我们使用三个指标，即<strong>准确率、召回率和 F-score
来评估性能</strong>。对于一个检测方法来说，精确率是其预测的假账户在测试集中为真实假账户的比例，召回率是测试集中真实假账户被该方法预测为假账户的比例，而F分数是精确率和召回率的调和平均值。比较的方法。我们将UFA与几种无监督的变体进行比较，包括UFA-naive、UFA-noLBP、UFA-noRG和超级视觉方法，包括Ianus[35]、XGBoost[6]和深度神经网络（DNN）。</p>
<h4><span id="52-实验结果">5.2 实验结果</span></h4>
<p>表4显示了ufa在七个数据集上的预测结果。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522407.png" alt="图片" style="zoom:50%;"></p>
<p>UFA可以在所有数据集中检测到约80%的假帐户，其精确度约为90%。一个关键原因是，通过无监督的权重学习和注册图构造，注册图中的假账户连接紧密，而良性账户连接稀疏。</p>
<p>例如，在第五天由构建出来的注册图中（从这里可以看出，腾讯构图的方式是构建天级别的图），平均而言，一个假帐户与22.32个其他假帐户存在连接，而与1个良性账户存在连接，而对于一个良性帐户而言，仅与2.04个其他良性账户相互连接。</p>
<p>然后，Louvain的方法可以很容易地检测到这些密集连接的假帐户。我们发现大约85%的假账户聚集在一起，剩下的15%的假账户是分散的，也就是说，他们与其他人没有共同的特征（这种就没办法了，毕竟ufa是完全从关联上出发去检测的）。因此，根据ufa的80%左右召回表现，证明了其在检测假账户方面的有效性。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522512.png" alt="图片" style="zoom:50%;"></p>
<ul>
<li><h5><span id="相似阈值的影响"><strong>相似阈值的影响</strong></span></h5></li>
</ul>
<p>回顾一下，<strong>UFA预先定义了一对注册账户之间的相似度阈值，以确定两个注册账户之间是否添加了一条边。一个自然的问题是这个相似度阈值对UFA的检测性能有什么影响</strong>。图3a显示了UFA与1.0和1.5之间的相似度阈值的结果。我们观察到，当阈值增加时，精确度增加，召回率下降，而F-Score首先增加，然后下降。原因是较大的阈值使一对注册账户在我们的注册图中更难连接。当使用较高的阈值时，注册图中的连接节点更有可能是假账户，所以我们可以有更高的精度。同时，更少的假账户可以相互连接，因此召回率下降。我们还注意到，当相似度阈值在1.2左右时，F-Score达到最大值。因此，我们在实验中选择默认的相似度阈值为1.2。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522878.png" alt="图片" style="zoom:50%;"></p>
<p>我们观察到，当阈值增加时，精度增加，而F分数先增加后减少。原因是阈值越大，在注册图中连接一对注册帐户就越困难。当使用更高的阈值时，注册图中连接的节点更有可能是假帐户，因此我们可以获得更高的精确度。同时，可以相互连接的假帐户更少，从而减少了recall。我们还注意到，当相似性阈值在1左右时，F分数达到最大值。因此，我们在实验中选择了一个默认的相似性阈值为1.2。</p>
<ul>
<li><h5><span id="社区规模的影响">社区规模的影响</span></h5></li>
</ul>
<p>UFA使用Louvain方法检测社区并预测社区中的注册帐户，这些帐户的大小大于预定义的阈值，即假帐户。我们研究了不同社区规模对UFA的检测性能的影响，结果如图3b所示。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522494.jpeg" alt="图片" style="zoom:50%;"></p>
<p>我们观察到，随着社区规模的阈值变大，精确度和F分数先增加后降低。当阈值大于15时，所有三个指标都是稳定的。所以，我们在实验中选择了社区规模的默认阈值为15。</p>
<h3><span id="六-在微信场景的实际部署">六、<strong>在微信场景的实际部署</strong></span></h3>
<p>UFA已经被微信部署了一年多，用于检测虚假账户。它是在Spark上用Python实现的，并被部署在微信的内部云计算平台YARD上。UFA以流程模式工作，其部署图如图6所示。具体来说，UFA系统有两个阶段：<strong>系统初始化和系统更新。</strong></p>
<h4><span id="61-系统初始化">6.1 <strong>系统初始化</strong></span></h4>
<p>微信最初部署时，UFA收集一定数量的注册账号，提取特征，构建注册特征bigraph，学习特征权重和注册帐户，并构建注册图。微信在部署后第一周使用所有注册账号完成系统初始化。初始化后，我们拥有特征节点和注册帐户的权重。系统初始化中的所有步骤都在流式处理服务器上执行。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522379.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h4><span id="62-系统更新">6.2 <strong>系统更新</strong></span></h4>
<p>系统初始化后，当WeChatserver收到新的注册帐户时，UFA先提取帐户特征，然后执行以下步骤。</p>
<ul>
<li>在注册特征的Bigraph中创建新节点/边。UFA先为不在当前注册特征的bigraph中的特征创建新注册节点和新特征节点。然后，UFA在注册节点及其特征节点之间创建新边。此步骤在流数据服务器上运行。</li>
<li>在注册图中创建新节点/边。UFA在此步骤中检索与新注册帐户接近的现有注册帐户。具体而言，UFA寻找所有现有注册帐户与新注册帐户之间共享的注册节点。然后，UFA使用特征节点的当前权重计算新注册帐户和找到的注册帐户之间的相似性。接下来，在注册图中，如果两个帐户之间的相似性大于预定义阈值，UFA将为新注册帐户创建一个新节点，并在新注册帐户和找到的每个注册帐户之间创建一条边。此步骤在流式处理服务器上运行。</li>
<li>定期更新特征/注册节点的权重并检测假帐户。<strong>为了减轻计算负担，UFA更新特征/注册节点的权重，并每小时检测一次假帐户</strong>。权重更新和伪造帐户检测都定期在检测服务器上执行。<strong>具体来说，流式处理服务器上的UFA会每小时更新注册-特征节点bigraph和注册-注册节点的同构图，并将这些图保存到数据库中。</strong>然后，从数据库加载图，并运行无监督权重学习算法和社区检测算法来检测假帐户。接下来，UFA将更新的特征/注册节点的权重和检测到的假帐户从检测服务器传输到流处理服务器。检测到的假帐户存储在数据库中。流服务器使用更新的特征/注册节点权重进行下一次定期系统更新。</li>
</ul>
<h4><span id="63ufa在真实场景中的表现">6.3
<strong>UFA在真实场景中的表现</strong></span></h4>
<p>微信所有检测到的假帐户，其中一些可能是良性帐户。如果良性帐号被封禁，微信安全团队会收到注册该帐号的用户的投诉。微信使用投诉数量来评估UFA的表现。</p>
<p>具体来说，微信安全团队有6名安全分析师来处理用户的投诉。总体而言，申请解锁账户在被封禁的账户中不到6%。此外，微信安全团队随机抽取了200个被UFA检测到的虚假账户，对UFA的性能进行评估，UFA的精度达到93%，与投诉测得的结果一致。</p>
<p>综上所述，UFA 平均每天检测 50 万个假账户，自 UFA部署以来总共检测到
1.8 亿个假账户（在 4 亿个注册账户中）。</p>
<p>Ianus 在现实世界中的部署限制，在 UFA 之前，微信已经部署了 Ianus [35]
大约六个月。<strong>Ianus
是一种监督式虚假账户检测方法，它也利用了账户的注册信息。然而，Ianus在部署一段时间后就暴露了它的弱点</strong>。</p>
<ul>
<li>首先，手动标记非常耗时。微信安全团队有6名安全分析师，他们的职责是对注册账号进行标记，每个分析师每天可以标记大约1000个注册。人工标注，比如600K个虚假账户，大概需要100天左右，很费时间。很难获得准确的标注，毕竟人也会犯错。许多虚假帐户仅在检查其注册信息，类似于良性帐户。</li>
<li>而在一定数量的噪音标签下，Ianus的性能将下降。</li>
<li>除此之外，需要经常对Ianus进行retraining，以保持较高的检测性能。</li>
</ul>
<p>图7显示了Ianus在连续14天的预测中的表现，不进行retraining。为了简单起见，我们只展示了分数，我们在精度和调用方面也有类似的观察结果。我们看到，Ianua的F-Score从第七天开始大幅下降。68%对55%。92%，在14天内。<strong>一个可能的原因是攻击者不断改变他们的注册模式以逃避Ianus的检测。</strong>因此，基于旧注册模式训练的Ianus不足以检测具有新注册模式的假帐户。为了保持较高的检测性能，需要经常使用新注册模式上的准确标签对Ianus进行重新训练。然而，正如我们上面提到的，它是耗时的，并且很难准确地标记注册帐户，所以靠谱的retraining需要的标签也不多。相比之下，UFA的分数相对稳定，表明UFA在实际部署中要比Ianus更好。</p>
<h3><span id="七-总结">七、 总结</span></h3>
<p>在本文中，我们开发了一种无监督的方法UFA来检测虚假账户，在他们被注册后立即检测。我们首先提取了揭示假账户异常注册模式的特征，其灵感来自于对微信中真实世界注册数据集的测量研究。然后，我们设计了一种无监督的权重学习算法来学习提取的特征和注册账户的权重。此外，我们构建了一个注册图来直接捕捉注册账户之间的关联性，如虚假账户是密集连接的，而良性账户是稀疏连接的。最后，我们采用了一种社区检测算法，通过分析注册图结构来检测虚假账户。我们使用微信的真实世界数据集对UFA进行了评估。我们的结果显示，UFA取得了94%的精度和80%的召回率。UFA已经被微信部署在检测虚假账户上一年多了，并且达到了93%的精度。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>账号安全</category>
      </categories>
      <tags>
        <tag>无监督</tag>
        <tag>账号安全</tag>
        <tag>图社区发现</tag>
      </tags>
  </entry>
  <entry>
    <title>风控反欺诈（1）【draft】图机器学习在蚂蚁推荐业务中的应用</title>
    <url>/posts/X0QGWS/</url>
    <content><![CDATA[<h2><span id="图机器学习在蚂蚁推荐业务中的应用">图机器学习在蚂蚁推荐业务中的应用</span></h2>
<blockquote>
<p>https://mp.weixin.qq.com/s/BgNQdW3RvLw6rS1Wy-emzA</p>
</blockquote>
<h3><span id="一-相关背景">一、相关背景</span></h3>
<p><strong>导读：</strong>本文将介绍图机器学习在蚂蚁推荐系统中的应用。<strong>在蚂蚁的实际业务中，有大量的额外信息，比如知识图谱、其他业务的用户行为等，这些信息通常对推荐业务很有帮助，我们利用图算法连接这些信息和推荐系统，来增强用户兴趣的表达。</strong></p>
<p>==全文主要围绕以下几方面内容展开：==</p>
<ul>
<li>背景</li>
<li>基于图谱的推荐</li>
<li>基于社交和文本的推荐</li>
<li>基于跨域的推荐</li>
</ul>
<p><img src="640.png" alt="图片" style="zoom:50%;"></p>
<p>支付宝除了最主要的支付功能外还有大量的推荐场景，包括腰封推荐、基金推荐和消费券推荐等等。支付宝域内的推荐相比于其他推荐最大的区别是用户的行为稀疏，活跃度较低，很多用户打开支付宝只是为了支付，不会关注其他东西。所以<strong><em>推荐网络中UI边的记录是非常少的，我们的关注点也是低活目标的推荐。</em></strong>比如为了提升DAU，可能只会给低活用户在腰封投放内容，正常用户是看不到的；基金推荐板块我们更关注的是那些没有理财或理财持仓金额较低的用户，引导他们买一些基金进行交易；消费券的推荐也是为了促进低活用户的线下消费。</p>
<p><strong>低活用户历史行为序列信息很少，一些直接根据UI历史行为序列来推荐的方法可能不太适用于我们的场景</strong>。因此我们引入了下面三个场景信息来增强支付宝域内的UI关系信息：</p>
<ul>
<li><strong>社交网络的UU关系</strong></li>
<li><strong>II图谱关系</strong></li>
<li><strong>其他场景的UI关系</strong></li>
</ul>
<p>通过社交网络的UU关系可以获取低活用户好友的点击偏好，根据同质性就可以推断出该用户的点击偏好，物品与物品之间的图谱关系可以发现、扩展用户对相似物品的喜好信息，最后跨域场景下的用户行为对当前场景的推荐任务也有很大帮助。</p>
<h3><span id="二-基于图谱的推荐">二、<strong>基于图谱的推荐</strong></span></h3>
<p><strong>很多推荐场景中用户的行为是稀疏的，尤其是在对新用户进行刻画时，可利用的行为信息很少，所以通常要引入很多辅助信息</strong>，比如attribute、contexts、images等等，我们这里引入的是knowledge
graph—知识图谱。</p>
<p>知识图谱是一个大而全的历史专家知识，有助于我们的算法推荐，但是还存在两个问题：</p>
<ul>
<li><p><strong>一是图谱本身可能并不是为了这个业务而设计的，所以里面包含很多无用信息，训练过程也非常耗时。</strong>一个常用的解决办法是只保留图谱中能关联上我们商品的边，把其他边都删掉，但这又可能会造成一些信息损失，因为其他边也是有用的。</p></li>
<li><p><strong>二是图谱用做辅助信息时，没办法将用户的偏好聚合到图谱内部的边上</strong>。==如上图所示，用户1喜欢电影1和电影2的原因可能是因为它们有同一个主演，而用户2喜欢电影2和电影3的原因是它们的类型相同==。如果只用普通的图模型的UI、II关系来建模，只能得到用户和电影的相关性，而没办法将用户的这些潜在意图聚合到图谱中。</p></li>
</ul>
<p>所以我们后面主要解决图谱蒸馏和图谱精炼这两个问题。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>风控反作弊</category>
      </categories>
  </entry>
  <entry>
    <title>风控反欺诈（4）智能风控体系总览</title>
    <url>/posts/3E0FW0E/</url>
    <content><![CDATA[<h3><span id="智能风控体系总览">智能风控体系总览</span></h3>
<h3><span id="一-智能风控体系介绍"><strong>一、智能风控体系介绍</strong></span></h3>
<p>智能风控是利用大数据、人工智能技术和科学决策方法，通过自动化预测、评级和决策等方式，提高风控效果和效率、降低成本的一套综合体系。智能风控包括智能风控的方法论，智能风控的算法，工程技术的实现以及深入业务场景的应用。</p>
<p><strong>智能风控方法</strong>包含模型搭建方法、数据挖掘方法、风控策略制定方法，通过一系列方法，我们可以构建智能风控的基本架构。</p>
<p><strong>智能风控算法</strong>包括机器学习算法、深度学习和关系网络等算法，这些算法是方法体系中的核心部件，也是智能风控得以展现智能的关键部分。</p>
<p><strong>工程技术实现</strong>是运用智能风控的方法论以及智能算法，结合工程技术，实现自动化的风控决策和智能交互。</p>
<p><strong>应用方面</strong>，在业务流程的全过程中，只要有风险点的环节都可以加入智能风控进行决策。根据不同的业务场景灵活的选取模型规则的组合进行自动决策。自动体系要达到的最终目的是提高企业风控的精准度和效率，将风险控制在合理的范围内，减少风险损失提高企业的盈利能力。</p>
<h3><span id="二-智能风控详细体系架构">二、<strong>智能风控详细体系架构</strong></span></h3>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305061648869.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>我们可以将智能风控体系拆解为图示的详细架构。该架构包含四层，分别为数据层、特征层、模型层和决策层。</p>
<ul>
<li>如果将整个智能风控体系比作一栋建筑，那么<strong>数据层</strong>是智能防控体系最基础的原材料。我们通过大量的历史数据来训练模型，通过数据构建特征，通过数据作为新决策的判断输入。</li>
<li><strong>特征层</strong>是智能风控的砖瓦，基于数据构建特征，通过提取数据中的关键信息，形成可以用于模型和决策的特征。</li>
<li><strong>模型层</strong>是智能风控的主体结构，通过历史样本数据和目标数据，利用各类机器学习算法基于丰富的特征，训练出满足各类业务场景的模型。</li>
<li><strong>策略层</strong>是智能风控的门面，特征和模型最终将服务于业务的特定场景。在不同的业务场景参与决策，策略层通过模型和规则的各种组合完成决策过程。</li>
</ul>
<p>智能风控的每一层，再进行横向划分，包括关键内容、流程步骤、算法方法、工具平台。</p>
<ul>
<li><strong>关键内容列</strong>包含每一层的主体内容和重要结果。</li>
<li><strong>流程步骤列</strong>是每一层构建关键的内容的流程和主要步骤。</li>
<li><strong>算法方法列</strong>是构建每一层结果采用的主要智能算法方法。</li>
<li><strong>工具平台列</strong>是包含构建流程管理关键结果的工具，是自动化管理的技术落地。</li>
</ul>
<p>以上是整体的智能风控的体系架构。接下来展开每一层进行详细介绍。</p>
<h4><span id="21-数据层">2.1 数据层</span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305061648134.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>首先是数据层。数据是所有智能风控的基础，数据中包含识别风险的信息，智能风控数据层包含不同类型的数据。根据来源我们可以将数据分为其<strong>内部数据</strong>和<strong>第三方数据</strong>。以金融风控场景中常见的数据为例，<strong>企业内部数据包含基础信息，比如身份信息、学历信息、设备相关的信息包含
app
行为数据、设备指纹数据等。</strong>交易数据包含授信记录数据、还款记录数据等。第三方数据就更加广泛，包括多头借贷数据、征信相关数据等。</p>
<blockquote>
<p><strong><font color="red">
清楚自己的数据都有哪些？waflog、router、环境、埋点、设备指纹</font></strong></p>
</blockquote>
<p><strong>数据处理上，按照处理的实效性划分，可以分为实时计算和离线计算</strong>。实时计算通常是用于实时决策场景。比如线上金融业务的授信审批，需要实时获取各类信贷决策的数据。<strong>离线计算通常用于定时任务，比如信贷风控中的贷中风控识别场景。从数据处理的方式上划分，可以分为流式数据处理和批量数据处理。</strong></p>
<ul>
<li><strong>数据处理的步骤通常分为数据采集、数据校验、数据清洗、数据存储、标准输出和数据监控</strong>。数据采集步骤对企业内部数据通常是从业务系统产生的数据元素获取需要的数据字段。对外是从第三方接口获取数据。</li>
<li>数据校验是对数据做基本的验证判断，确保指定对象的数据有效。数据清洗是对数据做规范标准化处理，排除异常和杂乱数据。数据存储分为线上实时数据和离线数据存储，以满足不同使用场景和目的。</li>
<li>标准化输出是将数据处理的结果对外提供使用接口或者其他的查询服务。</li>
<li>数据监控是对整个数据处理结果的过程进行监控预警，及时发现数据层的应用异常。</li>
<li>数据平台是数据层的支撑工具，通过数据平台来实现数据层的管理。通常数据平台包含内外部数据接入整合的功能，数据管理和服务的功能，数据校验和监控的功能。</li>
</ul>
<h4><span id="22-特征画像层详解">2.2 <strong>特征画像层详解</strong></span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305061648859.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>特征是对数据的再次加工,将智能风控建筑的原材料变成砖瓦。特征是从数据中抽取有效的、针对特定目的的部分信息，从数据产生特征的过程就是特征挖掘。</strong>数据质量决定了特征质量的上限，但是好的特征挖掘过程是尽量的从数据中挖掘出最有价值的信息。有些特征是直接从数据中获取的比如性别、年龄、居住区域这类身份特征和基础信息特征。另外一些特征就需要对原始数据进行汇总加工比如借款次数、额度使用占比等。还有一些特征需要基于关系图谱机器学习的方法进行深度加工才能提取，比如二度关系里人的特征、收入指数、消费能力指数等。</p>
<ul>
<li>特征提取的方法包括基于统计聚类的 RFM
方法，基于时序特征的提取方法，基于机器学习 NLP
图特征图算法等特征提取方法。虽然特征提取的方法不同，但是特征提取的关键步骤基本是一致的。</li>
<li>源数据分析和清洗是对原始数据的流转、时效、质量等进行分析并清洗处理成标准格式。中间数据构造是按照不同特征提取的方法构建中间数据集，比如二分类特征提取方法要求数据集为标准的宽表数据格式。</li>
<li>特征设计和生成是根据不同特征提取方法设计并生成特征，比如 RFM
特征方法中需要选取特征汇总的不同维度、汇总的对象以及汇总的计算方式。</li>
<li>特征评估是对特征效果进行分析，选择效果好、稳定性高的特征。</li>
<li>特征回溯是对历史数据进行回测，通常服务于特征提取后的建模场景。</li>
<li>特征监控是对已经进入使用阶段的特征进行持续监控以确保有效性和稳定性。</li>
<li>特征平台是为了支撑特征从开发到应用的工具平台。通常特征平台包括特征挖掘模块、特征计算模块和特征管理模块。</li>
</ul>
<h4><span id="23-模型算法层详解">2.3 <strong>模型算法层详解</strong></span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305061648599.jpg"></p>
<p>模型算法层是智能风控的核心，是构成智能风控建筑的主体结构。通过模型算法层实现智能化的预测评估。<strong>风控中典型的场景就是预测风险，计算发生风险的概率，再复杂的算法本质上还是可以理解为概率问题</strong>。风控场景中的模型有很多种类，这些都是根据业务场景来决定的。金融风控场景中我们构建模型计算评分来预测用户的欺诈概率、违约概率、贷中风险发生的概率、贷后催收回款的概率。<strong>在营销场景中我们构建模型来判断营销成交转化的概率、识别作弊的概率。在内容风控场景中构建模型来判定内容违规的概率。</strong></p>
<p>模型是机器学习算法构建的结果。为了构建模型我们可以选择的算法是多种多样的，新的算法也在不断产生和更新迭代。风控领域常用的算法包括基础算法如逻辑回归算法、决策树算法等。集成学习算法包括随机森林、xgboost
等。深度学习算法包括神经网络、图神经网络等等。</p>
<p>算法和场景虽然不同，但是<strong>构建模型的流程</strong>也是基本相似的。可以划分为如下<strong>几个步骤：</strong></p>
<ul>
<li>问题定义是对业务场景的问题进行明确和界定。</li>
<li>样本定义及划分是选择合适的样本定义标签，选择可用的特征范围。</li>
<li>模型架构设计是确定算法，确定模型结构。</li>
<li>数据准备与 EDA
是对样本数据进行整理探索性分析。检查样本的可靠性。</li>
<li>特征选择是从大量的被选特征当中选择效果好和覆盖率高的特征。</li>
<li>模型训练与评估是完成模型训练并评估模型效果，此过程可以循环迭代多次。</li>
<li>模型监控是在模型应用之后持续的监控，确保模型的有效性和稳定性。</li>
</ul>
<p>模型平台是支持模型管理的工具。通常模型平台包括自动建模功能模块、模型计算功能模块、模型管理功能模块。</p>
<h4><span id="24-决策应用层详解">2.4 <strong>决策应用层详解</strong></span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305061648138.jpg"></p>
<p>决策应用层是整个智能风控体系的最后环节。这一层针对业务场景，基于特征和模型结果制定决策方案，对最终的业务决策和流程产生影响。</p>
<p>策略环节通常需要设计一套决策流程，在流程中的每一个环节设置决策规则。这些规则包括直接使用特征制定的规则和基于模型制定的规则。通过规则实现业务流程的通过或者拒绝、差异化的分流等动作。在金融风控贷前场景中，通常的决策包括欺诈识别、信用风险识别以及其他一些准入拦截。对于通过的客户在进行差异化的审核操作、差异化的授信额度决策、差异化的定价政策等等。在策略制定的过程中，可以选择多种的决策算法进行支持的，包括决策树，异常点检测等等算法来支持我们制定决策规则，用最优化的算法来支持我们进行最优化决策点的选择。</p>
<p>风控策略制定中最常见的就是进行<strong>风控规则策略的制定</strong>，<strong>通常的流程如下：</strong></p>
<ul>
<li>识别业务场景中常见的风险点；</li>
<li>选择合适的分析样本；</li>
<li>基于历史数据选择算法生成规则；</li>
<li>对规则的有效性和稳定性进行评估；</li>
<li>设计规则测试的方案；</li>
<li><strong>通常进行 AB 实验来验证规则的效果</strong>；</li>
<li>对规则的有效性和稳定性进行持续监控；</li>
</ul>
<p>决策引擎是支持策略部署执行的一个工具。决策引擎通常包括规则配置、决策流的配置、审批管理等功能模块。</p>
<h3><span id="三-智能风控平台交互逻辑">三、<strong>智能风控平台交互逻辑</strong></span></h3>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305061648267.jpg"></p>
<p>企业在风控体系搭建的初期，不一定会有标准化的平台工具来支持。但是随着企业智能风控体系的这个发展和成熟，更加高效的方式还是去建立每个功能模块的平台化工具。</p>
<p>智能风控体系中几个关键平台工具之间的<strong>交互关系如上图所示：</strong></p>
<ul>
<li>数据平台主要是为特征平台提供数据的输入，同时，它也支持各类样本数据、分析数据的提取。</li>
<li>特征平台主要是为模型平台和决策引擎提供特征计算和输入。</li>
<li>模型平台主要是为决策引擎提供模型计算结果的输入。</li>
<li>决策引擎主要是基于特征平台和模型平台的结果进行决策，几个工具平台之间的相互依赖和配合，形成了智能风控全流程的一个闭环。</li>
</ul>
<h3><span id="四-发展趋势展望">四、<strong>发展趋势展望</strong></span></h3>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305061650840.png" style="zoom:50%;"></p>
<p>智能风控技术发展到今天，各种机器学习算法层出不穷。但是这些技术发展和其他新鲜事物是一样的，会从高速发展逐步进入稳定期。这个阶段新的技术不会有明显的颠覆性，更多的是在原有的基础上进行一定的改良。那么现在智能风控技术目前就处于这样一个阶段，但是在应用场景上随着智能风控技术的持续发展和应用场景的不断创新探索，智能风控会越来越深入到每一个业务场景的每一个环节。传统的通过人工完成的大部分工作都可以被智能风控技术所替代。不论是从风控识别的效率还是效果上，这类场景智能技术都比人工更好。但是另一方面，在一些特殊的复杂度较高的情况下，还是需要一些进行人工补充的，尤其是在数据量较少、新的风险模式变化不确定性又非常大的领域还是有人工发挥的余地。智能风控会占据大多数的通用场景，人工是趋于在一些细分领域或者小众的场景继续发挥价值。</p>
<p>关于智能风控体系，我在<strong>《智能风控实践指南：从模型特征到决策》</strong>的书里面也有更多的一些介绍，有兴趣的朋友可以参考。</p>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>DataFunTalk：https://zhuanlan.zhihu.com/p/606786916</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>风控反作弊</category>
      </categories>
  </entry>
  <entry>
    <title>风控反欺诈（5）【draft】京东零售-基于NLP的风控算法模型构建实践</title>
    <url>/posts/3FP6W7B/</url>
    <content><![CDATA[<h3><span id="京东零售基于nlp的风控算法模型构建实践">京东零售基于NLP的风控算法模型构建实践</span></h3>
<p><strong>导读：</strong>本团队主要负责京东零售领域的风控算法模型构建，针对京东零售风控方面，业务要求不断地更新、模型失效快、更新迭代慢以及成本高昂等情况，我们提出了自己设计研发的
NLP
预训练架构模型和<strong>用户行为预训练模型</strong>，并进行预训练模型的平台化，方便一键部署开发，快速迭代，简单易用，推理速度提升等，有效解决了业务问题，并在公开数据集上也得到了很好的效果。</p>
<h3><span id="一-背景介绍">一、背景介绍</span></h3>
<figure>
<img src="image-20230401170044956.png" alt="image-20230401170044956">
<figcaption aria-hidden="true">image-20230401170044956</figcaption>
</figure>
<p>如上图所示，京东零售风控的任务是维护京东零售平台健康的交易生态环境，主要包括主站
APP、PC 端等。场景包括 C 端和 B 端两大部分。</p>
<p><strong>C
端风控主要针对恶意刷券，使用外挂软件获取权益，比如用一些黑客软件抢茅台等，还有一些广告辱骂的内容，比如发小广告、不合规的内容等，以及价格方面的管控等</strong>。B
端风控主要是针对商家刷单行为、恶意套利行为，以及客服防骚扰。</p>
<figure>
<img src="image-20230401170213571.png" alt="image-20230401170213571">
<figcaption aria-hidden="true">image-20230401170213571</figcaption>
</figure>
<p><strong>如上图所示，零售风控算法能力整体上分为用户行为和文本两大部分。</strong>用户行为这一块，通过上面提到的场景，算法人员可以将这些场景的数据构建成统计特征、序列行为特征，比如浏览页面等。文本这一块，主要是内容风控，包含舆情，地址异常等场景识别作为基础，以
NLP 的文本特征作为识别的基础。风控领域相对于其他领域的 NLP
场景，其主要的特点是异音异形字的识别，比如加微信，如上图中所示，通过一些异形字体，+薇信，躲避文本的风控检测。</p>
<p><strong>以上两大场景，存在以下几个问题：</strong></p>
<ul>
<li>第一，失效快，比如广告引流场景，模型很快就会有效果衰减，具体原因就是恶意攻击者，会反复尝试不同的字体和形式，用以破解算法模型，从而达到自己的目的，导致模型失效或者效果下降。</li>
<li>第二，针对新的业务场景，需要大量的人工标注数据，人工标注的成本会非常高，而且耗时比较长。</li>
<li>第三，建模的效率低，效果差，因为首先要做特征，特征完之后，再预训练模型，整个链条拉得非常长，等到模型做好之后，业务方可能不需要这个模型了，或是效果不能达到预期，有的模型效果要求准确率达到接近
100%。</li>
</ul>
<p>针对这三个问题，我们做了一些思考研究。针对失效快的问题，是否可以建立一个长期有效的机制来解决；针对需要人工标注大量数据这个问题，是否可以建立一个小样本学习能力的模型，不需要标注那么多的标签数据，使用无监督的方式进行训练；针对建模效率低、效果差等，是否可建立一个特征，模型平台化自动生成的机制，使预训练模型和大模型更好地发挥作用，快速建模和生成模型。</p>
<p>基于以上思考，我们依赖于预训练技术，做了一些改进优化。</p>
<h3><span id="二-nlp-预训练"><strong>二、NLP 预训练</strong></span></h3>
<figure>
<img src="image-20230401170745015.png" alt="image-20230401170745015">
<figcaption aria-hidden="true">image-20230401170745015</figcaption>
</figure>
<p>如上图所示，NLP
是风控内容、舆情、地址等风控能力的基础，而且，近年来，<strong>预训练技术是处理
NLP
的最常用的方式。整体的流程如上图所示：首先数据采集，然后进行模型预训练，最后对模型进行微调。</strong></p>
<figure>
<img src="image-20230401170908842.png" alt="image-20230401170908842">
<figcaption aria-hidden="true">image-20230401170908842</figcaption>
</figure>
<h4><span id="三-用户行为预训练">三、<strong>用户行为预训练</strong></span></h4>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>https://zhuanlan.zhihu.com/p/600326545</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>风控反作弊</category>
      </categories>
  </entry>
  <entry>
    <title>风控反欺诈（6）【draft】小红书社区反作弊探索与实践</title>
    <url>/posts/13HY6RS/</url>
    <content><![CDATA[<h3><span id="小红书社区反作弊探索与实践">小红书社区反作弊探索与实践</span></h3>
<h3><span id="一-社区反作弊的意义">一、<strong>社区反作弊的意义</strong></span></h3>
<p>面对已知风险和产业链，下面来讨论下整个作弊防控的策略。所谓策略须先明确作弊防控的目标，以及达到目标的关键路径。</p>
<p><strong>首先明确对于反作弊的预期</strong>。反作弊的本质是与作弊者成本的对抗，任何反作弊系统都无法做到
100%
的准确和召回。前面提到，无论何种形式作弊，它都是以牟利为目的的，而利益的来源是作弊成本和收益之间的价值差异。反作弊的工作就是提高作弊成本，尽量压缩作弊利益空间，降低作弊者的动机。因此，合理的目标设定是降低作弊行为在正常行为中的占比，控制风险的浓度。</p>
<p><strong>关键路径是化被动识别为主动防御，如果长期作为被动方，可能没办法有全盘宏观的概念。</strong>要做到主动防御，一是构建风险的<strong>感知能力</strong>，尽早发现风险并且快速反应迭代；二是控制黑产的<strong>核心资源（账号，设备）</strong>，树立高门槛设置准入壁垒，并将有问题的账号进行存量清理。收缩作弊者能使用的账号量和设备量，相应的新账号成本也会变高，这就控制了核心资源。</p>
<figure>
<img src="image-20230401173214898.png" alt="image-20230401173214898">
<figcaption aria-hidden="true">image-20230401173214898</figcaption>
</figure>
<p>下面对作弊防控思路做进一步的拆解，也是一个比较通用的方法论，个人认为可以应用到各类风险控制场景里。<strong>首先业务风控最大的难点是对抗，无论作弊变成何种形式，唯一不变的就是对抗，它是一直存在的。</strong>围绕对抗抽象出几个模块：<strong>风险感知、能力建设、风险识别、风险处置、效果评估</strong>。在遇到新的对抗时，这几个环节间会进行不断的循环迭代。下面以小红书社区反作弊为例，具体介绍这几个模块的设置。</p>
<ul>
<li>风险感知层负责更快发现风险，化被动救火为主动防御。具体分为情报运营，黑产卧底和红蓝军对抗，帮助风险识别更早的发现问题，可以说情报是整个风险防控体系的眼睛，解决“看得见”的问题。</li>
<li><strong>能力建设是面向对抗的快速响应能力</strong>。这部分涉及的模块，一是端+云联防，在合法合规前提下通过端获取设备信息，并进一步加工为可用特征，供云防策略和算法使用。二是可以快速接入且可灵活配置的风控系统，以实现策略规则的快速迭代。三是为更快的实现从零到一的落地风控场景，搭建可跨场景协同使⽤的风险画像平台，在新风险场景里快速迁移和使用数据基建能力。</li>
<li><strong>风险识别模块，面向对抗需提高识别的准召</strong>。从几个角度拓展能力，首先扩充数据，结合<strong>设备特征、账号特征、行为特征，以及其他场景下识别的风险画像，做联合使用分析</strong>。其次，从挖掘的角度，利用官方平台和作弊者之间的信息不对称性，寻找作弊用户相较于正常用户的异常点：
<ul>
<li>尝试由点到线，从分析单个行为变成分析一串行为即行为序列挖掘；</li>
<li><strong>从单点到面， 通过账号、IP
或设备等节点之间的拓扑关系进行团伙挖掘，可以带来很大的增益</strong>。</li>
</ul></li>
<li><strong>风险处置方面需要选择更有效的方式提高绕过成本</strong>。主要分为两个层面，一是<strong>处置对象</strong>，二是<strong>处置手段</strong>。在每个场景下该怎么处置，并没有一个标准答案，建议结合具体业务和业务中的风险来判断，了解风险背后的动机，在考虑应该采取怎样的处置手段才能提高绕过成本。</li>
<li>效果评估可以评估风险水位，一般来说常用的指标有<strong>作弊漏过量、漏过率、作弊服务价格、账号价格</strong>等。</li>
</ul>
<p>小红书的风控体系，分为业务数据接入层，数据加工层，分析决策层，数据采集能力沉淀及运营和评估模块。</p>
<ul>
<li><strong>业务数据层</strong>，覆盖用户全场景的行为风控。从设备激活-&gt;账号注册-&gt;内容浏览
-&gt;交互-&gt;内容发布，从多场景层面实现联防联控。对于明确的作弊用户，直接拒绝访问从而加强准入的防御壁垒;
对于疑似异常用户或高难度作弊注册，建议做延迟处理或在后续关键环节上做拦截处置，可以达到增加绕过成本的目的：具体来说，如果在注册时直接拦截，作弊者可快速验证拦截原因；延迟拦截后作弊者定位识别方法的难度变大，找到绕过方法的成本也更高。</li>
<li><strong>数据接入层</strong>，风控引擎支持实时请求接入，也支持准实时流式接入和离线数据接入。</li>
<li><strong>数据加工层</strong>重点针对身份特征，网络环境，设备信息、行为数据、时序特征，累计因子等去做加工和挖掘，并输入至决策分析层。</li>
<li><strong>决策分析层</strong>由策略引擎、模型引擎和数据引擎组成。其中策略引擎完成实时的规则产出和返回，支持灵活的策略配置和策略上下线。模型引擎，对于简单模型，可以做到线上
Serving；对于复杂模型或需要分析的模型，需通过近线或离线实现。</li>
<li><strong>数据采集的能力沉淀层</strong>，包含设备指纹采集、名单系统、风险画像、关系图计算和风险事件模块。一方面，作为分析决策层的数据源做输入。另一方面，实现识别能力的迁移、使用等等。决策分析层也会向能力沉淀层做输出，
将新识别风险点落到能力沉淀里复用至其他风险场景。</li>
</ul>
<p><strong>我们有一些不同的治理方案：</strong></p>
<p><strong>一、对于影响的治理方案是清理这部分作弊的行为所得</strong>。但是，仅清理虚假流量，唯一的损失就是买量付出的钱。但对于买量者，还可以尝试其他作弊服务。因为作弊买量价位不会非常高，不断尝试的可能性就很强。关键点在于尝试作弊是没有边际成本的，比如某人偷东西后只是要求把偷窃所得还回去，而不会把他抓起来，只要不被发现就赚了。</p>
<p><strong>二、对于实现链路，针对刷量作弊的账号做治理</strong>。比如识别到一个用于刷量的机器账号，平台将该账号封禁。从账号的成本上考虑，提供刷量服务者手上的账号量会变的越来越少，做账号成本就会变高，刷量的服务价格就会上涨，刷量者尝试新手法时成本也会变高。</p>
<p><strong>三、从作弊动机角度考虑，按作弊程度作流量分发降权或商业权益限制。</strong>对买作弊流量的笔记做流量分发限制，作弊后可以获得的流量比不作弊更少。其次是限制买作弊流量博主的商业权益，因为很多买量者想通过商业化实现流量变现，对商业权益限制使齐无法做商业合作，对作弊者来说是很大的损失。该模块治理效果，可以大大降低买量者的作弊意愿。</p>
<p>从实践来说，从治理【风险影响】转变为治理【实现链路】与【作弊动机】，作弊意愿降低，作弊量级下降显著。</p>
<h4><span id="数据刷量反作弊实践风险识别"><strong>数据刷量反作弊实践——风险识别</strong></span></h4>
<figure>
<img src="image-20230401202502284.png" alt="image-20230401202502284">
<figcaption aria-hidden="true">image-20230401202502284</figcaption>
</figure>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li>https://zhuanlan.zhihu.com/p/599625620</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>风控反作弊</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-AVClass2-自动恶意软件标记工具</title>
    <url>/posts/3931MT5/</url>
    <content><![CDATA[<h1><span id="如何利用多杀软结果提取恶意软件标签">如何利用多杀软结果提取恶意软件标签</span></h1>
<ul>
<li>secrss.com/articles/33242</li>
<li><strong>通过多杀软结果挖掘得到更多关于样本的上下文信息是一个经久不衰的研究点</strong></li>
</ul>
<p><strong>从杀软标签中自动提取标签是对大量样本进行分类和索引的有效方法</strong>。此前的
AVClass 和 Euphony
等工作已经能够从杀软标签中提取家族名称。而杀软标签包含有价值的信息不止是家族，还有类别（例如勒索软件、下载器、广告软件）和行为（例如垃圾邮件、DDoS、信息窃取）等。</p>
<p><strong>恶意软件属性枚举和表征（MAEC）等标准定义了一种用于共享恶意软件分析结果的语言</strong>。然而，由于使用严格的受控词汇表（即预定义标签），这些词汇表可能并不总是符合分析师的需求，需要频繁更新，并且必然是不完整的，因此它们的采用率很低，例如，MAEC
中就不包括<strong>恶意软件家族</strong>。</p>
<p>杀软引擎有一些通用标签，标明恶意软件的类别、家族、文件属性和动态行为。也有一个通用标签（malicious,
application）和特定杀软引擎（deepscan,
cloud）才有的，或者是恶意软件家族变种（aghr, bcx）标签。</p>
<h3><span id="工作设计">工作设计</span></h3>
<p><strong>AVClass2 的目标是分辨提供有用信息的 Token，识别不同杀软引擎
Token 之间的关系，最后转换成分类法的标签。</strong></p>
<p>AVClass2
是一个自动恶意软件标记工具，可为样本提取一组干净的标签。AVClass2
附带一个默认的开放分类法，可将杀软标签的名词分类到不同的类别，捕获标签之间关系的默认标记规则和扩展规则。AVClass2
有一个更新模块，使用标签共现来识别标签之间的关系，以在杀软厂商引入新标签时保持工具更新。</p>
<p>AVCalss2 基于 AVClass 进行了最少必要更改，继承了 AVClass
的主要特点：可扩展性好、杀软引擎独立性好、平台无关性好、不需要样本文件、开源。</p>
<p>基本架构如下所示：</p>
<figure>
<img src="https://s.secrss.com/anquanneican/13c4e4d7d81462e10c618bee59fbf971.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>主要是两大模块：Labeling 模块和 Update 模块。</strong></p>
<ul>
<li>Labeling
模块将<strong>多个杀软的标签结果作为输入</strong>，同时可以提供使用的杀软引擎列表，如果不提供默认使用所有杀软引擎的标签结果。给出一组<strong>标记规则</strong>、一个<strong>可选扩展规则</strong>以及可将标签<strong>分类合并</strong>的分类法。</li>
<li>Update
模块将<strong>共现统计、标记规则、扩展规则和分类法作为输入</strong>。识别标签之间的<strong>强关联</strong>，生成新的标记规则、扩展规则和分类法。</li>
</ul>
<h3><span id="标签">标签</span></h3>
<p><strong>Labeling
模块分为三部分：标记化（Tokenization）、标记（Tagging）、扩展（Expansion）。</strong></p>
<ul>
<li><strong>标记化（Tokenization）将每个杀软标签拆分为一个 Token
列表</strong>。标记化是与厂商无关的，VirusTotal
现在已经支持超过一百个引擎。每个厂商的格式也不完全一致，经常修改。如果尝试为引擎的标签定义格式或者自动推断格式，可能会得到数百个格式模板。不仅选择正确格式进行解析很困难，遇到未知格式的标签还可能出现错误。</li>
<li><strong>标记（Tagging）会用分类法中的一组 Tag 替换杀软标签中的
Token，即将杀软标签中的 Token 转换为分类法中概念明确的
Tag</strong>。大多数标记规则会映射到单个标记，例如 downldr、dloader
会被映射到 downloader 上；finloski 和 fynloski 会被映射到 darkkomet
上。也存在一对多的关系，比如 ircbot 会映射到 irc 和 bot。</li>
<li><strong>扩展（Expansion）用于处理未知的
Token，使用扩展规则定义一个标签隐含一组其他标签</strong>。例如有 95%
的标签在带有 virut 的同时也带有 virus，virut 就会是 virus
的扩展规则。扩展规则一共分为两类，一类是类内规则一类是类间规则，处理顺序是先类间规则再类内规则。类内规则由分类法中统一类别的父子关系隐式定义，例如
adware 是 grayware
的子类。类间规则由分类法中不同类别的隐式关系定义，例如 filemodify
行为归属于 virus 类。</li>
</ul>
<p><strong>整体流程如下所示：</strong></p>
<figure>
<img src="https://s.secrss.com/anquanneican/018d45d7ed61a0cca153cfd53d145ade.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="分类法">分类法</span></h3>
<blockquote>
<p><strong>行为、类型、文件属性和家族</strong></p>
</blockquote>
<p>分类法定义了标记规则使用的标签之间的父子关系。AVClass2
的分类法被构造为树型结构，默认包含四个类型（<strong>行为 BEH、类型
CLASS、文件属性 FILE、家族 FAM</strong>）。</p>
<figure>
<img src="https://s.secrss.com/anquanneican/070902d5885e1c46d17142d43813a9fe.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>标签是自上而下进行描述的，例如 CLASS:grayware:adware。</p>
<p><strong>自带的默认分类法如下所示：</strong></p>
<figure>
<img src="https://s.secrss.com/anquanneican/45bbf65333720324166aeab69f49ece1.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li><strong>行为</strong>：例如
infosteal（信息窃取）、sendssms（发送短信）、spam（垃圾邮件）、mining（挖矿）等</li>
<li><strong>类别</strong>：例如
worm（蠕虫）、virus（病毒）、ransomware（勒索）、downloader（下载）。Trojan
问题很大，原来特指某类，后来变成了默认类型，故而认为 Trojan 为通用
Token。</li>
<li><strong>文件属性</strong>：例如<strong>文件类型</strong>（例如
pdf、flash、msword）、<strong>操作系统</strong>（android、linux、windows）、<strong>壳类型</strong>（pecompact、themida、vmprotect）、<strong>编程语言</strong>（autoit、delphi、java）</li>
<li><strong>家族</strong>：默认分类家族不包括父子关系</li>
</ul>
<h3><span id="update">Update</span></h3>
<p>为了新的家族、新的行为都能够通过 AVClass2
自动更新，需要根据共现关系识别数据集中的强关系，迭代更新到规则中。基于
VAMO 引用的杀软标签共现关系，在 AVClass 和 Euphony
中也用于合并家族。（Roberto Perdisci and U. ManChon. 2012. VAMO: Towards
a Fully Automated Malware Clustering Validity Analysis. In Annual
Computer Security Applications
Conference.）。共现的判断需要确定阈值，以AVClass的经验选择 𝑛 = 20 和 𝑇 =
0.94。</p>
<figure>
<img src="https://s.secrss.com/anquanneican/9d67ba609a2c45feb86dcd605dd5c06f.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="工作准备">工作准备</span></h3>
<p>使用 11 个数据集进行评估，数据集之间存在重复（例如 Drebin 是
MalGenome 的超集）但并未去重，为了便于单独映射结果。</p>
<figure>
<img src="https://s.secrss.com/anquanneican/18030348ab876b5fed8137aa52b61655.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="工作评估">工作评估</span></h3>
<p>通过在 4200 万恶意样本中评估 AVClass2，并且与 AVClass 和 Euphony
进行了比较，测试其效果。</p>
<h3><span id="标记覆盖">标记覆盖</span></h3>
<p>标签覆盖率如下所示：</p>
<figure>
<img src="https://s.secrss.com/anquanneican/0060066c74a362e126f439c6efc4b669.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li><p>选择至少四个杀软引擎标记为恶意的样本，最近的研究表明 2-14
个杀软引擎判定的筛选范围有利于平衡精度和召回率。</p>
<blockquote>
<p>Shuofei Zhu, Jianjun Shi, Limin Yang, Boqin Qin, Ziyi Zhang, Linhai
Song, and Gang Wang. 2020. <strong>Measuring and Modeling the Label
Dynamics of Online Anti-Malware Engines</strong></p>
</blockquote></li>
<li><p>AVClass2 可以为 89%
以上的样本提取至少一个标签，无法提取的基本都是检测结果较少的文件</p></li>
<li><p>测试时可识别的 975 个标签已经超过了 VirusTotal 的 335
个标签，VirusTotal 的标签基本都对应于文件属性和样本行为。其中，与
VirusTotal 重合的共有 259 个标签</p></li>
</ul>
<p>每个类别 TOP10 的标签如下所示：</p>
<figure>
<img src="https://s.secrss.com/anquanneican/9a1f118fb14f2944de07888d2beb9a08.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>超过 10% 的样本对应了四个类别的标签。例如
CLASS:grayware:adware:multiplug
是通过浏览器插件进行广告推广的软件。</li>
<li>Trojan 如果不是通用Token被剔除的话，会被分配给 86% 的样本。</li>
<li>最多的家族是 vobfus，占到了总数的十分一。</li>
<li>除了恶意软件外，grayware
也是常见家族的大赢家（loadmoney、softpulse、installererex、domaiq、firseria）。</li>
</ul>
<h3><span id="知识更新">知识更新</span></h3>
<p>使用 Andropup 数据集举例说明 update 模块的用法。首次测试观察到 65%
的样本包含一个未知标签，执行 update 模块后会下降到 16%。</p>
<figure>
<img src="https://s.secrss.com/anquanneican/78fad75a47f80238fc0ca5a40ea263b4.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>共现关系共计 30107 个，有归属于 11 类的 968 个强关联。96%
的强关联涉及未知 Token，从中自动识别出了 486 个新类别实体、216
个新标记规则、461 个扩展规则。处理完成后只剩下 3
个强关联不能自动更新，需要手动处理。</p>
<p>手动检查了更新的内容，1163 个更新中只有 11 个（0.9%）是需要调整的、3
个是需要手动检查的。</p>
<h4><span id="执行速度">执行速度</span></h4>
<figure>
<img src="https://s.secrss.com/anquanneican/3cee7fc69bc91ff6f01b24c764ed46ef.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>AVClass2 和 AVClass* 在四个数据集中获得了最好的 F1 成绩，而 AVClass
在 Malheur 上排名第一。</li>
<li>AVClass 最快，AVClass2 其次，Euphony 则比 AVClass 慢 7 到 34
倍。对特大的数据集 Euphony 会很慢或者因内存不足而崩溃。</li>
</ul>
<h2><span id="工作思考">工作思考</span></h2>
<p>AVClass2 对通过多杀软结果处理实现提取 VirusTotal 类的 Tag
标签很有帮助，实际上没有必要合并成一个完整的分类法的语法树结构。<strong>通过多杀软结果挖掘得到更多关于样本的上下文信息是一个经久不衰的研究点</strong>，本文作者也在
AVClass 的基础上再进一步做出了 AVClass2，<strong>==两个工作分别发表在
RAID 2016 与 ACSAC 2020 都是很不错的成绩。==</strong></p>
<p>像 AVClass++ 指出的那样，AVClass
在杀软引擎结果较少时效果较差，那些新提交到 VirusTotal
的样本会因此效果较差。另外就是杀软结果中也存在随机生成类的结果，这两点实际上都可能是未来在这条路上的研究进展，AVClass++
的解决方法是否很优则见仁见智，但仍不失为一个极佳的参考。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>风控反欺诈（3）Fraudar：二部图反欺诈</title>
    <url>/posts/VSDR5Z/</url>
    <content><![CDATA[<h2><span id="fraudar二部图反欺诈">Fraudar：二部图反欺诈</span></h2>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/172423556">Fraudar：二部图反欺诈</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/369534469">图异常簇检测：<em>FRAUDAR</em></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/528366101">京东图计算团队：一文读懂电商广告作弊与反作弊</a></p>
<p><strong>图异常检测系列文章：</strong></p>
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/348278101">图异常点检测：OddBall</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/348713075">图异常簇检测：LOCKINFER</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/369534469">图异常簇检测：FRAUDAR</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/380421374">图异常检测：GDN和Meta-GDN</a></li>
</ol>
</blockquote>
<p>可以说电商的发展，滋生并带火了一个由出资店铺、刷单中介、各级代理、刷手、空包物流组成的刷单产业。</p>
<h3><span id="一-黑产与反欺诈">一、黑产与反欺诈</span></h3>
<h4><span id="关系网络与二部图"><strong>关系网络与二部图</strong></span></h4>
<p><strong>不同于对个体自身特征的分析，网络提供了对多个对象的关系之间另一种看问题的视角</strong>。把对象看做结点，把交互看成边，对象间的发生的各种关联自然会构成一张关系网络。<strong>从图论的角度出发，根据结点属性的不同可以把网络分为同构图和异构图</strong>。同构图是由同一种结点组成的关系网络，如家庭亲属关系、社交好友关系、论文间的引用关系等。历史上对于同构图的网络表示有很多研究，早在十九世纪就形成了几何拓扑学这一数学分支。在现代的同构关系研究中也逐步提出了基于网页链接的谷歌PageRank网页评级、基于结点关系紧密度的Louvian社区发现等重要算法。<strong>不过异构图在生活中的表现更为广泛，异构图是由不同属性的结点组成的关系网络，如由买方卖方以及中介组成的交易网络、由大V和其关注者组成的关注网络、由手机号。</strong>二部图（也叫二分图）是异构网络的一种，它由两类结点组成，并且同类结点之间通常没有关联。前述的刷单欺诈，即是以<strong>出资店铺</strong>和<strong>刷手</strong>这两类结点组成的<strong>交易关系二部图</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191534576.jpg" alt="img" style="zoom: 67%;"></p>
<h4><span id="二部图下的欺诈"><strong>二部图下的欺诈</strong></span></h4>
<p>两类结点组成的欺诈场景还可以举出很多例子，如电商场景下<strong>用户对商户的薅羊毛、刷好评</strong>，如<strong>社交场景下水军账号的虚假关注、转发</strong>，又如<strong>消金场景下用户与商户勾结对平台的消费贷套现欺诈</strong>。<strong><font color="red">
这些行为都会使两类结点之间出现异常的连接分布，从整体网络看来其呈现出了一张致密的双边连接子图，且该子图内的结点与图外结点联系相对较少</font></strong>。我们把这种大量的、同步的非正常关联行为模式称之为Lockstep，即在本不应出现聚集行为的二部图自然关系网络中，出现了双边聚集性行为。</p>
<p>只要能把欺诈行为总结成一种模式，自然可以将其分离出来。但是欺诈者往往会对自己做出某种伪装以使自己看起来有向好的一面，意图绕过风控系统。如在刷单欺诈场景下，<strong>为了尽量贴近真实用户的购买习惯，刷单平台会对刷手提出一系列要求</strong>，比如要求货比三家、要求最低浏览时长、要求滚动浏览高度及停留时间、要求对于正常热销商品做一定购买等，这些行为都会导致风控经验指标和模型特征的部分失效。在二部图交易网络中，对于正常热销商品的购买体现为刷手为自己增加了一些优异的边连接，使自己看起来更像一个正常的消费者结点。<strong><font color="red">
我们需要一种能从这种复杂关系网络中对抗伪装、抽丝剥茧的提取出异常致密子图的算法。</font></strong>接下来对症下药引入Fraudar。<strong>Fraudar算法来源于2016年的KDD会议，并获得了当年的最佳论文奖。</strong></p>
<h3><span id="二-fraudar算法介绍-无监督异常簇检测">二、<strong>Fraudar算法介绍</strong>-
无监督异常簇检测</span></h3>
<blockquote>
<p><a href="https://link.zhihu.com/?target=https%3A//dl.acm.org/doi/pdf/10.1145/2939672.2939747">FRAUDAR:
Bounding Graph Fraud in the Face of
Camouflagedl.acm.org/doi/pdf/10.1145/2939672.2939747</a></p>
</blockquote>
<p><strong>简单来说，Fraudar定义了一个可以表达结点平均可疑度的全局度量G(·)</strong>，在逐步贪心移除可疑度最小结点的迭代过程中，使G(·)达到最大的留存结点组成了可疑度最高的致密子图。接下来我们稍微细化一下算法过程，以刷单交易场景为例（定义二部图结点集合S=[A,B]，其中A、B分别代表消费者和店铺的结点集合），看Fraudar是如何从交易网络剥离出刷手和其出资店铺的。</p>
<p>网络水军、刷量刷单等行为在互联网中屡见不鲜，如何检测网络中的该类行为，即<strong>异常簇，</strong>是值得研究的问题。<strong>本文介绍一种图异常簇检测方案-FRAUDAR，该方法在具有14.7亿条边的Twitter社交网络中成功检测出了一系列刷量账户。</strong></p>
<h4><span id="21-论文贡献"><strong>2.1 论文贡献</strong></span></h4>
<ol type="1">
<li>提出了一组满足公理的指标，且兼具多种优点。</li>
<li>提出了一个可证明的界限，即某个欺诈账户可以在图中有多少欺诈行为而不被抓获，即使是在伪装的情况下。接着通过新的优化改进了该界限，使其能够更好地区分真实数据中的欺诈行为和正常行为。</li>
<li>该算法在超大规模的Twitter网络中被证明了是有效的且能够在<strong>接近线性时间复杂度</strong>内完成任务。</li>
</ol>
<h4><span id="22-欺诈行为的特点">2.2 欺诈行为的特点</span></h4>
<p>网络中存在不少水军刷量刷单的现象，该类欺诈行为在社交网络中尤其显著，其中"刷量者"可称为<strong>follower</strong>，"刷单目标"可以称为<strong>followee。</strong>下图展示了Twitter中的“僵尸粉”购买服务案例：左图红色和蓝色颜色的柱子分别代表了正常用户和欺诈用户，用户所属的两个柱子中左柱子表示followee的数量，右柱子表示follower的数量；右图展示了某个刷量账号，其个人简介中表示“只要你follow他那么他就会follow你”。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191534862.jpg" alt="img" style="zoom:50%;"></p>
<p>欺诈行为在网络的<a href="https://www.zhihu.com/search?q=邻接矩阵&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22369534469%22%7D">邻接矩阵</a>视角下具有显著特征，某些“聪明”的刷量分子为了逃避检测往往会采取伪装（camouflage）来让自己看起来更像普通用户。下图从左到右分别展示了邻接矩阵中的随机伪装者、偏置伪装者和被劫持账户参与刷量行为。</p>
<h4><span id="23-fraudar算法">2.3 FRAUDAR算法</span></h4>
<p>FRAUDAR算法基于二部图表示，即网络中存在两种类型的节点Users和Objects。文中假设可能存在一个或多个User受到相关某个实体的控制，进而与Objects的某个子集交互而产生连边。算法所需的符号表示如下：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191535249.jpg" alt="img" style="zoom:50%;"></p>
<p>算法的目标是找到一个 <span class="math inline">\(S\)</span>, 并使得
<span class="math inline">\(S\)</span> 构成子图的嫌疑指标 <span class="math inline">\(g(S)\)</span> 最大。</p>
<p>子图内节点嫌疑度，即密集度指标 (density metrics) 可描述为： <span class="math inline">\(g(S)=\frac{f(S)}{|S|}\)</span></p>
<p>子图总嫌疑度 (total suspiciousness) 可描述为: <span class="math display">\[
\begin{aligned} f(S) &amp; =f_\nu(S)+f_{\varepsilon}(S) \\ &amp;
=\sum_{i \in S} a_i+\sum_{i, j \in S \wedge(i, j) \in \varepsilon} c_{i
j}\end{aligned}
\]</span> 其中, <span class="math inline">\(a_i\)</span> 和 <span class="math inline">\(c_{i j}\)</span> 都是大于 0 的常数, <span class="math inline">\(a_i\)</span> 即某个节点 <span class="math inline">\(i\)</span> 的嫌疑度, 而 <span class="math inline">\(c_{i j}=\frac{1}{\log \left(d_j+c\right)}\)</span>
可即边 <span class="math inline">\((i, j)\)</span> 的嫌疑度, <span class="math inline">\(d_j\)</span> 表示Object <span class="math inline">\(j\)</span> 的度, <span class="math inline">\(c\)</span> 是一个较小的常量。</p>
<p><strong>由此，FRAUDAR算法可描述为如下过程</strong>：</p>
<ol type="1">
<li>将优先级最高的节点移出二部图</li>
<li>更新与移出节点相关的节点可疑度</li>
<li>反复执行步骤1和步骤2，直至所有节点都被移出</li>
<li>最后比较各轮迭代中节点的可疑度，找到最大可疑度对应的子图</li>
</ol>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191535525.jpg" alt="img" style="zoom:50%;"></p>
<p>算法中有如下两点值得注意：</p>
<p><strong>1. 如何构造<a href="https://www.zhihu.com/search?q=优先树&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22369534469%22%7D">优先树</a></strong></p>
<p>优先树本质上是一个小顶堆，其叶子节点为二部图中的Users或Objects，排序规则依赖于节点的嫌疑度。由此，根结点将记录全局嫌疑度最小的节点，将根节点从二部图中移出使得新子图中的节点具有最大的平均嫌疑度。</p>
<p><strong>2. 如何更新可疑度</strong></p>
<p>删除网络中的节点导致<a href="https://www.zhihu.com/search?q=二部图&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22369534469%22%7D">二部图</a>结构被改变，因此每轮迭代后都需要在保持边可疑度不变的前提下，更新与被删除节点相关的节点可疑度，即相关节点减去被删节点的嫌疑度。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>风控反作弊</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-kaspersky《Machine Learning for Malware Detection》解析</title>
    <url>/posts/3JVWT1D/</url>
    <content><![CDATA[<h2><span id="machine-learning-formalware-detection">Machine Learning for
Malware Detection</span></h2>
<blockquote>
<p>本文总结了 kaspersky 利用机器学习为客户建立高级保护的丰富经验。</p>
</blockquote>
<h3><span id="一-基本方法检测恶意软件">一、基本方法检测恶意软件</span></h3>
<p>一个高效、健壮、可扩展的恶意软件识别模块是每个网络安全产品的关键组成部分。恶意软件识别模块会根据其在该对象上所收集的数据来决定该对象是否构成威胁。这些数据可以在不同的阶段进行收集：</p>
<ul>
<li><p><strong>需要有代表性的大型数据集</strong></p>
<blockquote>
<p>必须强调这种方法的数据驱动特性。一个创建的模型在很大程度上依赖于它在训练阶段看到的数据，以确定哪些特征与预测正确的标签有统计关联。让我们来看看为什么制作一个具有代表性的数据集如此重要。</p>
</blockquote></li>
<li><p><strong>训练的模型必须是可解释的</strong></p>
<blockquote>
<p>目前使用的大多数模型家族，如深度神经网络，都被称为黑盒模型。黑盒子模型被给予输入X，它们将通过一个难以被人类解释的复杂操作序列产生Y。这可能会在现实生活中的应用程序中带来一个问题。例如，当出现错误警报时，我们想理解为什么会发生它，我们会问这是训练集还是模型本身的问题。模型的可解释性决定了我们管理它、评估其质量和纠正其操作的容易程度。</p>
</blockquote></li>
<li><p><strong><font color="red"> 假阳性率必须非常低</font></strong></p>
<blockquote>
<p><strong>当算法将良性文件错误地标记恶意标签时，就会发生误报。我们的目标是使假阳性率尽可能低，或为零</strong>。这在机器学习应用程序中并不常见。这是很重要的，因为即使在一百万个良性文件中出现一个误报，也会给用户带来严重的后果。这是复杂的事实，有许多干净的文件在世界上，他们不断出现。</p>
<p>为了解决这个问题，重要的是要对机器学习模型和指标施加高要求，并在<strong>训练期间进行优化，并明确关注低假阳性率(FPR)【FP/(FP+TN)】模型</strong>。</p>
<p>这还不够，因为之前看不见的新良性文件可能会被错误检测到。我们考虑到这一点，并实现了一个<strong>灵活的模型设计，允许我们动态地修复假阳性，而不需要完全重新训练模型</strong>。这些示例在我们的执行前和执行后的模型中实现，这将在以下章节中描述。</p>
</blockquote></li>
<li><p><strong><font color="red">
算法必须允许我们快速调整它们以适应恶意软件作者的反击</font></strong></p>
<blockquote>
<p>在恶意软件检测领域之外，机器学习算法经常在<strong>固定数据分布的假设下工作，这意味着它不随时间变化</strong>。当我们有一个足够大的训练集时，我们可以训练模型，以便它将有效地推理测试集中的任何新样本。随着时间的推移，该模型将继续按预期进行工作。</p>
<p>在将机器学习应用于恶意软件检测后，我们必须面对我们的数据分布没有固定的事实：</p>
<ul>
<li>活跃的对手（恶意软件编写者）不断努力避免检测和发布新版本的恶意软件文件，这与在培训阶段看到的文件有显著不同。</li>
<li>成千上万的软件公司生产的新型良性可执行文件与以前已知的可执行文件显著不同。在训练集中缺乏关于这些类型的数据，但该模型需要识别出它们是良性的。</li>
</ul>
<p>这就导致了数据分布的严重变化，并提出了在任何机器学习实现中检测率随着时间的推移而下降的问题。在其反恶意软件解决方案中实现机器学习的网络安全供应商面临着这个问题，并需要克服它。<strong>该体系结构需要灵活，并且必须允许在再训练（retrain）之间“动态”更新模型</strong>。供应商还必须有<strong>有效的流程来收集和标记新样本，丰富训练数据集和定期的再训练模型。</strong></p>
</blockquote></li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181501281.png" alt="image-20220429233456832" style="zoom:50%;"></p>
<h3><span id="二-卡巴斯基实验室机器学习应用">二、卡巴斯基实验室机器学习应用</span></h3>
<blockquote>
<p>上述真实世界恶意软件检测的特性使机器学习技术的直接应用成为一项具有挑战性的任务。<strong>在将机器学习方法应用于信息安全应用方面，卡巴斯基实验室拥有近十年的经验</strong>。</p>
</blockquote>
<blockquote>
<p>在执行前检测新的恶意软件的<strong>相似性哈希</strong></p>
</blockquote>
<p>在杀毒行业的初期，计算机上的恶意软件检测是<strong>基于启发式特征</strong>，识别特定的恶意软件文件:</p>
<ul>
<li>代码段</li>
<li>代码片段或整个文件的哈希值</li>
<li>文件属性</li>
<li>以及这些特征的组合</li>
</ul>
<p>我们的主要目标是创建一个可靠的恶意文件指纹——一个功能的组合，可以快速检查。在此之前，这个工作流需要通过仔细选择指示恶意软件的代表性字节序列或其他特征来手动创建检测规则。在检测过程中，产品中的抗病毒引擎针对存储在防病毒数据库中的已知恶意软件指纹，检查文件中是否存在恶意软件指纹。</p>
<p>然而，恶意软件编写者发明了像服务器端多态性这样的技术。这导致每天都有成千十万的恶意样本被发现。同时，所使用的指纹对文件中的微小变化也很敏感。现有恶意软件的微小变化使它失去了雷达注意。前一种方法很快就变得无效了，因为：</p>
<ul>
<li>手动创建检测规则无法跟上新出现的恶意软件流。</li>
<li>针对已知恶意软件库检查每个文件的指纹意味着，在分析人员手动创建检测规则之前，您才能检测到新的恶意软件。</li>
</ul>
<p>我们感兴趣的是那些对文件中的小变化具有<strong>鲁棒性</strong>的特性。这些特性将检测到恶意软件的新修改，但不需要更多的资源来进行计算。性能和可伸缩性是反恶意软件引擎处理的第一阶段的关键优先事项。</p>
<p>为了解决这个问题，我们专注于提取以下特性：</p>
<ul>
<li>快速计算，如从<strong>文件字节内容</strong>或代码反汇编导出的统计数据</li>
<li>直接从可执行文件的结构中检索，比如<strong>文件格式描述</strong></li>
</ul>
<p><strong><font color="red">
使用这些数据，我们计算了一种特定类型的哈希函数，称为局部敏感哈希(LSH)。</font></strong></p>
<blockquote>
<p>ssdeep, TLSN 局部哈希</p>
</blockquote>
<p>两个几乎相同的文件的常规加密哈希和两个非常不同的文件的哈希差异一样大。文件的相似性和哈希值之间没有联系。然而，几乎相同的文件的LSHs映射到相同的二进制桶——它们的LSHs非常相似——而且概率非常高。两个不同文件的LSHs有很大差异。</p>
<blockquote>
<p><strong>LSH的基本思想是</strong>：将原始数据空间中的两个相邻数据点通过相同的映射或投影变换（projection）后，这两个数据点在新的数据空间中仍然相邻的概率很大，而不相邻的数据点被映射到同一个桶的概率很小。</p>
<ul>
<li>https://colobu.com/2018/08/16/locality-sensitive-hashing/</li>
</ul>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502195.png" alt="image-20220429233512068" style="zoom: 33%;"></p>
<p>但我们走得更远。LSH的计算是无监督的。它没有考虑到我们对每个样本都是恶意软件或良性的额外知识。</p>
<p>有一个相似和非相似对象的数据集，我们通过引入一个训练阶段来增强了这种方法。我们实现了一种相似性哈希方法。<strong>它类似于LSH，但它是==有监督==的，并且能够利用关于相似和非相似对象对的信息</strong>。在这种情况下：</p>
<ul>
<li>我们的训练数据X将是一对文件特征表示[X1, X2]</li>
<li>Y将是一个可以告诉我们这些物体在语义上是否真的相似的标签。</li>
<li>在训练过程中，该算法拟合哈希映射h(X)的参数，以最大化训练集中的对数，其中h(X1)和h(X2)对于相似的对象是相同的，而对于其他的对象是不同的。</li>
</ul>
<p>该算法正在应用于可执行文件特性，它提供了具有有用检测功能的特定相似性哈希映射。事实上，我们训练了这种映射的几个版本，它们对不同特征集的局部变化的敏感性不同。例如，一个版本的相似性散列映射可以更专注于捕获<strong>可执行文件结构</strong>，而较少关注实际内容。另一种方法可能更专注于捕获文件中的<strong>ascii字符串</strong>。</p>
<p>这就抓住了这样一种观点，即不同的特性子集可能或多或少可以区分不同类型的恶意软件文件。对于其中一个，文件内容统计数据可能显示未知恶意包装器的存在。对于其他方面，关于潜在行为的最重要信息集中在表示已使用的OSAPI、已创建的文件名、已访问的url或其他特性子集的字符串中。<strong>为了更精确的产品检测，将相似度哈希算法的结果与其他基于机器学习的检测方法相结合。</strong></p>
<blockquote>
<p><strong>基于局部敏感哈希（有监督）+
决策树集成的用户计算机两阶段预执行检测</strong></p>
</blockquote>
<p>为了分析在预执行阶段的文件，我们的产品将相似性哈希方法与其他训练过的算法结合在一个两阶段的方案中。为了训练这个模型，我们使用了大量我们知道是恶意软件和良性的文件。</p>
<p><strong>两阶段分析设计解决了减少用户系统的==计算负载==和==防止误报==的问题。</strong>一些对检测很重要的文件特性需要更大的计算资源来计算它们。这些功能被称为“重的”。为了避免对所有扫描文件的计算，我们引入了一个称为预检测的初步阶段。当使用“轻量级”特性分析文件，并在系统上没有大量负荷的情况下提取文件时，就会发生==预检测==。<strong>在许多情况下，预检测为我们提供了足够的信息，以知道一个文件是否是良性的，并结束了文件扫描</strong>。有时它甚至会检测到一个文件是恶意软件。如果第一阶段不够，则文件将进入第二阶段的分析，即提取“重”特征以进行精确检测。</p>
<p>在我们的产品中，两阶段分析的工作方式如下。在<strong>预检测阶</strong>段，对扫描文件的<strong>轻量级特征</strong>计算学习到的相似度<strong>哈希映射</strong>。然后，检查是否有其他文件具有相同的哈希映射，以及它们是恶意软件还是良性的。一组具有类似哈希映射值的文件被称为哈希桶。根据扫描文件所属的散列桶，可能会出现以下结果：</p>
<ul>
<li><p>在一个简单的区域案例中，文件落入一个只包含一种对象的桶中：恶意软件或良性的。如果一个文件落入一个“纯恶意软件桶”，我们会检测到它是恶意软件。如果它落入一个“纯良性的桶”，我们不会扫描它更深。在这两种情况下，我们都不提取任何新的“重”特性。</p></li>
<li><p>在硬区域中，哈希桶同时包含恶意软件和良性文件。这是系统唯一可以从扫描文件中提取“重”特征以进行精确检测的情况。<strong>对于每个硬区域，都有一个单独的特定区域的分类器训练。</strong>目前，我们使用<strong>决策树集成</strong>或基于“<strong>重”特征的相似性哈希</strong>，这取决于哪个队硬区域更有效。</p></li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502256.png" alt="image-20220429233534859" style="zoom: 33%;"></p>
<blockquote>
<p><strong>对象空间的分割</strong>：</p>
<p>使用相似性散列映射创建的对象空间的分割的示意图表示。为简单起见，该插图只有两个维度。每个单元格的一个索引对应于特定的<strong>相似度哈希映射值</strong>。网格中的每个单元格都说明了一个具有相同相似性哈希映射值的对象区域，也称为<strong>哈希桶</strong>。点颜色：恶意（<strong>红色</strong>）和良性/未知（<strong>绿色</strong>）。有两种选项可用的：将一个区域的散列添加到恶意软件数据库（简单区域）中，或者将其作为两阶段检测器的第一部分，并与特定区域的分类器（硬区域）结合使用。</p>
</blockquote>
<p>在现实中，有一些困难的区域不适合用这种两阶段的技术进行进一步的分析，因为它们<strong>包含了太多流行的良性文件</strong>。用这种方法处理它们会产生假阳性和性能下降的高风险。对于这种情况，我们不训练特定区域的分类器，也不通过该模型扫描该区域中的文件。为了在这样的区域进行正确的分析，我们使用了<strong>其他的检测技术</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502023.png" alt="image-20220429233555509" style="zoom:50%;"></p>
<p>预检测阶段的实现大大减少了在第二步中被大量扫描的文件的数量。这个过程提高了性能，因为在预检测阶段通过相似哈希映射查找可以快速完成。</p>
<p>我们的两阶段设计也降低了假阳性的风险：</p>
<ul>
<li>在第一个（预检测）阶段，我们不能在假阳性风险较高的区域使用特定区域的分类器进行检测。正因为如此，传递到第二阶段的对象的分布偏向于“恶意软件”类。这也降低了假阳性率。</li>
<li>在第二阶段，<strong>每个硬区域的分类器只从一个桶上对恶意软件进行训练，但在训练集的所有桶中可用的所有干净对象上。这使得区域分类器能够更精确地检测特定硬区域桶的恶意软件</strong>。当模型在具有真实数据的产品中工作时，它还可以防止任何意外的假阳性。</li>
</ul>
<p>两阶段模型的可解释性来自于数据库中的每个散列都与训练中的一些恶意软件样本子集相关联。<strong>整个模型可以通过添加检测来适应一个新的恶意软件流，包括散列映射和一个以前未观察到的区域的树集成模型。这允许我们撤销和重新训练特定区域的分类器，而不显著降低整个产品的检测率</strong>。如果没有这个，我们将需要对整个模型重新培训所有我们知道的恶意软件，我们想要做的每一个改变。话虽如此，两阶段恶意软件检测适用于在介绍中讨论的机器学习的细节。</p>
<h3><span id="三-针对罕见攻击的深度学习">三、针对罕见攻击的深度学习</span></h3>
<p>通常，当恶意和良性样本在训练集中大量表示时，机器学习会面对任务。但是有些攻击是如此罕见，以至于我们只有一个恶意软件进行训练的例子。这是针对性高调的有针对性攻击的典型情况。在这种情况下，我们使用了一个非常特定的基于深度学习的模型架构。我们将这种方法称为<strong>exemplar
network( ExNet)</strong>。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502308.png" alt="image-20220429233615467">
<figcaption aria-hidden="true">image-20220429233615467</figcaption>
</figure>
<p>这里的想法是，我们训练模型来构建<strong>输入特征的紧凑表示</strong>。然后，我们使用它们来同时训练多个<strong>单范例的分类器（per-exemplar
classifiers）</strong>——这些都是检测特定类型的恶意软件的算法。深度学习允许我们将这些多个步骤（对象特征提取、紧凑的特征表示和局部的，或每个范例的模型创建）结合到一个神经网络管道中，它可以提取各种类型的恶意软件的鉴别特征。</p>
<p>该模型可以有效地<strong>推广关于单个恶意软件样本</strong>和大量干净样本收集的知识。然后，它可以检测到相应的恶意软件的新修改。</p>
<h3><span id="四-在执行后行为检测中的深度学习">四、在执行后行为检测中的深度学习</span></h3>
<p>前面描述的方法是在静态分析的框架中考虑的，即在真实用户环境中执行对象之前提取和分析对象描述。</p>
<p>执行阶段的静态分析有许多显著的优势。其主要优点是它对用户来说是安全的。一个对象可以在它开始作用于真实用户的机器之前被检测到。但它面临着高级加密、混淆技术以及使用各种高级脚本语言、容器和无文件攻击场景的问题。这些情况都是当执行后的行为检测开始发挥作用的情况。</p>
<p>我们还使用深度学习方法来解决<strong>行为检测的任务</strong>。在执行后阶段，我们正在使用<strong>威胁行为引擎</strong>提供的<strong>行为日志</strong>。行为日志是在进程执行过程中发生的系统事件的序列，以及相应的参数。为了检测观察到的日志数据中的恶意活动，我们的模型将得到的事件序列压缩为一组二进制向量。然后，它训练一个深度神经网络来区分干净的和恶意的日志。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502002.png" alt="image-20220429233634048">
<figcaption aria-hidden="true">image-20220429233634048</figcaption>
</figure>
<p><strong>日志的压缩阶段</strong>包括以下几个步骤：</p>
<ul>
<li><p>将该日志转换为一个二部行为图。此图包含两种类型的顶点：事件和参数。在每个事件和参数之间绘制边，它们一起出现在日志中的同一行中。这样的图表示比初始的原始数据要紧凑得多。它对跟踪同一多处理程序的不同运行或分析过程的行为混淆所导致的任何行排列保持鲁棒性</p></li>
<li><p>之后，我们将自动从该图中提取特定的子图或行为模式。每个模式都包含与进程的特定活动相关的事件和相邻参数的子集，如网络通信、文件系统探索、系统寄存器的修改等</p></li>
<li><p>我们将每个“行为模式”压缩为一个稀疏的二进制向量。此向量的每个组件负责在模板中包含一个特定的事件或参数的令牌(与web、文件和其他类型的活动相关)。</p></li>
<li><p>训练后的深度神经网络将行为模式的稀疏二进制向量转换为称为<strong>模式嵌入</strong>的紧凑表示。然后将它们组合成一个单个向量，或进行<strong>日志嵌入</strong></p></li>
<li><p>最后，在日志嵌入的基础上，网络预测了日志的可疑性。</p></li>
</ul>
<p>所使用的神经网络的主要特征是所有的权值都是正的，所有的激活函数都是单调的。这些特性为我们提供了许多重要的优势：</p>
<ul>
<li><strong>在处理日志中的新行时，我们的模型的怀疑分数输出只随着时间的推移而增长。因此，恶意软件不能通过与它的主有效负载并行地执行额外的噪声或“干净的”活动来逃避检测</strong>。</li>
<li>由于模型的输出在时间上是稳定的，我们可能会免受由于在扫描干净日志时的预测波动而导致的最终错误警报。</li>
<li>在单调空间中处理日志样本，允许我们自动选择导致检测的事件，并更方便地管理假警报</li>
</ul>
<p>这样的方法使我们能够训练一个能够使用高级可解释的行为概念进行操作的深度学习模型。这种方法可以安全地应用于整个用户环境的多样性，并在其架构中集成了假告警修复能力。总之，所有这些都为我们提供了一种对行为检测最复杂的现代威胁的有力手段。</p>
<h3><span id="五-基础设施中的应用malwarehunter">五、基础设施中的应用（Malware
Hunter）</span></h3>
<p>从有效处理卡巴斯基实验室的恶意软件流到维护大规模检测算法，<strong>机器学习在建立适当的实验室基础设施中发挥着同样重要的作用</strong>。</p>
<h4><span id="51-聚类传入的对象流">5.1 聚类传入的对象流</span></h4>
<p><strong>每天都有成千上万的样本进入卡巴斯基实验室，同时人工对新型样本进行注释的高昂成本，减少分析师需要查看的数据量成为一项至关重要的任务</strong>。使用有效的聚类算法，我们可以从难以忍受的独立的未知文件数量增加到合理数量的对象组。这些对象组的部分将根据其中已注释的对象自动处理。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502650.png" alt="image-20220429232153712" style="zoom:50%;"></p>
<p>所有最近收到的传入文件都通过我们的实验室恶意软件检测技术进行分析，包括执行前和执行后。我们的目标是标记尽可能多的对象，但有些对象仍然未分类。我们想给它们贴上标签。为此，所有的对象，包括已标记的对象，都由<strong>多个特征提取器</strong>进行<strong>处理</strong>。然后，根据<strong>文件类型</strong>，它们通过几种聚类算法(例如k-means和dbscan)一起传递。这将产生类似的对象组。</p>
<p>在本文的这一点上，我们将面对四种不同类型的具有未知文件的结果集群：</p>
<ol type="1">
<li>包含恶意软件和未知文件的集群；</li>
<li>包含干净和未知文件的集群；</li>
<li>包含恶意软件、干净和未知文件的集群；</li>
<li>仅包含未知文件的集群。</li>
</ol>
<p>对于类型1-3簇中的对象，我们使用额外的机器学习算法，如<strong>贝叶斯网络（belief
propagation）</strong>，<strong>来验证未知样本与分类样本的相似性</strong>。在某些情况下，这甚至在第3类集群中也是有效的。这使我们能够自动标记未知文件，只为人类留下4型和部分3型的集群。这导致了每天所需的人类注释的急剧减少。</p>
<h4><span id="蒸馏工艺包装更新内容">蒸馏工艺：包装更新内容</span></h4>
<p>我们在实验室中检测恶意软件的方式不同于针对用户产品的最佳算法。一些最强大的分类模型需要大量的资源，如CPU/GPU的时间和内存，以及昂贵的特性提取器。</p>
<p>例如，由于大多数现代恶意软件编写者使用<strong>高级包装器和混淆器</strong>来隐藏有效负载功能，机器学习模型确实受益于使用具有高级行为日志的实验室内沙箱的执行日志。同时，在用户的机器上的预执行阶段收集这类日志的计算量可能会很高。它可能会导致显著的系统性能下降。</p>
<blockquote>
<p>对于加壳的恶意样本，需要沙箱分析，在用户终端</p>
</blockquote>
<p>在实验室中保存和运行那些<strong>“重型”</strong>模型更有效。一旦我们知道一个特定的文件是恶意软件，我们就会使用我们从模型中获得的知识来训练将在我们的产品中工作的<strong>轻量</strong>级分类器（to
用户）。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502687.png" alt="image-20220429232807391" style="zoom:50%;"></p>
<p>在机器学习中，这个过程被称为<strong>蒸馏</strong>。我们用它来教我们的产品检测新的恶意软件：</p>
<ul>
<li>在我们的实验室中，我们首先从标记的文件中提取一些耗时的特征，并对它们训练一个“沉重的”在实验室内的模型。</li>
<li>我们取一个未知文件集群，并使用我们的“重”实验室模型来对它们进行标签。</li>
<li>然后，我们使用新标记的文件来扩充轻量级分类模型的训练集。</li>
<li>我们向用户的产品提供了这个轻量级的模型。</li>
</ul>
<p>蒸馏使我们能够有效地输出我们的知识的新的和未知的威胁给我们的用户。</p>
<h4><span id="总结">总结</span></h4>
<p>将常规任务传递给算法会给我们留下更多的时间来研究和创建。这使我们能够为客户提供更好的保护。通过我们的努力、失败和胜利，我们已经了解到什么对于让机器学习对恶意软件检测产生它的卓越影响是重要的。</p>
<h5><span id="亮点">亮点：</span></h5>
<ul>
<li><p><strong>有正确的数据</strong>：这是机器学习的燃料。这些数据必须具有代表性，与当前的恶意软件环境相关，并在需要时正确标记。我们成为了在提取和准备数据以及训练我们的算法方面的专家。我们用数十亿个文件样本进行了有效的收集，以增强机器学习的能力。</p></li>
<li><p><strong>了解理论机器学习以及如何将其应用于网络安全。</strong>我们了解机器学习是如何工作的，并跟踪该领域出现的最先进的方法。另一方面，我们也是网络安全方面的专家，我们认识到每一种创新的理论方法给网络安全实践带来的价值。</p></li>
<li><p><strong>了解用户的需求，并成为将机器学习实现到帮助用户满足其实际需求的产品中的关键</strong>。我们使机器学习有效和安全地工作。我们建立了网络安全市场所需要的创新解决方案</p></li>
<li><p><strong>建立一个足够的用户基础</strong>：这引入了“群众”检测质量的力量，并给我们需要的反馈，告诉我们是对是错。</p></li>
<li><p><strong>保持检测方法的多层协同作用</strong>。只要当今的先进威胁攻击载体如此多样化，网络安全解决方案就应该提供<strong>多层的保护</strong>。在我们的产品中，<strong>基于机器学习的检测与其他类型的检测协同工作，以一种多层的现代网络安全保护方法进行工作。</strong></p></li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-Sophos《Learning from Context: Exploiting and Interpreting File Path Information for Better Malware Detection》</title>
    <url>/posts/2APFWS8/</url>
    <content><![CDATA[<h2><span id="learningfrom-context-exploiting-and-interpreting-file-path-information-forbetter-malware-detection">Learning
from Context: Exploiting and Interpreting File Path Information for
Better Malware Detection</span></h2>
<ul>
<li>https://ai.sophos.com/presentations/learning-from-context-a-multi-view-deep-learning-architecture-for-malware-detection/</li>
</ul>
<blockquote>
<p>用于静态可移植可执行（PE）恶意软件检测的机器学习（ML）通常使用每个文件的数字特征向量表示作为训练期间一个或多个目标标签的输入。然而，可以从查看文件的上下文中收集到许多正交信息。在本文中，我们<strong>建议使用静态上下文信息源（PE文件的路径）作为分类器的辅助输入</strong>。虽然文件路径本身不是恶意或良性的，但它们确实为恶意/良性判断提供了有价值的上下文。与动态上下文信息不同，文件路径的可用开销很小，并且可以无缝集成到多视图静态ML检测器中，在非常高的吞吐量下产生更高的检测率，同时基础结构的更改也很小。在这里，我们提出了一种多视图神经网络，它从PE文件内容以及相应的文件路径中提取特征向量作为输入并输出检测分数。为了确保真实的评估，我们使用了大约1000万个样本的数据集—来自实际安全供应商网络的用户端点的文件和文件路径。<strong>然后，我们通过LIME建模进行可解释性分析，以确保我们的分类器已学习到合理的表示，并查看文件路径的哪些部分对分类器得分的变化贡献最大</strong>。我们发现，我们的模型学习了文件路径的有用方面以进行分类，同时还学习了测试供应商产品的客户的工件，例如，通过下载恶意软件样本目录，每个样本都命名为其哈希。我们从我们的测试数据集中删减了这些工件，并证明在10−3假阳性率（FPR），10时为33.1%−4
FPR，基于类似拓扑的单输入PE文件内容模型。</p>
</blockquote>
<h3><span id="摘要">摘要</span></h3>
<p>用于恶意软件检测的机器学习（ML）分类器通常在进行恶意/良性判断时使用每个文件内容的数字表示。<strong>然而，也可以从文件所在的上下文中收集相关信息，这些信息通常被忽略。<font color="red">
上下文信息的一个来源是文件在磁盘上的位置。</font></strong>例如，如果检测器可以清楚地利用有关其所在路径的信息，则伪装为已知良性文件（例如Windows系统DLL）的恶意文件更有可能显得可疑。了解文件路径信息还可以更容易地检测那些试图通过将自己放置在特定位置来逃避磁盘扫描的文件**。文件路径也可以使用，开销很小，并且可以无缝集成到多视图静态ML检测器中，在非常高的吞吐量和最小的基础结构更改下，可能产生更高的检测率。</p>
<p>在这项工作中，我们提出了一种 <strong>multi-view</strong>
深度神经网络结构，该结构将PE文件内容中的特征向量以及相应的文件路径作为输入并输出检测分数。我们对大约1000万个样本的商业规模数据集进行了评估，这些样本是来自实际安全供应商提供服务的用户端点的文件和文件路径。<strong>然后，我们通过LIME建模进行可解释性分析，以确保我们的分类器已学习到合理的表示，并检查文件路径如何在不同情况下改变分类器的分数</strong>。我们发现，与只对PE文件内容进行操作的模型相比，<strong>我们的模型学习了文件路径的有用方面，在0.001假阳性率（FPR）下，真阳性率提高了26.6%，在0.0001
FPR下，提高了64.6%</strong>。</p>
<p><strong>keyword</strong> :
静态PE检测、文件路径、深度学习、多视图学习、模型解释</p>
<h3><span id="一-说明">一、说明</span></h3>
<p>商用便携式可执行（PE）恶意软件检测器由静态和动态分析引擎组成。<strong>静态检测通常首先用于标记可疑样本，它可以快速有效地检测大部分恶意软件</strong>。它涉及分析磁盘上的原始PE映像，可以非常快速地执行，但易受代码混淆技术的影响，例如压缩和多态/变形转换<strong>[1]</strong>。相比之下，动态检测需要在模拟器中运行PE，并在运行时分析行为[2]。当动态分析工作时，它不太容易受到代码混淆的影响，但与静态方法相比，它需要更大的计算容量和执行时间。此外，有些文件很难在仿真环境中执行，但仍然可以进行静态分析。<strong>因此，静态检测方法通常是端点恶意软件预防（在执行恶意软件之前阻止恶意软件）管道中最关键的部分</strong>。最近，由于采用了机器学习，静态检测方法的性能有所提高[3]，其中高度表达的分类器（例如深层神经网络）适合于数百万个文件的标记数据集。训练这些分类器时，它们使用静态文件内容作为输入，但不使用辅助数据。<strong>然而，我们注意到，由于辅助数据（例如网络流量、系统调用等），动态分析工作得很好。</strong>在这项工作中，我们试图使用文件路径作为正交输入信息来增强静态ML检测器。<strong>文件路径是静态可用的，无需操作系统的任何附加工具</strong>。通过将文件路径作为辅助输入，我们希望能够将有关文件的信息与在特定位置看到此类文件的可能性的信息结合起来，<strong>并识别与已知恶意软件和良性文件相关的常见目录层次结构和命名模式。</strong></p>
<blockquote>
<p><strong>静态检测</strong>：通用模块，快速有效地标记可疑样本；易受代码混淆技术（压缩和多态/变形转换）的影响。</p>
<p>[1] A. Moser, C. Kruegel, and E. Kirda, “Limits of static analysis
for malware detection,” in Twenty-Third Annual Computer Security
Applications Conference (ACSAC 2007). IEEE, 2007, pp. 421–430.</p>
<p><strong>动态检测</strong>：分析模块，需要更大的计算容量和执行时间；有些文件很难在仿真环境中执行。</p>
</blockquote>
<p>我们将分析重点放在三个模型上：</p>
<ul>
<li>仅基线文件内容（PE）模型，仅将PE功能作为输入并输出恶意软件置信度得分。</li>
<li>另一个基准文件路径仅内容（FP）模型，仅将文件的文件路径作为输入，并输出恶意软件置信度得分。</li>
<li>我们提出的多视图PE文件内容+上下文文件路径（PE+FP）模型，该模型同时考虑PE文件内容特征和文件路径，并输出恶意软件置信度得分。</li>
</ul>
<p>三个模型的示意图如图1所示。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181509919.png" alt="image-20220528162748125" style="zoom:50%;"></p>
<p>我们对从一家大型反恶意软件供应商的遥测数据中收集的时间分割数据集进行分析，发现我们在文件内容和上下文文件路径上训练的分类器在ROC曲线上，尤其是在低误报率（FPR）区域，产生了统计上显著更好的结果。</p>
<p><strong>本文的贡献如下：</strong></p>
<ul>
<li>我们从安全供应商的客户端点（而不是恶意软件/供应商标签聚合服务）获得一组真实、精心策划的文件和文件路径数据集。</li>
<li>我们证明，我们的多视图PE+FP恶意软件分类器在我们的数据集上的性能明显优于单独使用文件内容的模型。</li>
<li>我们将本地可解释模型不可知解释（LIME）<strong>[4]</strong>扩展到PE+FP模型，并使用它分析文件路径如何影响模型的恶意/良性决策。</li>
</ul>
<blockquote>
<p>[4] M. T. Ribeiro, S. Singh, and C. Guestrin, “Why should i trust
you?: Explaining the predictions of any classifier,” in Proceedings of
the 22nd ACM SIGKDD international conference on knowledge discovery and
data mining. ACM, 2016, pp. 1135–1144.</p>
</blockquote>
<p>本手稿的其余部分结构如下：第二节涵盖重要的背景概念和相关工作。第三节讨论数据集收集和模型制定。第四节将我们的新多视图方法与拓扑结构相似的纯内容基线模型进行了比较，并对我们的模型进行了可解释性分析。第五节结束。</p>
<h3><span id="二-背景和相关工作">二、背景和相关工作</span></h3>
<p>在本节中，我们将描述机器学习如何普遍应用于静态PE检测，以及我们的方法如何通过提供上下文信息作为辅助输入而在高层意义上有所不同。然后，我们介绍了其他机器学习领域的相关工作。</p>
<h4><span id="21-静态ml恶意软件检测">2.1 静态ML恶意软件检测</span></h4>
<p>机器学习已经应用于计算机安全领域多年了[5]，但在商业规模上使用ML的静态PE模型的破坏性性能突破是一个较新的现象。商业模型通常依赖深度神经网络[6]或增强的决策树集合[7]，并已扩展到其他静态文件类型，包括web内容[8]、[9]、office文档[10]和档案[10]。</p>
<p>大多数用于信息安全的静态ML（ML-Sec）分类器操作的是文件部分（例如，标题）上的学习嵌入[11]，整个文件上的学习嵌入[12]，或者最常见的是，操作的是设计用于总结每个文件内容的预设计数字特征向量[6]、[13]–[19]。预先构建的特征向量表示往往更具可伸缩性，可以快速从每个文件中提取内容，同时保留有用的信息。有很多方法可以构建特征向量，包括在滑动窗口上跟踪每字节统计信息【6】、【18】、字节直方图【7】、【18】、ngram直方图【13】、将字节视为图像中的像素值（文件内容的可视化）【13】、【18】、操作码和函数调用图统计信息【18】、符号统计信息【18】、哈希/数字元数据值【6】、【7】、【18】–例如。，入口点作为文件的一部分，或散列导入和导出，以及分隔标记的散列[10]、[19]。在实际应用中，从文件内容中提取的几种不同类型的特征向量通常连接在一起，以获得优异的性能。</p>
<h4><span id="22-learning-from-multiplesources">2.2 Learning from Multiple
Sources</span></h4>
<p>使用深度神经网络进行静态ML恶意软件检测的相关研究已经检验了从多个信息源学习的方法，但这些方法与我们的方法有根本不同：Huang等人【20】和Rudd等人【21】对多个辅助损失函数使用多目标学习【22】，【23】，他们发现这些函数在主要恶意软件检测任务中的性能有所提高。这两项工作都在培训期间使用元数据作为辅助目标标签，为模型提供额外的信息，并在部署时使用单个输入来做出分类决策。我们的方法利用了多种输入类型/模式——一种是以类似于[6]的PE特征向量的形式描述恶意样本的内容，另一种是将原始字符串提供给一个字符嵌入层（类似于[8]），该层提供了有关该样本出现位置的信息。这种技术是一种多视图学习方法[24]。顾名思义，多视图学习的大多数应用都是在计算机视觉中进行的，在计算机视觉中，多个视图实际上是由来自不同输入摄像头/传感器的视图或来自同一摄像头/传感器在不同时间的不同视图组成的。<strong>在ML-Sec空间中，我们只能找到两种专门将自己称为多视图的方法：即[25]，Narayanan等人将多内核学习依赖图应用于Android恶意软件分类，以及[26]，</strong>Bai等人将多视图集合用于PE恶意软件检测。虽然这些方法在某些方面与我们的方法相似，但据我们所知，我们是第一个在商业规模上使用外部上下文反馈到深层神经网络并结合文件内容特征来执行恶意软件检测多视图建模的方法。</p>
<blockquote>
<p>[25] A. Narayanan, M. Chandramohan, L. Chen, and Y. Liu, “A
multi-view context-aware approach to android malware detection and
malicious code localization,” Empirical Software Engineering, pp. 1–53,
2018.</p>
<p>[26] J. Bai and J. Wang, “Improving malware detection using
multi-view ensemble learning,” Security and Communication Networks, vol.
9, no. 17, pp. 4227–4241, 2016.</p>
</blockquote>
<h3><span id="三-实施细节">三、实施细节</span></h3>
<p>在本节中，我们将介绍我们的方法的实现细节，包括从客户端点获取PE文件和文件路径的数据收集过程、我们的特征化策略以及我们的多视图深度神经网络和比较基线的体系结构。</p>
<h4><span id="31-数据集">3.1 数据集</span></h4>
<p>在我们的实验中，我们从一家著名反恶意软件供应商的遥测数据中收集了三个不同的数据集：一个训练集、一个验证集和一个测试集。培训集由9148143个样本组成，这些样本首次出现在2018年6月1日至11月15日之间，其中693272个样本被标记为恶意样本。验证集包括在2018年11月16日至12月1日期间观察到的2225094个不同样本，其中85041个被标记为恶意样本。最后，测试集在2019年1月1日至1月30日期间共有249783个样本，其中38767个被标记为恶意。这些文件的恶意/良性标签是使用类似于[6]、[8]的标准计算的，但结合其他专有信息可以生成更准确的标签。</p>
<h4><span id="32-特征工程">3.2 特征工程</span></h4>
<p><strong>为了使用文件路径作为神经网络模型的输入，我们首先将可变长度字符串转换为固定长度的数字向量</strong>。我们使用类似于<strong>[8]</strong>的矢量化方案来实现这一点，方法是在每个字符上创建一个键控的查找表，该表用一个表示每个字符的数值（介于0和字符集大小之间）来表示。实际上，我们将此表实现为Python字典。在遥测和早期实验数据的指导下，我们将文件路径缩减到最后100个字符。短于100个字符的文件路径的功能用零填充。对于字符集，我们考虑整个Unicode字符集，但将词汇限制为150个最常见的字符。见附录？？供进一步讨论。作为PE文件内容的特征，我们使用了由四种不同特征类型组成的浮点1024维特征向量，类似于[6]。总的来说，我们将每个样本表示为两个特征向量：<strong>1024维的PE内容特征向量和100维的上下文文件路径特征向量。</strong></p>
<blockquote>
<p>[8] J. Saxe and K. Berlin, “expose: <strong>A character-level
convolutional neural network with embeddings for detecting malicious
urls, file paths and registry keys</strong>,” arXiv preprint
arXiv:1702.08568, 2017.</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181509845.png" alt="image-20220530152922273" style="zoom: 25%;"></p>
</blockquote>
<h4><span id="33-网络体系结构">3.3 网络体系结构</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181509415.png" alt="image-20220528204724740" style="zoom:50%;"></p>
<p>我们的多视图体系结构如图2所示。该模型有两个输入，<strong>1024个元素的PE内容特征向量xPE和100个元素的文件路径整数向量xFP</strong>，如第III-B节所述。每个不同的输入分别通过一系列具有各自参数θPE和θFP的层，用于PE特征和FP用于文件路径特征，并在训练期间联合优化。然后将这些层的输出连接（串联）并通过一系列最终隐藏层，即参数θO的联合输出路径。网络的最终输出由密集层和sigmoid激活组成。</p>
<ul>
<li><strong>PE
特征</strong>：PE输入臂θPE使xPE通过一系列块，每个块由四层组成：一个完全连接的层，一个使用[27]中所述技术实现的层规范化层，一个丢失概率为0.05的丢失层，以及一个校正线性单元（ReLU）激活。其中五个块依次连接，密集层大小分别为1024、768、512、512和512个节点。</li>
<li><strong>文件路径</strong>：
<ul>
<li>文件路径输入arm θFP 将
xFP（<strong>长度为100的向量</strong>）传递到嵌入层 ？？？</li>
<li><strong>该嵌入层将文件路径的每个字符转换为32维向量，从而为整个文件路径生成100x32的嵌入张量</strong>。</li>
<li><strong>然后将该嵌入馈入4个单独的卷积块</strong>，其中包含一个具有128个滤波器的1D卷积层、一个层归一化层和一个1D求和层，以将输出平坦化为向量。4个卷积块包含卷积层，卷积层的大小分别为2、3、4和5，用于处理2、3、4和5克的输入文件路径。</li>
<li>然后将这些卷积块的平坦输出<strong>串联</strong>起来，作为大小为1024和512个神经元的两个密集块的输入（与PE输入臂中的形式相同）。</li>
</ul></li>
<li><strong>输出层</strong>：PE
arm和文件路径arm的完全连接块的输出随后被连接并传递到由θO参数化的联合输出路径。该路径由层大小为512、256和128的密集连接块（与PE输入arm中的形式相同）组成。然后将这些块的128D输出馈送至致密层，该致密层将输出投射至1D，然后进行sigmoid激活，以提供模型的最终输出。</li>
</ul>
<p>仅PE模型只是PE+FP模型，但没有FP臂，输入xPE并拟合θPE和θO参数。类似地，FP模型是PE+FP模型，但没有3个授权的许可PE
arm，采用输入xFP拟合θFP和θO参数。适当调整输出子网络的第一层，以匹配前一层的输出。我们使用二进制交叉熵损失函数拟合所有模型。给定标签为y的输入x的深度学习模型f（x；θ）的输出∈
{0，1}，模型参数θ损失为：</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220528171648185.png" alt="image-20220528171648185" style="zoom:50%;"></p>
<p>通过优化器，我们求解ˆθ的最佳参数集，以最小化数据集上的组合损失：</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220528171710886.png" alt="image-20220528171710886" style="zoom:50%;"></p>
<p>其中M是数据集中的样本数，y（i）和x（i）分别是第i个训练样本的标签和特征向量。我们使用Keras框架构建和训练模型，使用Adam优化器和Keras的默认参数和1024个小批量。每个模型都经过15个阶段的训练，我们确定这些阶段足以使结果收敛。</p>
<h3><span id="4-实验分析">4、实验分析</span></h3>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181509685.png" alt="image-20220528172252766" style="zoom:50%;"></p>
<h3><span id="5-总结">5、总结</span></h3>
<p>我们已经证明，深度神经网络恶意软件检测器可以从合并来自文件路径的上下文信息中获益，即使这些信息本身不是恶意或良性的。<strong>将文件路径添加到我们的检测模型中不需要任何额外的端点检测，并且在整个相关FPR区域的总体ROC曲线中提供了统计上显著的改善</strong>。我们直接在客户端点分布上测量模型的性能这一事实表明，我们的多视图模型实际上可以部署到端点以检测恶意软件。我们在第IV-B节中进行的LIME分析表明，多视图模型能够提取暗示实际恶意/良性概念的上下文信息；不只是数据集的统计伪影，尽管正如我们所观察到的，它还可以学习这些伪影。除了端点部署之外，这项研究可以应用的另一个潜在领域是端点检测和响应（EDR）环境，在该环境中，我们的模型的输出可以用于根据事件的可疑程度对磁盘上的事件进行排序。有趣的是，石灰等技术在这方面也有应用。使用从LIME或类似方法得出的解释，可以创建分析工具，允许非恶意软件/取证专家的用户执行某种程度的威胁搜寻。如图4所示，重要性突出显示不仅对用户有用，而且是最近邻/相似性可视化方法的替代方法，该方法不会显示其他用户的潜在可识别信息（PII）。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>风控反欺诈（2）GraphSAGE算法在网络黑产挖掘中的思考</title>
    <url>/posts/3ADMGV5/</url>
    <content><![CDATA[<h2><span id="graphsage图算法在网络黑产挖掘中的思考">GraphSAGE图算法在网络黑产挖掘中的思考</span></h2>
<blockquote>
<p><font color="blue"> Harry 高级研究员-DataFunTalk
https://mp.weixin.qq.com/s/sZ7VQz26c5mrWAsnMKx8Hw</font></p>
<p><font color="blue">
<strong>graphSAGE-pytorch</strong>：https://github.com/twjiang/graphSAGE-pytorch/tree/master/src</font></p>
<p><strong>导读：</strong>虚拟网络中存在部分黑产用户，这部分用户通过违法犯罪等不正当的方式去谋取利益。作为恶意内容生产的源头，管控相关黑产用户可以保障各业务健康平稳运行。<strong>当前工业界与学术界的许多组织通常采用树形模型、社区划分等方式挖掘黑产用户，但树形模型、社区划分的方式存在一定短板，为了更好地挖掘黑产用户，我们通过图表征学习与聚类相结合的方式进行挖掘</strong>。本文将为大家介绍图算法在网络黑产挖掘中的思考与应用，主要介绍：</p>
<ul>
<li>图算法设计的背景及目标</li>
<li>图算法GraphSAGE落地及优化</li>
<li>孤立点&amp;异质性</li>
<li>总结思考</li>
</ul>
</blockquote>
<h3><span id="一-图算法设计的背景"><strong>一、 图算法设计的背景</strong></span></h3>
<p>在虚拟网络中存在部分的黑产用户，这部分用户通过违法犯罪等不正当的方式去谋取利益，比如招嫖、色情宣传、赌博宣传的行为，更有甚者，如毒品、枪支贩卖等严重的犯罪行为。当前工业界与学术界的许多组织推出了基于图像文字等内容方面的API以及解决方案。而本次主题则是介绍基于账号层面上的解决方法，为什么需要在账号层面对网络黑产的账号进行挖掘呢？</p>
<p><strong>原因主要有三：</strong></p>
<ul>
<li><strong>恶意账号是网络黑产的源头，在账号层面对网络黑产的账号进行挖掘可以对黑产的源头进行精准地打击</strong>；</li>
<li>账号行为对抗门槛高，用户的行为习惯以及关系网络是很难在短期内作出改变的，而针对单一的黑产内容可以通过多种方式避免被现有的算法所感知，虽然黑产用户可能不懂算法，但其可以通过“接地气”的方式来干扰算法模型，譬如在图片上进行简单的涂抹，在敏感处打上马赛克，在图片处加上黑框，通过简单的对抗手段会对基于黑产内容的算法产生较大的影响；</li>
<li>可以防范于未然，通过账号层面的关联提前圈定可疑账号，在其进行违法犯罪行为之前对账号进行相应的处理以及管控。</li>
</ul>
<p><strong>具体通过什么方式挖掘黑产账号？</strong></p>
<p>首先，简单介绍下在推荐场景中应用。比如广告推荐，通常上，广告商会给予平台方用户的用户标签，用户存在用户标签之后，平台方则会将相关类别的用户找出，然后将广告推送给对应的用户；另一种方式是广告方提供种子包给平台方，平台方会找到相似的用户，然后将广告推送给相关的用户，常见的应用场景有Facebook
look like、Google similar audiences。</p>
<h4><span id="11-应用场景">1.1 应用场景</span></h4>
<p><strong>在黑产场景中与推荐场景中的应用类似，主要分为两个任务场景：</strong></p>
<ul>
<li>找出目标恶意类别用户。比如需要找出散播招嫖信息的用户，则给定该类用户招嫖的标签，类似于一个用户定性的问题；</li>
<li>黑产种子用户扩散，即利用历史的黑产用户进行用户扩散以及用户召回，可以通过染色扩散以及相似用户检索等方式完成。</li>
</ul>
<p><strong><font color="red">
针对恶意用户定性的传统方法，通常采用树形模型，比如说XGboost、GBDT等</font></strong>。这类算法短板显而易见，其<strong>缺乏对用户之间的关联进行考虑</strong>；另外一种<strong>用户召回方式为用户社区划分（相似用户召回），其中比较常用的社区划分算法有FastUnfolding、Copra等</strong>。这类算法的缺陷也相当明显，其由于原本社区规模小，所以最终召回的人数也少。且会存在多个种子用户在同一个社区的情况，<strong>难以召回大量可疑用户</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533000.jpeg" alt="图片" style="zoom:50%;"></p>
<p><strong><font color="red">
通过图表征学习与聚类相结合的方式进行召回</font></strong>。<strong>通过图表征学习将图结构的节点属性以及结构特征映射到一个节点低维空间，由此产生一个节点特征，然后再去进行下游的任务，如用户定性即节点分类等</strong>。其中，图表征学习的关键点在于在进行低维的映射当中需要保留原始图的结构和节点属性信息。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533575.jpeg" alt="图片" style="zoom:50%;"></p>
<h4><span id="12-图算法设计">1.2 图算法设计</span></h4>
<ul>
<li>算法的覆盖率和精准度；</li>
<li>用户分群规模合理，保证分群的可用性；</li>
<li><strong>支持增量特征，下游任务易用性</strong>。</li>
</ul>
<p>由于业务场景更多为动态网络，当新增节点时，如果模型支持增量特征，则不需要重复训练模型，可以极大的减少开发的流程，节省机器学习的资源，缩短任务完成的时间。</p>
<h3><span id="二-图算法graphsage落地及优化">二、图算法GraphSAGE落地及优化</span></h3>
<h4><span id="21-graphsage核心思想">2.1 GraphSAGE核心思想</span></h4>
<p><strong><font color="red">
GraphSAGE核心思想主要为两点：邻居抽样；特征聚合。</font></strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533811.jpeg" alt="图片" style="zoom:50%;"></p>
<p><strong>GraphSAGE的聚合过程实际是节点自身的属性特征和其抽样的邻居节点特征分别做一次线性变换，然后将两者concat在一起，再进行一次线性变换得到目标节点的embedding特征</strong>。最后利用得到的目标节点的embedding特征进行下游的任务，训练的方式的可以采用无监督的方式，如<strong>NCE
Loss</strong>。</p>
<h4><span id="22-graphsage的优点">2.2 <strong>GraphSAGE的优点</strong></span></h4>
<p><strong>GraphSAGE通过邻居抽样的方式解决了GCN内存爆炸的问题</strong>，同时可以将<strong>==直推式学习转化为归纳式学习==</strong>，<strong>==避免了节点的embedding特征每一次都需要重新训练的情况，支持了增量特征==</strong>。为什么通过邻居随机抽样就可以使得直推式的模型变为支持增量特征的归纳式模型呢？</p>
<p>在原始的GraphSAGE模型（直推式模型）当中，节点标签皆仅对应一种局部结构、一种embedding特征。在GraphSAGE引入邻居随机抽样之后，节点标签则变为对应多种局部结构、多种embedding特征，这样可以防止模型在训练过程过拟合，增强模型的泛化能力，则可以支持增量特征。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533971.jpeg" alt="图片" style="zoom:50%;"></p>
<h4><span id="23-graphsage的缺点">2.3 <strong>GraphSAGE的缺点</strong></span></h4>
<ul>
<li><strong>原GraphSAGE无法处理加权图，仅能够邻居节点等权聚合</strong>；</li>
<li>抽样引入随机过程，推理过程中同一节点embedding特征不稳定；</li>
<li>抽样数目限制会导致部分局部信息丢失；</li>
<li>GCN网络层太多容易引起训练中过度平滑问题。</li>
</ul>
<h4><span id="24-graphsage的优化">2.4 <strong>GraphSAGE的优化</strong></span></h4>
<p>为解决上述GraphSAGE存在的缺点，对GraphSAGE进行优化。</p>
<h5><span id="聚合优化">聚合优化:</span></h5>
<p>解决等权聚合的问题。相对于直接将邻居节点进行聚合，将边权重进行归一化之后，点的邻居节点的特征进行点燃，最后再进行特征融合。这样做的好处主要有两点：边权重越大的邻居，对目标节点影响越大；节点边权重归一化在预处理阶段完成，几再与目标节乎不影响算法速度。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533699.jpeg" alt="图片" style="zoom:50%;"></p>
<h5><span id="剪枝优化">剪枝优化:</span></h5>
<p>解决embedding特征不稳定的问题。<strong>在训练的过程希望通过引入随机过程防止模型出现过拟合的现象</strong>，<strong>但是在模型的推理过程式是想要去掉这样一个随机过程</strong>。直接对原始网络进行剪枝操作，仅保留每个节点权重最大的K条边，在模型进行推理的时候，会将目标节点所有的K个邻居节点的特征都聚合到目标节点上，聚合方式同样为加权的方式。<strong>这样做的好处主要有两个点：在网络结构不变的情况下，保证同节点embedding特征相同；在保证算法精度的前提下，大幅度降低图的稠密程度，降低内存开销。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533517.jpeg" alt="图片" style="zoom:50%;"></p>
<h5><span id="采样优化">==采样优化:==</span></h5>
<p><strong>解决局部信息丢失以及训练过平滑的问题</strong>。主要通过<strong>DGL的抽样方式代替原有的抽样方式</strong>，具体的做法为：提前将每一个节点的属性特征与它所有的邻居节点的属性特征的均值进行concat，这样可以使得每一个节点初始状态下已经包含了周围一些邻居节点的一些信息，通过这种方式，在采样相同节点的前提下，可以获得更多的局部信息。<strong>一般情况下，GCN模型采用两层网络模型，当增加至第三层的时候则将存在内存爆炸的问题</strong>；当增加至第四层时，则将出现过平滑的问题，将导致特征分布去重，这样则导致节点没有区分性。而采用DGL采样，通过采样两层GCN模型而实际上采样了三层，而且不会出现过平滑问题。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533122.jpeg" alt="图片" style="zoom:50%;"></p>
<h4><span id="25-效果评估"><strong>2.5 效果评估</strong></span></h4>
<p>效果评估的指标主要有两个：<strong>聚类（社区）准确率；召回恶意率</strong>。相对于原有的fastunfolding以及<strong>node2vec</strong>从聚类准确率、召回恶意率、平均社区规模、运行时间作一个横向对比：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533948.jpeg" alt="图片" style="zoom:50%;"></p>
<h4><span id="三-孤立点amp异质性">三、<strong>孤立点&amp;异质性</strong></span></h4>
<h4><span id="31黑产挖掘场景中的孤立点的解决思路"><strong>3.1
黑产挖掘场景中的孤立点的解决思路</strong></span></h4>
<p><strong>黑产用户在被处理后，通常会快速地申请新的账号或使用备用账号，因为在对黑产的挖掘过程中就不可避免地会出现孤立点</strong>，类似在推荐算法中的冷启动问题。以node2vec算法为例，算法通常会通过游走去构造训练的节点段，那么如果孤立节点没有连边的话，节点是无法出现在训练集当中。<strong><font color="red">
为了解决该问题，引入一个解决推荐系统冷启动的算法——EGES</font></strong>，将每一个节点的属性特征映射到一个embedding特征，然后将每一个属性的embedding特征置于注意力层进行处理，比如将N个随机特征通过注意力加权，可以获得最终的一个节点层面的embedding特征，新增的节点将不再依赖于关系网络以及用户的一些交互行为，新增的节点可以通过自身的属性特征就直接获得我们的embedding特征，不需要考虑用户关系从而解决孤立点的问题。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533883.jpeg" alt="图片" style="zoom:50%;"></p>
<p>在具体落地过程中，提出了GraphSAGE-EGES算法，实际上是综合了两种算法的优势，GraphSAGE的节点本身的初始特征将其替换成了EGES增强之后的属性特征，通过此类方式，最终的算法框架如下图所示：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533345.jpeg" alt="图片" style="zoom:50%;"></p>
<h4><span id="32黑产网络中异质性的解决思路"><strong>3.2
黑产网络中异质性的解决思路</strong></span></h4>
<p>在正常的网络结构当中，一个用户的一阶邻居基本上都是同一类的用户，比如说在学术引用当中，一篇数据挖掘的论文，引用其的论文也多是与数据挖掘相关的。这一类的网络称之为同质性网络。<strong>但在黑产的关系网络当中，图的异质性就非常高了，黑产用户不仅仅与黑产用户相关，其也可以与正常用户建立关系，这种特殊的网络结构就会存在一些弊端</strong>，以下图异质性网络为例，圈住的正常节点的一阶邻居节点一半为恶意账号，算法进行预测、聚类时，该节点很多概率会被判定为恶意账号。圈住的恶意节点的一阶邻居3个皆为正常账号，算法进行预测、聚类时，该节点则大概率被判定为正常节点，导致算法的精度下降。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533084.jpeg" alt="图片" style="zoom:50%;"></p>
<p>为了解决上述问题，需要去考虑网络的结构是否合理。为了构建合理的网络结构，需要将恶意账号与正常账号之间存在的联系剔除掉，并将恶意账号之间的联系进行一定的增强。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533269.jpeg" alt="图片" style="zoom:50%;"></p>
<p>当网络结构合理时，算法进行预测、聚类时会更加准确，因此引入图结构学习的概念，尝试用LDS算法解决这类问题。</p>
<p>LDS算法的思想：在训练GCN模型的参数的同时对网络的结构进行调整，在最初的时候给予一个网络结构（邻接矩阵），先固定GCN的模型，然后训练邻接矩阵，通过几轮迭代之后再固定邻接矩阵，再训练GCN模型，通过几轮迭代之后，可以得出一个合理的网络结构。</p>
<p><strong>总的来说，这个算法实际上就是一个极大似然估计以及伯努利分布的问题。在LDS算法学习邻接矩阵的时候实际就是学习两个点的邻边是否应该存在，实际上为一个0-1分布。</strong>最终通过网络结构以及节点的标签去预估在当前数据标签的情况下，更应该得到什么样的一个网络结构，以上即为该算法的核心思想。</p>
<p>实际上，在许多业务场景当中会存在许多不合理的图结构，甚者在某些业务场景中不存在关系信息，这样的话，在最初达不到完整网络的情况时，通常会使用KNN的方式对网络进行初始化，然后再去学习一个更加合理的网络结构，最终达到一个更好节点预测、聚类的目的。</p>
<p><strong><font color="red">
实际上，在许多业务场景当中会存在许多不合理的图结构，甚者在某些业务场景中不存在关系信息，这样的话，在最初达不到完整网络的情况时，通常会使用KNN的方式对网络进行初始化，然后再去学习一个更加合理的网络结构，最终达到一个更好节点预测、聚类的目的。</font></strong></p>
<h3><span id="四-总结思考">四、<strong>总结思考</strong></span></h3>
<p>下面分享几点在算法落地以及算法选择中的一些工作总结与思考：</p>
<ul>
<li><strong><font color="red">
针对图算法这块，特征工程和图的构建方式是非常重要的</font></strong>。如果图的结构不合理的话，即使算法模型再强大、特征工程处理得再好，算法训练出的结果也不是最终理想的效果；</li>
<li><strong><font color="red">
多数业务场景的区分度是不一样的，不存在一个普适的算法可以解决所有业务场景存在的问题</font></strong>，如上述的FastUnfolding、node2vec在某些特定的业务场景下效果可以比GraphSAGE的效果更好，所以在面临具体问题的时候，需要结合场景作算法选择以及优化；</li>
<li><strong>在工业界落地的算法通常比较直接、明了，这样的算法往往效果更好</strong>。</li>
</ul>
<h3><span id="五-graphsage应用">五、GraphSAGE应用</span></h3>
<p>本例中的训练，评测和可视化的完整代码在下面的git仓库中</p>
<p><a href="https://link.zhihu.com/?target=https%3A//github.com/shenweichen/GraphNeuralNetwork">shenweichen/GraphNeuralNetworkgithub.com/shenweichen/GraphNeuralNetwor</a></p>
<p><strong>这里我们使用引文网络数据集Cora进行测试，Cora数据集包含2708个顶点,
5429条边,每个顶点包含1433个特征，共有7个类别。</strong></p>
<p>按照论文的设置，从<strong>每个类别中选取20个共140个顶点作为训练</strong>，<strong>500个顶点作为验证集合</strong>，<strong>1000个顶点作为测试集</strong>。
<strong>采样时第1层采样10个邻居，第2层采样25个邻居。</strong></p>
<ul>
<li>节点分类任务结果</li>
</ul>
<p>通过多次运行准确率在0.80-0.82之间。</p>
<ul>
<li>节点向量可视化</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191533940.jpg" alt="img" style="zoom:50%;"></p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>业务安全</category>
        <category>风控反作弊</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-【draft】Spotlight:Malware Lead Generation at Scale</title>
    <url>/posts/202K1SP/</url>
    <content><![CDATA[<h3><span id="spotlight-malwarelead-generation-at-scale">Spotlight: Malware
Lead Generation at Scale</span></h3>
<blockquote>
<p>原文链接：https://storage.googleapis.com/pub-tools-public-publication-data/pdf/5987ab07bad53af0a980f35849a86a655793bb17.pdf</p>
<p>原文解析：https://blog.csdn.net/ybdesire/article/details/112078223</p>
<p><strong>CrowdStrcike:</strong>https://www.crowdstrike.com/cybersecurity-101/threat-hunting/</p>
<p>VMware [Carbon
Black]:https://www.vmware.com/products/carbon-black-cloud.html</p>
</blockquote>
<p>恶意软件是当今网络安全的主要威胁之一，其应用范围从钓鱼邮件到勒索软件和特洛伊木马。由于恶意软件威胁的规模和多样性，从整体上打击它是不切实际的。相反，政府和公司成立了团队，专门识别、优先排序和删除直接影响其人口或商业模式的特定恶意软件系列。根据我们的调查，识别最令人不安的恶意软件系列（称为恶意软件搜索）并确定其优先级是一项耗时的活动，占典型威胁情报研究人员工作时间的20%以上。为了节省这一宝贵资源，扩大团队对用户在线安全的影响，我们推出了<strong>Spotlight，这是一个大规模恶意软件潜在客户开发框架</strong>。<strong>Spotlight首先根据第一方和第三方威胁情报筛选大型恶意软件数据集，以删除已知的恶意软件系列</strong>。然后，它将剩余的恶意软件分为可能未被发现的系列，并根据其潜在的业务影响对它们进行排序，以便进行进一步调查。我们对670万个恶意软件样本进行了评估，以表明它可以产生纯度超过99%（即同质性）的最高优先级集群，这比更简单的方法和之前的工作更高。为了展示Spotlight的有效性，我们将其应用于对真实数据的广告欺诈恶意软件搜索。利用Spotlight的输出，威胁情报研究人员能够快速识别三个执行广告欺诈的大型僵尸网络。</p>
<h5><span id="这篇论文首先抛出了一个痛点malwarehuting">这篇论文首先抛出了一个痛点：Malware
Huting</span></h5>
<ul>
<li>做<code>malware hunting</code>，就是从海量样本中找出值得关注的</li>
<li>这种<code>malware hunting</code>的工作，一般是Researcher来进行的（借助于一些信息做关联分析、手工分析样本）</li>
<li><code>malware hunting</code>的工作，做起来非常耗时间</li>
</ul>
<p><strong>Google为了解决这个痛点，就设计了Spotlight这个系统，结合了深度学习分类器，无监督聚类，动态静态分析，规则式判断。</strong></p>
<h5><span id="malwarehunting-malware-classification-malware-clustering-malwareprioritization">Malware
hunting = Malware classification + Malware clustering + Malware
prioritization</span></h5>
<h5><span id="spotlight大致的工作流程为">Spotlight大致的工作流程为：</span></h5>
<ul>
<li>输入：大量malware样本</li>
<li>处理：移除大量已知family的样本</li>
<li>输出：少量未知family的样本（人工从中找到新threat）</li>
<li>每个样本都有score：根据打分来判断malware对business的影响程度，从而得到人工分析的样本优先级</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-【draft】MOTIF: A Large Malware Reference Dataset with Ground Truth Family Labels</title>
    <url>/posts/9P3K1N/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-【draft】阿里云-webshell查杀</title>
    <url>/posts/1VTV8G0/</url>
    <content><![CDATA[<h3><span id="深度学习phpwebshell查杀引擎demo">深度学习PHP
webshell查杀引擎demo</span></h3>
<p>https://www.cdxy.me/?p=788</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-阿里云恶意软件检测平台</title>
    <url>/posts/H1YMKT/</url>
    <content><![CDATA[<h2><span id="一-阿里云恶意文件检测平台">一、阿里云恶意文件检测平台</span></h2>
<p>Linux沙箱 ｜
阿里云恶意文件检测平台开放Linux二进制文件检测：https://www.anquanke.com/post/id/276349#10006-weixin-1-52626-6b3bffd01fdde4900130bc5a2751b6d1</p>
<h3><span id="11-简介">1.1 简介</span></h3>
<p>在病毒检测方向，一直以来常见的两种手段就是<strong>静态特征检测</strong>与<strong>动态行为检测</strong>。两者各有优势与不足，<strong>静态特征检测方案实施成本更低，检出结果也更精准，但是其泛化能力不足</strong>，针对具有高级对抗能力的恶意文件显得力不从心，并且天然地处于被动的地位，人力运营成本会更高。</p>
<p>动态行为检测实施成本相对较高，需要有足够的资源，而且检出的结果在一定程度上不如静态检测精准，但是它最大的优势是可以从<strong>恶意行为、技术手段</strong>的角度识别恶意文件，具有极大的泛化能力。对于需要检测大量恶意文件的安全厂商来说，人工运营所有样本并提取静态特征是不现实的，而沙箱的作用也就显现出来了：在海量的文件中，识别出最值得关注的恶意文件。</p>
<h3><span id="12-沙箱优势">1.2 沙箱优势</span></h3>
<h4><span id="高性能的环境仿真">高性能的环境仿真</span></h4>
<p><strong>云沙箱依托于阿里云神龙架构，在具备高性能的仿真的同时，还支持资源池化和自动化运维的能力</strong>。利用自定义的虚拟化技术和定制的沙箱OS内核，对恶意样本使用的反虚拟化的技术具备天然的对抗能力，配合上专门打造的二进制检测探针，可以在安全、高效、仿真的隔离环境中对二进制进行深度的行为分析。</p>
<h4><span id="全面的动态行为分析">全面的动态行为分析</span></h4>
<p><strong>基于虚拟化构建的沙箱深度分析技术，对进程、文件、网络、敏感系统调用、rootkit、漏洞利用等进行全面监控</strong>，配合智能模型规则检测引擎，快速分析出样本潜在的恶意行为。</p>
<h4><span id="海量的数据积累">海量的数据积累</span></h4>
<p>阿里云沙箱服务于阿里云安全云上恶意文件检测，积累了海量样本数据，提炼出大量有独检优势的行为检测规则。</p>
<h3><span id="33-检测优势">3.3 检测优势</span></h3>
<h4><span id="算法模型覆盖未知威胁">算法模型——覆盖未知威胁</span></h4>
<p>基于阿里云平台海量样本数据和强劲计算能力，<strong>采用“机器智能(神经网络)”与“专家智能(行为标签、ATT&amp;CK)”结合的智能安全思想</strong>，挖掘海量样本数据中可疑内容信息和行为标签威胁值，构建智能的威胁检测模型发现新威胁。</p>
<p>将专家知识与海量数据结合智能化构建以<strong>ATT&amp;CK为核心的多模态特征表示</strong>，对样本行为从技术战术度量、敏感信息表征、意图逻辑推理等角度进行多维度刻画、分析，同时依赖机器智能的学习泛化能力、检测模型能覆盖更多的未知，拓展威胁发现边界。</p>
<figure>
<img src="https://p2.ssl.qhimg.com/t019938cd9a1afcd563.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-阿里云-郑翰-安全智能应用</title>
    <url>/posts/3FC64SH/</url>
    <content><![CDATA[<h2><span id="安全智能应用的一些迷思"></span></h2>
<h4><span id="1-文章主旨">1、文章主旨</span></h4>
<p>本文是一个面向安全学术圈和工业界同行的介绍性和探讨性议题，议题的前半部分会介绍一些工业实践中被证明有效的落地实践，后半部分更多地是希望抛砖引玉，通过抽象和定义最新的问题，吸引更多学术研究员的关注和合作。</p>
<h4><span id="2-目前可以做到哪些">2、目前可以做到哪些</span></h4>
<p>第一部分，本次演讲从目前工业界中智能算法的一些落地实践情况切入说起，总结目前智能安全从概念到落地的应用情况，主要目的是希望阐述，有哪些问题是已经得到解决，或者部分解决的，包括:</p>
<ol type="1">
<li><strong>在海量、富类型的样本集支持下，现有的深度学习和机器学习框架已经可以很好的实现有监督学习和预测的目标</strong>，复杂模型结构层面的调整对最终结果的提升非常有限，更多的瓶颈是在如何发现更多的打标数据上，即<strong>样本集概率空间覆盖度问题</strong>。</li>
<li><strong>文本内容检测</strong>是现在落地应用最多的场景之一(例如<strong>WAF</strong>、<strong>Webshell检测</strong>、<strong>二进制病毒检测</strong>、<strong>网页敏感内容检测</strong>、<strong>明码流量检测</strong>等)，<strong>传统的NLP和图形领域的特征工程和建模方法可以较好发挥作用</strong>。</li>
<li>针对<strong>简单场景问题</strong>(例如<strong>暴力破解攻击检测</strong>、<strong>异地登录检测</strong>、<strong>真实入侵证据发现</strong>)，<strong>简单统计</strong>和<strong>假设检验</strong>可以发挥较好作用。</li>
<li><strong>时序建模</strong>和<strong>时序异常检测算法</strong>在<strong>ddos、cc、定点API接口爆破检测</strong>上可以发挥较好效果，但受限于安全领域中存在较多的突然性、偶然性事件，时序周期性假设常常无法成立，这点极大限制了时序异常检测算法在安全领域内的应用。</li>
<li><strong>相似性匹配算法</strong>(例如<strong>simhash、ssdeep、kmeans</strong>)目前的主要落地场景主要是，扩展原有规则模型的泛化能力。纯粹无监督的相似性聚类由于缺乏可解释性，目前更多用于辅助专家决策。</li>
</ol>
<p>总结来说，当前工业界和学术界智能算法的应用可以综合概括为，"<strong>基于历史经验样本下的的拟合学习</strong>"，即”<strong>基于知识的对抗</strong>“，机器学习在其中充当的角色更多地是一种记忆学习，缺点是难以提供更多的泛化检测和0day发现能力。</p>
<h4><span id="3-还未解决的难题">3、还未解决的难题</span></h4>
<p>第二部分，笔者希望将我们在企业一线工作的经历进行总结和抽象，将目前智能安全中的一些未解决问题，用学术课题的方式明确地定义出来，将智能安全中的问题转化为学术研究课题，目标是争取更广大的国内科研高效和机构的研究力量，将更多的研究重点投入在实际的问题上，避免对历史老问题的重复研究和建设，包括:</p>
<ol type="1">
<li><strong>安全风险定量评估函数建模</strong>:
以恶意样本检测为例，恶意样本检测0day发现能力(对未知的未知发现能力)本质上是一个搜索优化问题，如何对每一个样本的威胁性(值越大表示恶意性越大，0或负值表示是正常样本)进行定量的定义和分析，是问题的关键。<strong>定义了明确的量化损失函数，恶意样本的检测就会从有监督学习问题转化为搜索优化问题。</strong></li>
<li><strong>基于威胁性定量评估损失函数下的随机搜索问题</strong>:
在基于对各个场景建立了明确的损失函数(例如某个ttp的风险分值、某个http
payload的恶意分值、某个文本文件的恶意分值)之后。接下来的工作就是结合安全问题的特点，开发针对性的优化搜索算法，例如<strong>蒙特卡洛搜索</strong>、<strong>随机梯度下降搜索</strong>。</li>
<li>非完整观测下的复杂事件动态推理过程:
入侵检测是安全攻防领域一个很重要的问题，这个问题本质上是一个<strong>复杂事件马尔科夫推理过程</strong>，各种日志采集点代表了可观测量，但实际情况是，我们永远不可能获得一个安全事件的完整观测视角(受限于日志采集的种类和完整性)。所以安全研究员要解决的问题是，<strong>如果在不完整观测的条件下，进行贝叶斯信念网络的建模，并基于该信念网络进行复杂事件推理</strong>。</li>
<li><strong>模型衰减对抗问题</strong>:
类似于自然界所有物理都在朝着熵增的方向演进，安全攻防中的所有模型都存在”性能衰退“的问题，在开发测试阶段完美适配了当前问题场景的模型在上线运行一段时间后，面临误报和漏报的风险会不断提高。</li>
<li>针对攻击入侵链路回溯的有向无环图推理问题:
入侵回溯场景中面对的主要问题有如下几不同事件节点之间的因果依赖推导:
因为攻击在逻辑上是存在逻辑先后关系的多条路径(攻击事件链路)的合并:
一台机器可能不只遭到一次和一个攻击者的攻击异构节点的融合:
一次成功的入侵回溯包括对已知告警节点的因果串联，以及融合其他可以提供更多线索证据的日志节点这两项工作子图融合:
从不同的日志视角可能获得多条攻击链路，入侵回溯师需要能够识别出其中的底层联系，将多条攻击链路合成到一个大的攻击视角中，为后续的决策提供更丰富的攻击者和攻击面信息。</li>
</ol>
<h4><span id="4-我们目前在尝试的项目">4、我们目前在尝试的项目</span></h4>
<p>第三部分，笔者会介绍一些目前我们公司团队在进行的课题研究方向，包括，</p>
<ol type="1">
<li>通过LSTM自动生成webshell黑样本</li>
<li>基于<strong>GAN网络绕过</strong>现有深度学习AV检测模型</li>
<li>基于<strong>遗传优化算法</strong>的的自动化0day样本生成</li>
<li><strong>基于贝叶斯信念网络的入侵回溯推理</strong></li>
<li><strong>==通过攻击链路中已回溯出来的信息（进程、网络、文件）横向关联其他被这个团伙入侵的机器，然后继承他们的入侵原因==</strong></li>
</ol>
<h4><span id="5-历史外部演讲">5、历史外部演讲</span></h4>
<ul>
<li>《云环境自动化入侵溯源实战》, KCon 2019 [<a href="http://link.zhihu.com/?target=https%3A//static.cdxy.me/201908-%E4%BA%91%E7%8E%AF%E5%A2%83%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E4%BE%B5%E6%BA%AF%E6%BA%90%E5%AE%9E%E6%88%98-KCon.pdf">slides]</a></li>
<li>"Hunting zero-days for millions of websites on Alibaba Cloud", XCon
2019 [<a href="http://link.zhihu.com/?target=https%3A//static.cdxy.me/XCON-2019-EN.pdf">slides]</a></li>
<li>"Webshell Detection via Attention-Based Opcode Sequence
Classification", Artificial Intelligence for Business Security Workshop
(AIBS @ IJCAI-19). Macao, CN. 10-12 Aug 2019. [<a href="http://link.zhihu.com/?target=https%3A//static.cdxy.me/AIBS_2019_paper_3.pdf">paper]</a></li>
<li>"Enhance Security Awareness with Data Mining", BlueHat Shanghai
2019</li>
<li>[<a href="http://link.zhihu.com/?target=https%3A//www.butian.net/datacon">DataCon
2019]</a> 1st place solution of malicious DNS traffic &amp; DGA
analysis. [<a href="http://link.zhihu.com/?target=https%3A//www.cdxy.me/%3Fp%3D806">writeup]</a></li>
<li>《企业安全数据分析思考与实践》, FreeBuf公开课 [<a href="http://link.zhihu.com/?target=http%3A//static.cdxy.me/data-knowledge-action_cdxy.pdf">slides]</a></li>
<li>《从数据视角探索安全威胁》, 先知白帽大会2018 [<a href="http://link.zhihu.com/?target=https%3A//xzfile.aliyuncs.com/upload/zcon/2018/10_%E4%BB%8E%E6%95%B0%E6%8D%AE%E8%A7%86%E8%A7%92%E6%8E%A2%E7%B4%A2%E5%AE%89%E5%85%A8%E5%A8%81%E8%83%81_cdxy.pdf">slides]</a></li>
</ul>
<h2><span id="企业安全数据分析实践与思考">企业安全数据分析实践与思考</span></h2>
<p>https://live.freebuf.com/detail/c5e504cf96a4e1826a609553bf6054f9</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地【draft】AVclass2-Massive Malware Tag Extraction from AV Labels</title>
    <url>/posts/35YGSMK/</url>
    <content><![CDATA[<h3><span id="avclass2massive-malware-tag-extraction-from-av-labels">AVclass2:
Massive Malware Tag Extraction from AV Labels</span></h3>
<h3><span id="参考文献">参考文献</span></h3>
<ul>
<li><p>https://mzgao.blog.csdn.net/article/details/109628163</p></li>
<li><p>AVCLASS: A Tool for Massive Malware
Labeling：https://link.springer.com/chapter/10.1007/978-3-319-45719-2_11</p></li>
<li><p>AVclass2: Massive Malware Tag Extraction from AV
Labels：https://arxiv.org/pdf/2006.10615.pdf</p></li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意加密流量（1）DataCon2020恶意加密流量检测</title>
    <url>/posts/3G00B93/</url>
    <content><![CDATA[<h2><span id="datacon2020-恶意加密流量检测">DataCon2020-恶意加密流量检测</span></h2>
<blockquote>
<ul>
<li>思科AISec’16：《Identifying Encrypted Malware Traffic with
Contextual Flow
Data》：https://www.cnblogs.com/bonelee/p/9604530.html</li>
</ul>
</blockquote>
<h2><span id="一-流量处理的工具">一、流量处理的工具</span></h2>
<h3><span id="zeek"><strong>zeek</strong></span></h3>
<p><a href="https://darkdefender.medium.com/https-medium-com-melanijan93-analysing-pcaps-with-bro-zeek-33340e710012">使用
Bro/Zeek 分析 PCAP</a></p>
<p><a href="https://www.freebuf.com/sectool/235587.html">流量分析的瑞士军刀：Zeek</a></p>
<h3><span id="joy">joy</span></h3>
<p><a href="https://github.com/ahlashkari/CICFlowMeter">CICFlowMeter</a>：</p>
<h2><span id="二-anovel-malware-encrypted-traffic-detectionframework-based-on-ensemblelearning">二、A
Novel Malware Encrypted Traffic DetectionFramework Based On Ensemble
Learning</span></h2>
<blockquote>
<p>zeek:https://docs.zeek.org/en/master/logs/index.html
zeek-flowmeter:https://github.com/zeek-flowmeter/zeek-flowmeter
zeek-tls-log-alternative:https://github.com/0xxon/zeek-tls-log-alternative</p>
</blockquote>
<h4><span id="概述">概述：</span></h4>
<p>在我们的工作中，有一些定义。首先，<strong>将5元组定义为源IP、源端口、目标IP、目标端口和协议</strong>。<strong>其次，前向流是从客户端到服务器具有相同5元组的数据包集</strong>。反向词流与正向流相似，但与五元组相反。最后，流动是向前流动和向后流动的结合。由于我们从流量中提取的特征是异构的，我们不能简单地将它们合并并以常见的方式将它们装配到单个分类器中。我们将不同的特征匹配到相应的分类器中，并进行多数投票以获得最终结果。同时，我们考虑了flowlevel和host级别的行为。对不同级别的特性进行聚合和分析，以提高框架的TPR和较低的FPR。图1：。概述了我们的框架。我们将介绍每个特性以及相应的分类器、实现和性能。</p>
<h3><span id="21-数据包级">2.1 数据包级</span></h3>
<h4><span id="1长度分布">（1）长度分布</span></h4>
<p>根据Cisco的研究【17】，<strong>恶意软件和普通软件在正向流和反向流中的数据包长度分布不同</strong>。<strong><font color="red">
例如，当我们使用谷歌搜索时，客户端向服务器发送少量数据包，然后服务器返回大量数据包。然而，恶意软件的作用恰恰相反：恶意软件通常让客户端将数据传输到服务器，然后服务器定期返回调度命令。</font></strong>无论是否加密，数据包长度始终可见，因此它适合作为一种功能。我们将数据包长度和方向编码为一维独立特征。我们推测，感染恶意软件的客户端和服务器之间的一些控制消息的长度总是相似且频繁的，这具有很好的区分程度。<strong>我们考虑每个可能的数据包长度和方向元组。由于Internet上的最大传输单元（MTU）是1500字节，并且数据包的方向有两个发送或接收方向，因此我们的长度分布特征是3000维。</strong>为了提取这些特征，我们计算具有不同长度的所有数据包的数量，并进行规范化以确保概率分布。我们使用随机森林（RF）算法来处理这些特征。因为它能更好地处理高维特征，并且具有可解释性。</p>
<h4><span id="2长度序列">（2）长度序列</span></h4>
<p>第二部分，在不使用序列信息的情况下，我们只使用了数据包长度的统计特征，这可能会在时间上丢失一些信息，因此我们提取了数据包长度序列。<strong>我们在每个客户端的双向上取前1000个数据包长度</strong>，并将其放入TextCNN算法中以提取局部序列关系。因为该算法运行速度快，精度高。文本数据的卷积神经网络TextCNN【22】是一种用于句子分类任务的有用的深度学习算法。<strong>在这种情况下，我们将每个数据包的长度视为一个单词，长度序列相当于一个句子</strong>。</p>
<h4><span id="3服务器ip">（3）服务器IP</span></h4>
<p>在我们的数据集中，服务器IP地址是一个重要的标识符。<strong>我们假设，在同一地区，如果客户端感染了相同的恶意软件，则可能会导致其访问相同的服务器IP地址</strong>。因此，我们还考虑了对服务器IP地址的访问。<strong>值1或0表示是否访问了特定的服务器IP地址（一个热编码）</strong>。我们使用朴素贝叶斯（NB）算法来处理这些特征。由于朴素贝叶斯算法是一种非参数算法，其本质是寻找特征和标签之间的关系。因此，它可以被视为一个黑名单。</p>
<h4><span id="4词频分类器">（4）词频分类器</span></h4>
<p><strong>X509证书在Internet上广泛使用</strong>。它们用于验证实体之间的信任。证书颁发机构通常将X509证书链接在一起。如图2所示。[23]，<strong>X509证书提供URL、组织、签名等信息</strong>。我们从培训集中每个客户端的TLS流中提取X509证书链，并获取证书中<strong>主题</strong>和<strong>颁发者</strong>中包含的单词。我们将所有单词组合在一起，并将客户的流量视为由这些单词组成的句子。与B部分类似，我们计算每个单词的数量并将其用作特征。0我们使用朴素贝叶斯（NB）算法来处理这些特征。如果测试集样本证书中的所有单词从未出现在训练集中，我们将直接推断它是恶意的。因为训练集包含最流行的域名。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182036362.png" alt="image-20220621131035005" style="zoom: 67%;"></p>
<h4><span id="5tcp状态马尔可夫">==（5）TCP状态马尔可夫==</span></h4>
<p>我们发现<strong>恶意流量和正常流量之间TCP连接状态的分布是不同的</strong>。表一说明了可能的TCP连接状态<a href>24</a>:</p>
<blockquote>

</blockquote>
<p>我们按照流出现的时间对其进行排序，然后使用马尔可夫随机场转移矩阵（MRFTM）对该特征进行编码。MRFTM在建模连接状态序列时很有用。MRFTM[i，j]中的每个条目统计第i个和第j个状态之间的转换次数。最后，我们对MRFTM的行进行规范化，以确保适当的马尔可夫链。然后我们将其重塑为一维向量，也就是说，我们使用MRFTM的条目作为特征。我们使用随机森林（RF）算法来处理这些特征。</p>
<h3><span id="22-会话流级">2.2 会话流级</span></h3>
<h4><span id="6会话流量统计">（6）会话流量统计</span></h4>
<p>在加密流量中，上述5种分类器在主机级使用不同的特征提取方法和分类方法。此外，为了进一步提高准确率，防止恶意软件由于缺乏领域知识而欺骗分类器，我们还提取了TLS握手中的明文信息。在这个分类器中，我们首先考虑流级特征。我们仅选择TLS流，并分析每个流。一旦推断流是恶意的，就会推断相应的客户端被感染。我们对TCP和TLS协议进行了深入分析，<strong>提取了1000多个维度的流级特征</strong>，包括以下部分：</p>
<ul>
<li><strong>TCP连接状态特性</strong>：如F部分所述，我们对每个流的TCP连接状态进行一次热编码。</li>
<li><strong>统计特征</strong>：我们还提取常规统计特征，表II显示了相关特征名称和描述。</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037399.png" alt="image-20220621141516374" style="zoom: 50%;"></p>
<ul>
<li><p><strong>长度马尔可夫特征</strong>：数据包长度序列的操作类似于F部分中的TCP连接状态序列。长度值被离散为大小相等的容器。长度数据马尔可夫链有10个箱子，每个箱子150字节。假设一个1500字节的MTU，任何观察到的大小大于1350字节的数据包都被放入同一个bin中。</p></li>
<li><p><strong>TLS握手功能</strong>：我们发现客户端和服务器的TLS协议版本在恶意和良性TLS流之间有不同的分布，因此我们对客户端和服务器的TLS版本进行了一次热编码。此外，由于恶意软件可能使用旧的密码套件，我们在客户端和服务器上都对密码套件和扩展进行n-hot编码，即将所有密码套件和扩展扩展扩展为一维0向量，如果当前流使用某个密码套件或扩展，则相应的位置集值为1。</p></li>
<li><p><strong>TLS证书特性</strong>：我们发现，在恶意流中，很大一部分叶证书是自签名的，或者自签名证书出现在证书链中。恶意软件喜欢利用的自签名证书的成本很低。因此，我们分析从服务器发送的证书：<strong>证书链是否包含自签名证书、叶证书是否过期、证书版本、证书有效期、公钥长度、是否发生警报</strong>。同时，考虑到之前的词频分类器，我们发现一些词无法区分恶意和良性，因此我们还将流词频添加到流特征中。</p></li>
<li><p>合并和适配：我们将上述功能合并到5元组（源IP、目标IP、源端口、目标端口和协议）中，并将其适配到随机林（RF）算法中。一旦流被推断为恶意，相应的客户端就会被推断为受到恶意影响。</p></li>
</ul>
<p>在本节中，我们使用来自真实恶意软件的加密流量来评估我们的框架。首先，我们描述了数据集的格式。其次，我们分析了每个分类器的有效性以及集成后的有效性。然后，我们展示了我们的集成学习方法的优势。</p>
<h4><span id="数据表示">数据表示：</span></h4>
<p>如表三所示，列车数据包括3000台正常主机产生的正常流量和3000台恶意软件感染主机产生的恶意流量。我们的任务是检测测试数据中的客户端IP地址是否感染了恶意软件。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037660.png" alt="image-20220621132459446" style="zoom:50%;"></p>
<p><strong>表V显示了每个分类器的得分</strong>。我们将每个分类器与投票结果进行比较，发现集成后的最终效果优于任何单个分类器的得分。我们的方法得分为86.6，TPR为95.0%，FPR为8.4%。流量统计分类器得分最高，其次是长度序列分类器和长度分布分类器。我们在每个分类器中使用默认参数。由于流级特征包含最丰富的信息，因此<strong>流统计分类器的性能最好</strong>，正如我们所期望的那样。我们可以推断，<strong>数据包长度</strong>是一个重要特征。事实上，在流量分类（非恶意流量检测）领域，有很多优秀的作品使用数据包长度进行分类，并取得了很好的效果[11][25]。目前，已有的一些基于机器学习的工作[8][9]与我们的流统计分类器或流合并分类器相似，也就是说，它们只使用流级特征或主机级特征。经过实验，我们的最终效果已经超过了每一个分类器。这表明我们的框架是有效和健壮的。此外，框架可以很容易地调整每个分类器的概率阈值，以提高TPR或降低FPR，以适应不同的场景。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037087.png" alt="image-20220621132751726" style="zoom:50%;"></p>
<h2><span id="三-知乎-s1mple">三、知乎-s1mple</span></h2>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/262533938"><em>DataCon</em>2020<em>加密</em>恶意<em>流量</em>检测初赛Writeup及总结反思</a></p>
</blockquote>
<ul>
<li><p><strong>特征选择（Feature
Selection）</strong>，选取对于区分正常/恶意流量有明显作用的
Features。</p>
<ul>
<li><strong>TLS客户端指纹信息</strong>
<ul>
<li><strong>客户端支持的加密套件数组</strong>（Cipher
suites），<strong>服务器端选择的加密套件</strong>。</li>
<li><strong>支持的扩展</strong>（TLS
extensions），若分别用向量表示客户端提供的密码套件列表和 TLS
扩展列表，可以从服务器发送的确认包中的信息确定两组向量的值。</li>
<li><strong>客户端公钥长度</strong>（Client public key
length），从密钥交换的数据包中，得到密钥的长度。</li>
<li><strong>Client version</strong>，the preferred TLS version for the
client</li>
<li><strong>是否非CA自签名</strong>，统计数据表示，恶意流量约70%出现非CA认证服务器且自签名的情况，非恶意流量约占0.1%。此项判断的依据是：未出现
<code>CA: True</code> 字段（默认非 CA 机构）且
<code>signedCertificate</code> 中的 <code>issuer</code> 字段等于
<code>subject</code> 字段。</li>
</ul></li>
</ul>
<blockquote>
<p>在进行TLS握手时，会进行如下几个步骤：</p>
<ol type="1">
<li><strong>Client Hello</strong>，客户端提供支持的加密套件数组（cipher
suites）；</li>
<li><strong>Server
Hello</strong>，由服务器端选择一个加密套件，传回服务器端公钥，并进行认证和签名授权（<strong>Certificate</strong>
+ Signature）；</li>
<li>客户端传回客户端公钥（<strong>Client Key
Exchange</strong>），客户端确立连接；</li>
<li>服务器端确立连接，开始 HTTP 通信。</li>
</ol>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037145.jpg" alt="img" style="zoom:50%;"></p>
</blockquote>
<ul>
<li><strong>数据包元数据</strong>
<ul>
<li><strong>数据包的大小</strong>，数据包的长度受 UDP、TCP 或者 ICMP
协议中数据包的有效载荷大小影响，如果数据包不属于以上协议，则被设置为 IP
数据包的大小。</li>
<li><strong>到达时间序列</strong></li>
<li><strong>字节分布</strong></li>
</ul></li>
<li><strong><font color="red"> HTTP头部信息</font></strong>
<ul>
<li><strong>Content-Type</strong>，正常流量 HTTP 头部信息汇总值多为
<code>image/*</code>，而恶意流量为
<code>text/*、text/html、charset=UTF-8</code> 或者
<code>text/html;charset=UTF-8</code>。</li>
<li><strong>User-Agent</strong></li>
<li><strong>Accept-Language</strong></li>
<li><strong>Server</strong></li>
<li><strong>HTTP响应码</strong></li>
</ul></li>
<li><strong><font color="red"> DNS响应信息</font></strong>
<ul>
<li><strong>==域名的长度==</strong>：正常流量的域名长度分布为均值为6或7的高斯分布（正态分布）；而恶意流量的域名（FQDN全称域名）长度多为6（10）。</li>
<li><strong>==数字字符及非字母数字(non-alphanumeric
character)的字符占比==</strong>：正常流量的DNS响应中全称域名的数字字符的占比和非字母数字字符的占比要大。</li>
<li><strong>DNS解析出的IP数量</strong>：大多数恶意流量和正常流量只返回一个IP地址；其它情况，大部分正常流量返回2-8个IP地址，恶意流量返回4或者11个IP地址。</li>
<li><strong>TTL值</strong>：正常流量的TTL值一般为60、300、20、30；而恶意流量多为300，大约22%的DNS响应汇总TTL为100，而这在正常流量中很罕见。</li>
<li><strong>域名是否收录在Alexa网站</strong>：恶意流量域名信息很少收录在Alexa
top-1,000,000中，而正常流量域名多收录在其中。</li>
</ul></li>
</ul></li>
<li><p><strong>特征提取（Feature Extraction）</strong>，从 pcap
文件中提取上述
Features，并转换为模型训练所需要的格式。我们选择的特征提取工具为
<strong>Zeek</strong>。特征提取我们采用的工具是
<strong>Zeek</strong>，它的前身是 Bro，一款网络安全监视（Network
Security Monitoring）工具，它定义了自己的 DSL 语言，<strong>支持直接处理
pcap 文件生成各类日志文件</strong>，包括 dns、http、smtp 等：Zeek
网上有一些现成的脚本，我们采用的是 <strong>Zeek
FlowMeter</strong>，它基于 OSI
七层协议的网络层和传输层，可以分析并生成一些 Packets
到达时间序列、Packet
字节大小和元数据等新特征。<strong>在使用时，我们需要在
<code>local.zeek</code> 配置文件中加入
<code>@load flowmeter</code>，这样 Zeek 在执行时会加载
<code>flowmeter.zeek</code> 并生成对应的
<code>flowmeter.log</code>，下面列出了 FlowMeter
提取出的一些特征，包括上下行包总数、包负载均值方差等。</strong>其他详细的特征请见
<a href="https://link.zhihu.com/?target=https%3A//github.com/zeek-flowmeter/zeek-flowmeter">zeek-flowmeter
GitHub官方文档</a>。除 <code>flowmeter.log</code> 之外我们还需要关注
<code>conn.log</code>、<code>ssl.log</code> 和
<code>X509.log</code>。这几个日志共同字段 <code>uid</code> 是 Zeek
根据一次连接的源/目的 IP、源/目的端口四元组生成的唯一
ID。为了方便后续的处理，我们将这几个日志文件统一读入，使用
<code>uid</code> 字段连接后转成 csv
格式输出到文件。<strong>最终我们提取的特征如下：</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037409.png" alt="image-20220621141516374" style="zoom: 50%;"></p></li>
<li><p><strong>模型训练（Model
Training）</strong>，选择合适的机器学习模型对三类 pcap
文件进行训练和预测。我们选择的 Python 机器学习库为
<strong>scikit-learn</strong>。</p>
<ul>
<li><strong>Anomaly Detector</strong>：在 black
数据集中同时存在恶意流量和正常流量，没有明确的标注，无法直接用于训练分类器。而
white 数据集中都是正常流量，可以先用 white 数据集来训练一个 Anomaly
Detector 分类器。然后用这个分类器在 black
数据集中推理得到哪些是恶意流量。我们的模型选取的隔离森林
<code>IsolationForest</code>。</li>
<li><strong>Misuse
Detector</strong>：<strong>假设这些由异常检测器识别的可疑流量是恶意流量，我们就有了恶意流量的标注</strong>。接下来我们用这些恶意流量
labels，结合 white 数据集中的正常流量 labels，来训练一个 Misuse
Detector。我们选取了 XGBoost
基于树的模型，目标选取为多分类问题（分类数为2）。</li>
</ul></li>
</ul>
<h2><span id="四-加密恶意流量检测方向清华大学hawkeye战队"><strong><font color="red">四
、加密恶意流量检测方向（清华大学HawkEye战队）</font></strong></span></h2>
<blockquote>
<p><strong>清华大学HawkEye战队</strong>：https://datacon.qianxin.com/blog/archives/122</p>
</blockquote>
<h3><span id="41-概述">4.1 概述</span></h3>
<p>我们所采用的检测方法的总体结构是让多个分别利用不同的<strong>异构特征训练</strong>而成的分类器进行多数投票
(Majority Voting) 的方式来获取最终的判定结果。</p>
<p><strong>由于我们所采用的多种特征是异构数据，
且具有不同的组织特点，我们并没有直接采用将这些特征统一编码并输入到集成学习分类器中的常规方式，而是针对各个特征的特点分别构建对应的分类器</strong>，并利用他们的分类结果进行投票，最终取得多数票的分类结果被定为最终的分类结果。</p>
<p>参与投票的多个模型中部分使用了多维特征综合分析，<strong>另一部分使用经过分析后黑白样本区分较大的、置信度较高的单维特征对多维特征中的潜在的过拟合和判断错误进行消解</strong>。同时，我们考虑到了<strong>数据包级、流级、主机级多维度的行为建模</strong>，将不同层次的数据进行聚合分析，提升对于黑白样本建模的准确度。图<a href="applewebdata://7EAAA994-C40A-4F1C-A798-46DA93A65C37#_bookmark0">1</a>展
示了我们方案的整体流程。下面我们将分别介绍我们所采用的特征及对应的分类器、投票机制、
实现和性能以及展望和总结。</p>
<h3><span id="42-特征选取与子分类器">4.2 <strong>特征选取与子分类器</strong></span></h3>
<p>下面我们将详细介绍六个参与投票的子模型中的每一个模型所采用的特征及对应的分类器，
以及设计的动机和意义。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037655.png" alt="image-20220621153938899" style="zoom: 50%;"></p>
<h4><span id="1包长分布特征3000维">（1）<strong>包长分布特征</strong>（3000维）</span></h4>
<p>不同的软件在通信数据的体量上具有不同的特点，我们认为功能或实现相似的软件会具有
相同的数据包体量分布特点，正如视频软件的下行流量通常远大于上行流量，而恶意键盘记录
器的上行流量总是远大于下行流量一样。</p>
<p>将每一个可能的报文长度和方向的二元组视为包长分布特征中的一个独立的维度。由
于以太网最小帧长为64 字节，而<strong>互联网的最大传输单元通常是 1500
字节，报文的方向只有收发两个方向</strong>，我们的包长分布特征是一个维数约
3000 的概率分布。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037030.png" alt="image-20220623173625843" style="zoom:50%;"></p>
<p><strong>编码方式与分类器</strong>：</p>
<p><strong>对该特征的提取，我们采用
以频率估计概率的方式，统计每个流量样本中的各个长度和方向的报文的数量，并除以报文总
数得到其概率分布</strong>。</p>
<p>由于包长分布的特征本质上是一个离散概率分布，最直接的分类器应该是基于度量的分类
算法，通过度量分布之间的相似性大小来判断其类别所属。<strong>我们采用了
Hellinger 距离的度量方式与kNN分类算法，Hellinger
距离是在概率分布空间对欧氏距离的模拟</strong>。由于kNN算法并不需要训练过程，而在分类过程中需要计算待分类的样例与已有样本集中的每个样例的相似性度量结果，因此其运行效率十分低下，于是我们也考虑了采用随机森林的分类器来利用这一特征的方式。</p>
<h4><span id="2证书主体与签发者黑白名单特征">（2）<strong>证书主体与签发者黑白名单特征</strong></span></h4>
<p>我们认为决定一个软件是否是<strong>恶意软件不仅仅取决于其通信内容，也取决于其通信的对象</strong>，
而通信内容由于加密无法作为可辨识的特征，因此我们着重考虑了客户端流量样本中的通信对象。</p>
<p><strong><font color="red"> 在 TLS
建立连接的过程中，服务端发来的证书中的叶子证书的 Subject
字段表明了客户端的直接通信对象，而 Issuer
字段则表明了该证书的直属签发机构。</font></strong></p>
<p><strong>Subject 字段里的 common name
通常是一个域名</strong>，我们认为这将是一个很重要的标识信息，因为恶意软件与恶意域名关联的可
能性较大。图3中展示了恶意和正常证书中主体和签发者的情况，可以看出黑白样本有明显区别
并都存在着访问频次较高的项。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037876.png" alt="image-20220623191438824" style="zoom:50%;"></p>
<p><strong>编码方式与分类器</strong>：</p>
<p><strong>我们对训练集中的每个流量样本统计了其中的叶子证书所涉及到的不同
Subject 和 Issuer 的
数量，并记录每个流量样本与他们通信的频数。</strong></p>
<p><strong>X509证书在Internet上广泛使用</strong>。它们用于验证实体之间的信任。证书颁发机构通常将X509证书链接在一起。如图2所示。[23]，<strong>X509证书提供URL、组织、签名等信息</strong>。我们从培训集中每个客户端的TLS流中提取X509证书链，并获取证书中<strong>主题</strong>和<strong>颁发者</strong>中包含的单词。我们将所有单词组合在一起，并将客户的流量视为由这些单词组成的句子。与B部分类似，我们计算每个单词的数量并将其用作特征。0我们使用朴素贝叶斯（NB）算法来处理这些特征。如果测试集样本证书中的所有单词从未出现在训练集中，我们将直接推断它是恶意的。因为训练集包含最流行的域名。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037096.png" alt="image-20220621131035005" style="zoom: 67%;"></p>
<h4><span id="3通信ip-地址黑白名单特征">（3）<strong>通信</strong>
<strong>IP</strong> <strong>地址黑白名单特征</strong></span></h4>
<p>除了证书中的 Subject 和 Issuer 信息外，服务端 IP
地址是另一个表示软件通信对象的标识
符。有少数流量样本中出现了缺少证书的情况，且我们认为同一地区遭受同类恶意软件感染很
可能会造成他们对相同的 IP 地址的访问，因此我们将流量样本中的远程 IP
地址的访问情况也 作为一个判断是否包含恶意流量的依据。</p>
<h4><span id="4流级荷载无关特征提取"><strong><font color="red">
（4）流级荷载无关特征提取</font></strong></span></h4>
<blockquote>
<p>对于黑样本的流标记问题存在一定问题，由于被感染的主机也可能会进行正常通信，而且
恶意软件也可能出现正常行为</p>
</blockquote>
<p>我们首先考虑流级特征，由于 TCP
连接可以由流的四元组确定，所以恶意通信一般是指流
级别的，分析每条流的黑或白是十分合理的。我们综合考虑了已有相关工作 [<a href="applewebdata://CE580100-416D-47E9-B704-9182656D72ED#_bookmark4">1</a>–<a href="applewebdata://CE580100-416D-47E9-B704-9182656D72ED#_bookmark5">3</a>]，以及对
TCP、 TLS/SSL 协议进行深入分析，共提取了超过 1000
维与荷载无关的流级特征，包含如下几部分:</p>
<ul>
<li><strong>元数据（Metadata）</strong>：即单条流的基本统计数据，包含持续时间（duration）、总的流入（inbound）/流出（outbound）的字节数、数据包个数；</li>
<li><strong>窗口序列统计特征</strong>：我们对出/入流量分别维护了包<strong>时间间隔</strong>和<strong>包长度的窗口</strong>，每个窗口提取统计特征，包含<strong>平均值、标准差、最大值、最小值</strong>；除此而外，我们发现仅仅关注一整个窗口的特征粒度不够细化，为了更加精细化的对流量行为进行捕获和建模，我们关注窗口中的每个数据包，并使用马尔科夫转移矩阵的方式捕获相邻包之间的关系。以构建包长窗口的马尔科夫矩阵为例，我们首先将包长均匀分成
15 个桶（bin），然后建立 15×15
的矩阵，每个元素表示从行转移到列所代表的的桶，最后对矩阵进行行的归一化处理，将其转化为概率形式；</li>
<li><strong>TLS/SSL</strong>
<strong>握手包特征</strong>：首先我们发现本赛题中客户端和服务器端都出现了多种不同的协议类型，而黑和白训练集中客户端和服务器不同版本的分布是不同的，因此协议版本可以
作为一个特征，我们将客户端和服务器端使用的 TLS
版本进行独热（one-hot）编码；同时 我们关注到 Hello 包中 GMT Unix Time
字段在黑/白训练集中的分布也有所不同，因此我 们将客户端和服务器端的 GMT
Unix Time 的是否存在、是否使用随机时间编码为 0/1
的特征；此外，<strong>由于恶意软件和恶意服务器使用的加密套件和列表</strong>很有可能与正常的加密流量
有所区别，<strong><font color="red">
我们将客户端与服务器端的加密套件（列表）和扩展列表进行独热编码，即将
所有可能的加密套件和扩展列出展成一维 0
向量，当前流使用的套件和扩展对应的位置赋 值为 1；</font></strong></li>
<li><strong>TLS/SSL证书特征</strong>：服务器端证书对于区分正常和恶意流量有着重要的作用，如恶意通信的证书多采用自签名的方式。因此我们对服务器端证书进行了特征挖掘，主要选用如下的
0/1 特征：<strong><font color="red">
是否自签名、是否过期、版本号、证书有效期、公钥长度；</font></strong>同时，我们考虑到之
前模型发现有些<strong>证书主体域名</strong>单一使用无法区分黑/白的情况，因此也嵌入到多维特征中，
使用独热编码对训练集常用证书主体域名进行独热编码。</li>
</ul>
<h4><span id="5主机级荷载无关特征聚合流级统计信息">（5）<strong>主机级荷载无关特征聚合</strong>
(流级统计信息)</span></h4>
<p><strong>单独的看每条流可能漏掉了流之间的关联行为即主机级别的行为</strong>，比如恶意软件在发出正常的访问谷歌流量后可能就要开始进行恶意传输。再比如，有少量正常流也会出现自
签名，如果我们单独看流，可能就会误判，但是如果我们基于主机提取特征发现同一
IP
下有多条流都是自签名，则我们就会有很大的信心认为这是恶意的。因此，我们将上一小节中流级别
的特征进行聚合，并以流为基本单位提取主机级别特征。</p>
<p><strong>主机级特征聚合部分主要考虑了如下的特征:</strong></p>
<ul>
<li><strong>总包个数</strong>，<strong>每条流的平均包个数</strong>，<strong>时间间隔、包长的均值</strong>，以及上一个小节中证书部分的相关特
征，即<strong>自签名流数量，过期流数量，有效期过长（比如
100年）的流数量及其均值。</strong></li>
<li>TLS 半连接 和无连接</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>算法比赛</category>
        <category>网络安全</category>
        <category>加密流量检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意加密流量（2）Datacon2021恶意加密流量检测</title>
    <url>/posts/28SSFDQ/</url>
    <content><![CDATA[<h2><span id="datacon2021-网络流量分析writeup">Datacon2021 网络流量分析
Writeup</span></h2>
<h4><span id="一-恶意流量分析">一、恶意流量分析</span></h4>
<h4><span id="11-比赛题目">1.1 比赛题目</span></h4>
<p>本题文件中提供了一段时间的失陷主机的通讯流量，参赛选手需审计该流量包，进行追踪溯源，找到真正的恶意服务器，最终获取key，此外本题还设有可以获得额外分数的彩蛋题目。</p>
<p>以主机端的网络流量为基础，通过流量审计和主动探测的方式，对攻击者进行追踪溯源和行为分析。</p>
<h4><span id="二-恶意攻击指令识别">二、恶意攻击指令识别</span></h4>
<h4><span id="12-比赛题目">1.2 比赛题目</span></h4>
<p>本题中提供了一段时间的失陷主机的通讯流量和单个指令的流量样本的提供给参算选手，参赛选手需通过恶意软件通讯特征筛选出恶意流量，并通过提供的单一的下发指令流量作为样本，分析出通讯流量（http、dns、https）中下发的指令序列。</p>
<blockquote>
<p>域前置技术：</p>
</blockquote>
<p>各命令对应的数据流也有不同的特征。比如，screen
命令会有来自服务端和客户端双向的大流量，hash命令有来自服务端的大流量和客户端的小流量，sleep
命令仅有get数据包，没有post数据包等，如图所示。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037518.png" alt="image-20220618161916376">
<figcaption aria-hidden="true">image-20220618161916376</figcaption>
</figure>
<h3><span id="三-加密代理流量分析">三、加密代理流量分析</span></h3>
<h4><span id="31-比赛题目-阶段一-流量审计">3.1 比赛题目-阶段一 【流量审计】</span></h4>
<p>本题中，<strong>管理员获取了内网中由数个不明用户构建的加密代理节点</strong>，这些软件使用的通信协议不完全一致，管理员只分别提取了一定数量的样本。参赛选手需要通过不同的加密代理特征，按照样本对目标流量进行分类。</p>
<p>概述：本题共有11个加密代理。对应11个类别，其中11个类别共包含带标签样本51个。无标签样本1000个，需要们通过分析51个带有标签样本，找到11个类别所对应的具体的特征，从而对1000个测试样本进行分类。</p>
<p>由于此题类别数目较少，只有圱圱个类别，且每个类别对应的带标签样本数目也很少，因此我们采取规则匹配的方法来实现分类。我们的实验框架如图所示。</p>
<p>首先通过分析不同的类别特征制定每个类别对应的规则，从1000个测试样本的pcap包里根据规则从提取相应的数据，继而基于这些数据进行匹配分类。最终对于极少数没有匹配结果的样本，采用人工审查的方式进行分类。值得注意的是，由于同一个样本可能满足多个类别的特点，所以不同类别的规则匹配顺序会对分类结果有一定影响。</p>
<h4><span id="311-加密代理特点分析">3.1.1 加密代理特点分析</span></h4>
<p><strong>加密流量的特征</strong>一般包含<strong>协议特征</strong>、<strong>数据元统计特征</strong>。尤其应该注意<strong>TLS协议的流量特点</strong>。</p>
<p>对于恶意加密流量和良性加密流量的区别，cisco的研究表明【6】显示，对于TLS协议特征，在ClientHello数据包中，恶意软件提供于普通客户端完全<strong>不同的一组密码套件</strong>，此外，这些密码套件通常很脆弱或已经过时。相比之下，几乎所有良性应用程序都提供相同的密码套件。除此之外，<strong>恶意软件通常提供很少的扩展</strong>，而正常用户最多有9个拓展。此外<strong>客户端的公钥长度也存在很大的差异</strong>。在ServerHello和Certificate中，<strong>恶意软件查询的服务器会选择不常见的密码套件</strong>，因为优先提供的<strong>密码套件的大小受到限制</strong>。此外，证书的有效期和SAN条目数量也存在区别，而且<strong>恶意服务器发送自签名证书的比例也比普通服务器高一个数量级</strong>。</p>
<p><strong><font color="red">
对于数据元统计特征，恶意流量于良性流量的特征差异主要表现在数据信息、数据包的大小、到达时间序列和字节分布等。</font></strong></p>
<h4><span id="312-特征分析与规则制定">3.1.2 特征分析与规则制定</span></h4>
<p>基于上述加密代理的特点, 我们分析 51 个带标签的样本, 并着重关注了 TLS
特征。我们对协议信息、TLS 应用数据、TLS 握手信息、数据信息、数据
包大小等特征进行了分析, 找到了有效区分的方法。</p>
<p>其中有三个类别有明显的区别, 只关注协议信息即可区分开来</p>
<ul>
<li>类别 0 对应的 pcap 包所有的通信流量只包含 UDP 协议, 而在 11
个类别中, 只有类别 0 具有此特点。</li>
<li>类别 6 中, 发现只有类别 6 的流量中同时出现了 TCP 和 UDP 协议, 此外,
只有类别 6 中出现了 OCSP 协议。</li>
<li>类别 8 中, 我们发现了 WireGuard 协议, WireGuard 是一种 VPN 协议,
它的大量出现使得类别 8 的特 征变得明显。通过以上方法,
我们可以通过协议信息将类别 0、类别 6、类别 8 区分出来。</li>
</ul>
<p>剩下的 8 类需要我们做进一步区分, 我们发现类别 4、类别 5、类别
7、类别9 的通信流量中只包含 TCP 协议, 类别 1、类别 2、类别 3、类别 10
的通信流量 由 TCP+TLS 协议组成。</p>
<p>到了此时, 我们的进度开始变得缓慢, 因为剩下的 8 类
没有很明显的区分特征。但是在我们的不觖努力下, 我们逐渐有了突破, 我们
发现：</p>
<ul>
<li>在类别 1 中, 存在 tls.app_data 字段的前 12 位为 00:00:00:00:00:00
的流量, 如图3.2所示;</li>
<li>在类别 7 中, 存在 data.data 字段的前 6 位为 00:00:00 的 流量;</li>
<li>在类别 5 中, 存在 data.data 字段的第 5 位到第 12 位为 <span class="math inline">\(48: 00: 02: 8 \mathrm{a}\)</span> 的 流量,
如图3.3所示;</li>
<li>在类别 3 中, 存在 tls.handshake.extensions_length 字段值 为 156
的流量; 在类别 10 中, 存在 tls.handshake.ciphersuite 值为 <span class="math inline">\(0 \times 1301\)</span> 并且 tls.handshake.type
值为 2 的流量;</li>
<li>在类别 2 中, 存在 tls.handshake.ciphersuite 值为 0x1303 并且
tls.handshake.type 值为 2 的流量;</li>
<li>在类别 4 中, 存在 frame.len 值为 1514 和 71 的流量, 值得注意的是,
当出现 frame.len 为 1514 时, 通常下一 条流量的 frame.len 为 71 ;</li>
<li>在类别 9 中, 存在 data.len 的值为 1424 的流量。 综上所述,
我们可以通过以上方法将 11 个类别区分出来, 文字描述略显繁 杂,
表3.1展示了我们制定的匹配规则。</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037861.png" alt="image-20220618165211660" style="zoom:50%;"></p>
<h3><span id="32比赛题目-阶段二"><strong><font color="red"> 3.2
比赛题目-阶段二</font></strong></span></h3>
<blockquote>
<p>同一代理协议、少量样本标签</p>
</blockquote>
<p><strong>身份不明的用户或恶意软件可能使用未授权的加密代理进行通信</strong>，访问恶意网站或正常网站。确认这些行为的详细信息有利于对可疑用户行为和恶意软件进行分析，但截获的加密流量无法进行破解。</p>
<p>本题中，<strong>管理员使用机器自动产生了恶意软件与多个恶意网站（或正常网站）通信产生的，经过加密代理的流量</strong>。根据已知的信息，管理员提取了一部分可以确定类别的样本信息。参赛选手需要利用管理员生成的样本，标记每个流量包可能访问站点的标签。</p>
<h4><span id="321-概述">3.2.1 概述</span></h4>
<p><strong>题目主要考察加密流量识别能力，需要选手根据提供的已知类别样本，识别测试数据可能可能访问何种恶意站点。</strong>经过对题目和数据的初步分析，我们发现所<strong><font color="red">
提供加密流量数据均由同一加密代理软件产生</font></strong>，且数据包中并未观测到特殊应用层协议可供分析。因此，我们确定了从<strong>统计特征</strong>和<strong>行为特征</strong>两个角度角度对加密流量样本进行审计分析，深入挖掘标识访问不同恶意通信流量的有效特征，从而实现对恶意流量的自动化分类的基本思路。</p>
<p>图3.6展示了我们方案的整体流程。具体来讲，我们分别提取训练样本的<strong>多维统计特征</strong>及<strong>标识行为特征的包长序列特征</strong>，分别构建分类器，基于投票机制结合多维分类结果来获得最终判定结果，从而避免异构数据混淆和权重问题带来的误分类情况。接下来我们将分别介绍我们所采用的特征及对应的分类器、实现和性能以及展望和总结。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182037437.png" alt="image-20220618170112661" style="zoom:50%;"></p>
<h4><span id="322-结题思路">3.2.2 结题思路</span></h4>
<p><strong>数据分析</strong>：拿到数据后我们首先对提供的训练样本和测试样本进行初步分整理分析;<code>train_data</code>文件夹中，
共包含1401个流量样本，除第85类只有2个样本，29、52、94只有6个样本，平均每个家族都有13-15个样本。下面我们将详细介绍<strong>六个参与投票的子模型</strong>中的每一个模型所采用的特征及对应的分类器，以及设计的动机和意义。</p>
<h5><span id="1数据包特征">（1）数据包特征</span></h5>
<p><strong>由于网络中不同的服务商提供的服务不同，导致数据流中的==数据分组大小==存在一定的差异</strong>，如流媒体的数据分组较小以提高播放流畅度而文件下载通常是以最大的负载进行传输[7]。由于数据分组大小与网络服务有关且不受加密技术的影响，因此可以根据数据分组的分布对加密流量进行识别。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182038655.png" alt="image-20220618170711029" style="zoom:50%;"></p>
<p>我们根据方向的不同，首先针对每个pacp文件分别提取<strong>前向包有效负载长度序列</strong>和<strong>后向有效负载长度序列</strong>。然后每个序列分别提取方差、均值、四分位值、众数、平均数、最大值等特征从而描述分布特点。</p>
<blockquote>
<p>由于包长分布的特征本质上是一个离散概率分布，特征值之间的差值可以很好的描述不同分布之间的差异，因此我们选择<strong>基于欧拉距离度量的KNN分类算法</strong>。KNN通过测量不同特征值之间的距离来讲待检测样本分类到训练样本之中，因此并不适用于特征维度过高的数据，我们所提取的圱圲维特征可以较好地应用于此。</p>
</blockquote>
<h5><span id="2-流级特征">(2) 流级特征</span></h5>
<p><strong>根据五元组（源IP、目的IP、源端口，目的端口，协议）划分得到的会话数据能够最大程度的保留客户端和服务端之间的通信特征信息，因此成为了流量分析领域常用的分析对象[8].</strong>通信双方的<strong><font color="red">
会话级别的统计特征</font></strong>能够很好的反映不同类型应用的属性。</p>
<ul>
<li><strong>恶意通信往往具有持续时间短、传输速率快、出入站比例大等特点</strong>；</li>
<li><strong>正常流量则往往具有持续时间长、包长分布均匀、数据包到达间隔稳定、出入站比例较小等特点。</strong></li>
</ul>
<p>本题中提供的加密流量只是对数据包的载荷进行加密，对流的特征属性的影响较小，因此可以根据流量的属性如间隔时间，报文大小，流持续时间等提取相应的流量特征，根据流量特征准确的识别出访问不同网站的加密流量的类别。如图所示，为题目提供训练样本中不同类别的加密流量在流级统计特征上的分布差异。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182038992.png" alt="image-20220618171300097" style="zoom:67%;"></p>
<h5><span id="提取方式"><strong><font color="red">
提取方式：</font></strong></span></h5>
<p><strong>我们利用SplitCap工具按照（源IP、目的IP、源端口, 目的端口,
协议）五元组将提供的训练和测试数据分别拆分成单独的会话,</strong>
并过滤掉末完成三次握手的会话。我们认为末完成三次握手的会话可能是由于抓包或是题目设定原因出现了截断,
而这种不完整的会话若何混合在其他完整的会话中一同提取统计特征,
将会使特征变得混淆而不可用。因此我们从全部切分得到的46,667个会
话文件中过滤后得到可用于特征提取和模型训练的 <strong>22,211
条完整会话。</strong></p>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/482187008"><em>SplitCap</em>划分pcap文件</a>:将pcap拆分为较小pcap的文件。</p>
</blockquote>
<p>在确定并获得训练数据后, 我们直接实现了从原始报文数据中的流量特征提取,
没有依赖tshark等第三方工具。具体来讲, <strong><font color="red">
我们基于
python和dpkt库，直接将pcap文件作为二进制流读取并依据协议解析每个字段,
从而计算80+维的会
话统计特征。</font></strong>具体使用特征如表3.4所示:</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182038246.png" alt="image-20220618171529682" style="zoom:50%;"></p>
<blockquote>
<p>dpkt:</p>
<p>scapy:</p>
<p>joy：</p>
</blockquote>
<p>特征提取后, 我们选择XGBoost作为流级特征的分类算法。XGBoost (eXtreme
Gradient Boosting）是基于Boosting框架的一个算法工具包 (包括工程实现), 在
并行计算效率、缺失值处理、预测性能上都非常强大。同时基于树的方法可以
直接对特征重要性进行评分,
这对于后续挑选重要特征、降低特征维度、删除冗余特征十分方便，同时还可以对max_depth参数进行限制防止特征过于细化和线性相关带来的过拟合风险。</p>
<h5><span id="3-网站行为特征">(3) 网站行为特征</span></h5>
<p>由于本题数据说明提到所有样本均由同一加密代理生成，<strong>差异在于访问了不同的目标网站</strong>。而恶意网站由于其目的和功能的不同，<strong>在通信过程中往往存在特定的通信模式和规律，通过分析比较有效负载长度序列的异同，可有效定位不同类别的访问流量</strong>【9】</p>
<p>与流级特征中提取的包长统计特征不同，该部分重点关注的是<strong>序列特征</strong>，通过数据包长度的时序性交错变化来反映不同网站的应用和业务特征。在加密代理不变且网站业务功能稳定的情况下，利用基于包长序列的网站应用行为特征进行加密网站流量分类具备相当的稳定性和精确度。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182038582.png" alt="image-20220618171923243" style="zoom: 67%;"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182038497.png" alt="image-20220618172009931" style="zoom:50%;"></p>
<p>为证明该特征的有效性, <strong>我们先将序列长度窗口设定为 11</strong>
, 在 1401 个训练样本中获得了1396个样本所包含的独特包长序列,
并基于匹配的强规则确定4734个样本的标签。此次提交获得了55.18分,
即提交内容获得了94%左右的 正确率，从根本上证明该特征的有效性。</p>
<p>在获得以上的验证结果后，我们开始思考如何将以上的匹配规则“软化”
成机器学习可以处理的形式。我们希望能够兼顾包长序列在莫以类别的出现频
率和 “特异程度”, 结合以往课程和信息检索相关知识,</p>
<p><strong><font color="red"> 我们想到了 TF-IDF(term frequency-inverse
document frequency) 技术。即将包长序列视为 <span class="math inline">\(i\)</span> tem, 拼接后形成 对应该类别的 “文档”,
随后基于tf-idf思想, 计算每个item的出现频率tf和特异性程度idf,
两者结合后用来代表该类别的特征向量。</font></strong>在本题提供的数据中,
<strong>我们共得到了1306维的特征</strong>,
也就是说1396的训练样本和8109的测试样本, 共出
现不同的包长序列1306个。</p>
<p>在获得特征向量后,
我们依然选择了在前面就已经取得良好表现的梯度提升树算法一XGBoost作为该部分的子分类器。主要是考虑到该部分特征向量维
度较高, 且容易出现过拟合的问题。因此, 我们在设定树模型的超参数时, 集中
调整了如max_depth、colsample_bytree、subsample以及eta、lambda、alpha等
控制数据采样和正则化程度的超参数。</p>
<h4><span id="323-结果验证与评估">3.2.3 结果验证与评估</span></h4>
<p><strong>我们基于
python的sklearn和dpkt库实现了相应的机器学习模型和特征提取</strong>。
由于所提供数据包规模不大, dpkt并为遇到内存爆炸无法打开的情况, sklearn中
所包含的KNN模型和XGBoost模型则均采用之前多次试验得到的较好的超参数设置。而且<strong>在流级特征分类</strong>时,
我们基于XGBoost树模型特有的特征重要度评分功能, 进行了一定程度的特征选择,
最终得到了纬度较低且精确度较高的模型作为最终使用的判定模型。</p>
<p>给予我们的多级别特征提取和分类器投票结果,
提交多次后发现并末达到理想的分数。因此后期我们又基于KNN算法和tf-idf特征进行进一步分类,
将多 个模型判定结果均相同的 2270
个测试样本提取出来补充相对较少的训练样本集 重新训练各部分子分类器,
最终达到了87分的结果。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>算法比赛</category>
        <category>网络安全</category>
        <category>加密流量检测</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-【draft】2021 BlackHat-Slips: A Machine-Learning Based, Free-Software, Network Intrusion Prevention System</title>
    <url>/posts/3J22ASH/</url>
    <content><![CDATA[<h2><span id="slipsa-machine-learning-based-free-software-network-intrusion-preventionsystem">Slips:
A Machine-Learning Based, Free-Software, Network Intrusion Prevention
System</span></h2>
<blockquote>
<p>2021 BlackHat Europe Arsenal, Slips: A Machine-Learning Based,
Free-Software, Network Intrusion Prevention System [<a href="https://mega.nz/file/EAIjWA5D#DoYhJknH1hpbqfS2ayVLwA7ewNT50jFQb7S3dVAKPko">slides</a>]
[<a href="https://www.blackhat.com/eu-21/arsenal/schedule/#slips-a-machine-learning-based-free-software-network-intrusion-prevention-system-25116">web</a>]</p>
<p><strong>开源项目</strong>：https://github.com/stratosphereips/StratosphereLinuxIPS</p>
</blockquote>
<h3><span id="一-简介">一、简介</span></h3>
<p><strong>Slips是一个自由软件行为Python入侵预防系统（IDS/IPS），它使用机器学习来检测网络流量中的恶意行为。</strong></p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>加密流量识别</category>
      </categories>
  </entry>
  <entry>
    <title>恶意加密流量（3）西湖论剑AI大数据安全分析赛</title>
    <url>/posts/RGS2PC/</url>
    <content><![CDATA[<h2><span id="西湖论剑ai大数据安全分析赛加密恶意流量检测">西湖论剑AI大数据安全分析赛加密恶意流量检测</span></h2>
<blockquote>
<p>数据集：csv</p>
<p>加密恶意流量检测初赛第一名，决赛第二名方案：https://github.com/undefinedXD/WestLakeSwordComp</p>
</blockquote>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>算法比赛</category>
        <category>网络安全</category>
        <category>加密流量检测</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-【draft】思科-Realtime Robust Malicious Traffic Detection via Frequency Domain Analysis</title>
    <url>/posts/13712CV/</url>
    <content><![CDATA[<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202305061700924.png"></p>
<p>CCS 2021 上也发表了一篇利用频域分析检测恶意流量的工作《Realtime
Robust Malicious Traffic Detection via Frequency Domain Analysis》</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>加密流量识别</category>
      </categories>
  </entry>
  <entry>
    <title>高级威胁发现（4）【Nan】RAID-Cyber Threat Intelligence Modeling Based on GCN</title>
    <url>/posts/22KBA6T/</url>
    <content><![CDATA[<h2><span id="raid-cyberthreat-intelligence-modeling-based-on-gcn">RAID-Cyber
Threat Intelligence Modeling Based on GCN</span></h2>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg5MTM5ODU2Mg==&amp;mid=2247490941&amp;idx=1&amp;sn=30cf491cf7455bbd075f8285d292a9d8&amp;chksm=cfccadb0f8bb24a6c4e87c5c95aecda92578ee634f2b8642bece665efde54417655ed79936c7&amp;scene=178&amp;cur_album_id=1776483007625822210#rd">[AI安全论文]
05.RAID-Cyber Threat Intelligence Modeling Based on GCN</a></p>
<p>这篇文章将详细介绍北航老师发表在RAID 2020上的论文《Cyber Threat
Intelligence Modeling Based on Heterogeneous Graph Convolutional
Network》</p>
<p>原文作者：Jun Zhao, Qiben Yan, Xudong Liu, Bo Li, Guangsheng Zuo
原文链接：https://www.usenix.org/system/files/raid20-zhao.pdf
论文来源：RAID 2020/CCF B</p>
</blockquote>
<h3><span id="摘要">摘要</span></h3>
<p>网络威胁情报（CTI，Cyber Threat
Intelligence）已在业界被广泛用于抵御流行的网络攻击，CTI通常被看作将威胁参与者形式化的妥协指标（IOC）。然而当前的网络威胁情报（CTI）存在三个主要局限性：</p>
<ul>
<li>IOC提取的准确性低</li>
<li><strong>孤立的IOC几乎无法描述威胁事件的全面情况</strong></li>
<li><strong>异构IOC之间的相互依存关系尚未得到开发，无法利用它们来挖掘深层次安全知识</strong></li>
</ul>
<p>本文提出了基于异构信息网络（HIN， Heterogeneous Information
Network）的网络威胁情报框架——HINTI，旨在建模异构IOCs之间的相互依赖关系，以量化其相关性，对CTI进行建模和分析。</p>
<p>本文的主要贡献如下：</p>
<ul>
<li><strong>提出了基于多粒度注意力机制（ multi-granular
attention）的IOC识别方法，可以从非结构化威胁描述中自动提取网络威胁对象，并提高准确性。</strong></li>
<li>构建一个异构信息网络（HIN）来建模IOCs之间的依赖关系</li>
<li>提出一个基于图卷积网络（Graph Convolutional
Networks）的威胁情报计算框架来发现知识</li>
<li>实现了网络威胁情报（CTI）原型系统</li>
</ul>
<p>实验结果表明，本文提出的IOC提取方法优于现有方法，HINTI可以建模和量化异构IOCs之间的潜在关系，为不断变化的威胁环境提供了新的线索。</p>
<blockquote>
<p>IOC（Indicator of
Compromise）是MANDIANT在长期的数字取证实践中定义的可以反映主机或网络行为的技术指示器。</p>
</blockquote>
<h3><span id="一-hinti工作步骤">一、HINTI工作步骤</span></h3>
<ul>
<li>通过B-I-O序列标注方法对安全相关帖子进行标注，用于构建IOC提取模型。</li>
<li>将标记的训练样本输入神经网络，训练<strong>IOC提取模型</strong>。</li>
<li><strong>HINTI利用句法依赖性解析器</strong>（e.g.，主-谓-宾，定语从句等）提取IOC之间的关联关系，每个IOC均表示为三元组（IOCi，relation，IOCj）</li>
<li>最后，HINTI集成了基于异构图卷积网络的CTI计算框架以有效地量化IOC之间的关系进行知识发现。</li>
</ul>
<h4><span id="11-hinti总体架构">1.1 HINTI总体架构</span></h4>
<p>HINTI由四个主要部分组成：（a）收集与安全相关的数据并提取即IOC；（b）将IOC之间的相互依存关系建模为异构信息网络；（c）使用基于权重学习的相似性度量将节点嵌入到低维向量空间中；（d）基于图卷积网络和知识挖掘来计算威胁情报。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191555337.jpeg" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
  <entry>
    <title>高级威胁发现（5）Log2vec: A Heterogeneous Graph Embedding Based Approach for Detecting Cyber Threats within Enterprise</title>
    <url>/posts/31GH3TV/</url>
    <content><![CDATA[<h2><span id="log2veca-heterogeneous-graph-embedding-based-approach-for-detecting-cyberthreats-within-enterprise"><strong>Log2vec:
A Heterogeneous Graph Embedding Based Approach for Detecting Cyber
Threats within Enterprise</strong></span></h2>
<blockquote>
<p>【顶会论文解读】Log2vec 基于异构图Heterogeneous Graph
检测网络空间威胁 - 笑个不停的文章 - 知乎
https://zhuanlan.zhihu.com/p/275952146</p>
<p><strong>AIops博客</strong>：https://blog.csdn.net/markaustralia/category_11284226.html</p>
<p><a href="https://randy.blog.csdn.net/article/details/111773951?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-111773951-blog-118577347.pc_relevant_multi_platform_whitelistv1&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-111773951-blog-118577347.pc_relevant_multi_platform_whitelistv1&amp;utm_relevant_index=2">基于深度学习的日志数据异常检测</a></p>
</blockquote>
<p>发表在<strong>CCS2019</strong>会议的一篇应用异质图embedding进行企业内部网络空间威胁检测的文章。</p>
<h3><span id="摘要">摘要</span></h3>
<p>内部人员的攻击以及APT攻击是组织常见的攻击类型，现有的检测算法多基于行为检测，大部分方法考虑log日志的序列关系以及用户的行为序列，忽略了其他的关系导致不使用于丰富多样的攻击场景。<strong>本文提出的Log2vec模型，将日志转化为异质图，将日志学习为低纬度的embedding并使用检测算法进行攻击检测（由于攻击样本较少，因此使用聚类算法进行检测）。</strong></p>
<h3><span id="一-引言">一、引言</span></h3>
<p>现有方法一般会转换用户的各种操作（也包括日志条目）分成序列，这些序列可以保存信息，例如
日志条目之间的顺序关系，然后使用序列处理技术，例如
深度学习从过去的事件中学习并预测下一个事件。<strong>本质上，这些日志条目级别的方法可以模拟用户的正常行为行为并将其偏离标记为异常。</strong></p>
<p>但是，这种方法忽略了其他关系。
例如，<strong>比较用户的日常行为是常规内部威胁检测的一种常用方法</strong>。
此检测基于以下前提：用户的日常行为在一段时间内（几天之间的逻辑关系）相对规则。
上述预测方法忽略了这种关系，并且会降低其性能。
此外，他们需要正常的日志条目，甚至需要大量标记数据来进行模型训练。
但是，在现实世界中，存在罕见的攻击动作，从而限制了其正确预测的能力。</p>
<p><strong>对于检测内部威胁以及APT攻击来说，我们面临三个问题：</strong></p>
<p>（1）<strong>如何同时检测上述两种攻击情形，特别是考虑到检测系统中提到的所有三种关系（日志之间序列关系
sequantial relationship among log entries、几天之内的逻辑关系logical
relationship among days以及交互关系interactive relationship among
hosts）；</strong></p>
<p><strong>解决办法</strong>：构建异构图来表示前面提到的三种关系；</p>
<p>（2）<strong>如何在APT场景中进行细粒度的检测，尤其是深入挖掘和分析主机内日志条目之间的关系；</strong></p>
<p><strong>解决办法</strong>：将日志条目分为五个属性。根据这些属性，我们深入考虑了主机内日志之间的关系，并设计了精细的规则来关联它们。这种设计使正常和异常日志条目可以在这种图中拥有不同的拓扑；</p>
<p>（3）<strong>如何针对训练模型进行无攻击样本的检测。【内部威胁】</strong></p>
<p><strong>解决办法</strong>：log2vec的图嵌入和检测算法将日志条目表示并分组到不同的群集中，而没有攻击样本，适用于数据不平衡的情况（针对问题3）。此外，图形嵌入本身可以自动学习每个操作的表示形式（矢量），而无需手动提取特定于领域的特征，从而独立于专家的知识。我们的改进版本可以进一步差分提取并表示来自上述异构图的操作之间的多个关系。</p>
<h3><span id="二-文章的设计">二、<strong>文章的设计</strong></span></h3>
<p><strong>Log2vec包含以下三个组件：</strong></p>
<ul>
<li><p><strong>图的构造。</strong>
Log2vec构造一个异构图以集成日志之间的多个关系条目;</p></li>
<li><p><strong>图嵌入</strong>（也是图表示学习）。这是一种强大的图形处理方法，可用于了解每个操作的</p>
<p>表示（向量）基于它们在这种图中的关系。通过矢量化用户操作，可以直接比较他们的操作</p>
<p>找出异常的相似之处；</p></li>
<li><p><strong>检测算法，</strong>无监督，要有效将恶意操作分组为单个群集</p></li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191555029.png" alt="image-20220703183858975" style="zoom:50%;"></p>
<h3><span id="三-概述">三、概述</span></h3>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191555735.png" alt="image-20220703184011385" style="zoom:50%;"></p>
<p>如图2（a）所示，<strong>日志记录了用户的操作，如登录操作，设备之间移动操作以及网络操作</strong>。图2（b）描述日志的属性，<strong>主体（user），操作类型（visit或者send），客体（网址或者是邮件）以及时间和主机（设备ID）</strong>。实际上，日志的属性能够反映用户的行为，比如，第一个登录的时间和日志结束的时间能够反映用户的工作时长。系统管理员会频繁的登录服务器和操作对系统进行维护。</p>
<p>图2（c）将a中显示的<strong>日志组成序列</strong>，然后使用如LSTM的方法学习日志序列信息进行预测。此类模型能够捕捉日志的因果信息和序列关系。但是，这样的方法忽视了其他关系，比如（a）中day3序列，有大量的设备连接和文件复制的操作，远比以前多（这意味着数据泄露）。
可以通过直接比较用户的日常行为来检测出这种差异。进行比较的前提是，在一段时间内（几天之间的逻辑关系），用户的日常行为相对规则且相似。
虽然是深度学习，例如
LSTM可以记住序列的长期依赖关系（多天），它没有明确比较用户的日常行为，也无法获得令人满意的性能。
类似地，它们不能保持图2d中主机之间的另一种关系，交互关系，并且不能在APT检测中正常工作。
另外，其中一些需要大量标记数据进行培训。
但是，在我们的检测方案中，存在罕见的攻击行为。</p>
<p>图2d展示了图2a中的登录（红色字体）的图表，<strong>该图表指示用户在主机之间的行为</strong>。
我们可以分析主机之间的这些交互关系，以发现异常登录。
例如，管理员可以定期登录到一组主机以进行系统维护，而APT实施者只能访问他可以访问的主机。
登录跟踪的功能可以捕获这种差异。例如，良性跟踪中涉及的主机数量（1或3，实线）通常不同于APT（2，虚线）。在分析了这些功能之后，可以识别出受感染的主机。
但是，这些主机包含许多良性操作，并且手动提取的特定于域的特征显然无法应用于图2c中的攻击。</p>
<p>本文构建的模型用于检测以下类型的攻击：
第一种情况是<strong>内部人员滥用职权执行恶意操作，例如访问数据库或应用程序服务器，然后破坏系统或窃取知识产权以谋取个人利益</strong>。
其次，<strong>恶意内部人员通过窥视或密钥记录器获取其他合法用户的凭据，并利用此新身份来寻找机密信息或在公司中造成混乱</strong>。
这两种情况属于内部员工的典型攻击。
第三种攻击是<strong>APT参与者破坏了系统中的主机，并从该主机中持续破坏了多个主机，以提升其特权并窃取机密文件。</strong></p>
<h3><span id="四-详细论述"><strong>四、详细论述</strong></span></h3>
<h4><span id="41-图构建">4.1 图构建</span></h4>
<p><strong><font color="red">
本文构建的图的节点是日志，只有一种节点类型，边是通过规则来建立联系的，本文提出10条规则，代表着图有10种边类型。因此，本文构建的异构图只是边类型不同，节点类型是相同的。</font></strong></p>
<p><strong>定义：&lt;sub,obj,A,T,H&gt; 提取日志的五个主要属性：subject,
object, operation type, time and host，称为元属性</strong></p>
<ul>
<li>sub表示用户集合；</li>
<li>obj表示客体集合（文件、移动存储设备、网站）；</li>
<li>A是操作类型集合（文件操作和网页利用）；</li>
<li>T表示时间</li>
<li>H是主机（计算机或者是服务器）。</li>
</ul>
<p><strong>sub,obj,A,H有自己的子属性</strong>。比如，用户在服务器中写入文件，sub的属性包括用户角色（系统管理员等）和所属单位；obj属性包括文件类型和大小；H属性包括是文件服务器还是邮件服务器；对于登录操作，A的属性包括身份验证。对于用户登录，可以表示为user
(sub) logs in to (A) a destination host (obj) in a source one (H),</p>
<h4><span id="42-构建图的规则">4.2 <strong>构建图的规则</strong></span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191555928.png" alt="image-20220703193951973" style="zoom:50%;"></p>
<p>上图，R1-3描述一天中的因果关系和序列关系；R4-6描述多天之间的逻辑关系；R7
R9描述用户登录和web浏览行为序列。R8 R10按照逻辑关系进行关联。</p>
<p><strong>log2vec考虑三种关系：</strong></p>
<ul>
<li>causal and sequential relationships within a day;
一天内的因果关系和顺序关系；</li>
<li>logical relationships among days；日之间的逻辑关系</li>
<li>logical relationships among objects；对象之间的逻辑关系。</li>
</ul>
<p>在设计有关这三种关系的规则时，我们考虑这些元属性的不同组合，以关联较少的日志条目，并将更精细的日志关系映射到图中。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191555332.png" alt="image-20220703194402679" style="zoom:50%;"></p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
  <entry>
    <title>高级威胁发现（6）UNICORN: Provenance-Based Detector for APTs</title>
    <url>/posts/1WZGAE8/</url>
    <content><![CDATA[<h2><span id="ndss20unicorn-provenance-based-detector-for-apts">NDSS20
UNICORN: Provenance-Based Detector for APTs</span></h2>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg5MTM5ODU2Mg==&amp;mid=2247492967&amp;idx=1&amp;sn=60f14977758cc7d1e8504446422e5ec0&amp;chksm=cfcf55aaf8b8dcbc86935b76e7f36961202174ecba1df597fee9d44428c607e80d41add1b2f9&amp;scene=178&amp;cur_album_id=1776483007625822210#rd">[AI安全论文]
06.NDSS20 UNICORN: Provenance-Based Detector for APTs</a></p>
</blockquote>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191555641.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<blockquote>
<p>原文作者：Xueyuan Han, Thomas Pasquier, Adam Bates, James Mickens and
Margo Seltzer 原文标题：UNICORN: Runtime Provenance-Based Detector for
Advanced Persistent Threats
原文链接：https://arxiv.org/pdf/2001.01525.pdf 发表会议：NDSS
2020参考文献：感谢两位老师
https://blog.csdn.net/Sc0fie1d/article/details/104868847
https://blog.csdn.net/xjxtx1985/article/details/106473928</p>
</blockquote>
<h3><span id="摘要">摘要</span></h3>
<p>本文提出的<strong>UNICORN是一种基于异常的APT检测器</strong>，可以有效利用数据<strong>Provenance进行分析</strong>。通过广泛且快速的图分析，使用<strong>graph
sketching技术</strong>，UNICORN可以在长期运行的系统中分析Provenance
Graph，从而识别未知慢速攻击。其中，Provenance
graph提供了丰富的上下文和历史信息，实验证明了其先进性和较高准确率。</p>
<p>由于APT（Advanced Persistent
Threats）攻击具有缓慢可持续的攻击模式以及频繁使用0-day漏洞的高级特性使其很难被检测到。<strong>本文利用数据来源分析（provenance）提出了一种基于异常的APT检测方法，称为UNICORN。</strong></p>
<ul>
<li>从建模到检测，UNICORN专门针对APT的独有特性（low-and-slow、0-Days）设计。</li>
<li>UNICONRN利用高效的图分析方法结合溯源图丰富的上下文语义和历史信息，在没有预先设定攻击特征情况下识别隐蔽异常行为。</li>
<li>通过图概要（graph
sketching）技术，它有效概括了长时间系统运行来对抗长时间缓慢攻击。</li>
<li>UNICONRN使用一种新的建模方法来更好地捕捉长期行为规律，以提高其检测能力。</li>
</ul>
<p>最后通过大量实验评估表明，本文提出的方法优于现有最先进的APT检测系统，并且在真实APT环境中有较高的检测精度。</p>
<h3><span id="一-引言">一、引言</span></h3>
<p>APT攻击现在变得越来越普遍。这种攻击的时间跨度长，且与传统攻击行为有着本质的区别。APT攻击者的目的是获取特定系统的访问控制，并且能够长期潜伏而不被发现。攻击者通常使用0-day漏洞来获取受害者系统的访问控制。</p>
<p><strong>传统检测系统通常无法检测到APT攻击。</strong></p>
<ul>
<li>依赖恶意软件签名的检测器对利用新漏洞的攻击无效。</li>
<li>基于异常检测的系统通常分析一系列的系统调用或日志系统事件，其中大部分方法无法对长期行为进行建模。</li>
<li>由于基于异常检测的方法只能检测系统调用和事件的短序列很容易被绕过。</li>
</ul>
<p>综上，当前针对APT攻击的检测方法很少能成功。攻击者一旦使用0-Day漏洞，防御者便无计可施；而基于系统调用和系统事件的检测方法，由于数据过于密集，这些方法难以对长时间的行为模式进行建模。<strong>因此，数据溯源（data
provenance）是一种检测APT更合适的数据。</strong></p>
<p>最近的研究成果表明数据溯源是一个很好的APT检测数据源。数据溯源将系统执行表示成一个有向无环图（DAG），该图描述了系统主体（如进程）和对象（文件或sockets）之间的信息流。即使跨了很时间，在图中也把因果相关的事件关联到一起。因此，即使遭受APT攻击的系统与正常系统比较类似，但是溯源图中丰富的上下文语义信息中也可以很好地区分正常行为与恶意行为。</p>
<p><strong>然而，基于数据溯源的实时APT检测依然具有挑战。</strong>
随着APT攻击的渗透的进行，数据溯源图的规模会不断增大。其中必要的上下文分析需要处理大量图中的元素，而图上的分析通常复杂度比较高。当前基于数据溯源的APT检测方法根据已有的攻击知识通过简单的边匹配实现APT检测，无法处理未知的APT攻击。基于溯源的异常检测系统主要是基于图模型的邻域搜索，利用动态或静态模型识别正常行为模式。理论上关联的上下文越丰富越好，但是实际中由于图分析的复杂性较高限制了其可行性。</p>
<ul>
<li>Provenance
Graph的分析是相当耗费计算资源，因为APT是可持续攻击，图的规模也会越来越大</li>
</ul>
<p><strong><font color="red">
当前APT检测系统面临如下三种问题：</font></strong></p>
<ul>
<li>静态模型难以捕获长时间的系统行为；</li>
<li>low-and-slow
APT投毒攻击：由于APT高级可持续的特性可以在系统中潜伏很长时间，相关的行为会被认为是正常行为，这样的攻击会影响检测模型；</li>
<li>在主存内进行计算的方法，应对长期运行的攻击表现不佳。</li>
</ul>
<p>基于此，本文提出了UNICORN，使用graph
sketching来建立一个增量更新、固定大小的纵向图数据结构。这种纵向性质允许进行广泛的图探索，使得UNICORN可以追踪隐蔽的入侵行为。而固定大小和增量更新可以避免在内存中来表示provenance
graph，因此UNICORN具有可扩展性，且计算和存储开销较低。UNICORN在训练过程中直接对系统的行为进行建模，但此后不会更新模型，从而防止模型的投毒攻击。</p>
<p><strong><font color="red"> 本文的主要贡献如下：</font></strong></p>
<ul>
<li>针对APT攻击特性提出一种<strong>基于Provenance的异常检测系统</strong>。</li>
<li><strong>引入一种新的基于概要的（sketch-based）、时间加权的（time-weighted）溯源编码</strong>，该编码非常紧凑且可处理长时间的溯源图。</li>
<li>通过模拟和真实的APT攻击来评估UNICORN，证明其能高精度检测APT活动。</li>
<li><strong><font color="red"> 实现代码开源。</font></strong></li>
</ul>
<h3><span id="二-背景">二、背景</span></h3>
<h4><span id="21-系统调用追踪的挑战"><strong>2.1 系统调用追踪的挑战</strong></span></h4>
<p><strong>系统调用抽象提供了一个简单的接口，用户级应用程序可以通过这个接口请求操作系统的服务</strong>。作为调用系统服务的机制，系统调用接口通常也是攻击者入侵的入口点。因此，系统调用跟踪一直被认为是入侵检测的实际信息源。然而：</p>
<ul>
<li>当前的攻击检测系统是对非结构化的系统调用的审记日志进行分析，但捕获的系统调用杂乱分散，传统基于异常检测的思路无法处理APT。因此需要将其关联成data
provenance，基于溯源的方法是将历史上下文数据都编码到因果关系图中。</li>
<li>数据溯源方法已经被应用到攻击调查中，已经有一些方法能够根据审计数据构建系统溯源图用以实现对系统执行过程的建模。然而这些方法依然存在一些局限：(1)
这种事后构建很难保证溯源图的正确性，由于系统调用问题存大量并发，溯源图的完整性与可靠性无法保证；(2)
容易被绕过；(3) 时空复杂度较高。</li>
<li>由于一些内核线程不使用系统调用，因此<strong>基于Syscall生成的Provenance是一些分散的图，而不是一张系统运行状况的完整图</strong></li>
</ul>
<h4><span id="22-全系统追踪溯源">2.2 <strong>全系统追踪溯源</strong></span></h4>
<p><strong>全系统溯源运行在操作系统层面，捕获的是所有系统行为和它们之间的交互</strong>。通过捕获信息流和因果关系，即使攻击者通过操作内核对象来隐藏自己的行踪也无济于事。</p>
<p>本文使用CamFlow，采用了Linux安全模块（Linux Security
Modules，LSM）框架来确保高效可靠的信息流记录。LSM可以消除race
condition。</p>
<blockquote>
<p><strong>CamFlow：溯源搜集系统</strong>，参考官网
https://camflow.org/。</p>
<p><strong>CamFlow
将系统的执行表示为有向无环图</strong>。图中的顶点表示内核对象（例如线程、文件、套接字等）的状态，关系表示这些状态之间的信息流。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191555346.png" alt="CamFlow 图表概览" style="zoom: 33%;"></p>
<p>在上面的示例中<code>process 1</code>克隆<code>process 2</code>。
<code>process 2</code>写到一个<code>pipe</code>。
<code>process 1</code>同读<code>pipe</code>。创建版本是为了保证非周期性并代表信息的正确排序（有关详细信息，请参阅我们的<a href="http://camflow.org/publications/ccs-2018.pdf">CCS'18
论文</a>）。</p>
</blockquote>
<h3><span id="23-问题描述">2.3 问题描述</span></h3>
<p>现有基于数据溯源的APT攻击检测方法主要存在如下缺陷：</p>
<ul>
<li>预定义的边匹配规则过于敏感，很难检测到APT攻击中的0-Day漏洞；</li>
<li>溯源图的近邻约束导致其只能提供局部上下文信息（而非whole-system），然而这会影响相关异常检测精度；</li>
<li>系统行为模型难以检测APT：静态模型无法捕获长期运行的系统的行为；动态模型容易遭受中毒攻击；</li>
<li>溯源图的存储与计算都是在内存中，在执行长期检测上有局限性。</li>
</ul>
<p><strong>UNICORN可以解决如上问题，其本质是把APT检测问题看成大规模、带有属性的实时溯源图异常检测问题。在任何时间，从系统启动到其当前状态捕获的溯源图都将与已知正常行为的溯源图进行比较。如果有明显差别，那么就认为该系统正在遭受攻击。</strong></p>
<p>对于APT检测来说，理想基于溯源的IDS应该如下：</p>
<ul>
<li>充分利用溯源图的丰富上下文，以时间与空间有效的方法持续分析溯源图；</li>
<li>在不假设攻击行为的基础上，应考虑系统执行的整个持续时间；</li>
<li>只学习正常行为的变化，而不是学习攻击者指示的变化。</li>
</ul>
<h3><span id="三-威胁模型">三、威胁模型</span></h3>
<p>假设主机入侵检测有适当的场景：攻击者非法获得对系统的访问权限，并计划在不被检测的情况下驻留在系统中很长一段时间。<strong>攻击者可能分阶段执行攻击，在每个阶段还会使用大量的攻击技术</strong>。UNICORN的目标是通过解决主机生成的溯源来实现在所有阶段对APT攻击进行检测。本文假设，我们假设在受到攻击之前，UNICORN在正常运行期间会完全观察主机系统，并且在此初始建模期间不会发生攻击。</p>
<p>数据收集框架的完整性是UNICORN正确性的核心，因此<strong>我们假定所使用的CamFlow中，LSM完整性是可信的。同时，本文假设内核、溯源数据和分析引擎的正确性，我们重点关注UNICORN的分析能力。</strong></p>
<h3><span id="四-系统设计">四、系统设计</span></h3>
<p>独角兽是一个基于主机的入侵检测系统，能够同时检测在网络主机集合上的入侵。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191555615.png" alt="图片" style="zoom: 67%;"></p>
<ol type="1">
<li><strong>以一个带标签的流式溯源图作为输入</strong>。该图由CamFlow生成，每条边是带属性的。溯源系统构建一个具有偏序关系的DAG溯源图，能实现有效的流式计算和上下文分析。</li>
<li><strong>建立一个运行时的内存直方图</strong>。UNICORN有效构建一个流式直方图，该直方图表示系统执行的历史，如果有新边产生则实时更新直方图的计数结果。通过迭代的探索大规模图的近邻关系，发现了在上下文环境中系统实体的因果关系。该工作是UNICORN的第一步，具体来说，<strong>直方图中每个元素描述了图中唯一的一个子结构</strong>，同时考虑了子结构中的顶点与边上的异构标签，以及这些边的时间顺序。APT攻击缓慢的渗透攻击目标系统，希望基于的异常检测方法最终忘记这一行为，把其当成正常的系统行为，但是APT攻击并不能破坏攻击成功的相关信息流依赖关系。</li>
<li><strong>定期计算固定大小的概要图（graph
sketch）</strong>。在纯流式环境，当UNICORN对整个溯源进行汇总时，唯一直方图元素的数量可能会任意增长。这种动态变化导致两个直方图之间的相似计算变得非常有挑战，从而使得基于直方图相似计算的建模以及检测算法变的不可行。<strong>UNICORN采用相似度保存的hash技术把直方图转换成概要图。概要图可以增量维护，也意味着UNICORN并不需要将整个溯源图都保存在内存中。</strong>另外，<strong>概要图保存了两个直方图之间的jaccard相似性，这在后续图聚类分析中特别有效。</strong></li>
<li><strong>将简略图聚类为模型</strong>。UNICORN可以在没有攻击知识的前提下实现APT攻击检测。与传统的聚类方法不同，UNICORN利用它的流处理能力生成一个动态演化模型。该模型通过在其运行的各个阶段对系统活动进行聚类捕获单个执行中的行为改变，但是UNICORN无法在攻击者破坏系统时动态实时修改模型。因此，它更适合APT攻击这类长期运行的攻击。</li>
</ol>
<h4><span id="41-溯源图">4.1 溯源图</span></h4>
<p>最近几年溯源图在攻击分析中越来越流行，并且本身固有的特别可以有效的用于APT检测。溯源图挖掘事件之间的因果关系，因果关系有助于对时间跨度较远的事件进行推理分析，因此有助于在检测APT相关攻击。</p>
<p>UNICORN根据两个系统执行的溯源图的相似性还判定两个系统的行为相似性。而且UNICORN总是考虑整个溯源来检测长期持续的攻击行为。<strong>当前已经有许多图相似度计算方法，然而这些算法大部分是NPC的，即使多项式时间复杂度的算法也无法满足整个溯源图快速增涨的需求。</strong></p>
<h4><span id="42-构建graph直方图">4.2 构建Graph直方图</span></h4>
<p>本文方法的目标是有效对溯源图进行比较分析，同时容忍正常执行中的微小变化。对于算法，我们有两个标准：</p>
<ul>
<li>图表示应考虑长期的因果关系；</li>
<li>必须能够在<strong>实时流图数据</strong>上实现该算法，以便能够在入侵发生时阻止入侵（不仅仅是检测到入侵）。</li>
</ul>
<p><strong><font color="red">
本文基于一维WL同构检验，采用了线性时间的、快速的Weisfeiler-Lehman（WL）子树图核算法。该算法的使用依赖于构造的顶点直方图的能力，需要直方图能捕捉每个顶点周围的结构信息。</font></strong>根据扩充的顶点标签对顶点进行分类，这些标签完全描述了顶点的领域，并且<strong>通过迭代的标签传播来构造这些扩展的顶点标签</strong>。</p>
<p>同构性的WL检验及其子树kernel变化，以其对多种图的判别能力而闻名，超越了许多最新的图学习算法（例如，图神经网络）。对Weisfeiler-Lehman（WL）子树图核的使用取决于我们构建顶点直方图的能力，捕获围绕每个顶点的图结构。我们根据增强顶点标签对顶点进行分类，标签描述了顶点的R-hop邻居。</p>
<p>为了简单说明，假设有一个完整静态图，重标记对所有的输入标签的聚合。对每个顶点都重复执行这个过程来实现对n跳邻居的描述。一旦为图中的每个顶点都构建了扩展标签，那么就可以基于此生成一个直方图，其中每个bucket表示一个标签。两个图的相似性比较是基于以下假设：两个图如果相似那么在相似的标签上会有相似的分布。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191555022.png" alt="图片" style="zoom: 67%;"></p>
<p>我们的目标是构建一个直方图，图中的每个元素对应一个唯一的顶点标签，用于捕获顶点的R-hop的in-coming邻居。</p>
<p><strong>信息流的多样性与复杂性（Streaming Variant and
Complexity）</strong>。算法1只有新顶点出现或是新边出现对其邻顶点有影响时才会执行。本文方法只需要为每条新边更新其目标顶点的邻域。UNICORN采用这种偏序关系来最小化计算代价。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191555986.png" alt="图片" style="zoom: 67%;"></p>
<p><strong>直方图元素的概念漂移问题</strong>。APT攻击场景需要模型必须能够处理长期运行行为分析能力，而系统行为的动态变化会导致溯源图的统计信息也随之变化，这种现象就叫概念漂移（concept
drift）。</p>
<p>UNICORN通过对直方图元素计数使用指数权重衰减来逐渐消除过时的数据（逐渐忘记机制），从而解决了系统行为中的此类变化。它分配的权重与数据的年龄成反比。</p>
<p><span class="math display">\[
H_h=\sum_t \mathbb{1}_{x_t=h}
\]</span></p>
<p><strong>入侵检测场景中的适用性</strong>。上述“逐渐忘记”的方法，使得UNICORN可以着眼于当前的系统执行动态，而且那些与先前的object/activity有关系的事件不会被忘记。</p>
<h4><span id="43-生成概要图graph-sketches">4.3 生成概要图（Graph Sketches）</span></h4>
<p>Graph直方图是描述系统执行的简单向量空间图统计量。然而，与传统的基于直方图的相似性分析不同，UNICORN会随着新边的到来不断更新直方图。另外，UNCORN会根据图特征的分布来计算相似性，而不是利用绝对统计值。</p>
<p><strong><font color="red"> 本文采用locality sensitive
hashing，也称作similarity-preserving data
sketching。UNICORN的部署采用了前人的研究成果HistoSketch，该方法是一种基于一致加权采样的方法，且时间得性是常数。</font></strong></p>
<h4><span id="44-学习进化模型">4.4 学习进化模型</span></h4>
<p>在给定graph
sketch和相似性度量的情况下，聚类是检测离群点常用的数据挖掘手段。<strong>然而传统的聚类方法无法捕获系统不断发展的行为</strong>。UNICORN利用其流处理的能力，创建了进化模型，可以捕获系统正常行为的变化。更重要的是，模型的建立是在训练阶段完成的，而不是在部署阶段，因为部署阶段训练模型可能会遭受中毒攻击。</p>
<p><strong><font color="red">
UNICORN在训练期间创建一个时序sketches，然后使用著名的K-medods算法从单个服务器对该概要序列进行聚类，使用轮廓系数（silhouette
coefficient）确定最佳K值。</font></strong>每个簇表示系统执行的元状态（meta-states），如启动、初始化、稳定状态。然后UNICORN使用所有簇中sketches的时间顺序和每个簇的统计量（如直径、medoid），来生成系统进化的模型。</p>
<blockquote>
<ul>
<li>更新C中的每一列，即类中心 <img src="https://www.zhihu.com/equation?tex=c_j" alt="[公式]">
,对于第j类，<strong>中心 <img src="https://www.zhihu.com/equation?tex=c_j" alt="[公式]">
需要通过遍历所有该类中的样本，取与该类所有样本距离和最小的样本为该中心。</strong></li>
</ul>
<p>K-means 模型: <span class="math inline">\(\min _{G, C} \sum_{i=1}^n
\sum_{j=1}^k g_{i j}\left\|x_i-c_j\right\|_2\)</span> 算法流程：</p>
<ul>
<li>固定C,更新 G</li>
<li>更新C中的每一列, 即类中心 <span class="math inline">\(c_j\)</span>,其通过计算第j类中样本的平均值得到</li>
</ul>
<p>K-mediods:模型： <span class="math inline">\(\min _{G, C \subseteq X}
\sum_{i=1}^n \sum_{j=1}^k g_{i j}\left\|x_i-c_j\right\|_1 \quad\)</span>
可以是曼哈顿距离或其它距离度量;由于类中心的更新规
则，该方法较之于K-means更鲁棒。 算法流程:</p>
<ul>
<li>固定C,更新 G</li>
<li>更新C中的每一列，即类中心<span class="math inline">\(c_{j}\)</span>,对于第j类，<strong>中心<span class="math inline">\(c_{j}\)</span>需要通过遍历所有该类中的样本，取与该类所有样本距离和最小的样本为该中心。</strong></li>
</ul>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191556090.png" alt="图片" style="zoom: 67%;"></p>
<p><strong>对于每个训练实例，UNICORN创建一个模型，该模型捕获系统运行时执行状态的更新。直观地说，这类似于跟踪系统执行状态的自动机。</strong>最终的模型由训练数据中所有种源图的多个子模型组成。</p>
<h4><span id="45-异常检测">4.5 异常检测</span></h4>
<p>在部署期间，异常检测遵循前面章节中描述的相同流模式。UNICORN周期性地创建graph
sketch，因为直方图从流式溯源图演变而来。给定一个概要图，UNICORN将该概要与建模期间学习的所有子模型进行比较，将其拟合到每个子模型中的一个聚类中。</p>
<p><strong>UNICORN假设监视从系统启动开始，并跟踪每个子模型中的系统状态转换。要在任何子模型中为有效，概要必须适合当前状态或下一个状态；否则，被视为异常。因此，我们检测到两种形式的异常行为：</strong></p>
<ul>
<li>不符合现有聚类的概要</li>
<li>聚类之间的无效转换</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（1）科大讯飞A</title>
    <url>/posts/3KZY6WZ/</url>
    <content><![CDATA[<h2><span id="科大讯飞2021ai开发者大赛恶意软件分类">科大讯飞2021
A.I.开发者大赛——恶意软件分类</span></h2>
<blockquote>
<p>比赛链接：https://link.zhihu.com/?target=https%3A//challenge.xfyun.cn/topic/info%3Ftype%3Dmalware-classification</p>
<p><strong>操作码逆词频共现矩阵 + Vision Transformer</strong> - 知乎
https://zhuanlan.zhihu.com/p/396207089</p>
</blockquote>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>算法比赛</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>高级威胁发现（3）SLEUTH: Real-time Attack Scenario Reconstruction from COTS Audit Data</title>
    <url>/posts/M5Q53E/</url>
    <content><![CDATA[<h2><span id="sleuthreal-time-attack-scenario-reconstruction-from-cots-audit-data">SLEUTH:
Real-time Attack Scenario Reconstruction from COTS Audit Data</span></h2>
<ul>
<li>https://blog.csdn.net/Sc0fie1d/article/details/104273798</li>
</ul>
<h3><span id="摘要">摘要</span></h3>
<p>本文提出了一种实时重构企业主机上攻击场景的方法和系统。为了满足问题的<strong>可伸缩性</strong>和<strong>实时需求</strong>，我们开发了一个平台中立的、基于主存的、审计日志数据的依赖图抽象方法。然后，我们提出了高效的、基于标签的攻击检测和重建技术，包括源识别和影响分析。我们还开发了一些方法，通过构建紧凑的攻击步骤的可视化图来揭示攻击的大局。我们的系统参与了由DARPA组织的红色团队评估，并能够成功地检测并重建了红色团队对运行Windows、FreeBSD和Linux的主机的攻击细节</p>
<h3><span id="一-说明">一、说明</span></h3>
<p>我们正在目睹由熟练的对手进行的有针对性的网络攻击(“企业高级和持续威胁(APTs))[1]的迅速升级。通过将社会工程技术（例如，鱼叉式网络钓鱼）与先进的开发技术相结合，这些对手通常会绕过广泛部署的软件保护系统，如ASLR、DEP和沙箱。因此，企业越来越依赖于二线防御，例如，<strong>入侵检测系统(IDS)、安全信息和事件管理(SIEM)工具、身份和访问管理工具，以及应用程序防火墙。虽然这些工具通常很有用，但它们通常会生成大量的信息，这使得安全分析师很难区分真正重要的攻击——众所周知的“大海捞针”——从背景噪音</strong>。此外，分析人员缺乏“连接这些点”的工具，即，将跨越多个应用程序或主机并在长时间扩展的攻击活动的碎片拼凑起来。相反，需要大量的手工努力和专业知识来整理由多个安全工具发出的众多警报。因此，许多攻击活动被错过了数周甚至数月的[7,40]。</p>
<p>为了有效地控制高级攻击活动，分析人员需要新一代的工具，不仅帮助检测，而且还生成一个总结攻击的因果链的紧凑总结。这样的摘要将使分析人员能够快速确定是否存在重大入侵，了解攻击者最初是如何违反安全规则的，并确定攻击的影响。</p>
<p>将导致攻击的事件的因果链拼接在一起的问题首先在反向跟踪器[25,26]中进行了探索。随后的研究[31,37]提高了由反向跟踪器构建的依赖链的精度。然而，这些工作在一个纯粹的法医环境中运行，因此不处理实时进行分析的挑战。相比之下，本文提出了侦探（<strong>SLEUTH</strong>），一个系统，该系统可以实时提醒分析师一个正在进行的活动，并在攻击后的几秒钟或几分钟内为他们提供一个紧凑的、直观的活动摘要。这将使在对受害者企业造成巨大损害之前及时作出反应。实时攻击检测和场景重构提出以下几点：</p>
<ul>
<li><strong>事件存储和分析</strong>：我们如何有效地存储来自事件流的数百万条记录，并让算法在几秒钟内筛选这些数据？</li>
<li><strong>确定分析实体的优先级</strong>：我们如何帮助被数据量淹没的分析师，优先排序并快速“放大”最有可能的攻击场景？</li>
<li><strong>场景重构</strong>：如何从攻击者的入口点开始，简洁地总结攻击场景，识别整个活动对系统的影响？</li>
<li><strong>处理常见的使用场景</strong>：如何应对正常的、良性的活动，这可能类似于在攻击期间观察到的常见活动，例如，软件下载？</li>
<li><strong>快速、交互式推理</strong>：我们如何为分析人员提供通过数据进行有效推理的能力，比如说，用另一种假设？</li>
</ul>
<p>下面，我们将简要介绍侦探调查，并总结我们的贡献。侦探假设攻击最初来自企业外部。例如，对手可以通过外部提供的恶意输入劫持web浏览器、插入受感染的u盘或向企业内运行的网络服务器提供零日攻击来启动攻击。我们假设对手在侦探开始监视系统之前并没有在主机上植入持续的恶意软件。我们还假设操作系统内核和审计系统是值得信赖的</p>
<h4><span id="11方法概述和贡献">1.1方法概述和贡献</span></h4>
<p>图1提供了我们的方法的概述。侦探是操作系统中立的，目前支持微软的Windows、Linux和FreeBSD。来自这些操作系统的审计数据被处理成平台中立的图形表示，其中顶点表示主题（<strong>进程</strong>）和对象（<strong>文件、套接字</strong>），边表示审计事件（例如，读、写、执行和连接等操作）。该图可作为攻击检测、因果关系分析和场景重建的基础。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191554457.png" alt="image-20220513135637994">
<figcaption aria-hidden="true">image-20220513135637994</figcaption>
</figure>
<ul>
<li><p>本文的第一个贡献是<strong>针对高效事件存储依赖图表示的开发和紧凑的事件存储和分析（第2节）的挑战</strong>。主存表示上的图形算法可以比磁盘上的表示快几个数量级，这是实现实时分析能力的一个重要因素。<strong>在我们的实验中，我们能够在14秒内处理来自FreeBSD系统的79小时的审计数据，主存使用量为84MB。这种性能表示的分析速率比生成数据的速率快2万倍。</strong></p></li>
<li><p>本文的第二个主要贡献是<strong>开发了一种基于标签的方法</strong>，<strong>用以识别最有可能参与攻击的主题、对象和事件</strong>。标签使我们能够确定分析的优先级和重点，从而解决上面提到的第二个挑战。标签编码对数据（即对象）以及过程（主题）的可信度和敏感性进行评估。此评估是基于来自审计日志的数据来源。从这个意义上说，<strong>从审计数据中衍生出的标签类似于粗粒度信息流标签</strong>。我们的分析也可以很自然地支持更细粒度的标记，例如，细粒度的污染标记[42,58]，如果它们可用的话。在第3节中更详细地描述了标签，以及它们在攻击检测中的应用。</p></li>
<li><p>本文的第三个贡献是<strong>开发了利用标签进行根源识别和影响分析的新算法</strong>（第5节）。从图1中所示的攻击检测组件产生的警报开始。我们的反向分析算法遵循图中的依赖关系来识别攻击的来源。从源代码开始，我们使用前向搜索对对手的行动进行全面的影响分析。我们提出了几个标准，以生成一个紧凑的图。我们还给出了一些转换，进一步简化了这个图，并生成了一个图，以一种简洁和语义上有意义的方式直观地捕获攻击，例如，图中的图。
4.实验表明，我们基于标记的方法是非常有效的：例如，侦探可以分析3850万个事件，并生成一个只有130个事件的攻击场景图，代表事件量减少了5个数量级。</p></li>
<li><p>本文的第四个贡献，旨在解决上面提到的最后两个挑战，是一个用于<strong>标记初始化和传播的可定制策略框架</strong>(第4节)。我们的框架提供了合理的默认值，但是可以覆盖它们以适应特定于操作系统或应用程序的行为。这使我们能够调整检测和分析技术，以避免在良性应用程序表现出类似攻击行为的情况下出现误报。(参见第6.6节了解的尾部。)策略还使分析人员能够测试攻击的“备选假设”，方法是重新对认为为可信或敏感的内容进行分类，并重新运行分析。如果分析人员怀疑某些行为是攻击的结果，他们还可以使用策略捕获这些行为，并重新运行分析以发现其原因和影响。由于我们处理和分析审计数据的速度比它生成的速度快数万倍，因此可以有效地、并行地、实时地测试alternate假设。</p></li>
</ul>
<p>本文的最后贡献是一个实验评估（第6节），主要基于由<strong>DARPA组织</strong>的一个红色团队评估，作为其透明计算项目的一部分。在这项评估中，<strong>在Windows、FreeBSD和Linux主机</strong>上进行了类似现代apt的攻击活动。在这项评估中，侦探能够：</p>
<ul>
<li>在几秒钟内处理包含参与期间产生的数千万事件的审计日志；</li>
<li>成功地检测和重建这些攻击的细节，包括它们的入口点、系统中的活动和过滤点；</li>
<li>过滤无关事件，实现数据中非常高的减少率(高达100K次)，从而提供这些攻击的清晰语义表示，其中几乎不包含系统中其他活动的噪声；</li>
<li>并实现较低的假阳性和假阴性率。</li>
</ul>
<p>我们的评估并不是为了表明我们发现了最复杂的对手；相反，我们的观点是，给定几种未知的可能性，我们系统的优先级结果可以实时到位，没有任何人类的帮助。因此，它确实填补了今天存在的一个空白，即法医分析似乎主要是手动启动的。</p>
<h3><span id="二-主内存依赖性图">二、 主内存依赖性图</span></h3>
<p>为了支持快速检测和实时分析，我们将依赖关系存储在图形数据结构中。存储此图的一个可能的选择是图形数据库。然而，诸如Neo4J[4]或Titan[6]等流行数据库的性能[39]在许多图形算法中都是有限的，除非主内存足够大，可以容纳大部分数据。此外，一般图数据库的内存使用太高，适合我们的问题。即使是毒刺[16]和NetworkX[5]，两个为主存性能而优化的图形数据库，每个图边[39]分别使用约250字节和3KB。<strong>在企业网络上报告的审计事件的数量每天很容易达到数十亿到数百亿亿美元之间，这将需要几tb范围内的主内存。相比之下，我们提出了一个更有效的空间依赖图设计，每条边只使用大约10个字节。在一个实验中，我们能够在329mb的主存中存储38m个事件</strong>。</p>
<p><strong>Subjects</strong>：</p>
<ul>
<li>表示进程；</li>
<li>属性值包括：process
id（pid）、命令行、所有者（owner）以及代码和数据的标签</li>
</ul>
<p><strong>Objects</strong>：</p>
<ul>
<li>表示实体，例如文件、pipes、网络连接</li>
<li>属性值包括：名称、类型（文件、pipe、socket等）、所有者和标签</li>
</ul>
<p><strong>事件</strong>：subjects和objects之间或者两个subjects之间带标签的边，用read
、connect、 execveread、connect、execveread、connect、execve来表示。
<strong>事件存储在subjects中</strong>，从而消除了subject-event的指针、事件标识符（event
id）的需求。他们的表示采用<strong>可变长编码</strong>，在通常情况下可以采用4
bytes，当需要时可以扩展到8、12或者16 bytes。</p>
<h3><span id="三-标签和攻击检测">三、 标签和攻击检测</span></h3>
<p>我们使用标签来描述<strong>objects和subjects的可信度和敏感度</strong>。对可信度和敏感度的评估基于以下三个因素：</p>
<ul>
<li><strong>起源（Provenance）</strong>：依赖图中，subject或object直接祖先的标记</li>
<li><strong>系统先验知识</strong>：我们对一些重要应用行为的了解，比如远程接入服务器、软件安装程序和重要的文件（/etc/passwd
和 /dev/audio）</li>
<li><strong>行为</strong>：观察subject的行为，并将其与预期行为进行比较</li>
</ul>
<p>一个默认的策略被用从从input到output传播标签：为output分配input的可信度标签中的最低值，以及机密性标签的最大值（也就是说，入口点的行为是危险的，出口点的行为也被标注为危险；入口点的数据是机密的，出口点的数据也被标注为是机密的）。这是一种保守的策略，该策略可能会导致一些良性事件被错误地识别为恶意事件（over-tainting），但绝不会漏掉攻击。</p>
<p><strong>标签在SLEUTH中扮演了核心角色</strong>。它为攻击检测提供了重要的上下文信息，每个事件都在这些标记组成的上下文中进行解释，以确定其导致攻击的可能性。此外，标签对我们的前向和回溯分析的速度也很有用。最后，标签为消除大量与攻击无关的审计数据也起到了关键作用。</p>
<h4><span id="31-标签设计">3.1 标签设计</span></h4>
<p>如下定义<strong>可信度标签（trustworthiness
tags，t-tags）</strong>，可信度依次降低：</p>
<ul>
<li><p><strong>良性可信标签（Benign authentic
tag）</strong>：为<strong>数据和代码</strong>分配该标签，其来源（source）为<strong>良性</strong>且可靠性<strong>可被验证</strong>的</p></li>
<li><p><strong>良性标签（Benign
tag）</strong>：为<strong>数据和代码</strong>分配该标签，其来源为<strong>良性</strong>，但是来源可靠性<strong>未被充分验证</strong></p></li>
<li><p><strong>未知标签（Unknown
tag）</strong>：为<strong>数据和代码</strong>分配该标签，但是其来源未知</p></li>
</ul>
<p><strong>策略（policy）定义了那些来源是良性的</strong>，哪些来源验证时充分的；策略的最简单情况是白名单。如果对于某个源，没有策略应用在它上面，那么这个源则被打上未知标签。如下定义<strong>机密性标签（confidentiality
tags，c-tags）</strong>，机密性依次降低：</p>
<ul>
<li><strong>Secret</strong>：高度敏感的信息，例如登陆凭证、私钥</li>
<li><strong>Sensitive</strong>：数据的披露可能会对安全产生重大影响，例如，披露了系统中的漏洞，但没有为攻击者提供访问系统的直接途径。</li>
<li><strong>Private</strong>：资料的披露涉及私隐，但未必构成安全威胁。</li>
<li><strong>Public</strong>：可以被公开的数据</li>
</ul>
<p>我们设计的一个重要方面是分离<strong>代码和数据的t-tag</strong>。具体而言，即一个subject给定两个t-tag，一个表示其代码可信度（code
trustworthiness，code t-tag），另一个表示其数据可信度（data
trustworthiness，data
t-tag）。这样的设计可以削减重建场景的规模，加快取证分析的速度。而机密性标签仅仅与数据相关联。</p>
<p>已经存在的objects和subjects使用<strong>标签初始化策略</strong>分配初始标签。在系统执行过程中还会产生新的objects和subjects，它们由<strong>标签传播策略</strong>分配标签。最后，<strong>基于行为的检测策略</strong>来检测攻击。</p>
<h4><span id="32-基于标签的攻击检测">3.2 基于标签的攻击检测</span></h4>
<p>检测方法不应该要求知晓特定应用的一些细节，因为这需要有关应用程序的专家知识，而在动态环境中，<strong>应用程序可能会频繁更新</strong>。</p>
<p>我们不把着眼点放在变化的应用行为上，而是着眼于攻击者的高级别目标，比如后门插入和信息窃取。具体而言，我们结合了攻击者的动机和手段的推理，注意到我们提出的标签就是用来捕获攻击者的手段：如果一段数据或代码有未
知 标 签 未知标签未知标签，那么它就是由不受信任的源产生的。</p>
<p>根据攻击者的攻击步骤，我们<strong>定义</strong>了下面包含<strong>攻击者目标和手段的策略</strong>（Detection
Policy）：</p>
<ul>
<li><p><strong>不受信任的代码执行</strong>：当一个拥有高code
t-tag的subject执行或<strong>加载拥有低t-tag的object</strong>时，便会引发警报</p></li>
<li><p><strong>被拥有低code t-tag的subject修改</strong>：当拥有低code
t-tag的subject修改一个拥有高t-tag的object时，便会引发警报。修改的可能是文件内容或者文件名、文件权限等。</p></li>
<li><p><strong>机密文件泄露</strong>：当不可信的subjects泄漏敏感数据时，将触发警报。具体地说，也就是具有sensitive
c-tag 和 unkonwn code
t-tag的subject在网络中执行写操作时会触发警报。</p></li>
<li><p><strong>为执行准备不可信的数据</strong>：该策略由一个拥有unknown
t-tag的subject的操作触发，该操作使一个object可执行。这样的操作会包含chmod和mprotect</p></li>
</ul>
<blockquote>
<p><strong>一点优势</strong>：值得注意的是，攻击者的手段并不会因为数据或代码经过了多个中间媒介之后而被“稀释”。啥意思呢？举个栗子：对于不受信任的代码执行策略来说，如果直接从未知网站加载数据的话，当然会触发警报。但是，当这些数据是被下载、提取、解压缩，甚至有可能是编译之后再加载的，在经过了重重转化之后，只要数据被加载，该策略仍然能够被触发。随后再进行回溯分析，就可以找到漏洞利用的第一步。</p>
<p>（与其它探测器合作的能力）另外，<strong>其它检测器的输入可以很容易地被集成到SLEUTH中</strong>。比如说，某个外部的检测器将一个subject标为可疑，这个时候再SLEUTH中可以将该subject的code
t-tag标为unknown，从而后面的分析都会受益。此外该操作也会保留图节点之间的依赖关系。</p>
</blockquote>
<p>被不受信的代码执行所触发的策略，不应该被认为工作在静态环境中（需要动态匹配策略），静态环境意味着不允许新代码产生。实际上，我们期望可以连续地更新和升级，但在企业环境中，我们不希望用户下载未知代码。因此，下面会叙述如何支持标准化的软件更新机制。</p>
<h3><span id="四-策略框架">四、策略框架</span></h3>
<p>本文开发了一个灵活的<strong>策略框架（policy
framework）</strong>，用于标签的分配、传播和攻击检测。我们使用<strong>基于规则</strong>的记法来描述策略，例如：</p>
<p><code>exec(s,o):o.ttag&lt;benign→alert("UntrustedExec")</code></p>
<p>这条规则被触发的条件是：当一个subject s 执行了一个object
o(比如文件），而o的t-tag要小于良性。
在该策略框架中，<strong>规则通常与事件关联</strong>，并且包含objects或subjects的<strong>属性的一些条件</strong>，这些属性包括：</p>
<ul>
<li><p><strong>name</strong>：使用Perl正则表达式来匹配<strong>object
name</strong>和<strong>subject命令行</strong></p></li>
<li><p><strong>tags</strong>:
条件中可以放置objects或subjects的t-tags或者c-tags。对于subjects来说，代码和数据的t-tag可以分别使用</p></li>
<li><p><strong>所有权和权限</strong>：条件中可以放置objects和subjects的所有权，或者objects和事件权限</p></li>
</ul>
<p>不同类型的策略有不同的作用：</p>
<ul>
<li>检测策略：引发警报</li>
<li>标签初始化和传播策略：修改标签</li>
</ul>
<p><strong>触发点（trigger
points）</strong>：为了更好地控制不同类型策略的匹配，我们将策略与触发点联系起来。此外，触发点允许有相似目的的不同事件共享策略。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191554914.png" alt="在这里插入图片描述">
<figcaption aria-hidden="true">在这里插入图片描述</figcaption>
</figure>
<p>上图展示了策略框架中定义的触发点，define表示一个新的object，比如一个新网络连接的建立、首次提及一个已经存在的文件、新文件的创建等。
（检测策略匹配过程）当事件出现时，检测策略就会被执行。后面，除非手动配置，否则仅当<strong>目标subject或object</strong>（某个信息流的终点，Target）发生变化时，检测策略才会被再次执行。</p>
<p>（标签策略）然后，标签策略按照指定的顺序进行尝试，一旦规则匹配，被规则指定的标签将会被分配给<strong>目标事件（Target，也就是subject/object）</strong></p>
<h3><span id="五-基于标签的双向分析">五、基于标签的双向分析</span></h3>
<h4><span id="51-回溯分析">5.1 回溯分析</span></h4>
<p>回溯分析的目标是识别攻击的入口点，入口点是图中入度为0的节点，并且被标记为untrusted。通常是网络连接，但有时也会是其他形式，比如U盘中的文件。</p>
<p><strong>回溯分析的起点是检测策略产生警报的地方</strong>。每个警报都与一个或多个实体相关，这些实体在图中被标记为可疑节点。反向搜索涉及对图的反向遍历，从而识别由可疑节点连接到入口点的路径。我们注意到，在这样的遍历和接下来的讨论中，依赖关系边的方向是相反的。反向搜索带来了几个重大<strong>挑战</strong>:</p>
<ul>
<li><p><strong>性能</strong>：依赖图可能包含数亿条边。警报数可以达到数千。在这么大的图上执行反向搜索，会消耗大量的计算资源。</p></li>
<li><p><strong>多路径</strong>：通常，从可疑节点向后可访问多个入口点。然而，在APT攻击中，通常只有一个真正的入口点。因此，简单的反向搜索可能会导致大量的误报</p></li>
</ul>
<p>标签可以用来解决这两个挑战。一方面，标签的计算和传播本来就是一种简洁的路径计算。另一方面，如果节点的标签值是unknown，那么该节点很有可能会构成攻击路径。如果节点A的标签是unknown，这意味着至少存在一条路径，从不受信任的入口点指向节点A，这样节点A就比其他拥有良性标签的邻居节点更有可能是攻击的一部分。使用标签来进行反向搜索，消除许多无关节点，极大地减少了搜索空间。</p>
<p>基于此，我们将反向分析当作<strong>最短路径问题</strong>的一个实例，<strong>标签</strong>被用来定义边的代价<strong>（cost）</strong>。一方面，标签能够“引导”搜索沿着攻击相关的路径，并远离不相关的路径。这使得搜索可以在不必遍历整个图的情况下完成，从而解决了性能方面的挑战。另一方面，最短路径算法通过选择最接近可疑节点的入口点（以路径成本衡量）来解决多个路径的挑战。
计算最短路径使用<strong>Dijkstra算法</strong>，当入口点被加入到路径中时，算法就停止。</p>
<p><strong>代价函数设计</strong>：对于那些表示节点依赖关系的<strong>边</strong>，如果其标签是<strong>“未知”</strong>，则为其分配<strong>较低的开销</strong>；其它节点分配较高的开胶，<strong>具体地说：</strong></p>
<ul>
<li>从一个“未知”数据/代码 t-tag 的节点，到一个“良性”代码/数据 t-tag
节点的边，为其分配<strong>代价为0</strong></li>
<li>从一个“良性”代码/数据 t-tag
的节点引出的边，为其分配一个<strong>较高的代价</strong></li>
<li>从已有“未知” tag
的节点之间引入边，为其分配<strong>代价为1</strong></li>
</ul>
<p>与未知 subject/object 直接相关的良性 subject/object
表示图中恶意和良性部分之间的边界。因此，它们必须包含在搜索中，因此这些边的代价是0。</p>
<p>良性实体之间的信息流动不是攻击的一部分，因此我们将它们的代价设置得非常高，以便将它们排除在搜索之外。</p>
<p>不可信节点之间的信息流可能是攻击的一部分，因此我们将它们的代价设置为一个较低的值。它们将被包括在搜索结果中，除非由较少边组成的可选路径可用。</p>
<h4><span id="52-向前分析">5.2 向前分析</span></h4>
<p>前向分析的目的是为了评估攻击的影响。通过从一个入口点开始，发现所有依赖于入口点的可能影响。与反向分析类似，主要的挑战是图的大小。一种简单的方法是，标记所有从入口点可到达的
subject/object，这些 subject/object
是通过反向分析得到的。不幸的是，这种方法将导致影响图太大。
在实验中，利用这种方法得到的影响图包含数百万条边，利用我们的简化算法可以降低100到500倍。</p>
<p>一个降低其大小的方法是使用距离阈值dth
，来排除那些距离可疑节点太远的点，分析人员可以调节该阈值。我们使用在回溯分析时使用到的
cost 。</p>
<p>（为什么回溯分析不考虑？？）不同于回溯分析的是，我们考虑机密性。特别的，一条边两端的节点，一个由高机密性标签，另外一个具有低代码
integrity（可信度？？） 标签（如未知进程）或者低数据 integrity
标签（如未知socket），那么为这条边分配代价为0；而当另一个节点由良性标签时，为其分配较高代价值。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-滴滴安全《安全运营之自动编排SOAR的探索》</title>
    <url>/posts/18H2CQ3/</url>
    <content><![CDATA[<h2><span id="滴滴安全运营之自动编排soar-的探索">滴滴安全运营之自动编排
(SOAR) 的探索</span></h2>
<blockquote>
<p>DiDi:https://www.secrss.com/articles/25896</p>
</blockquote>
<h4><span id="困难和挑战">困难和挑战</span></h4>
<ul>
<li><strong>海量异构的日志数据源</strong>
<ul>
<li><strong>覆盖广</strong>：通过各类sensor采集的数据，覆盖了办公网和客服网的终端，以及测试网生产网的服务器，还有公有云的虚拟机等等。</li>
<li><strong>来源多</strong>：HIDS，网络层的NTA，终端EDR，还有VPN的认证日志，DNS的解析记录，802.1x的认证，AD域控的日志，还有防火墙邮件服务器密罐的日志等等。</li>
<li><strong>量级大</strong>：每天用于安全审计的原始日志达到了10Tb及以上的量级。</li>
<li><strong>异构性</strong>：Hive、ElasticSearch、Kafka等等，而有些日志是设备通过Syslog和Webhook的方式打给我们的，这些日志都是异构的。</li>
</ul></li>
<li><strong>有效的告警会淹没在误报当中</strong>
<ul>
<li>黑名单的规则来定义异常，无法感知未知；白名单规则，通过定义正常来发现异常；</li>
<li><strong>统计规则阈值的选取也和误报息息相关</strong>；</li>
<li><strong>在甲方日常的安全运营中，团队可能会受 KPI的影响</strong></li>
</ul></li>
<li><strong>告警研判推理的挑战</strong>
<ul>
<li><strong><font color="red">
如果我们缺少有效的关联分析能力，就很难从各个孤立的告警中还原出攻击者的一次战术动作。</font></strong></li>
<li><strong>告警研判过程中存在重复低效的二次取证的工作</strong></li>
<li><strong>不完备的资产实体库</strong></li>
<li><strong>研判过程中还缺乏知识的指引</strong></li>
</ul></li>
</ul>
<h4><span id="如何针对事件检测响应去建构知识体系"><strong>如何针对事件检测响应去建构知识体系？</strong></span></h4>
<ul>
<li><strong>知识模型</strong>：STRIDE的模型、kill
Chain杀链模型、ATT&amp;CK模型</li>
<li><strong>知识交换</strong>：指交换威胁情报和lOC识别的知识，目前业内比较通用的有像<strong>==STIX2.0==，还有TAXll协议</strong>。</li>
<li><strong>知识运用</strong>：如何运用知识来指导我们做lOC规则的开发，如何做研判策略的设计，以及如何制定事件处置的SOP流程等等。</li>
<li><strong>知识迭代</strong>：知识模型自身的迭代，比如说近期ATT&amp;CK模型也推出了<strong>Sub-techniques</strong>，就是子技术的概念。另一方面就是日常运营的案件如何反馈到知识模型来做迭代。</li>
</ul>
<h4><span id="如何建立科学的度量和评价体系"><strong>如何建立科学的度量和评价体系？</strong></span></h4>
<p>我们在事件检测运营中有很多指标，比如<strong>围绕资产实体的，有HIDS部署的覆盖率，比如终端EDR的安装覆盖率，还有跨网络、跨安全域网络边界、南北向流量检测覆盖率</strong>等等。</p>
<p>还有围绕运营流程的，比如像比较核心的MTTD/MTTR指标。还有围绕能力矩阵的，比如ATT&amp;CK矩阵的覆盖率。<strong>指标的选取，它关系到能否把控安全态势的全局以及能否做好牵引能力的建设，因此选取有效的度量和评价体系，也是存在挑战的。</strong></p>
<blockquote>
<p><strong>MTTD = 故障与检测之间的总时间/事件数量</strong></p>
<p><strong>MTTA =
指从系统产生告警到人员开始注意并处理的平均时间。</strong></p>
</blockquote>
<h3><span id="安全编排自动化与响应soar它能为安全事件检测与响应流程带来哪些改善"><strong>安全编排自动化与响应SOAR，它能为安全事件检测与响应流程带来哪些改善?</strong></span></h3>
<blockquote>
<p><strong>SOAR分为安全编排自动化，安全事件响应平台，以及威胁情报平台三种技术工具的融合。</strong></p>
</blockquote>
<h4><span id="soar如何加速事件检测和响应"><strong>SOAR如何加速事件检测和响应</strong></span></h4>
<p>首先在IDR运营流程中，我们接收到一个异常的事件Event，我们如何通过SOAR的思想来处理这个事件，从而提升IDR流程的效率？</p>
<ul>
<li><strong>告警分诊</strong>:一个原始的告警里边可能只包含了少量的事件信息，我们需要在这个阶段使<strong>告警丰富化</strong>，也就是
Enrichment概念——<strong>将原始告警中的IP服务器，终端ID这样的字段，在我们内部的资产库当中查询出详细的信息，并且自动补充到告警信息中。</strong></li>
<li><strong>初步决策</strong>，比如有些字段命中了<strong>白名单库</strong>，或者威胁情报显示这是一个非恶意的良性的特征。将告警作为误报直接关闭，减少后面人工审计的运营负担。</li>
<li><strong>调查取证</strong>：通过SOAR的自动调用能力，可以调用后台的数据，收集更多的IOC信息，我们也可以调用沙箱这个能力对可疑文件进行动态的检测，得到检测结果，从而实现证据的自动收集。</li>
<li><strong>溯源关联分析</strong>：实现告警事件的上下文相关联事件的聚合。</li>
</ul>
<blockquote>
<p>比如说同一个告警事件，它发生在不同的资产实体上，或者说同一个资产实体，它在一定的时间段内，发生了多类的告警事件.</p>
</blockquote>
<p><strong>经过前期的告警分诊、误报关闭、调查取证的几个阶段，原始的事件event就转化为了一个需要人工验证的incident案件</strong>。在这个环节安全工程师会根据前面SOAR自动补充和取证的信息做出研判，进入到对这个事件的响应的流程。<strong>响应阶段也可以利用SOAR自动地执行安全处置的动作，包括邮件IM通知员工，或创建处置或漏洞工单，或是向防火墙/终端EDR下发安全策略（比如封禁）等等</strong>。这样我们就通过SOAR完成了一次告警事件的检测与响应的流程。</p>
<h4><span id="剧本编排的概念"><strong><font color="red">
剧本编排的概念</font></strong></span></h4>
<p><strong>以钓鱼邮件检测与响应的剧本为例。</strong></p>
<ul>
<li><strong>检测钓鱼邮件</strong>时，首先是提取<strong>邮件的信息</strong>，包括<strong>发件人</strong>、<strong>收件人</strong>、正文里可点击的<strong>url链接列表</strong>、<strong>附件</strong>等等。
<ul>
<li>从AD里查询出<strong>员工的相关信息</strong>，可以自动去邮件服务器的访问日志里面去查看员工近期有没有<strong>异常的登录行为</strong>，比如说异地登录，或者是使用非常设备登录等等。</li>
<li><strong>URL链接</strong>，我们首先去威胁情报里查一下有没有命中情报样本。针对可疑的URL链接，我们可以结合像Whois信息，像域名的信息，对
URL进行评分。</li>
<li><strong>针对邮件的附件</strong>也可以做静态分析，看是否包含
office鱼叉。我们还可以利用Cuckoo这样的动态沙箱对邮件附件里的可执行文件做行为检测。我们还可以利用外部的比如Virus
Total这样的样本分析平台，来看是否命中恶意样本。</li>
</ul></li>
<li>经过信息的自动化收集和分析的动作，我们进入到最后的<strong>人工审计环节</strong>。这个时候安全工程师会结合前面自动收集的信息去做研判。一旦安全工程师识别出这是一个有效的钓鱼邮件，也会通过<strong>剧本的方式去执行后续的这些自动化的动作，包括向员工发送告警工单，要求他修改域账号的密码</strong>。我们还可以将发件人的邮箱加入邮件安全网关的发件人黑名单列表里，防止他再给其他员工继续发邮件。我们也可以将恶意的或可疑的钓鱼邮件链接的域名加入到我们DNS封禁列表里，<strong>来防止进一步的扩散</strong>。</li>
</ul>
<h4><span id="结合滴滴的实践经验和探索介绍贴合甲方实际场景的soar建设思路"><font color="red">
结合滴滴的实践经验和探索，介绍贴合甲方实际场景的SOAR建设思路</font></span></h4>
<p><strong>需要明确SOAR</strong>在事件检测响应体系中的定位，也就是它<strong>与SIEM/SOC/安全事件响应平台SIRP之间的关系</strong>，还有它<strong>与TIP威胁情报平台之间的关系</strong>。SOAR可以理解为是事件响应平台或者是SOC的扩展能力。
当然SOAR也可以作为一个独立的平台，与SOC和TIP实现打通。</p>
<blockquote>
<p>根据Gartner的定义，SOAR是一系列技术的合集，它能够帮助企业和组织收集安全运营团队监控到的各种信息，也包括各种安全系统产生的告警，并对这些信息进行告警分诊和事件分析。</p>
</blockquote>
<p><strong>SOAR在甲方如何落地，主要考虑三方面：</strong></p>
<ul>
<li><strong>实现路径</strong>:
<ul>
<li>可以采用商业化的产品，近期我们也看到很多国内外知名安全厂商陆续推出了SOAR这款产品。</li>
<li>我们也可以基于开源工具做二次开发，比如说剧本编排引擎，它特别类似于一个<strong>Workflow的工作流引擎</strong>，我们可以基于开源的像Activity或者是Airflow这样的工作流引擎去做二次的开发。</li>
<li>使用自研的方式。</li>
</ul></li>
<li><strong>技术选型</strong>：主要是考虑可视化剧本的编排引擎，还有剧本的执行引擎。</li>
<li><strong>系统设计</strong>：SOAR虽然是一个扩展的能力，但是从系统设计的角度来说，一旦我们引入SOAR，就会将它串联到我们整个的
IDR流程当中。所以SOAR自身的稳定性，还有一些其他的技术指标，比如像EPS每秒处理的事件数，SLA，包括一些其他的benchmark等等，这些也是我们关注的重点。刚才也提到SOAR会串联到IDR流程里，所以它有可能会引入或导致一个单点问题，所以我们也会考虑分布式的部署。还有降级，一旦SOAR不可用的时候，我们的SOC或者事件响应平台能否降级到没有SOAR的状态。</li>
</ul>
<h4><span id="如何评估soar的效果和收益"><strong><font color="red">
如何评估SOAR的效果和收益？</font></strong></span></h4>
<ul>
<li><strong>对IDR核心运营指标MTTD和MTTR的提升</strong>，它能让我们技术运营投入更少的人力去做更多的事，提升人效。</li>
<li><strong><font color="red">
他能否通过SOAR来识别攻击者完整的战术动作，也就是TTP。</font></strong></li>
<li>通过将剧本的引入，将流程案件知识固化下来，牵引我们能力侧的建设。</li>
</ul>
<h4><span id="结合滴滴的经验和探索介绍一下soar的系统设计思想"><strong>结合滴滴的经验和探索，介绍一下SOAR的系统设计思想？</strong></span></h4>
<p><strong>首先我们从各个sensor采集到的数据经过ETL存储在大数据的组件当中</strong>。我们的策略规则是作用在这些大数据的计算引擎上，像
Spark，Hadoop，还有Flink这样实时的引擎，也包括我们自研的异常检测的引擎，最终产生的异常告警事件会打到我们的event
gateway通用事件网关上。这一阶段被我们称为异常检测阶段。</p>
<p>事件网关主要做两个事：一，做<strong>标准化</strong>，将这些异构的数据源产生的各种类型的告警里的字段格式和数据类型做标准化，以便后面我们在做SOAR编排的时候降低成本。二，<strong><font color="red">
在这个环节我们会做
index，把原始的告警事件索引到数据库里，以便我们后面做关联分析，或者我们可以回溯的时候去实时地查询历史的告警事件数据。</font></strong></p>
<p>【<strong>告警分诊</strong>】经过事件网关以后，我们紧接着做两个事情，<strong>一个是做Enrichment丰富化</strong>，第二个是做<strong>威胁情报</strong>。我们在丰富化这个阶段会补齐像服务器地址、员工信息、终端信息和调研我们内部的核心的资产库，将告警信息做丰富化。
第二就是我们会初步匹配告警字段里边比如像域名，像文件哈希，去我们本地的威胁情报库里面做匹配。</p>
<p>【<strong>调查取证</strong>】接下来就进入到我们的核心检测阶段SOAR编排环节，在这个环节我们将各种检测能力抽象成为各种检测引擎，比如像攻击检测引擎、误报检测引擎、调查取证引擎和关联分析引擎等等。</p>
<ul>
<li><p>【<strong>黑名单</strong>】<strong>攻击检测</strong>引擎是做什么？主要是根据告警事件里的一些字段去我们本地的黑名单库列表里做匹配，一旦确认命中我们的黑名单，就可以不需要做后面一些列复杂的调查取证和关联分析工作，可以直接交给人工来做研判，甚至对它可以绕过人工来做自动化响应。</p></li>
<li><p>【<strong>白名单</strong>】<strong>误报检测</strong>是根据字段里边的一些特征，以及我们之前配置的白名单规则，命中了白名单，这个事件我们可以把它自动关闭掉，以减少后面调查取证的负担。</p></li>
<li><p><strong>调查取证</strong>我们是将一些通用的外部接口和能力封装成一些函数或者脚本，来做自动化的调用。而这些封装的能力之间，我们也是以一个子剧本的方式来进行编排，它可以根据剧本流程的配置来做自动化的执行和调用。</p></li>
<li><p><strong><font color="red">
关联分析引擎也是基于我们配置好的一些关联分析的规则，来针对这一个告警事件的上下文，或者一段时间内它同资产的一些其他告警事件来做关联和聚合，上报给人工去做研判。</font></strong></p></li>
</ul>
<p><strong>这些不同的检测引擎之间，我们也是通过剧本的方式把它进行一个整体的编排</strong>。有些我们可以先经过攻击检测引擎，误报检测引擎，再做调查取证和关联分析；而有一些告警类型，我们通过剧本的编排，它就不需要去做攻击检测了，比如他通过误报检测就可以直接到调查取证检测。这些其实都是通过剧本来实现一个动态编排。</p>
<p>【<strong>人工验证</strong>】经过这个阶段的检测，原始事件就形成了一个具体的需要人工验证的案件，也就是<strong>incident</strong>。从原始的事件到案件，这个阶段我们称它为是检测阶段的SOAR编排。【<strong>自动处置</strong>】这阶段经过人工的验证，如果是一个有效的案件需要经过处置的话，它就会进入到后续的自动处置的流程里面。而这一阶段我们也是通过剧本的方式，将各种处置能力封装来自动编排上。这里边包括像通过邮件和IM消息的方式来通知用户，也包括我们调用工单系统，还有就是我们调用
EDR/IPS/防火墙的一些封禁策略等等，把它封装成自动的脚本，通过剧本的方式做编排，做自动的调用。</p>
<h4><span id="在做soar系统设计的时候是如何把知识体系来融合到系统设计里的呢"><strong>在做SOAR系统设计的时候，是如何把知识体系来融合到系统设计里的呢？</strong></span></h4>
<p>在上文提到的情报交互里有一个<strong>STIX2.0协议</strong>，STIX2.0有很多个构件，其中有几个构件其实是可以指导我们去做异常检测规则的开发，以及SOAR编排里的关联分析和处置动作的。</p>
<ul>
<li><p><strong>indicator</strong>，就可以指导我们去做异常检测阶段的IOC规则开发；</p></li>
<li><p><strong>Attack
Pattern</strong>，描述的其实就是TTP，可以指导我们在SOAR检测阶段去做关联分析规则；</p></li>
<li><p><strong>course of
action</strong>构件，它是指导我们在做响应处置阶段的SOP的流程。</p></li>
</ul>
<p>我们前面也提到了ATT&amp;CK模型，其实<strong>ATT&amp;CK模型和STIX2.0之间是有映射关系的</strong>，我们可以将我们的异常检测规则映射到ATT&amp;CK模型上，主要是做两个事，第一个就是我们根据现有的检测点，可以总体来看我们<strong>对ATT&amp;CK的覆盖率</strong>，这样它能牵引我们去做能力侧的建设，也就是<strong>检测策略建设</strong>。<strong>当我们发现缺少哪一部分的检测能力，我们就可以去部署新的sensor，开发新的IOC规则。</strong></p>
<p><strong>我们也可以结合ATT&amp;CK模型去和我们的真实的日常运营中的案件做结合，去查看我们ATT&amp;CK热力图，去从整体安全态势上看我们哪些场景是经常会被攻击的</strong>。我们也可以结合资产的重要性、等级和实际发生的案件，通过一个公式来计算出我们整体的风险值。</p>
<p>【<strong>异常检测评估指标</strong>】整个SOAR流程和指标体系也是紧密结合的，包括我们在异常检测阶段有能力矩阵的覆盖率这样的指标。还有我们在检测阶段的SOAR编排决定了我们的MTTD（平均检测时间）的指标，以及在响应阶段SOAR关联了我们的MTTR（平均响应时间）指标。</p>
<p>这样我们就围绕着SOAR的系统设计，将IDR事件检测与响应流程、SOAR的自动编排、知识体系和指标体系，都融合在了我们整个的SOAR的系统设计思想里。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>智能安全运维</category>
      </categories>
  </entry>
  <entry>
    <title>AI安全（1）Adversarial Attacks and Defenses in Deep Learning: From a Perspective of Cybersecurity</title>
    <url>/posts/2CNVQ7Q/</url>
    <content><![CDATA[<h2><span id="adversarialattacks-and-defenses-in-deep-learning-from-a-perspective-ofcybersecurity">Adversarial
Attacks and Defenses in Deep Learning: From a Perspective of
Cybersecurity</span></h2>
<ul>
<li>https://dl.acm.org/doi/10.1145/3547330</li>
</ul>
<h3><span id="摘要">摘要</span></h3>
<p>深度神经网络的卓越性能推动了深度学习在广泛领域的应用。然而，对抗性样本带来的潜在风险阻碍了深度学习的大规模部署。在这些场景中，人眼无法察觉的对抗性扰动会显著降低模型的最终性能。已经发表了许多关于对抗性攻击及其在深度学习领域的对策的论文。大多数论文都集中在逃避攻击上，即在测试时发现对抗性示例，而不是在训练数据中插入中毒数据的中毒攻击。此外，由于没有标准的评估方法，很难评估对抗性攻击的真实威胁或深度学习模型的稳健性。因此，在本文中，我们回顾了迄今为止的文献。此外，我们试图为系统地理解对抗性攻击提供第一个分析框架。该框架是从网络安全的角度构建的，为对抗性攻击和防御提供生命周期。</p>
<h3><span id="说明">说明</span></h3>
<p>机器学习技术已被应用于广泛的场景，并取得了广泛的成功，尤其是在深度学习方面，它正迅速成为各种任务中的关键工具。然而，在许多情况下，机器学习或深度学习模型的失败可能会导致严重的安全问题。例如，在自动驾驶汽车中，无法识别交通标志可能会导致严重事故[1]。因此，在大规模部署之前，训练一个准确稳定的模型至关重要。不幸的是，近年来，许多研究揭示了模型安全中一个令人失望的现象，即深度学习模型可能容易受到对抗性示例的影响，即被对手恶意干扰的样本。以这种方式被篡改的模型很有可能会产生错误的预测，尽管它们可能在良性样本中显示出很高的准确性[2-5]。对抗性攻击可以被广泛定义为一类攻击，其目的是通过将对抗性示例插入训练阶段（称为中毒攻击[6-8]）或推理阶段（称称为逃避攻击[2，3]）来欺骗机器学习模型。无论哪种攻击都会显著降低深度学习模型的鲁棒性，并引发模型安全问题。此外，最近在现实世界中发现了深受这种模型安全问题困扰的深度学习解决方案的漏洞，这引发了人们对深度学习技术的信任程度的担忧</p>
<p>由于在深度学习技术的实际应用中，隐私和安全的潜在威胁多种多样，越来越多的组织，如ISO、IEEE和NIST，正在参与人工智能标准化的过程。对一些国家来说，这项工作被认为类似于一些国家的新基础设施建设[9]。ISO提出了一个关于人工智能系统生命周期的项目，该项目将技术的生命周期分为八个阶段，包括初始化、设计和开发、检查和验证、部署、运行监控、持续验证、重新评估和放弃[10]。本周期中没有进一步解决的是对抗性攻击如何阻碍深度学习模型的商业部署。因此，评估模型安全威胁是人工智能项目生命周期中的一个关键组成部分。此外，考虑到可能的对抗性攻击和防御的分散性、独立性和多样性，如何分析模型的安全威胁也应该标准化。迫切需要的是一个风险图，以帮助准确确定项目生命周期每个阶段的多种类型的风险。更严重的是，攻击的防御仍处于早期阶段，因此对更复杂的分析技术提出了更高的要求。</p>
<p>近年来，一些与对抗性机器学习相关的调查已经发表。Chakraborty等人[11]描述了安全相关环境中对抗性示例的灾难性后果，并回顾了一些强有力的对策。然而，他们的结论表明，它们都不能成为应对所有挑战的灵丹妙药。Hu等人[12]首先介绍了基于人工智能的系统的生命周期，用于分析每个阶段的安全威胁和研究进展。对抗性攻击分为训练和推理阶段。Serban等人[13]和Machado等人[14]分别回顾了在对象识别和图像分类中关于对抗性机器学习的现有工作，并总结了存在对抗性示例的原因。Serban等人[13]还描述了对抗性示例在不同模型之间的可转移性。与参考文献[14]提供设计防御的相关指导类似，Zhang等人[15]还从防御者的角度对相关工作进行了全面调查，并总结了深度神经网络对抗性示例起源的假设。还有一些关于对抗性机器学习在特定领域的应用的调查，如推荐系统[16]、网络安全领域[17]和医疗系统[18]。</p>
<blockquote>
<p>[17]</p>
</blockquote>
<p>先前已经观察到，在网络安全背景下，高级持续威胁（APT）通常是高度有组织的，成功的可能性极高[19]。以Stuxnet为例，这是最著名的APT攻击之一。它于2009年发射，摧毁了伊朗的核武器计划[19]。APT的工作流程系统地考虑了安全问题，这使得APT相关技术既能获得出色的成功率，即绕过这些防御，又能以高度有效的方式评估系统的安全性。受APT工作流程的启发，我们将此系统分析工具应用于网络安全问题，作为分析对抗性攻击威胁的潜在方法。APT主要由多种类型的现有底层网络空间攻击（如SQL注入和恶意软件）组成。不同类型的底层攻击的组合策略及其五阶段工作流程意味着，与单一攻击相比，APT的成功率极高。然而，有趣的是，根据现有的对抗性攻击策略，可以将其巧妙地划分为这五个阶段。基于这一观察，我们发现在评估对抗性攻击的威胁时，类似于APT的工作流程是有效的。因此，这构成了我们分析和对策框架的基础。尽管一些综述论文总结了模型安全方面的工作，但攻击方法或防御通常仍分为依赖类和分段类。这意味着不同方法之间的关系尚未明确确定。在这篇文章中，我们从APT的角度系统地对现有的对抗性攻击和防御进行了全面系统的回顾。我们的贡献如下：</p>
<ul>
<li>我们提供了一个新颖的网络安全视角来研究深度学习的安全问题。我们首次提出将APT概念纳入深度学习中对抗性攻击和防御的分析中。其结果是为模型安全性提供了一个标准的类似APT的分析框架。与之前部分关注机制[13，20]、威胁模型[21]或情景[22]的调查不同，我们的工作可以为理解和研究这个问题提供全局和系统层面的视角。具体而言，先前的研究倾向于在小组中讨论具有类似策略的方法。分别研究了不同策略的对抗性攻击，忽略了不同攻击群之间的关系。相反，我们的工作将对抗性攻击视为一个全球系统，每一组具有相似策略的攻击都只是这个全球系统的一部分。与网络安全类似，考虑不同群体之间的关系有助于进一步提高攻击的有效性；</li>
<li>基于类似APT的分析框架，我们对现有的对抗性攻击方法进行了系统的审查。根据APT的逻辑，对抗性攻击可以明确地分为五个阶段。在每个阶段，都确定了共同的基本组成部分和短期目标，这有助于以深入的顺序提高攻击性能；</li>
<li>我们还回顾了在类似APT的分析框架内对对抗性攻击的防御。同样，防御分为五个阶段，提供自上而下的顺序来消除对抗性例子的威胁。可以识别不同阶段的防御方法之间的关系，从而激发一种可能的策略，将多种防御结合起来，为深度学习模型提供更高的鲁棒性</li>
<li>我们分别从数据和模型的角度总结了对抗性示例存在的假设，并全面介绍了对抗性机器学习中常用的数据集</li>
</ul>
<p>我们希望这项工作能激励其他研究人员在系统层面上看待模型的安全风险（甚至隐私威胁），并在全球范围内评估这些风险。如果可以建立一个标准，那么各种财产，例如健壮性，就可以在更短的时间内更准确地访问。因此，用户对深度学习模型的信心将会增强。</p>
<h3><span id="二-相关研究">二、相关研究</span></h3>
<p>深度学习是指建立在深度神经网络（DNN）上的一组机器学习算法，已广泛应用于预测和分类等任务[21]。DNN是一种数学模型，包括具有大量计算神经元和非线性激活函数的多层。典型的深度学习系统的工作流程包括两个阶段：训练阶段和推理阶段。两个阶段的详细流程如下所示，如图1所示：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191546299.png" alt="image-20230402204215480">
<figcaption aria-hidden="true">image-20230402204215480</figcaption>
</figure>
<p>图1：深度学习系统的一般工作流程。在训练阶段，基于训练数据迭代更新参数θ。得到最佳参数θ后 ,
在推理阶段，输入将被输入到经过训练的模型中，这将为决策提供相应的输出</p>
<ul>
<li><p>在训练阶段，DNN的参数通过迭代前馈和反向传播不断更新。反向传播中的梯度下降方向是通过优化损失函数来引导的，该函数量化了预测标签和地面实况标签之间的误差。具体地，给定输入空间X和标签空间Y，最优参数θ 
期望DNN
f的损失函数L最小化训练数据集（X，Y）上的损失函数。因此，在训练过程中要找到最佳θ 
可以定义为：</p>
<p><span class="math display">\[
\theta^{\star}=\underset{\theta}{\arg \min } \sum_{x_i \in \mathcal{X},
y_i \in \mathcal{Y}} \mathcal{L}\left(f_\theta\left(x_i\right),
y_i\right)
\]</span></p>
<p>其中fθ是要训练的DNN模型；xi∈X是从训练数据集中采样的数据实例，yi和fθ（xi）分别表示相应的地面真实标签和预测标签。</p></li>
<li><p>在推理阶段，训练的模型f  具有固定最优参数的θ 
被应用来提供关于未被包括在训练数据集中的看不见的输入的决策。给定看不见的输入xj，可以通过单个前馈过程来计算相应的模型决策yj（即xj的预测标签）：yj=f 
θ（xj）。值得注意的是，一次成功的对抗性攻击通常会在推理阶段导致被操纵的预测yõ，这可能与xj的正确标签相去甚远。</p></li>
</ul>
<h4><span id="22-针对dnn的威胁模型">2.2 针对DNN的威胁模型</span></h4>
<p>为了对这些攻击进行分类，我们通过引入模型攻击的关键组件来指定针对DNN的威胁模型。威胁被分解为三个维度：对手的目标、对手的特异性和对手的知识。这三个维度可以帮助我们识别潜在的风险，并了解对抗性攻击环境中的攻击行为。在图2中，我们概述了对抗性攻击中的威胁模型。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191546534.png" alt="image-20230403202614103">
<figcaption aria-hidden="true">image-20230403202614103</figcaption>
</figure>
<h5><span id="221-攻击目标">2.2.1 攻击目标</span></h5>
<ul>
<li>中毒攻击。在中毒攻击中，攻击者可以访问和修改训练数据集，以影响最终训练的模型[23-26]。攻击者在训练数据中注入假样本以生成有缺陷的模型的方式可以被视为“中毒”。中毒攻击通常会导致准确性下降[25]或对给定测试样本的错误分类[26]。•躲避攻击。</li>
<li>在规避攻击中，对手的目标是攻击训练有素且固定的DNN，而没有任何权限修改目标模型的参数[13，18，23]。通过这种方式，攻击者不再需要训练数据集的可访问性。相反，攻击者生成目标模型无法识别的欺骗性测试样本，以逃避最终检测[27，28]。</li>
</ul>
<h5><span id="222-对抗性特异性">2.2.2 对抗性特异性</span></h5>
<p>对抗性特异性的差异取决于攻击者是否能够在推理阶段为给定的对抗性样本预先定义特定的欺诈预测。</p>
<ul>
<li>非目标攻击。在无目标攻击中，对手的唯一目的是欺骗目标模型生成错误预测，而不关心选择哪个标签作为最终输出[29-32]。</li>
<li>有针对性的攻击。在有针对性的攻击中，对于给定的样本，攻击者不仅希望目标模型做出错误的预测，而且还旨在诱导模型提供特定的错误预测[33-36]。一般来说，有针对性的攻击不会像无针对性的那样成功。</li>
</ul>
<h5><span id="223-敌人的知识">2.2.3 敌人的知识</span></h5>
<ul>
<li>白盒攻击。在白盒设置中，对手能够访问目标模型的细节，包括结构信息、梯度和所有可能的参数[30，34，37]。因此，对手可以通过利用手头的所有信息来精心制作对抗性样本。</li>
<li>黑匣子攻击。在黑盒设置中，攻击者在不了解目标模型的情况下实施攻击。攻击者可以通过与目标模型交互来获取一些信息[36，38，39]。这是通过将输入查询样本输入到模型中并分析相应的输出来完成的。</li>
</ul>
<h4><span id="23-对抗性攻击">2.3 对抗性攻击</span></h4>
<h5><span id="231-逃逸攻击">2.3.1 逃逸攻击</span></h5>
<p>Szegedy等人[2]首先在对抗性攻击中引入了对抗性示例的概念，它可以在推理阶段以高成功率误导目标模型。他们提出了一种通过等式（1）搜索具有目标标签的最小失真对抗性示例的方法：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191546941.png" alt="image-20230402210029648" style="zoom:50%;"></p>
<p>通过这个方程，他们可以找到最接近的x  通过最小化与良性样本x的距离 x  −
x 22，并且将被f（x）的条件错误地分类为目标标签t ) =
时间。这个问题可以导致方程（2）中的目标，该目标可以通过L-BFGS算法来解决：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191546006.png" alt="image-20230402210112765" style="zoom:50%;"></p>
<h5><span id="232-投毒攻击">2.3.2 投毒攻击</span></h5>
<p>与推理攻击中发生的规避攻击不同，中毒攻击旨在通过污染训练数据来降低模型的准确性。攻击者需要一些权限来操纵训练数据，例如数据注入和数据修改[11]。因此，发起中毒攻击的目标可以分为两类：可用性违规和完整性违规。前者旨在降低受害者模型的置信度或准确性，破坏整个系统，而后者试图在不影响其他正常样本的情况下，通过引入后门，在某些特定样本上误导受害者模型[11]。具体而言，针对仅涉及训练样本的神经网络的中毒实例可以通过以下两种策略来制作：双层优化和特征碰撞[23]。</p>
<ul>
<li>双层优化：修改数据的经典数据中毒可以形式化为双层优化问题[23]。然而，对于非凸神经网络，双层优化问题是棘手的。Mu~noz-Gonz´alez等人[24]提出了“反向梯度下降”来近似内部问题的解，然后对外部损失进行梯度下降，尽管这在计算上仍然很昂贵。为了加快中毒样品的生产，Yang等人[25]引入GAN来产生毒素。MetaPoison等人[26]也被提出作为一阶方法，使用集成策略近似解决生产毒药的双层优化。</li>
<li>特征冲突：基于双层优化的方法通常对迁移学习和端到端训练都有效，而特征冲突策略可以用于在有针对性的错误分类设置中设计针对迁移学习的有效攻击。例如，Shafahi等人[40]开发了一种方法，在特征空间中生成与目标样本相似的中毒样本，同时在输入空间中接近原始良性样本。这两类方法只需要操作训练的权限，而不需要标签，并且训练数据的语义将保持不变。这些带有干净标签的中毒样本将更难被检测到。</li>
</ul>
<p>此外，除了仅操纵训练数据的中毒攻击外，另一种类型的中毒攻击是后门攻击，它需要在推理阶段向输入插入触发器的额外能力[23]。</p>
<p>后门攻击：后门攻击中的对手通常可以修改训练样本的标签[41]。这些带有后门触发器的错误标记数据将被注入到训练数据集中。因此，基于该数据集的训练模型将被迫为新样本（使用触发器）分配所需的目标标签。大多数后门攻击都需要在制作毒药的过程中给训练样本贴上错误的标签，而这些毒药更有可能被防御者识别出来。因此，还提出了一些干净标签后门攻击[42]，并使用参考文献[40]中提出的特征碰撞策略来制作后门样本。</p>
<h4><span id="24-advanced-persistentthreats">2.4 Advanced Persistent
Threats</span></h4>
<p>高级持久性威胁（APT）是一系列新定义的攻击过程，其中攻击是长时间连续的，例如数年。分析APT的工作流程构成了我们对抗性攻击和防御分析框架的基础。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>AI安全</category>
      </categories>
  </entry>
  <entry>
    <title>高级威胁发现（1）基于溯源图的入侵检测</title>
    <url>/posts/ANF4PB/</url>
    <content><![CDATA[<h2><span id="基于溯源图的入侵检测">基于溯源图的入侵检测</span></h2>
<blockquote>
<ul>
<li>浙大：https://www.zhihu.com/people/li-zhen-yuan-20/posts</li>
<li>武大：</li>
<li>中科院：</li>
</ul>
</blockquote>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553343.png" alt="image-20230320161317805">
<figcaption aria-hidden="true">image-20230320161317805</figcaption>
</figure>
<p>从早期的对恶意程序的动静态分析，到现在业界比较热门的对攻击链的检测，这个议题已经历很多很多。但很多现有的研究因为开销和误报问题并没有被真正的用于生产环境。而现有的安全产品大多基于静态分析和简单的动态分析，并不能很好的为攻击建模，已经越来越难适应复杂多变的攻击形式和攻击场景；</p>
<blockquote>
<p><strong>2019 CCS 议题 Cyber Threat
共有四篇文章</strong>，列举如下：</p>
<ol type="1">
<li><strong>Log2vec: A Heterogeneous Graph Embedding Based Approach for
Detecting Cyber Threats within Enterprise</strong>, Fucheng Liu, Yu Wen,
Dongxue Zhang, Xihe Jiang (Chinese Academy of Science),Xinyu Xing (The
Pennsylvania State University),Dan Meng (Chinese Academy of
Science)</li>
<li><strong>POIROT: Aligning Attack Behavior with Kernel Audit Records
for Cyber Threat Hunting</strong>, Sadegh M. Milajerdi (UIC),Birhanu
Eshete (University of Michigan-Dearborn),Rigel Gjomemo (UIC),V.N.
Venkatakrishnan (UIC)</li>
<li><strong>Effective and Light-Weight Deobfuscation and Semantic-Aware
Attack Detection for PowerShell Scripts</strong>, Zhenyuan LI (Zhejiang
University),Qi Alfred Chen (University of California, Irvine),Chunlin
Xiong (Zhejiang University),Yan Chen (Northwestern University),Tiantian
Zhu (Zhejiang University of Technology),Hai Yang (MagicShield Inc)</li>
<li><strong>MalMax: Multi-Aspect Execution for Automated Dynamic Web
Server Malware Analysis</strong>, Abbas Naderi-Afooshteh (University of
Virginia),Yonghwi Kwon (University of Virginia),Jack Davidson
(University of Virginia),Anh Nguyen-Tuong (University of Virginia),Ali
Razmjoo-Qalaei,Mohammad-Reza Zamiri-Gourabi (ZDResearch)</li>
</ol>
</blockquote>
<p>其中，前两篇都用图表示攻击流程，然后分别采用机器学习的方法和图匹配的类规则方法进行检测。而后两篇则将关注点放在脚本类的恶意程序上。前者（也就是我们的工作）用主要是静态分析的方法解决混淆问题，而后者则用动态方法分析了恶意程序变体的问题。下面我们分两组讨论这四篇文章。</p>
<h3><span id="前言">前言：</span></h3>
<h4><span id="网络空间威胁检测面临的一些研究问题">网络空间威胁检测面临的一些研究问题？</span></h4>
<ul>
<li><strong>缓慢又隐蔽的高级持续性威胁的检测难题</strong>：高级持续性威胁（Advanced
Persistent
Threat）往往采用隐蔽的攻击形式，在很长的一段时间内缓慢的渗透入目标系统并长期潜伏以达到攻击目的。因为其缓慢又隐蔽的特性，传统的防御手段往往很难对其实施有效的监控。正所谓“我设置阈值过高，就会错过攻击；我设置阈值过低，就没空管理系统（误报太多）”。</li>
<li><strong>用什么数据什么结构准确度表示一个威胁行为的问题</strong>：用什么方式表示一个威胁或攻击行为一直以来被研究者关注。不同的表示方式都有其优点与缺点，很难给出一个绝对的判断，应该根据不同场景做不同选择。举例来说，<strong>现在常用的威胁情报（IoC）使用非常简单的数据，包括恶意的IP、恶意文件的Hash，几乎没有任何鲁棒性可言</strong>，但却是现实中常用的安全工具，有效的保护了许多系统的安全。其他常见的方式还包括，系统调用的序列、API调用树、代码动态执行图等。一般而言，简单的结构意味着更高的效率，但表达能力更差，误报的概率更高。而复杂的结构，表达能力更好的同时检测效率却受到影响。</li>
<li><strong>如何设计检测算法权衡威胁检测的响应速度与检测精度矛盾</strong>：威胁检测的系统的响应速度很大程度的影响了该系统的应用场景和价值。响应速度越快，就能越早的定位并阻止进一步的攻击发生，从而尽可能的减小损失。但是鱼与熊掌往往不可得兼，效率高、响应速度快的速度在检测能力上往往不如响应速度慢、收集数据更加全面的系统。现有的系统都尝试在响应速度和检测精度之间找到一个行之有效的平衡点。</li>
<li><strong>如何设计存储系统以权衡存储空间与查询效率之间的矛盾</strong>：如前面所说，高级持续性威胁往往是“low
and
slow”的，攻击的周期可能长达几十天。此外，为了保护系统安全，日志系统往往需要保存很长一段时间内的日志以便事后的取证（Digital
Forensic）分析。因此系统有很强的存储的日志的需求。对一个大公司来说，这可能以为着PB级的存储以及百万美元的开销。因此<strong>日志存储系统的设计和针对性的数据压缩算法</strong>也是必不可少的。</li>
</ul>
<h4><span id="1-溯源图">1、溯源图</span></h4>
<p>溯源图（Provenance
Graph）描述计算机中的事件并在图中进行威胁检测是最近几年学术界和工业界都很关注的一个课题。使用图的形式，相比于之前常用的序列有更加好的表达能力。但是图上计算的复杂性，也给研究人员带来了许多的挑战，很多研究组在近几年带来了许多的研究成果（我可能会在后面展开讲讲这方面工作，也是一个很有意思的题目）。<strong>值得一提的是本议题第二篇文章
POIROT（大侦探波罗）的“侦探”三部曲（SLEUTH，HOLMES，POIROT）都发表在四大会上，有兴趣的同学可以在<a href="http://link.zhihu.com/?target=https%3A//www.researchgate.net/profile/Sadegh_Milajerdi%3FenrichId%3Drgreq-edb099d62869d1044744443018cd8dac-XXX%26enrichSource%3DY292ZXJQYWdlOzMzNjA1NzMyNztBUzo4MDcyNjA4MTMwMjUyODJAMTU2OTQ3NzM4NDE2Ng%3D%3D%26el%3D1_x_5%26_esc%3DpublicationCoverPdf">这里</a>找到更多。</strong></p>
<p><strong><font color="red">
溯源图是由计算机中的实体为节点（进程、文件、网络套接字）、将实体间的操作（进程文件、开启新的进程）视为节点之间的边，这样就构成了一个有向信息图。</font></strong>溯源图可以用来表示系统中的各种行为，包括各种攻击行为。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553381.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553747.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="2-如何在溯源图中高效的定位威胁呢">2、如何在溯源图中高效的定位威胁呢？</span></h4>
<h5><span id="poirot-签名匹配">POIROT 签名匹配：</span></h5>
<p>在 POIROT 中，作者们创新的提出了另一种和溯源图类似的图 --
查询图。<strong>他们先人工的分析 APT
攻击白皮书，入侵报告等威胁情报并手工提取出其中涉及的实体和实体间的操作，构成查询图（Gq）</strong>。然后给出了一个专门设计的图匹配算法，从而实现了个高效的检测。这其实是一种类似<strong>签名匹配的检测算法</strong>，因此优点在于较高的效率和低的误报率。但是缺点也很明显，这种方法无法检测未知的攻击，对变体的抵抗能力也比较弱。而且提取特征的过程全是手工完成的，人力成本较高。</p>
<h5><span id="log2vec-异常检测">Log2vec 异常检测：</span></h5>
<p>首先值得一提的是，这也是一片国内的文章，出自中科院信工所。他们将最近在机器学习领域很火的
Graph Embedding
方法迁移到了“溯源图”上（这里需要说明，他们说使用的图结构在溯源图的基础上加上了很多额外的联系，因此联系更紧密）。他们的主要贡献在于证明了
Graph Embedding
在可以用于加强版的溯源图，使得生成的向量有很好的表达能力，可以用于攻击的检测。</p>
<h4><span id="3-溯源图在检测上的优势待补充">3、溯源图在检测上的优势？【待补充】</span></h4>
<p>利用这些边和节点，溯源图可以表示出系统对象之间的数据流与控制流关系，从而<strong>将存在因果联系（Causality）的节点连接起来，无论两个节点之间相隔多少的其他节点，或者发生时间相差多少</strong>。以RQ1中的高级持续性威胁为例，无论攻击如何隐蔽与缓慢，我们都可以在溯源图中找到对应的节点与因果联系，从而对其进行有效的检测。</p>
<p>溯源图包含着丰富的系统行为语义，也有很强的<strong>关联分析能力</strong>，因此在检测未知威胁和告警关联、<strong>误报过滤方面</strong>有着很强能力、很好的效果。</p>
<h4><span id="4-基于溯源图做入侵检测-关联分析和告警消减中的常见问题和可能的风险">4、基于溯源图做入侵检测、关联分析和告警消减中的常见问题和可能的风险</span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553024.png" alt="基于溯源图做入侵检测、关联分析和告警消减中的常见问题和可能的风险">
<figcaption aria-hidden="true">基于溯源图做入侵检测、关联分析和告警消减中的常见问题和可能的风险</figcaption>
</figure>
<blockquote>
<p><strong>基于溯源图的入侵检测和告警关联分析方案已经越来越多的被各大安全厂商采纳作为新的检测引擎核心</strong>。溯源图包含着丰富的系统行为语义，也有很强的关联分析能力，因此在检测未知威胁和告警关联、误报过滤方面有着很强能力、很好的效果。然而基于系统溯源图的检测系统本身也会引入新的问题，一些错误的使用可能会导致新的风险。本文整理归纳了利用系统溯源图做威胁检测过程中可能遇到的一些常见问题，和潜在的攻击方式，希望引起大家重视。</p>
</blockquote>
<h4><span id="41用溯源图进行检测过程中遇到的问题">4.1
用溯源图进行检测过程中遇到的问题</span></h4>
<p><strong><font color="red">
利用溯源图进行检测的最大问题，或者说挑战，就是性能问题。主要表现在两个方面：</font></strong></p>
<ul>
<li><p>数据量过大带来的<strong>数据收集开销</strong>：为了构建完整的系统溯源图，检测系统需要收集大量的数据，一般来说单台主机一天收集的数据量会在GB这一数量级。因此存储和处理数据会带来很大的开销。</p></li>
<li><p>图结构处理带来的<strong>计算开销</strong>：因为溯源图原始的图结构，完整的处理其信息会引入大量的开销。</p></li>
</ul>
<h4><span id="42带有风险的缓解措施和针对性的绕过手段">4.2
带有风险的缓解措施和针对性的绕过手段</span></h4>
<p>对于安全系统，尤其是面向业界的安全系统而言，性能就是生命，直接决定了乙方会不会接受安全产品。所以，从业者采用了各种方式来缓解性能压力，这些方法从原理上来说可以分为两大类：<strong>“剪枝”</strong>与<strong>“衰减”</strong>。</p>
<p><strong>“剪枝”就是将被认为无关的攻击路径整条排除</strong>，不予考虑；<strong>“衰减”则是认为局部的可疑行为只会与临近的行为关联</strong>，所以行为的影响力会随着图中距离的变远而逐步减小。（具体的实现比较复杂，不再赘述。）实际情况中，这两种方法往往可以一起使用使性能最优。</p>
<p>然而，需要注意的是这两种方案都有可能导致攻击漏报，而攻击者也完全可以利用这两个特性来针对性的构造攻击。事实上，了解原理后，有些攻击的构造会相当的容易。接下来我会由简单到复杂介绍几个具体的缓解方法和对应的攻击构造思路：</p>
<ul>
<li>利用包括<strong>数字签名</strong>在内的<strong>简单白名单策略</strong>进行<strong>剪枝</strong>：<strong>利用白名单进行初步的数据过滤是一种很直接也很有效的方法，但是过于简单的白名单策略可能导致攻击者很容易的绕过</strong>。以数字签名为例，绕过数字签名的方式有很多：包括签名伪造、DLL
Side loading以及最近很火的供应链攻击方案。</li>
<li>基于<strong>局部异常行为</strong>的<strong>剪枝</strong>：攻击行为往往会导致异常的系统行为（溯源图中的边），比如不应该出现的进程对文件访问等。部分工作针对这一特性认为“常见的系统行为就是相对安全的，因此可以忽略”。针对这一类的缓解方案，攻击者可以采用Live-off-the-Land的攻击思路，即尽可能的采用系统中原有的数据访问路径。<strong><font color="red">
比如说经典的Gitpwn攻击，利用Git的代码提交流程完成源代码的窃取和上传。可以避免异常的文件访问和网络传输流程，从而完成攻击。</font></strong></li>
<li><strong>衰减</strong>：利用衰减的思路，<strong>安全分析人员通过控制检测点的传播轮数（保留时间）</strong>，可以有效控制每次需要处理的图的规模，从而大幅度的降低的算法的复杂度。然而攻击者可以通过加长攻击链（增加攻击间隔）来避免被检测。需要注意的是加长攻击需要使得溯源图中节点的距离变大，如下图所示，常规的有核心控制节点的攻击图并不能真正拉长攻击链。这里可以使用的攻击技术报告DLL
side
loading、注册表自启动等等。值得一提的是，基于衰减的压缩方案往往和剪枝的方案共同使用，也意味着双倍的风险。</li>
</ul>
<p>上面几点仅仅是抛砖引玉，除此之外，其他的安全风险还包括：<strong>1）不完整的因果关系数据；2）受限的攻击案例分析等。</strong>可以看到，引入溯源图在解决部分问题的同时也引入了新的安全问题，构建真正安全系统的路还很长。希望大家也可以提出自己的看法，多多交流。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
  <entry>
    <title>高级威胁发现（2）溯源图技术在入侵检测与威胁分析中的应用</title>
    <url>/posts/3593RMP/</url>
    <content><![CDATA[<h3><span id="溯源图技术在入侵检测与威胁分析中的应用">溯源图技术在入侵检测与威胁分析中的应用</span></h3>
<p>现代信息系统中存在的众多漏洞一直是攻击者进行攻击的“关键”突破点，因此漏洞检测已经成为防守方的一门必修课。但常见的漏洞检测方法中，模糊测试覆盖率不足，基于符号执行程序的验证方法又对检测设备的性能有较高要求，此外漏洞发现后的补洞过程也极为耗时。</p>
<p>入侵检测与威胁分析系统的研发为对抗攻击提供了更直接、更快速的新方法,
能很大程度缓解上述问题。然而，现有的入侵检测系统大多依赖于提取自已有攻击的攻击特征，如<strong>入侵指标（Indicator
of
Compromise，IoC）</strong>等，其作为检测依据并未真正把握到攻击的要点，使得防御者总是落后一步。攻击者总是可以通过找到新的攻击面，构造多阶段多变的复杂攻击来绕此类检测。因此，安全研究人员和从业人员亟需重新考虑传统的入侵检测方案，设计出新一代更加通用和鲁棒的入侵检测机制来检测各种不断变化的入侵方式。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553344.png" alt="图片" style="zoom: 67%;"></p>
<p>David Bianco很早便提出了入侵检测的 “痛苦金字塔模型”(如图1所示)
，研究指出相对于 “Hash 值”、“IP 地址”等底层入侵指标，<strong>“攻击工具”
和 “攻击策略、技术、流程（TTPs）”
等高层特征在入侵检测中有更大的价值</strong>，也更难以分析和改变。这是因为底层的入侵指标的出现更具偶然性，因此攻击者很容易改变这些指标来逃避检测。<strong>此外，无文件攻击和
“Live-off-the-Land”
攻击等攻击技术的出现，使得攻击行为涉及的底层特征与正常行为完全无法区分</strong>。而高层次特征中带有丰富的语义信息（包括攻击的方法、目标、利用的技术等），更具鲁棒性。<strong>对于攻击者而言，攻击策略、技术、流程（TTPs）与其最终的攻击目标直接相关</strong>，很难被真正的改变，因此对入侵检测更有意义。同时，语义信息可以很好的帮助安全分析人员理解攻击，包括入侵的途径、可能的损失等，从而针对性地做出对应的止损和弥补措施。</p>
<h3><span id="一-系统溯源图介绍">一、<strong>系统溯源图介绍</strong></span></h3>
<p>2015
年，<strong>美国国防部高级研究计划署（DARPA）</strong>启动的一项名为
“<strong>透明计算（Transparent Computing）</strong>”
的科研项目为上述问题的解决提供了可能性。该项目旨在通过将目前不透明的计算系统变得透明，辅助海量的系统日志建模，从而为后续的高层次程序行为分析和高效地入侵检测提供支持。具体来说，该项目<strong>将开发一套数据收集与建模系统来记录和建模所有系统和网络实体</strong>（包括<strong>进程、文件、网络端口</strong>等）及其之间的互动和因果关系（Causal
Dependency）。这些实体和关系可以以图的形式表示，如图2所示，一般被称为
“<strong>溯源图（Provenance Graph）</strong>” 或者 “因果图（Causality
Graph）”。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553405.png" alt="图片" style="zoom:67%;"></p>
<p>上图是一个利用Firefox漏洞进行入侵的溯源图例子：</p>
<ul>
<li>攻击者从x.x.x.x:80发起攻击</li>
<li>利用Firefox的漏洞创建并启动了mozillanightly浏览器插件</li>
<li>该插件通过cmd执行环境信息获取命令获取敏感信息后回传到x.x.x.x:443</li>
<li>最后创建burnout.bat清除所有入侵痕迹。（箭头方向代表数据流或者控制流方向）</li>
</ul>
<p><strong><font color="red">
溯源图是一个带有时间信息的有向图，两个节点之间可能有多条不同属性（包括时间和具体操作等）的边。该图准确的记录了系统实体间的交互关系，包含丰富的信息。</font></strong>前文提到的攻击图可以看作溯源图中提取并抽象后的，与攻击直接相关的部分子图。但需要指出的是，溯源图记录的并不是细粒度的数据流和控制流，而是可能的因果控制关系，因此在<strong>进行多跳的分析时会引入错误的依赖</strong>，导致核心的依赖爆炸问题，这也是基于溯源图入侵检测的核心问题。【难点】</p>
<h3><span id="二-基于系统溯源图的入侵检测框架"><strong>二、基于系统溯源图的入侵检测框架</strong></span></h3>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553006.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p><strong>溯源图能很好地还原系统中的各种行为，使其成为了近年来入侵检测领域热门有潜力的研究方向</strong>。安全研究者在其基础上设计了多种模型来进行系统中恶意行为地检测与分析，包括
“数据采集、解析和压缩”，“数据存储与压缩”，和 “入侵检测和溯源分析”
在内的许多具体研究问题。我们整理了威胁分析与检测系统的整体框架，如图3所示。以下，我们将具体讨论框架的三个模块并对其中技术进行分析：</p>
<h4><span id="21-数据收集模块">2.1 <strong>数据收集模块</strong></span></h4>
<p>数据收集是所有检测和分析系统的基础。一般而言，基于溯源图的威胁检测系统会收集<strong>系统日志</strong>作为数据源，包括
<strong>Windows 的内置日志系统 Event Tracing for
Windows（ETW）</strong>、<strong>Linux 的日志系统
Auditd</strong>等。基于依赖分析的方法的一个普遍的挑战是
“依赖爆炸问题”。错误的依赖会导致后续分析的开销与误报指数型增长，导致分析的失败，而细粒度的数据收集可以从根本上缓解这一问题。</p>
<blockquote>
<p>ETW（Event Tracing for
Windows）:https://cloud.tencent.com/developer/article/1020029</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553107.png" alt="image-20220614224748594" style="zoom: 50%;"></p>
</blockquote>
<h4><span id="22-数据管理模块"><strong>2.2 数据管理模块</strong></span></h4>
<p>系统日志为威胁分析提供了大量有价值的信息，然而其巨大的数据量给数据的<strong>存储和分析</strong>带来了很大的压力。因此在数据管理模块中，我们一方面需要提供<strong><font color="red">
合理的数据存储模型来存储海量的数据并提供高效的查询分析接口</font></strong>，另一方面要尝试通过<strong><font color="red">
压缩和剪枝去除冗余的数据</font></strong>。</p>
<blockquote>
<p><strong>数据存储模型</strong>
利用图结构存储溯源图是一种解决思路，但受溯源图规模限制，将图完全存储在内容内存中是不现实的，只能在小规模的实验中使用，无法大规模部署。因此，研究者们提出了将图中所有边视为数据流，每个边只处理一次，并利用节点上标签记录计算过程的方案。为了加以区分，我们将用图数据存储图的方案称为
“缓存图”，流式处理的方案为“流式图”。流式图方案存在优势的原因在于溯源图中边的数量远远大于节点数量，因此查询节点的属性效率比查询边的效率高得多。类似地，一些研究以节点作为键，边为值，将溯源图存储在查询效率更高的关系型数据库中，我们称之为
“节点数据库”。</p>
</blockquote>
<p>数据压缩算法
溯源图上的数据压缩算法可以大致分为两类：<strong>一类是通用的压缩算法，尽可能地保持了溯源图的信息</strong>；另一类与检测和分析算法耦合，使用有较大的局限性，而本文主要分析前者。</p>
<h4><span id="23-威胁检测与分析模块">2.3 <strong>威胁检测与分析模块</strong></span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191554502.png" alt="图片" style="zoom:60%;"></p>
<p>溯源图提供了丰富的语义信息，支持多种检测分析方案，如表1所示。这些检测方案考虑了不同的攻击模型，针对不同攻击模型提出来不同的检测模型，大致可以分为几类：</p>
<ul>
<li><strong>子图匹配</strong>:
在<strong>溯源图中定位攻击行为抽象出的攻击图</strong>。准确的图匹配的开销过大，因此研究者提出了几种<strong>模糊匹配</strong>方法，包括：<strong>基于威胁情报的图对齐、基于图嵌入的机器学习匹配</strong>等。</li>
<li><strong>节点标签传播计算结</strong>:
并用标签的传递代替复杂的图计算的
“标签传播（TagPropagation）算法”。这类算法一般使用<strong>流式图</strong>作为数据模型，避免了大量的数据读写操作，因此整体效率最高,
但也对检测和分析算法作出了更多的限制。</li>
<li><strong>异常检测模型</strong>:
已有的溯源图上的异常检测模型一般先寻找局部的异常点，并通过依赖分析关联异常点，从而作出全局的判断。</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
  <entry>
    <title>软件程序分析（1）【draft】BDCI2022</title>
    <url>/posts/1A2QT8E/</url>
    <content><![CDATA[<h2><span id="linux跨平台二进制函数识别">Linux跨平台二进制函数识别</span></h2>
<p>https://www.datafountain.cn/competitions/593/datasets</p>
<h2><span id="web攻击检测与分类识别">Web攻击检测与分类识别</span></h2>
<p>https://www.datafountain.cn/competitions/596/ranking?isRedance=0&amp;sch=2006&amp;page=1</p>
<h2><span id="大数据平台安全事件检测与分类识别">大数据平台安全事件检测与分类识别</span></h2>
<p>https://www.datafountain.cn/competitions/595/datasets</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>算法比赛</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>【draft】Soghos-家族语义标签问题</title>
    <url>/posts/Z02VQH/</url>
    <content><![CDATA[<p>https://mzgao.blog.csdn.net/article/details/118943477</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>AI安全（3）A survey on practical adversarial examples for malware classifiers</title>
    <url>/posts/17HFC4S/</url>
    <content><![CDATA[<h3><span id="恶意软件的对抗样本综述"><strong>恶意软件的对抗样本综述：</strong></span></h3>
<h3><span id="asurvey-on-practical-adversarial-examples-for-malwareclassifiers"><strong>A
survey on practical adversarial examples for malware
classifiers</strong></span></h3>
<ul>
<li><p><strong>INTRODUCTION</strong></p></li>
<li><p><strong>BACKGROUND</strong></p>
<ul>
<li><strong>Machine learning for malware</strong></li>
<li><strong>Adversarial examples</strong></li>
</ul></li>
<li><p><strong>PRACTICAL ATTACKS</strong></p>
<ul>
<li><strong>Gradient-driven approaches</strong>
<ul>
<li><strong>Editing bytes and metadata</strong></li>
<li><strong>Code transformations</strong></li>
</ul></li>
<li><strong>Problem-driven approaches</strong>
<ul>
<li><strong>Editing bytes and metadata</strong></li>
<li><strong>Code transformations</strong></li>
</ul></li>
</ul></li>
<li><p><strong>DISCUSSION</strong></p>
<ul>
<li><p><strong>Challenges</strong></p>
<ul>
<li><p><strong>Threat models</strong></p></li>
<li><p><strong>Establishing baselines</strong></p></li>
</ul></li>
<li><p><strong>Possible research directions</strong></p>
<ul>
<li><strong>Defending against practical adversarial malware
examples</strong></li>
<li><strong>Relationships between obfuscation and adversarial
examples</strong></li>
<li><strong>Integration of static and dynamic analysis
techniques</strong></li>
</ul></li>
<li><p><strong>Other Survey and systematization of knowledge
papers</strong></p></li>
</ul></li>
<li><p><strong>CONCLUSION</strong></p></li>
<li><p><strong>ACKNOWLEDGMENTS</strong></p></li>
</ul>
<hr>
<h3><span id="abstract">ABSTRACT</span></h3>
<blockquote>
<p>基于机器学习的解决方案非常有助于解决处理大量数据的问题，例如恶意软件检测和分类。然而，人们发现，深层神经网络容易受到敌对示例的攻击，或故意干扰输入以导致错误标签的攻击。研究人员已经表明，可以利用此漏洞创建规避恶意软件样本。然而，许多提议的攻击并不生成可执行文件，而是生成特征向量。为了充分了解敌对示例对恶意软件检测的影响，我们回顾了针对生成可执行敌对恶意软件示例的恶意软件分类器的实际攻击。我们还讨论了该研究领域当前面临的挑战，以及改进建议和未来研究方向。</p>
</blockquote>
<h3><span id="1-introduction">1 INTRODUCTION</span></h3>
<blockquote>
<p>基于机器学习的解决方案非常有助于解决处理大量数据的问题，例如恶意软件检测和分类。然而，人们发现，深层神经网络容易受到敌对示例的攻击，或故意干扰输入以导致错误标签的攻击。研究人员已经表明，可以利用此漏洞创建规避恶意软件样本。然而，许多提议的攻击并不生成可执行文件，而是生成特征向量。为了充分了解敌对示例对恶意软件检测的影响，我们回顾了针对生成可执行敌对恶意软件示例的恶意软件分类器的实际攻击。我们还讨论了该研究领域当前面临的挑战，以及改进建议和未来研究方向。</p>
</blockquote>
<blockquote>
<p>然而，在2014年，Szegedy等人表明深层神经网络（DNN）容易受到对抗性攻击。Grosse等人进一步证明，这种漏洞也适用于基于机器学习的恶意软件检测器和分类器[29]。自这项工作以来，针对流行的基于机器学习的模型（如MalConv[62]）开发了许多攻击，但其中许多攻击并不实用。具体地说，许多攻击不会生成实际的恶意软件，而是生成一个特征向量，表示可能受干扰的恶意文件应该是什么样子以逃避检测。由于逆特征映射的困难，在给定特征向量的情况下生成可执行程序是不切实际的[59]。也就是说，特征提取过程不是唯一可逆的，也不能保证找到的解决方案将包含与原始恶意软件样本相同的程序逻辑。在这项工作中，我们回顾了针对基于机器学习的恶意软件分类器和检测器的实际攻击，或者针对这些导致可执行恶意软件的ML模型的攻击。在第2节中，我们介绍并定义了对抗性示例以及考虑这些示例的威胁模型。然后，我们在第3节回顾了恶意软件领域的实际对抗性示例研究。我们为该领域的未来方向提供建议，并在第4节讨论任何挑战。最后，我们在第5节总结。</p>
</blockquote>
<h3><span id="2-background">2 BACKGROUND</span></h3>
<h4><span id="21-machine-learning-formalware">2.1 Machine learning for
malware</span></h4>
<blockquote>
<p>检测恶意软件的经典方法是提取在受感染系统上发现的恶意样本的文件签名，并将其添加到签名数据库，也称为基于签名的检测[51]。对于这种方法，必须在整个样本以及相关样本的子集中搜索已知签名，因为恶意行为可以嵌入并交织在其他良性软件中。然而，由于基于特征码的检测依赖于捕获恶意软件样本，然后对其进行分析以生成新的特征码，因此它只能防御已知的攻击，并且只能尝试防御新的或模糊的恶意软件[67]。</p>
</blockquote>
<blockquote>
<p>基于机器学习的方法被提出作为这个问题的解决方案，因为它们能够预测新输入的标签。机器学习模型，如支持向量机（SVM）和均值聚类，用于恶意软件分类、检测和分析方法。在分类问题中，我们尝试将恶意软件样本分离为预定义的恶意软件系列。基于学习的模型基于由标记恶意软件样本组成的训练数据，推断新恶意软件样本的分类。检测问题可以看作是分类的一个子问题。对于检测，基于学习的模型用于在给定恶意和良性可执行文件时查找或检测恶意软件样本。由于检测是二进制分类的一种情况，基于学习的检测模型也可以称为分类器。分类和检测是训练数据标记时的监督算法。机器学习也可用于增强恶意软件分析。非监督聚类算法可用于学习恶意软件样本之间的新相似性[32]。此外，我们可以对基于学习的模型进行推理，以更好地理解恶意软件的恶意原因[7,20]。最近，随着深入学习方法研究的增加，研究人员开始利用卷积神经网络来分类和检测恶意软件[52,62]。</p>
</blockquote>
<h4><span id="211-static-features">2.1.1 Static Features</span></h4>
<blockquote>
<p>N-gram是目前流行的用于恶意软件分类和检测的功能。Kolter和Maloof提出使用各种机器学习模型，包括朴素贝叶斯分类器、决策树、支持向量机（SVM）和增强模型[37]，从PE恶意软件中提取最相关的=-克字节码进行分类。他们发现，除了分类之外，他们的模型还可以用于恶意软件检测.</p>
<p>McBoost是作为一种在搜索恶意软件时快速分析大量二进制文件的工具引入的，并采用了三步流程[58]。第一步是使用基于启发式的分类器和两个不同的基于n-gram的分类器的集合来检测打包器。如果检测到封隔器，则使用QEMU和动态分析对二进制文件进行解包。最后，使用一个单独的n-gram分类器来检测应该转发以进行额外分析的恶意软件。</p>
<p>Santos等人在2009年提出使用=-grams作为基于文件签名的方法的替代方案。在这样做的过程中，他们表明机器学习，特别是k近邻模型和=-grams可以成功地用于检测新的恶意软件样本[67]#-grams还与动态特征一起使用，以同时合并恶意软件的多个视图，而无需实际进行动态分析[5]。最近的工作，如为Kaggle
Microsoft恶意软件挑战提出的解决方案[64，78]，证明了字节和操作码=-grams的持续使用，分类准确率几乎为100%。</p>
<p>与使用操作码序列生成=gram类似，可以从程序的操作码跟踪中提取马尔可夫链。这样的马尔可夫链使用唯一的操作码作为其状态，并显示从一个操作码到另一个操作代码的转换概率。Anderson等人使用程序的马尔可夫链之间的相似性作为恶意软件检测的一个特征。类似地，Runwal等人[53]提出使用马尔可夫链之间的图相似性来检测嵌入式恶意软件，Shafiq等人[45]提出使用马尔科夫链来测量熵来检测恶意软件。</p>
<p>Jang等人介绍了BitShred，一种用于恶意软件分类和分析的工具[32]。BitShred使用位置敏感哈希对从样本中提取的=gram指纹进行哈希，以降低特征空间的维数。在k近邻模型中使用散列来对恶意软件样本进行聚类。此外，作者还表明BitShred可以用于改进以前的恶意软件检测和分类模型。例如，作者表明BitShred可以用于散列动态特征，例如Bayer等人[12]中生成的行为简档，以降低特征空间的维数。</p>
<p>Drebin对Android软件进行大规模静态分析，以提取硬件使用和请求、权限、API调用和网络信息等功能[7]。这些特征用于通过生成二进制指示符向量将样本映射到联合向量空间。这些二进制指示符向量被用作SVM的输入，SVM将样本标记为良性或恶意。重要的是，Drebin利用其模型的简单性，将模型的决策归因于特定的特征。这使得Drebin比基于复杂架构（如卷积神经网络）的恶意软件分类器和检测器更容易解释。</p>
<p><strong>【ember、+ 字节直方图】</strong></p>
<p><strong>【恶意软件图像】</strong>Nataraj等人提出使用恶意软件图像（二进制文件的黑白图像表示）来检测恶意软件[52]。从那时起，研究人员和商业杀毒软件都使用恶意软件图像来高精度检测恶意软件[23，26，78]。Nataraj等人使用恶意软件图像创建了一个特征向量，该向量将用作支持向量机的输入。然而，最近的工作也表明，使用原始图像作为卷积神经网络的输入是有效的[23，34，38，82]。</p>
<p><strong>【CFG控制流图】</strong>在开发静态功能方面也进行了研究，这些功能可以使用控制流图深入了解程序在运行时的行为。这项研究主要围绕构建控制流图和使用图匹配技术来检测恶意软件[13，16]。Ma等人在使用控制流图时采取了类似的方法，但提取了一系列API调用，试图模拟动态分析[46]。</p>
<p><strong>【Malconv】</strong>Raff等人采用了一种不同的方法，并提出了一种卷积神经网络（CNN）模型，该模型将整个二进制作为输入[62]。特别地，所提出的模型MalConv查看文件的原始字节以确定恶意。MalConv借鉴了神经网络的研究，从长序列中学习更高级别的表示，并依赖于CNN捕捉高级别局部不变量的能力。MalConv通过提取文件的：字节来工作。这些：用0G5字节填充字节，以创建大小为3的特征向量。如果：&gt;3，则使用文件的前3个字节，而不使用任何额外的填充。通过与CNN联合学习的嵌入，将这个3长度的向量映射到固定长度的特征向量。</p>
</blockquote>
<h4><span id="212-dynamic-features">2.1.2 Dynamic Features</span></h4>
<blockquote>
<p>动态分析是一种通过在实时环境中运行二进制文件来分析二进制文件的技术。此环境通常是一个安全的沙盒或测试环境，如CWSandbox[80]和cuckoo
sandbox[1]，以确保主机的安全。通常，这些环境都经过大量检测，以便记录已执行和加载的代码以及对内部文件、目录和设置所做的任何更改。这些记录的特征称为动态特征。</p>
<p>提取动态特征的最常用方法是记录系统和API调用的频率和顺序[3,21]。例如，<strong>Accessminer</strong>在动态分析期间记录系统调用trace，并生成每个样本的n-grams表示[42]。Accessminer将一个样本标记为恶意软件，如果该样本相对于某个预定义阈值包含多个“恶意”=-grams实例。动态分析的另一个好处是可以捕获和分析网络流量和通信，如Taintdroid[22]所述。这些功能还可用于为其他功能生成不同的恶意软件表示，或降低维数。</p>
<p>Bailey等人提出了一种用于恶意软件自动分类和分析的动态分析工具，该工具使用动态分析来记录生成的新进程、修改的任何文件、修改的任何注册表项以及网络访问和使用情况[11]。这些记录的特征用于创建amalware指纹，该指纹关注的是状态变化，而不是代码序列。这些动态特征用于使用标准化压缩距离度量创建恶意软件样本的层次聚类。</p>
<p>Rieck等人使用CWSandbox进行动态分析，类似于Bailey等人的工作，但是，使用字符串从结果文本报告中提取特征[63]。字符串频率与SVMto一起用于分类恶意软件样本。作者还表明，他们的方法可以通过引入新的“未知”类而扩展到恶意软件检测，而无需在训练集中引入良性样本。</p>
<p>拜耳等人通过使用污染分析来了解可执行文件如何使用来自操作系统的信息，从而扩展了之前的工作[12]。此外，所提出的方法使用操作系统对象和操作的抽象来创建行为概要。作者认为，由于能够在没有虚假系统调用的情况下对程序进行抽象或推理，因此抽象对规避更具鲁棒性。然后，将提取的行为特征与基于位置敏感哈希的聚类算法结合使用，对恶意软件样本进行分类。</p>
<p>程序的行为也可以建模为图，如Kolbitsch等人的工作[35]。作者扩展了malspec[18]，并使用systemcalls生成了程序的行为图。每个行为图都是一个有向无环图，其中节点是系统调用，有向边表示信息流。使用图匹配和相似性度量对已知恶意软件样本进行检测。</p>
</blockquote>
<h4><span id="22-adversarial-examples">2.2 Adversarial examples</span></h4>
<blockquote>
<p>定义-&gt;图片等领域的限制条件-&gt;常用方法介绍-&gt;</p>
<p>在[72]中首次引入了对抗性示例的概念，并在[28]中进行了扩展。假设5是敌方计划攻击的目标分类器。这个分类器可以表示为一个函数<span class="math inline">\(f(x)\)</span>，它接受一个输入并给它分配一个标签。通过用X扰动原始输入f生成对抗性示例x′5，使5（G）≠
5（G′）。</p>
<p>有很多方法可以找到X，最流行的是快速梯度符号法[28]和卡里尼·瓦格纳（C&amp;W）攻击[15]用于白盒模型，而<strong>替代模型攻击</strong>[55]用于黑盒模型。大多数攻击都会使用损失函数相对于输入的梯度来找到输入必须扰动的方向，以使输出发生想要的变化。然后使用该方向来查找X。我们在附录中简要讨论了这些攻击和其他攻击。</p>
</blockquote>
<h4><span id="221-threat-models">2.2.1 Threat models.</span></h4>
<p>威胁模型是研究中对攻击者能力和已知信息的明确定义。在本节中，我们定义了机器学习领域中广泛使用的<strong>白盒</strong>和黑盒威胁模型。威胁模型由三部分组成：<strong>威胁向量和威胁面、知识和能力</strong>。</p>
<p><strong>威胁向量和威胁面</strong>：威胁向量和威胁面表示攻击者与目标模型交互的方式。威胁向量是攻击者可以用来攻击模型的允许输入空间和位置。威胁面或攻击面是所有此类威胁向量的集合。通常情况下，威胁向量和威胁面由机器学习模型的输入和输出组成。然而，攻击者进入这些表面的能力进一步受到其知识和能力的限制。</p>
<p><strong>Knowledge:</strong>攻击者的知识表示我们假设对攻击者了解<strong>目标模型的内容</strong>。然后，攻击者利用这些知识构建并发起攻击。在对抗式机器学习中，可以将攻击者的知识概括为白盒和黑盒模型。在白盒模型中，假设攻击者对系统有完全的了解。因此，我们假设攻击者可以完全访问目标机器学习模型（带有权重和参数）以及用于训练模型的数据。在黑箱模型中，假设攻击者只能访问模型的输入和输出。因此，攻击者不知道模型的内部或训练过程（例如，从可执行文件和梯度信息中提取的特征）。<strong>攻击者也可以建模为灰盒模型。在灰箱模型中，攻击者可以访问模型的输入、输出和一些其他信息（模型使用的特征）等。</strong></p>
<blockquote>
<p>本研究中回顾的作品与攻击者的知识并不完全一致。具体地说，有些作品可能假设攻击者还可以访问恶意软件源代码，而其他作品则没有。在第3节中，将明确指出每部作品与对抗性知识的一般定义之间的偏差</p>
</blockquote>
<p><strong>能力</strong>：攻击者的能力表示我们假设对攻击者可以发动的攻击类型。在对抗样本中，我们可以指定攻击者将使用的<strong>攻击算法</strong>。在恶意软件领域的对抗性示例中，攻击者的能力受到其知识的限制。例如，通过访问恶意软件源代码，攻击者可以轻松地在编译时应用特定的转换。但是，如果没有源代码，这将变得更加困难。</p>
<h4><span id="222-adversarial-malwareexamples">2.2.2 Adversarial malware
examples</span></h4>
<blockquote>
<p>大多数对抗性示例研究是使用自然图像数据集进行的，如MNIST、CIFAR10和ImageNet。然而，有必要考虑一组<strong>允许干扰攻击者恶意软件实例功能的允许扰动</strong>。</p>
</blockquote>
<blockquote>
<p>对于自然图像，像素值会受到干扰以生成一个对抗性示例。只要得到的像素值在0到255之间，像素值的任何负数或正数变化都会导致图像发生轻微变化。可执行程序可以用类似的方式表示。根据定义，二进制文件的每个字节都在0x00和0xff之间。每个字节的十六进制表示可以转换为其十进制等效值（0到255之间）。在此状态下，可以使用相同的方法扰动字节和像素。然而，对字节的任意扰动可能不会产生有效的可执行文件，因为可执行程序存在于离散空间中。考虑改变可执行文件的一个字节的简单情况。如果字节来自ELF的.text部分，则新修改的字节可能会通过更改函数参数或导致错误指令而中断程序的功能。因此，将对抗性示例技术应用于恶意软件领域需要特别注意二进制文件的构造。最重要的是，对抗性恶意软件示例必须包含与原始恶意程序相同的恶意程序逻辑和功能。</p>
</blockquote>
<p><strong>对抗性恶意软件示例是一种直接的威胁，因为它们是规避性的恶意可执行文件，可以利用许多商业防病毒软件对混淆和变异的持久漏洞</strong>[61]。<strong>这将实际的恶意软件示例与恶意特征向量区分开来。虽然恶意特征向量也可以逃避检测或分类，但没有直接威胁</strong>。<strong>Pierazzi等人认为，在给定敌对特征向量的情况下生成可执行文件是困难的，并将其称为反向特征映射问题。逆特征映射问题没有唯一的解决方案</strong>。在n-gram分类器的简单情况下，可以通过多种方式添加n-gram。但是，它们并不能保证产生与原始恶意软件样本包含相同程序逻辑或可执行性的可执行文件。当处理黑盒模型时，这个问题变得更加困难，因为攻击者不知道分类器的输入和内部结构。Pierazzi等人解释说，实际的恶意软件示例有两种方法可以避免这种情况：</p>
<p>（1）一种梯度驱动方法，其中代码扰动对梯度的影响是近似的，并用于遵循梯度的方向；</p>
<p>（2）一种问题驱动方法，其中突变首先随机应用，然后再开始一种进化的方法。</p>
<h4><span id="3-practical-attacks">3 PRACTICAL ATTACKS</span></h4>
<blockquote>
<p>在本节中，我们将回顾对抗性恶意软件示例文献中的实际攻击，或导致可执行二进制文件的攻击。在表3中，我们概述了本工作中的实际攻击记录（1）如果工作是针对使用静态功能的恶意软件分类器评估的（2）如果工作是针对使用动态功能的恶意软件分类器评估的，（3）评估中的targetmodels，（4）攻击中的可用转换，（5）该方法是梯度驱动还是问题驱动。</p>
</blockquote>
<blockquote>
<p>我们使用[59]中的术语，并按照第2.2.2节中定义的梯度驱动和问题驱动方法组织我们的审查。对于这两种方法，我们进一步将文献组织为第3.1.1和3.2.1节中主要编辑字节和元数据的攻击，以及第3.1.2和3.2.2节中利用代码转换的攻击。</p>
</blockquote>
<figure>
<img src="image-20210415140727064.png" alt="image-20210415140727064">
<figcaption aria-hidden="true">image-20210415140727064</figcaption>
</figure>
<ul class="task-list">
<li><p><input type="checkbox" checked>[65] Generic Black-Box
End-to-End Attack Against State of the Art API Call Based Malware
Classifiers</p></li>
<li><p><input type="checkbox">[6] Learning to Evade Static PE Machine
Learning Malware Models via <strong>Reinforcement
Learning</strong></p></li>
<li><p><input type="checkbox" checked>[36] <strong>Adversarial
Malware Binaries: Evading Deep Learning for Malware Detection in
Executables</strong></p></li>
<li><p><input type="checkbox" checked>[39] <strong>Deceiving
End-to-End Deep Learning Malware Detectors using Adversarial
Examples</strong></p></li>
<li><p><input type="checkbox" checked>[20] Explaining
Vulnerabilities of Deep Learning to Adversarial Malware
Binaries</p></li>
<li><p><input type="checkbox">[57] Generation &amp; Evaluation of
Adversarial Examples for Malware Obfuscation.</p></li>
<li><p><input type="checkbox" checked><strong>[68]</strong>
<strong>Automatic Generation</strong> of Adversarial Examples for
Interpreting Malware Classifiers</p></li>
<li><p><input type="checkbox">[83] Malware Detection in Adversarial
Settings: Exploiting Feature Evolutions and Confusions in Android
Apps.</p></li>
<li><p><input type="checkbox">[40] Deceiving Portable Executable
Malware Classifiers into Targeted Misclassification with Practical
Adversarial Examples</p></li>
<li><p><input type="checkbox" checked>[59] <strong>Intriguing
Properties of Adversarial ML Attacks in the Problem Space (2020
S&amp;P)</strong></p></li>
<li><p><input type="checkbox">[24] <strong>HideNoSeek: Camouflaging
Malicious JavaScript in Benign ASTs (2019 CCS)</strong></p></li>
</ul>
<h4><span id="31-gradient-driven-approaches">3.1 Gradient-driven approaches</span></h4>
<h4><span id="311-editing-bytes-andmetadata">3.1.1 Editing bytes and
metadata</span></h4>
<blockquote>
<p>创建实际恶意软件示例的一种流行方法是在二进制文件中的未使用空间中添加或更改字节。此外，这可以在头中完成，以在不影响功能的情况下更改头元数据。在本节中，我们将回顾使用这种类型转换的拟议攻击。因为这些攻击集中在未使用或“不重要”（用于执行）字节上，所以它们不需要源代码来生成规避恶意软件样本。然而，除了GADGET[65]之外，这些攻击仍然是白盒攻击，因为它们需要完全访问目标模型来计算梯度。</p>
</blockquote>
<ul class="task-list">
<li><input type="checkbox" checked>##### <strong>[65] Generic
Black-Box End-to-End Attack Against State of the Art API Call Based
Malware Classifiers</strong></li>
</ul>
<p>2018年，Rosenberg等人提出了GADGET，这是一个利用DNN之间对抗样本的可转移性将PE恶意软件转化为规避变体的软件框架[65]。提议的攻击假设一个黑盒威胁模型，无法访问恶意软件源代码。但是，攻击假设目标模型将一系列API调用作为输入。为了生成对抗性示例，GADGET构建了一个代理或替代模型，该模型使用Papernot等人提出的基于Jacobian的数据集扩充进行训练，作为对自然图像分类器的攻击[55]。数据集扩充创建合成输入，帮助替代模型更好地逼近目标黑盒模型的决策边界。这增加了攻击可转移性的概率，因为替代模型和目标模型都将学习到类似的分布。一旦替代模型得到训练，通过向原始恶意软件的API调用序列添加虚拟API调用，生成对抗性恶意软件示例。作者将这些伪API调用称为语义NOP作为所选的API调用，或者它们相应的参数对原始程序逻辑没有影响。需要注意的是，作者只添加API调用，因为删除API调用可能会破坏程序的功能。</p>
<blockquote>
<p>算法介绍：假设原始API调用序列是一个数组F0，其中每个索引都是9∈
[0，=]包含一个API调用。此过程的每个迭代8都返回一个新数组F8。在迭代8中，一个API调用3被添加到F8中−1在某个指数9处，将其推向梯度指示的方向，该梯度对替代模型的决策影响最大。这将导致F8，其中F8[9]=3和F8[9+1::]=F8−1[9:]因为索引9之后的前一序列中的所有API调用基本上都是“向后推”的。</p>
</blockquote>
<p>这种通过添加伪API调用来干扰输入的方法确保了功能不会被破坏。为了从这个对抗性API调用序列生成实际的可执行文件，GADGET实现了一个钩住所有API调用的包装器。钩子根据需要从敌对API调用序列调用原始API和虚拟API。这些钩子确保生成的敌对恶意软件示例在某种意义上保持原始样本的功能和行为。GADGET根据定制模型进行评估，包括logistic回归、递归神经网络（RNN）、全连接深度神经网络（DNN）、卷积神经网络（CNN）、支持向量机、增强决策树和随机森林分类器。作者还表明，他们的攻击产生的恶意软件能够避开使用静态特征（如可打印字符串）的分类器。</p>
<ul class="task-list">
<li><input type="checkbox" checked><strong>[36] Adversarial Malware
Binaries: Evading Deep Learning for Malware Detection in
Executables</strong></li>
</ul>
<blockquote>
<p>Kolosnjaji等人提出了一种针对MalConv的白盒攻击，该攻击通过迭代操作文件末尾的填充字节来生成对抗性PE恶意软件示例[36]。尽管作者指出PE中任何位置的字节都可以更改，但它需要对文件体系结构的精确了解，因为简单的更改可能会破坏文件完整性。因此，提议的攻击只关注字节附加。作者面临的一个挑战是由于其嵌入层，MALCONV的不可微性。为了避免这种情况，作者建议计算目标函数相对于嵌入表示I的梯度，而不是输入。每个填充字节都替换为最靠近第6行的嵌入式字节&lt;（[）=I+[=其中=是标准化的渐变方向。但是，如果第6行（[）上的“&lt;”投影未与=”对齐，则选择下一个最近的嵌入字节。通过仅更改文件末尾的填充，提议的攻击不会更改程序逻辑或原始almarware示例的功能。<strong>但是，这也限制了攻击允许的干扰总数</strong>。如第2节所述，MalConv从二进制文件中最多提取3个字节。如果二进制文件的大小小于3，则提取的：字节数为（3−
:)
附加到它的0xff填充字节。这意味着提议的攻击受到原始恶意软件样本大小的限制。</p>
</blockquote>
<ul class="task-list">
<li><input type="checkbox" checked><strong>[39] Deceiving
End-to-End Deep Learning Malware Detectors using Adversarial
Examples</strong></li>
</ul>
<blockquote>
<p>Kruek等人[39]扩展了Kolosnjaji等人的工作，提出了一种方法，用于在敌对示例嵌入的情况下重建PE恶意软件样本。作者发现，从扰动嵌入重建字节∗
像我一样经常是不平凡的∗ 可能会与我失去相似之处∈ /
用于学习“将填充字节映射到嵌入字节的函数。因此，他们提出了一种新的损失函数，以确保扰动嵌入∗
将接近于实际的嵌入”。这是通过在生成的嵌入和“”之间的损失函数中引入距离项来实现的。</p>
</blockquote>
<ul class="task-list">
<li><input type="checkbox" checked><strong>[20] Explaining
Vulnerabilities of Deep Learning to Adversarial Malware
Binaries</strong></li>
</ul>
<blockquote>
<p>Demetrio等人提出将特征属性作为一种可解释的机器学习算法，以理解机器学习模型做出的决策[20]。特征归因基于Sundararajan等人于2017年引入的一种称为积分梯度的技术[71]。Demetrio等人观察了输入可执行文件的每个字节的属性，发现MalConv对二进制文件的PE头部分的权重很大。作者利用了这一漏洞，提出了针对MalConv的白盒攻击，该攻击只改变恶意软件样本头中的字节。此攻击使用了与[36]中相同的算法，但干扰了头中未使用和可编辑的字节，而不是在文件末尾填充。</p>
</blockquote>
<h4><span id="312-code-transformations">3.1.2 Code transformations</span></h4>
<blockquote>
<p>上面的许多工作都指出，只要程序的功能和恶意行为没有改变，建议的方法就可以用来改变恶意二进制文件的.text部分。以下攻击利用模糊处理技术更改.text部分。</p>
</blockquote>
<ul class="task-list">
<li><input type="checkbox"><strong>[57] Generation &amp; Evaluation of
Adversarial Examples for Malware Obfuscation.</strong></li>
</ul>
<blockquote>
<p>Park等人提出了一种白盒攻击，该攻击利用语义NOP（如mov
eax、x86汇编中的eax）来创建对抗性PE恶意软件示例[57]。作者攻击了使用可执行文件[52]的图像表示作为输入的卷积神经网络。可执行文件的图像表示将每个字节视为一个像素，并使用字节的十进制值作为像素值。攻击提出了两个步骤。首先，使用FGSM生成对抗性示例。此对抗性示例是一个映像，可能与原始恶意软件示例的功能或恶意行为不同。在第二步中，原始恶意软件样本和生成的敌对图像被用作动态规划算法的输入，该算法使用LLVM过程插入语义NOP。与[65]中添加API调用以类似于生成的对抗性特征向量的方式类似，动态规划算法添加了语义NOP，使得生成的恶意软件样本的图像表示类似于步骤1中生成的敌对图像。作者继续证明，由于敌对示例和干扰的可转移性，这种攻击可以用于黑盒模型[50，
55].
使用一个简单的2层CNN作为替代模型，作者生成了对抗性恶意软件示例，这些示例也避开了黑盒模型，其中一个是使用字节级特征的梯度增强决策树。作者还提到，考虑到恶意软件的源代码，他们的攻击效果最好。然而，在缺乏源代码的情况下，可以使用二进制翻译和重写技术插入必要的语义NOP。需要注意的是，引入这些技术也会引入二进制提升过程中的工件。</p>
</blockquote>
<h4><span id="32-problem-driven-approaches">3.2 Problem-driven approaches</span></h4>
<blockquote>
<p>在本节中，我们将回顾采用问题驱动方法的对抗性恶意软件示例算法。与第3.1节类似，我们使用攻击的可用转换进一步组织审查。问题驱动的方法不需要白盒访问梯度信息的目标。因此，以下方法是黑盒攻击。</p>
</blockquote>
<h4><span id="321-editing-bytes-andmetadata">3.2.1 Editing bytes and
metadata</span></h4>
<ul class="task-list">
<li><input type="checkbox"><strong>[6] Learning to Evade Static PE
Machine Learning Malware Models via Reinforcement Learning</strong>
<ul>
<li>Anderson</li>
</ul></li>
</ul>
<blockquote>
<p>其中，Anderson等人提出了一个具有强化学习代理集[6]。RL代理因产生逃避检测的恶意软件的行为而获得奖励。通过这个游戏，代理学习创建规避恶意软件的策略。提议的攻击利用以下不会改变原始程序逻辑的操作：</p>
<ul>
<li>向导入表中添加从未使用过的函数</li>
<li>更改节名</li>
<li>创建新的但未使用的部分</li>
<li>向节中未使用的空间添加字节</li>
<li>删除签名者信息</li>
<li>更改调试信息</li>
<li>打包或解包二进制文件</li>
<li>修改标题</li>
</ul>
<p>使用这些操作，RL代理能够改变诸如PE元数据、人类可读字符串和字节直方图等特性。在培训阶段发生多达50000个突变后，RL代理根据梯度增强决策树模型进行评估，结果表明该模型能够成功地对恶意软件进行分类[78]。作者指出，他们的对抗性例子应该是功能性的。然而，他们发现，他们的攻击破坏了某些Windows
PE的功能，这些PE使用了不太常见的文件格式或违反PE标准的混淆技巧。作者声称，通过确保二进制检测框架能够正确解析原始恶意软件样本，可以简单地解决这一问题。</p>
</blockquote>
<ul class="task-list">
<li><input type="checkbox"><strong>[68] Automatic Generation of
Adversarial Examples for Interpreting Malware Classifiers</strong></li>
</ul>
<blockquote>
<p>Song等人在生成对抗性恶意软件示例时采用了不同的方法[68]。提议的攻击随机生成一系列宏操作，并将其应用于原始PE恶意软件样本。重复此操作，直到生成的转化恶意软件逃避检测。一旦恶意软件样本不可信，不必要的宏操作将从应用于其的宏操作序列中删除。这样做是为了最大限度地减少由于某些混淆技巧而意外破坏功能的可能性。剩余的宏操作随后被分解为微操作，以获得更详细的转换跟踪，从而生成恶意软件示例。我们建议读者阅读原始文章，以获得关于每个宏和微操作的更多详细信息，但是，我们在此简要描述它们。宏操作包括以下内容：</p>
<ul>
<li>将字节追加到二进制文件的末尾</li>
<li>将字节追加到节末尾未使用的空间</li>
<li>增加一个新的部分重命名</li>
<li>注销已签名证书</li>
<li>删除调试信息</li>
<li>将标头中的校验和值归零</li>
<li>用语义等价的指令替换指令</li>
</ul>
<p>其中一些宏操作可以分解为一系列较小的操作，称为微操作。例如，追加字节的操作可以分解为一次添加一个字节的序列。作者声称，通过分解每个宏操作，可以深入了解特定操作导致逃避的原因。提出的方法不是利用诸如FGSMor
C&amp;Wattack之类的对抗性示例生成算法，而是试图对机器学习模型提供一种更易于解释的攻击。该方法针对商业防病毒软件进行了评估，并被发现对包含静态和动态分析的分类器有效。</p>
</blockquote>
<h4><span id="322-code-transformation">3.2.2 Code transformation</span></h4>
<ul class="task-list">
<li><input type="checkbox"><strong>[83] Malware Detection in
Adversarial Settings: Exploiting Feature Evolutions and Confusions in
Android Apps.</strong></li>
</ul>
<blockquote>
<p>Yang等人提出了两种对恶意软件样本的攻击，以逃避机器学习模型的检测，但没有使用机器学习算法[83]。建议的进化攻击不是针对错误分类，而是基于变异的上下文特征（由时间特征、区域设置特征和依赖性特征组成）模仿Android恶意软件的自然进化[84]。这是通过混淆工具OCTOPUS自动化这些变异策略并大规模使用它们来识别目标分类器上的“盲点”来实现的。恶意软件家族被组织成系统进化树[69]，以分析家族内的共同特征和不同特征。然后根据可行性和频率对每个特征变异进行排序，并进行排序。然后，顶级G突变用于生成新的恶意软件变体。作者还提出了一种特征混淆攻击来补充进化攻击。特征混淆攻击的目标是修改恶意软件样本，使某些特征与良性样本的特征相似。攻击开始于收集一组混乱的功能，或恶意软件和良性样本共享的一组功能。对于混淆特征集中的每个特征，记录包含该特征的良性和恶意样本数。如果存在更多良性样本，则该特征将添加到“目标特征”列表中。然后，攻击会变异恶意软件样本，使其包含已发现的目标特征，从而增加规避的可能性。针对基于Android学习的恶意软件分类器AppContext[84]和Drebin[7]对提出的方法进行了评估。需要注意的是，虽然攻击不需要白盒访问目标模型，但它确实假设（1）恶意软件源代码和（2）模型使用的功能知识。</p>
</blockquote>
<ul class="task-list">
<li><input type="checkbox"><strong>[40] Deceiving Portable Executable
Malware Classifiers into Targeted Misclassification with Practical
Adversarial Examples</strong></li>
</ul>
<blockquote>
<p>Kucuk等人认为，敌对恶意软件示例必须避开基于静态和动态机器学习的分类器[40]。因此，他们提出了一种针对PE恶意软件的攻击，利用虚假控制流混淆和API混淆来逃避使用静态和动态特征的模型的检测。应用的控制流混淆基于LLVM-Obfuscator[33]。LLVM模糊器通过使用不透明谓词和从不使用任意指令执行伪基本块，在LLVM-IR级别改变程序的控制流。使用差分分析，作者找到了最佳控制流混淆和伪基本块，以生成一个恶意软件示例。这会干扰静态特性，例如n-grams、操作码频率和导入的API调用。该攻击使用一种遗传算法来最小化所需目标类别的频率特征向量与恶意软件样本之间的Kullback-Leibler（KL）散度。为了规避基于动态API调用的恶意软件分类器，作者使用相同的遗传算法确定哪些API调用必须进行模糊处理，然后使用[70]中介绍的技术进行模糊处理。此外，再次使用相同的遗传算法确定应添加到原始恶意软件样本中的其他API调用序列，类似于[65]所采用的方法。</p>
</blockquote>
<ul class="task-list">
<li><input type="checkbox" checked><strong>[59] Intriguing
Properties of Adversarial ML Attacks in the Problem Space (2020
S&amp;P)</strong></li>
</ul>
<blockquote>
<p>Pierazzi等人提出了一种针对Android恶意软件分类器Drebin的黑盒攻击[59]。作者提出了一种问题空间方法，使用<a href="Opaque%20predicates%20are%20a%20commonly%20used%20technique%20in%20program%20obfuscatio">不透明谓词</a>反复插入良性代码块，以改变Drebin提取的特征。这些良性代码块是在攻击之前通过分析训练集中的样本来初始化的，这些样本用于识别导致负面或良性标签的代码序列。攻击受到可行性检查的限制，以避免过度转换，从而增加怀疑。此外，使用FlowDroid[8]和So烟灰[75]插入代码块，以最小化副作用或伪影。</p>
</blockquote>
<ul class="task-list">
<li><input type="checkbox"><strong>[24] HideNoSeek: Camouflaging
Malicious JavaScript in Benign ASTs (2019 CCS)</strong></li>
</ul>
<blockquote>
<p>HideNoSeek与其他应用代码转换的攻击不同，它试图通过将抽象语法树（AST）转换为良性来隐藏恶意JavaScript[24]。攻击开始于构建恶意和良性文件的AST，以检测两个类之间共享的子AST或子图。为了创建对抗性示例，HideNoSeek利用随机化、数据模糊和不透明结构插入良性子AST。该攻击还可以重写现有的AST，使其看起来是良性的。这些攻击是在黑盒模型中针对基于Zozzle的定制分类器进行的，Zozzle是一种使用从JavaScript
AST中提取的特征的贝叶斯分类器[19]。</p>
</blockquote>
<h3><span id="4-discussion">4 DISCUSSION</span></h3>
<h4><span id="41-challenges">4.1 Challenges</span></h4>
<blockquote>
<p>首先，还应注意的是，我们绝不会减少或淡化恶意软件领域中不产生可执行恶意软件样本的对抗性示例研究的贡献。然而，我们认为，为了在现实的敌对环境中更好地构建提议的攻击，有必要扩展或包括关于扩展攻击以产生可执行恶意软件样本的可能方法的讨论。随着对抗性示例研究的快速发展，有必要充分了解这些攻击如何过渡到恶意软件检测和网络安全领域。全面开发或概念验证攻击也有助于开发针对敌对恶意软件样本的健壮模型。</p>
</blockquote>
<h4><span id="411-threat-models">4.1.1 Threat models</span></h4>
<blockquote>
<p>这一研究领域的一个挑战是威胁模型的不一致性。我们认为有必要明确定义每项研究中考虑的威胁模型，以便更好地理解攻击的局限性以及作者所做的任何假设。除了对抗性示例文献中使用的一般白盒和黑盒威胁模型外，我们建议包括（1）对源代码可用性的假设，以及（2）由于时间或计算限制对对手进行攻击的可行性。与Papernot等人[55]的工作类似，观察改变对手资源的效果会很有趣，例如，限制目标模型允许的查询数量，或为对手攻击的每次迭代产生成本。</p>
</blockquote>
<h4><span id="412-establishing-baselines">4.1.2 Establishing baselines</span></h4>
<blockquote>
<p>另一个挑战是建立基线和基本真相。在整个审查的论文中，没有一致的数据集，也没有一致的（ML或商业）恶意软件分类器。尽管本次调查中考虑的所有作品都对顶级分类词有很高的漏检率，但我们无法公平地对它们进行评估。在提议的攻击和它们的实验评估之间保持一致将允许更好地比较攻击。然而，如[76]所示，维护一致的数据集和恶意软件分类器以及进行公平评估都会带来自身的挑战。这也将有助于扩展Quarta
et.al.提出的评估，Quarta
et.al.使用他们的框架crAVe表明，简单地混淆或变异恶意软件样本就足以逃避检测，因为并非所有反病毒软件都进行某种形式的动态分析。</p>
</blockquote>
<h4><span id="413-dataset">4.1.3 Dataset</span></h4>
<blockquote>
<p>数据集：虽然将旧恶意软件转换为规避恶意软件确实显示了恶意软件检测中的漏洞，但排除较新的恶意软件样本会带来概念漂移(concept
drift.)的风险。例如，如果恶意软件针对新平台进行了大幅更改，则旧的恶意软件数据集可能无法正确反映恶意功能和行为。良性程序样本也是如此。传统上，良性样本是从新安装的操作系统中刮取的。然而，目前尚不清楚这些预装程序是否反映了用户下载和/或扫描恶意行为的程序。</p>
</blockquote>
<h4><span id="414-malware-classifiers">4.1.4 Malware classifiers</span></h4>
<blockquote>
<p>目前尚不清楚哪种恶意软件分类器最适合评估攻击。正如Song等人所说，假设模型的任何先验知识也是不现实的。我们认为目前没有也不会有一个一致的恶意软件检测模型基线，因为该领域的研究仍在增长。然而，我们建议未来的工作在黑盒威胁模型下评估他们对多分类器的攻击。这将有助于理解攻击在决策过程中使用不同特征的各种检测模型之间的可转移性。</p>
</blockquote>
<h4><span id="42-possible-researchdirections">4.2 Possible research
directions</span></h4>
<h4><span id="421defending-against-practical-adversarial-malware-examples">4.2.1
Defending against practical adversarial malware examples</span></h4>
<blockquote>
<p>一些研究已经在评估恶意软件领域中对抗性训练的使用[4,43]。然而，鲁棒机器学习研究包括许多其他防御策略，如平滑[2]和随机化[60]。目前尚不清楚这些方法是否会转移和防御对抗性恶意软件示例。</p>
</blockquote>
<h4><span id="422relationships-between-obfuscation-and-adversarial-examples">4.2.2
Relationships between obfuscation and adversarial examples</span></h4>
<blockquote>
<p>混淆和敌对示例有一个共同的目标：逃避检测。此外，大多数实用的对抗性恶意软件示例算法都将流行的混淆策略纳入了攻击中。一个可能的研究问题是评估使用更先进的模糊处理方法（如虚拟化）生成对抗性示例的可行性。目前还不清楚对抗性恶意软件示例与更传统的恶意软件规避技术（如Bulazel等人[14]中总结的技术）相比有什么好处。在Song等人[68]和Demetrio等人[20]的工作基础上扩展对抗性恶意软件示例的可解释性，并利用这一点进一步开发规避转换，这也是很有趣的。</p>
</blockquote>
<h4><span id="423integration-of-static-and-dynamic-analysis-techniques">4.2.3
Integration of static and dynamic analysis techniques</span></h4>
<blockquote>
<p>许多经过审查的工作都假设在测试之前没有对恶意软件样本进行高级分析。然而，情况并非总是如此。例如，预处理步骤可用于使用除臭框架（如SATURN[25]）对[57]和[40]产生的规避恶意软件样本进行除臭。未来的攻击和防御工作将考虑使用分类和检测管道，而不是单一的机器学习模型或商业防病毒产品，这将是一件有趣的事情。</p>
</blockquote>
<h4><span id="43-othersurvey-and-systematization-of-knowledge-papers">4.3 Other
Survey and systematization of knowledge papers</span></h4>
<blockquote>
<p>在本节中，我们将对涉及相关主题的知识论文进行其他调查和系统化。袁等人。深入学习的对抗性攻击和防御调查[86]。它们还提供了可以使用对抗性攻击的应用程序和问题域。与这项工作类似，Maiorca等人对基于机器学习的PDF恶意软件检测系统的对抗性攻击进行了调查[48]。Bulazel和Yener调查动态恶意软件分析规避和缓解策略[14]。Ye等人综述了数据挖掘技术在恶意软件检测中的应用[85]。Ucci等人利用机器学习对恶意软件分析进行了调查[74]。最后，van
der
Kuowe等人调查了为公平准确地评估安全性研究而必须考虑的常见基准测试缺陷。</p>
</blockquote>
<h3><span id="5-conclusion">5 CONCLUSION</span></h3>
<blockquote>
<p>我们对恶意软件领域中的实际对抗性示例进行了调查。随着基于机器学习的解决方案开始在工业界和学术界被采用，对抗性示例及其对网络安全领域的影响的研究非常重要。我们希望这项调查将为这一领域的未来研究提供有用的信息。</p>
</blockquote>
<hr>
<h4><span id="遗传算法">遗传算法</span></h4>
<ul>
<li><strong>Robust Android Malware Detection against Adversarial Example
Attacks.</strong> <a href="https://dblp.uni-trier.de/db/conf/www/www2021.html#LiZYLGC21">WWW
2021</a>: 3603-3612</li>
<li><strong>secml-malware: A Python Library for Adversarial Robustness
Evaluation of Windows Malware Classifiers.</strong> <a href="https://dblp.uni-trier.de/db/journals/corr/corr2104.html#abs-2104-12848">CoRRabs/2104.12848</a>
(2021)</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>AI安全</category>
      </categories>
  </entry>
  <entry>
    <title>AI安全（5）Functionality-Preserving Black-Box Optimization of Adversarial Windows Malware 2021 TIFS</title>
    <url>/posts/3SMQYQP/</url>
    <content><![CDATA[<h2><span id="functionality-preservingblack-box-optimization-of-adversarial-windows-malware-2021-tifs"><strong>Functionality-Preserving
Black-Box Optimization of Adversarial Windows Malware 2021 TIFS
</strong></span></h2>
<p><strong>keyword:</strong> 对抗样本；黑盒优化；</p>
<h3><span id="abstract">Abstract：</span></h3>
<p>基于机器学习的Windows恶意软件检测器很容易受到攻击性示例的攻击，即使攻击者只获得对模型的黑盒查询访问权限。这些攻击的<strong>主要缺点</strong>是：<strong>查询效率低</strong>下，因为它们依赖于对输入恶意软件反复应用随机转换；它们可能还需要在优化过程的<strong>每次迭代中在沙盒中执行恶意软件</strong>，以确保其入侵功能得到保留。依赖于在恶意文件的<strong>末尾或在一些新创建的部分中注入良性内容</strong>（这些内容永远不会被执行）。<strong>我们的攻击被形式化为一个有约束的最小化问题，这也使得规避检测的概率和注入的有效负载的大小之间的权衡得到优化</strong>。对两种流行的静态Windows恶意软件检测器进行了实证研究，结果表明，即使只返回预测的标签，我们的黑盒攻击也可以通过很少的查询和较小的有效负载绕过它们。还评估了我们的攻击是否会转移到其他商业防病毒解决方案中，并意外地发现它们平均<strong>可以避开12个以上的商业防病毒引擎</strong>。讨论了我们的方法的<strong>局限性</strong>，以及它将来可能扩展到基于动态分析的目标恶意软件分类器。</p>
<h3><span id="一-introduction">一、Introduction</span></h3>
<p>机器学习在计算机安全领域正变得越来越普遍。学术界和工业界都在投入时间、金钱和人力资源来应用这些统计技术来解决恶意软件检测的艰巨任务。特别是，Windows恶意软件仍然是一种威胁，因为每天都有成千上万的恶意程序被上传到<strong>VirusTotal</strong><sup>[1]</sup>。现代方法使用机器学习来大规模检测此类威胁，利用许多不同的学习算法和特征集<sup>[1]–[7]</sup>。虽然这些技术已显示出很有前途的恶意软件检测能力，但它们最初的设计目的并不是为了处理攻击者可以操纵输入数据以逃避检测的非平稳、对抗性问题。</p>
<p>在过去的十年中，这一点在对抗式机器学习领域得到了广泛的证明<sup>[8]，[9]</sup>。该研究领域研究了机器学习算法在训练或测试阶段受到攻击时的安全性问题。特别是，在基于学习的Windows恶意软件检测器的背景下，已经证明可以针对目标系统仔细优化对抗性恶意软件样本以绕过它<sup>[10]–[17]</sup>。其中许多攻击都在黑盒设置中进行了演示，在黑盒设置中，攻击者只能对目标模型进行查询访问<sup>[14]–[17]</sup>。这确实对作为云服务部署的此类系统的安全性提出了质疑，因为外部攻击者可以查询这些系统，然后根据目标系统提供的反馈优化其操作，直到实现规避。</p>
<p>然而，这些黑盒攻击在以下方面仍然不是非常有效：（i）所需查询的数量<strong>(reguired
queries)</strong>，（i）其优化过程的复杂性<strong>(complexity)</strong>，以及（i）<strong>对输入样本执行的操作量(amount
of manipulations)</strong>，如下所述: 1. 首先查询效率 is hindered by the
fact that
攻击通过反复迭代并非专门针对逃避检测的转换（如在文件结尾后注入随机字节）来优化恶意软件。优化过程在计算上可能要求很高，因为有些攻击需要在每次迭代时在沙盒中执行敌对恶意软件样本，以确保其入侵功能得到保留。这种验证步骤是由在特征空间中操纵数据（而不是考虑可实现的输入修改<sup>[18]</sup>的攻击所要求的或者考虑可能破坏恶意软件样本<sup>[14]</sup>的功能的输入变换<sup>[19]</sup>。
2.
虽然在沙盒中执行一次恶意软件样本可能不会显著减慢整个过程，但因为它需要在感染前的阶段恢复虚拟环境的状态。当优化过程的每次迭代后都必须重复此步骤时，问题就变得相关了。此外，许多恶意软件样本可以检测它们是否在虚拟环境中运行，并延迟执行以保持未被检测到：Malware
dynamic analysis evasion techniques：A survey； 3.
所有这些攻击都通过显著操纵输入恶意软件的内容来实现规避，而<strong>不考虑额外的限制</strong>，例如，对生成的文件大小或注入的节数的限制。这可能导致攻击样本很容易被检测为异常，只需查看一些无关紧要的特征（<strong>trivial
characteristics</strong>），如文件大小或节数。</p>
<p>在本文中，我们提出了一个新的黑盒攻击家族（Section 3）
可以有效地优化恶意软件样本。首先，我们的攻击是高效查询的，因为它们依赖于注入特定目标的内容以便于规避，即从良性样本中提取（而不是随机生成）。第二，它们在设计上保留了功能，因为它们利用了一组操作，这些操作仅通过利用用于在磁盘上存储程序的文件格式的模糊性将内容注入恶意程序，而不改变其执行跟踪。虽然在这项工作中，我们只关注在文件末尾（填充）或在一些新创建的节（节注入）中注入内容，但我们的方法足够通用，可以包含更广泛的功能保留操作。最后，我们的攻击更加隐蔽。特别地，它们被形式化为<strong>一个约束最小化问题，该问题不仅优化了规避检测的概率</strong>，而且通过一个特定的正则化项<strong>（via
a specific regularization
term.）</strong>来惩罚注入的敌方有效载荷的大小。</p>
<h3><span id="二-programs-and-malwaredetection">二、PROGRAMS AND MALWARE
DETECTION</span></h3>
<p>在本节中，我们首先讨论Windows可移植可执行文件（PE）格式，2它描述了程序如何存储在磁盘上，并向操作系统（OS）解释了如何在执行之前将其加载到内存中。然后，我们将介绍这项工作剩余部分中使用的两种流行的基于学习的Windows恶意软件检测器。</p>
<h4><span id="21-the-windowsportable-executable-pe-file-format">2.1 The Windows
Portable Executable (PE) File Format</span></h4>
<p>Windows
PE格式由几个组件组成，如图1所示，如下所述。DOS标题（A）。它包含用于在DOS环境中加载可执行文件的元数据，以及DOS存根，如果在DOS环境中执行，则会打印“此程序无法在DOS模式下运行”。保留这两个组件是为了保持与旧版Microsoft操作系统的兼容性。从现代应用程序的角度来看，DOS头中唯一相关的部分是：（i）幻数MZ，文件的两字节长签名，以及（ii）偏移量0x3c处的四字节长整数，用作指向实际头的指针。如果这两个值中的一个由于某种原因被置乱，则认为程序已损坏，操作系统将不会执行该程序。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211340691.png" alt="image-20210724201057346" style="zoom:50%;"></p>
<p>PE
header（B）。它包含幻数PE以及其他文件特征，如目标体系结构、头大小和文件属性。</p>
<p>Optional
Header（C）。它包含操作系统初始化加载程序所需的信息。它还包含指向有用结构的偏移量，如操作系统解析依赖关系所需的导入地址表（IAT）和导出表偏移量，后者指示在何处查找其他程序可以引用的函数。截</p>
<p>Section
Table（D）。它是一个条目列表，指示程序的每个核心组件的特征，以及OS加载程序应该在文件中找到它们的位置。</p>
<p>Sections（E）节。这些连续的字节块承载着可执行文件的真实内容。要列出一些：。文本包含代码。数据包含全局变量和。rdata包含只读常量和计数。</p>
<p>可执行程序的结构可用于静态推断有关其行为的信息。事实上，大多数防病毒供应商应用静态分析来检测野外威胁，而不在受控环境中执行可疑程序。这种方法节省了时间和资源，因为防病毒程序不会在主机操作系统内执行可疑软件。静态分析是第一道防线，其性能对于抵御野外无数威胁至关重要。</p>
<h4><span id="22-learning-basedwindows-malware-detection">2.2 Learning-Based
Windows Malware Detection</span></h4>
<ul>
<li>MalConv</li>
<li>EMBER</li>
</ul>
<h3><span id="三-black-boxoptimization-of-adversarial-windows-malware">三、BLACK-BOX
OPTIMIZATION OF ADVERSARIAL WINDOWS MALWARE</span></h3>
<p>在本节中，我们将介绍一种新的黑盒攻击框架，命名为GAMMA（Genetic
adricative Machine learning Malware
attack）。GAMMA可以有效地优化敌方恶意软件样本，同时只需要黑盒访问模型，即只查询目标模型并观察其输出，而不访问其内部结构和参数。我们的攻击依赖于一组保留功能的操作，这些操作利用用于在磁盘上存储程序的PE格式的模糊性将内容注入恶意程序，而不改变其执行跟踪。这使我们能够摆脱需要计算的验证步骤，以确保被操纵的恶意软件保留其预期功能。特别是，我们认为这里的内容操纵，特别是针对有利于逃避，即，<strong>从良性样本中提取，而不是随机产生。虽然这使得我们的攻击更加有效，但值得注意的是，我们的框架足够通用，可以包含许多其他不同的内容操作技术</strong>。最后，为了使我们的攻击更加隐蔽，我们将其形式化为一个约束优化问题，该问题不仅最小化了逃避检测的概率，而且通过一个特定的惩罚项最小化了注入内容的大小。</p>
<p><strong>符号定义</strong>，我们用x 2 x表示  f0；：：：；255g 
（恶意）输入程序，描述为任意长度的字节字符串。然后，我们定义了一组k个不同的保留功能的操作，这些操作可以作为向量s2
s应用于输入程序x  [0；1]k</p>
<ul>
<li>Notation: <span class="math inline">\(x\)</span> malicious；<span class="math inline">\(s\)</span> (k 种
vector);（良性初始注入+遗传算法）</li>
</ul>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211340847.png" alt="image-20210725161919601">
<figcaption aria-hidden="true">image-20210725161919601</figcaption>
</figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211340732.png" alt="image-20210725161950958" style="zoom:50%;"></p>
<h4><span id="31functionality-preservingmanipulations保留功能的操作">3.1
<strong>Functionality-Preserving
Manipulations</strong>（保留功能的操作）</span></h4>
<p>我们在这里讨论一组可以在我们的攻击框架中使用的保留功能的操作。在windowspe文件格式的上下文中，只有一些转换可以在不影响输入程序执行的情况下应用。我们将其分为结构性和行为性两类，详情如下。</p>
<ul>
<li><strong>Structural结构化</strong>：这一系列操作只影响输入程序的结构，利用文件格式中的模糊性，而不改变其行为。
<ol type="1">
<li>Perturb Header
Fields：扰动标题字段[13]–[15]。此技术包括更改节名称、中断校验和以及更改调试信息。</li>
<li>Filling Slack
Space：填充松弛空间[12]–[15]，[23]。此技术操纵编译器插入的空闲空间，以保持文件内部的对齐。相应的空闲字节（图1中的E内）通常被设置为零，并且它们从不被可执行文件的代码引用。</li>
<li><strong>Padding</strong>：填充[11]、[12]、[23]。这种技术在文件末尾注入额外的字节（在图1中的E之后）。</li>
<li>Manipulating DOS Header and
Stub：操作DOS头和存根[10]，[22]。这项技术修改了DOS头中一些现代程序不使用的字节。</li>
<li>Extend the DOS Header:
扩展DOS标头[22]。这种技术通过在程序的实际头之前注入内容来扩展DOS头。</li>
<li><strong>Content
shifting</strong>：内容转移[22]。这种技术通过向前移动内容，在节的开始之前创建额外的空间，并在中间注入对抗性内容。</li>
<li>Import Function
Injection：导入函数注入[13]–[15]。该技术通过向导入地址表添加适当的条目来注入导入函数，指定在加载过程中必须包括哪个库中的哪个函数（这影响图1中的C和E）。</li>
<li>Section
Injection：第[13]-[15]节。这种技术通过在节表中创建一个额外的条目将新的节注入到输入文件中（从而影响图1中的D和E）。每个节条目的长度为40字节，因此所有内容都必须按该长度进行移位，而不会影响头指定的文件和节对齐方式。</li>
</ol></li>
<li><strong>Behavioral行为</strong>：这一系列的干扰可以改变程序的行为和执行痕迹，但仍然保留恶意软件程序的预期功能。例如，这些转换包含[24]中的二进制重写技术，如下所述。</li>
</ul>
<ol type="1">
<li>Packing：<strong>加壳</strong>[13]–[15]。软件加壳的原理是在原始程序外部添加一个保护层，以保护程序代码和数据不被恶意软件攻击者破解、篡改或复制。通过壳程序的加载和解码、原始程序的加密和解密、壳程序的动态反调试和反破解、以及代码混淆和虚拟机技术等手段，可以使程序更加安全和难以被攻击者破解。<strong>封隔器的作用是侵入性的，因为输入样本的整个结构都被修改了；</strong>
<ul>
<li>[13] R. L. Castro, C. Schmitt, and G. D. Rodosek, “ARMED: How
automaticmalware modifications can evade static detection?” in Proc. 5th
Int.Conf. Inf. Manage. (ICIM), Mar. 2019, pp. 20–27.</li>
<li>[14] R. L. Castro, C. Schmitt, and G. D. Rodosek, “Aimed: Evolving
malwarewith genetic programming to evade detection,” in Proc. 18th Int.
Conf.TrustCom, 2019, pp. 240–247.</li>
<li>[15] H. S. Anderson, A. Kharkar, B. Filar, and P. Roth, “Evading
machinelearning malware detection,” in Proc. BlackHat, 2017.</li>
</ul></li>
<li>Direct：直接[24]。这种方法重写代码的特定部分，比如用等价的指令替换汇编指令（例如，用相反的符号进行加法和减法）。
<ul>
<li>这种技术被称为“<strong>代码混淆</strong>”（code
obfuscation）。它是一种常见的恶意软件攻击技术，攻击者使用代码混淆技术来隐藏恶意代码的真实意图，使其更难以被检测和分析。</li>
<li>在这种技术中，攻击者会通过重写代码的特定部分来进行代码混淆。例如，攻击者可以用等价的指令替换汇编指令，或者用相反的符号进行加法和减法等操作。这样一来，原本的代码逻辑就被混淆了，使得恶意代码更难以被理解和分析。</li>
<li>代码混淆技术可以有效地防止恶意代码被检测和分析，因为它使得恶意代码的行为更难以被预测和理解。然而，代码混淆也会使得恶意代码更难以被清除和修复，因为恶意代码的行为可能会受到混淆代码的影响，从而导致误报和误判。</li>
<li>[24] M. Wenzl, G. Merzdovnik, J. Ullrich, and E. Weippl, “From
hackto elaborate technique—A survey on binary rewriting,” ACM
Comput.Surv., vol. 52, no. 3, pp. 1–37, Jul. 2019</li>
</ul></li>
<li>Minimal
Invasive[15]，[24]。此技术将入口点设置为新的可执行部分，该部分跳回原始代码。
<ul>
<li>这种技术被称为“<strong>代码注入</strong>”（code
injection）。它是一种恶意软件攻击技术，攻击者通过将恶意代码注入到受害者计算机中的合法进程中，来控制受害者计算机、窃取敏感信息或者执行其他恶意行为。</li>
<li>在这种技术中，攻击者会将恶意代码插入到被感染程序的可执行部分中，并将程序的入口点设置为恶意代码的起始位置，使程序在运行时首先执行恶意代码。然后，恶意代码会执行一些操作（如窃取信息、下载其他恶意代码等），最后将程序的控制权转回到原始代码中，以避免被检测到。</li>
<li>代码注入是一种常见的恶意软件攻击技术，攻击者可以使用多种方法来实现代码注入，如缓冲区溢出、API
Hooking、DLL注入等。为了防止代码注入攻击，建议用户保持软件的更新和使用安全软件进行防护。</li>
</ul></li>
<li>Full
Translation：完整翻译[24]。这种方法将所有代码提升到更高的表示形式，例如LLVM，4，因为它简化了扰动的应用，然后将代码翻译回汇编语言。
<ul>
<li>这种技术被称为“<strong>语义混淆</strong>”（semantic
obfuscation）。它是一种常见的恶意软件攻击技术，攻击者使用语义混淆技术来隐藏恶意代码的真实意图，使其更难以被检测和分析。</li>
<li>在这种技术中，攻击者会将所有代码提升到更高的表示形式，例如LLVM，因为这样可以简化扰动的应用。然后，攻击者会将代码翻译回汇编语言，但是这时的代码已经被语义混淆了，使得其更难以被理解和分析。</li>
<li>语义混淆技术可以有效地防止恶意代码被检测和分析，因为它使得恶意代码的行为更难以被预测和理解。然而，语义混淆也会使得恶意代码更难以被清除和修复，因为恶意代码的行为可能会受到混淆代码的影响，从而导致误报和误判。</li>
</ul></li>
<li>Dropper[30]。这种方法将代码存储为另一个二进制文件的资源，然后在运行时加载。
<ul>
<li>这种技术被称为“<strong>二进制文件注入</strong>”（binary file
injection）。它是一种恶意软件攻击技术，攻击者使用二进制文件注入技术来隐藏恶意代码，使其更难以被检测和分析。</li>
<li>在这种技术中，攻击者会将恶意代码存储为另一个二进制文件的资源，然后在运行时加载。这样一来，恶意代码就被隐藏在另一个二进制文件的资源中，使得它更难以被检测和分析。</li>
<li>二进制文件注入技术可以有效地防止恶意代码被检测和分析，因为它使得恶意代码更难以被发现。然而，二进制文件注入也会使得恶意代码更难以被清除和修复，因为恶意代码可能会被存储在多个文件中，从而需要进行全面的扫描和清除。</li>
<li>[30] F. Ceschin, M. Botacin, H. M. Gomes, L. Oliveira, and A.
Grégio,“Shallow security: On the creation of adversarial variants to
evademachine learning-based malware detectors,” in Proc. 3rd
ReversingOffensive-Oriented Trends Symp., 2019, pp. 1–9.</li>
</ul></li>
</ol>
<ul>
<li><strong>Padding and Section-Injection Attacks
填充和节注入攻击</strong></li>
</ul>
<p>虽然GAMMA可以通过在[33
]中的开源实现支持大多数上述操作，但是我们只考虑在这项工作中的<strong>填充</strong>和<strong>分段注入攻击</strong>，因为它们提供了两个<strong>有代表性的示例</strong>，即在不需要操纵额外的头组件的情况下，在样本内注入内容（例如，节区表）。特别是，<strong>Padding</strong>将内容注入到可执行文件的未使用空间中，而不改变任何其他头组件。相反，<strong>Section
infection</strong>不仅允许像其他技术一样注入自定义内容，而且还通过在节表中添加节条目来操纵可执行文件的结构。</p>
<h3><span id="四-实验">四、实验</span></h3>
<p>在本节中，我们根据经验评估了针对GBDT和MalConv恶意软件检测器的攻击的有效性。我们在一台装有Intel的工作站上进行了实验 
至强  CPU E5-2670，具有48个CPU和128 GB
RAM。MalConv的预训练版本呈现出略有不同的体系结构w.r.t。原始公式：1
MB的输入大小和256的填充值，以避免移动预处理部分。该网络使用PyTorch实现【25】。我们使用DEAP开发了GAMMA的遗传优化器【26】。我们使用10个元素的总体大小N测试了攻击，将查询预算T从10更改为510。如果优化器在一个局部最小值上停滞了5次以上的迭代，我们将停止该过程。我们使用正则化参数的值 
2层10  ig9i=3。由于攻击特征空间S在攻击者可能添加的节数上是参数化的，因此我们随机提取了75个。如第III-a节所述，我们的goodware数据集中的rdata部分将用于向输入恶意软件添加内容，最大容量为2.5
MB。我们愿意将此数字设置为高值，因为优化器将发现较小的有效负载，这要归功于行为为“1”标准的惩罚术语所施加的稀疏性。我们实现并公开了用于计算这些攻击的库，名为secml恶意软件。5.</p>
<h4><span id="41-无攻击时的性能">4.1 无攻击时的性能</span></h4>
<p>为了在没有攻击的情况下评估这两种分类器的性能，我们收集了一组分类器；15000良性和15；000个恶意软件样本。恶意软件样本是从VirusTotal收集的，而<strong>goodware样本是通过从GitHub下载可执行程序收集的</strong>。结果如图3所示。为GBDT选择的阈值为0.8336，对应于0.039的假阳性率（FPR）和0.95的真阳性率（TPR）。<strong>MalConv使用的阈值为0.5，这导致FPR为0.035，TPR为0.69</strong>。图中的红点直接在曲线上显示这些值。这些结果与GBDT【6】的作者给出的描述相当，因为两种检测器的w.r.t得分略低。这篇论文中报道了这一点。不过，它们都可以作为我们分析的基线。</p>
<h4><span id="42-攻击评估">4.2 攻击评估</span></h4>
<p>我们从收集的15K恶意软件中<strong>随机抽取500个用于对抗性攻击</strong>，其中包括5.3%的勒索软件、29%的下载软件、18%的病毒、7%的后门软件、29%的灰色软件、8%的蠕虫，以及其他百分比较低的家族。图4显示了检测率和对抗性有效载荷大小如何随查询数量和正则化参数的值而变化。曲线图中的每条曲线都是通过计算每个值的平均检测率和平均大小生成的 ,
针对发送的不同查询数重复此操作。作为的值 
由于在计算目标函数时，惩罚项可以忽略不计，因此该算法可以找到更多有效载荷较大的规避样本。另一方面，通过增加 
由此产生的攻击特征向量变得稀疏，生成更小但更可检测的对抗性示例。在这种情况下，惩罚项会吞噬分类器计算的分数，这在优化过程中变得无关紧要。另一个重要影响是遗传优化器使用的总查询数：发送的越多，敌对示例的检测率和大小越好。直观地说，通过发送更多的查询，GAMMA可以同时探索更多隐藏和回避的解决方案，但在优化过程的早期阶段无法找到此类解决方案。为了证明我们的方法的有效性，我们报告了应用递增长度随机字节序列的结果。这个实验强调了轻微的下降趋势，但使用良性内容注入的优化攻击比随机干扰更有效。分段注入攻击比填充攻击更能降低GBDT的检测率。由于第一种技术还在节表中引入了节条目，因此与填充攻击修改的特性相比，对抗性有效载荷干扰的特性更多。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211340248.png" alt="image-20220606205653971">
<figcaption aria-hidden="true">image-20220606205653971</figcaption>
</figure>
<h4><span id="43-硬标签攻击">4.3 硬标签攻击</span></h4>
<p>我们在表I中显示了聚合结果，重点比较了软标签和硬标签攻击的性能。每个条目表示每个检测器的平均检测率和平均对抗有效负载大小，给定一对用于计算指定攻击的查询/正则化参数。我们计算了4个不同的 
在集合f10中  （2i+1）g4i=1。结果表明，在没有置信度得分的情况下，一旦发现一个规避有效载荷，则无论正则化参数的值如何，其大小都会在遗传算法的一次又一次迭代中得到优化 .
这是由我们为实验设置的结果造成的：我们使用一个无限值来丢弃每个检测到的敌对示例，因此所有剩余的示例仅用于优化大小，作为优化的约束本身。我们的方法在这种环境中的有效性是由注入的内容的性质引起的，它模仿良性类，图4证实了这一点，其中注入随机字节序列对目标没有影响。相反，查询的数量本身起到了调节器的作用，因为太少的查询会导致更大的对抗性有效载荷，而置信度较低，而大量的查询会导致分数较高的小有效载荷。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211341881.png" alt="image-20220606205832607" style="zoom:50%;"></p>
<h4><span id="44-时间分析">4.4 时间分析</span></h4>
<p>从时间的角度来看，GAMMA的复杂性主要取决于查询探测器所花费的时间。表II显示了计算每个攻击和目标的单个查询所需的平均运行时间。令人惊讶的是，特征提取阶段和GBDT预测所花费的时间之和小于神经网络处理所有字节所需的时间。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211341457.png" alt="image-20220606210050720" style="zoom:50%;"></p>
<h4><span id="45-加壳影响">4.5 加壳影响</span></h4>
<p>由于这些分类器仅利用静态特征，因此我们有理由问自己，在不应用第三节中介绍的所有技术的情况下，加密程序内容是否足以逃避检测。<strong>打包是一种通过应用压缩、加密或编码算法来减少可执行文件大小的技术。由于打包器的作用完全改变了磁盘上的程序表示，恶意软件供应商广泛使用打包器向分析师隐藏其产品，增加了逆向工程分析的难度。</strong>在这种情况下，我们将一种著名的技术UPX7应用于1000个恶意软件和1000个goodware程序，并测试MalConv和GBDT的规避率。UPX封隔器的有效性如图5所示。这两个检测器在打包样本时都会给出恶意分数，通过查看打包好的goodware程序的方框图，这是很直观的。这两种检测器都增加了它们对恶意软件类别的得分，而打包恶意软件的均值和方差只有很小的变化。</p>
<p>从这些结果来看，我们认为，探测器将包装技术的应用视为一种恶意特征。这可能是由于训练集中有大量打包的恶意软件，而不是缺少打包的好软件。因此，基于此类数据训练的模型可能会有偏差，使他们错误地认为样本是恶意的，只是因为它是打包的。此外，如果使用一种技术打包足够的样本，学习算法应该能够捕获打包程序中打包程序本身留下的签名。例如，UPX打包器创建两个名为UPX0和UPX1的可执行部分，其中包含提取代码和原始压缩程序。<strong>我们认为，通过包装技术进行规避更可能由看不见的包装商实现，即恶意软件供应商自己开发的定制解决方案</strong>。</p>
<blockquote>
<p>We believe that evasion through packing techniques should more likely
to be achieved by unseen packers, <strong>i.e.</strong> custom solutions
developed by malware vendors themselves.</p>
</blockquote>
<h4><span id="46evaluation-on-antivirus-programs-virustotal">4.6
<strong>Evaluation on Antivirus Programs</strong> (VirusTotal)</span></h4>
<p>我们在此评估我们的攻击对商用探测器的影响。在这种情况下，我们无意逃避这些商业程序的检测，例如打包输入样本，而是评估这些方法是否可以检测到我们的攻击，因为我们的攻击只对输入恶意软件样本的内容进行了最小程度的修改。特别是，我们应用于恶意软件样本的操作仅涉及每个程序的语法结构，我们的目的是评估此类转换的应用是否会对其他防病毒程序构成威胁。我们预计，大多数商业解决方案不应受到此类攻击的影响。我们依赖VirusTotal检索到的响应，8这是许多威胁检测器的在线接口。该服务提供了一个API，可以通过从远程上传样本来查询系统。我们通过在向样本中注入对抗性负载之前和之后发送200个恶意软件样本来测试我们的攻击性能，该样本使用针对GBDT分类器的分段注入攻击进行了优化。我们还将我们的攻击与基线随机攻击进行比较，基线随机攻击只是向每个样本添加50
KB的随机负载。表三显示了VirusTotal上托管的防病毒程序平均有多少（总共70个）检测到提交的恶意软件样本。虽然随机攻击只会略微减少每个样本的检测数量，但分段注入攻击能够绕过平均每个样本12个以上的检测器。为了更好地评估我们的攻击对单个杀毒程序的影响，在表IV中，我们报告了2019年Gartner端点保护平台幻方图上出现的9种不同杀毒产品的检测率，9包括许多领先和有远见的产品，在执行随机和部分注入攻击之前和之后。在许多情况下，我们的节注入攻击能够大幅降低检测率（参见，例如，AV1、AV3、AV7和AV9），显著优于随机攻击（参见，例如，AV1和AV9）。原因可能是，其中一些防病毒程序已经使用基于静态机器学习的检测器，在保护终端客户端免受恶意软件攻击时实施了第一道防线，这也在他们的博客或网站上得到了证实，这使他们更容易受到我们的攻击。综上所述，我们的分析强调，这些商业产品可以通过转移攻击来规避，我们相信，通过对其进行优化攻击，它们的检测率可能会下降更多。</p>
<h3><span id="五-related-work">五、RELATED WORK</span></h3>
<h5><span id="强化学习15">强化学习[15]</span></h5>
<blockquote>
<p>Anderson等人[15]提出了一种强化学习方法，以确定导致逃避的最佳操作顺序。为了测试代理的有效性，他们还测试了随机选取的操作的应用。他们用作基线的模型是我们在这项工作中分析的GBDT分类器的原始版本，使用较少的样本进行训练。为了训练学习代理的策略，他们通过为可使用的查询数量确定预算，让模型探索对抗性示例的空间。用于培训这些策略的查询平均数量约为1600[15]。作者没有报告对抗性恶意软件产生的文件大小：强化学习方法包含放大磁盘上表示的操作，但不清楚如何和多少。不同的是，我们的方法不需要培训阶段，因为它可以针对远程探测器进行部署。我们使用的转换在设计上是功能不变的，它们的应用程序不会改变程序的执行流。最后，通过在优化过程中插入正则化器，我们考虑了有多少内容被添加到输入恶意软件中。通过这种方法，可以控制插入噪声的数量，并且该算法可以找到不仅避开目标分类器，而且在大小上受到限制的对抗性示例。</p>
</blockquote>
<h5><span id="随机算法和遗传算法1314">随机算法和遗传算法[13],[14]</span></h5>
<blockquote>
<p>Castro等人[13]，[14]应用随机算法和遗传算法来干扰输入恶意软件，并在沙箱中的优化过程的每次迭代中测试样本的功能。这些突变与Anderson等人提出的相同[15]。这些工作的作者表示，他们需要大约4分钟来创建敌对恶意软件，使用100个查询。尚未公布任何架构细节。我们不需要在沙箱中验证恶意软件，因为我们在变异过程中包含了领域知识。因此，我们的方法在同一时间跨度内执行1400个查询。他们也没有报告哪些是导致规避的最具影响力的突变：后者至关重要，我们正在处理统计算法中的潜在漏洞，与其他安全漏洞相比，这些漏洞的存在并不明显。</p>
</blockquote>
<h5><span id="gan27">GAN[27]</span></h5>
<blockquote>
<p>Hu和Tan[17]开发了一个生成性对抗网络（GAN）[27]，其目的是绕过目标分类器，打造对抗性恶意软件。网络会了解哪些API导入应该添加到原始样本中，但不会生成真正的恶意软件，因为这种攻击只在功能空间内运行。相反，由于每次都会生成真实的样本，因此我们创建了功能正常的恶意软件。针对Windows恶意软件检测器的黑匣子攻击的概述见表V，其中我们将上述技术与我们的方法进行了比较。</p>
</blockquote>
<h3><span id="六-conclusion-and-futurework">六、<strong>CONCLUSION AND FUTURE
WORK</strong></span></h3>
<p>在本文中，我们<strong>提出了一个基于学习的Windows恶意软件检测器的新的黑盒攻击家族，它既能有效地进行查询，又能保持功能</strong>，克服了以往工作的局限性。我们的攻击依赖于在恶意文件末尾或在新创建的部分中注入良性内容（这些内容永远不会被执行），利用用于在磁盘上存储程序的文件格式的模糊性，而不改变其执行痕迹。所提出的攻击被形式化为一个有约束的最小化问题，该问题能够在规避检测的概率和注入的有效负载大小之间进行优化。我们对两个流行的基于学习的Windows恶意软件检测器进行了广泛的实证评估，结果表明，即使目标模型只输出预测的标签，我们的黑盒攻击也可以通过很少的查询和非常小的有效负载绕过它们。我们还表明，我们的攻击可以成功地转移到其他商业防病毒解决方案，发现他们可以逃避，平均而言，多达12个商业防病毒引擎提供的VirusTotal。尽管如此，我们相信直接针对这些探测器的优化攻击可能会更加有效。未来工作：未来工作的一个有趣途径是调查针对我们的攻击的适当对策的适用性，如第节所讨论的。六、
包括使用更健壮的特征表示（对基于字节或基于节的操作不敏感）和学习范式（通过对抗性再训练、特定攻击检测机制或使用领域知识约束）。另一个有希望的研究方向是将我们的攻击扩展到只在文件末尾或新创建的部分中注入内容的操作之外。我们坚信这是可以很容易实现的，因为我们的方法已经足够普遍，可以包含更广泛的功能保留操作，包括第节中讨论的操作。III-A级。将我们的工作扩展到处理也可以修改恶意软件程序动态执行的操作，例如在保留恶意意图的同时改变其控制流，无疑是一个挑战。然而，这无疑将为改进基于动态程序分析提取的特征的恶意软件检测器的评估和对抗性健壮性提供重要的一步。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>AI安全</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（11）T&amp;-Blackhat 2022-Malware Classification With Machine Learning Enhanced by Windows Kernel Emulation</title>
    <url>/posts/2Z5SQWP/</url>
    <content><![CDATA[<h2><span id="malware-classification-with-machine-learning-enhanced-by-windows-kernelemulation"><font color="red">
Malware Classification With Machine Learning Enhanced by Windows Kernel
Emulation</font></span></h2>
<blockquote>
<p>论文：http://i.blackhat.com/USA-22/Thursday/US-22-Trizna-Malware-Classification-with-machine-learning.pdf</p>
<p>项目：https://github.com/dtrizna/quo.vadis</p>
<p>作者：<strong>Dmitrijs Trizna</strong></p>
</blockquote>
<p>我们提出了一种混合机器学习架构，该架构同时使用多个深度学习模型来分析Windows可移植可执行文件的上下文和行为特征，并根据元模型的决策生成最终预测。当代机器学习Windows恶意软件分类器中的检测启发式通常基于样本的静态属性，因为通过虚拟化进行的动态分析对于大量样本是具有挑战性的。为了克服这一限制，我们采用了一种Windows内核仿真，它允许以最小的时间和计算成本跨大型语料库获取行为模式。<strong>我们与一家安全供应商合作，收集了超过10万个类似于当代威胁场景的野生样本，其中包含执行时应用程序的原始PE文件和文件路径</strong>。获取的数据集至少比行为恶意软件分析相关工作中报告的数据集大十倍。训练数据集中的文件由专业威胁情报团队使用手动和自动逆向工程工具进行标记。我们通过在获得训练集三个月后收集样本外测试集来估计混合分类器的操作效用。我们报告了一种改进的检测率，高于当前最先进模型的能力，特别是在低误报要求下。此外，我们还发现了元模型在验证和测试集中识别恶意活动的能力，即使没有一个单独的模型表达足够的信心来将样本标记为恶意。我们得出结论，元模型可以从不同分析技术产生的表示组合中学习恶意样本的典型模式。此外，我们公开发布预先训练的模型和仿真报告的非命名数据集。</p>
<p><strong>因此实现了与虚拟化相比的高分析速率</strong>。由于数据异构性，我们考虑使用多个单独的预训练模块和元模型的组合解决方案，而不是构建具有端到端可训练架构的单个特征向量。该架构允许通过仅重新训练元模型，以最小的努力扩展决策启发式的模块性。在本出版物的范围内，混合ML体系结构的评估依赖于三种不同的分析技术</p>
<p>缺乏出版物人工制品是任何研究中一个臭名昭著的缺陷，并导致了科学的再现性危机。因此，我们披露了源代码和预训练的PyTorch[19]和scikit
learn[25]模型，并为我们的模型提供了类似scikit
learn[20]的API，遵循机器学习对象广泛采用的接口。据我们所知，我们是安全研究社区中第一个发布基于（a）上下文、（b）静态和（c）PE文件动态属性的单一决策启发的模型。</p>
<p>模型训练三个月后，我们收集了一个样本外数据集。我们承认，与任何单独的方法能力相比，基于软件混合表示的恶意软件分类可以提高检测性能，降低针对恶意逻辑不断演变的误报率</p>
<p><strong>仿真器不需要调动成熟的操作系统操作，因为它们允许以合理的速度获取大量遥测数据，而不需要虚拟化基础设施</strong>。因此，利用仿真器作为ML模型的遥测源进行动态恶意软件分析研究很有前景，但尚未普遍采用。据我们所知，Athiwaratkun和Stokes在2017年首次报告了系统调用收集的仿真器利用率[4]。他们的模型类似于自然语言处理（NLP）中使用的递归方案。Agrawal等人[2]进一步发展了这项工作，他们提出了一种类似的架构，用于在仿真器的帮助下获取的任意长API调用序列。Mandiant的数据科学团队通过基于仿真的动态分析进行了有前景的研究。具体而言，Li等人[16]提供了一个扩展摘要，报告了仿真器[18]在与我们的架构类似的混合分析中的使用情况</p>
<p>基于仿真的行为分析工作的稀疏性是由于它们的局限性。仿真是在模拟器运行的操作系统之上的抽象，不会与硬件发生直接交互。理论上，完美的仿真器可以欺骗任何系统调用背后的逻辑。尽管如此，像Windows
N这样的内核并没有集成大量的功能，从而实现了难以置信的一对一复制。我们在第3.2节中报告了与相关的基于虚拟化的工作数据集的详细错误率和数据多样性比较。根据经验证据，我们认为现代Windows内核仿真在ML恶意软件检测器中具有巨大潜力。仿真报告生成丰富多样的遥测，绕过静态分析限制。它包含可执行文件调用的一系列内核API调用，并描述对文件或注册表项的操作以及尝试的网络通信。</p>
<p><strong>例如，我们在训练和验证数据集报告中获取了2822个唯一的API调用</strong>。与相关工作数据集相比，这种行为的异构性明显更高-Athiwaratkun和Stokes[4]总共有114个独特的API调用，Kolosnjaji等人[14]报告了60个独特的API调用，Yen等人[33]有286个不同的API调用。<strong>Rosenberg等人[23]有314个单独的API调用</strong>。由于独特调用的数量与样本数量正相关，因此我们的数据集的较大容量可以部分地描述这种观察。然而，我们强调这是仿真技术效率的证据。仿真报告生成丰富多样的遥测数据，其质量相当于用于动态分析目的的沙箱。</p>
<h3><span id="三-数据集">三、数据集</span></h3>
<p>本工作中提出的混合解决方案的功能基于输入数据，包括（a）适用于动态分析的武装PE文件和（b）上下文文件路径信息。获取上下文数据的必要性导致无法利用公共数据收集，因为对于每个数据样本，我们都需要拥有原始PE字节和文件路径数据。</p>
<p>据我们所知，所有已知数据集均未提供文件执行时具有文件路径值的PE样本的上下文信息。例如，Kyadige和Rudd等人[15]依赖专有的Sophos威胁情报源，不公开发布其数据集。上下文数据的私有性质是可以理解的，因为这种遥测将包含敏感组件，如个人计算机上的目录。</p>
<p>因此，我们与一家未公开的安全供应商合作，收集了大量数据集，其中包含原始PE文件和来自个人客户系统的样本文件路径，类似于最新的威胁场景。根据所有客户接受的隐私政策处理数据。因此，我们不会公开发布文件路径和原始PE数据集。敏感数据组件（如用户名或自定义环境变量）来自预处理阶段的遥测，在模型参数或仿真报告中没有相似之处。</p>
<h4><span id="31-数据集结构">3.1 数据集结构</span></h4>
<p>我们分两次收集数据集。第一部分构成了我们分析的基础，包括98966个样本，329GB的原始PE字节。80%的语料库被用作固定的训练集，20%形成样本内验证集。我们使用这些数据对模型进行预训练，并研究我们的混合解决方案配置。</p>
<p>第二次数据集采集会议发生在三个月后，从27500个样本（约100GB的数据）形成了样本外测试集。该语料库用于评估混合模型的实际效用，并研究模型在进化的恶意景观上的行为。</p>
<p>数据集中的PE文件由专业威胁情报团队标记，利用恶意软件分析师操作的手动和自动逆向工程工具。数据集涵盖七个恶意软件家族和benignware，详细分布参数如表1所示。除“干净”外，所有标签均表示恶意文件。因此，我们收集了相对更多的“干净”样本，以平衡数据集中的恶意和良性标签。</p>
<p>由于大多数恶意软件被编译为x86二进制文件，因此我们关注32位（x86）图像，并有意跳过64位（x64）图像的集合，以保持数据集的同质性和标签平衡。此外，恶意软件作者更喜欢x86二进制文件，因为Microsoft向后兼容性允许在64位系统上执行32位二进制文件，但反之亦然。数据集由可执行文件（.exe）组成，我们有意省略库PE文件（.dll）。</p>
<h4><span id="32-样本评估">3.2 样本评估</span></h4>
<p>表1中表示的所有示例都是用Windows内核仿真器处理的。我们使用Mandiant根据MI
T许可证发布并积极维护的Speakeasy[18]基于Python的仿真器。我们测试中使用的Speakeasy版本是1.5.9。它依赖于QEMU[6]CPU仿真框架。我们获得了108204个成功的仿真报告，每个报告的平均运行时间为<strong>12.23秒</strong>，仿真了来自训练和验证集的90857个样本，以及测试集中的17347个样本。</p>
<p>不幸的是，一些示例模拟是错误的，主要是由于写入汇编指令的无效内存读取。然而，模拟错误的另一个常见原因是<strong>调用了不受支持的API函数或反调试技术</strong>。图1显示了不同恶意软件系列的错误率。</p>
<p>据推测，模拟数据集的一个潜在缺点可能是，<strong>与沙箱中实时执行样本相比，其相对稀疏</strong>。然而，经验证据表明，我们的数据集比使用全Windows系统虚拟化执行类似数据采集的其他组报告的数据更为多样。<strong>例如，我们在训练和验证数据集报告中获得2822个唯一的API调用。</strong>与相关工作数据集相比，这种行为的异构性明显更高-Athiwaratkun和Stokes[4]总共有114个独特的API调用，Kolosnjaji等人[14]报告了60个独特的API调用，Yen等人[33]有286个不同的API调用。<strong>Rosenberg等人[23]有314个单独的API调用</strong>。这种观察部分可以通过我们数据集的更大容量来描述，因为唯一调用的数量与样本数量正相关。然而，我们强调这是仿真技术效率的证据。仿真报告生成丰富多样的遥测数据，其质量相当于用于动态分析目的的沙箱。</p>
<h3><span id="四-系统结构">四、系统结构</span></h3>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191552651.png" alt="image-20220918180837521" style="zoom:50%;"></p>
<p>图2显示了混合模型体系结构的总体概述𝜙,
它们被“融合”在一起，由元模型生成最终决策𝜓. 三种早期融合模型𝜙 是：</p>
<ul>
<li>file-path 1D convolutional neural network (CNN), 𝜙𝑓𝑝</li>
<li>emulated API call sequence 1D CNN, 𝜙𝑎𝑝𝑖</li>
<li>FFNN model processing Ember feature vector, 𝜙𝑒𝑚𝑏</li>
</ul>
<p>每个子模型从输入数据获取的128维表示向量。此外，所有三个模型的输出连接在一起形成384维向量。因此，给定输入样本𝑥,
由原始PE（字节）及其文件路径（字符串）组成，早期融合过程统称为：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191552576.png" alt="image-20220918180145232" style="zoom:50%;"></p>
<p>中间向量𝜙 (𝑥) 传递给元模型𝜓, 其产生最终预测：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191552409.png" alt="image-20220918180255048" style="zoom:50%;"></p>
<p><strong>所有早期融合网络都是单独预训练的</strong>，在第4.3节中详细定义了模型配置和训练过程。我们想强调，构建具有多个单独预训练组件的模块化系统而不是构建单个端到端可训练架构的决策是经过深思熟虑的。首先，Yang等人[32]表明，具有高概率的复合神经网络优于单个预训练组件的性能。</p>
<p><strong>「
然而，主要原因是通过仅重新训练元模型，扩展具有互补模块的混合决策启发式的巨大潜力」</strong>。恶意活动分类问题依赖于原始PE字节以外的高度异构的信息源，这种体系结构保留了添加依赖于系统日志记录的启发式的能力。在本次发布之时，我们已经合并了文件路径信息，例如可以从<strong>Sysmon2</strong>遥测中获取。然而，可以进一步提取Sysmon数据或<strong>Speakeasy</strong>报告中的知识。</p>
<h4><span id="41-api-调用处理">4.1 API 调用处理</span></h4>
<blockquote>
<p><strong>Json_normalize</strong>：json to pandas</p>
</blockquote>
<p>为了获取API调用序列的数值，我们根据可变词汇表大小选择最常见的调用𝑉 .
保留的API调用是标签编码的，不属于词汇表的调用将替换为专用标签。使用填充标签将最终序列截断或填充到固定长度𝑁.</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191552244.png" alt="image-20220918181408143" style="zoom:50%;"></p>
<p>表2显示了数据集多样性和各自模型性能背后的统计数据。尽管100个最常见的调用在一个数据集中包含95%以上的API调用，<strong>但实验表明该模型仍然受益于相对较大的词汇表大小值，因此我们选择𝑉
=
600用于我们的最终配置。</strong>这种现象可以通过每个样本的API调用分布来解释。具有数百个调用的冗长可执行文件会影响系统调用频率，而具有适度API序列的可执行文件则执行更独特的函数组合。</p>
<h4><span id="42-路径处理">4.2 路径处理</span></h4>
<p>路径预处理的第一部分包括<strong>路径规范化</strong>，因为文件路径语义的某些部分具有与通过深度学习模型进行的安全分析无关的可变性。如果使用<strong>通用命名约定（UNC）格式</strong>，则包括特定的<strong>驱动器号或网络位置</strong>，以及单个用户名。因此，在规范化过程中，我们为这些<strong>路径组件引入了通用占位符</strong>，如下所示：</p>
<blockquote>
<p>[drive][user]\04-ca\8853.vbs [drive][user].tmp [net]2021.xlsm</p>
</blockquote>
<p>此外，有必要分析Windows环境变量，使其类似于实际的文件路径，而不是用作变量名的环境别名。因此，<strong>我们构建了一个由大约30个环境变量组成的变量映射</strong>，这些变量表示系统上的特定路径，并在当代和传统Windows系统中使用。变量映射的一些示例如下所示:</p>
<blockquote>
<p>r"%systemdrive%": r"[drive]", r"%systemroot%": r"[drive]",
r"%userprofile%": r"[drive][user]"</p>
</blockquote>
<p><strong>分别使用100和150个最频繁的UTF-8字节。频率阈值以下的罕见字符将被丢弃，并由单个专用标签替换。</strong></p>
<h4><span id="43-早期融合模型架构">4.3 早期融合模型架构</span></h4>
<p>如第3节所述，我们不能依赖于公开发布的恶意软件集合，因为该模型在执行时需要文件路径形式的上下文信息，而这些信息不是公开的。因此，与现有研究相比，为了保持评估模型性能的能力，我们只能依赖其他研究小组发布的带有预训练参数的恶意软件分类模型，并进一步评估我们数据集上的模型。不幸的是，没有任何混合或动态分析出版物[14、17、23、27、33]提供这样的伪影。</p>
<p>幸运的是，多个静态分析出版物伴随着代码库形式的工件[3，21，24]。例如，可以直接使用Ember
LightGBM[12]模型，该模型是在Endgame3于2019年发布的Ember数据集[3]上预训练的。<strong>然而，我们不将该模型包括在我们的复合解决方案中，因为决策树模型不学习元模型可以使用的表示，只提供标量形式的最终预测。</strong>我们仍然依赖Ember特征提取方案[3]，但使用Rudd等人[24]发布的FFNN，分别具有三个隐藏层或512、512和128个隐藏神经元，均使用ELU[9]非线性，具有层归一化[5]和丢失率[30]𝑝
=
0.05。我们在来自Ember训练集[3]的600k个特征向量和来自我们训练集的72k个样本上重新训练了200个周期的FFNN。</p>
<p><strong>「
文件路径和API调用序列的分析可以被表述为相关的优化问题，即一维（1D）序列的分类
」</strong>。我们在受Kyadige和Rudd等人[15]影响的两种模型中使用了类似的神经结构，即嵌入层，具有用于表示提取的一维卷积神经网络（CNN）和完全连接的神经网络学习分类器功能。我们知道，有多种选择可以用交替结构（如递归神经网络（RNN）[8，10]）来建模序列分类问题。<strong>然而，如API调用序列分类的相关工作所示，两种模型体系结构都报告了类似的性能[14，23]，但表明1D
CNN的计算要求明显降低[34]。</strong></p>
<p>编码输入向量𝑥 定长𝑁 为嵌入层提供尺寸𝐻 词汇量𝑉 .
这些参数受到超参数优化的影响。通过验证集上的超参数优化获得的<strong>文件路径模型</strong>的最佳值为：输入向量𝑥𝑓𝑝
长𝑁 = 100，嵌入维数𝐻 = 64、词汇量𝑉 =
150.模拟<strong>API调用序列模型</strong>的相应值为：输入向量𝑥𝑒𝑚 长𝑁 =
150，嵌入尺寸𝐻 = 96和词汇量𝑉 =
600.<strong>文件路径模型的词汇表由最常见的UTF-8字节形成，对于API调用序列模型，选择最常见的系统调用</strong>。<strong>两个词汇表都有两个用于填充和稀有字符的标签</strong>。<strong>「
嵌入层的输出被传递到四个单独的1D 卷积层
」</strong>，内核大小为2、3、4和5个字符，输出通道的数量𝐶 = 128.带较低𝐶
价值模型表现不佳。例如𝐶 = 64文件路径的模块验证集F1分数低至0.962，而𝐶 ∈
{100，128，160}得分在0.966左右。</p>
<p>所有四个卷积层的输出连接到大小为 4×𝐶
并传递到具有四个隐藏层的FFNN，其中包含1024、512、256和128个神经元。FFNN的隐藏层使用整流线性单元（ReLU）[1]激活。最后一层使用S形激活。在ReLU激活之前，将批量归一化[11]应用于FFNN的隐藏层。此外，为了防止过度装配，使用
𝑝 = 0.5的速率。</p>
<p>使用二进制交叉熵损失函数拟合所有早期融合网络：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191552850.png" alt="image-20220918183415081" style="zoom:50%;"></p>
<p>𝜙 (𝑥; 𝜃) 表示由深度学习模型给定参数近似的函数𝜃, 和𝑦 ∈
｛0，1｝是地面真相标签。使用Adam优化器[13]进行优化，学习率为0.001，批量大小为1024个样本。<strong>我们使用PyTorch[19]深度学习库构建了一维卷积网络、EMBER
FFNN和训练例程</strong>。</p>
<h4><span id="44-元模型">4.4 元模型</span></h4>
<p>早期融合模型的输出𝜙 (𝑥) 用于训练元模型𝜓.
<strong>评估了三种不同的架构类型，使用scikit学习库[20]实现了逻辑回归和FFNN，并基于xgboost[7]实现了梯度提升决策树分类器</strong>。</p>
<p>自元模型𝜓 执行相对复杂的非线性映射 [0，1]^384→
[0，1]，基于表3中的性能指标，我们得出结论，融合的分类表面不平滑，并呈现了利用所有三种特征提取方法的表示进行最终决策的组合，而逻辑回归等简单模型无法学习。<strong>我们选择具有384、128、64和16个神经元的四层FFNN作为最终评估的元模型，因为它具有接近最佳的分数。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191552051.png" alt="image-20220918183736944" style="zoom:50%;"></p>
<h3><span id="五-实验结果">五、实验结果</span></h3>
<p>实验表明，同时利用静态、动态和上下文信息的检测率明显高于单个模型的性能，特别是在<strong>低误报要求下</strong>。这种需求通常表达为安全行业中的机器学习解决方案。不符合低误报需求的解决方案通常不允许为人类分析师生成警报[22]。图3显示了样本外测试集给定固定假阳性率（FPR）的检测率（%）。</p>
<p>在100000个案例中，在FPR仅为100个错误分类的情况下设置警报阈值，Ember
FFNN、filepath和仿真模型的个体模型检测率分别为56.86%、33.31%和33.89%。
<strong>然而，通过结合从所有三种处理技术中学习到的表示，混合解决方案可以从训练三个月后收集的测试集中的所有样本中正确分类86.28%。</strong></p>
<p>令人惊讶的观察结果产生了文件路径和仿真模型。两种模型各自表现相对较差，尤其是与余烬FFNN相比。这一观察结果背后的一个潜在解释是由原始ember出版物[3]中的600k个特征向量组成的ember
FFNN训练集。这种训练语料库比我们的100k样本更好地概括了“真实”恶意PE分布，反映了特定时间窗口中的威胁情况。</p>
<p>然而，在低误报要求下，仅文件路径和仿真模型的组合，忽略静态分析，优于在更广泛的数据集上训练的最先进的余烬特征提取方案，在10000个样本中的一个样本的FPR下，检测率为77.36%对55.86%。</p>
<p>此外，将这两种模型结合在一起会导致检测率高于单个模型的累积能力，从而更加突出了混合元模型相对于狭义解决方案的优势。例如，虽然单个文件路径和仿真模型在105个错误警报的FPR中仅检测到33.31%和10.24%的样本，但它们的组合产生了77.36%的检测率。</p>
<p><strong>这一观察结果适用于从不同系统和不同时间框架收集的样本内验证和样本外测试集</strong>，使我们能够得出结论，这是具有元模型的混合检测启发式的一般属性，而不是特定数据集的伪影。对于文件路径、仿真和组合启发式，在105种情况下，给定一次错误分类的样本内验证集的值分别为34.46%、13.52%和97.25%</p>
<p>这一观察结果可以得出结论，元模型可以学习不同分析技术产生的恶意样本表示外组合的典型模式，例如组合特定的API调用序列和Trizna文件路径n-gram。这些表示中的每一个单独产生的证据都不足以将样本归类为恶意，因为它也发生在良性应用中。因此，只有当良性和恶意样本都被标记时，检测才会解除假阳性要求。然而，来自文件路径和API调用的表示的组合允许元模型在384维空间中构建决策边界以隔离此类情况，从而产生超过40%的检测率。</p>
<p>因此，我们看到，静态、动态和上下文数据的综合利用解决了独立方法的弱点，允许最小化FPR和假阴性率（FNR）。
表4中报告了所有集合的F1得分、精确度、召回率、精确度和AUC得分，<strong>元模型决策阈值为0.98，类似于FPR≈
验证集为0.25%</strong>。虽然样本</p>
<p><strong>内验证集的报告结果允许得出模型几乎没有过度拟合的结论，但我们仍然观察到样本外测试集F1和AUC得分下降了≈
4.− 4.5%.
尽管恶意软件家族的比例相同，但检测分数仍会下降，我们认为这种现象的因果关系源自恶意逻辑的进化本质。</strong></p>
<h3><span id="六-结论">六、结论</span></h3>
<p>我们已经证明，ML算法受益于混合分析，从而提高了性能，特别是在低误报要求下。我们确实报告了基于余烬特征向量[3]的当前最先进的恶意软件建模方案的异常性能，该方案报告的检测率明显高于单独的文件路径或仿真模型，如图3所示。然而，将余烬模型与文件路径或模拟或两种模型相结合，可以显著提高检测能力，在某些情况下，如低误报要求，几乎30%。</p>
<p>此外，我们报告说，混合解决方案可以检测恶意样本，即使没有一个单独的组件表示足够的信心来将输入分类为恶意。例如，对于100000个错误分类案例的FPR，单个文件路径和仿真模型仅检测到33.31%和10.24%的样本。它们的组合产生77.36%的检测率，如果两个模型一起使用但独立使用，则检测能力提高了40%以上。</p>
<p>我们得出结论，<strong>元模型</strong>可以从不同分析技术产生的表示组合中学习恶意样本的典型模式。此外，这一结论得到了数据集大小的支持，数据集大小明显大于行为恶意软件分析的相关工作。</p>
<p>我们认为，动态和语境分析的积极特征可以进一步扩展。虽然我们用API调用序列表示系统上的PE行为，<strong>但并非所有可执行功能都是通过API调用表示的</strong>。==<strong>额外的可见性源对于最小化模型决策启发式中的模糊性可能至关重要，我们认为扩展组合解决方案的模块性是一个有前途的研究方向。我们的分析中省略了大部分仿真遥测。</strong>==</p>
<p>我们公开发布了108204个样本的模拟报告，并期望在这方面进一步开展工作。<strong>文件系统和注册表修改、网络连接和内存分配可能为检测提供关键信息。</strong>我们解决方案的架构允许我们通过只重新训练<strong>元模型</strong>的参数，以最小的努力扩展决策启发式的模块性。</p>
<h2><span id="代码结构">代码结构</span></h2>
<blockquote>
<p>data/</p>
<ul>
<li><p>adversarial.emulated</p></li>
<li><p>emulation.dataset</p></li>
<li><p>path.dataset</p></li>
<li><p>pe.dataset</p></li>
<li><p>train_val_test_sets</p></li>
</ul>
<p>evaluation/【评估】</p>
<p>img/【图片】</p>
<p>modules/【模型保存】</p>
<p>preprocessing/【数据预处理】</p>
<ul>
<li>arrary</li>
</ul>
<p>utils/</p>
<p>models.py 【模型结构】【CompositeClassifier 类】</p>
<p>example.py 【代码样例】</p>
</blockquote>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（12）Neurlux: Dynamic Malware Analysis Without Feature Engineering</title>
    <url>/posts/1EB7867/</url>
    <content><![CDATA[<h2><span id="neurluxdynamic-malware-analysis-without-feature-engineering">Neurlux:
Dynamic Malware Analysis Without Feature Engineering</span></h2>
<blockquote>
<ul>
<li>论文：https://dl.acm.org/doi/10.1145/3359789.3359835#:~:text=Neurlux%20does%20not%20rely%20on%20any%20feature%20engineering%2C,report%20is%20from%20a%20malicious%20binary%20or%20not.</li>
<li>项目：https://github.com/ucsb-seclab/Neurlux</li>
</ul>
</blockquote>
<h3><span id="摘要">摘要</span></h3>
<p>恶意软件检测在计算机安全中起着至关重要的作用。现代机器学习方法一直以提取恶意特征的领域知识为中心。然而，可以使用许多潜在的功能，手动识别最佳功能既耗时又困难，特别是考虑到恶意软件的多样性。在<strong>本文中，我们提出了Neurlux，一种用于恶意软件检测的神经网络。Neurlux不依赖任何特征工程，而是从详细描述行为信息的动态分析报告中自动学习。我们的模型借鉴了文档分类领域的思想，使用报告中的单词序列来预测报告是否来自恶意二进制文件。我</strong>们调查了我们模型的学习特征，并显示了它倾向于给予报告的哪些组成部分最高的重要性。然后，我们在两种不同的数据集和报告格式上评估了我们的方法，表明Neurlux改进了现有技术，可以有效地从动态分析报告中学习。此外，我们还表明，我们的方法可移植到其他恶意软件分析环境，并可推广到不同的数据集。</p>
<h3><span id="说明">说明</span></h3>
<p>随着恶意软件变得越来越复杂，恶意软件分析也需要不断发展。传统上，大多数反恶意软件使用基于签名的检测，将可执行文件与已知恶意软件签名列表进行交叉引用。然而，这种方法有局限性，因为对恶意软件的任何更改都可能更改签名，因此同一恶意软件的新版本通常可以通过加密、混淆、打包或重新编译原始样本来逃避基于签名的检测。VirusTotal报告称，每天分析超过68万个新样本[40]，其中可能有相当多的样本只是之前看到的样本的重新打包版本，正如Brosch等人[3]观察到的那样。超过50%的新恶意软件只是现有恶意软件的重新打包版本。</p>
<p>近年来，由于需要将技术推广到以前看不见的恶意软件样本，因此产生了利用机器学习技术的检测方法[25，26，38]。恶意软件分析可以大致分为两类：代码（静态）分析和行为（动态）分析。静态分析和动态分析都有其优点和缺点。尽管动态分析提供了可执行行为的清晰画面，但它在实践中面临着一些问题。例如，对不可信代码的动态分析需要一个复制目标主机的虚拟机，这需要大量的计算资源。此外，恶意软件可能不会表现出其恶意行为，或者虚拟化环境可能不会反映恶意软件所针对的环境[5，15，27，30]。为了避免这些限制，一些相关工作仅依赖于从静态分析中提取的特征来实现对大量恶意软件样本的快速检测。然而，可以采用各种加密和混淆技术来阻碍静态分析[19，24]。这对静态恶意软件检测器来说是一个更严重的问题，因为包装在今天的良性样本中也被广泛使用。样本[28]。尽管动态分析被证明容易受到规避技术的影响，但运行时行为很难混淆。动态分析二进制文件可以解包并记录其与操作系统的交互，这是恶意软件分析的一个有吸引力的选择。</p>
<p>无论使用静态分析还是动态分析，大多数基于机器学习的恶意软件检测器都严重依赖于相关的领域知识[12，13，34]。这些方法通常依赖于恶意软件专家手动调查的功能，这需要大量的功能工程。例如，Kolbitsch等人[13]捕获了PE可执行程序在为此目的设计的特定功能中的行为图。恶意软件不断被创建、更新和更改，这可能会使最初精心设计的功能不适用于较新的恶意软件或不同的恶意软件家族。在这种情况下，必须不断完善成本高昂的特征工程工作。因此，找到一种降低人工特征工程成本的方法来从原始数据中提取有用的信息是至关重要的。</p>
<p>最近有一些关于基于深度学习的恶意软件分类的工作，这不需要特征工程。然而，现有的深度学习方法并没有利用来自现有动态分析系统的信息，而是倾向于选择一种类型的动态特征[14]或使用静态特征[6]。这些解决方案遗漏了关于每个样本所采取的行动的完整信息。</p>
<p>在本文中，我们提出了Neurlux，这是一个使用神经网络分析动态分析报告的系统。Cuckoo[21]等服务通过在沙盒中跟踪可执行文件来提供对可执行文件的详细动态分析。此分析包含诸如网络活动、注册表更改、文件操作等信息。我们使用这些报告作为分析的基础。也就是说，给定一个动态分析报告，我们希望能够预测该报告是针对恶意软件样本还是良性可执行文件。</p>
<p>我们的直觉是，我们可以将这些报告视为文件。凭借这种直觉，我们提出了Neurlux，这是一种神经网络，它在不需要任何特征工程的情况下学习并操作（清洁的）动态分析报告。Neurlux借用了文档分类领域的概念，将报告视为一系列单词，这些单词构成了一系列句子，从而创建了一个有用的模型。Neurlux打算用学习这些行为伪像或启发式的神经网络来取代昂贵的手工启发式。</p>
<p>为了检查我们的方法是否偏向于特定的报告格式（即沙盒），我们在评估中包括了两个不同的沙盒，即杜鹃沙盒[21]、杜鹃沙盒和一个商业反恶意软件供应商的沙盒（我们将其称为VendorSandbox）。此外，我们使用了两个不同的数据集，一个由商业反恶意软件供应商VendorDataset提供，另一个是标记的基准数据集EMBER[2]EmberDataset。</p>
<p>为了证明Neurlux比特征工程方法做得更好，我们实现了三种这样的技术，并与稍后讨论的技术进行了比较。此外，我们实现并比较了由Karbab等人[11]提出的MalDy模型作为基线。MalDy将行为（动态）报告形式化为一个单词袋（BoW），其中特征是报告中的单词。总之，我们做出了以下贡献：</p>
<ul>
<li>我们提出了Neurlux，这是一种利用文档分类概念来检测恶意软件的方法，该方法基于沙箱生成的行为（动态）报告，而无需进行功能工程。唯一的预处理步骤是清理报告以提取单词，在此基础上，我们的模型学习相关的单词序列，这有助于其预测。Neurlux在我们的K倍验证中显示出高准确度，达到96.8%的测试准确度。</li>
<li>我们在动态分析报告中创建并测试了几种恶意软件分类方法，包括新方法，如集成功能的堆叠集合和功能计数模型。我们与这些方法进行了比较，表明Neurlux优于特征工程方法。</li>
<li>我们通过在新的数据集和新的报告格式（即由新的沙盒生成）中测试Neurlux来评估其泛化能力，并表明它的泛化能力比我们评估的方法更好。</li>
<li>可执行文件的源代码和数据集将在github上发布。</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（13）Dynamic Malware Analysis</title>
    <url>/posts/GW7NEC/</url>
    <content><![CDATA[<h2><span id="dynamicmalware-analysis-in-the-modern-eraa-state-of-the-art-survey">Dynamic
Malware Analysis in the Modern Era—A State of the Art Survey</span></h2>
<p>​
本次调查的目的是对用于动态分析恶意软件的现有方法进行全面和最新的概述，其中包括对每种方法的<strong>描述</strong>、其<strong>优缺点</strong>以及对<strong>恶意软件规避技术的适应性</strong>。此外，我们还概述了利用机器学习方法来增强动态恶意软件分析能力的一些重要研究，这些研究旨在检测、分类和分类。</p>
<h4><span id="学习内容">学习内容：</span></h4>
<ul>
<li>分析方法：<strong>易失性内存取证（volatile memory
forensics）、侧通道分析（side-channel analysis）</strong></li>
</ul>
<h4><span id="动态分析的意义">动态分析的意义：</span></h4>
<ol type="1">
<li>虽然恶意软件编写者可以使用各种技术（如代码混淆、动态代码加载、加密和打包）来逃避静态分析（包括基于签名的防病毒工具）态分析对这些技术是健壮的，并且可以提供关于所分析文件的更多理解，因此可以导致更好的检测能力。</li>
</ol>
<h4><span id="动态分析的局限性">动态分析的局限性：</span></h4>
<ul>
<li>只有执行的代码是可观察的。这意味着，如果没有精确地满足所需的条件，那么某些代码可能无法执行，从而无法进行分析。<strong>Deeplocker</strong></li>
<li>动态分析还需要计算开销，这可能会降低执行速度。</li>
<li>分析必须在恶意软件针对的特定操作系统和/或硬件上执行。</li>
</ul>
<h4><span id="说明">说明：</span></h4>
<ul>
<li>物联网设备是另一个可以受益于内存分析的平台示例，因为基于软件的新检测机制的设计和安装并不简单。此外，由于物联网设备具有有限的计算资源，现有的动态分析技术对于此类设备可能不太相关或有效。</li>
</ul>
<h4><span id="恶意软件分类">恶意软件分类</span></h4>
<ul>
<li>Classification of Malware by Type</li>
<li>Classification of Malware by Malicious Behavior</li>
<li>Classification of Malware by Privilege</li>
<li>About Behavior and Privilege</li>
</ul>
<h4><span id="analyzing-malware-behavior">ANALYZING MALWARE BEHAVIOR</span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191623702.png" alt="image-20210529200406017">
<figcaption aria-hidden="true">image-20210529200406017</figcaption>
</figure>
<h4><span id="动态恶意软件分析框架描述">动态恶意软件分析框架描述</span></h4>
<h4><span id="分析技术和学术工具">分析技术和学术工具</span></h4>
<ul>
<li><h5><span id="函数功能分析">函数功能分析</span></h5>
<ul>
<li>每个进程都依赖函数调用来执行其职责，不管这些函数是进程内部的还是外部的（例如，由其他进程导出的函数、系统调用）。通过跟踪恶意软件调用的各种函数以及与这些函数相关的参数，可以更好地了解所分析恶意软件的行为。调用函数时获取通知可以通过将一段代码<strong>Hooking</strong>到该函数来实现。
<ul>
<li>hooking mechanism</li>
<li>code injection</li>
</ul></li>
<li><strong>TTAnalyze(LastLine)</strong>是一个分析工具，它用一个称为Inside
the
Matrix（insideetm）的客户机组件扩展了QEMU仿真器，该组件将虚拟地址转换为物理地址。</li>
<li><strong>CWSandbox</strong>基于将可信DLL的代码注入到分析的进程中，该进程通过覆盖导出地址表（EAT）中的条目并将执行重定向到CWSandbox来拦截函数调用。CWSandbox收集大量的信息（比如被调用函数的名称、参数、系统状态等），然后将这些信息呈现给用户。</li>
<li><strong>Capture</strong>使用三个监视器分析操作系统的状态：<strong>文件系统监视器</strong>（跟踪所有硬盘上的读/写事件）、<strong>注册表监视器</strong>（跟踪多个注册表事件，如OpenKey、CreateKey等）和<strong>进程监视器</strong>（跟踪进程的创建和终止）。所有监视器都提供其他数据，如触发事件的进程、完整路径和时间戳。使用内核驱动程序，捕获与上述每个监视器对应的内核事件。最终结果是恶意软件触发的事件列表，以及它们的时间戳和参数。</li>
<li><strong>MalTRAK</strong>是一个跟踪恶意软件行为并扭转其影响的框架。它使用内核模式组件并将自身与关键函数挂钩，以跟踪恶意软件的操作，同时提供撤消这些操作的机制。</li>
<li><strong>dAnubis</strong>是用来分析内核驱动程序和检测rootkit的。它使用一个in-guest组件来监视rootkit和系统其余部分之间的通信。触发器引擎调用各种windowsapi调用来显示<strong>rootkit（定义为一组在恶意软件中获得root访问权限、完全控制目标操作系统和其底层硬件的技术编码）</strong>的存在（例如，隐藏的进程或文件）。</li>
</ul></li>
<li><h5><span id="execution-control-执行控制">Execution Control 执行控制</span></h5>
<p>动态恶意软件分析应该包含一种机制，偶尔停止恶意软件的执行，并检查恶意进程和操作系统的状态。执行控制技术包括：</p>
<ul>
<li><strong>Debugging</strong>调试（也称为单步）是一种可靠的分析技术，最初是为了帮助程序员发现代码中的错误而开发的。使用CPU的陷阱标志在每个操作码指令后生成中断，调试器可以允许恶意软件在强制上下文切换回分析进程之前只运行一条操作码指令，然后分析进程可以检查恶意软件和操作系统的状态。</li>
<li>等</li>
</ul></li>
<li><p><strong>Flow Tracking 流量跟踪</strong></p>
<p>细粒度分析用于跟踪通过恶意软件执行代码的信息流（例如，当一个函数的结果用作调用另一个函数的参数时）。</p>
<ul>
<li><strong>Data Tainting</strong></li>
<li><strong>Vigilite</strong>是一种分析工具，它使用二进制工具实现数据污染。最初是为了检测和阻止蠕虫的传播而开发的，Vigilite寻找来自网络的受污染数据的执行。因此，污点源是网络，当指令指针（IP）指向污点数据时，污点接收器就到达了，这意味着一些来自网络的不可信代码正在被执行。</li>
<li><strong>Panorama</strong>最初是一个TEMU插件，用于对各种I/O设备（包括硬盘、键盘或鼠标）进行污染分析。后来成为一个独立的平台。全景图的输出是以图形的形式提供的，它允许用户跟踪进程和内存区域之间的数据流。</li>
<li><strong>Dytan</strong>是Pin仪器系统的一个扩展，为数据污染提供了一个易于使用的API。它的开发采用了灵活的设计，允许用户配置各种组件，如污染源、污染汇、数据流跟踪器和控制流跟踪器。Dytan可以配置为跟踪显式和隐式信息流。此外，它的功能可以通过使用回调函数来扩展，回调函数实现额外的污染源、标签、传播和接收器。</li>
<li><strong>TQana</strong>是一个构建在QEMU之上的框架，用于分析和检测安装在internetexplorer上的恶意浏览器扩展。它使用带有两个污点源的数据污点：（1）用户访问的页面的所有URL字符串和（2）浏览器收到的响应其请求的信息。污点接收器是文件系统、注册表和网络。当受污染的数据被写入文件或通过网络发送时，被分析的样本就被怀疑是间谍软件。</li>
</ul></li>
<li><p><strong>Tracing 追踪</strong></p>
<p>收集执行某些代码后留下的信息称为跟踪。网络连接和分配给恶意软件的内存会留下恶意软件行为的痕迹。分析这些痕迹可以提供有关恶意软件的见解，而无需使用客户端组件中的。</p>
<ul>
<li><strong>Volatile memory analysis
易失性内存分析分析</strong>从内存转储文件分析恶意软件的影响（见第6.5节）需要了解操作系统如何跟踪进程、文件、用户和配置。所有这些数据结构都以二进制形式存在于内存转储中。</li>
<li><strong>Network Tracing</strong>
网络跟踪由于恶意软件在大多数情况下需要连接Internet才能执行其操作，因此在没有Internet访问的情况下，可能无法显示恶意软件的确切性质。然而，允许恶意软件完全访问互联网有时是不可取或不可能的。通过恶意软件限制网络访问并分析网络连接可以揭示恶意软件的C&amp;C和从中收到的命令。恶意软件留下的网络痕迹有助于理解其呈现的通信模式。</li>
<li><strong>HookFinder</strong>是TEMU实现的另一部分，旨在通过分析易失性内存来检测和分析恶意钩子。在堆栈中找到的信息被转换为创建钩子图，这有助于识别钩子链。然后，HookFinder将属于恶意软件的内存段标记为污点接收器。为了验证钩子实际上是由恶意软件安装的，HookFinder调用各种函数调用，并通过检查指令指针（IP）来跟踪控制流。当IP指向受污染的内存时，恶意钩子就会被发现并验证。</li>
<li><strong>LiveDM</strong>利用QEMU来分析内核中新内存区域的分配。通过挂接操作系统实现的几个内存分配函数，它可以跟踪恶意软件的安装位置，并对恶意软件的二进制代码执行静态分析。使用模拟器对客户操作系统的控制，LiveDM能够获得客户操作系统的易失性内存并分析受感染的内核。</li>
<li>等</li>
</ul></li>
<li><p><strong>Side-channel Analysis</strong></p>
<ul>
<li>到目前为止提出的分析技术依赖于从操作系统、易失性存储器或仿真机器的状态中提取数据。然而，任何类型的计算设备都可能成为恶意软件的攻击目标。这些设备包括PCI卡、物联网设备、硬盘、医疗设备等。分析和检测这些设备上运行的恶意软件是困难的，因为大多数情况下，这些设备不包含一个操作系统，可以支持传统的分析技术。与从操作系统的角度（或二进制级别）跟踪系统的行为不同，<strong>可以通过物理组件的功耗、电磁辐射或内部CPU事件来分析它们的行为</strong>。获取的数据分为“正常行为”和“感染行为”。使用统计方法和机器学习算法，检测到偏离正常行为可能表明CPU行为异常（例如，存在cryptominer或rootkit）。侧通道分析无法提供有关操作系统、网络或正在修改的文件的内部事件的深入信息。没有向仅仅收到最终判决的用户提供报告（称为恶意或非恶意）。</li>
<li><strong>WattsUpDoc</strong>是一种分析工具，用于使用外部设备对医疗设备进行侧信道分析。它证明了侧通道分析可以用于分析没有操作系统的设备，而无需向分析的设备加载任何代码。</li>
</ul></li>
</ul>
<h4><span id="布局映射技术mappingtechniques-to-layouts">布局映射技术（MAPPING
TECHNIQUES TO LAYOUTS）</span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191624416.png" alt="image-20210531145449113">
<figcaption aria-hidden="true">image-20210531145449113</figcaption>
</figure>
<p>​
恶意软件和分析工具之间的战争是一场军备竞赛。攻击者不断开发新的方法来规避和检测分析框架，同时负责检测恶意软件的分析框架和工具的能力也在不断提高。创建图13是为了帮助读者理解这场军备竞赛以及<strong>攻击者和分析人员使用的不同方法</strong>。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191624015.png" alt="image-20210531150025715">
<figcaption aria-hidden="true">image-20210531150025715</figcaption>
</figure>
<h4><span id="综合比较研究">综合比较研究</span></h4>
<p>本部分比较了近年来动态恶意软件分析的研究，并讨论了与此相关的趋势和参数。进行此比较，我们可以发现一些重要的见解，我们也与读者分享。</p>
<ul>
<li><p>基于功能和实际方面的比较</p>
<ul>
<li><p>我们的比较基于以下几个关键方面：</p>
<p>（1）该工具的相关性（其对科学界的影响和贡献基于引文数量和是否开源），</p>
<p>（2）该工具提供的分析的多功能性，</p>
<p>（3）用于实现该工具的分析布局（见第6节），</p>
<p>（4）工具的限制（预分析要求、所依赖的附加软件、特殊要求的硬件）和</p>
<p>（5）工具提供的输出。请注意，这些工具是按分析技术分组的，在每种技术中，它们是按出版年份排序的。关于图14的详细说明如下：</p></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（1）SeqNet: An Efficient Neural Network for Automatic Malware Detection</title>
    <url>/posts/JFCMNX/</url>
    <content><![CDATA[<h2><span id="seqnetan-efficient-neural-network-for-automatic-malware-detection">SeqNet:
An Efficient Neural Network for Automatic Malware Detection</span></h2>
<ul>
<li>https://github.com/Darren-8/SeqNet.git.</li>
</ul>
<h3><span id="摘要">摘要</span></h3>
<p>恶意软件继续快速发展，每天捕获超过45万个新样本，这使得手动恶意软件分析变得不切实际。然而，现有的深度学习检测模型需要人工特征工程，或者需要很高的计算开销来进行长时间的训练，这可能会很难选择特征空间，并且很难再训练来缓解模型老化。因此，对探测器的一个关键要求是实现自动、高效的检测。在本文中，我们<strong>提出了一种轻量级的恶意软件检测模型SeqNet</strong>，该模型可以在原始二进制文件上以低内存进行高速训练。通过避免上下文混淆和减少语义丢失，SeqNet在将参数数量减少到仅136K时保持了检测精度。在我们的实验中，我们证明了我们的方法的有效性和SeqNet的低训练成本要求。此外，我们还公开了我们的数据集和代码，以促进进一步的学术研究。</p>
<h3><span id="一-说明">一、说明</span></h3>
<p>恶意软件是一种严重的网络安全威胁，可能会对个人和公司系统造成严重损害，例如，急剧减速或崩溃、严重数据丢失或泄漏，以及灾难性的硬件故障。<strong>AVTest报告称，平均每天检测到超过45万个新的恶意程序和可能不需要的应用程序</strong>。[1].
大量新的恶意软件变体使得手动恶意软件分析效率低下且耗时。为了更有效地检测恶意软件，许多研究人员提出了用于恶意软件分析和检测的高级工具[2,5,9,14]。这些工具通过对分析员的行为进行部分工作，帮助他们更高效地完成任务。然而，在处理如此大量的恶意软件时，这些解决方案无法从根本上减少工作量。为了解决这个问题，许多专家和学者将机器学习算法，尤其是深度学习应用于恶意软件检测和分类[7,12,15,16,18,22,26,28,34,37,45,50,51,53,55,58-60,62,63]。他们的努力为恶意软件分析神经网络的研究和实用的恶意软件自动检测做出了很大贡献。</p>
<p>然而，这些模型通常需要各种特征工程来帮助神经网络做出判断，这可能很费劲，并且容易丢失一些关键信息。为了实现更加友好和自动的检测，提出了基于二进制的方法[31,37,41,42]。两种流行的原始二进制处理方法是文件剪切和二进制图像转换。然而，这两种方法可能会遇到<strong>语境混乱和语义丢失</strong>，这将在后面讨论。</p>
<p><strong>此外，模型老化是神经网络的一个关键问题</strong>[25,40]。与计算机视觉和自然语言处理不同，恶意软件正在不断快速发展。恶意软件检测是攻击者和检测器之间的斗争。随着恶意软件的不断发展，深度学习模型可能已经过时。例如，五年前训练的模型在今天的恶意软件检测中可能非常薄弱。神经网络很难识别看不见的恶意行为，这可能会导致较低的检测精度和更容易的规避。模型不可能预测未来恶意软件的特征，但快速学习检测新恶意软件的知识是可行的。因此，再培训模式成为缓解老龄化问题的少数方法之一。我们可以让神经网络快速重新训练，学习新恶意软件的新特征，以便识别新的攻击方法。</p>
<p><strong>由于模型的结构和规模，再培训可能会耗费时间和计算量，而且如此高的成本可能会导致模型更新困难</strong>。此外，恶意软件检测是几乎所有电子系统中的常见操作，对于计算能力较低的设备来说，进行检测是必要的。例如，笔记本电脑或其他移动设备很难运行一个庞大的模型来扫描所有文件以检测恶意软件。这些要求表明，检测模型应该足够小和有效，使其更实用，以便我们能够快速重新培训或执行检测。此外，无需复杂特征工程的自动检测对于各种场景中使用的模型至关重要。</p>
<p>总的来说，我们的工作面临两个挑战：<strong>自动化和高效</strong>。检测模型应该足够自动化，并且几乎不需要人工特征工程。该模型的规模应足够小，以降低训练和检测成本。</p>
<p>在本文中，我们提出了一个有效的恶意软件自动检测模型，该模型只有大约136K个参数，我们称之为SeqNet。在没有人工特征选择的情况下，SeqNet可以仅基于原始二进制文件自动分析样本并找出恶意程序和良性程序之间的差异。较小的神经网络通常具有较少的参数，这可能会导致较低的学习能力。这可能是因为较小的模型往往更难适应从原始二进制文件到恶意域的复杂映射。这个问题可能会导致小型深度学习模型中恶意软件检测的准确性较低。</p>
<p>为了在减少参数数量时保持准确性，我们<strong>提出了一种新的二进制代码表示方法</strong>，以减少语义损失并避免上下文混淆。根据我们的方法，我们使SeqNet在无需特征工程的情况下，在可移植可执行（PE）恶意软件检测方面表现良好。基于这种表示方法，我们创建了一种新的卷积方法，称为<strong>序列深度可分离卷积（SDSC）</strong>，以进一步压缩检测模型的规模。我们在一个大型PE数据集上对SeqNet进行训练，发现与许多现有的基于二进制的方法和模型相比，它具有很好的性能。我们还在进一步的实验中证明了我们的模型收缩方法的有效性。此外，我们还公开了我们的代码和数据集以供进一步研究，我们希望深度学习算法能够更好地应用于恶意软件检测。</p>
<p>我们在一个大型PE数据集上对SeqNet进行训练，发现与许多现有的基于二进制的方法和模型相比，它具有很好的性能。我们还在进一步的实验中证明了我们的模型收缩方法的有效性。此外，我们还公开了我们的代码和数据集以供进一步研究，我们希望深度学习算法能够更好地应用于恶意软件检测。</p>
<h4><span id="本文的主要贡献包括">本文的主要贡献包括：</span></h4>
<ul>
<li>我们提出了一种<strong>新的方法来表示二进制代码</strong>，同时减少语义损失，避免上下文混淆。</li>
<li>基于上述新的表示方法，我们提出了一种<strong>新的卷积压缩恶意软件检测模型的方法SDSC</strong>。</li>
<li>我们<strong>设计了一个深度卷积神经网络（CNN），称为SeqNet</strong>，它具有更小的规模和更短的训练过程。</li>
<li>我们将数据集和代码公开以供进一步研究。</li>
</ul>
<p>这是本文的布局。第2节介绍了深层恶意软件检测的主要方法和几个问题。第3节描述了我们应用于SeqNet的主要方法。第四部分阐述了我们的实验和相应的结果。</p>
<h3><span id="二-背景">二、背景</span></h3>
<p>在本节中，我们将介绍使用深度学习进行恶意软件检测的背景。首先，我们列举了这方面的两种主要方法。然后进一步讨论了目前流行的二进制表示方法的几个问题。最后，我们解释了其中一种方法所基于的深度可分离卷积。</p>
<h4><span id="21-深度恶意软件检测">2.1 深度恶意软件检测</span></h4>
<p>神经网络具有强大的学习能力，在计算机视觉和自然语言处理中得到了广泛的应用。深度学习算法已经被许多研究人员应用于恶意软件检测。据我们所知，我们认为有两种主流思想，类似于[47]。</p>
<p><strong>基于特征的方法</strong>。在早期作品中，深度学习模型是从精心制作的恶意软件功能中训练出来的[7、15、16、18、26、28、34、58、63]。在检查可疑样本时，模型需要提取特定特征，以特定方式处理它们，然后检测恶意代码以给出结果。所选功能可以是API调用、控制流图（CFG）或任何其他能够反映程序操作的信息。的确，人工特征学习是神经网络识别恶意样本和良性样本之间主要差异的有效方法。然而，特定的领域特征只能从一个角度很好地描述样本的关键信息。它不能完全覆盖二进制代码的语义，甚至会引发严重的信息丢失。例如，仅使用API调用作为特性会导致模型忽略控制流。此外，精心设计的功能需要足够的先验知识，这需要专家仔细选择。因此，耗时的手动特征提取可能会限制基于特征的模型的使用，并使其难以对抗恶意软件的持续演化。</p>
<p><strong>基于二进制的方法</strong>。与传统的特征工程相比，自动特征提取是神经网络的发展趋势之一，人工干预更少，性能更好。我们读取文件的二进制文件，直接将其发送到检测模型，无需或几乎不需要预处理。该模型将自动找到可疑部分，并将二进制文件识别为恶意或良性。这种方法可以更有效地避免人们分析恶意软件的需要，并更好地减少分析人员的工作量。<strong>此外，通过减少手动特征工程造成的损失，直接从原始二进制文件学习可能会更好地保留语义和上下文信息。</strong></p>
<p>为了使我们的模型更加自动化，避免信息丢失，<strong>我们将重点放在基于二进制的模型上</strong>，SeqNet将原始二进制文件用作输入。此外，较低的计算开销可以使模型更好地适应恶意软件的演变，并扩展应用场景，例如在物联网环境中。我们将一种新颖但简单的二进制代码表示方法应用于SeqNet，并在减少参数时保持其性能。</p>
<h4><span id="22-二进制代码表示法">2.2 二进制代码表示法</span></h4>
<p>在这一部分中，我们将介绍几种主要的二进制代码表示方法，它们适用于基于二进制的模型。将样本转换为神经网络的输入会显著影响模型的性能。因此，<strong>正确的二进制代码表示方法是基于二进制的恶意软件检测神经网络的重要组成部分</strong>。目前，人们提出了两种主要的方法来完全表示原始二进制码。</p>
<p><strong>文件剪切</strong>。<strong>由于内存限制的限制，许多作品对最大文件大小设置了人为限制，这种方法是从二进制程序的开头提取一段固定长度的代码片段</strong>。如果二进制程序的长度小于所需代码段的长度，则该代码段的末尾将填充零。文件剪切会导致语义信息丢失，因为如果二进制文件的结尾比固定长度长得多，就会忽略它。然而，恶意代码通常位于二进制文件的末尾。例如，嵌入的病毒通常嵌入在受感染文件的尾部，这可能有助于它们逃避基于这种方法的模型的检测。<strong>为了缓解这个问题，Mal-ConvGCT[42]通过扩展代码段大小限制来提高MalConv[41]的性能。</strong></p>
<p><strong>二值图像转换</strong>。第二种方法将所有二进制代码转换为图像，并利用图像分类解决方案执行恶意软件检测。所有<strong>图像都可以使用双线性插值算法重新采样到相同的大小</strong>。然而，图像与序列不同，这可能会导致几个问题。我们认为这种方法会导致上下文信息混乱，下面列举了三个例子。</p>
<ul>
<li><strong>边缘丢失</strong>：如果二进制指令位于图像边缘，换行符可能会将指令分成两部分，如图1（a）所示。此问题可能会导致模型难以识别多条长指令。此外，由于<strong>强相关指令的中断，上下文信息可能在边缘被破坏</strong>。</li>
<li><strong>重采样噪声</strong>：如果我们重塑图像大小，不同行中不相关的指令会导致上下文信息混淆，如图1（b）所示。这个问题很容易使原始序列中的指令彼此相距很远，而被迫集成到相应的图像中，这可能会混淆神经网络。</li>
<li><strong>填充问题</strong>：填充操作可能会使模型难以识别原始序列的开始和结束，如图1（c）所示。为了确保卷积层输入和输出的一致性，我们通常在输入的边缘填充一些零，神经网络可能会根据填充得到空间信息[27]。与图像处理不同，识别出的空间信息可能会误导模型。</li>
</ul>
<p><strong>文件剪切导致的语义丢失</strong>和<strong>二值图像转换导致的上下文混乱</strong>阻碍了恶意软件检测模型的性能。这些问题可能会混淆神经网络，甚至误导它们做出截然相反的决定。通过缓解这些问题，我们可以帮助我们的模型在减少参数时保持其性能。</p>
<h4><span id="23-卷积法">2.3 卷积法</span></h4>
<p>传统的卷积算法模拟动物视觉，在计算机视觉中具有很好的性能。这个简单的操作可以有效地提取图像中的视觉特征。低级卷积层检测图像中的纹理和简单特征，高级卷积层可以识别内容和整体语义[61]。这就是为什么计算机可以通过多个卷积层的叠加来识别复杂的物体。</p>
<p>然而，传统卷积所需的参数数量往往使得深度学习模型太大，无法应用于计算能力较低的设备。此外，参数过多的模型可能需要很长的训练过程。例如，VGG有超过1.3亿个参数，已经接受了2年的培训 
3周[49]。如此庞大的模型不适合在普通设备上运行。</p>
<p>因此，我们将CNN架构应用于SeqNet，并将DSC的输入形式从2D调整为1D，从而更好地减少了训练参数的数量。因此，训练时间成本和新生成的模型的大小都进一步减小。我们的方法的细节在第3节中描述。</p>
<h3><span id="三-方法">三、 方法</span></h3>
<p>在本节中，我们将介绍SeqNet的详细信息。首先，我们概述了我们的方法。其次，我们引入了可以减少语义损失和避免语境混淆的序列表征。第三部分描述了SDSC如何压缩模型的规模。最后，我们详细介绍了SeqNet的体系结构。</p>
<h4><span id="31概述">3.1概述</span></h4>
<p>SeqNet的目标是以较低的培训成本实现高效、自动的恶意软件检测。在整个培训和检测过程中，操作员不需要专业的恶意软件分析知识来执行手动领域特定的功能工程。实际上，我们直接将原始二进制文件输入SeqNet，SeqNet将自动分析序列并提取特征。SeqNet的输出是可疑样本的恶意可能性，输入样本是否为恶意软件取决于模型给出的可能性。</p>
<p>准确检测是恶意软件检测模型的基本要求。我们认为恶意软件检测不同于图像分类。恶意软件检测可能需要更多地关注几个<strong>关键的恶意代码</strong>，而图像分类可能更关注整体。根据这一理论，我们对SeqNet的主要设计要点之一是减少上下文混淆和语义丢失。我们使用<strong>原始二进制序列作为SeqNet的输入</strong>，这样可以避免上下文混淆，减少语义损失。</p>
<p>轻量级模型通常具有更广泛的应用场景和更快的检测性能。显然，小型模型的培训成本也很低。因此，压缩SeqNet的规模是必要的。新的卷积方法，称为序列深度可分离卷积（SDSC），有助于SeqNet满足这一要求。</p>
<h4><span id="32-序列表征">3.2 序列表征</span></h4>
<p>输入格式对神经网络性能和模型大小至关重要。较大的输入往往导致较大的模型，适当的输入格式可以有效地提高神经网络的学习效果。SeqNet的输入是原始二进制序列，这些序列通过线性插值算法调整到相同的长度。原始二进制序列输入几乎不需要人工干预。在不转换为图像的情况下，很明显，我们可以避免上下文信息混淆，减少语义损失，如图所示</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182201637.png" alt="image-20220510151305157">
<figcaption aria-hidden="true">image-20220510151305157</figcaption>
</figure>
<blockquote>
<p>一个例子表明，序列表征可以解决上下文混淆和语义丢失的问题。在图像中，二进制指令“BF
01
00”在边缘被切断，但它仍保留序列中的形状。插值后，我们可以看到，图像强制加强了“56”与“00”之间的关系，其中“56”表示“推esi”，而“00”在“0F
85 93 00 00 00 00 00”中表示“jnz loc
1000DF90”，但它忽略了具有更强关系的指令，例如“推edi”和“mov
edi，1”。在序列中，指令“56”与前端结合，而不是“00”，并且在物理上与“57”保持接近，后者表示“推edi”。在图像中，输入到卷积层之前添加的填充提供了不正确的位置信息，但在序列中，它标记了开始和结束。</p>
</blockquote>
<ul>
<li><strong>避免边缘丢失</strong>。由于序列只有两条边，即开始和结束，因此可以避免边缘丢失。序列格式符合代码的空间结构，因此任何指令都没有中断，这使得所有指令在输入模型时都完好无损。中断的消失也有效地保护了原始二进制序列的语义，因为相邻的指令是不分离的。</li>
<li><strong>重采样降噪</strong>。当我们调整序列的大小时，元素只会受到前向和后向上下文的影响，因此重采样噪声可以减少。此外，图像中两条无关指令之间的强制关系消失。通过使用序列特征，远程指令不能相互影响，这使得模型能够更清楚地识别指令之间的关系。此外，通过使用线性插值算法，我们可以确保输入序列的长度是相同的。</li>
<li><strong>避免问题</strong>。填充问题可以解决，因为在卷积之前，我们只需要在序列的两端填充。此外，与向图像中添加不正确的信息相比，序列中的填充将有效地标记相应程序的开始和结束。因此，该模型可以根据填充来识别指令的正确位置。</li>
<li><strong>语义损失减少</strong>。由于我们输入的是整个二进制文件，而不仅仅是一个片段，因此语义损失可能会减少。通过线性插值算法，我们可以压缩语义，而不是忽略它。在这种情况下，嵌入式病毒也可能包括在内，因为程序中的所有指令都被输入到模型中。</li>
</ul>
<p>在缩放到相同的长度之前，我们首先规范化整个序列，使元素的值介于-1和1之间，并以浮点格式存储。由于实数字段的连续性，浮点格式可以比整数格式代表更多的信息。因此，这个操作对于减少线性插值算法造成的语义损失是必要的，如图4所示。通过对数据集进行统计，<strong>我们发现大多数文件的大小约为256KB。因此，我们将所有输入序列扩展到2^18字节。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191547964.png" alt="image-20220510152040055" style="zoom:50%;"></p>
<blockquote>
<p>图4：如果我们在规范化之前调整序列的大小，结果不能代表原始二进制代码（a）中的所有信息。<strong>相反，如果我们在规范化后调整以浮点格式存储的序列的大小，我们可以有效地减少语义损失</strong>（b）。</p>
</blockquote>
<p>在序列格式中，指令之间的所有信息都将得到正确和更好的保留。两条指令之间的物理距离反映了关系的真实强度。这种表示方法还利用了代码中的空间局部性，因为模型将更多地关注附近的指令，而不是那些相关性较弱的指令。因此，该模型在学习和检测时接收到的干扰较小。</p>
<p><strong>使用序列特征而不是二进制图像转换的另一个原因是，可执行文件的前后相关性比平面相关性更明显。这就是为什么序列可以更好地代表程序。</strong></p>
<h4><span id="33-序列深度可分离卷积">3.3 序列深度可分离卷积</span></h4>
<p><strong>序列输入格式不仅解决了语义丢失和上下文混淆的问题，还压缩了SeqNet的规模</strong>。SeqNet的卷积核只需要在只有一维的序列上提取特征。与处理一维输入相比，提取二维特征需要更大的卷积核和更多的计算。例如，如图2（c）所示，a
3 3用于图像的内核至少需要10个参数（包括偏差），而3 1序列中使用的内核只需要至少四个参数（包括偏差）。</p>
<p><strong>基于序列输入和深度可分离卷积</strong>[21]，我们提出了一种称为序列深度可分离卷积（SDSC）的方法，它需要更少的参数和更少的计算。在SDSC中，我们使用3 1个内核替换DSC中的2D深度卷积内核。通过使用SDSC层，SeqNet的尺寸比现有模型小得多。<strong>在下文中，我们分析了与DSC相比计算量的减少</strong>。</p>
<p>此外，SDSC的输入是一维数据，因此与DSC相比，它不太容易受到无关指令的影响。在实验中，我们发现SDSC具有良好的性能，并成功地保持了SeqNet的性能。基于SDSC，我们在SeqNet中使用了以下两种主要的卷积块架构。</p>
<ul>
<li><strong>标准SDSC块</strong>。如图5（a）所示，标准SDSC块由三部分组成。我们使用批量归一化层[23]来帮助模型更好地了解训练样本的概率分布。ReLU[38]激活函数可以通过使模型快速收敛来加速训练过程</li>
<li><strong>残差SDSC块</strong>。如图5（b）所示，剩余SDSC块结合了ResNet[19]中使用的方法。通过跳过SDSC块，我们可以有效地防止梯度消失，并构建更深层的架构。</li>
</ul>
<h4><span id="34-模型架构">3.4 模型架构</span></h4>
<p>SeqNet的构建主要基于SDSC，图6解释了该架构。为了减少参数的数量，我们使用<strong>更小的核和更深的结构</strong>，这也可以扩大感受野。标准SDSC块用于在对序列进行下采样时提取特征。对于第一个卷积层，我们使用单个公共卷积层嵌入原始输入，内核大小为3*1.我们<strong>设置大小是因为经常使用的CPU指令的长度通常是三个字节</strong>。对于高层特征，我们使用五个剩余的SDSC块进行分析，与完全连接的层相比，这也可以更好地保留上下文和空间信息。此外，<strong>残差SDSC块可以防止梯度消失，使模型快速收敛</strong>。最后两层是完全连接层和softmax层。全连通层用于对模型前端给出的分析结果进行分类。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191547603.png" alt="image-20220510152817964" style="zoom:50%;"></p>
<p>在这个公式中，P表示转换后的结果，x表示softmax层的输入。对于池层，我们使用平均池。<strong>在我们的实验中，我们发现当剩余SDSC块的数量为5个，输入128个通道，并且完全连接的层的数量仅为1个时，该模型的性能最好</strong>。SeqNet输出样本的恶意可能性，如果可能性超过50%，模型将视其为恶意软件。根据输出，对于损失函数，我们使用交叉熵函数。SeqNet总共只有大约136K个参数，几乎是MalConv的十分之一，我们将在第4节中讨论。</p>
<h3><span id="四-实验">四、实验</span></h3>
<h4><span id="41培训数据集">4.1培训数据集</span></h4>
<p>建立良好的培训数据集对于评估SeqNet的性能至关重要。正确的标签和足够的样本是展示SeqNet学习能力的必要条件。对于样本类型，我们认为PE恶意软件是电子系统的主要威胁之一。此外，有很多PE恶意样本，很容易获得足够的PE样本。</p>
<p>因此，以下实验适用于一组PE文件，因为它们很普遍。在这项工作中，所有恶意样本都来自VirusShare[4]。<strong>齐安信公司提供了约10000份良性样本。我们还从真实的个人电脑中收集了许多良性样本，以模拟我们日常生活中的真实环境。为了确保良性样本中没有混合病毒，我们使用VirusTotal[6]检测所有文件。如果在VirusTotal报告中没有AV引擎将其视为恶意软件，我们将其视为良性样本。操作系统文件和恶意软件通常具有类似的行为，这可能会混淆检测模型，甚至会混淆训练有素的分析师[8]</strong>。因此，为了帮助SeqNet观察恶意程序和良性程序之间的一般差异，并使SeqNet更加健壮，<strong>我们添加了大约10000个系统文件作为良性数据。</strong>VirusTotal[6]也会检查系统文件，以确保它们是良性的。我们总共获得了72329个二进制文件的训练数据集，其中37501个恶意文件和34828个良性文件，以及24110个二进制文件的验证数据集，其中12501个恶意文件和11609个良性文件。</p>
<p>数据集中的所有文件都是PE文件，我们<strong>通过比较SHA256值来消除重复</strong>。我们将恶意和良性样本的比例设置为1左右，以确保结果可靠。例如，如果数据集只有恶意样本，模型可能会通过识别“4D
5A”来检测所有恶意软件。相反，如果我们向数据集中添加足够多的良性样本，模型就可以了解恶意样本和良性样本之间的真正区别。</p>
<h4><span id="42-测量">4.2 测量</span></h4>
<p>在我们的实验中，我们从训练成本和准确性两个方面测量SeqNet。对于培训成本测量，我们使用参数的数量来表示模型的规模。更大的模型包含更多的神经元，需要更多的参数来构建。在训练和预测过程中，每个参数都会占用恒定的内存。因此，参数的数量显著影响模型训练和预测所需的记忆。为了准确测量模型推理的计算开销，我们通过输入一个随机二进制来计算每个模型上的浮点运算（Flops）。我们还通过记录一个历元所需的时间来测量模型的速度，包括训练和验证过程。</p>
<h4><span id="43-培训">4.3 培训</span></h4>
<p>设置模型和培训设置会显著影响培训过程和结果。所有模型都经过70个阶段的训练，我们选择了过去30个阶段的验证结果，以获得平均精度和其他指标。<strong>我们将批量大小设置为32，并选择Adam[29]作为所有模型的优化器。为了保证训练的公平性，我们将交叉熵损失应用于所有模型。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191547084.png" alt="image-20220510153236041" style="zoom:50%;"></p>
<h4><span id="44-模型评估">4.4 模型评估</span></h4>
<p>我们选择几种最先进的基于二进制的方法作为基线。<strong>为了反映基于图像转换的模型的总体性能，我们选择著名的MobileNet[21]作为代表性模型</strong>。我们将程序转换为RGB图像作为MobileNet的输入。在转换过程中，一个字节映射一个通道中的一个像素。<strong>对于基于文件剪切的模型，我们选择MalConv[41]和MalConvGCT[42]</strong>。<strong>ResNet和MobileNet都是由Pytorh[39]实现的，我们使用ResNet18作为ResNet，而MobileNet
v2作为MobileNet</strong>。我们使用MalConv和MalConvGCT作者提供的源代码，并将它们应用到我们的实验中。我们在每个模型的末尾添加一个softmax层，以便在验证时将结果转换为可能性格式。根据表1中的参数数量，我们可以发现SeqNet的最小参数仅为MalConv和Mal-ConvGCT的十分之一。此外，SeqNet在恶意软件检测方面保持了良好的性能。图7是精度和模型尺寸对比图，左上角的模型位置表明模型尺寸较小，精度较高。</p>
<p>精度还表明，SeqNet误解良性样本的可能性很低。此次召回意味着SeqNet可能有能力防止逃税。在训练过程中，我们发现大多数模型在第一个历元后达到90%的准确率。在我们的训练中，我们发现SeqNet只需要大约两分钟半就可以完成一个历元，而Mal-Conv大约需要一个小时。因此，我们可以看到，SeqNet的微小尺寸导致了较低的计算开销，基于卷积的体系结构加速了训练和推理。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191547005.png" alt="image-20220510153439695" style="zoom:50%;"></p>
<h4><span id="45-进一步评估和消融研究">4.5 进一步评估和消融研究</span></h4>
<p>接下来，我们将描述进一步的实验，以讨论SeqNet中的上下文混淆避免、模型收缩和架构设计。我们对SeqNet进行了几个简单的更改，以测试我们的假设。</p>
<ul>
<li><strong>语境混乱</strong>。为了证明上下文混淆的存在，我们将SeqNet更改为SeqNet2D，可以输入512
* 512张图片。我们将图像大小设置为512 *
512，因为它可以提供与序列相同的信息量。<strong>SeqNet2D使用深度可分离卷积层的架构与SeqNet非常相似</strong>。表2确保了图像转换方法会导致混淆，在从程序学习功能时可能会混淆网络。MobileNet使用图像作为输入，因此表1还通过SeqNet和ResNet之间的比较反映了上下文混淆的存在。</li>
<li><strong>模型收缩</strong>。SDSC层通过降低输入维数和分解卷积来减少参数量。我们用SeqNet中的公共卷积层替换所有SDSC层，并将新模型命名为SeqNetConv，以反映因子分解卷积的效果。为了验证尺寸减小在模型收缩中的作用，我们使用SeqNet2D作为实验对象。我们还将公共卷积层应用于SeqNet2D，并调用新模型SeqNet2DConv来展示这两种方法的缩减效果。如表2所示，我们可以看到维数的有效降低减少了参数的数量，卷积分解进一步减少。通过结果可以看出，SDSC层在保持性能的情况下有效地缩小了模型。我们还发现，参数越少，模型在训练时收敛速度越快。</li>
<li><strong>结构设计</strong>。在我们的实验中，我们还发现，更深层次的结构可能不会表现得更好。我们调整SeqNet的深度。具有更深层次架构的模型称为SeqNetDeep，而更浅层次的架构称为SeqNetShal。与我们的直觉类似，较浅的体系结构会显著降低模型的性能。然而，表2中的结果表明，更深层次的体系结构并不能明显提高性能，而是扩大了模型的规模。<strong>我们假设这种现象可能是因为从二进制到恶意软件的简单映射关系，而不需要复杂的神经网络来拟合。</strong>另一个可能的原因是，更深层次的结构使网络难以训练，这可能会导致精确度较低。我们发现的另一个现象是，扩张卷积不能有效地提高性能。我们认为这是因为与输入的长度相比，使用或不使用扩张卷积对模型的感受野没有太大影响。</li>
</ul>
<h4><span id="46-稳健性评估">4.6 稳健性评估</span></h4>
<p>我们还检查了SeqNet的健壮性，并将其与MalConv进行了比较。关于攻击深度模型有大量的研究[24,32,36,44,48,54,56]。<strong>然而，与针对图像相关任务的神经网络的传统攻击不同，我们不能直接在二进制文件上添加扰动，因为这可能会使二进制文件不可执行</strong>。此外，我们很难根据提取的特征[47]调整攻击策略以适应原始的二进制模型。因此，对于攻击策略，我们采用[30]中的方法，在输入端的填充部分注入一个短的有毒二进制文件。</p>
<p>由于Mal-Conv和SeqNet之间的输入格式不同，我们等效地采用了有毒二进制生成方法。与沿梯度选择最近的嵌入向量相比，SeqNet的毒药生成过程如下所示。</p>
<p>为了使攻击策略在有限的二进制长度下有效，我们从验证恶意数据集中随机选择了500个可用样本。我们将毒药的长度设置为32000字节，MalConv的整个二进制文件固定为16000000字节，并逐步增加毒药生成迭代次数。我们测试了SeqNet和MalConv错误分类的样本数量。结果如图9所示。我们看到SeqNet对有毒二进制攻击有很强的防御能力。我们假设这种现象是由于文件剪切方法中的填充部分造成的漏洞。<strong>基于文件剪切的模型在训练时经常会看到不完整的二进制文件。</strong>因此，文件剪切中的填充使攻击者有机会混淆模型，而模型不确定有毒二进制文件是否是样本的一部分。与文件剪切相比，我们的方法可以通过输入整个二进制文件来缓解这个问题。然而，我们认为这一理论仍需进一步验证，我们可能会在未来的工作中对其进行研究。</p>
<h4><span id="47-案例研究">4.7 案例研究</span></h4>
<p>为了更好地理解SeqNet所学到的知识，我们随机选择了四个样本，并使用Grad
<strong>CAM</strong>[46]解释技术生成热图，以便我们能够可视化哪个部分对结果影响最大。此外，我们还手动分析相应的样本，以验证SeqNet是否找到了正确的恶意代码。在手动分析中，我们通过IDA
Pro[3]分解样本，精确定位恶意功能或代码。为了更好地绘制结果，我们提取了热图的关键部分，并对片段应用以下归一化公式。</p>
<p>其中X表示代码段。用于热图的激活图是由SeqNet的最后一个卷积层和ReLU层生成的，因为剩余的空间信息由卷积层编码。我们还在原始二进制文件上标记手动定位结果，以便更好地进行比较。图10显示了手动定位和基于梯度凸轮的解释之间的比较。我们看到，本地激活位置与分析人员定位的恶意部件接近，这反映了SeqNet可能会发现恶意代码并进行可靠的检测。在我们的解释中，我们发现在整个热图中有许多噪音。我们认为这可能是因为数据集中可能存在潜在的异常统计[10]和一些错误标签[43]。然而，遗憾的是，由于学术界对良性档案的忽视，我们很难收集到更多的良性样本。我们希望在未来的工作中能够探索这一现象。此外，我们还发现PE头通常会对SeqNet产生很大影响。这可能意味着PE头包含恶意软件中的恶意信息。更多细节见附录。</p>
<h3><span id="5讨论">5.讨论</span></h3>
<p>在这一部分中，我们将讨论我们的工作的局限性，并提出一些未来需要进一步研究的工作。</p>
<h4><span id="51局限性">5.1局限性</span></h4>
<p>尽管SeqNet表现良好，但我们的工作仍有一些局限性。仍然是<strong>语义缺失</strong>。虽然我们有效地减少了语义损失，但SeqNet的输入仍然不能包含所有语义。如果序列太长，在插值过程中会对序列进行压缩，压缩后的序列不能代表所有原始信息。此外，如果序列太短，序列将被扩展，这可能会混淆SeqNet。SeqNet的体系结构决定了输入必须具有相同的大小，这是SeqNet的一个限制。</p>
<p><strong>缺乏良性样本</strong>。我们面临的主要困难是缺乏良性样本。我们可以获得大量恶意软件收集网站，但很难找到权威的良性样本提供商。为了均匀采样，仅通过添加恶意样本来扩展训练数据集是不合适的，这可能会降低SeqNet的性能，并使实验结果不可靠。因此，很难在具有足够样本的更大数据集上训练神经网络。</p>
<p><strong>标签的质量</strong>。除了缺乏良性样本，标签的质量可能是一个潜在问题。由于权威供应商寥寥无几，我们无法保证培训和验证数据集中的所有良性样本都正确标记。我们数据集中的所有恶意样本都是从VirusShare收集的，无需人工确认。几家报纸检查了恶意软件标签的质量，发现它可能达不到我们的预期[43]。虽然这些限制可能会对SeqNet的训练过程产生一些影响，但我们假设，几个不正确的标记样本不会显著影响整体性能。</p>
<p><strong>可能存在的漏洞</strong>。对抗性攻击是大多数神经网络的风险，我们也不例外。有动机的对手可能会污染训练数据集，并逃避SeqNet的检测。<strong>此外，基于梯度的攻击是混淆深度学习模型的有效方法[17,30,32]。相反，这个问题也有很多解决方案[7,12,20,33,57]。</strong>虽然SeqNet可以抵御多次攻击，但我们仍然无法完全保证SeqNet的安全。此外，SeqNet的健壮性原则需要我们进一步探索。</p>
<h4><span id="52-未来工作">5.2 未来工作</span></h4>
<p>我们提出了一种高效的恶意软件自动检测神经网络SeqNet。SeqNet的主要目标是实现自动、高效的检测，可以以较低的原始二进制文件培训成本快速进行培训。尽管如此，未来仍有许多工作需要完成。基于深度学习的恶意软件检测研究的最大障碍之一是<strong>缺乏工业规模的公共可用数据集</strong>。研究人员需要权威可靠的数据集，这些数据集不仅包含恶意特征，还包含原始二进制序列。我们将建立一个更大的数据集，以进一步评估SeqNet的性能。此外，还需要足够的良性样本进行进一步研究。<strong>我们认为，当使用深度学习模型进行检测时，恶意软件分析不仅应该关注恶意样本，还应该关注良性样本</strong>。由于神经网络是黑盒模型，恶意软件检测神经网络的可靠性可能会受到怀疑。虽然SeqNet给了我们很好的结果，但我们仍然无法完全解释原因。因此，在实践中使用深度学习算法检测恶意软件仍需进一步研究。通过我们的实验，<strong>我们认为神经网络在恶意软件检测方面可能具有巨大的潜力</strong>，我们期待着神经网络在这一领域取得重大突破。SeqNet的健壮性仍需进一步研究。我们仍然缺乏这方面的实验和研究。在未来的工作中，我们将更深入地探索该模型的稳健性，并对其进行更多的改进和分析。</p>
<blockquote>
<p>基于二进制的模型。与传统的特征工程相比，自动特征提取是神经网络的发展趋势之一，人工干预更少，性能更好。Raff等人设计了一种称为MalConv的架构，它可以直接从原始PE二进制样本中学习，而无需手动选择特征[41,42]。Krc al等人设计了一个简单的CNN，可以从PE原始字节序列中学习，而无需特定领域的特征选择，这项工作获得了较高的AUC分数，尤其是在小型PE恶意软件样本上[31]。</p>
</blockquote>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（2）Dynamic Malware Analysis with Feature Engineering and Feature Learning</title>
    <url>/posts/NFRYYZ/</url>
    <content><![CDATA[<h2><span id="dynamicmalware-analysis-with-feature-engineering-and-feature-learning">Dynamic
Malware Analysis with Feature Engineering and Feature Learning</span></h2>
<ul>
<li>项目：https://github.com/joddiy/DynamicMalwareAnalysis</li>
<li>文章：https://arxiv.org/abs/1907.07352</li>
</ul>
<h3><span id="摘要">摘要</span></h3>
<p>动态恶意软件分析在隔离的环境中执行程序，并监控其运行时行为（如系统<strong>API调用</strong>），以检测恶意软件。该技术已被证明对各种代码混淆技术和新发布的（“零日”）恶意软件有效。然而，现有的工作通常<strong>只考虑API名称而忽略参数</strong>，<strong>或者需要复杂的特征工程操作和专家知识来处理参数</strong>。在本文中，我们<strong>提出了一种新的、低成本的特征提取方法，以及一种有效的深度神经网络体系结构，用于准确、快速地检测恶意软件</strong>。具体而言，<strong>特征表示方法利用特征哈希技巧对与API名称关联的API调用参数进行编码</strong>。深度神经网络体系结构应用多个选通CNN（卷积神经网络）来转换每个API调用的提取特征。通过双向LSTM（长-短期内存网络）进一步处理输出，以<strong>了解API调用之间的顺序相关性</strong>。实验表明，我们的解决方案在大型真实数据集上的性能明显优于基线。从烧蚀研究中获得了有关特征工程和建筑设计的宝贵见解。</p>
<h3><span id="一-说明">一、说明</span></h3>
<p>网络安全给全世界带来了巨大的经济成本。美国政府的一份报告（CEA
2018）估计，2016年美国经济中恶意网络活动的成本在570亿美元至1090亿美元之间。恶意软件（或恶意软件）是快速发展的主要网络安全威胁之一。据报道，每年发现超过1.2亿个新的恶意软件样本（AV-TEST
2017）。因此，开发恶意软件检测技术是迫切而必要的。</p>
<p>数十年来，研究人员一直致力于恶意软件检测。主流解决方案包括静态分析和动态分析。静态分析方法扫描软件的二进制字节流以创建签名，如可打印字符串、n-gram、指令等（Kruegel等人，2005）。然而，基于签名的静态分析可能容易受到代码混淆的影响（Rhode、Burnap和Jones，2018；Gibert等人，2018），或者不足以检测新的（“zeroday”）恶意软件（Vinod等人，2009）。相反，动态分析算法在隔离的环境（例如沙盒）中执行每个软件，以收集其运行时行为信息。通过使用行为信息，动态分析的检测率更高，比静态分析更稳健（Damodaran
et al.2017）。在本文中，我们主要关注动态分析。</p>
<p>在行为信息中，<strong>系统API调用序列</strong>是最常用的数据源，因为它捕获了软件执行的所有操作（包括<strong>网络访问、文件操作等</strong>）。序列中的每个API调用都包含两个重要部分，即<strong>API名称和参数</strong>。每个API可能有零个或多个参数，每个参数都表示为<strong>名称-值对</strong>。为了处理行为信息，提出了许多特征工程方法。例如，如果我们将API名称视为一个字符串，则可以提取最多N个（例如1000个）频繁的N-gram特征（N=1，2.....)
从序列中。然而，从异构类型的参数（包括字符串、整数、地址等）中提取特征并非易事。最近，研究人员将深度学习模型应用于动态分析。卷积神经网络（CNN）和递归神经网络（RNN）等深度学习模型可以直接从序列数据中学习特征，而无需进行特征工程。尽管如此，计算机视觉和自然语言处理等传统深度学习应用程序的数据是同质的，例如图像（或文本）。<strong>使用深度学习模型处理异构API参数仍然具有挑战性</strong>。因此，大多数现有方法都忽略了这些参数。有几种利用API参数的方法（Tian
et al.2010；Fang et al.2017；Agrawal et
al.2018）。然而，这些方法要么将所有参数视为字符串（Tian et
al.2010；Agrawal et al.2018），要么只考虑参数的统计信息（Ahmed et
al.2009；Tian et al.2010；Islam et
al.2013）。因此，<strong>它们无法充分利用来自不同类型参数的异构信息</strong>。</p>
<p>在本文中，我们提出了一种<strong>新的特征工程方法</strong>和一种<strong>新的恶意软件检测深度学习体系结构</strong>。特别是，对于不同类型的参数，我们的特征工程方法<strong>利用哈希方法分别提取异构特征</strong>。<strong>从API名称、类别和参数中提取的特征将进一步串联并输入到深度学习模型中</strong>。我们使用多个选通CNN模型（Dauphin
et
al.2017）从每个API调用的高维哈希特征中学习抽象的低维特征。来自选通CNN模型的输出由双向LSTM处理，以提取所有API调用的顺序相关性。</p>
<p>我们的解决方案比所有基线都有很大的优势。通过广泛的烧蚀研究，我们发现特征工程和模型架构设计对于实现高泛化性能至关重要。本文的主要贡献包括：</p>
<ul>
<li>我们为系统API参数提出了一种新的特征表示。从我们的数据集中提取的特征将发布供公众访问。</li>
<li>我们设计了一种深度神经网络结构来处理提取的特征，它将多个门控CNN和一个双向LSTM相结合。它以巨大的利润超过了所有现有的解决方案。</li>
<li>我们在一个大型真实数据集1上进行了广泛的实验。通过消融研究，发现了有关特征和模型架构的宝贵见解。</li>
</ul>
<h3><span id="二-相关工作">二、相关工作</span></h3>
<p>在本节中，我们将从特征工程和深度学习的角度回顾动态恶意软件分析。</p>
<h4><span id="21-api调用的功能工程">2.1 API调用的功能工程</span></h4>
<p>（Trinius等人，2009）介绍了一种称为<strong>恶意软件指令集（MIST）</strong>的特征表示。MIST使用多个级别的功能来表示系统调用。第一级表示API调用的类别和名称。以下级别是为每个API调用手动指定的，以表示它们的参数。然而，对于不同的API，同一级别的特性可能表示不同类型的信息。这种不一致性给使用机器学习模型学习模式带来了挑战。</p>
<p>（Qiao等人，2013）扩展了MIST，提出了一种称为<strong>基于字节的行为指令集（BBIS）</strong>的表示。他们声称，只有MIST的第一级（API调用的类别和名称）是有效的。此外，他们还提出了一种算法<strong>CARL来处理连续重复的API调用</strong>。</p>
<p>统计特征是训练机器学习模型的常用方法。提取API调用名称及其参数中的字符串，以计算频率和分布，作为中的特征（Tian
et al.2010；Islam et al.2010；2013）。（Ahmed et
al.2009）还使用统计特征来捕获空间和时间信息。从参数中提取空间信息，如均值、方差和熵。时间信息来自ngram
API调用，包括两个n-gram API调用之间的相关性和转换可能性。</p>
<p>（Salehi、Ghiasi和Sami
2012）提出了一种将API调用与其参数关联起来的特性表示。它将每个参数与其API调用的名称连接起来，形成一个新的序列，然而，这种方法会导致一个非常长的特征向量，并且可能会丢失API调用序列的模式。</p>
<p>（Hansen等人，2016）提出了另外两种特征表示法。这些表示包括前200个API调用及其“参数”。但是，此“参数”仅指示此API调用是否与后一个API调用连接，而忽略原始参数。</p>
<h4><span id="22-deep-learning-basedapproaches">2.2 Deep Learning Based
Approaches</span></h4>
<p>（David and Netanyahu
2015）将<strong>沙盒报告视为一个完整的文本字符串</strong>，然后用任何特殊字符拆分所有字符串。他们计算每个字符串的频率，并使用20000位向量来表示最频繁的20000个字符串。他们的模型是一个<strong>深度信念网络（DBN）</strong>，由八层组成（从20000个大小的向量到30个大小的向量）。利用交叉熵损失对模型进行训练。在一个包含600个测试样本的小数据集上，它们的准确率达到98.6%。</p>
<p>（Pascanu et
al.2015）提出了两个阶段的方法，即特征学习阶段和分类阶段。在第一阶段，他们<strong>使用RNN根据之前的API调用序列预测下一个可能的API调用</strong>。在分类阶段，他们冻结RNN，并将输出输入最大池层，以转换特征进行分类。在75000个样本的数据集上，它们的召回率达到71.71%，假阳性率为0.1%。</p>
<p><strong>（Kolosnjaji et
al.2016）提出了一种将CNN与LSTM相结合的方法。他们的方法堆叠两个CNN层，每个CNN层使用一个3大小的内核来模拟3-gram方法。在CNN之后，附加一个具有100大小隐藏向量的LSTM来处理时间序列。以前的论文通常忽略了论点。</strong></p>
<p><strong>（Huang和Stokes
2016）使用了一种包含三个部分的特征表示，即参数中存在可运行代码、API调用名称与其中一个参数的组合（手动选择）以及3-gram的API调用序列</strong>。通过随机投影（random
projection），此特征表示从50000减少到4000。（Agrawal et
al.2018）提出了一种特征表示方法，<strong>该方法使用来自API调用名称的一个one-hot和参数字符串的前N个频繁N-gram</strong>。该模型使用了几个堆叠的LSTM，其性能优于（Kolosnjaji等人，2016）。他们还声称，多个LSTM不能提高性能。</p>
<h3><span id="三-系统框架">三、系统框架</span></h3>
<p>为了收集运行时API调用，我们实现了图1所示的系统。该系统由体育档案采集、行为信息采集、特征提取和模型训练三部分组成。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191547460.png" alt="image-20220526165948643">
<figcaption aria-hidden="true">image-20220526165948643</figcaption>
</figure>
<h4><span id="31-pe文件收集">3.1 PE文件收集</span></h4>
<p>我们系统的工作流程从可移植可执行文件（PE）集合开始。在本文中，我们重点检测Windows系统中可移植可执行文件（PE）格式的恶意软件，这是最流行的恶意软件文件格式（AV-TEST
2017）。此收集部分已由新加坡SecureAge
Technology本地反病毒公司实施。此外，该公司还维护了一个包含12个防病毒引擎的平台，用于对PE文件进行分类。对分类结果进行聚合，以获得每个PE文件的标签，用于模型培训。一旦模型经过培训，它将作为第13个防病毒引擎添加到平台中。收集之后，将维护一个执行队列，以提交PE文件以供执行。它监视存储使用情况并决定是否执行更多PE文件。</p>
<h4><span id="32-行为信息收集">3.2 行为信息收集</span></h4>
<blockquote>
<p>https://cuckoosandbox.org/</p>
<p>json在线解析：http://www.jsons.cn/jsoncheck/</p>
</blockquote>
<p><strong>布谷鸟</strong>是一款开源软件，用于运行PE文件和收集执行日志。它在虚拟机内执行PE文件，并使用API挂钩监视API调用跟踪（即行为信息）。此外，布谷鸟模拟了一些用户行为，例如单击按钮、键入一些文本等。<strong>在我们的系统中，我们在每台服务器上维护了数十台虚拟机。所有虚拟机都安装了64位Windows
7系统和一些日常使用的软件</strong>。我们利用虚拟机的快照功能在执行后回滚它。<strong>所有生成的日志都存储在本地的布谷鸟服务器上</strong>。</p>
<h4><span id="33-特征提取和模型训练">3.3 特征提取和模型训练</span></h4>
<p>沙盒生成的执行日志包含<strong>PE文件的详细运行时信息</strong>，PE文件的大小从几KB到数百GB不等。我们设计了一个可以<strong>并行运行的特征工程解决方案</strong>，<strong>以有效地从原始执行日志中提取特征</strong>。提取特征后，我们在带有GPU的模型服务器上训练我们的深度学习模型，以进行恶意软件分类。</p>
<h3><span id="4-方法">4、方法</span></h3>
<blockquote>
<p>#### cuckoo json:</p>
<ul>
<li><p><strong>behavior</strong></p>
<ul>
<li><p>summary</p>
<ul>
<li>file_recreated</li>
<li>file_failed</li>
<li>dll_loaded</li>
<li>guid</li>
<li>file_opened</li>
<li>file_created</li>
<li>file_written</li>
</ul></li>
<li><p><strong>generic</strong></p>
<ul>
<li>process_path: 进程启动路径</li>
<li><strong>process_name</strong>: 进程执行程序名</li>
<li>pid: 进程id</li>
<li>first_seen: 进程启动时间戳</li>
<li>ppid: 父进程id</li>
</ul></li>
<li><p><strong>apistats</strong>：<strong>API名称的调用次数信息</strong></p></li>
<li><p><strong>processes</strong></p>
<ul>
<li><p>command_line</p></li>
<li><p><strong>calls</strong></p>
<blockquote>
<p>{ "<strong>api</strong>": "NtCreateFile",
"<strong>category</strong>": "file", "return_value": 0, "stacktrace": [
], "flags": { "desired_access":
"FILE_READ_ATTRIBUTES|READ_CONTROL|SYNCHRONIZE", "share_access":
"FILE_SHARE_READ", "file_attributes": "", "create_disposition":
"FILE_OPEN", "create_options":
"FILE_NON_DIRECTORY_FILE|FILE_SYNCHRONOUS_IO_NONALERT", "status_info":
"FILE_OPENED" }, "<strong>arguments</strong>": { "desired_access":
"0x00120080", "share_access": 1, "<strong>filepath_r</strong>":
"\??\C:\Users\xn\AppData\Local\Temp\0e823db8b1beaca62207e2a82a9cd691c7af44cd14b876cb9f823f29750dd008",
"<strong>filepath</strong>":
"C:\Users\xn\AppData\Local\Temp\0e823db8b1beaca62207e2a82a9cd691c7af44cd14b876cb9f823f29750dd008",
"file_attributes": 0, "create_disposition": 1, "file_handle":
"0x000004ac", "status_info": 1, "create_options": 96 }, "tid": 3564,
"status": 1, "time": 1622640835.384851 },</p>
</blockquote></li>
<li><p><strong>modules</strong>: <strong>样本运行时调用的系统文件信息,
包括被调用文件名/路径/基地址及其大小</strong></p></li>
<li><p>time: 运行时间</p></li>
</ul></li>
<li><p><strong>processtree</strong></p>
<ul>
<li>children: 子进程列表</li>
</ul></li>
</ul></li>
</ul>
</blockquote>
<h4><span id="41-特征工程">4.1 特征工程</span></h4>
<blockquote>
<ul>
<li><p><strong>FeatureHasher</strong>:
https://scikit-learn.org/dev/modules/generated/sklearn.feature_extraction.FeatureHasher.html#sklearn.feature_extraction.FeatureHasher</p></li>
<li><p><strong>Feature Hashing for Large Scale Multitask
Learning</strong> （2013）</p></li>
</ul>
</blockquote>
<p>以前的大多数工作（Qiao et al.2013；Pascanu et al.2015；Kolosnjaji et
al.2016）都<strong>忽略了API调用的参数</strong>，只考虑了API名称和类别。因此，一些重要（鉴别）信息丢失（Agrawal
et
al.2018）。例如，如果忽略文件路径参数，则两个写操作（API调用）的功能将完全相同。但是，当目标文件由程序本身创建时，写入操作可能是良性的，但如果目标文件是系统文件，则写入操作可能是恶意的。一些考虑到论点的著作（Trinius
et al.2009；Agrawal et al.2018；Huang and Stokes
2016）未能利用不同类型论点的异质信息。我们建议采用（Weinberger et
al.2009）中的哈希方法，<strong>分别对API的名称、类别和参数进行编码</strong>。</p>
<p>如下表所示，我们的特征表示由不同类型的信息组成。<strong>API名称有8维，API类别有4维。API参数部分有90个维，16个用于整数参数，74个用于字符串参数。对于字符串参数，将处理几种特定类型的字符串（文件路径、DLL等）。此外，从所可打印字符串中提取了10个统计特征</strong>。将所有这些特征串联起来，形成<strong>102维特征向量</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191547725.png" alt="image-20220526170451620" style="zoom:50%;"></p>
<ul>
<li><h4><span id="api名称和类别">API名称和类别</span></h4></li>
</ul>
<blockquote>
<p>单词拆分？fastext？<strong>删除循环调用？</strong></p>
</blockquote>
<p><strong>布谷鸟沙盒总共跟踪312个API调用，它们属于17个类别</strong>。每个API名称由多个单词组成，每个单词的第一个字母大写，例如“<strong>GetFileSize</strong>”。我们<strong>将API名称拆分为单词</strong>，然后应用下面的<strong>特性哈希技巧处理这些单词</strong>。对于API类别，由于该类别通常是单个单词，例如“<strong>network</strong>”，我们将该单词拆分为字符并应用特征哈希技巧。此外，我们<strong>计算API名称、类别和参数的MD5值，以删除任何连续重复的API调用</strong>。</p>
<p>我们使用方程1中的<strong>特征哈希</strong>（Weinberger et
al.2009）<strong>将字符串序列编码为固定长度的向量</strong>。随机变量x表示元素序列，其中每个元素要么是字符串，要么是字符。M表示维度数量，即8表示API名称，4表示API类别。第i个bin的值通过以下公式计算：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191548610.png" alt="image-20220526172933876" style="zoom:50%;"></p>
<p>其中，h是将元素（例如xj）映射到自然数m的哈希函数∈
{1，…，M}作为bin索引；ξ是另一个将元素映射到{+-1}
。也就是说，对于x的每个元素xj，其bin索引h（xj）为i，我们将ξ（xj）添加到bin中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">APIName</span>(<span class="title class_ inherited__">FeatureType</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; api_name hash info &#x27;&#x27;&#x27;</span></span><br><span class="line">    name = <span class="string">&#x27;api_name&#x27;</span></span><br><span class="line">    dim = <span class="number">8</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(FeatureType, self).__init__()</span><br><span class="line">        self._name = re.<span class="built_in">compile</span>(<span class="string">&#x27;^[a-z]+|[A-Z][^A-Z]*&#x27;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">raw_features</span>(<span class="params">self, input_dict</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        input_dict: string</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        tmp = self._name.findall(input_dict)</span><br><span class="line">        hasher = FeatureHasher(self.dim, input_type=<span class="string">&quot;string&quot;</span>).transform([tmp]).toarray()[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> hasher</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_raw_features</span>(<span class="params">self, raw_obj</span>):</span><br><span class="line">        <span class="keyword">return</span> raw_obj</span><br><span class="line">      </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">APICategory</span>(<span class="title class_ inherited__">FeatureType</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; api_category hash info &#x27;&#x27;&#x27;</span></span><br><span class="line">    name = <span class="string">&#x27;api_category&#x27;</span></span><br><span class="line">    dim = <span class="number">4</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(FeatureType, self).__init__()</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">raw_features</span>(<span class="params">self, input_dict</span>):</span><br><span class="line">        hasher = FeatureHasher(self.dim, input_type=<span class="string">&quot;string&quot;</span>).transform([input_dict]).toarray()[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> hasher</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_raw_features</span>(<span class="params">self, raw_obj</span>):</span><br><span class="line">        <span class="keyword">return</span> raw_obj</span><br></pre></td></tr></table></figure>
<ul>
<li><h4><span id="api参数">API参数</span></h4></li>
</ul>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191548031.png" alt="image-20230319160222991">
<figcaption aria-hidden="true">image-20230319160222991</figcaption>
</figure>
<p>至于API参数，只有两种类型的值，即<strong>整数</strong>和<strong>字符串</strong>。整数的单个值没有意义。需要参数名称才能获取值的含义。<strong>相同的整数值可能表示具有不同参数名称的完全不同语义</strong>。例如，<strong>名为“port”的数字22与名为“size”的数字不同</strong>。我们采用前面的特征哈希方法<strong>对整数的参数名称及其值进行编码</strong>，如等式2所示。我们使用参数名称来定位哈希容器。特别是，我们使用名称哈希值为i的所有参数通过求和更新第i个bin。对于每个这样的参数，我们计算对bin的贡献，如等式2所示，其中ξ(<span class="math inline">\(x_{name_j}\)</span>)是参数名称上的哈希函数，<span class="math inline">\(x_{value_j}\)</span>是整数参数的值。由于整数可能在某个范围内稀疏分布，因此我们使用对数对值进行规格化，以压缩该范围。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191548958.png" alt="image-20220526174316254" style="zoom:50%;"></p>
<p>其中，h和ξ是与等式1中相同的哈希函数。<strong>对于API参数字符串，它们的值比整数更复杂。某些以“0x”开头的字符串包含某些对象的地址。还有一些可能包含文件路径、IP地址、URL或纯文本</strong>。此外，一些API参数甚至可能包含整个文件的内容。字符串的多样性使得处理它们具有挑战性。根据之前的工作（Tian
et al.2010；Islam et al.2010；2013；Ahmed et
al.2009），最重要的字符串是关于<strong>文件路径、DLL、注册表项、URL和IP地址的值</strong>。因此，我们使用<strong>方程1中的特征哈希方法【string】</strong>来提取这些字符串的特征。</p>
<p>为了捕获<strong>字符串中包含的层次信息</strong>，我们将整个字符串解析为几个子字符串，并分别对它们进行处理。例如，我们使用“C:\”来标识文件路径。所有这些子串都通过方程1进行处理</p>
<blockquote>
<p><strong>Path</strong>：<strong>对于像“C:\a\b\C”这样的路径，将生成四个子字符串，即“C:”、“C:\a”、“C:\a\b”和“C:\a\b\C”。</strong></p>
<p>dll：以“.dll”结尾的字符串</p>
<p>注册表：项通常以“HKEY”开头</p>
<p>IP：由点分隔的四个数字（范围从0到255）组成的字符串</p>
<p>URL：我们仅从URL的主机名生成子字符串。例如，对于“https://security.ai.cs.org/，将生成以下子字符串“org”、“cs.org”、“ai.cs.org”和“security.ai.cs.org”。</p>
</blockquote>
<p><strong>DLL、注册表项和IP也采用相同的处理方法</strong>。<strong>dll是以“.dll”结尾的字符串。注册表项通常以“HKEY”开头。IP是由点分隔的四个数字（范围从0到255）组成的字符串</strong>。URL略有不同，我们仅从URL的主机名生成子字符串。例如，对于“https://security.ai.cs.org/，将生成以下子字符串“org”、“cs.org”、“ai.cs.org”和“security.ai.cs.org”。这样，域和组织信息将对该功能贡献更多。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PRUIInfo</span>(<span class="title class_ inherited__">FeatureType</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Path, Registry, Urls, IPs hash info &#x27;&#x27;&#x27;</span></span><br><span class="line">    name = <span class="string">&#x27;prui&#x27;</span></span><br><span class="line">    dim = <span class="number">16</span> + <span class="number">8</span> + <span class="number">12</span> + <span class="number">16</span> + <span class="number">12</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(FeatureType, self).__init__()</span><br><span class="line">        self._paths = re.<span class="built_in">compile</span>(<span class="string">&#x27;^c:\\\\&#x27;</span>, re.IGNORECASE)</span><br><span class="line">        self._dlls = re.<span class="built_in">compile</span>(<span class="string">&#x27;.+\.dll$&#x27;</span>, re.IGNORECASE)</span><br><span class="line">        self._urls = re.<span class="built_in">compile</span>(<span class="string">&#x27;^https?://(.+?)[/|\s|:]&#x27;</span>, re.IGNORECASE)</span><br><span class="line">        self._registry = re.<span class="built_in">compile</span>(<span class="string">&#x27;^HKEY_&#x27;</span>)</span><br><span class="line">        self._ips = re.<span class="built_in">compile</span>(<span class="string">&#x27;^\d&#123;1,3&#125;\.\d&#123;1,3&#125;\.\d&#123;1,3&#125;\.\d&#123;1,3&#125;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">raw_features</span>(<span class="params">self, input_dict</span>):</span><br><span class="line">        paths = np.zeros((<span class="number">16</span>,), dtype=np.float32)</span><br><span class="line">        dlls = np.zeros((<span class="number">8</span>,), dtype=np.float32)</span><br><span class="line">        registry = np.zeros((<span class="number">12</span>,), dtype=np.float32)</span><br><span class="line">        urls = np.zeros((<span class="number">16</span>,), dtype=np.float32)</span><br><span class="line">        ips = np.zeros((<span class="number">12</span>,), dtype=np.float32)</span><br><span class="line">        <span class="keyword">for</span> str_name, str_value <span class="keyword">in</span> input_dict.items():</span><br><span class="line">            <span class="keyword">if</span> self._dlls.<span class="keyword">match</span>(str_value):</span><br><span class="line">                tmp = re.split(<span class="string">&#x27;//|\\\\|\.&#x27;</span>, str_value)[:-<span class="number">1</span>]</span><br><span class="line">                tmp = [<span class="string">&#x27;\\&#x27;</span>.join(tmp[:i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(tmp) + <span class="number">1</span>)]</span><br><span class="line">                dlls += FeatureHasher(<span class="number">8</span>, input_type=<span class="string">&quot;string&quot;</span>).transform([tmp]).toarray()[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> self._paths.<span class="keyword">match</span>(str_value):</span><br><span class="line">                tmp = re.split(<span class="string">&#x27;//|\\\\|\.&#x27;</span>, str_value)[:-<span class="number">1</span>]</span><br><span class="line">                tmp = [<span class="string">&#x27;\\&#x27;</span>.join(tmp[:i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(tmp) + <span class="number">1</span>)]</span><br><span class="line">                paths += FeatureHasher(<span class="number">16</span>, input_type=<span class="string">&quot;string&quot;</span>).transform([tmp]).toarray()[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">elif</span> self._registry.<span class="keyword">match</span>(str_value):</span><br><span class="line">                tmp = str_value.split(<span class="string">&#x27;\\&#x27;</span>)[:<span class="number">6</span>]</span><br><span class="line">                tmp = [<span class="string">&#x27;\\&#x27;</span>.join(tmp[:i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(tmp) + <span class="number">1</span>)]</span><br><span class="line">                registry += FeatureHasher(<span class="number">12</span>, input_type=<span class="string">&quot;string&quot;</span>).transform([tmp]).toarray()[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">elif</span> self._urls.<span class="keyword">match</span>(str_value):</span><br><span class="line">                tmp = self._urls.split(str_value + <span class="string">&quot;/&quot;</span>)[<span class="number">1</span>]</span><br><span class="line">                tmp = tmp.split(<span class="string">&#x27;.&#x27;</span>)[::-<span class="number">1</span>]</span><br><span class="line">                tmp = [<span class="string">&#x27;.&#x27;</span>.join(tmp[:i][::-<span class="number">1</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(tmp) + <span class="number">1</span>)]</span><br><span class="line">                urls += FeatureHasher(<span class="number">16</span>, input_type=<span class="string">&quot;string&quot;</span>).transform([tmp]).toarray()[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">elif</span> self._ips.<span class="keyword">match</span>(str_value):</span><br><span class="line">                tmp = str_value.split(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">                tmp = [<span class="string">&#x27;.&#x27;</span>.join(tmp[:i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(tmp) + <span class="number">1</span>)]</span><br><span class="line">                ips += FeatureHasher(<span class="number">12</span>, input_type=<span class="string">&quot;string&quot;</span>).transform([tmp]).toarray()[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> np.hstack([paths, dlls, registry, urls, ips]).astype(np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_raw_features</span>(<span class="params">self, raw_obj</span>):</span><br><span class="line">        <span class="keyword">return</span> raw_obj</span><br></pre></td></tr></table></figure>
<h4><span id="统计信息">统计信息</span></h4>
<p>对于许多其他类型的字符串，根据之前的工作（Ahmed et al.2009；Tian et
al.2010；Islam et
al.2010），我们<strong>从所有可打印字符串中提取统计信息</strong>。可打印字符串由0x20到0x7f的字符组成。<strong>因此，包括所有路径、注册表项、URL、IP和其他一些可打印字符串</strong>。</p>
<ul>
<li>以“MZ”开头的一类字符串通常是包含整个PE文件的缓冲区，通常出现在恶意PE文件中，如<strong>线程注入</strong>（Liu
et al.2011）。因此，我们额外计算“MZ”字符串的出现次数。</li>
<li><strong>10维向量用于记录字符串的数量、平均长度、字符数、所有可打印字符串的字符熵，以及路径、DLL、URL、注册表项、IP和“MZ”字符串的数量。</strong>我们没有处理其他参数，如虚拟地址、结构等，与上述类型的参数相比，这些参数相对不太重要。</li>
</ul>
<p>虽然所提出的特征工程方法很容易使用额外的bins应用于它们，但我们期待着进行更有针对性的研究来探索这些论点。</p>
<h4><span id="42-模型结构">4.2 模型结构</span></h4>
<p>我们提出了一种深度神经网络架构，它利用了所提出的特征工程步骤中的特征。图2概述了我们提出的深度学习模型。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191548514.png" alt="image-20220526184024769" style="zoom:50%;"></p>
<ul>
<li><h4><span id="输入模块">输入模块</span></h4></li>
</ul>
<p>在特征工程之后，我们得到大小为（N，d）的输入向量，<strong>其中N是API调用序列的长度</strong>，<strong>d（102位）是每个提取的API特征的维数</strong>。我们首先通过<strong>批量规范化层（BN）</strong>对输入进行规范化（Ioffe和Szegedy
2015）。该批次标准化层通过减去批次平均值并除以批次标准偏差来标准化输入值。<strong>它保证了特征向量的某些维数不会太大而影响训练；实验验证了该方法的正则化效果。</strong></p>
<ul>
<li><h4><span id="门控cnns模块">门控CNNs模块</span></h4></li>
</ul>
<p>输入模块后应用了多个<strong>门控-CNN</strong>（Dauphin et
al.2017）。<strong>门控-CNN允许选择重要和相关的信息，使其在语言任务上与循环模型相比，但消耗更少的资源和时间</strong>。对于每个选通的CNN，输入分别馈入两个卷积层。设XA表示第一卷积层的输出，XB表示第二卷积层的输出；它们由<img src="image-20220526184352710.png" alt="image-20220526184352710" style="zoom:50%;">组成，它涉及到元素乘法运算。这里，σ是sigmoid函数。<strong>σ（XB）被视为控制从XA传递到模型中下一层的信息的门</strong>。<strong>按照（Shen
et
al.2014)中的想法，一维卷积滤波器被用作n-gram检测器。如图2所示，我们使用两个选通CNN，其过滤器大小分别为2和3。所有卷积层的滤波器个数为128，步长为1。</strong></p>
<ul>
<li><h4><span id="bi-lstm模块">BI-LSTM模块</span></h4></li>
</ul>
<p><strong>来自门CNN的所有输出连接在一起</strong>。对这些输出应用批处理规范化层，以减少过拟合。我们使用<strong>双向LSTM来学习序列模式</strong>。<strong>每个LSTM的单元数为100</strong>。LSTM是一种递归神经网络架构，其中设计了几个门来控制信息传输状态，以便能够捕获长期上下文信息（Pichotta和Mooney
2016）。双向LSTM是两个LSTM叠加在一起，但方向输入不同。与单向LSTM相比，双向LSTM能够同时整合过去和未来状态的信息。双向LSTM在恶意软件检测方面已被证明是有效的（Agrawal
et al.2018）。</p>
<ul>
<li><h4><span id="分类模块">分类模块</span></h4></li>
</ul>
<p><strong>在Bi
LSTM模块中学习序列模式后，应用全局最大池层从隐藏向量中提取抽象特征</strong>。全局最大池层不是使用Bi
LSTM的最终激活，而是依赖于整个序列中观察到的每个信号，这有助于保留整个序列中学习到的相关信息。在全局最大池层之后，<strong>我们使用单元数为64的密集层将中间向量的维数减少到64</strong>。将<strong>ReLU激活应用于该致密层</strong>。然后，我们使用速率为0.5的<strong>衰减层（dropout）</strong>来减少过度拟合。最后，<strong>单位数为1的致密层将维数减少到1</strong>。在致密层之后附加一个<strong>Sigmoid激活以输出概率</strong>。我们的模型使用与每个输入向量相关的标签进行监督。为了测量用于训练模型的损失。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191548788.png" alt="image-20220526185129696" style="zoom:50%;"></p>
<p>此外，我们采用的优化方法是Adam，学习率为0.001。</p>
<h2><span id="dynamic-malware-analysis-代码结构"><strong><font color="red">
Dynamic Malware Analysis - 代码结构</font></strong></span></h2>
<blockquote>
<p><strong>model.py</strong></p>
<ul>
<li>ClassifyGenerator: Generates data for Keras</li>
<li>Model: 模型结构定义、模型训练</li>
<li>Cuckoo2DMDS：</li>
<li>DMDS</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（3）Living-Off-The-Land 恶意软件系统分析</title>
    <url>/posts/3403A74/</url>
    <content><![CDATA[<h2><span id="living-off-the-land恶意软件系统分析">Living-Off-The-Land
恶意软件系统分析</span></h2>
<blockquote>
<p>[][AI安全论文] <strong>1、<a href="https://mp.weixin.qq.com/s?__biz=Mzg5MTM5ODU2Mg&amp;mid=2247496069&amp;idx=1&amp;sn=f5aecaae5494b900b29f12078a2d632e&amp;chksm=cfcf4148f8b8c85ee56fbab09252bb4dc90f936cfb6decaa860b5e91457c9838cfb35179041a&amp;scene=178&amp;cur_album_id=1776483007625822210#rd">21.S&amp;P21
Survivalism经典离地攻击（Living-Off-The-Land）恶意软件系统分析</a>:S&amp;P21的离地攻击（Living-Off-The-Land）系统分析，这是一篇非常经典的论文，并且系统性分析文章是另一种讲故事的方式。</strong></p>
<p>2、2021 RAID <strong>Living-Off-The-Land Command Detection Using
Active
Learning</strong>：https://dl.acm.org/doi/pdf/10.1145/3471621.3471858</p>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191548226.png" alt="图片" style="zoom:67%;"></p>
<blockquote>
<p>原文作者：Frederick Barr-Smith, Xabier Ugarte-Pedrero, et al.
<strong>原文标题</strong>：Survivalism: Systematic Analysis of Windows
Malware Living-Off-The-Land
<strong>原文链接</strong>：https://ieeexplore.ieee.org/document/9519480
<strong>发表会议</strong>：2021 IEEE Symposium on Security and Privacy
(SP)</p>
</blockquote>
<p><strong>文章目录：</strong></p>
<ul>
<li><p><strong>摘要</strong></p></li>
<li><p><strong>一.引言</strong></p>
<p>1.什么是离地攻击</p>
<p>2.APT中的离地攻击</p>
<p>3.提出五个关键问题</p>
<p>4.贡献（Contribution）</p></li>
<li><p><strong>二.背景和相关工作</strong></p>
<p>A.LotL Binaries</p>
<p>B.Scope of our Study</p>
<p>C.Related Work</p></li>
<li><p><strong>三.MOTIVATION: 杀毒软件产品 vs
离地攻击技术</strong></p></li>
<li><p><strong>四.离地攻击流行性评估</strong></p>
<p>A.Dataset Composition</p>
<p>B.Analysis Pipeline</p>
<p>C.LotL Technique Identification</p>
<p>D.Parameter Analysis to Identify Execution Purpose</p></li>
<li><p><strong>五.评估结果</strong></p>
<p>A.商用恶意软件中LotL技术的流行性（Prevalence）</p>
<p>B.Comparison of Benign and Malicious Samples</p>
<p>C.Prevalence of LotL techniques in APT Malware</p></li>
<li><p><strong>六.案例分析</strong></p></li>
<li><p><strong>七.要点和讨论</strong></p></li>
<li><p><strong>八.局限性和未来工作</strong></p></li>
<li><p><strong>九.个人感受</strong></p></li>
</ul>
<h3><span id="摘要">摘要</span></h3>
<p>随着恶意软件检测算法和方法变得越来越复杂（sophisticated），恶意软件作者也采用（adopt）同样复杂的逃避机制（evasion
mechansims）来对抗（defeat）它们。<strong>民间证据表明离地攻击技术（Living-Off-The-Land，LotL）是许多恶意软件攻击中最主要的逃避技术之一。这些技术利用（leverage）系统中已经存在的二进制文件来执行（conduct）恶意操作。</strong>基于此，我们首次对Windows系统上使用这些技术的恶意软件进行大规模系统地调查。</p>
<p>在本文中，我们分析了这些本地系统的二进制文件在多个恶意软件数据集上的使用情况，这些数据集共包含31,805,549个样本。我们发现平均流行率（prevalence）为9.41%。实验结果表明，LotL技术被大量的使用，特别是在高级持久性威胁（Advanced
Persistent Threat
，APT）恶意软件样本中，离地攻击占比为26.26%，是社区恶意软件的两倍多。</p>
<p><strong>为了验证（illustrate）LotL技术的逃逸潜力，我们在本地沙箱环境（sandboxed
environment）中对几个完全打补丁的Windows系统进行了离地攻击技术的测试，其结果表明在10个最流行的反病毒产品（anti-virus）中存在明显的gap。</strong></p>
<h3><span id="一-引言">一、引言</span></h3>
<h4><span id="11-什么是离地攻击">1.1 什么是离地攻击</span></h4>
<p>恶意软件开发和检测是猫和老鼠的游戏，恶意软件作者不断开发新技术来绕过（bypass）检测系统。像AV杀毒软件（anti-virus）这样的安全产品通过静态和启发式分析（heuristic
analysis）技术，以检测、分类和防止恶意软件有效执行。</p>
<p>在过去，许多解决方案严重依赖于基于签名的检测，但不幸的是，由于使用了<strong>多态性（polymorphism）和加壳程序（packers）</strong>，这些方法变得不再那么有效。相反，许多产品开始开发启发式分析解决方案，包括检测恶意行为的算法。这些算法已成为AV引擎的重要组成部分。随着时间的推移，这些算法越来越复杂，因此需要更多创新性的逃避技术。</p>
<p>恶意软件作者和红队经常研究和发现新方法来绕过安全解决方案。虽然它们的潜在目标本质上可能有所不同，但这两种类型的攻击者通常都利用（leverage）最先进（state-of-the-art）的逃避技术来实现目标。<strong>从防守者的角度来看，为了及时作出响应，了解这些攻击和研究它们的趋势是至关重要的（crucial）</strong>。其中，在红队和恶意软件作者中都流行的规避策略就是使用离地攻击（LotL）技术。</p>
<p><strong>离地攻击（LotL）技术是指使用系统中已经存在或易于安装的二进制文件（如已签名的合法管理工具）来执行后渗透活动（post-exploitation
activity）。</strong></p>
<ul>
<li>通过利用这些工具，攻击者可以<strong>实现注册表修改、持久化、网络或系统侦察，或执行其他恶意代码</strong>。它们甚至可以用来减少由恶意活动产生的事件日志，而不需要将其他文件下载到本地的系统中。</li>
</ul>
<h4><span id="12-apt中的离地攻击">1.2 APT中的离地攻击</span></h4>
<p>离地攻击并不是隐蔽的技术，它们在互联网上公开记录着。许多开源的攻击安全工具利用了LotL技术，并且经常被攻击者所使用，从合法的红队到业余的网络攻击者，以及有组织的APT团队。</p>
<ul>
<li><code>PoshSpy[15]</code>：是一个俄罗斯APT29攻击模块，它是第一个被检测到的APT组织使用的LotL技术，特别是在PowerShell和Windows
Management中。</li>
<li>伊朗威胁组织[1]、APT33、APT34和其他组织也以使用本地Windows二进制文件和其它签名工具而闻名，特别是PowerShell[8]。</li>
</ul>
<p>尽管“离地攻击”在信息安全界是一个相对知名的术语，但有时很难找到一个精确的定义。此外，据我们所知，没有任何研究包含了对LotL技术在恶意软件样本中的流行程度的系统分析。关于LotL技术的文档大多以博客的形式出现，并记录着某些恶意软件家族的在野发现，或者攻击者在远程访问受损系统中所使用技术的描述。</p>
<ul>
<li>例如，<code>Emotet</code> 和
<code>Trickbot</code>，两个最常见的远程访问木马（Remote Access
Trojans，RAT），据称是使用链接的LotL二进制文件来实现持久化。</li>
<li>作为一种对策，微软描述了对抗使用LotL技术商用RAT的基本步骤。高度逃逸的远程访问木马
<code>Astaroth</code>，<code>TA505</code>
组织的一些恶意软件库，<code>Dexphot cryptominer</code> 和
<code>Nodersok</code> 同期使用的多个LotL二进制文件。</li>
</ul>
<h4><span id="13-提出5个关键性问题">1.3 提出5个关键性问题</span></h4>
<p>在本文中，我们分析了LotL现象，即商用恶意软件中与离地攻击二进制文件利用相关的文件。我们首先描述了什么是LotL
binary以及它如何被恶意软件利用来实施恶意行为的。</p>
<p>本文的研究重点是以Windows为主导的操作系统下流行且恶意软件最常针对的目标。<strong>许多基于离地攻击的AV逃逸行为已被记录下来。因此（As
a
consequence），安全界很大程度上认为，LotL技术（如代理执行恶意软件）实际上对安全解决方案是有效的。</strong></p>
<p>首先，我们提出了第一个假设以及第一个研究问题：</p>
<blockquote>
<p>#### <strong>问题1：Can LotL techniques effectively evade commercial
AV?</strong></p>
<p>#### LotL技术能有效地逃避目前大部分安全厂商的杀毒软件检测吗？</p>
</blockquote>
<p>为了回答这个问题，我们评估了一组具有代表性的安全产品，并展示了其中的一些技术，虽然这是攻击者和防御者所熟知的，但仍然是绕过安全解决方案的有效方法，因此对安全行业来说这仍是一个开放的挑战。</p>
<p><strong>事实上，LotL二进制文件经常被系统管理员和高级计算机用户使用来执行（perform）系统管理任务，这使得即使是对于训练有素的分析人员来说，区分（distinguish）合法行为和恶意行为也非常困难</strong>。我们负责任地向受影响的供应商披露了我们的发现并进行跟进，因此提高了他们的检测能力。</p>
<p>尽管现有的文档提供了这些技术使用的可靠证据，但仍然不清楚这种现象在恶意软件样本中有多普遍。因此（In
this way），我们就提出了第二个研究问题：</p>
<blockquote>
<p>#### <strong>问题2：How prevalent is the use of LotL binaries in
malware?</strong></p>
<p>#### 在恶意软件中使用LotL二进制文件的情况有多普遍？</p>
</blockquote>
<p>在此基础上，我们试图阐明当前威胁情景中的一些趋势，以确定（identify）：</p>
<blockquote>
<p>#### <strong>问题3：What purposes do malware binaries use LotL
techniques for?</strong></p>
<p>#### 恶意软件的二进制文件使用LotL技术的目的是什么？</p>
<p>#### <strong>问题4：Which malware families and types use LotL
binaries most prolifically and how does their usage differ?</strong></p>
<p>####
哪些恶意软件家族和类型使用LotL二进制文件最多，它们的使用情况又有何不同？</p>
</blockquote>
<p>此外，我们还调查（investigate）了为什么这些技术难以检测。部分杀毒软件公司参与了我们的披露，即将恶意攻击与系统管理员执行完全合法的管理任务区分开来是困难的。这就给我们带来了另一个问题：</p>
<blockquote>
<p><strong>问题5：What are the overlaps and differences in the behavior
of legitimate and malicious binaries with respect to the usage of LotL
binaries? How would this affect detection by heuristic AV
engines?</strong></p>
<p>####
在使用LotL二进制文件方面，合法和恶意二进制文件的行为有哪些重叠和差异呢？这将如何影响启发式AV引擎的检测呢？</p>
</blockquote>
<p>虽然恶意样本和良性样本之间的LotL二进制使用频率（prevalence）有一些明显的差异，但我们也注意到一些类别存在某些相似性，如<strong>代理执行（proxied
execution）</strong>。</p>
<p>最后，<strong>我们将注意力集中在高逃逸和高级持续威胁的恶意软件上，我们发现它利用离地攻击技术是商用恶意软件的两倍</strong>。在表1中列出了一些使用LotL技术进行攻击的APT组织。</p>
<h4><span id="14-贡献">1.4 贡献</span></h4>
<p>据我们所知，本文提出了迄今为止对商用和APT恶意软件使用LotL技术最大规模的系统分析。本文的核心（core
）贡献：</p>
<ul>
<li>我们通过测试一组最流行的AV引擎来对抗基于LotL技术部署的恶意载荷，以评估LotL技术的可行性，并展示了离地攻击检测的复杂性对行业仍是一个挑战。<strong>即使在披露9个月后，这些技术仍没有被发现</strong>。</li>
<li>我们对代表现代商用恶意软件的几个数据集进行了大规模的评估，并确定了LotL技术的流行程度，以及在不同恶意软件家族和类型之间的差异。我们还评估了LotL技术由于假阳性风险可能对行业产生的影响。</li>
<li>我们评估了一个APT恶意软件数据集，并将其公开以促进（facilitate）后续的研究，并确定它执行LotL技术的频率是商用恶意软件的两倍。此外，我们还确定了哪些APT组织最多地使用LotL技术。</li>
</ul>
<h3><span id="二-背景和相关工作">二、背景和相关工作</span></h3>
<p>我们首先定义LotL二进制文件，并枚举恶意软件使用这些二进制文件的目的。</p>
<h4><span id="21-lotl-binaries">2.1 LotL Binaries</span></h4>
<p>近年来，“<code>Living-Off-The-Land binary（LOLbin）</code>”已经成为一个常用词，用来指在网络攻击中广泛使用的二进制文件。历史上，“Living-Off-The-Land”一直被用来表示可以为农业或狩猎提供喂养土地或离地的概念。<strong>转换为恶意软件和入侵领域，攻击者可能利用那些已经可以使用的文件（即系统上已经存在或易于安装的）来发起攻击并躲避检测。</strong></p>
<p>在本文中，我们将LotL二进制定义为：</p>
<ul>
<li><strong>任何具有公认合法用途的二进制文件，在攻击期间利用它直接执行恶意行为，或间接协助一系列恶意行动，从而达到恶意结果。</strong></li>
</ul>
<blockquote>
<p>In this paper, we define a LotL binary as any binary with a
recognised legitimate use, that is leveraged during an attack to
directly perform a malicious action; or to assist indirectly, in a
sequence of actions that have a final malicious outcome.</p>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191548420.png" alt="图片" style="zoom:50%;"></p>
<h4><span id="举例">举例：</span></h4>
<ul>
<li>在Windows系统上默认安装的二进制文件（binaries installed），如
<code>Reg.exe</code> 、<code>Sc.exe</code> 和 <code>Wmic.exe</code>
是最常被恶意软件执行的文件。</li>
<li>大多数默认安装的二进制文件都是由微软认证码签名的。认证码签名证明二进制文件没有在编译中被篡改或修改，这些二进制文件甚至可能被列为白名单。<strong>利用可信的LotL二进制文件的恶意软件可能因此避开杀毒软件</strong>。在Windows系统上使用系统二进制文件可以作为恶意软件操作的一部分，更重要的是，许多LotL技术使用系统二进制文件来实现这些二进制文件的目的。</li>
<li>此外，可以使用外部签名二进制文件（external signed binaries），如
<code>PsExec.exe</code>
或其他系统内部二进制文件。虽然它们使用频率不高，但本文的分析也囊括了这些文件。<strong>如APT组织在
<code>SoftCell</code> 和 <code>Havex</code> 中都使用
<code>PsExec.exe</code>
来秘密执行远程命令，从而实现网络中的横向移动。</strong></li>
<li>某些罕见情况，脆弱的（已签名）驱动程序被用来升级系统上的权限。这是
<code>RobbinHood</code> 勒索软件和各种 <code>APT wiper</code>
恶意软件样本所使用的一种技术，针对 <code>Saudi Arabian</code> 系统，包括
<code>Dustman</code> 、<code>Shamoon</code> 和
<code>Zerocleare</code>。</li>
</ul>
<h4><span id="可追溯性traceability"><strong>可追溯性（Traceability）：</strong></span></h4>
<ul>
<li>某些LotL二进制文件可能会比其他文件留下更多的系统日志，安全工具或取证分析人员可以利用这些日志来检测恶意操作。<strong>例如，可以将Powershell配置为具有全面的日志记录</strong>。</li>
<li>微软甚至建议<strong>阻止在系统上执行一些本机的二进制文件</strong>，除非有充分的理由。</li>
</ul>
<h4><span id="22-scope-of-our-study">2.2 Scope of our Study</span></h4>
<p>在本文中，我们关注的是Windows恶意软件执行系统二进制文件的目的。这些目的通常包括沿着
<strong>kill
chain</strong>的进展或逃避AV的检测。所有这些技术都被部署在系统的用户空间中。</p>
<p><code>hollowing</code> 和 <code>injection（注入）</code>
不在我们的研究范围内，尽管这是无文件恶意软件部署的常见技术。因为根据我们早期的定义，它们不是LotL技术。</p>
<h4><span id="23-related-work">2.3 Related Work</span></h4>
<blockquote>
<p>离地攻击相关工作较少，并且都非常经典，因此下面罗列了详细的相关研究，仅供自己后续深入，也希望对您有所帮助。</p>
</blockquote>
<ul>
<li>LotL恶意软件及其别名，“advanced volatile
threat”或“无文件”恶意软件在当前的学术文献中很少被提及。这主要受限于介绍分析少或描述为一个新兴的高逃逸恶意软件变体。</li>
<li>Li等[31]对恶意PowerShell脚本进行了分析，其中有一个小节专门描述了LotL攻击和无文件攻击作为近年来网络攻击的趋势。（<strong>作者第17篇博客详细介绍过PS经典</strong>）</li>
<li>Wang等[72]最近发表的一篇关于数据来源分析的论文指出，Living-Off-The-Land
是一种新兴的、突出的逃避型恶意软件子类（evasive malware
subtype）。（<strong>经典的You Are What You
Do后续即将分享</strong>）</li>
<li>先前的工作[64]进行了介绍性分析，然而LotL恶意软件还没有受到详细的学术分析。（An
emerging threat Fileless malware: a survey and research
challenges）</li>
<li><strong>赛门铁克</strong>[73,66]和<strong>思科Talos</strong>的[65]白皮书介绍了这个主题，并对多个数据集的流行性进行了分析。目前，没有论文对包含多个使用LotL技术的Windows恶意软件数据集进行大规模地系统分析。（<strong>经典</strong>）
<ul>
<li>https://www.symantec.com/content/dam/symantec/docs/security-center/white-papers/istr-living-off-the-land-and-fileless-attack-techniques-en.pdf</li>
<li>https://www.symantec.com/content/dam/symantec/docs/white-papers/living-off-the-land-turning-your-infrastructure-against-you-en.pdf</li>
<li>https://blog.talosintelligence.com/2019/11/hunting-for-lolbins.html</li>
</ul></li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191548029.png" alt="图片" style="zoom:50%;"></p>
<p>在一些论文中提到了LotL技术，强调了高隐蔽（stealthiness）和APT恶意软件曾使用。</p>
<ul>
<li><p>在一篇关于恶意软件分析工具Yara的论文中，Cohen[9]将LotL描述 “ LotL
as a trend that has been recently observed in the tactics used by elite
threat actors”，我们的分析结果进一步证实了该说法。</p></li>
<li><p>Hassan等[21]的研究表明，APT恶意软件使用LotL攻击策略来实现持续攻击并分析了两个活动，他们的工作还利用了MITRE
ATT&amp;CK框架[45]，通过MITRE定义了一个描述和分类知名攻击的分类方法。<strong>许多LotL技术在MITRE
ATT&amp;CK框架内被索引</strong>。Mitre公司及其常见CVE漏洞是安全领域的既定权威，他们囊括并描述许多LotL技术，这样表明离地攻击是一个值得深入分析的课题。</p></li>
<li><ul>
<li><strong>W. U. Hassan, A. Bates, and D. Marino, “Tactical Provenance
Analysis for Endpoint Detection and Response Systems,” IEEE Symposium on
Security and Privacy, 2020.</strong></li>
</ul></li>
</ul>
<p><strong>强烈推荐一个包含LotL二进制和ATT&amp;CK功能映射的资源</strong>：</p>
<ul>
<li>https://github.com/LOLBAS-Project/LOLBAS</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191548854.png" alt="图片" style="zoom:50%;"></p>
<p>与我们研究相关的是对基于脚本的恶意软件分析和去混淆。使用LotL技术的恶意软件经常使用恶意脚本作为有效负载。（<strong>下列论文在作者第16篇PowerShell总结博客中详细介绍过</strong>）</p>
<ul>
<li>Ugarte等[67]通过识别可疑行为模式，测试了经
<code>Powershell.exe</code> 二进制调用的恶意脚本。</li>
<li><strong>Rubin等[61]将机器学习应用于检测PowerShell恶意软件（微软团队）</strong>。</li>
<li>Curtsinger[11]等人提出了恶意Javascript攻击的检测机制——ZOZZLE。</li>
</ul>
<p><strong>虽然这些论文提出了有效的检测方法，但是他们都是为狭隘的恶意载荷（payload）所用，他们没有分析更广泛的恶意软件生态系统和这些有效载荷是如何被LotL二进制文件触发的。</strong></p>
<h3><span id="三-动机">三、动机</span></h3>
<p><strong>安全研究人员已经记录了许多使用LotL技术成功躲避安全产品的案例</strong>。在许多情况下，这些<strong>LotL二进制文件被用来代理恶意载荷的执行，使其在一个合法的进程上下文中执行，或者作为一个合法系统进程的子进程生成一个新进程</strong>。在某些情况下，这些有效载荷作为LotL二进制调用的副作用被执行，而在其他情况下，它只是其主要记录行为的结果。此外，许多杀毒产品未能正确检测到这些技术。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191548198.png" alt="图片" style="zoom:50%;"></p>
<p><strong>为了回答第一个问题，我们首先分析了当前AV产品是否将LotL技术作为恶意行为的指标。</strong></p>
<p>为此，我们首先选择了10个具有代表性的AV产品（详见附录C），并利用常见<strong>基于LotL的代理执行技术来实施反弹Shell的模拟攻击</strong>。此外，本研究的目的不是测试任何特定AV产品的检测能力或将它们相互比较，而是确定是否存在普遍的检测差距。</p>
<ul>
<li>实验在联网的Windows
10虚拟机执行，并将最新的本地AV产品连接到它们的云组件。</li>
<li>利用一个反弹Shell来评估AV系统在部署LotL技术的恶意软件中有多脆弱。本文认为能够允许远程执行命令的reverse
shell是成功执行代码的证明，这与许多远程访问木马（RAT）功能相同。</li>
<li>通过从不同LotL二进制文件中运行这个反弹shell来进行实验，以测试AV产品是否检测到离地攻击技术是恶意的。</li>
<li>我们在必要时混淆了反弹shell的有效载荷，并使用各种有效载荷类型来测试AV检测传递机制本身的能力，而不是通过静态签名传递的特定有效载荷（详见附录D）。</li>
</ul>
<h4><span id="实验结果如表2所示">实验结果如表2所示：</span></h4>
<ul>
<li><strong>可以发现大部分的AV引擎允许我们建立一个反弹Shell并执行命令，它们并没有检测出利用LotL技术的恶意软件，60个中只检测出4个。</strong></li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191549745.png" alt="图片" style="zoom:50%;"></p>
<h4><span id="负责任的披露和回应">负责任的披露和回应：</span></h4>
<p>此后，我们向相关的AV供应商发布了一份文件，包含我们检查的结果并协助补救。9个月后，我们在Windows
10机器上重复了类似的测试，这允许我们测试AV供应商是否在他们的产品中包含了新的启发式规则来检测LotL二进制的使用。其结果如下：</p>
<ul>
<li><strong>可以发现在60个相同的有效载荷中检测到了25个</strong></li>
<li>在检测到的反弹shell测试中，我们修改了载荷（利用混淆或运行不同的载荷），同时为LotL二进制文件保持了完全相同的命令行参数，通过利用这些混淆和修改的有效载荷，我们成功地在这25个被拦截的实例中的19个执行了一个反向shell。</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191549539.png" alt="图片" style="zoom:50%;"></p>
<p><strong>实验结果表明，LotL技术仍然是杀毒软件供应商面临的一个重大挑战。合法用户通常以不可预知的方式使用这些工具，而安全公司很难在没有误报的情况下部署有效的检测策略。</strong></p>
<p>接下来将展示这些技术如何在商用恶意软件中是普遍存在的，以及离地攻击是不应该被安全社区忽视的问题。</p>
<h3><span id="四-离地攻击流行性评估">四、离地攻击流行性评估</span></h3>
<p>在本节中，我们测量了恶意软件中LotL技术的流行程度，并试图回答所提出的研究问题。</p>
<h4><span id="41-数据集描述">4.1 数据集描述</span></h4>
<p>评估工作是在9个独立的子数据集上进行的。我们总共收集了31,805,549个样本，其中我们从VirusTotal（VT）中获得了16,048,202份行为报告。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191549136.png" alt="图片" style="zoom:50%;"></p>
<p><strong>Public Datasets</strong></p>
<p>公共恶意软件数据集，包括商用恶意软件、VirusShare语料库的二进制文件、窗口恶意PE文件、佐治亚理工学院发布的可执行文件、VX-Mumbal和MalShare共享的样本（两个重点的共有数据集）。</p>
<ul>
<li>https://impactcybertrust.org/dataset{ }view?idDataset=1143</li>
<li>https://vx-underground.org/samples.html</li>
<li>https://malshare.com</li>
</ul>
<p><strong>VirusTotal Balanced Dataset</strong></p>
<p>从VT中收集了237,288个hash值，利用 <code>AVClass</code>
预处理代码和打标签（家族分类），并平衡数据集中每个族。</p>
<p><strong>APT Malware</strong></p>
<p>我们根据一种类似于数据集论文dAPTaset[59]的方法收集了一个APT恶意软件的数据集。我们处理了HTML页面和pdf文件（<code>APTnotes</code>），并提取了这些文件中包含的所有恶意软件的hash值。</p>
<ul>
<li>https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-rezaeirad.pdf</li>
<li>https://github.com/aptnotes/data</li>
</ul>
<p><strong>Yara Rule Match Malware</strong></p>
<p>部署3个Yara规则来检测LotL二进制文件，并使用Livehunte来识别上传到VT的新的恶意软件hash，并使用LotL技术匹配恶意软件的行为特征。</p>
<h4><span id="42-analysis-pipeline">4.2 Analysis Pipeline</span></h4>
<p>当收集了由Windows
PE二进制文件组成的不同数据集，我们就分析样本的行为。包括三个阶段：</p>
<ul>
<li>data collection</li>
<li>data augmentation</li>
<li>data analysis</li>
</ul>
<blockquote>
<p>First Seen：首次发现病毒样本的时间戳 AVClass
Family：某恶意软件样本所属家族 <strong>Behavioural
Report：恶意行为报告，由特定恶意软件样本执行的进程和Shell命令的列表</strong></p>
</blockquote>
<h4><span id="43-lotl-techniqueidentification">4.3 LotL Technique
Identification</span></h4>
<p><strong>数据准备就绪，那么如何识别是否使用了LotL技术呢？</strong></p>
<p>我们使用<strong>模式匹配</strong>来识别恶意软件执行过程中对LotL二进制文件调用的情况，从而处理所有收集到的行为报告（<code>behavioural reports</code>）。行为报告包括两个指标：</p>
<ul>
<li><p><strong>Shell Commands（Shell命令）</strong></p>
<p><strong>恶意二进制文件在主机操作系统中执行的Shell命令</strong>，Shell命令日志可以通过引用系统二进制文件的绝对路径来显示它的执行情况。<strong>同时，Windows的命令提示符还包括许多别名，例如Reg.exe的reg</strong>。</p></li>
<li><p><strong>Processes（进程）</strong></p>
<p><strong>进程日志明确由恶意软件样本执行的系统二进制文件</strong>。执行的参数也包含在行为报告中的进程日志中。</p></li>
</ul>
<p>在我们的分析中，如果一个样本的行为报告包含至少一个LotL二进制文件的执行，那么它使用了LotL技术。<strong>我们记录了每一个LotL的执行及其参数细节，并将它们插入到数据库中。然后，我们分析了这些恶意软件样本的参数，以确定每个数据集中最常见的参数类型和执行目的。</strong></p>
<p>具体而言，我们确定了这两种独立类型的二进制文件：</p>
<ul>
<li><strong>Default System Binaries</strong></li>
<li><strong>Installed Signed Binaries</strong></li>
</ul>
<p>模式匹配优化：模式匹配方法在不断改进，直到所有识别的LotL命令被正确分类和映射到执行目的，并进行了数据清洗处理。</p>
<ul>
<li>不带参数的二进制执行移除</li>
<li>沙箱产物删除（如Explorer.exe和sha256），Web访问不处理</li>
<li>删除Verclsid.exe的实例</li>
</ul>
<h4><span id="44-parameteranalysis-to-identify-execution-purpose">4.4 Parameter
Analysis to Identify Execution Purpose</span></h4>
<p><strong>为了确定LotL技术的执行目的，我们观察了恶意软件样本提供的参数。</strong></p>
<p>图1说明了四个进程执行的映射。该映射通过识别单独的执行目的来在所有数据集上实施，<strong>例如执行Net.exe时使用stop参数表示任务停止。在将单个命令映射到执行目的之后，我们将为该二进制文件选择所有匹配的执行</strong>。我们在所有系统二进制执行中重复该步骤，直到每次执行被分类为属于特定的执行目的或被错误分类。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191549986.png" alt="图片" style="zoom:50%;"></p>
<p>按照这种方法，我们按目的将参数分为9个独立的类别。</p>
<p><strong>首先是三种与执行有关的类型：</strong></p>
<ul>
<li><strong>Proxied
Execution</strong>：代理执行，如Mshta.exe执行.hta文件，Rundll32.exe执行.dll文件</li>
<li><strong>Persistence</strong>：持久化：如果恶意代码配置或修改系统以在未来某个时间点执行命令或存储的作业，那么它就实现了持久性，比如Sc.exe带有创建参数的Bitsadmin.exe，或带有日期时间参数的Schtasks.exe/At.exe</li>
<li><strong>Delayed Execution</strong>：延迟执行，比如
Ping.exe执行-n</li>
</ul>
<p><strong>接着是三类与底层系统组件的修改有关。恶意软件通常从事这种行为，以便在机器上对目标进行进一步的传播或行动。</strong></p>
<ul>
<li><strong>Firewall Modification</strong>：防火墙修改，如Netsh.exe</li>
<li><strong>Registry Modification</strong>：注册表修改，如Reg.exe</li>
<li><strong>Permissions
Modification</strong>：权限修改，如Cacls.exe修改文件权限</li>
</ul>
<p><strong>最后是与执行或系统修改无关的三类。</strong></p>
<ul>
<li><strong>File Opening</strong>：打开文件，如Explorer.exe</li>
<li><strong>Reconnaissance</strong>：侦察，触发本地或远程配置的横向移动，如Net.exe</li>
<li><strong>Task
Stopping</strong>：使用LotL二进制文件秘密停止另一个进程或服务，如Taskkill.exe</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（5）BODMAS-An Open Dataset for Learning based Temporal Analysis of PE Malware</title>
    <url>/posts/1KY76QV/</url>
    <content><![CDATA[<h3><span id="bodmasan-open-dataset-for-learning-based-temporal-analysis-of-pe-malware">BODMAS:
An Open Dataset for Learning based Temporal Analysis of PE Malware</span></h3>
<blockquote>
<p>2021 <a href="https://dblp.uni-trier.de/db/conf/sp/sp2021w.html#YangCLA021">SP
Workshops</a></p>
<p>On training robust PDF malware classifiers. (2020 USENIX)</p>
</blockquote>
<h3><span id="一-摘要">一、摘要</span></h3>
<p>我们描述并发布了一个名为BODMAS的开放PE恶意软件数据集，以促进基于机器学习的恶意软件分析的研究工作。通过仔细检查现有的open
PE恶意软件数据集，我们发现了两个缺失的功能（即<strong>最近/时间戳</strong>的恶意软件样本和精心策划的<strong>家族信息</strong>），这限制了研究人员研究<strong>概念漂移和恶意软件系列演化</strong>等紧迫问题的能力。出于这些原因，我们发布了一个新的数据集来填补空白。<strong>BODMAS数据集包含从2019年8月至2020年9月收集的57293个恶意软件样本和77142个良性样本，以及精心策划的家族信息（581个家族）</strong>。我们还进行了初步分析，以说明概念漂移的影响，并讨论该数据集如何有助于促进现有和未来的研究工作。</p>
<h3><span id="二-说明">二、说明</span></h3>
<p>如今，研究人员[30]、[5]、[11]、[6]和反病毒供应商[1]将机器学习模型（包括深度神经网络）广泛应用于恶意软件分析任务中。在这一工作领域，拥有公共数据集和开放基准是非常可取的。一方面，这些数据集将有助于促进解决开放性挑战的新工作（例如，对抗性机器学习、可解释技术[28]、[10]）。另一方面，公共基准和数据集可以帮助研究人员轻松地比较他们的模型，并跟踪整个社区的进展。然而，创建开放式恶意软件数据集是一项极具挑战性的工作。例如，[5]的作者讨论了许多此类挑战，包括<strong>法律限制、标记恶意软件样本的成本和难度，以及潜在的安全责任</strong>。除了这些因素外，另一个关键挑战是恶意软件（以及良性软件）的动态演化性质[20]。随着时间的推移，新的恶意软件系列和变种不断出现，它们不断地对底层数据分布进行更改。因此，随着时间的推移，不断需要发布新的数据集和基准。在过去的十年中，只有少数公开的PE恶意软件数据集发布到研究社区[30]。值得注意的例子包括Microsoft恶意软件分类挑战数据集[24]、Ember[5]、<strong>UCSB打包恶意软件数据集[2]</strong>和最近的SOREL-20M数据集[11]。我们在表一中总结了它们的主要特征。</p>
<blockquote>
<p>[30] Survey of machine learning techniques for malware analysis.
(2019 C&amp;S)</p>
<p>[5] Ember: an open dataset for training static pe malware machine
learning models</p>
<p>[11] SOREL-20M: A Large Scale Benchmark Dataset for Malicious PE
Detection</p>
<p><strong>[6] Scalable, behavior-based malware clustering (2009
NDSS)</strong></p>
<p><strong>[28] Exploring backdoor poisoning attacks against malware
classifiers</strong></p>
<p><strong>[10] Maldae: Detecting and explaining malware based on
correlation and fusion of static and dynamic characteristics. (2019
C&amp;S)</strong></p>
<p>[20]</p>
</blockquote>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（10）Dos and Don&#39;ts of Machine Learning in Computer Security</title>
    <url>/posts/21HN90E/</url>
    <content><![CDATA[<h2><span id="dos-anddonts-of-machine-learning-in-computer-security">Dos and
Don'ts of Machine Learning in Computer Security</span></h2>
<blockquote>
<p>改github的主页信息</p>
<p>USENIX Security
'22：https://www.usenix.org/conference/usenixsecurity22/presentation/arp</p>
<p><strong>Why not（ ? ）Use AI in Cyber Security</strong></p>
</blockquote>
<h3><span id="摘要">摘要</span></h3>
<p><strong>随着计算系统处理能力的不断增强和海量数据集的日益可用，机器学习算法在许多不同领域取得了重大突破</strong>。这一发展影响了计算机安全，催生了一系列基于机器学习的安全系统的工作，例如<strong>恶意软件检测、漏洞发现和二进制代码分析</strong>。尽管机器学习在安全领域有着巨大的潜力，但它容易出现一些微妙的缺陷，这些缺陷会破坏其性能，并使基于学习的系统可能不适合安全任务和实际部署。</p>
<p>在本文中，我们用批判的眼光看待这个问题。首先，我们确定了基于学习的安全系统的设计、实现和评估中的常见陷阱。我们对过去10年中顶级安全会议上的30篇论文进行了研究，确认这些缺陷在当前安全文献中普遍存在。在实证分析中，我们进一步证明了个别陷阱如何导致不切实际的表现和解释，阻碍对当前安全问题的理解。作为补救措施，我们提出了可行的建议，以支持研究人员在可能的情况下避免或减轻陷阱。此外，我们发现了将机器学习应用于安全时存在的问题，并为进一步的研究提供了方向。</p>
<h3><span id="一-说明">一、说明</span></h3>
<p><strong>没有一天不阅读机器学习的成功故事</strong>。对专业计算资源和大型数据集的广泛访问，以及用于深度学习的新概念和架构，为机器学习在几个领域的突破铺平了道路，例如自然语言的翻译[13，31，125]和图像内容的识别[62，78，117]。这一发展自然影响了安全研究：虽然过去主要局限于特定应用[53、54、132]，但机器学习现在已成为研究和解决多个应用领域中普遍存在的安全相关问题的关键促成因素之一，包括<strong>入侵检测</strong>[43、93]、<strong>恶意软件分析</strong>[69、88]、<strong>漏洞发现</strong>[83、142]，和<strong>二进制代码分析</strong>[42、114、140]。</p>
<p>然而，机器学习没有洞察力，需要在相当精细的工作流程中对数据的统计特性进行推理：错误的假设和实验偏见可能会对这一过程产生怀疑，以至于不清楚我们是否可以信任使用学习算法得出的科学发现[56]。<strong>二十年前[11、119、126]开始尝试识别特定安全领域（如网络入侵检测）中的挑战和限制，最近扩展到其他领域，如恶意软件分析和网站指纹识别[3、72、104、112]</strong>。然而，与这项工作垂直的是，我们认为存在与机器学习相关的一般陷阱，这些陷阱影响所有安全领域，迄今为止几乎没有受到关注。<strong>这些缺陷可能导致结果过于乐观，甚至影响整个机器学习工作流，削弱假设、结论和经验教训</strong>。因此，人们感觉到一种虚假的成就感，阻碍了学术界和工业界采用研究进展。健全的科学方法是支持直觉和得出结论的基础。我们认为，这一需求在安全性方面尤其重要，在安全性领域，过程往往受到积极绕过分析并破坏系统的对手的破坏。</p>
<p><strong>在本文中，我们确定了十个常见但微妙的陷阱，这些陷阱对研究结果的有效性构成威胁，并阻碍了对其的解释。</strong>为了支持这一说法，我们分析了过去十年中30篇依靠机器学习解决不同问题的顶级安全论文中这些陷阱的普遍性。令我们惊讶的是，每篇论文至少有三个陷阱；更糟糕的是，有几个陷阱影响了大多数论文，这表明这个问题是多么普遍和微妙。尽管这些陷阱很普遍，但了解它们在多大程度上削弱了结果并导致过于乐观的结论可能更为重要。最后我们对四个不同安全领域中的陷阱进行了影响分析。这些发现支持了我们的假设，回应了社区更广泛的关注。</p>
<h4><span id="贡献">贡献：</span></h4>
<ul>
<li><strong>陷阱识别</strong>。我们确定了机器学习在安全性方面的十个陷阱，并提出了可行的建议，以支持研究人员尽可能避免这些陷阱。此外，要确定无法轻松缓解的开放性问题，需要进一步研究。</li>
<li><strong>流行率分析</strong>。我们分析了在过去十年中发表的30份具有代表性的顶级证券报纸中发现的陷阱的普遍性。此外，我们进行了一项广泛的调查，其中我们获得并评估了这些论文作者关于已识别缺陷的反馈。</li>
<li><strong>影响分析</strong>。在四个不同的安全领域，我们通过实验分析了此类缺陷在多大程度上导致了实验偏差，以及我们如何通过应用建议的建议来有效克服这些问题。</li>
</ul>
<blockquote>
<p><strong>评论</strong> :
这项工作不应被解释为指手画脚的练习。相反，这是一种反思性的努力，表明了微妙的陷阱会对安全研究的进展产生多大的负面影响，以及我们作为一个社区如何充分缓解它们。</p>
</blockquote>
<h3><span id="二-机器学习中的陷阱">二、机器学习中的陷阱</span></h3>
<p>尽管机器学习取得了巨大的成功，但在实践中应用机器学习通常并不简单，而且容易出现一些缺陷，从明显的缺陷到微小的瑕疵。<strong>忽视这些问题可能会导致实验偏差或错误结论，尤其是在计算机安全方面。</strong>在本节中，我们介绍了在security
research中经常出现的十个常见陷阱。虽然这些陷阱乍一看似乎显而易见，但它们根源于安全研究中普遍存在的细微缺陷，甚至在ATOP会议上发表的论文中也是如此。</p>
<p>我们根据典型机器学习工作流的各个阶段对这些缺陷进行分类，如图1所示。对于每个缺陷，我们提供了简短的描述，讨论了其对安全领域的影响，并提出了建议。此外，彩色条显示了我们分析中遭受陷阱的论文比例，较暖的颜色表示存在陷阱（见图3）</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550030.png" alt="image-20220804131643885">
<figcaption aria-hidden="true">image-20220804131643885</figcaption>
</figure>
<h3><span id="21-数据收集与标记">2.1 数据收集与标记</span></h3>
<p>基于学习的系统的设计和开发通常从获取代表性数据集开始。显然，使用不切实际的数据进行实验会导致错误估计方法的能力。以下两个陷阱经常导致这个问题，因此在开发基于学习的计算机安全系统时需要特别注意。</p>
<h4><span id="221-sampling-bias-样本偏差1">2.2.1 Sampling Bias ：
样本偏差（1）</span></h4>
<p>收集的数据不足以代表潜在安全问题的真实数据分布。</p>
<p><strong>描述</strong>：除了少数例外，研究人员开发基于学习的方法时没有确切了解输入空间的真实潜在分布。相反，他们需要依赖于包含固定数量样本的数据集，这些样本旨在与实际分布相似。虽然在大多数情况下不可避免地存在一些偏见，但理解特定问题固有的特定偏见对于限制其在实践中的影响至关重要。如果数据不能有效地表示输入空间，甚至不能遵循不同的分布，那么从训练数据中得出有意义的结论就变得很有挑战性。</p>
<p><strong>安全影响</strong>：<strong>采样偏差与安全高度相关，因为数据采集尤其具有挑战性</strong>，通常需要使用多个质量不同的源。例如，对于用于Android恶意软件检测的合适数据集的收集，只有少数公共来源可用于获取此类数据[6,
134]。因此，依赖合成数据或组合来自不同来源的数据是常见的做法，正如我们在第4节中通过最先进的入侵和恶意软件检测方法的例子所证明的那样，这两种方法都会引入偏差。</p>
<p><strong>建议</strong>：在许多安全应用程序中，从真实分布中采样极其困难，有时甚至不可能。因此，这种偏差通常只能得到缓解，但不能完全消除。在§4中，我们表明，<strong>在某些情况下，一个合理的策略是构造真实分布的差分集并对其进行单独分析。进一步的策略包括使用合成数据扩展数据集</strong>[例如，28，60，137]或使用转移学习[See99，135，145，147]。然而，应避免来自不兼容源的数据混合，因为这是额外偏差的常见原因。无论如何，应该公开讨论所用数据集的局限性，让其他研究人员更好地理解潜在采样偏差的安全含义。</p>
<h4><span id="221-labelinaccuracy标签不准确2">2.2.1 Label
Inaccuracy：标签不准确（2）</span></h4>
<p>分类任务所需的地面真实值标签不准确、不稳定或错误，影响基于学习的系统的整体性能[85，144]</p>
<p><strong>描述</strong>：许多基于AI的安全系统是为分类任务而构建的。为了训练这些系统，每次观测都需要一个
<strong>ground-truth</strong>
label。不幸的是，这种标记很少是完美的，研究人员必须考虑不确定性和噪声，以防止他们的模型受到固有偏差的影响。</p>
<p><strong>安全影响</strong>：对于许多相关的安全问题，如检测网络攻击或恶意软件，通常无法获得可靠的标签，从而导致鸡和蛋的问题。作为补救措施，研究人员通常采用启发式方法，例如使用无法提供可靠基础真相的外部来源。例如，像
virustotal
这样的服务通常用于获取恶意软件的标签信息，但这些服务并不总是一致的[144]。此外，随着时间的推移，对手行为的改变可能会改变不同等级之间的比例[3,92，144]，引入一种称为<strong>标签偏移的偏差</strong>[85]。无法适应这些变化的系统一旦部署，性能将下降。</p>
<p><strong>建议</strong>：通常，应尽可能验证标签，例如，通过手动调查假阳性或随机样本[例如，122]。如果不排除噪声，则可以通过（i）使用稳健模型或损失函数，（ii）<strong>在学习过程中积极建模标签噪声</strong>，或（iii）清除训练数据中的噪声标签来减少其对学习模型的影响[见55,67,84]。为了证明这些方法的适用性，我们主要采用附录a中的清理方法。请注意，标签不确定的实例不得从测试数据中删除。这代表了采样偏差（P1）和数据窥探（P3）的变化，这是我们在§2.2中详细讨论的一个陷阱。由于标签可能会随时间变化，因此有必要采取预防措施，防止标签移动[85]，例如延迟标签，直到获得稳定的地面真相为止[见144]。</p>
<h3><span id="22-系统设计和学习">2.2 系统设计和学习</span></h3>
<p>一旦收集到足够的数据，就可以训练基于学习的安全系统。<strong>这个过程包括从数据预处理到提取有意义的特征和建立有效的学习模型</strong>。不幸的是，这些步骤中的每一步都可能引入缺陷和弱点。</p>
<h4><span id="221-data-snooping数据窥探3">2.2.1 Data Snooping：数据窥探（3）</span></h4>
<p><strong>学习模型是用实践中通常不可用的数据训练的。数据窥探可以以多种方式发生，其中一些非常细微，难以识别[1]。</strong></p>
<p><strong>描述</strong>：在生成学习模型之前，通常将收集的数据拆分为单独的训练集和测试集。虽然分割数据似乎很简单，但测试数据或其他通常不可用的背景信息有许多微妙的方式可以影响训练过程，从而导致数据窥探。<strong>虽然附录中提供了数据监听示例的详细列表（见表8</strong>），但我们大致区分了三种类型的数据监听：测试、临时和选择性监听。<strong>当测试集用于最终评估之前的实验时，会发生测试窥探</strong>。这包括识别有用特征、参数和学习算法的准备工作。<strong>如果忽略数据中的时间依赖性，则会发生时间监听</strong>。这是一个常见的陷阱，<strong>因为许多与安全相关的问题的潜在分布都处于不断变化的状态</strong>[例如，87，104]。最后，选择性监听描述了基于实践中不可用的信息清理数据。一个例子是基于完整数据集（即，训练和测试）的统计数据删除外部LIER，这些数据集通常在训练时不可用。</p>
<p><strong>安全影响</strong>：在安全方面，由于新的攻击或技术，数据分布是非平稳的，并且不断变化。因此，窥探未来或外部数据源的数据是一种普遍现象，导致结果过于乐观。例如，一些研究人员已经在基于学习的恶意软件检测系统中发现了时间窥探[4,8,104]。在所有这些情况下，由于混合了过去和现在的样本，这些方法的能力被高估。同样，在安全研究中也存在测试和选择性窥探事件，导致结果出现无意偏差（见§3）。</p>
<p><strong>建议</strong>：虽然训练、验证和测试数据应该严格分开似乎很明显，但在预处理阶段，这种数据隔离往往会被无意中违反。<strong>例如，我们观察到，在整个数据集上计算tf-idf权重或神经嵌入是一个常见错误</strong>（见§3）。为了避免这个问题，测试数据应该在数据收集期间尽早分割，并单独存储，直到最终评估。<strong>此外，在创建数据时，应考虑数据内的时间依赖性,数据集被拆分</strong>[4，87，104]。然而，其他类型的数据窥探很难解决。例如，随着公开数据集的特征日益暴露，使用该数据开发的方法隐含地从测试数据中获取年龄知识[见1，90]。<strong>因此，对知名数据集的实验应与对来自考虑适应应用领域的较新数据的实验相补充。</strong></p>
<h4><span id="222-spuriouscorrelations假相关性4">2.2.2 Spurious
Correlations：假相关性（4）</span></h4>
<p><strong>与安全问题无关的工件创建了用于分类的快捷模式。因此，学习模型适应这些工件，而不是解决实际任务</strong>；</p>
<p><strong>描述</strong>：伪相关性是由与要解决的任务相关但实际上与之无关的产生的，从而导致错误关联。考虑一个网络入侵检测系统的例子，其中数据集中的大部分攻击来自某个网络区域。该模型可以学习检测特定IP范围而不是一般攻击模式。请注意，虽然抽样偏差是产生虚假相关性的常见原因，但这些偏差也是由其他因素造成的，我们在附录a.对此进行了更详细的讨论</p>
<p><strong>安全影响</strong>：<strong>机器学习通常应用于安全领域的黑盒。因此，虚假的相关性往往无法确定。一旦结果被解释并用于得出一般结论，这些相关性就会带来问题</strong>。如果不知道虚假相关性，则存在高估方法能力和误判其实际局限性的高风险。例如，§4.2报告了我们对漏洞发现系统的分析，表明基础数据中存在明显的虚假相关性。</p>
<p><strong>建议</strong>：<strong>为了更好地了解基于学习的系统的能力，我们通常建议应用机器学习的解释技术</strong>[见59、79、133]。尽管存在一些限制[例如，66，75127]，这些技术可以揭示虚假的相关性，并允许从业者评估其对系统能力的影响。作为一个例子，我们在§4中展示了不同安全相关问题的可解释学习如何有助于识别该问题。请注意，根据基于学习的系统的目标，一种设置中的虚假相关性可能被视为另一种设置的有效信号。因此，我们建议提前明确定义该目标，并验证系统学习的相关性是否符合该目标。例如，一个强大的恶意软件检测系统应该检测与恶意活动相关的特征，而不是数据中存在的其他无关信息</p>
<h4><span id="223-biased-parameterselection-有偏参数选择5">2.2.3 Biased Parameter
Selection ：有偏参数选择（5）</span></h4>
<p><strong>基于学习的方法的最终参数在训练时并不完全固定。相反，它们间接依赖于测试集</strong>。</p>
<p><strong>描述</strong>：在整个学习过程中，通常通过改变参数生成不同的模型。选择性能最佳的模型，并给出其在测试集上的性能。虽然这种设置通常是合理的，但它仍然会受到参数选择偏差的影响。<strong>例如，通过调整超参数或校准测试数据（而不是训练数据）上的阈值，可以很容易产生过于乐观的结果。</strong></p>
<p><strong>安全影响</strong>：参数在训练时未完全校准的安全系统在现实环境中的性能可能会有所不同。<strong>虽然网络入侵检测系统的检测阈值可以使用测试集上获得的ROC曲线来确定，但由于现实世界流量的多样性，在实践中很难选择相同的操作点</strong>[119]。与原始实验设置相比，这可能导致系统性能下降。请注意，此陷阱与数据窥探（P3）有关，但应明确考虑，因为它很容易导致夸大的结果。</p>
<p><strong>建议</strong>：这种陷阱构成了数据窥探的一种特殊情况，因此适用相同的对策。然而，在实践中，通过使用分离的评估集进行模型选择和参数调整，可以很容易地固定有偏差的参数选择。与通常难以缓解的一般数据窥探相比，严格的数据隔离已经足以排除确定超参数和阈值时的问题。</p>
<h3><span id="23-performance-evaluation">2.3 Performance Evaluation</span></h3>
<p><strong>性能评估典</strong>型机器学习工作流的下一个阶段是系统性能评估。在下文中，我们将展示不同的陷阱如何在评估此类系统时导致不公平的比较和有偏见的结果。</p>
<h4><span id="231-inappropriatebaseline-不适当的基线6">2.3.1 Inappropriate
Baseline: 不适当的基线（6）</span></h4>
<p>评估不使用或使用有限的基线方法进行。结果是，不可能证明对现有技术和其他安全机制的改进;</p>
<p><strong>描述</strong>:为了说明一种新方法在多大程度上提高了技术水平，将其与先前提出的方法进行比较至关重要。在选择基线时，重要的是要记住，不存在优于一般[136]中所有其他方法的通用学习算法。因此，仅提供所提出方法的结果或与基本相同的学习模型进行比较，并没有提供足够的背景来评估其影响。</p>
<p><strong>安全影响</strong>：<strong>过于复杂的学习方法会增加过度拟合的可能性，还会增加运行时开销、攻击面以及部署的时间和成本</strong>。为了证明与传统方法相比，机器学习技术提供了显著的改进，因此有必要对这些系统进行并排比较。</p>
<p><strong>推荐</strong>：在整个评估过程中，应考虑简单模型，而不是仅仅关注复杂模型进行比较。<strong>这些方法易于解释，计算要求较低，并且在实践中证明是有效的和可扩展的</strong>。在第4节中，我们演示了如何使用易于理解的简单模型作为基线来解释不必要的复杂学习模型。类似地，我们表明自动机器学习（AutoML）框架工作[例如，48,70]有助于找到合适的基线。虽然这些自动化方法肯定不能取代经验丰富的数据分析师，但它们可以用来设定所提出方法应达到的下限。最后，检查非学习方法是否也适用于应用场景是至关重要的。<strong>例如，对于入侵和恶意软件检测，存在多种使用其他检测策略的方法[例如，45、102、111]</strong>。</p>
<h4><span id="232inappropriate-performance-measures不适当的性能衡量标准7">2.3.2
Inappropriate Performance Measures：不适当的性能衡量标准（7）</span></h4>
<p><strong>精选的性能度量没有考虑到应用场景的限制，例如数据不平衡或需要保持较低的误报率。</strong></p>
<p><strong>描述</strong>：可提供范围广泛的性能指标，但并非所有这些指标都适用于安全环境。例如，在评估检测系统时，仅报告一个性能值（如精度）通常是不够的，因为真阳性和假阳性判断是不可观察的。然而，更先进的测量方法，如ROC曲线，在某些应用环境中可能会模糊实验结果。图2显示了不平衡数据集上的ROC曲线和精度召回曲线（分类比率1:100）。仅考虑ROC曲线，性能看起来非常出色，但低精度揭示了分类器的真实性能，这对于许多安全应用来说是不切实际的；此外，各种与安全相关的问题涉及两个以上的类，需要多类度量。这一套可能会引入更多的微妙陷阱。众所周知，常用的策略，如”macro-averagingormicro-averaging
“会过度估计和低估小类[51]。</p>
<p><strong>安全影响</strong>：不适当的性能度量是安全研究中的一个长期问题，特别是在检测任务中。例如，虽然真阳性和假阳性可以更详细地描述系统的性能，但当攻击发生率较低时，它们也可以掩盖实际精度。在机器学习中，性能指标的选择非常具体。因此，我们无法提供一般指南。相反，我们建议考虑基于学习的系统的实际部署，并确定有助于实践评估其性能的措施。请注意，这些度量通常与标准度量（如精度或误差）不同，因为它们更符合系统的日常操作。为了给读者一种直觉，在§4.1中，我们展示了Android恶意软件检测器的不同性能测量如何导致对其性能的矛盾解释。</p>
<h4><span id="233-base-ratefallacy基本利率谬误8">2.3.3 Base Rate
Fallacy：基本利率谬误（8）</span></h4>
<p><strong>在解释性能指标时，忽略了较大的类别不平衡，导致对绩效的高估。</strong></p>
<p><strong>描述</strong>：如果不考虑负类的基本速率，类不平衡很容易导致对性能的错误预测。如果这一类占主导地位，即使是极低的假阳性率也会导致意外的高假阳性率。请注意与先前陷阱的不同之处：P7指的是对绩效的不恰当描述，而基本利率谬误则是对结果的错误解释。这种特殊情况在实践中很容易被忽视（见§3）。考虑图2中的示例，其中99%的真阳性可能为1%的假阳性。然而，如果我们考虑1:100的分类比率，这实际上对应于每99个真阳性对应100个假阳性。</p>
<p><strong>安全影响</strong>：基本速率谬误与各种安全问题有关，例如入侵检测和网站指纹识别[11,
72,
100]。<strong>因此，现实地量化攻击者构成的安全和先验威胁是一项挑战。类似地，安装恶意软件的概率通常远低于恶意软件检测实验[104]</strong>。</p>
<p><strong>建议</strong>：安全方面的几个问题围绕着检测罕见事件，如威胁和攻击。对于这些问题，我们提倡使用精度和召回以及相关措施，如精度召回曲线。与其他衡量标准不同，这些功能考虑了分类平衡，因此类似于可靠的性能指标,对于关注少数类的检测任务[38118]。然而，请注意，如果少数群体的流行率被夸大，例如，由于抽样偏差[104]，精确度和召回率可能会产生误导。在这些情况下，马修相关系数（MCC）等其他度量更适合评估分类器的性能[29]（见§4）。此外，ROC曲线及其AUC值是比较检测和分类方法的有用指标。为了更加关注实际约束，我们建议考虑仅将曲线调整到可处理的假阳性率，并计算有界AUC值。<strong>最后，我们还建议讨论与负类（白样本）的基本比率相关的误报类，这使读者能够了解误报决策导致的工作量。</strong></p>
<h3><span id="24-部署和操作">2.4 部署和操作</span></h3>
<p>在典型机器学习工作流的最后一个阶段，部署了开发的系统来解决实践中潜在的安全问题。</p>
<h4><span id="241-lab-onlyevaluation仅实验室评估9">2.4.1 Lab-Only
Evaluation：仅实验室评估（9）</span></h4>
<p>基于学习的系统在实验室环境中进行了简单的评估，没有讨论其实际局限性</p>
<p><strong>描述</strong>：与所有经验学科一样，在某些假设下进行实验以证明方法的有效性是很常见的。虽然执行受控实验是检验某一方法特定方面的合法方法，但应在现实环境中进行评估，以透明地评估其能力，并展示将促进进一步研究的开放挑战。</p>
<p><strong>安全影响</strong>：许多基于学习的安全系统仅在实验室环境中评估，夸大了其实际影响。<strong>一个常见的例子是仅在封闭世界设置中评估的检测方法，具有有限的多样性，不考虑非平稳性[15,71]</strong>。例如，大量网站指纹攻击仅在有限时间内的封闭环境中评估[72]。类似地，一些基于学习的恶意软件检测系统在现实环境中没有得到充分的研究[见5，104]</p>
<p><strong>建议</strong>：<strong>重要的是要尽可能准确地远离实验室设置和近似的真实世界设置</strong>。例如，应考虑数据的时间和空间关系，以解释野外遇到的典型动态[见104]。类似地，运行时和存储约束应在实际条件下进行分析[See
15，112，130]。理想情况下，所提议的系统应该被部署来发现在纯实验室环境中无法观察到的问题，例如真实世界网络流量的多样性[see119]，尽管由于道德和隐私限制，这并非总是可能的。</p>
<h4><span id="242inappropriate-threat-model不恰当的威胁模型10">2.4.2
Inappropriate Threat Model：不恰当的威胁模型（10）</span></h4>
<p>没有考虑机器学习的安全性，使系统面临各种攻击，如中毒和逃避攻击；</p>
<p><strong>描述</strong>：基于学习的安全系统在一个恶劣环境中运行，在设计这些系统时应考虑到这一点。<strong>先前在对抗式学习方面的工作表明，在工作流程的各个阶段，机器学习本身都引入了相当大的攻击面</strong>[见18，101]。其广泛的攻击面使这些算法容易受到各种类型的攻击，例如对抗性预处理、中毒和逃避[19、20、25、105、108]。</p>
<p><strong>安全影响</strong>：在威胁模型和评估中包括对抗性影响通常至关重要，因为攻击的系统不能保证输出可信和有意义的结果。因此，除了传统的安全问题外，还必须考虑与机器学习相关的攻击。例如，与考虑到安全因素而设计的适当规范化模型相比，攻击者可能更容易避开仅依赖少数功能的模型[40]，尽管还应考虑特定领域的影响[105]。此外，机器学习工作流程中的语义漏洞可能会造成攻击盲点。例如，不精确的解析和特征提取可能会使对手隐藏恶意内容[131]。</p>
<p><strong>建议</strong>：在使用基于学习的系统的大多数安全领域中，我们在一个动态的环境中操作。因此，应准确定义威胁模型，并根据这些模型评估系统。在大多数情况下，有必要假设一个适应性强的对手专门针对拟议的系统，并将搜索和利用弱点进行规避或操纵。类似地，考虑机器学习工作流的所有阶段并调查可能的漏洞也是至关重要的[见18、26、39、101]。对于该分析，我们建议尽可能关注白盒策略，遵循Kerckhoff的原则[73]和安全最佳实践。最后，我们要强调的是，对对抗性方面的评估不是附加内容，而是安全研究中的一个强制性组成部分。</p>
<h3><span id="三-流行性分析">三、流行性分析</span></h3>
<p>一旦我们了解了基于学习的安全系统所面临的陷阱，就有必要评估其普遍性并调查其对科学进步的影响。为此，我们对过去十年在ACM
CCS、IEEE S&amp;P、USENIX
Security和NDSS上发表的30篇论文进行了研究，这是我们社区中与安全相关研究的四大会议。这些论文被选为我们研究的代表性例子，因为它们涉及大量不同的安全主题，并成功地将机器学习应用于相应的研究问题。</p>
<p>特别是，我们选择的顶级论文涵盖以下主题：</p>
<ul>
<li>恶意软件检测[9，34，88，104，121，138]；</li>
<li>网络入侵检测[43，93，113，115]；</li>
<li>漏洞发现[42、49、50、83]；</li>
<li>tacks网站指纹识别[44100110116]；</li>
<li>社交网络滥用[22,95,120]；</li>
<li>二进制代码分析[14，32，114]；</li>
<li>代码归属[2,23]；</li>
<li>隐写术[17]；</li>
<li>网上诈骗[74]；</li>
<li>游戏机器人[80]；</li>
<li>[68]</li>
</ul>
<p><strong>评估标准</strong>：对于每一篇论文，<strong>陷阱大致分为存在、不存在、文本不清楚或不适用</strong>。在没有补救（存在）的实验中，陷阱可能完全存在，也可能不存在。如果作者纠正了任何偏见或缩小了他们的主张范围以适应陷阱，这也被视为不存在。此外，我们还介绍了一个类别，以说明确实存在陷阱的实验，但其影响已经得到了特别处理。如果目前或部分出现了一个陷阱，但在文本中得到了承认，我们将按照讨论的方式对分类进行调整。如果审稿人无法排除由于信息缺失而出现的陷阱，我们会将出版物与文本区分开来。最后，在P10的特殊情况下，如果陷阱不适用于纸张的设置，则将其视为单独的类别；</p>
<p><strong>观察</strong>：<strong>普适性分析的汇总结果如图3所示。条形图的颜色表示存在陷阱的程度，其宽度表示具有该分类的论文的比例。受影响纸张的数量记录在条形图的中心</strong>。最普遍的缺陷是<strong>抽样偏差</strong>（P1）和<strong>数据窥探</strong>（P3），这两种情况至少部分出现在90%和73%的论文中。在超过50%的论文中，我们发现至少部分存在不适当的威胁模型（第10页）、仅实验室评估（第9页）和不适当的性能度量（第7页）。每一份报纸都会受到至少三个陷阱的影响，这突出了这些问题在最近的计算机安全研究中的普遍性。特别是，我们发现数据集的收集仍然非常具有挑战性：我们作为社区开发的一些最具权威性和扩展性的开放数据集仍然不完善（见§4.1）</p>
<p>&lt;img src="pic/Dos and Don'ts of Machine Learning in Computer
Security</p>
<blockquote>
<p>改github的主页信息</p>
<p>USENIX Security
'22：https://www.usenix.org/conference/usenixsecurity22/presentation/arp</p>
<p><strong>Why not（ ? ）Use AI in Cyber Security</strong></p>
</blockquote>
<h3><span id="摘要">摘要</span></h3>
<p><strong>随着计算系统处理能力的不断增强和海量数据集的日益可用，机器学习算法在许多不同领域取得了重大突破</strong>。这一发展影响了计算机安全，催生了一系列基于机器学习的安全系统的工作，例如<strong>恶意软件检测、漏洞发现和二进制代码分析</strong>。尽管机器学习在安全领域有着巨大的潜力，但它容易出现一些微妙的缺陷，这些缺陷会破坏其性能，并使基于学习的系统可能不适合安全任务和实际部署。</p>
<p>在本文中，我们用批判的眼光看待这个问题。首先，我们确定了基于学习的安全系统的设计、实现和评估中的常见陷阱。我们对过去10年中顶级安全会议上的30篇论文进行了研究，确认这些缺陷在当前安全文献中普遍存在。在实证分析中，我们进一步证明了个别陷阱如何导致不切实际的表现和解释，阻碍对当前安全问题的理解。作为补救措施，我们提出了可行的建议，以支持研究人员在可能的情况下避免或减轻陷阱。此外，我们发现了将机器学习应用于安全时存在的问题，并为进一步的研究提供了方向。</p>
<h3><span id="一-说明">一、说明</span></h3>
<p><strong>没有一天不阅读机器学习的成功故事</strong>。对专业计算资源和大型数据集的广泛访问，以及用于深度学习的新概念和架构，为机器学习在几个领域的突破铺平了道路，例如自然语言的翻译[13，31，125]和图像内容的识别[62，78，117]。这一发展自然影响了安全研究：虽然过去主要局限于特定应用[53、54、132]，但机器学习现在已成为研究和解决多个应用领域中普遍存在的安全相关问题的关键促成因素之一，包括<strong>入侵检测</strong>[43、93]、<strong>恶意软件分析</strong>[69、88]、<strong>漏洞发现</strong>[83、142]，和<strong>二进制代码分析</strong>[42、114、140]。</p>
<p>然而，机器学习没有洞察力，需要在相当精细的工作流程中对数据的统计特性进行推理：错误的假设和实验偏见可能会对这一过程产生怀疑，以至于不清楚我们是否可以信任使用学习算法得出的科学发现[56]。<strong>二十年前[11、119、126]开始尝试识别特定安全领域（如网络入侵检测）中的挑战和限制，最近扩展到其他领域，如恶意软件分析和网站指纹识别[3、72、104、112]</strong>。然而，与这项工作垂直的是，我们认为存在与机器学习相关的一般陷阱，这些陷阱影响所有安全领域，迄今为止几乎没有受到关注。<strong>这些缺陷可能导致结果过于乐观，甚至影响整个机器学习工作流，削弱假设、结论和经验教训</strong>。因此，人们感觉到一种虚假的成就感，阻碍了学术界和工业界采用研究进展。健全的科学方法是支持直觉和得出结论的基础。我们认为，这一需求在安全性方面尤其重要，在安全性领域，过程往往受到积极绕过分析并破坏系统的对手的破坏。</p>
<p><strong>在本文中，我们确定了十个常见但微妙的陷阱，这些陷阱对研究结果的有效性构成威胁，并阻碍了对其的解释。</strong>为了支持这一说法，我们分析了过去十年中30篇依靠机器学习解决不同问题的顶级安全论文中这些陷阱的普遍性。令我们惊讶的是，每篇论文至少有三个陷阱；更糟糕的是，有几个陷阱影响了大多数论文，这表明这个问题是多么普遍和微妙。尽管这些陷阱很普遍，但了解它们在多大程度上削弱了结果并导致过于乐观的结论可能更为重要。最后我们对四个不同安全领域中的陷阱进行了影响分析。这些发现支持了我们的假设，回应了社区更广泛的关注。</p>
<h4><span id="贡献">贡献：</span></h4>
<ul>
<li><strong>陷阱识别</strong>。我们确定了机器学习在安全性方面的十个陷阱，并提出了可行的建议，以支持研究人员尽可能避免这些陷阱。此外，要确定无法轻松缓解的开放性问题，需要进一步研究。</li>
<li><strong>流行率分析</strong>。我们分析了在过去十年中发表的30份具有代表性的顶级证券报纸中发现的陷阱的普遍性。此外，我们进行了一项广泛的调查，其中我们获得并评估了这些论文作者关于已识别缺陷的反馈。</li>
<li><strong>影响分析</strong>。在四个不同的安全领域，我们通过实验分析了此类缺陷在多大程度上导致了实验偏差，以及我们如何通过应用建议的建议来有效克服这些问题。</li>
</ul>
<blockquote>
<p><strong>评论</strong> :
这项工作不应被解释为指手画脚的练习。相反，这是一种反思性的努力，表明了微妙的陷阱会对安全研究的进展产生多大的负面影响，以及我们作为一个社区如何充分缓解它们。</p>
</blockquote>
<h3><span id="二-机器学习中的陷阱">二、机器学习中的陷阱</span></h3>
<p>尽管机器学习取得了巨大的成功，但在实践中应用机器学习通常并不简单，而且容易出现一些缺陷，从明显的缺陷到微小的瑕疵。<strong>忽视这些问题可能会导致实验偏差或错误结论，尤其是在计算机安全方面。</strong>在本节中，我们介绍了在security
research中经常出现的十个常见陷阱。虽然这些陷阱乍一看似乎显而易见，但它们根源于安全研究中普遍存在的细微缺陷，甚至在ATOP会议上发表的论文中也是如此。</p>
<p>我们根据典型机器学习工作流的各个阶段对这些缺陷进行分类，如图1所示。对于每个缺陷，我们提供了简短的描述，讨论了其对安全领域的影响，并提出了建议。此外，彩色条显示了我们分析中遭受陷阱的论文比例，较暖的颜色表示存在陷阱（见图3）</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551371.png" alt="image-20220804131643885">
<figcaption aria-hidden="true">image-20220804131643885</figcaption>
</figure>
<h3><span id="21-数据收集与标记">2.1 数据收集与标记</span></h3>
<p>基于学习的系统的设计和开发通常从获取代表性数据集开始。显然，使用不切实际的数据进行实验会导致错误估计方法的能力。以下两个陷阱经常导致这个问题，因此在开发基于学习的计算机安全系统时需要特别注意。</p>
<h4><span id="221-sampling-bias-样本偏差1">2.2.1 Sampling Bias ：
样本偏差（1）</span></h4>
<p>收集的数据不足以代表潜在安全问题的真实数据分布。</p>
<p><strong>描述</strong>：除了少数例外，研究人员开发基于学习的方法时没有确切了解输入空间的真实潜在分布。相反，他们需要依赖于包含固定数量样本的数据集，这些样本旨在与实际分布相似。虽然在大多数情况下不可避免地存在一些偏见，但理解特定问题固有的特定偏见对于限制其在实践中的影响至关重要。如果数据不能有效地表示输入空间，甚至不能遵循不同的分布，那么从训练数据中得出有意义的结论就变得很有挑战性。</p>
<p><strong>安全影响</strong>：<strong>采样偏差与安全高度相关，因为数据采集尤其具有挑战性</strong>，通常需要使用多个质量不同的源。例如，对于用于Android恶意软件检测的合适数据集的收集，只有少数公共来源可用于获取此类数据[6,
134]。因此，依赖合成数据或组合来自不同来源的数据是常见的做法，正如我们在第4节中通过最先进的入侵和恶意软件检测方法的例子所证明的那样，这两种方法都会引入偏差。</p>
<p><strong>建议</strong>：在许多安全应用程序中，从真实分布中采样极其困难，有时甚至不可能。因此，这种偏差通常只能得到缓解，但不能完全消除。在§4中，我们表明，<strong>在某些情况下，一个合理的策略是构造真实分布的差分集并对其进行单独分析。进一步的策略包括使用合成数据扩展数据集</strong>[例如，28，60，137]或使用转移学习[See99，135，145，147]。然而，应避免来自不兼容源的数据混合，因为这是额外偏差的常见原因。无论如何，应该公开讨论所用数据集的局限性，让其他研究人员更好地理解潜在采样偏差的安全含义。</p>
<h4><span id="221-labelinaccuracy标签不准确2">2.2.1 Label
Inaccuracy：标签不准确（2）</span></h4>
<p>分类任务所需的地面真实值标签不准确、不稳定或错误，影响基于学习的系统的整体性能[85，144]</p>
<p><strong>描述</strong>：许多基于AI的安全系统是为分类任务而构建的。为了训练这些系统，每次观测都需要一个
<strong>ground-truth</strong>
label。不幸的是，这种标记很少是完美的，研究人员必须考虑不确定性和噪声，以防止他们的模型受到固有偏差的影响。</p>
<p><strong>安全影响</strong>：对于许多相关的安全问题，如检测网络攻击或恶意软件，通常无法获得可靠的标签，从而导致鸡和蛋的问题。作为补救措施，研究人员通常采用启发式方法，例如使用无法提供可靠基础真相的外部来源。例如，像
virustotal
这样的服务通常用于获取恶意软件的标签信息，但这些服务并不总是一致的[144]。此外，随着时间的推移，对手行为的改变可能会改变不同等级之间的比例[3,92，144]，引入一种称为<strong>标签偏移的偏差</strong>[85]。无法适应这些变化的系统一旦部署，性能将下降。</p>
<p><strong>建议</strong>：通常，应尽可能验证标签，例如，通过手动调查假阳性或随机样本[例如，122]。如果不排除噪声，则可以通过（i）使用稳健模型或损失函数，（ii）<strong>在学习过程中积极建模标签噪声</strong>，或（iii）清除训练数据中的噪声标签来减少其对学习模型的影响[见55,67,84]。为了证明这些方法的适用性，我们主要采用附录a中的清理方法。请注意，标签不确定的实例不得从测试数据中删除。这代表了采样偏差（P1）和数据窥探（P3）的变化，这是我们在§2.2中详细讨论的一个陷阱。由于标签可能会随时间变化，因此有必要采取预防措施，防止标签移动[85]，例如延迟标签，直到获得稳定的地面真相为止[见144]。</p>
<h3><span id="22-系统设计和学习">2.2 系统设计和学习</span></h3>
<p>一旦收集到足够的数据，就可以训练基于学习的安全系统。<strong>这个过程包括从数据预处理到提取有意义的特征和建立有效的学习模型</strong>。不幸的是，这些步骤中的每一步都可能引入缺陷和弱点。</p>
<h4><span id="221-datasnooping数据窥探3">2.2.1 Data
Snooping：数据窥探（3）</span></h4>
<p><strong>学习模型是用实践中通常不可用的数据训练的。数据窥探可以以多种方式发生，其中一些非常细微，难以识别[1]。</strong></p>
<p><strong>描述</strong>：在生成学习模型之前，通常将收集的数据拆分为单独的训练集和测试集。虽然分割数据似乎很简单，但测试数据或其他通常不可用的背景信息有许多微妙的方式可以影响训练过程，从而导致数据窥探。<strong>虽然附录中提供了数据监听示例的详细列表（见表8</strong>），但我们大致区分了三种类型的数据监听：测试、临时和选择性监听。<strong>当测试集用于最终评估之前的实验时，会发生测试窥探</strong>。这包括识别有用特征、参数和学习算法的准备工作。<strong>如果忽略数据中的时间依赖性，则会发生时间监听</strong>。这是一个常见的陷阱，<strong>因为许多与安全相关的问题的潜在分布都处于不断变化的状态</strong>[例如，87，104]。最后，选择性监听描述了基于实践中不可用的信息清理数据。一个例子是基于完整数据集（即，训练和测试）的统计数据删除外部LIER，这些数据集通常在训练时不可用。</p>
<p><strong>安全影响</strong>：在安全方面，由于新的攻击或技术，数据分布是非平稳的，并且不断变化。因此，窥探未来或外部数据源的数据是一种普遍现象，导致结果过于乐观。例如，一些研究人员已经在基于学习的恶意软件检测系统中发现了时间窥探[4,8,104]。在所有这些情况下，由于混合了过去和现在的样本，这些方法的能力被高估。同样，在安全研究中也存在测试和选择性窥探事件，导致结果出现无意偏差（见§3）。</p>
<p><strong>建议</strong>：虽然训练、验证和测试数据应该严格分开似乎很明显，但在预处理阶段，这种数据隔离往往会被无意中违反。<strong>例如，我们观察到，在整个数据集上计算tf-idf权重或神经嵌入是一个常见错误</strong>（见§3）。为了避免这个问题，测试数据应该在数据收集期间尽早分割，并单独存储，直到最终评估。<strong>此外，在创建数据时，应考虑数据内的时间依赖性,数据集被拆分</strong>[4，87，104]。然而，其他类型的数据窥探很难解决。例如，随着公开数据集的特征日益暴露，使用该数据开发的方法隐含地从测试数据中获取年龄知识[见1，90]。<strong>因此，对知名数据集的实验应与对来自考虑适应应用领域的较新数据的实验相补充。</strong></p>
<h4><span id="222-spuriouscorrelations假相关性4">2.2.2 Spurious
Correlations：假相关性（4）</span></h4>
<p><strong>与安全问题无关的工件创建了用于分类的快捷模式。因此，学习模型适应这些工件，而不是解决实际任务</strong>；</p>
<p><strong>描述</strong>：伪相关性是由与要解决的任务相关但实际上与之无关的产生的，从而导致错误关联。考虑一个网络入侵检测系统的例子，其中数据集中的大部分攻击来自某个网络区域。该模型可以学习检测特定IP范围而不是一般攻击模式。请注意，虽然抽样偏差是产生虚假相关性的常见原因，但这些偏差也是由其他因素造成的，我们在附录a.对此进行了更详细的讨论</p>
<p><strong>安全影响</strong>：<strong>机器学习通常应用于安全领域的黑盒。因此，虚假的相关性往往无法确定。一旦结果被解释并用于得出一般结论，这些相关性就会带来问题</strong>。如果不知道虚假相关性，则存在高估方法能力和误判其实际局限性的高风险。例如，§4.2报告了我们对漏洞发现系统的分析，表明基础数据中存在明显的虚假相关性。</p>
<p><strong>建议</strong>：<strong>为了更好地了解基于学习的系统的能力，我们通常建议应用机器学习的解释技术</strong>[见59、79、133]。尽管存在一些限制[例如，66，75127]，这些技术可以揭示虚假的相关性，并允许从业者评估其对系统能力的影响。作为一个例子，我们在§4中展示了不同安全相关问题的可解释学习如何有助于识别该问题。请注意，根据基于学习的系统的目标，一种设置中的虚假相关性可能被视为另一种设置的有效信号。因此，我们建议提前明确定义该目标，并验证系统学习的相关性是否符合该目标。例如，一个强大的恶意软件检测系统应该检测与恶意活动相关的特征，而不是数据中存在的其他无关信息</p>
<h4><span id="223-biasedparameter-selection-有偏参数选择5">2.2.3 Biased
Parameter Selection ：有偏参数选择（5）</span></h4>
<p><strong>基于学习的方法的最终参数在训练时并不完全固定。相反，它们间接依赖于测试集</strong>。</p>
<p><strong>描述</strong>：在整个学习过程中，通常通过改变参数生成不同的模型。选择性能最佳的模型，并给出其在测试集上的性能。虽然这种设置通常是合理的，但它仍然会受到参数选择偏差的影响。<strong>例如，通过调整超参数或校准测试数据（而不是训练数据）上的阈值，可以很容易产生过于乐观的结果。</strong></p>
<p><strong>安全影响</strong>：参数在训练时未完全校准的安全系统在现实环境中的性能可能会有所不同。<strong>虽然网络入侵检测系统的检测阈值可以使用测试集上获得的ROC曲线来确定，但由于现实世界流量的多样性，在实践中很难选择相同的操作点</strong>[119]。与原始实验设置相比，这可能导致系统性能下降。请注意，此陷阱与数据窥探（P3）有关，但应明确考虑，因为它很容易导致夸大的结果。</p>
<p><strong>建议</strong>：这种陷阱构成了数据窥探的一种特殊情况，因此适用相同的对策。然而，在实践中，通过使用分离的评估集进行模型选择和参数调整，可以很容易地固定有偏差的参数选择。与通常难以缓解的一般数据窥探相比，严格的数据隔离已经足以排除确定超参数和阈值时的问题。</p>
<h3><span id="23-performance-evaluation">2.3 Performance Evaluation</span></h3>
<p><strong>性能评估典</strong>型机器学习工作流的下一个阶段是系统性能评估。在下文中，我们将展示不同的陷阱如何在评估此类系统时导致不公平的比较和有偏见的结果。</p>
<h4><span id="231-inappropriatebaseline-不适当的基线6">2.3.1 Inappropriate
Baseline: 不适当的基线（6）</span></h4>
<p>评估不使用或使用有限的基线方法进行。结果是，不可能证明对现有技术和其他安全机制的改进;</p>
<p><strong>描述</strong>:为了说明一种新方法在多大程度上提高了技术水平，将其与先前提出的方法进行比较至关重要。在选择基线时，重要的是要记住，不存在优于一般[136]中所有其他方法的通用学习算法。因此，仅提供所提出方法的结果或与基本相同的学习模型进行比较，并没有提供足够的背景来评估其影响。</p>
<p><strong>安全影响</strong>：<strong>过于复杂的学习方法会增加过度拟合的可能性，还会增加运行时开销、攻击面以及部署的时间和成本</strong>。为了证明与传统方法相比，机器学习技术提供了显著的改进，因此有必要对这些系统进行并排比较。</p>
<p><strong>推荐</strong>：在整个评估过程中，应考虑简单模型，而不是仅仅关注复杂模型进行比较。<strong>这些方法易于解释，计算要求较低，并且在实践中证明是有效的和可扩展的</strong>。在第4节中，我们演示了如何使用易于理解的简单模型作为基线来解释不必要的复杂学习模型。类似地，我们表明自动机器学习（AutoML）框架工作[例如，48,70]有助于找到合适的基线。虽然这些自动化方法肯定不能取代经验丰富的数据分析师，但它们可以用来设定所提出方法应达到的下限。最后，检查非学习方法是否也适用于应用场景是至关重要的。<strong>例如，对于入侵和恶意软件检测，存在多种使用其他检测策略的方法[例如，45、102、111]</strong>。</p>
<h4><span id="232inappropriate-performance-measures不适当的性能衡量标准7">2.3.2
Inappropriate Performance Measures：不适当的性能衡量标准（7）</span></h4>
<p><strong>精选的性能度量没有考虑到应用场景的限制，例如数据不平衡或需要保持较低的误报率。</strong></p>
<p><strong>描述</strong>：可提供范围广泛的性能指标，但并非所有这些指标都适用于安全环境。例如，在评估检测系统时，仅报告一个性能值（如精度）通常是不够的，因为真阳性和假阳性判断是不可观察的。然而，更先进的测量方法，如ROC曲线，在某些应用环境中可能会模糊实验结果。图2显示了不平衡数据集上的ROC曲线和精度召回曲线（分类比率1:100）。仅考虑ROC曲线，性能看起来非常出色，但低精度揭示了分类器的真实性能，这对于许多安全应用来说是不切实际的；此外，各种与安全相关的问题涉及两个以上的类，需要多类度量。这一套可能会引入更多的微妙陷阱。众所周知，常用的策略，如”macro-averagingormicro-averaging
“会过度估计和低估小类[51]。</p>
<p><strong>安全影响</strong>：不适当的性能度量是安全研究中的一个长期问题，特别是在检测任务中。例如，虽然真阳性和假阳性可以更详细地描述系统的性能，但当攻击发生率较低时，它们也可以掩盖实际精度。在机器学习中，性能指标的选择非常具体。因此，我们无法提供一般指南。相反，我们建议考虑基于学习的系统的实际部署，并确定有助于实践评估其性能的措施。请注意，这些度量通常与标准度量（如精度或误差）不同，因为它们更符合系统的日常操作。为了给读者一种直觉，在§4.1中，我们展示了Android恶意软件检测器的不同性能测量如何导致对其性能的矛盾解释。</p>
<h4><span id="233-base-ratefallacy基本利率谬误8">2.3.3 Base Rate
Fallacy：基本利率谬误（8）</span></h4>
<p><strong>在解释性能指标时，忽略了较大的类别不平衡，导致对绩效的高估。</strong></p>
<p><strong>描述</strong>：如果不考虑负类的基本速率，类不平衡很容易导致对性能的错误预测。如果这一类占主导地位，即使是极低的假阳性率也会导致意外的高假阳性率。请注意与先前陷阱的不同之处：P7指的是对绩效的不恰当描述，而基本利率谬误则是对结果的错误解释。这种特殊情况在实践中很容易被忽视（见§3）。考虑图2中的示例，其中99%的真阳性可能为1%的假阳性。然而，如果我们考虑1:100的分类比率，这实际上对应于每99个真阳性对应100个假阳性。</p>
<p><strong>安全影响</strong>：基本速率谬误与各种安全问题有关，例如入侵检测和网站指纹识别[11,
72,
100]。<strong>因此，现实地量化攻击者构成的安全和先验威胁是一项挑战。类似地，安装恶意软件的概率通常远低于恶意软件检测实验[104]</strong>。</p>
<p><strong>建议</strong>：安全方面的几个问题围绕着检测罕见事件，如威胁和攻击。对于这些问题，我们提倡使用精度和召回以及相关措施，如精度召回曲线。与其他衡量标准不同，这些功能考虑了分类平衡，因此类似于可靠的性能指标,对于关注少数类的检测任务[38118]。然而，请注意，如果少数群体的流行率被夸大，例如，由于抽样偏差[104]，精确度和召回率可能会产生误导。在这些情况下，马修相关系数（MCC）等其他度量更适合评估分类器的性能[29]（见§4）。此外，ROC曲线及其AUC值是比较检测和分类方法的有用指标。为了更加关注实际约束，我们建议考虑仅将曲线调整到可处理的假阳性率，并计算有界AUC值。<strong>最后，我们还建议讨论与负类（白样本）的基本比率相关的误报类，这使读者能够了解误报决策导致的工作量。</strong></p>
<h3><span id="24-部署和操作">2.4 部署和操作</span></h3>
<p>在典型机器学习工作流的最后一个阶段，部署了开发的系统来解决实践中潜在的安全问题。</p>
<h4><span id="241-lab-onlyevaluation仅实验室评估9">2.4.1 Lab-Only
Evaluation：仅实验室评估（9）</span></h4>
<p>基于学习的系统在实验室环境中进行了简单的评估，没有讨论其实际局限性</p>
<p><strong>描述</strong>：与所有经验学科一样，在某些假设下进行实验以证明方法的有效性是很常见的。虽然执行受控实验是检验某一方法特定方面的合法方法，但应在现实环境中进行评估，以透明地评估其能力，并展示将促进进一步研究的开放挑战。</p>
<p><strong>安全影响</strong>：许多基于学习的安全系统仅在实验室环境中评估，夸大了其实际影响。<strong>一个常见的例子是仅在封闭世界设置中评估的检测方法，具有有限的多样性，不考虑非平稳性[15,71]</strong>。例如，大量网站指纹攻击仅在有限时间内的封闭环境中评估[72]。类似地，一些基于学习的恶意软件检测系统在现实环境中没有得到充分的研究[见5，104]</p>
<p><strong>建议</strong>：<strong>重要的是要尽可能准确地远离实验室设置和近似的真实世界设置</strong>。例如，应考虑数据的时间和空间关系，以解释野外遇到的典型动态[见104]。类似地，运行时和存储约束应在实际条件下进行分析[See
15，112，130]。理想情况下，所提议的系统应该被部署来发现在纯实验室环境中无法观察到的问题，例如真实世界网络流量的多样性[see119]，尽管由于道德和隐私限制，这并非总是可能的。</p>
<h4><span id="242inappropriate-threat-model不恰当的威胁模型10">2.4.2
Inappropriate Threat Model：不恰当的威胁模型（10）</span></h4>
<p>没有考虑机器学习的安全性，使系统面临各种攻击，如中毒和逃避攻击；</p>
<p><strong>描述</strong>：基于学习的安全系统在一个恶劣环境中运行，在设计这些系统时应考虑到这一点。<strong>先前在对抗式学习方面的工作表明，在工作流程的各个阶段，机器学习本身都引入了相当大的攻击面</strong>[见18，101]。其广泛的攻击面使这些算法容易受到各种类型的攻击，例如对抗性预处理、中毒和逃避[19、20、25、105、108]。</p>
<p><strong>安全影响</strong>：在威胁模型和评估中包括对抗性影响通常至关重要，因为攻击的系统不能保证输出可信和有意义的结果。因此，除了传统的安全问题外，还必须考虑与机器学习相关的攻击。例如，与考虑到安全因素而设计的适当规范化模型相比，攻击者可能更容易避开仅依赖少数功能的模型[40]，尽管还应考虑特定领域的影响[105]。此外，机器学习工作流程中的语义漏洞可能会造成攻击盲点。例如，不精确的解析和特征提取可能会使对手隐藏恶意内容[131]。</p>
<p><strong>建议</strong>：在使用基于学习的系统的大多数安全领域中，我们在一个动态的环境中操作。因此，应准确定义威胁模型，并根据这些模型评估系统。在大多数情况下，有必要假设一个适应性强的对手专门针对拟议的系统，并将搜索和利用弱点进行规避或操纵。类似地，考虑机器学习工作流的所有阶段并调查可能的漏洞也是至关重要的[见18、26、39、101]。对于该分析，我们建议尽可能关注白盒策略，遵循Kerckhoff的原则[73]和安全最佳实践。最后，我们要强调的是，对对抗性方面的评估不是附加内容，而是安全研究中的一个强制性组成部分。</p>
<h3><span id="三-流行性分析">三、流行性分析</span></h3>
<p>一旦我们了解了基于学习的安全系统所面临的陷阱，就有必要评估其普遍性并调查其对科学进步的影响。为此，我们对过去十年在ACM
CCS、IEEE S&amp;P、USENIX
Security和NDSS上发表的30篇论文进行了研究，这是我们社区中与安全相关研究的四大会议。这些论文被选为我们研究的代表性例子，因为它们涉及大量不同的安全主题，并成功地将机器学习应用于相应的研究问题。</p>
<p>特别是，我们选择的顶级论文涵盖以下主题：</p>
<ul>
<li>恶意软件检测[9，34，88，104，121，138]；</li>
<li>网络入侵检测[43，93，113，115]；</li>
<li>漏洞发现[42、49、50、83]；</li>
<li>tacks网站指纹识别[44100110116]；</li>
<li>社交网络滥用[22,95,120]；</li>
<li>二进制代码分析[14，32，114]；</li>
<li>代码归属[2,23]；</li>
<li>隐写术[17]；</li>
<li>网上诈骗[74]；</li>
<li>游戏机器人[80]；</li>
<li>[68]</li>
</ul>
<p><strong>评估标准</strong>：对于每一篇论文，<strong>陷阱大致分为存在、不存在、文本不清楚或不适用</strong>。在没有补救（存在）的实验中，陷阱可能完全存在，也可能不存在。如果作者纠正了任何偏见或缩小了他们的主张范围以适应陷阱，这也被视为不存在。此外，我们还介绍了一个类别，以说明确实存在陷阱的实验，但其影响已经得到了特别处理。如果目前或部分出现了一个陷阱，但在文本中得到了承认，我们将按照讨论的方式对分类进行调整。如果审稿人无法排除由于信息缺失而出现的陷阱，我们会将出版物与文本区分开来。最后，在P10的特殊情况下，如果陷阱不适用于纸张的设置，则将其视为单独的类别；</p>
<p><strong>观察</strong>：<strong>普适性分析的汇总结果如图3所示。条形图的颜色表示存在陷阱的程度，其宽度表示具有该分类的论文的比例。受影响纸张的数量记录在条形图的中心</strong>。最普遍的缺陷是<strong>抽样偏差</strong>（P1）和<strong>数据窥探</strong>（P3），这两种情况至少部分出现在90%和73%的论文中。在超过50%的论文中，我们发现至少部分存在不适当的威胁模型（第10页）、仅实验室评估（第9页）和不适当的性能度量（第7页）。每一份报纸都会受到至少三个陷阱的影响，这突出了这些问题在最近的计算机安全研究中的普遍性。特别是，我们发现数据集的收集仍然非常具有挑战性：我们作为社区开发的一些最具权威性和扩展性的开放数据集仍然不完善（见§4.1）</p>
<p>此外，文本中存在的一些陷阱比其他陷阱更容易被忽略。我们观察到，当没有对参数的描述时，这种有偏参数选择（P5）,给出了超参数或调谐过程；对于伪相关（P4），当没有试图解释模型的决定时；以及当文本中未明确描述数据集分割或归一化过程时的数据窥探（P3）。这些问题还表明，由于缺乏信息，实验设置更难复现；</p>
<p><strong>作者的反馈</strong>：为了促进我们社区内的讨论，我们联系了所选论文的作者，并收集了对我们研究结果的反馈。我们对135位有联系方式的作者进行了调查。为了保护作者的隐私并鼓励公开讨论，所有回复均匿名。调查包括一系列关于已识别缺陷的一般和具体问题。首先，我们询问作者是否阅读过我们的作品，并认为它对社区有帮助。其次，对于每一个陷阱，我们收集反馈信息，说明他们是否同意（a）他们的出版可能受到影响，（b）安全文件中经常出现陷阱，以及（c）在大多数情况下很容易避免。为了量化评估回答，我们对每个问题使用五点Likert量表，范围从强烈不同意到强烈同意。此外，我们提供了一个不回答的选项，并允许作者省略问题。我们收到了49位作者的反馈，回复率为36%。这些作者对应于30篇选定论文中的13篇，因此占考虑研究的43%。关于一般性问题，46（95%）的作者阅读了我们的论文，48（98%）同意这有助于提高对已识别缺陷的认识。对于具体的陷阱问题，作者和我们的发现之间的总体一致性平均为63%，这取决于安全区域和陷阱。所有的作者都认为他们的论文至少有一个缺陷。平均而言，他们指出他们的工作中存在2.77个陷阱，标准偏差为1.53，涵盖了所有十个陷阱。在评估总体缺陷时，作者特别同意，仅<strong>实验室评估（92%）、基本比率谬误（77%）、不适当的绩效衡量（69%）和抽样偏差（69%）经常发生在安全人员中</strong>。此外，他们指出，<strong>不适当的性能测量（62%）、不适当的参数选择（62%）和基准利率谬误（46%）在实践中可以很容易地避免</strong>，而其他陷阱需要更多的努力。我们在附录B中提供了关于该调查的更多信息。总之，我们从该调查中得出了三个中心观察结果。首先，大多数作者都同意，我们的社区缺乏对已识别缺陷的意识。第二，他们确认，这些陷阱在安全文献中很普遍，有必要减轻它们。第三，仍然缺乏对已识别缺陷的一致理解。例如，几位作者（44%）既不同意也不反对数据窥探是否容易避免，强调了明确定义和建议的重要性。我们发现§2中引入的所有陷阱在安全研究中都很普遍，影响了17%到90%的选定论文。每篇论文至少有三个陷阱，只有22%的实例与本文中的讨论相关。虽然作者在某些情况下甚至可能故意省略了对陷阱的讨论，但我们的患病率分析结果总体上表明，我们的社区缺乏认识。虽然这些发现指出了研究中的一个严重问题，<strong>但我们想指出，所有分析的论文都提供了出色的贡献和宝贵的见解。我们的目标不是责怪研究人员陷入陷阱，而是提高安全领域机器学习研究的意识和实验质量。</strong></p>
<h3><span id="四-影响分析">四、影响分析</span></h3>
<p>在前几节中，我们介绍了计算机安全文献中普遍存在的缺陷。然而，到目前为止，尚不清楚单个陷阱会在多大程度上影响实验结果及其结论。在本节中，我们估计了机器学习在安全领域的流行应用中的一些缺陷的实验影响。同时，我们展示了§2中讨论的建议如何帮助识别和解决这些问题。在我们的讨论中，我们考虑了计算机安全领域的四个热门研究主题：</p>
<ul>
<li><strong>移动恶意软件检测</strong>： (P1, P4, and P7)</li>
<li>漏洞发现： (P2, P4, and P6)</li>
<li>源代码作者归属：（P1和P4）</li>
<li><strong>网络入侵检测</strong>：（P6和P9）</li>
</ul>
<blockquote>
<p><strong>评论对于该分析，我们考虑了每个安全域的最先进方法</strong>。我们注意到，本节中的结果并不意味着具体批评这些方法；我们选择它们是因为它们代表了陷阱如何影响不同领域。值得注意的是，我们能够复制这些方法的事实高度赞扬了他们的学术水平;</p>
</blockquote>
<h4><span id="41-移动恶意软件检测">4.1 移动恶意软件检测</span></h4>
<p>使用机器学习自动检测Android恶意软件是一个特别活跃的研究领域。这种方法的设计和评估是微妙的，可能会显示出一些先前讨论的缺陷。在下文中，我们<strong>讨论了采样偏差（P1）、伪相关性（P4）和不适当的性能度量（P7）对基于学习的检测的影响</strong>；</p>
<p><strong>数据集集合</strong>：最近移动数据的一个常见来源是AndroZoop项目[6]，该项目从各种来源收集Android应用程序，包括Official
谷歌市场和几个中国app软件市场。在撰写本文时，它包括来自18个不同来源的超过1100万个Android应用程序。<strong>除了样本本身，它还包括元信息，如抗病毒检测的数量</strong>。虽然AndroZoo是获取移动应用的优秀来源，但我们证明，如果不考虑数据集的特性，实验可能会出现严重的抽样偏差（P1）。请注意，以下讨论不限于AndroZoo数据，而是与Android数据集的组成相关。</p>
<p><strong>数据集分析</strong>：在第一步中，我们通过考虑应用程序的来源和Android应用程序的防病毒检测数量来分析AndroZoo的数据分布。为了进行分析，我们将各个市场大致分为四个不同的来源：谷歌游戏、中国市场、VirusShare和所有其他市场。图4显示了从特定来源随机采样的概率，这取决于应用程序的防病毒检测数量。例如，当选择一个对检测次数没有限制的样本时，从谷歌游戏中采样的概率大约为80%。如果我们考虑10次检测的结果，我们从中国市场随机选择应用的概率是70%。如果我们忽略数据分布，数据集中的大部分良性应用很可能来自GooglePlay，而大多数恶意应用来自中国市场。请注意，此采样偏差不限于Andro
Zoo。我们确定了DredeBin数据集[9]的类似抽样偏差，该偏差通常用于评估基于学习的Android恶意软件检测方法的性能[9、58、146]。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551654.png" alt="image-20220807135625094" style="zoom: 67%;"></p>
<p><strong>实验装置</strong>：为了更好地理解这一发现，我们使用两个数据集进行了实验：</p>
<ul>
<li>对于第一个数据集（D1），我们将来自Google
Play的10000个良性应用程序与来自中国市场的1000个恶性应用程序（安齐安达应用程序中国）合并。</li>
<li>然后，我们使用相同的10000个良性应用程序创建第二个数据集（D2），但将它们与Google
Play独家提供的1000个软件样本相结合。所有合法的应用程序都至少被10个病毒扫描程序检测到。接下来，我们使用来自最先进分类器的两个特征集（DREBIN[9]和OPSEQS[91]），在这些数据集上训练线性支持向量机[47]。</li>
</ul>
<p><strong>实验结果</strong>：在数据集D1和D2之间，DREBIN 和
OPSDEQS的召回率（真阳性率）分别超过10%和15%，而准确性仅受到轻微影响（见表1）。因此，性能度量的选择至关重要（P7）。有趣的是，URLplay.google.Com
被证明是良性类的五个最具歧视性的特征之一，这表明分类者已经学会区分Android
apps的起源，而不是恶意软件和benign apps
之间的区别（P4）。<strong>虽然我们的实验装置通过故意忽略时间相关性（P3）高估了分类器的性能，但我们仍然可以清楚地观察到陷阱的影响</strong>。请注意，在以前的工作[4,
104]中已经证明了在这种情况下时间窥探的效果。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551720.png" alt="image-20220807211200980" style="zoom: 67%;"></p>
<h3><span id="42-漏洞发现">4.2 漏洞发现</span></h3>
<p>源代码中的漏洞可能导致权限提升和远程代码执行，使其成为主要威胁。由于手动搜索漏洞复杂且耗时，近年来提出了基于机器学习的检测方法[57，83，141]。在下面的内容中，我们展示了用于漏洞检测的数据集包含仅在一个类（P4）中发生的事件。我们还发现，用于检测脆弱性的神经网络Vuldeepecker[83]使用伪影进行分类，并且简单的线性分类器在相同的数据集上获得更好的结果（P6）。最后，我们讨论了forVulDeePecker提出的预处理步骤如何使我们无法确定某些代码片段是否包含漏洞（P2）</p>
<p><strong>数据集集合</strong>：在我们的分析中，我们使用了Li等人[83]发布的数据集，其中包含来自国家漏洞数据库[36]和SARD项目[37]的源代码。我们关注与缓冲区（CWE-119）相关的漏洞，并获得了39757个源代码片段，其中10444（26%）被标记为包含漏洞。</p>
<h3><span id="43-源代码作者归属">4.3 源代码作者归属</span></h3>
<p>基于源代码识别开发人员的任务称为作者归属[23]。编程习惯具有多种风格模式，因此</p>
<h4><span id="44-网络入侵检测检测">4.4 网络入侵检测检测</span></h4>
<p>网络入侵是安全[41]中最古老的问题之一，毫不奇怪，异常网络流量的检测严重依赖于基于学习的方法[27,81,82,93]。<strong>然而，收集真实攻击数据的挑战[46]常常导致研究人员生成合成数据，用于实验室评估</strong>（P9）。在这里，我们演示了这些数据如何不足以证明使用复杂模型（如神经网络）的合理性，以及将一个更简单的模型作为基线将如何揭示这些缺点（P6）。</p>
<p><strong>数据集集合</strong>：我们考虑Mirsky等人<a href>93</a>发布的数据集，其中包含物联网（IoT）网络流量的捕获，模拟Mirai僵尸网络恶意软件的初始激活和传播。该数据包覆盖了三台个人电脑和九台物联网设备的Wi-Fi网络上119分钟的流量.</p>
<p><strong>数据集分析</strong>：首先，我们分析捕获的网络流量的传输量。图8显示了捕获过程中良性和恶意数据包的频率，划分为10秒。这表明在分组频率中有一个强信号，这高度指示了一个持续攻击。<strong>此外，所有良性活动似乎都随着袭击的开始而停止。74分钟后，尽管网络上有很多设备。这表明个体观测可能已经合并，并可能进一步导致系统受益于虚假相关性</strong>（P4）</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551694.png" alt="image-20220807213124529" style="zoom:50%;"></p>
<blockquote>
<p>图:Mirai数据集中良性与恶意数据包的频率<a href>93</a>。灰色虚线显示了定义使用简单基线计算的正常流量的阈值（箱线图法[129]）。用于校准的数据范围由浅蓝色阴影区域突出显示.</p>
</blockquote>
<p><strong>实验设置</strong>：为了说明这些缺陷的严重程度，我们考虑了<strong>Kitsune<a href>93</a></strong>，这是一种基于深度学习的最先进入侵检测器，构建在一组au-toencoders上。对于每个数据包，提取115个特征，输入到12个自动编码器，这些自动编码器本身反馈到另一个作为异常检测器运行的最终自动编码器。</p>
<blockquote>

</blockquote>
<p><strong>作为与Kitsune进行比较的简单基线，我们选择了箱线图法[129]</strong>，这是一种识别异常值的常用方法。我们使用10秒滑动窗口处理分组，并使用每个窗口的分组频率作为唯一特征。接下来，我们从干净的校准分布推导出一个上下阈值：τlow=Q1−1.5·IQRand
，τ高＝Q3+1.5·IQR。<strong>在测试期间，如果滑动窗口的数据包频率在τ低和τ高之间，则数据包被标记为良性，否则为恶意。在图8中，这些阈值用灰色虚线表示。</strong></p>
<p><strong>后果</strong>：表5显示了与箱线图方法相比，自动编码器集成的分类性能。虽然两种方法在ROC
AUC方面表现相似，但简单箱线图法在低误报率（FPR）下优于自动编码器集成。<strong>除了其优越的性能外，箱线图方法与集成的特征提取和测试程序相比，重量非常轻</strong>。这一点尤其重要，因为集成设计用于在低延迟的资源受限设备（如物联网设备）上运行。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551172.png" alt="image-20220807220205015" style="zoom:50%;"></p>
<blockquote>
<p>表5：比较Kitsune<a href>93</a>，一种自动编码器集成NIDS，相比于一个简单基线，箱线图法[129]，用于检测Mirai感染。</p>
</blockquote>
<p><strong>注意</strong>：<strong>本实验的目的不是证明箱图法可以检测到野外操作的Mirai实例，也不是证明Kitsuneis无法检测到其他攻击，而是证明没有适当基线（P6）的实验不足以证明集成的复杂性和过度性</strong>。箱线图法的成功还表明，简单的方法可以揭示仅用于实验室评估的数据产生的问题（第9页）。在Mirai数据集中，感染过于明显；在野外进行的攻击很可能只占网络流量的一小部分。</p>
<h3><span id="五-总结">五、总结</span></h3>
<p>我们识别并系统地评估了机器学习在安全领域的应用中的十个细微缺陷。这些问题会影响研究的有效性，并导致高估安全系统的性能。我们发现这些陷阱在安全研究中非常普遍，并展示了这些陷阱在不同安全应用中的影响。为了支持研究人员避免这些问题，我们提供了适用于所有安全领域的建议，从入侵和恶意软件检测到漏洞发现。最终，我们努力提高安全领域机器学习实验工作的科学质量。在Sommer和Paxson[119]的开创性研究十年后，weagain鼓励社区深入封闭的世界，探索将机器学习嵌入现实世界安全系统的挑战和机遇。AI安全的十大缺陷/image-20220806171411086.png"
alt="image-20220806171411086" style="zoom:50%;" /&gt;</p>
<p>此外，文本中存在的一些陷阱比其他陷阱更容易被忽略。我们观察到，当没有对参数的描述时，这种有偏参数选择（P5）,给出了超参数或调谐过程；对于伪相关（P4），当没有试图解释模型的决定时；以及当文本中未明确描述数据集分割或归一化过程时的数据窥探（P3）。这些问题还表明，由于缺乏信息，实验设置更难复现；</p>
<p><strong>作者的反馈</strong>：为了促进我们社区内的讨论，我们联系了所选论文的作者，并收集了对我们研究结果的反馈。我们对135位有联系方式的作者进行了调查。为了保护作者的隐私并鼓励公开讨论，所有回复均匿名。调查包括一系列关于已识别缺陷的一般和具体问题。首先，我们询问作者是否阅读过我们的作品，并认为它对社区有帮助。其次，对于每一个陷阱，我们收集反馈信息，说明他们是否同意（a）他们的出版可能受到影响，（b）安全文件中经常出现陷阱，以及（c）在大多数情况下很容易避免。为了量化评估回答，我们对每个问题使用五点Likert量表，范围从强烈不同意到强烈同意。此外，我们提供了一个不回答的选项，并允许作者省略问题。我们收到了49位作者的反馈，回复率为36%。这些作者对应于30篇选定论文中的13篇，因此占考虑研究的43%。关于一般性问题，46（95%）的作者阅读了我们的论文，48（98%）同意这有助于提高对已识别缺陷的认识。对于具体的陷阱问题，作者和我们的发现之间的总体一致性平均为63%，这取决于安全区域和陷阱。所有的作者都认为他们的论文至少有一个缺陷。平均而言，他们指出他们的工作中存在2.77个陷阱，标准偏差为1.53，涵盖了所有十个陷阱。在评估总体缺陷时，作者特别同意，仅<strong>实验室评估（92%）、基本比率谬误（77%）、不适当的绩效衡量（69%）和抽样偏差（69%）经常发生在安全人员中</strong>。此外，他们指出，<strong>不适当的性能测量（62%）、不适当的参数选择（62%）和基准利率谬误（46%）在实践中可以很容易地避免</strong>，而其他陷阱需要更多的努力。我们在附录B中提供了关于该调查的更多信息。总之，我们从该调查中得出了三个中心观察结果。首先，大多数作者都同意，我们的社区缺乏对已识别缺陷的意识。第二，他们确认，这些陷阱在安全文献中很普遍，有必要减轻它们。第三，仍然缺乏对已识别缺陷的一致理解。例如，几位作者（44%）既不同意也不反对数据窥探是否容易避免，强调了明确定义和建议的重要性。我们发现§2中引入的所有陷阱在安全研究中都很普遍，影响了17%到90%的选定论文。每篇论文至少有三个陷阱，只有22%的实例与本文中的讨论相关。虽然作者在某些情况下甚至可能故意省略了对陷阱的讨论，但我们的患病率分析结果总体上表明，我们的社区缺乏认识。虽然这些发现指出了研究中的一个严重问题，<strong>但我们想指出，所有分析的论文都提供了出色的贡献和宝贵的见解。我们的目标不是责怪研究人员陷入陷阱，而是提高安全领域机器学习研究的意识和实验质量。</strong></p>
<h3><span id="四-影响分析">四、影响分析</span></h3>
<p>在前几节中，我们介绍了计算机安全文献中普遍存在的缺陷。然而，到目前为止，尚不清楚单个陷阱会在多大程度上影响实验结果及其结论。在本节中，我们估计了机器学习在安全领域的流行应用中的一些缺陷的实验影响。同时，我们展示了§2中讨论的建议如何帮助识别和解决这些问题。在我们的讨论中，我们考虑了计算机安全领域的四个热门研究主题：</p>
<ul>
<li><strong>移动恶意软件检测</strong>： (P1, P4, and P7)</li>
<li>漏洞发现： (P2, P4, and P6)</li>
<li>源代码作者归属：（P1和P4）</li>
<li><strong>网络入侵检测</strong>：（P6和P9）</li>
</ul>
<blockquote>
<p><strong>评论对于该分析，我们考虑了每个安全域的最先进方法</strong>。我们注意到，本节中的结果并不意味着具体批评这些方法；我们选择它们是因为它们代表了陷阱如何影响不同领域。值得注意的是，我们能够复制这些方法的事实高度赞扬了他们的学术水平;</p>
</blockquote>
<h4><span id="41-移动恶意软件检测">4.1 移动恶意软件检测</span></h4>
<p>使用机器学习自动检测Android恶意软件是一个特别活跃的研究领域。这种方法的设计和评估是微妙的，可能会显示出一些先前讨论的缺陷。在下文中，我们<strong>讨论了采样偏差（P1）、伪相关性（P4）和不适当的性能度量（P7）对基于学习的检测的影响</strong>；</p>
<p><strong>数据集集合</strong>：最近移动数据的一个常见来源是AndroZoop项目[6]，该项目从各种来源收集Android应用程序，包括Official
谷歌市场和几个中国app软件市场。在撰写本文时，它包括来自18个不同来源的超过1100万个Android应用程序。<strong>除了样本本身，它还包括元信息，如抗病毒检测的数量</strong>。虽然AndroZoo是获取移动应用的优秀来源，但我们证明，如果不考虑数据集的特性，实验可能会出现严重的抽样偏差（P1）。请注意，以下讨论不限于AndroZoo数据，而是与Android数据集的组成相关。</p>
<p><strong>数据集分析</strong>：在第一步中，我们通过考虑应用程序的来源和Android应用程序的防病毒检测数量来分析AndroZoo的数据分布。为了进行分析，我们将各个市场大致分为四个不同的来源：谷歌游戏、中国市场、VirusShare和所有其他市场。图4显示了从特定来源随机采样的概率，这取决于应用程序的防病毒检测数量。例如，当选择一个对检测次数没有限制的样本时，从谷歌游戏中采样的概率大约为80%。如果我们考虑10次检测的结果，我们从中国市场随机选择应用的概率是70%。如果我们忽略数据分布，数据集中的大部分良性应用很可能来自GooglePlay，而大多数恶意应用来自中国市场。请注意，此采样偏差不限于Andro
Zoo。我们确定了DredeBin数据集[9]的类似抽样偏差，该偏差通常用于评估基于学习的Android恶意软件检测方法的性能[9、58、146]。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551441.png" alt="image-20220807135625094" style="zoom: 67%;"></p>
<p><strong>实验装置</strong>：为了更好地理解这一发现，我们使用两个数据集进行了实验：</p>
<ul>
<li>对于第一个数据集（D1），我们将来自Google
Play的10000个良性应用程序与来自中国市场的1000个恶性应用程序（安齐安达应用程序中国）合并。</li>
<li>然后，我们使用相同的10000个良性应用程序创建第二个数据集（D2），但将它们与Google
Play独家提供的1000个软件样本相结合。所有合法的应用程序都至少被10个病毒扫描程序检测到。接下来，我们使用来自最先进分类器的两个特征集（DREBIN[9]和OPSEQS[91]），在这些数据集上训练线性支持向量机[47]。</li>
</ul>
<p><strong>实验结果</strong>：在数据集D1和D2之间，DREBIN 和
OPSDEQS的召回率（真阳性率）分别超过10%和15%，而准确性仅受到轻微影响（见表1）。因此，性能度量的选择至关重要（P7）。有趣的是，URLplay.google.Com
被证明是良性类的五个最具歧视性的特征之一，这表明分类者已经学会区分Android
apps的起源，而不是恶意软件和benign apps
之间的区别（P4）。<strong>虽然我们的实验装置通过故意忽略时间相关性（P3）高估了分类器的性能，但我们仍然可以清楚地观察到陷阱的影响</strong>。请注意，在以前的工作[4,
104]中已经证明了在这种情况下时间窥探的效果。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551324.png" alt="image-20220807211200980" style="zoom: 67%;"></p>
<h3><span id="42-漏洞发现">4.2 漏洞发现</span></h3>
<p>源代码中的漏洞可能导致权限提升和远程代码执行，使其成为主要威胁。由于手动搜索漏洞复杂且耗时，近年来提出了基于机器学习的检测方法[57，83，141]。在下面的内容中，我们展示了用于漏洞检测的数据集包含仅在一个类（P4）中发生的事件。我们还发现，用于检测脆弱性的神经网络Vuldeepecker[83]使用伪影进行分类，并且简单的线性分类器在相同的数据集上获得更好的结果（P6）。最后，我们讨论了forVulDeePecker提出的预处理步骤如何使我们无法确定某些代码片段是否包含漏洞（P2）</p>
<p><strong>数据集集合</strong>：在我们的分析中，我们使用了Li等人[83]发布的数据集，其中包含来自国家漏洞数据库[36]和SARD项目[37]的源代码。我们关注与缓冲区（CWE-119）相关的漏洞，并获得了39757个源代码片段，其中10444（26%）被标记为包含漏洞。</p>
<h3><span id="43-源代码作者归属">4.3 源代码作者归属</span></h3>
<p>基于源代码识别开发人员的任务称为作者归属[23]。编程习惯具有多种风格模式，因此</p>
<h4><span id="44-网络入侵检测检测">4.4 网络入侵检测检测</span></h4>
<p>网络入侵是安全[41]中最古老的问题之一，毫不奇怪，异常网络流量的检测严重依赖于基于学习的方法[27,81,82,93]。<strong>然而，收集真实攻击数据的挑战[46]常常导致研究人员生成合成数据，用于实验室评估</strong>（P9）。在这里，我们演示了这些数据如何不足以证明使用复杂模型（如神经网络）的合理性，以及将一个更简单的模型作为基线将如何揭示这些缺点（P6）。</p>
<p><strong>数据集集合</strong>：我们考虑Mirsky等人<a href>93</a>发布的数据集，其中包含物联网（IoT）网络流量的捕获，模拟Mirai僵尸网络恶意软件的初始激活和传播。该数据包覆盖了三台个人电脑和九台物联网设备的Wi-Fi网络上119分钟的流量.</p>
<p><strong>数据集分析</strong>：首先，我们分析捕获的网络流量的传输量。图8显示了捕获过程中良性和恶意数据包的频率，划分为10秒。这表明在分组频率中有一个强信号，这高度指示了一个持续攻击。<strong>此外，所有良性活动似乎都随着袭击的开始而停止。74分钟后，尽管网络上有很多设备。这表明个体观测可能已经合并，并可能进一步导致系统受益于虚假相关性</strong>（P4）</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551606.png" alt="image-20220807213124529" style="zoom:50%;"></p>
<blockquote>
<p>图:Mirai数据集中良性与恶意数据包的频率<a href>93</a>。灰色虚线显示了定义使用简单基线计算的正常流量的阈值（箱线图法[129]）。用于校准的数据范围由浅蓝色阴影区域突出显示.</p>
</blockquote>
<p><strong>实验设置</strong>：为了说明这些缺陷的严重程度，我们考虑了<strong>Kitsune<a href>93</a></strong>，这是一种基于深度学习的最先进入侵检测器，构建在一组au-toencoders上。对于每个数据包，提取115个特征，输入到12个自动编码器，这些自动编码器本身反馈到另一个作为异常检测器运行的最终自动编码器。</p>
<blockquote>

</blockquote>
<p><strong>作为与Kitsune进行比较的简单基线，我们选择了箱线图法[129]</strong>，这是一种识别异常值的常用方法。我们使用10秒滑动窗口处理分组，并使用每个窗口的分组频率作为唯一特征。接下来，我们从干净的校准分布推导出一个上下阈值：τlow=Q1−1.5·IQRand
，τ高＝Q3+1.5·IQR。<strong>在测试期间，如果滑动窗口的数据包频率在τ低和τ高之间，则数据包被标记为良性，否则为恶意。在图8中，这些阈值用灰色虚线表示。</strong></p>
<p><strong>后果</strong>：表5显示了与箱线图方法相比，自动编码器集成的分类性能。虽然两种方法在ROC
AUC方面表现相似，但简单箱线图法在低误报率（FPR）下优于自动编码器集成。<strong>除了其优越的性能外，箱线图方法与集成的特征提取和测试程序相比，重量非常轻</strong>。这一点尤其重要，因为集成设计用于在低延迟的资源受限设备（如物联网设备）上运行。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551961.png" alt="image-20220807220205015" style="zoom:50%;"></p>
<blockquote>
<p>表5：比较Kitsune<a href>93</a>，一种自动编码器集成NIDS，相比于一个简单基线，箱线图法[129]，用于检测Mirai感染。</p>
</blockquote>
<p><strong>注意</strong>：<strong>本实验的目的不是证明箱图法可以检测到野外操作的Mirai实例，也不是证明Kitsuneis无法检测到其他攻击，而是证明没有适当基线（P6）的实验不足以证明集成的复杂性和过度性</strong>。箱线图法的成功还表明，简单的方法可以揭示仅用于实验室评估的数据产生的问题（第9页）。在Mirai数据集中，感染过于明显；在野外进行的攻击很可能只占网络流量的一小部分。</p>
<h3><span id="五-总结">五、总结</span></h3>
<p>我们识别并系统地评估了机器学习在安全领域的应用中的十个细微缺陷。这些问题会影响研究的有效性，并导致高估安全系统的性能。我们发现这些陷阱在安全研究中非常普遍，并展示了这些陷阱在不同安全应用中的影响。为了支持研究人员避免这些问题，我们提供了适用于所有安全领域的建议，从入侵和恶意软件检测到漏洞发现。最终，我们努力提高安全领域机器学习实验工作的科学质量。在Sommer和Paxson[119]的开创性研究十年后，weagain鼓励社区深入封闭的世界，探索将机器学习嵌入现实世界安全系统的挑战和机遇。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（6）DeepReflect：通过二进制重构发现恶意行为</title>
    <url>/posts/2Y43CXR/</url>
    <content><![CDATA[<h2><span id="usenixsec21deepreflect通过二进制重构发现恶意行为经典">USENIXSec21
DeepReflect：通过二进制重构发现恶意行为（经典）</span></h2>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg5MTM5ODU2Mg&amp;mid=2247495981&amp;idx=1&amp;sn=fa34f5211e67a7d6c144019424657d22&amp;chksm=cfcf41e0f8b8c8f6e91705e142147a6803ca1af45aa8173727e7858788b1473da5b00db25d7b&amp;scene=178&amp;cur_album_id=1776483007625822210#rd">参考材料</a></p>
<p>原文作者：Evan Downing, Yisroel Mirsky, Kyuhong Park, Wenke Lee
原文标题：DeepReflect: Discovering Malicious Functionality through
Binary Reconstruction
原文链接：https://www.usenix.org/conference/usenixsecurity21/presentation/downing
发表会议：USENIXSec 2021
<strong>代码地址</strong>：https://github.com/evandowning/deepreflect</p>
</blockquote>
<h3><span id="一-摘要">一、摘要</span></h3>
<p>深度学习已在恶意软件分类任务中表现出良好的结果。然而：</p>
<ul>
<li><strong>人工分析效率低</strong>：对于未知恶意软件的binary，分析人员仍要花大量时间来利用静态分析工具逆向整个binary，从而识别关键的恶意行为</li>
<li><strong>监督学习开销大</strong>：尽管机器学习可用来帮助识别二进制的重要部分，但由于获取足够大的标记数据集开销很大，因此监督学习方法是不切实际的</li>
</ul>
<p><strong>为了提高静态（或手动）逆向工程的生产力，我们提出了DeepReflect：一种用于定位（localize）和识别（identify）恶意二进制文件中恶意软件组件的工具。</strong></p>
<ul>
<li>为了定位恶意软件组件，我们以一种新型（novel）方式，即首先使用一个<strong>无监督的深度神经网络l来定位恶意软件中恶意组件（函数）的位置</strong></li>
<li><strong>其次，通过半监督聚类分析对恶意组件进行分类，根据恶意行为分类确定恶意函数的行为</strong>，其中分析人员在他们的日常工作流程中逐步提供标签</li>
<li>该工具是实用的，因为它不需要数据标记（require no data
labeling）来训练定位模型，也不需要最小/非侵入性标记来增量地训练分类器</li>
</ul>
<h4><span id="11-企业界对比capa">1.1 <strong>企业界对比：CAPA</strong></span></h4>
<p>我们通过5个恶意软件分析人员对超过26k个恶意软件样本进行评估。<strong>实验发现，DeepReflect让每个分析人员需要逆向工程的函数数量平均减少了85%</strong>。本文方法还可以检测到80%的恶意软件组件，而当使用基于签名的工具CAPA时，该值仅为43%。</p>
<h4><span id="12-学术界对比shap">1.2 <strong>学术界对比：Shap</strong></span></h4>
<p>此外，DeepReflect提出的自动编码器（autoencoder）比Shap（一种人工智能解释工具）表现得更好。这一点很重要，因为<strong>Shap是一种最先进（state-of-the-art）的方法，需要一个标记的数据集</strong>，而我们的自动编码器不需要。</p>
<h3><span id="二-引言">二、引言</span></h3>
<h4><span id="21-背景引出挑战">2.1 背景引出挑战</span></h4>
<p>静态逆向工程恶意软件可能是一个手动且乏味的过程。公司每周可以收到多达
500
万个PE样本。虽然大多数组织提前对这些样本进行分类（triage），以减少要分析的恶意软件数量（即，检查
VirusTotal来获取反病毒 (AV)
引擎结果、在受控沙箱中执行样本、提取静态和动态签名等）
，但最终仍然需要静态逆向工程的恶意软件样本。这是因为<strong>总会有新的恶意软件样本</strong>，没有被反病毒公司分析过，或者缺乏签名来识别这些新样本。最终，该样本有可能会拒绝在分析人员的动态沙箱（sandbox）中执行。</p>
<p>当前的解决方案以为恶意软件样本创建签名、分类和聚类的形式存在。然而，这些解决方案只能预测样本的类别（例如，良性与恶意，或特定的恶意软件家族）。<strong>他们无法定位或解释恶意软件样本本身内部的行为（定位恶意函数位置、解释恶意函数行为），而分析师需要执行（perform）这些行为来生成报告并改进他们公司的恶意软件检测产品</strong>。事实上，由于工作量过大，该领域已呈现了倦怠。</p>
<p>为了确定他们的需求，我们咨询了四名逆向工程恶意软件分析师（一名来自AV公司，三名来自政府部门）。本文发现，如果恶意软件分析师有一个工具可以：</p>
<ul>
<li><strong>识别恶意软件中恶意函数的位置</strong></li>
<li><strong>标记这些恶意函数的行为</strong></li>
</ul>
<p>那么，他们的工作将更有效率。开发这样一种工具的挑战在于：</p>
<ul>
<li><strong>需要能够区分什么是良性的（benign），什么是恶意的（malicious）</strong></li>
<li><strong>理解识别出的恶意行为的语义</strong></li>
</ul>
<p>对于第一个挑战，区分良性和恶意是困难的，因为恶意软件和良性软件的行为通常在高层次上重叠。对于第二个挑战，自动标记和验证这些行为是很困难的，因为没有单独标记的恶意软件函数的数据集（与使用反病毒标签的开放数据集的恶意软件检测和分类系统不同）。</p>
<h4><span id="22-如何解决挑战">2.2 如何解决挑战</span></h4>
<p>为了解决这些挑战，我们开发了DEEPREFLECT，它使用：</p>
<ul>
<li><font color="red"><strong>一个无监督的深度学习模型来定位二进制中的恶意函数【异常检测】</strong></font></li>
<li><font color="red"><strong>一个半监督聚类模型，它使用从分析人员的日常工作流程中获得的少量标签对识别的函数进行分类</strong></font></li>
</ul>
<p><strong>为了定位（locate）二进制文件中的恶意软件组件，我们使用自动编码器(autoencoder，AE)</strong>。AE是一种基于神经网络的机器学习模型，<strong>其任务是将其输入重构为输出（编码还原）</strong>。由于网络内层存在压缩，AE被迫学习训练分布中的关键概念。我们的直觉是，如果在良性二进制文件上训练AE，它将很难重建恶意二进制文件（即我们没有训练它的样本）。自然地，AE将无法重建（reconstruct）包含恶意行为的二进制数据区域（在良性样本中是不可见或罕见的）。<font color="red"><strong>因此（Thus），重构错误可以用来识别恶意软件中的恶意组件</strong></font>。此外，由于AE是以无监督的方式训练的，我们不需要数百万标记的样本，公司可以利用自己的恶意软件二进制数据集。</p>
<p><strong>为了对定位的恶意软件组件进行分类</strong>，我们：</p>
<ul>
<li>对恶意软件样本中所有已识别的函数进行聚类</li>
<li>使用分析人员在日常工作流程中所做的注释（即少量人工分析的函数行为标签）来标记聚类结果</li>
</ul>
<p><strong>这种方法是半监督的，因为每个类簇（cluster）只需要少数函数的行为标签（如三个）即可将大多数标签分配给整个集群</strong>。随着时间推移，我们可以将AE识别的函数映射到聚类模型来预测函数的类别（如，C&amp;C、特权升级等），即认为函数和最接近的类簇有相同的行为标签。这反过来又节省了分析人员的时间，因为他们不必一次又一次地对相同的代码进行逆向工程。</p>
<p>注意，无监督 AE
为恶意软件分析人员提供了即时实用程序，无需训练或使用半监督聚类模型。这是因为它：</p>
<ul>
<li><strong>通过对最相关的函数进行排序（重构误差）来吸引分析师的注意力</strong></li>
<li>过滤掉可能需要花费分析师数小时或数天时间来解释的函数</li>
</ul>
<blockquote>
<p>DEEPREFLECT根据我们是为恶意软件分析人员的反馈进行设计和修改的，并评估其有效性和实用性。</p>
<p><strong>我们评估了DEEPREFLECT的性能，包括五个工作：</strong></p>
<ul>
<li>识别恶意软件中的恶意活动</li>
<li>聚类相关的恶意软件组件</li>
<li>将分析人员的注意力集中在重要事情上</li>
<li>揭示不同恶意软件家族之间的共享行为</li>
<li>处理涉及混淆的对抗性攻击</li>
</ul>
</blockquote>
<h4><span id="23-创新contribution">2.3 创新（Contribution）</span></h4>
<p><strong>我们的贡献如下：</strong></p>
<ul>
<li><strong>提出了一个新颖的工具，它可以帮助恶意软件分析师：(1)
在静态恶意软件样本中自动定位和识别恶意行为，(2)
洞察分析不同恶意软件家族之间的功能关系。</strong></li>
<li><strong>提出一种在静态分析中使用机器学习的新颖实用方法</strong>：（1)
AE训练是在一种无监督方式下进行的，<strong>无需为系统标注任何样本</strong>，就可以产生突出显示恶意软件组件的实用程序，(2)
分类是以半监督方式完成，<strong>具有最小的干预</strong>：分析人员的常规工作流的注释用作标签，群集中的大多数标签用于对相关的恶意软件组件进行分类。</li>
<li>本文提出了一种解释框架（如我们提出的 AE 或
SHAP）定位恶意软件重要部分的方法，该方法可以<strong>映射回原始二进制或控制流图的特征</strong>。</li>
</ul>
<h3><span id="3-scope-amp-overview">3 <strong>Scope &amp; Overview</strong></span></h3>
<h4><span id="31-motivation">3.1 Motivation</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550446.png" alt="图片" style="zoom: 67%;"></p>
<p><font color="red"><strong>图1展示了一个典型的恶意软件分析师Molly的工作流程</strong>
</font>。当给定一个恶意软件样本，Molly的任务是了解该样本在做什么，以便她写一份技术报告并改进公司的检测系统，从而在未来识别该类样本。</p>
<ol type="1">
<li><strong>首先查询VT（virtotul）和其他组织</strong>，以确定他们以前是否见过这个特定的样本，然而并没有</li>
<li>在一个自定义的<strong>沙箱中执行样本以了解其动态行为</strong>，然而没有显示任何恶意行为或拒绝执行；运行一些内部工具，诱使恶意软件执行其隐藏的行为，但仍无效时；</li>
<li>尝试<strong>脱壳（unpacking）</strong>和<strong>静态逆向分析恶意样本</strong>，以了解其潜在行为</li>
<li><font color="red"><strong>在反汇编程序（IDA Pro 或
BinaryNinja）中打开脱壳后的样本，被数千个函数淹没，接着运行各种静态签名检测工具来识别恶意软件的某些特定恶意组件，但仍无效</strong></font></li>
<li>逐个<strong>查看每个函数（可能通过 API
调用和字符串过滤）以尝试了解它们的行为</strong></li>
<li><strong>在分析样本的行为后，撰写分析报告（包含基本信息、IOC、静态签名等）</strong></li>
</ol>
<p>然而，当新的样本出现时，Molly需要重复同样的任务。由于这种重复的体力劳动，这项工作对Molly来说变得单调乏味和耗时。<font color="red">
<strong>DEEPREFLECT旨在减轻恶意分析师的分析工作，能逆向一个未知的恶意软件样本，从而减轻他们繁重的任务，并为相似的函数标注行为标签。</strong></font></p>
<h4><span id="32-proposed-solution">3.2 Proposed Solution</span></h4>
<p>我们提出了<strong>DEEPREFLECT</strong>，该工具能：</p>
<ul>
<li><p><strong>定位恶意软件binary中的恶意函数</strong></p>
<blockquote>
<p>locates malicious functions within a malware binary</p>
</blockquote></li>
<li><p><strong>描述这些函数的行为</strong></p>
<blockquote>
<p>describes the behaviors of those functions</p>
</blockquote></li>
</ul>
<p>虽然分析人员可能首先尝试通过搜索特定的字符串和API调用来静态地识别行为，但这些行为很容易被分析人员混淆或隐藏（
obfuscated or
hidden）。<strong>DEEPREFLECT没有做出这样的假设，并试图通过控制流图(control-flow
graph，CFG)特性和API调用（API
calls）的组合来识别这些相同的行为</strong>。</p>
<p><font color="red">
<strong>DEEPREFLECT通过学习正常情况下良性的二进制函数来工作</strong></font>。因此，任何异常都表明这些函数不会出现在良性二进制文件中，而可能被用于恶意行为中。这些异常函数更可能是恶意函数，分析师可以只分析它们，从而缩小工作范围。如图5所示，DEEPREFLECT将分析师必须分析的函数数量平均减少了
85%。此外，实验表明我们的方法优于旨在实现相同目标的基于签名的技术。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550151.png" alt="图片" style="zoom:67%;"></p>
<h4><span id="33-research-goals">3.3 Research Goals</span></h4>
<p>本文有四个主要目标：</p>
<ul>
<li>准确地识别恶意软件样本中的恶意活动</li>
<li>帮助分析人员在静态分析恶意软件样本时集中注意力</li>
<li><strong>处理新的（不可见的）恶意软件家族</strong></li>
<li><strong>深入了解恶意软件家族的关系和趋势</strong></li>
</ul>
<h3><span id="4-模型设计">4、模型设计</span></h3>
<h4><span id="41-总体框架">4.1 总体框架</span></h4>
<p><strong>DEEPREFLECT的目标是识别恶意软件二进制中的恶意函数</strong>。在实践中，<font color="red"><strong>它通过定位异常基本块（感兴趣区域
regions of
interest，RoI)来识别可能是恶意的函数</strong></font>。然后，分析人员必须确定这些函数是恶意行为还是良性行为。DEEPREFLECT有两个主要步骤，如图2所示：</p>
<ul>
<li><strong>RoI检测（RoI
detection）</strong>：通过AE（AutoEncoder）来执行的</li>
<li><strong>RoI注释（RoI
annotation）</strong>：通过对每个函数的所有RoI聚类，并将标记聚类结果来执行注释。注意，一个函数可能有多个ROI，用每个函数自己的ROI的均值表示该函数，然后对函数聚类</li>
</ul>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550631.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h5><span id="1术语-terminology">（1）术语 Terminology</span></h5>
<p><strong>首先定义恶意行为（malicious
behaviors）的含义</strong>。我们根据识别恶意软件源代码的<strong>核心组件</strong>（例如，拒绝服务功能、垃圾邮件功能、键盘记录器功能、命令和控制C&amp;C功能、利用远程服务等）来生成真实情况（ground-truth）。<font color="red"><strong>通过MITRE
ATT&amp;CK框架描述</strong></font>，如表3所示。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550843.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p><strong>然而，当静态逆向工程评估恶意软件二进制文件时（即在野生恶意软件二进制
in-the-wild malware
binaries），我们有时无法肯定地将观察到的低级函数归因于更高级别的描述</strong>。</p>
<p>例如，恶意软件可能会因为许多不同的原因修改注册表项，但有时确定哪个注册表项因什么原因而被修改是很困难的，因此只能粗略地标记为“<font color="red"><code>防御逃避：修改注册表（Defense Evasion: Modify Registry）</code>”
</font>。即使是像CAPA这样的现代工具，也能识别出这些类型的模糊标签。<strong>因此，在我们的评估中，我们将“恶意行为”表示为可由MITRE
ATT&amp;CK框架描述的函数。</strong></p>
<h5><span id="2-roi-detection">（2） <strong>RoI Detection</strong></span></h5>
<p><strong>检测的目标是自动识别恶意软件二进制文件中的恶意区域</strong>。例如，我们希望检测C&amp;C逻辑的位置，而不是检测该逻辑的特定组件（例如，网络API调用connect()、send()
和
recv()）。<strong>RoI检测的优点是分析人员可以快速定位启动和操作恶意行为的特定代码区域</strong>。先前的工作只关注于创建临时签名，简单地将二进制文件标识为恶意软件或仅基于API调用的某些函数。这对于分析人员扩大他们的工作特别有用（即不仅仅依赖手动逆向工程和领域专业知识）。</p>
<h5><span id="3-roi-annotation"><strong>(3) RoI Annotation</strong></span></h5>
<p><strong>注释的目标是自动标记包含RoI的函数的行为，即识别恶意函数在做什么</strong>。由于分析人员为标记集群所执行的初始工作是一个长尾分布。也就是说，只需要前期做比较重要的工作，随着时间推移，工作量会减少。这个过程的优点很简单：它为分析人员提供了一种自动生成未知样本的报告及见解的方法。例如，如果恶意软件示例的变体包含与之前的恶意软件示例相似的逻辑（但对于分析人员来说看起来不同以至于不熟悉），我们的工具为他们提供了一种更快实现这一点的方法。</p>
<h4><span id="42-roi-detection">4.2 RoI Detection</span></h4>
<p>首先介绍了AutoEncode（AE）神经网络。此外，先前的工作已经证明，当自动编码器在良性分布上进行训练时，AE可以检测到恶意（异常）行为。我们的假设是，与良性二进制文件相比，恶意软件二进制文件将包含相似但独特的功能。</p>
<p>当使用大量良性样本训练AE后，给定一个随机的样本，可以利用公式(2)计算，超过<strong>MSE</strong>的即认为是恶意区域，突出显示ROI异常基本块。与先前识别整个样本为恶意区域的工作相比，我们识别了每个样本中的恶意区域。具体而言，我们计算的
<code>localized MSE</code> 定义如下： <span class="math display">\[
\operatorname{LMSE}(x, \hat{x})=\left(x^{(i)}-\hat{x}^{(i)}\right)^{2}
\]</span></p>
<h4><span id="1features"><font color="red">
（1）<strong>Features</strong></font></span></h4>
<p>为了在二进制样本中定位恶意行为的位置，编码使用的特征必须一对一的映射回原样本。<strong>因此，作者将每个二进制文件表示为一个
m×c
的矩阵，该矩阵使用c个静态特征捕获前m个基本块以总结样本的behavior</strong>。<strong>m设置为20k个基本块，是因为95%的数据集样本具有20k或者更少的基本块，
c设置为18个特征</strong>。<strong>基本块</strong>通常是以控制传输指令结尾的一系列指令。当然，根据反汇编程序的不同，基本块可能会有不同的表示，因此这种严格的定义可能不适用于所有静态恶意软件分析系统。</p>
<p>我们特征（c）的灵感来自于先前工作中发现的特征，即<strong>属性控制流图（attributed
control flow
graph，ACFG）</strong>特征<strong>[23,75]</strong>。在这些工作中，ACFG特征被选择来执行二进制相似性，因为它们假设这些特征(由结构和数字CFG特征组成)将在多个平台和编译器上是一致的。</p>
<blockquote>
<p><strong>[23] Scalable graph-based bug search for firmware images.
2016 CCS</strong></p>
<p><strong>[75] Neural Network-based Graph Embedding for Cross-Platform
Binary Code Similarity Detection. 2017 CCS</strong></p>
</blockquote>
<p>虽然可以说我们的目标是相似的（即识别二进制文件之间的异同），但我们专门为研究恶意软件定制了这些功能。特别是，我们选择了autoencoder要使用的功能，以捕获更高级别的行为。我们的特征包括每个<strong>基本块中的指令类型计数</strong>（为ACFG特征提取的指令类型的更详细形式）、<strong>CFG的结构特征</strong>和<strong>API调用类别</strong>（用于总结恶意软件程序行为[18]），将每个基本块总结如下：</p>
<h5><span id="astructural-characteristics"><font color="red">(a)
<strong>Structural Characteristics</strong> </font></span></h5>
<p><strong>结构特征2个</strong>，每个<strong>基本块的后代（offspring）数量</strong>和<strong>betweenness
score</strong>，可以描述不同功能的<strong>控制流结构</strong>，比如网络通信（connect,
send, recv）或文件加密（findfile, open, read, encrypt, write,
close）。如图所示:</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550517.png" alt="image-20220602164403223" style="zoom:67%;"></p>
<blockquote>
<p>该恶意软件通过InternetOpenUrlA() 访问URL，通过CreateFileA()
创建文件，并通过InternetReadFile() 和WriteFile()
将从连接接收的数据写入文件。</p>
</blockquote>
<p><strong>(b) Arithmetic Instructions</strong></p>
<p><strong>算术指令3个</strong>，每个<strong>基本块基本数学、逻辑运算、位移指令的数量</strong>（“basic
math”, “logic operation”, and “bit
shifting”）。这些算术指令特征可以用来表示如何对更高层次的行为执行数学运算，以及数字如何与函数交互。例如，加密函数可能包含大量的xor指令，混淆函数可能包含逻辑和位移操作的组合等。<strong>我们从《英特尔体系结构软件开发人员手册》[26]中检索到这些说明</strong>。此外，我们还提供了一个恶意软件示例，在图中展示了这些类型的功能。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550537.png" alt="image-20220602164519015" style="zoom:67%;"></p>
<blockquote>
<p>此函数对数据执行各种按位操作。类似这样的复杂逻辑可以解释为执行某种除臭或解码，以隐藏恶意软件解释或收集的数据。</p>
</blockquote>
<p><strong>(c) Transfer Instructions</strong></p>
<p><strong>转移指令</strong>3个，每个基本块<strong>内堆栈操作，寄存器操作和端口操作的数量</strong>（“stack
operation”, “register operation”, and “port
operation”）。这些底层特征可描述更高级别函数的<strong>传输操作</strong>，比如函数的参数和返回值是如何与函数内其余数据交互的，从而描述更复杂的逻辑和数据操作。<strong>例如去混淆、解密函数可能设计更多move-related指令，C&amp;C逻辑设计更多堆栈相关指令</strong>。因为它调用了更多的内部/外部函数。我们同样从《英特尔体系结构软件开发人员手册》中检索到了这些说明</p>
<p><strong>(d) API Call Categories</strong></p>
<p><strong>API类别10个</strong>，我们使用的API调用特性是每个基本块中与<strong>“文件系统”、“注册表”、“网络”、“DLL”、“对象”、“进程”、“服务”、“同步”、“系统信息”和“时间”相关的API调用的数量</strong>。这些类别的灵感来自<strong>priorwork
for malware
clustering</strong>[18]。这些特性可用于表示执行恶意活动（如网络通信和文件系统、注册表和进程操作）所需的高级库操作。由于这些直接表示高级行为，因此它们对于理解函数的总体行为至关重要。<strong>下图显示了利用这些不同调用类型执行不同行为的恶意软件功能的示例。</strong></p>
<blockquote>
<p><strong>[18] Scalable, Behavior-Based Malware Clustering. NDSS
2009.</strong></p>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550690.png" alt="image-20220602164417162" style="zoom:67%;"></p>
<blockquote>
<p>此函数用于搜索具有特定扩展名（即doc、jpg等）的各种文件。然后将这些文件复制到单独的位置。此行为可能是针对其他恶意行为的设置，如数据外泄或勒索。</p>
</blockquote>
<p><strong>我们认为，与经典的ACFG功能相比，这些功能更适合恶意软件</strong>，因为（1）它们包括在priorwork中用于恶意软件检测的API调用（2）<strong>指令类别更细粒度，允许每个基本块中有更多的上下文</strong>（如前所述）以及（3）<font color="red"><strong>它们不依赖太容易规避攻击的字符串</strong></font>[77]。当然，如果有一个有动机的对手，任何机器学习模型都可能受到攻击和欺骗，从而产生错误和意外的输出。虽然我们的功能和模型也不例外，但我们认为它们足以产生可靠的模型（即，其行为符合预期），并使其变得足够困难，以至于对手必须广泛地工作以产生误导性的输入（如中所示 4.7).
有关对我们系统的潜在攻击的讨论，请参阅 5.</p>
<h4><span id="2模型">（2）模型</span></h4>
<p><strong>Autoencoder使用U-Net模型，U-Net的优点是其在编码器和解码器之间有跳过连接（skip
connections），对样本x可以跳过某些特征的压缩以在重构的x’中保持更高的保真度</strong>。</p>
<p>首先收集大量的良性样本，对每个binary抽取上述18个静态特征用于表示该binary。设有用feature表示的样本x，AE重构后得到x’，训练的目标是最小化重构损失，即输入x和输出x’之间的损失。</p>
<p><strong>RoI
Detection会在m个基本块中检测出一些异常基本块</strong>。这些基本块分别属于不同的函数，使用例如BinaryNinja的工具就可以确定ROI属于哪些函数，即认为这些函数可能是恶意函数，也就完成了恶意函数定位的任务。<strong>后续RoI
Annotation就是对这些函数聚类，完成恶意函数行为标记（分类）的任务。</strong></p>
<h4><span id="43-roi-annotation">4.3 RoI Annotation</span></h4>
<p><strong>给定一个新样本x，我们希望识别其每个函数的行为（类别），并将其报告给Molly</strong>。由于标记所有的函数都是不实用的，所以我们只注释了少量的函数，并使用聚类分析来传播结果。</p>
<h5><span id="1clusteringfeatures">（1）<strong>Clustering
Features</strong></span></h5>
<p>假设一组脱壳恶意软件，按上述特征提取方式（18种特征）得到每个binary的特征表示，其中一个binary为x。</p>
<p><strong>（2）Clustering Model</strong></p>
<p>使用PCA将特征数从18降维至5，然后使用HDBSCAN算法对5维特征聚类。</p>
<h3><span id="五-实现">五、实现</span></h3>
<p>接下来，我们将描述如何部署和使用它。</p>
<p><strong>(1) Initialization</strong></p>
<ul>
<li>首先对良性和恶意binaries脱壳</li>
<li>提取binary静态特征，形成20×18的矩阵</li>
<li><strong>用良性样本训练AutoEncoder</strong></li>
<li><strong>使用训练好的AE从恶意样本中提取ROIs，即恶意基本块位置</strong></li>
<li>计算恶意二进制中恶意函数的行为表示，加入聚类的训练集D</li>
<li>PCA降维并聚类生成C</li>
</ul>
<p>人工分析恶意软件手动打标，这些label注释到聚类训练集中，从而评估实验结果。换句话说，每个cluster只需要其中几个函数的label，就可确定整个cluster的label，即确定整个cluster中函数的恶意行为。</p>
<p><strong>(2) Execution</strong></p>
<p>当Molly收到一个新的样本x，DeepReflect会自动定位恶意函数并标注恶意行为。</p>
<ul>
<li><strong>对样本x执行脱壳（unpack）</strong></li>
<li>通过AutoEncoder获取ROIs</li>
<li>使用BinaryNinja以及ROIs确定恶意函数集合，然后计算恶意函数的行为表示</li>
<li>PCA模型降维</li>
<li>计算每个恶意函数最相近的集群，通过计算和聚类中心的距离实现</li>
<li>分配大数据集群注释给函数</li>
</ul>
<p>接下来，Molly分析highlighted functions，从而实现：</p>
<ul>
<li>obtains a better perspective on what the malware is doing</li>
<li>annotates any function labeled “unknown” with the corresponding
MITRE category (dynamically updating D)</li>
<li>observe shared relationships between other malware samples and
families by their shared
clusters（共享关系，分析恶意软件家族的相关性）</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（4）【draft】You are What you Do</title>
    <url>/posts/7X1P6X/</url>
    <content><![CDATA[<h2><span id="youare-what-you-do-hunting-stealthy-malware-via-data-provenanceanalysis">You
Are What You Do: Hunting Stealthy Malware via Data Provenance
Analysis</span></h2>
<p>https://blog.csdn.net/ll14856lk/article/details/122151992</p>
<p>https://mzgao.blog.csdn.net/article/details/118355956</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>AI安全（4）Black-Box Adversarial Attacks Against Deep Learning Based Malware Binaries Detection with GAN</title>
    <url>/posts/35K4AXJ/</url>
    <content><![CDATA[<h2><span id="black-boxadversarial-attacks-against-deep-learning-based-malware-binariesdetection-with-gan">Black-Box
Adversarial Attacks Against Deep Learning Based Malware Binaries
Detection with GAN</span></h2>
<h3><span id="摘要">摘要：</span></h3>
<p>​
<strong>【目的】</strong>为了有效地检测恶意软件，有越来越多的基于原始软件二进制文件的深度学习方法。最近的研究表明，深度学习模型很容易被愚弄，通过对输入引入细微的扰动而做出错误的决定，这在对抗性攻击中吸引了大量的工作。<strong>【缺点】</strong>然而，大多数现有的攻击方法都是基于手动特性（例如API调用）或白盒设置，使得这些攻击在当前的现实场景中是不切实际的。<strong>【工作】</strong>在这项工作中，我们提出了一种新的攻击框架，称为GAPGAN，它通过生成对抗网络（GANs）生成对抗有效负载（填充字节）。据我们所知，这是第一个针对基于深度学习的恶意软件二进制文件检测在字节级别执行端到端黑盒攻击的工作。<strong>【创新一】</strong>在我们的攻击框架中，我们将输入的离散恶意软件二进制文件映射到连续空间，然后将其提供给GAPGAN的生成器以生成对抗性有效载荷。我们将有效载荷附加到原始二进制文件中，以便在保留其功能的同时创建一个对抗性示例。<strong>【创新二】</strong>我们建议使用动态阈值来减少有效载荷从连续格式映射回原始离散格式时的有效性损失。为了平衡生成器对有效负载和对抗性样本的关注，我们使用了一种自动权重调整策略。<strong>【结果】</strong>我们用恶意软件和良性软件训练GAPGAN。一旦训练完成，生成器可以在不到20毫秒的时间内生成一个只包含输入恶意软件的对抗性样本，我们应用GAPGAN攻击最先进的探测器MalConv，只需附加2.5%的有效负载即可达到100%的攻击成功率。我们也在不同的防御方法下攻击具有不同结构的深度学习模型。实验结果表明，GAPGAN在效率和有效性上都优于其他最新的攻击模型。</p>
<h3><span id="一-说明">一、说明</span></h3>
<p>深度神经网络已经取得了巨大的成功，越来越多的工作倾向于使用深度学习进行有效的恶意软件检测。其中，一些工作（例如，[5]和[12]）基于可能包含程序恶意行为的手动功能（例如，API调用）检测恶意软件，一些工作（例如，[21]、[24]和[4]）直接使用软件信息而不运行，其他工作（例如，[13]和[20]）集成上述策略或使用其他方法，如可视化。最近，有一种趋势是使用原始二进制文件进行恶意软件检测，它可以有效地挖掘文件不同部分之间的潜在关系。随着恶意软件的快速发展，防御效率在当今的现实场景中变得至关重要，这使得基于原始二进制文件的端到端检测更具前景。</p>
<p>然而，许多研究工作（[25]、[7]、[17]、[9]和[27]）表明，深层神经网络容易受到对抗性攻击。攻击者对原始数据添加了人类无法察觉的小干扰，这可能会误导分类器做出错误的决策。这些研究指出，深度学习算法和人工智能应用的安全性面临严重威胁。</p>
<p>在恶意软件检测中，大多数对抗性攻击（例如，<strong>[14]、[15]和[3]</strong>【<strong>问题空间扰动</strong>】）依赖于检测器的完整信息（例如，白盒攻击）。<strong>然而，这种攻击有其局限性，例如，目标模型必须完全暴露给攻击者</strong>。同时，之前的攻击工作（例如，[11]、[2]和[23]
【<strong>特征空间扰动</strong>】）基于推测用于训练探测器的手动特征。<strong>如果猜测是错误的，或者一旦后卫改变了训练策略，这种攻击将无效。</strong>基于原始二进制文件的检测的广泛使用也使得这种需要大量资源和时间来提取特征的攻击不适用。与手动特性不同，即使稍加修改，也不能简单地更改原始二进制数据，否则会损坏其功能。此外，二进制数据的大小差异很大，这进一步增加了攻击难度。我们还发现，在保存生成的对抗性样本时，将连续空间中的对抗性有效载荷转换回离散二进制时，会忽略细微的扰动，这会影响对抗性攻击的有效性。<strong>因此，如何在保护原有功能的同时，对基于恶意软件二进制文件的深度学习模型进行有效而实用的黑盒攻击仍然是一个巨大的挑战。</strong>本文提出了一种新的攻击框架GAPGAN，该框架通过GANs生成对抗性有效载荷。据我们所知，这是第一项针对基于深度学习的恶意软件二进制文件检测在字节级别执行端到端黑盒攻击的工作。我们应用GAPGAN攻击最先进的检测器MalConv[21]以及其他具有不同结构的深度学习模型。实验表明，我们的模型可以实现较高的攻击成功率，并且在效率和有效性方面优于其他最先进的攻击方法。</p>
<p>We have the following contributions:</p>
<ul>
<li>我们提出了一种新的对抗性攻击框架GAPGAN，该框架在字节级对基于深度学习的恶意软件二进制检测执行端到端的黑盒攻击，使攻击更加高效。</li>
<li>在GAPGAN中，生成器生成对抗性有效载荷，ap将其挂起到原始数据，以制作恶意软件对抗性样本，同时保留其功能。一旦训练过程完成，生成器可以在不到二十毫秒的时间内高效地生成每个对抗性样本。</li>
<li><strong>我们建议在将有效负载从连续空间映射回离散二进制文件时，使用动态阈值来减少有效负载有效性的损失。为了平衡生成器对有效负载和对抗性样本的关注，我们采用了自动权重调整策略。</strong></li>
<li>我们应用GAPGAN攻击最先进的恶意软件检测器MalConv。实验表明，GAPGAN生成的对抗性样本在附加2.5%数据长度的对抗性有效载荷进行检测时，攻击成功率可达100%。实验还表明，GAPGAN在不同防御方式下的效率和有效性均优于其他最先进的攻击方法。</li>
</ul>
<p>论文的剩余部分由五个部分组成：第二部分介绍了本文的研究背景和相关工作。在第3节中，我们将解释攻击框架GAPGAN的详细信息。在第4节中，我们描述了实验设置，包括数据集、指标和目标模型。在第5节中，我们展示了我们的实验结果。在第6节中，我们总结了我们的工作并给出了结论。</p>
<h3><span id="二-背景和相关工作">二、背景和相关工作</span></h3>
<h4><span id="21针对恶意软件检测的对抗性攻击">2.1
针对恶意软件检测的对抗性攻击</span></h4>
<p>大多数用于恶意软件检测的传统机器学习和深度学习方法（例如，[5]和[12]）侧重于从程序的行为信息中提取的手动特征，如签名和API调用。对于这种检测方法，早期的攻击工作主要基于防守者应该使用的手动特征。一些工作建议使用API作为二进制特性，然后采用深度学习模型来生成对抗性样本（[11]和[8]）。一种基于API调用序列的不同方法使用优化过程来执行对抗性攻击【23】。[2]
建议使用强化学习进行攻击，它包含大量手动信息作为特征，例如PE头元数据、节元数据和字节直方图。Xu等人[29]提出了一种基于遗传编程的攻击方法，对文件结构进行随机操作。然而，这些攻击需要专家经验和大量的时间来获得有效的特征，一旦防御者知道用于攻击的特征，快速更新的检测器就可以轻松规避攻击。</p>
<p>最近的恶意软件检测工作（例如，[21]、[24]和[4]）更注重对原始软件二进制文件使用深度学习模型，因为深度神经网络可以有效地挖掘原始数据中的潜在特征，而无需大量数据预处理和先验经验。为了赶上最新的恶意软件检测技术，攻击者开始寻找可应用于原始软件二进制文件的新方法（例如，[14]、[15]和[3]）。与提取的特征不同，原始二进制数据不能简单地更改，否则可能会丢失重要功能。此外，原始二进制文件具有可变的输入大小，这会进一步使这些攻击比以前更加棘手。</p>
<p>[14]
提出了第一种字节级的对抗性攻击，它结合了梯度上升和贪婪策略。它会在文件末尾逐个追加字节，以保留其功能。然而，它执行的白盒攻击在现实场景中有局限性，模型需要计算每个填充字节的梯度，这会消耗大量时间和资源。[15]
还提出了一种通过注入局部扰动来处理离散序列的方法。但是，它处于白盒设置中，效率不高。[3]
提出了白盒和黑盒方法。在黑盒方法中，它随机选择良性数据块并将其附加到恶意软件数据中，每次都测试结果。在执行攻击之前，获取有效块需要大量时间。这种方法简单但繁琐且效率低下，不适用于有效的恶意软件对抗性样本生成。相反，我们将展示我们的端到端框架可以在黑盒环境中进行攻击，并在更短的时间内生成对抗性样本。</p>
<h4><span id="22-generative-adversarialnetworks-gans">2.2 Generative Adversarial
Networks (GANs)</span></h4>
<p>近年来，生成性对抗网络（GANs）[6]广泛应用于计算机视觉任务中（例如，[30]、[16]和[1]）。根据他们的高水平模仿能力，一些作品（例如，[11]和[28]）采用GANs进行对抗性攻击。最具代表性的攻击方法使用称为蒸馏的方法将鉴别器与目标模型的输出相匹配，训练生成器生成可能误导鉴别器的数据。通过这种方式，敌对样本可以间接攻击目标模型，即敌对样本的可转移性[19]。与之前的工作不同，我们使用生成器生成对抗性有效载荷，用于在不破坏其功能的情况下制作对抗性样本。在我们的模型中，一旦GANs的训练过程完成，生成器可以在很短的时间内仅使用输入的恶意软件二进制文件独立生成恶意软件对抗样本。</p>
<h3><span id="三-方法">三、方法</span></h3>
<p>在本节中，我们将简要解释输入二进制文件和对抗性示例的形式化定义，然后介绍GAPGAN的框架和策略细节。</p>
<h4><span id="31-问题定义">3.1 问题定义</span></h4>
<p>【<strong>问题定义</strong>】软件的二进制文件由属于离散空间 <span class="math inline">\(\mathcal{X}=\{0, \ldots, 255\}\)</span>
的字节序列组成。设 <span class="math inline">\(b=\left(b_1, \ldots,
b_n\right) \in \mathcal{X}^n\)</span> 表示一个二进制文件，其中<span class="math inline">\(n\)</span>是字节序列的长度，因文件而异。二进制文件<span class="math inline">\(b\)</span>带有标签<span class="math inline">\(y
\in\{-1,1\}\)</span>，其中<span class="math inline">\(y=1\)</span>表示它是良性软件<span class="math inline">\(b_{b e n}\)</span>，否则它是恶意软件<span class="math inline">\(b_{m a l}\)</span>。</p>
<p>恶意软件检测器旨在学习一个映射函数<span class="math inline">\(f\)</span> : <span class="math inline">\(x
\rightarrow\{-1,1\}\)</span>，满足<span class="math inline">\(f\left(b_{\text {mal }}\right)=-1\)</span>和<span class="math inline">\(f\left(x_{\text {ben
}}\right)=1\)</span>。相反，对抗攻击的目标是找到一个模型<span class="math inline">\(g\)</span>并生成一个有效的对抗样本 <span class="math inline">\(b_{a d v}=g\left(b_{m a l}\right)\)</span>
，使得恶意软件检测器将其分类为良性软件，即<span class="math inline">\(f\left(b_{a d v}\right)=1\)</span>。同时，<span class="math inline">\(b_{a d v}\)</span>必须保留<span class="math inline">\(b_{\mathrm{mal}}\)</span>的原始功能。【可执行】</p>
<h4><span id="32-gapgan">3.2 <strong>GAPGAN：</strong></span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211339641.png" alt="image-20210602221731158">
<figcaption aria-hidden="true">image-20210602221731158</figcaption>
</figure>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211339571.png" alt="image-20210707153446579">
<figcaption aria-hidden="true">image-20210707153446579</figcaption>
</figure>
<p>【框架流程概述】图1显示了拟议框架GAPGAN的概述。它包括两个阶段：训练过程和进攻过程。在训练过程中，我们同时训练生成器网络G和鉴别器D，其中G打算为输入恶意软件生成对抗性有效载荷，并将它们连接起来以制作对抗性样本，而D试图提取目标黑箱检测器f，并模仿f对原始良性样本和生成的对抗性样本的判定。在攻击过程中，我们只需要经过训练的生成器来攻击黑箱检测器。</p>
<p>【扰动添加概述】为了在制作恶意软件的对抗性示例时保护其原始功能，<strong>有一些流行的方法，如使用调试日志和在运行前压缩数据，但它们是费时费力。通过仔细选择和操纵执行的其他攻击非常复杂，可能需要特定的经验，不适用于有效的对抗性攻击。受之前工作（[3]和[14]）的启发，我们选择在文件末尾附加字节（有效载荷）以保留其功能，这很简单，不需要任何专家经验</strong>.</p>
<p>【数据预处理】由于软件文件的长度<span class="math inline">\(n\)</span>变化很大，我们首先将零（表示为图1中的蓝色部分）附加到输入二进制文件的末尾，以匹配网络的输入大小<span class="math inline">\(t\)</span>，即<span class="math inline">\(b^{\prime}=\left(b_1, \ldots, b_n, 0, \ldots,
0\right) \in \mathcal{X}^t\)</span>，其中<span class="math inline">\(t
\geq
n\)</span>。通过这种方式，我们可以将不同长度的每个样本输入到具有固定大小的特定网络中。然后，我们通过归一化将离散二进制中的每个字节映射到连续空间<span class="math inline">\([-1,1]\)</span>。我们将归一化后的输入定义为<span class="math inline">\(x\)</span>，其中<span class="math inline">\(x=\left(x_1, \ldots, x_t\right) \in
\mathbb{R}^t\)</span>。【值得注意的是，为了保留可执行文件的多态性，没有将输入进行归一化。】</p>
<p>在数据预处理之后，将标准化的恶意软件xmal馈送到生成器G。然后，G基于xmal的相应特征生成对抗性负载aadv(在图1中表示为红色部分)：</p>
<p><span class="math display">\[
aadv = G(xmal) (1)
\]</span></p>
<p>我们将aadv附加到xmal的末尾以制作对抗性恶意软件样本xadv;</p>
<p><span class="math display">\[
xadv = [xmal，aadv]
\]</span></p>
<p>其中[·，·]表示连接操作。</p>
<p>在训练D时，我们将xadv和xben都合并到数据池中。在每次迭代中，我们从数据池中抽取混合示例批次，然后使用它们来查询黑盒检测器f。接下来，我们使用f响应的标签来拟合D，使得D的决策边界尽可能接近f。</p>
<p>在训练过程中，生成器G学习创建可以避开鉴别器D的样本。此外，随着D和我们的目标模型f之间的相似性的提高，G对f的对抗性攻击能力也将提高。最后，由于对抗性攻击的可转移性，G生成的对抗性样本也可以有效地避开f。</p>
<p>一旦训练过程完成，我们就可以使用训练后的G在很短的时间内生成对抗性样本，只需输入恶意软件。值得注意的是，我们在攻击过程中放弃了填充零，以减少有效载荷的整个长度。根据我们的实际经验，这会使攻击成功率略有下降，但损失是可以接受的。此外，我们需要将对抗性样本转换回离散空间作为可执行文件。</p>
<p>【模型结构】为了使我们的框架适应不同长度的恶意软件二进制文件和有效负载，<strong>生成器网络设计为具有可变的输入和输出大小。更具体地说，生成器首先使用两个卷积层提取输入的特征。然后，它使用完全连接的图层调整高级特征的大小。经过两层反卷积和一层1∗
1卷积，产生对抗性有效载荷。</strong>另一方面，鉴别器使用卷积层和完全连接层进行二元分类。请注意，如果确定了输入数据的大小和我们决定生成的有效负载的长度，我们可以使用它们作为输入来轻松调整GAPGAN的结构，因为生成器和鉴别器中的层都是完全连接的。</p>
<h4><span id="33-black-box-attacks-strategy">3.3 Black-box Attacks Strategy</span></h4>
<blockquote>
<p><strong>生成器G：</strong></p>
<ol type="1">
<li><p>将n长度的字节序列添加到t长度（t&gt;n)</p></li>
<li><p>通过<strong>标准化</strong>将离散二进制文件中的每个字节映射到一个连续空间[-1,1]</p></li>
<li><p>将<strong>填充后的恶意软件样本</strong>输入到<strong>生成器</strong>生成对抗样本<span class="math inline">\(adv\)</span></p></li>
<li><p>讲对抗样本<span class="math inline">\(adv\)</span>添加到<strong>填充后的恶意软件样本</strong>后</p></li>
</ol>
<p><strong>检测器D:</strong></p>
<ol type="1">
<li>将对抗样本和良性样本中抽取在黑盒上<strong>打标签</strong></li>
<li>用黑盒打上的标签数据去<strong>拟合检测器D</strong>，使得D的决策边界尽可能接近黑盒</li>
</ol>
<p><strong>训练结束：</strong></p>
<ol type="1">
<li>在攻击过程中放弃了填充零，以减少有效负载的整个长度。</li>
<li>将对抗性样本转换回离散空间作为可执行文件</li>
</ol>
</blockquote>
<p><strong>生成器</strong>：生成器G的目的是学习Xmal的特征，Xmal的原始标签是y=−1，并生成相应的有效样本Xadv，这会误导D将其预测为y=1的“良性”。在我们的实践经验中，G往往更关注D对xadv的预测结果，这带来了一个严重的问题，即对抗有效载荷aadv的有效性得不到很好的提高。因此，<strong>我们让G同时考虑xadv的全局和局部（即xadv和aadv）有效性</strong>。生成器G的对抗性损失函数为：
<span class="math display">\[
LG = −(1 − β)Ex∼pxadv(D(x)) − βEa∼paadv(D(a))
\]</span></p>
<p>其中，β是一个超参数，用于在xadv和aadv之间保持生成器注意力的平衡。我们试图找到β的最佳值，然而，固定的β并不总是表现得最好，因为每次攻击程序运行时，网络的条件都不同。因此，最好的β应该具有自适应调整的能力。受[18]的启发，我们考虑根据D到xadv和aadv的输出自动调整β，这分别代表了它们的攻击有效性。我们给出了自动调谐机制：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211339178.png" alt="image-20210603141233344" style="zoom:50%;"></p>
<p>如果xadv比aadv更有效，那么D到xadv的输出期望就更大。自动机构将增加β
间接提高aadv的学习率。我们将在实验中证明它的有效性。</p>
<p>【介绍动态蒸馏】</p>
<p><strong>判别器：</strong>我们使用鉴别器D来动态提取目标黑盒模型f。更具体地说，我们从数据池中采样一批混合数据，通过查询f来获得标签。样本及其相应的标签用于基于距离度量H拟合D。D的蒸馏损失为：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211339381.png" alt="image-20210603141837636" style="zoom:50%;"></p>
<p>D试图学习f对xben和xadv的决策策略。通过这种方式，D被视为替代检测器，用于将对抗性样本的攻击有效性转移到最终目标黑盒模型f。</p>
<p><strong>动态阈值策略</strong>：在攻击过程中，我们将生成敌方样本并保存在本地。然而，我们发现<strong>当我们将对抗性样本从对抗性连续空间映射回二进制的离散空间时，细微的扰动将被忽略。大部分包含攻击有效性的有效载荷将被忽略</strong>，因为它们的值很小。为了解决这个问题，我们建议使用动态阈值策略来限制有效载荷的最小值：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211339142.png" alt="image-20210603143629837" style="zoom:50%;"></p>
<p>其中<strong>e</strong>表示有效载荷中的每个字节，<strong>i</strong>是当前训练迭代时间，<strong>Tmax</strong>是最大训练迭代时间，<strong>西格玛</strong>是最大阈值。我们直接将具有小值的字节设置为阈值以下的零。然而，<strong>如果我们使用静态阈值，G的学习过程将会丢失</strong>。如果一个字节的值很小，但有一定的攻击效果，它首先会被设置为零的阈值。<strong>然后G将继续对字节或其他相邻字节添加扰动</strong>，以提高该区域的对抗攻击效能。最后该字节或其他相邻字节将被修改，以填充设置为零的字节的对抗攻击损失。</p>
<p>值得注意的是，在我们设置后，所有的调整过程都将使用梯度下降算法自动执行 .
在上述工作的基础上，黑匣子攻击对恶意软件检测的总体算法如算法1所示。在第5节中，我们将展示我们的攻击实验的细节。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211338898.png" alt="image-20220606212943284" style="zoom:50%;"></p>
<h3><span id="四-实验装置experimentalsetup">四、实验装置（EXPERIMENTAL
SETUP）</span></h3>
<p>本节介绍了我们的攻击实验准备工作，包括<strong>数据集</strong>、<strong>评估指标</strong>以及我们<strong>选择和训练的目标模型</strong>。</p>
<h4><span id="41-数据集">4.1 <strong>数据集</strong></span></h4>
<blockquote>
<p>研究二进制文件长度对攻击的影响</p>
</blockquote>
<p>恶意软件和良性软件数据从不同来源收集，用于我们的对抗性攻击实验，如表1所示。恶意软件样本从<strong>VirusTotal4</strong>和<strong>Microsoft恶意软件分类挑战赛</strong>（Kaggle
2015）下载【22】。良性软件示例由Windows软件包管理器<strong>Chocolate
Software5下载</strong>。将数据分为四个数据集，使恶意软件的二进制长度分布接近每个数据集中的良性软件。使用具有不同最大和平均长度的数据集1、2和3来<strong>研究二进制文件长度对攻击的影响</strong>。数据集2和数据集4具有不同的来源，但长度分布很近，用于<strong>评估攻击算法的泛化</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211338455.png" alt="image-20210603152949793" style="zoom:50%;"></p>
<p><strong>评估方法：</strong>攻击成功率（ASR）指标</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211338962.png" alt="image-20210603153146322" style="zoom:50%;"></p>
<h4><span id="42-target-black-box-models">4.2 Target Black-box Models</span></h4>
<blockquote>
<p>四种目标模型</p>
</blockquote>
<p>我们选择最先进的恶意软件检测器MalConv[21]作为我们的主要目标黑箱模型。MalConv首先将输入二进制文件中的每个字节嵌入到8维向量中，然后使用两个具有不同激活函数的卷积层进行分类。我们为每个数据集训练一个输入大小为2000000的MalConv检测器。表2显示了每个MalConv探测器在培训后的测试精度。它表明，经过训练的MalConv检测器具有与[21]中类似的性能。</p>
<p>为了测试对抗攻击方法的泛化性，我们还使用了四种不同结构的深度学习模型作为目标模型。为了减少输入二进制文件的大尺寸，我们考虑在每个深度学习模型中添加CNN结构。输入二进制文件中的每个字节都以与MalConv相同的方式嵌入到8维向量中。我们在数据集2和4上训练这四个模型，检测精度如表2所示。结果表明，这四种检测器也达到了较好的分类精度。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211338337.png" alt="image-20220524173957601" style="zoom:50%;"></p>
<h3><span id="五-experimental-results">五、EXPERIMENTAL RESULTS</span></h3>
<p>在本节中，我们将展示GAPGAN在对抗性攻击实验中的有效性。我们还将其与不同防御下的其他最先进的攻击方法进行了比较。</p>
<p>我们首先应用GAPGAN以不同长度的对抗性有效载荷攻击四个经过训练的MalConv（我们在上一节中展示了它们）。有效负载率用于表示有效负载长度与二进制文件长度的比率，以进行检测。根据表3所示的对不同数据集的攻击性能，可以看出GAPGAN可以对MalConv模型执行有效的黑盒攻击。从数据集2和数据集4的结果可以看出，敌对样本对不同数据的攻击成功率较高。此外，由于有效载荷率的增加，原始长度较短的对抗性二进制文件可能具有更好的攻击效果。<strong>值得一提的是，从数据集1生成的对抗性样本的ASR可以达到100%，只有一小部分有效载荷，即检测数据总长度的2.5%</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211338843.png" alt="image-20210603152949793" style="zoom:50%;"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211338632.png" alt="image-20220524175422368" style="zoom:50%;"></p>
<p>我们发现，当ASR已经达到很高的值时，使用较大的有效负载可能只会提高很少的攻击成功率（例如，当附加10%的有效负载时，ASR为98.21%，但当附加两倍长度的有效负载时，ASR仅提高1.79%）。然而，随着有效载荷长度的增加，被检测的风险和成本将增加。同时，为了证明GAPGAN生成的对抗性有效载荷的有效性，我们将其与随机有效载荷进行比较，如图2所示。我们发现，<strong>与随机生成的有效载荷相比</strong>，具有GAPGAN生成的有效载荷的对抗性样本具有更好的攻击效果。还可以看出，<strong>随机有效载荷的ASR与有效载荷率成正比，而对抗性有效载荷随着有效载荷率的增加而迅速增加</strong>，当达到较高值时，ASR的增长速度减慢。我们认为，每个数据集都存在最佳的有效负载率，即当附加较大的有效负载时，ASR的增长率将快速下降。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211338959.png" alt="image-20220524174337289" style="zoom:50%;"></p>
<h4><span id="52-与最新攻击方法的比较">5.2 与最新攻击方法的比较</span></h4>
<blockquote>
<p>黑盒、速度、攻击等级</p>
<ol type="1">
<li><p><strong>基于梯度优化的方法</strong>：Adversarial malware
binaries: Evading deep learning for malware detection in
executables</p></li>
<li><p><strong>基于API调用序列的AdvSeq方法</strong>：Generic black-box
end-to-end attack against state of the art API call based malware
classifiers</p></li>
<li><p><strong>基于API调用序列的MalGAN</strong></p></li>
</ol>
</blockquote>
<p>我们将GAPGAN与恶意软件检测任务中其他最先进的对抗性攻击方法进行了比较，即Opt。<strong>基于梯度优化的方法</strong>【14】、<strong>基于API调用序列的AdvSeq方法</strong>【23】和<strong>基于API调用和GANs的MalGAN方法</strong>【11】。其结果如表4所示。可以看出，只有Opt。方法在白盒设置中执行攻击。从攻击效率的角度来看，一旦攻击模型得到训练，GAPGAN和MalGAN生成对抗性样本的速度远远快于其他方法（AdvSeq也基于复杂的优化过程，这被认为是无效的）。然而，只有GAPGAN在字节级别执行有效的黑盒攻击，这在现实场景中更具威胁性。为了进一步探索针对基于二进制文件的检测的攻击方法的有效性，我们选择比较GAPGAN和Opt。方法，即字节级攻击方法。选择具有随机有效载荷的对抗性样本进行比较。从表5可以看出，这两种攻击方法对不同的检测器都具有良好的攻击性能。然而，GAPGAN执行高效的黑盒攻击，这被认为是应用程序中对抗性攻击的关键。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211338268.png" alt="image-20220524174702187" style="zoom:50%;"></p>
<p><strong>针对二进制文件检测的攻击方法的有效性，我们选择GAPGAN和Opt进行比较</strong>，两种攻击方法对不同的检测器都有很好的攻击性能。然而，GAPGAN执行高效的黑盒攻击，这对于应用中的对抗性攻击至关重要。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211338553.png" alt="image-20210603162247046" style="zoom:50%;"></p>
<h4><span id="53-不同防御方式下的攻击性能">5.3 不同防御方式下的攻击性能</span></h4>
<p>人们提出了许多防御方法来防御各种攻击。使模型对对抗性样本具有鲁棒性的最常用方法是<strong>对抗性训练</strong>[7]，它在训练过程中引入对抗性扰动，使深度学习模型调整决策策略。另一种有效的防御方法[26]<strong>随机消除输入数据</strong>，以消除对抗性样本的攻击有效性。我们比较了随机有效载荷与GAPGAN和Opt生成的对抗性样本的攻击效果。在这些防御之下。为了模拟真实场景，我们假设攻击者不知道有关防御的任何信息。<strong>在RND防御方法的实验中，我们随机消除10%的输入数据，并测试对抗样本的攻击成功率</strong>。由于检测器的结构包含一个嵌入层，因此在对抗性训练防御方法中无法传递梯度。因此，我们建议使用用于提取检测器的替代模型来生成具有对抗性干扰的训练数据。新的训练数据用于提高检测器的鲁棒性。使用之前的探测器生成的对抗性样本将在重新培训的探测器上进行评估。表6显示了防御攻击的结果。我们表明，在大多数情况下，GAPGAN的攻击性能优于Opt。方法，尤其是在对抗性训练的防守下。一种可能的解释是Opt。该方法过度依赖于目标模型的结构和梯度信息。此外，有效载荷中的一个字节由Opt根据当前敌对样本的梯度生成。方法在RND防御的随机置零过程中，当字节之间的连接被切断时，攻击的有效性会受到很大的损害。相比之下，GAPGAN考虑了整个对手样本的攻击能力，使其在防御下更有效。</p>
<blockquote>
<p>为了防御各种攻击，人们提出了许多防御方法。使模型对对抗性样本具有鲁棒性的最常用方法是<strong><em>对抗性训练Explaining
and harnessing adversarial
examples</em></strong>，它在训练过程中引入对抗性扰动，使深度学习模型调整决策策略。另一种有效的防御方法<strong><em>随机消除输入数据
Adversary resistant deep neural networks with an application to malware
detection</em></strong>，以消除对手样本的攻击效果。我们比较了随机有效载荷与GAPGAN和Opt生成的对抗样本的攻击效果。在这些防御之下。</p>
<p><strong>在大多数情况下，GAPGAN的攻击性能优于Opt。方法，尤指在对抗性训练的防守下。</strong></p>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211338852.png" alt="image-20220524175324124" style="zoom:50%;"></p>
<h4><span id="54-动态参数的使用效果">5.4 动态参数的使用效果</span></h4>
<blockquote>
<p>集成比列调节</p>
</blockquote>
<p><strong>W</strong>: without using the method; <strong>S</strong>:
using static parameter<strong>; D</strong>: using dynamic parameter</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304211338844.png" alt="image-20210603164901344" style="zoom:50%;"></p>
<p><strong>动态阈值和自动权重调整策略显著提高了对抗性样本的有效性</strong></p>
<h3><span id="六-结论">六、结论</span></h3>
<p>​
在本文中，我们基于GAN的思想提出了一个对抗性攻击框架GAPGAN来生成对抗性样本，以对抗基于二进制文件的恶意软件检测。在我们的模型中，我们将<strong>生成器生成的对抗性有效负载附加到原始恶意软件二进制文件中，以在不破坏其原始功能的情况下创建一个对抗性示例</strong>。实验表明，GAPGAN可以有效地攻击最先进的检测器MalConv以及其他不同结构的深度学习模型。结果还表明，<strong>在现有防御机制下，我们的模型在效率和有效性上都优于其他最先进的攻击方法</strong>。GAPGAN是第一个实用的针对恶意软件检测的端到端黑盒攻击框架，对下一代流行的检测技术，即基于原始二进制文件的恶意软件检测构成威胁。虽然我们的工作集中在恶意软件二进制文件，它可以很容易地扩展到其他领域，如对抗性文本或图形生成。这使得GAPGAN成为一个很有前途的攻击框架，用于提高恶意软件检测或其他任务防御方法的健壮性。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>AI安全</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（9）Forecasting Malware Capabilities From Cyber Attack Memory Images</title>
    <url>/posts/1J98PCJ/</url>
    <content><![CDATA[<h2><span id="forecastingmalware-capabilities-from-cyber-attack-memory-images">Forecasting
Malware Capabilities From Cyber Attack Memory Images</span></h2>
<blockquote>
<ul>
<li>项目：https://www.usenix.org/conference/usenixsecurity21/presentation/alrawi-forecasting</li>
<li>文章：https://arxiv.org/abs/1907.07352</li>
</ul>
</blockquote>
<h3><span id="摘要">摘要</span></h3>
<p>正在进行的网络攻击的补救依赖于及时的恶意软件分析，其目的是发现尚未执行的恶意功能。不幸的是，这需要在不同工具之间重复切换上下文，并且会给分析员带来很高的认知负荷，从而减慢调查速度，并给攻击者带来优势。<strong>我们提出了Forecast，这是一种事后检测技术，可使事件响应者自动预测恶意软件的执行能力。预测基于概率模型，该模型允许预测发现能力，并根据其相对执行可能性（即预测）对每个能力进行权衡</strong>。<strong><font color="red">
Forecast利用当前攻击的执行上下文（来自恶意软件的内存映像）来指导恶意软件代码的符号分析。</font></strong>我们进行了广泛的评估，有6727个真实世界的恶意软件和旨在颠覆预测的未来主义攻击，显示了预测恶意软件能力的准确性和鲁棒性。</p>
<blockquote>
<p>Forecast is based on a probabilistic model that allows Forecast to
discover capabilities and also weigh each capability according to its
relative likelihood of execution</p>
</blockquote>
<h3><span id="一-说明">一、说明</span></h3>
<p>网络攻击响应需要对抗阶段性恶意软件功能（即尚未执行的恶意功能），以防止进一步的损害[1]、[2]。不幸的是，检测后预测恶意软件功能仍然是手动的、繁琐的和容易出错的。目前，分析师必须重复执行多个分类步骤。例如，分析员通常会将二进制文件加载到静态反汇编程序中，并执行内存取证，以组合静态和动态工件。这一艰苦的过程需要在二进制分析和取证工具之间进行上下文切换。因此，它给分析员带来了很高的认知负荷，减慢了调查速度，给攻击者带来了优势。</p>
<p><strong>为了自动化事件响应，符号执行很有可能用于恶意软件代码探测，但缺少先前的攻击执行状态，而这种状态在事后可能无法重新实现（例如，来自C&amp;C活动的具体输入）</strong>。特定于环境的条件（如预期的C&amp;C命令）限制了动态和协同技术（如[3]–[14]）预测无法访问的能力。此外，这些技术依赖于剖析独立恶意软件二进制文件或在沙箱中运行它。然而，已知恶意软件会删除其二进制文件或将自身锁定为仅在受感染的计算机上运行（硬件锁定）。<strong>更糟糕的是，研究人员发现，无文件恶意软件事件（即，仅驻留在内存中）继续增加[1]、[15]、[16]</strong>。</p>
<p>有权访问正确的执行上下文对于引导恶意软件显示其功能是必要的。恶意软件在内部收集来自特定环境源的输入，例如注册表、网络和环境变量，以便做出行为决策【11】、【17】、【18】。因此，恶意软件的理想和实用输入公式可以根据内存中的该内部执行状态进行调整，其中包含已收集的输入工件。<strong>事实证明，在检测到恶意进程后，反病毒和IDS已经收集了该进程的内存映像。恶意软件内存映像包含被调查的特定攻击实例特有的这种内部具体执行状态。</strong></p>
<p><strong><font color="red">
在我们的研究过程中，我们注意到，如果我们可以在内存图像中设置代码和数据页的动画，并根据捕获的快照执行向前的代码探索，那么我们就可以重用这些早期的具体执行数据来推断恶意软件的下一步。</font></strong>此外，通过分析这些具体输入如何在代码探索期间诱导路径，我们可以根据恶意软件捕获的执行状态预测哪些路径更有可能执行功能。基于这一思想，<strong><font color="red">
我们提出用通过内存图像取证获得的具体执行状态对恶意软件的预阶段路径进行符号探索。</font></strong>通过这一点，我们克服了分析员之前必须进行的艰苦而繁重的认知过程。</p>
<p><strong>我们介绍了Forecast，这是一种后检测技术，使事件响应者能够从捕获的内存图像中预测可能的功能。Forecast根据发现的每个功能的执行概率（即预测）对其进行排序，以使分析师能够确定其修复工作流的优先级。</strong>为了计算这种概率，Forecast会衡量每条路径对具体数据的相对使用情况。这种方法基于内存映像执行状态的具体程度（或DC）的形式化模型。Forecast从内存映像中的最后一个指令指针（IP）值开始，通过象征性地执行每条指令的CPU语义来探索每条路径。在此探索过程中，预测建模符号和具体数据的混合如何影响路径生成和选择。基于这种混合，沿路径计算每个状态的“具体性”分数，以得出每个发现能力的预测百分比。DC（s）还通过动态调整循环边界、处理符号控制流和修剪路径来优化符号分析，以减少路径爆炸。</p>
<p>为了自动识别每个功能，我们开发了几个模块化的功能分析插件：<strong>代码注入、文件过滤、滴管、持久性、键和屏幕监视、反分析和C&amp;C
URL连接</strong>。每个插件根据API序列、它们的参数以及它们的输入和输出约束如何连接每个API来定义一个给定的功能。Forecast插件是可移植的，可以很容易地扩展以捕获基于目标系统API的其他功能。值得注意的是，Forecast的分析只需要一个法医记忆图像，允许它对无文件恶意软件工作，使其非常适合事件响应。</p>
<p>我们使用涵盖274个家族的6727个真实恶意软件（包括打包和解包）的内存图像评估Forecast。与人工专家手动生成的报告相比，Forecast可提供准确的能力预测。此外，我们还表明，Forecast对旨在颠覆Forecast的未来主义攻击具有鲁棒性。我们表明，预测的检测后预测是由早期的具体输入准确诱导的。我们将预测与S2E【6】、angr【22】和Triton【23】进行了经验比较，发现预测在识别能力和减少路径爆炸方面优于它们。预测可在线访问：https://cyfi.ece.gatech.edu/.</p>
<blockquote>
<p>“S2E: A platform for in-vivo multi-path analysis of software
systems,” 2011</p>
<p>“SoK: (State of) The Art of War: Offensive Techniques in Binary
Analysis,” 2016</p>
<p>“Triton: A Dynamic Symbolic Execution Framework” 2015</p>
</blockquote>
<h3><span id="二-概述">二、概述</span></h3>
<p>本节介绍了结合<strong>记忆图像取证和符号分析技术</strong>的挑战和好处。以<strong>DarkHotel事件</strong>[2]为例，我们将展示事件响应者如何利用预测加快调查并补救网络攻击。</p>
<p><strong><font color="red"> 运行示例：DarkHotel
APT。</font></strong>DarkHotel是一种APT，通过矛式网络钓鱼攻击C&amp;C服务器【2】。感染后，DarkHotel会从受害者的文件系统中删除其二进制文件，与C&amp;C服务器通信，将线程注入Windows资源管理器，并最终过滤侦察数据。当IDS检测到受感染主机上的异常活动时，终端主机代理会捕获可疑进程内存（即DarkHotel内存），终止其执行，并生成通知。<strong>此时，事件响应者必须从不同的可用取证来源（网络日志、事件日志、内存快照等）快速了解DarkHotel的能力，以防止进一步的损坏。</strong></p>
<p>动态技术【11】–【14】可能需要一个激活的C&amp;C以诱使恶意软件二进制文件显示其功能，然而该C&amp;C可能已被取下。由于DarkHotel只驻留在内存中，这些通过在沙盒中运行恶意软件而起作用的技术无法应用。</p>
<ul>
<li><strong>只有内存图像，分析员可以使用取证工具，如Volatility</strong>【24】，来“切割”内存图像代码和数据页。基于提取的代码页，符号分析可以模拟恶意软件的执行，以探索所有潜在的路径。</li>
<li>不幸的是，现有的符号工具需要一个格式正确的二进制文件，并且没有针对内存图像进行优化[7]、[22]、[23]。</li>
</ul>
<p><strong>理想情况下，分析员可以手动将这些代码片段投影到符号分析中，并从数据页中获取具体值，以告诉哪一个代码分支会导致某个功能</strong>。然而，这种用提取的内存工件“缝合”代码的来回过程涉及符号执行和取证工具之间的上下文切换。这给分析员带来了很高的认知负担。<strong>分析员还必须处理路径爆炸、API调用模拟[4]、[22]、[25]–[27]和具体化API参数（例如攻击者的URL）等挑战，这些挑战可能无法在内存映像中静态访问</strong>。最后，分析师必须沿每条路径手动检查API，以推断高级功能。</p>
<h4><span id="21混合事件响应">2.1混合事件响应</span></h4>
<p>事件响应者依靠内存取证来识别内存图像中的攻击瑕疵。然而，仅仅是基于签名的记忆取证，由于高漏报率，会遗漏重要的数据结构【21】。另一方面，符号执行可以正向探索代码，但会遇到路径爆炸等问题[22]。为了解决这些限制，Forecast通过反馈循环将符号执行和内存取证结合起来，以解决这两种技术的缺点。</p>
<p><strong>上下文感知记忆取证</strong>。符号分析提供代码探索上下文，以准确识别内存取证遗漏的数据构件。例如，DarkHotel内存图像的传统法医解析遗漏了C&amp;C
URL字符串，因为它们通过自定义编码方案进行了混淆。然而，对引用这些字节作为参数的指令（如strncpy
API）进行的后续符号分析允许Forecast正确识别和利用内存映像中的这些数据瑕疵。此外，有针对性的恶意软件可能会采用旨在颠覆预测的策略，使用反取证和反符号分析，这是我们在设计和评估中仔细考虑的。</p>
<p>内存图像取证提供了具体的输入，可以帮助符号分析执行地址具体化、控制流解析和循环边界。此外，内存取证可以识别内存中加载的库地址，从而允许Forecast执行库函数模拟。</p>
<p>路径概率。给定一个内存映像，目标是利用可用的具体数据来探索潜在的代码路径，并预测沿途的功能。通过分析具体内存图像数据是如何产生不同路径的，Forecast可以得出一条路径相对于其他路径达到某种能力的概率。Forecast基于建模具体和符号数据操作如何影响路径生成和选择来计算此概率。Forecast还利用此概率度量作为一种启发式方法来修剪具有最少具体数据的路径。</p>
<h4><span id="22-incident-response-withforecast">2.2 Incident Response with
Forecast</span></h4>
<p><strong>Forecast可识别来自自动管道中恶意软件内存映像的功能</strong>。为了证明这一点，我们模拟了DarkHotel的攻击和内存捕获，其中包括使用DarkHotel的网络签名设置IDS并执行高级持久性威胁（APT）。检测完成后，IDS向终端host
agent发出信号，以捕获DarkHotel进程内存。然后，我们输入该内存图像进行预测以进行分析。在459秒内，<strong><font color="red">
Forecast显示了DarkHotel的功能：C&amp;C通信（即mse.vmmnat.com）、文件过滤（即主机信息）和代码注入（即注入Windows
Explorer）。</font></strong></p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550504.png" alt="image-20220624145017568">
<figcaption aria-hidden="true">image-20220624145017568</figcaption>
</figure>
<p>处理法医记忆图像有六个阶段，如图1所示。1
Forecast以取证方式解析内存映像，并通过将最后一个CPU和内存状态加载到符号环境中进行分析来重建先前的执行上下文。在分析内存映像时，Forecast检查加载的库，以识别导出的函数名和地址。接下来，2
Forecast继续探索可能的路径，利用内存映像中可用的具体数据来具体化路径约束。3预测模型和权重每个路径如何由具体数据归纳，并为每个生成的路径分配概率。4
Forecast然后使用此概率作为权重来调整循环边界并修剪错误路径，从而允许Forecast缩小诱导能力相关路径的范围。5
Forecast将已识别的API与功能分析插件库相匹配，以向分析师报告功能。最后，6
Forecast确定了三种能力，并从路径概率中得出了它们的预测百分比，分别为31%、15%和54%。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（8）【draft】Heterogeneous Temporal Graph Transformer: An Intelligent System for Evolving Android Malware Detection</title>
    <url>/posts/2MYAND2/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-CrowdStrike《无文件攻击白皮书》解析</title>
    <url>/posts/1J88NKC/</url>
    <content><![CDATA[<h2><span id="theforrester-wavetm-endpoint-detection-and-response-providers-q22022"><strong>The
Forrester Wave™: Endpoint Detection And Response Providers, Q2
2022</strong></span></h2>
<p>在我们对端点检测和响应提供商的 20 个标准评估中，我们确定了 15
个最重要的——Bitdefender、BlackBerry Cylance、Check Point Software
Technologies、CrowdStrike、Cybereason、Elastic、FireEye、Fortinet、McAfee、Microsoft、Palo
Alto Networks、SentinelOne 、Sophos、趋势科技和 VMware Carbon Black —
并对它们进行了研究、分析和评分。该报告显示了每个供应商如何衡量并帮助安全专业人员根据他们的需求选择合适的供应商。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181505869.png" alt="image-20220426183404208" style="zoom: 33%;"></p>
<h1><span id="crowdstrike无文件攻击白皮书解析">CrowdStrike《无文件攻击白皮书》解析</span></h1>
<blockquote>
<p>原文链接：https://www.secrss.com/articles/26671</p>
</blockquote>
<p>CrowdStrike是端点保护平台（EPP）的最强者，是云交付的下一代端点保护的领导者。由于CrowdStrike邮件推送了“<strong>无文件攻击白皮书</strong>”《谁需要恶意软件？<strong>对手如何使用无文件攻击来规避你的安全措施</strong>》（Who
Needs Malware? How Adversaries Use Fileless Attacks To Evade Your
Security），笔者顺手对其进行了<strong>全文翻译</strong>。</p>
<p><strong>无文件攻击（Fileless
attack）</strong>是<strong>不向磁盘写入可执行文件</strong>的攻击方法，难以被常规方法检测出来。根据CrowdStrike统计，“10个成功突破的攻击向量中有8个使用了无文件攻击技术。”即
<strong>80%的成功入侵都使用了无文件攻击</strong> <strong>。</strong>
根据二八原理，这显然是安全人员应该高度关注的技术类型。</p>
<p><strong>无文件攻击白皮书</strong>解释了<strong>无文件攻击的工作原理、传统解决方案失效的原因，以及CrowdStrike解决该难题的方法</strong>。CrowdStrike的解决方案是<strong>应用程序清单、漏洞利用阻断、攻击指标（IOA）、托管狩猎、无签名人工智能等技术的集成化方法</strong>。</p>
<p>除了全文翻译外，笔者主要在文末做了两块内容增补：一是关于CrowdStrike<strong>Threat
Graph（威胁图</strong>）的技术思想<strong>，因为威胁图 是 CrowdStrike
Falcon（猎鹰）端点保护平台的“ </strong>大脑” ；二是
关于CrowdStrike提出的<strong>攻击指标</strong>（IOA）<strong>与传统的失陷指标（IOC）</strong>的对比。<strong>笔者认为，这两类技术领域具有战略价值</strong>。如果说全文翻译只花费一小时的话，这些增补内容反而消耗了笔者两个小时。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181505079.png" alt="img" style="zoom:33%;"></p>
<p>随着安全措施在检测和阻止恶意软件和网络攻击方面越来越出色，对手和网络犯罪分子被迫不断开发新技术来逃避检测。其中一种高级技术涉及<strong><font color="red">
“无文件”（fileless）攻击，即不向磁盘写入可执行文件。</font></strong>这类攻击特别有效地躲避了传统防病毒（AV）解决方案，因为传统防病毒（AV）方法寻找被保存到磁盘上的文件并扫描这些文件以确定它们是否恶意。</p>
<p>虽然无文件攻击并不新鲜，但它们正变得越来越普遍。在2016年的调查中，CrowdStrike
Services事件响应团队发现，<strong>10个成功入侵的攻击向量中有8个使用了无文件攻击技术</strong>。为了帮助您了解无文件攻击所带来的风险，本白皮书解释了无文件攻击的工作原理、当前解决方案对其无能为力的原因，以及CrowdStrike解决这一难题的行之有效的方法。</p>
<h3><span id="什么是无文件攻击">什么是无文件攻击？</span></h3>
<p>当攻击者通过消除将PE（可移植可执行文件）复制到磁盘驱动器的传统步骤来逃避检测时，就会发生无文件或无恶意软件的攻击。<strong>有多种技术可以采取这种方式危害系统</strong>。</p>
<ul>
<li><p><strong>漏洞利用和漏洞利用工具包</strong>，通常通过利用操作系统（OS）或已安装应用程序中存在的漏洞，直接在内存中执行攻击。</p></li>
<li><p><strong>使用盗用的凭证</strong>，是发起无文件攻击的另一种普遍方法。Verizon在其2017年的DBIR（数据泄露调查报告）中发现，81%的数据泄露涉及弱口令、默认口令或被盗口令，比上一年增加了18%。这使得攻击者能够像普通用户一样访问系统。</p></li>
<li><p>一旦实现初步突破，对手就可以<strong>依赖操作系统本身提供的工具</strong>，如Windows管理工具和Windows
<strong>PowerShell</strong>，以执行进一步的操作，而不必将文件保存到磁盘。例如，它们可以通过在注册表、内核中隐藏代码，或者通过创建允许它们随意访问系统的用户帐户来<strong>建立持久化</strong>，而无需向磁盘写入任何内容。</p></li>
</ul>
<p>在安全行业，对上述这些技术的使用，通常被称为“<strong>living off the
land</strong>”（离地生存？生存手段？）。</p>
<h4><span id="真实案例一个无文件入侵的解剖">真实案例：一个无文件入侵的解剖</span></h4>
<p>通过展示CrowdStrike
Services事件响应团队发现的一个真实的案例，我们可以检查端到端的无恶意软件入侵是什么样子。</p>
<p>在本例中，首个目标是<strong>使用Microsoft
ISS并运行SQL服务器数据库的web服务器</strong>。对于最初的入侵，攻击者使用了一个web
shell，一个可以被上传到web服务器并在其上执行的简短脚本。脚本可以用web服务器支持的任何语言编写，比如Perl、Python、ASP或PHP。Web
Shell在此类攻击中很流行，因为它们可以通过<strong>利用系统上存在的漏洞直接加载到内存中</strong>，而无需将任何内容写入磁盘。在这一特定的攻击中，对手使用SQL注入，将其web
shell嵌入到服务器。</p>
<blockquote>
<p>WEB
Shell允许使用web浏览器来远程访问系统。它们可以用ASP或PHP或任何其他web脚本语言编写，代码可以非常小。如下所示：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181506159.png" alt="img" style="zoom:50%;"></p>
<p>由于web服务器<strong>没有正确检查转义字符</strong>，攻击者能够简单地将web
shell回传到服务器上。所用的web shell，名为“<strong>China
Chopper</strong>”（中国菜刀/直升机），包含了JavaScript命令，值得注意的是它只使用了72个字符。在内存中执行web
shell，使攻击者能够使用Chopper用户界面，对web服务器执行任意命令。通过对web服务器的完全远程访问，攻击者通过执行编码的PowerShell命令，来窃取凭据。</p>
</blockquote>
<p>第一步是从远程服务器下载脚本，将脚本直接加载到内存中，然后执行它。这个脚本反过来窃取了缓存在web服务器内存中的所有纯文本密码。在几秒钟内，攻击者获得了系统上所有帐户的多个用户名和密码。</p>
<p><strong>PowerShell是一个合法的Windows工具</strong>，它允许攻击者在受损系统上执行任何操作，而不必在磁盘上写入恶意软件。为了进一步做混淆，攻击者可以对其PowerShell脚本进行编码，如下所示：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181506444.png" alt="img" style="zoom:50%;"></p>
<p>下一步是让攻击者在服务器上实现<strong>持久化</strong>。为了在不需要任何恶意软件的情况下执行此操作，攻击者使用了一种称为“<strong>粘滞键</strong>”（Sticky
Keys）的技术。通过修改Windows注册表中的一行，攻击者可以使用PowerShell或WMI命令，轻松完成此操作，从而将Windows屏幕键盘进程，设置为<strong>调试模式</strong>。</p>
<p><strong>粘滞键（Sticky
Keys）</strong>是使攻击者<strong>无需登录凭据</strong>即可<strong>访问命令shell</strong>的注册表项。如下所示：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181506654.png" alt="img" style="zoom:50%;"></p>
<p>当设置为调试模式时，屏幕键盘允许具有远程访问权限的任何人，以系统权限打开命令行，而无需登录。一旦设置了该注册表项，攻击者可以通过打开到web服务器的远程桌面连接，随时返回。此外，访问系统而<strong>不在Windows事件历史记录中生成登录事件</strong>，会使攻击者的行为几乎无法追踪。</p>
<blockquote>
<p>现在小结一下，本案例中，<strong>在不同的攻击阶段所使用的文件技术</strong>包括：</p>
<ul>
<li><p><strong>初始入侵</strong>：针对Web服务器的<strong>SQL注入</strong>攻击；</p></li>
<li><p><strong>命令与控制（C2）</strong>：“中国菜刀/直升机”的<strong>Web
Shell</strong>；</p></li>
<li><p><strong>提升权限</strong>：使用<strong>PowerShell脚本</strong>转储<strong>凭据</strong>；</p></li>
<li><p><strong>建立持久化</strong>：修改<strong>注册表</strong>粘滞键技术。</p></li>
</ul>
</blockquote>
<h3><span id="作案工具真实世界的无文件恶意软件">作案工具：真实世界的无文件恶意软件</span></h3>
<p>无文件恶意软件经常使用的工具和技术包括：</p>
<ul>
<li><strong>漏洞利用工具包</strong></li>
<li><strong>利用合法工具，如WMI和PowerShell</strong></li>
<li><strong>使用被盗凭证</strong></li>
<li><strong>注册表驻留恶意软件</strong></li>
<li><strong>内存型（Memory-only）恶意软件</strong></li>
</ul>
<p><strong>1）漏洞利用工具包（Exploit kits）</strong></p>
<p>漏洞利用是一种允许攻击者利用操作系统或应用程序漏洞来访问系统的技术。<strong>漏洞利用是一种高效的无文件技术</strong>，因为它们可以直接注入内存中，而无需将任何内容写入磁盘。</p>
<p>通过允许攻击者自动化和大规模执行初始突破，漏洞利用工具包使得攻击者的生活更轻松、工作更高效。<strong>所需要做的只是，诱使受害者进入漏洞利用工具包服务器</strong>，办法通常是网络钓鱼或社会工程。</p>
<p>这些工具包通常提供对许多漏洞的攻击，以及一个管理控制台，一旦成功利用漏洞，攻击者就可以控制失陷的系统。有些漏洞利用工具包甚至提供了扫描受害者系统中的漏洞的功能，因此可以快速构建并启动成功的漏洞攻击。</p>
<p><strong>2）注册表驻留恶意软件</strong></p>
<p>注册表驻留恶意软件是安装在Windows注册表中的恶意软件，以便在逃避检测的同时，保持持久性。第一种是<strong>Poweliks</strong>，此后就出现了许多变体。一些变体，如Kovter，使用了类似的注册表隐藏技术，来保持不被发现。Poweliks<strong>调用C2（命令和控制）服务器</strong>，攻击者可以从该服务器向受损系统发送进一步的指令。所有这些操作，都可以在没有任何文件写入磁盘的情况下进行。</p>
<p><strong>3）内存型（Memory-only）恶意软件</strong></p>
<p>有些恶意软件只存在于内存中，以逃避检测。新版本的<strong>Duqu蠕虫</strong>就是这种情况，它只驻留在内存中，不会被发现。Duqu
2.0有两个版本：第一个是后门，它允许攻击者在组织中站稳脚跟。如果攻击者认为目标值得攻击，他可以使用Duqu
2.0的高级版本，该版本提供了诸如侦察、横向移动、数据渗出等附加功能。Duqu2.0以成功攻破电信行业的公司以及至少一家知名的安全软件提供商而闻名。</p>
<p><strong>4）无文件型勒索软件</strong></p>
<p>甚至勒索软件攻击者，现在也在使用无文件技术，来实现他们的目标。在这类勒索软件中，<strong>恶意代码要么嵌入文档中以使用本机脚本语言（如宏），要么使用漏洞直接写入内存</strong>。然后，勒索软件<strong>使用合法的管理工具如PowerShell，来加密人质文件</strong>，而所有这些都不需要写入磁盘。</p>
<h3><span id="为何传统技术无法抵御无文件攻击">为何传统技术无法抵御无文件攻击</span></h3>
<p>由于传统安全解决方案极难检测到无文件攻击，因此无文件攻击正在增加。让我们来看看，为什么当今市场上的一些端点保护技术，对这些无恶意软件入侵如此脆弱。</p>
<p><strong>1）传统防病毒（AV）</strong>旨在寻找已知恶意软件的特征码。由于无文件攻击没有恶意软件，所以AV没有可检测的特征码。</p>
<p><strong>2）基于机器学习（ML）</strong>的反恶意软件方法，在应对无文件攻击时，面临着与传统AV相同的挑战。<strong>ML动态分析</strong>未知文件，并将其区分为好的或坏的。但是我们已经注意到，在无文件攻击中，<strong>没有要分析的文件</strong>，因此ML无法提供帮助。</p>
<p><strong>3）白名单方法</strong>包括列出一台机器上所有良好的进程，以防止未知进程执行。无文件攻击的问题在于，它们利用易受攻击的合法白名单应用程序，并利用内置的操作系统可执行文件。阻止用户和操作系统共同依赖的应用程序，并不是一个好的选项。</p>
<p><strong>4）使用失陷指标（IOC）工具</strong>来防止无文件攻击也不是很有效。本质上，<strong>IOC类似于传统的AV签名，因为它们是攻击者留下的已知恶意制品</strong>。然而，由于它们利用合法的进程，并且在内存中操作，所以无文件攻击不会留下制品，因此IOC工具几乎找不到任何东西。</p>
<p><strong>5）另一种方法涉及沙箱</strong>，它可以采取多种形式，包括基于网络的爆破和微虚拟化。由于无文件攻击不使用PE文件，因此沙盒没有什么可爆破的。即便真有东西被发送到沙箱，因为无文件攻击通常会劫持合法进程，大多数沙箱也都会忽略它。</p>
<h3><span id="crowdstrike的解决方案">CrowdStrike的解决方案</span></h3>
<p>正如我们所看到的，如果您依赖基于签名的方法、沙盒、白名单甚至机器学习保护方法，那么想检测无文件技术是非常有挑战性的。</p>
<p>为了抵御秘密的、无文件的攻击，<strong>CrowdStrike独特地将多种方法结合到一个强大的集成式方法中，提供了无与伦比的端点保护</strong>。CrowdStrikeFalcon平台通过单个的轻量级代理提供了云原生的下一代端点保护，并提供一系列互补的预防和检测方法：</p>
<ul>
<li><p><strong>应用程序清单（Application
inventory）</strong>：可以发现在您的环境中运行的任何应用程序，帮助您找到漏洞，以便您可以修补或更新它们，使之不会成为漏洞利用工具包的目标。</p></li>
<li><p><strong>漏洞利用阻断（Exploit
blocking）</strong>：通过未修补漏洞的漏洞利用方法，来阻断无文件攻击的执行。</p></li>
<li><p><strong><font color="red"> 攻击指标（IOA，Indicators of
Attack）：</font></strong>在攻击的早期阶段，识别并阻止恶意活动，以免其完全执行并造成损害。此能力还可以防止那些新的勒索软件类别，那些勒索软件不使用文件加密受害者系统。**</p></li>
<li><p><strong>托管狩猎（Managed
hunting）</strong>：全天候地主动搜索由于无文件技术而产生的恶意活动。</p></li>
</ul>
<h4><span id="ioa攻击指标的力量">IOA（攻击指标）的力量</span></h4>
<blockquote>
<p><strong>IOA检测恶意软件或攻击完成其任务所必须执行的事件序列,
IOA关注的是所执行的行为、它们之间的关系、它们的顺序、它们的依赖性，将它们视为揭示一系列事件背后真实意图和目的的指标。IOA不关注攻击者使用的特定工具和恶意软件。</strong></p>
</blockquote>
<p>IOA之所以引人注目，是因为它们提供了<strong>针对无文件攻击的独特的主动预防能力</strong>。<strong>IOA寻找攻击可能正在进行的迹象，而不是关心攻击的步骤是如何执行的</strong>。<strong>迹象可以包括代码执行、试图隐身、横向移动等等</strong>。<strong>如何启动或执行这些步骤对IOAs来说并不重要</strong>。</p>
<p><strong><font color="red">
IOA关注的是所执行的行为、它们之间的关系、它们的顺序、它们的依赖性，将它们视为揭示一系列事件背后真实意图和目的的指标。IOA不关注攻击者使用的特定工具和恶意软件。</font></strong></p>
<p>此外，在无文件攻击的情况下，恶意代码可以利用诸如PowerShell之类的合法脚本语言，而无需写入磁盘。正如我们所看到的，这对于基于签名的方法、白名单、沙箱甚至机器学习来说都是一个挑战。相比之下，<strong>IOA检测恶意软件或攻击完成其任务所必须执行的事件序列。</strong>这可以暴露最隐秘的无文件方法，因此它们可以被迅速处理。</p>
<p>最后，由于IOA会查看意图、上下文、活动序列，因此<strong>即使恶意活动是使用合法帐户实施的，也可以检测和阻止这些活动</strong>，攻击者使用窃取的凭据时通常会出现这种情况。</p>
<p>所有这些使得<strong>IOA成为防止无文件恶意软件攻击的突破口</strong>。IOA不再基于磁盘上可执行文件的存在与否，来开展无文件攻击这场徒劳的战斗，而是在<strong>造成任何损害之前监视、检测、阻止此类攻击的影响</strong>。</p>
<h4><span id="托管狩猎">托管狩猎</span></h4>
<p>托管狩猎（Managed
Hunt）是针对文件攻击的另一种独特而有效的防御措施。<strong>Falcon
OverWatch</strong>（猎鹰看守）是Falcon平台的<strong>威胁搜索组件</strong>，它提供了一个<strong>额外的保护层</strong>，来抵御无文件攻击。</p>
<p><strong>利用Falcon平台的强大功能，OverWatch（看守）团队全天候主动狩猎威胁，监控客户的环境，并狩猎那些标准安全技术无法检测到但可能表明正在发生攻击的狡猾活动。</strong>Falcon
OverWatch确保即使是最复杂和最隐蔽的攻击，也能在发生时被发现。它通过狩猎和识别难以检测的、复杂的、尖端的攻击，生成有意义的警报和精确的指导性补救建议，从而提高您对抗无文件技术的效率。</p>
<h4><span id="结论">结论</span></h4>
<p>由于漏洞利用工具包的存在，导致了攻击组合的高效性和易创建性，很可能会提高无文件黑客技术的普及率。不幸的是，鉴于传统杀毒软件无法阻止无文件攻击，犯罪黑客越来越可能将注意力集中在这些隐形技术上。因此，安全专家需要在他们的安全策略中，考虑无文件恶意软件和无文件攻击的存在。</p>
<p>正如本文所解释的那样，传统的安全措施在面对无文件攻击时可能不够有效，需要新的保护方法。CrowdStrike
Falcon（猎鹰平台）提供了一种全面的解决方案，不仅可以防御无文件攻击，而且还可以很好地防御已知和未知的恶意软件威胁。</p>
<h3><span id="威胁图和攻击指标">威胁图和攻击指标</span></h3>
<p>CrowdStrike将自身定位为<strong>云交付</strong>的<strong>下一代端点保护</strong>的领导者。CrowdStrike是第一家也是唯一一家统一了<strong>下一代防病毒、端点检测和响应（EDR）、IT卫生、漏洞评估、全天候托管狩猎服务</strong>的公司——全部通过<strong>一个轻量级代理</strong>提供，彻底革新了端点保护。CrowdStrike的<strong>端点保护平台</strong>（EPP）如下图所示：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181507229.png" alt="img" style="zoom:50%;"></p>
<h4><span id="威胁图threat-graph">威胁图（Threat Graph）</span></h4>
<p>CrowdStrike
Falcon（猎鹰）平台由两种紧密集成的<strong>专有技术</strong>组成：一个是易于部署的智能<strong>轻量级代理</strong>；另一个是基于云的动态<strong>图数据库</strong>，即上面提到的<strong>威胁图</strong>（Threat
Graph）。</p>
<p><strong>下表进一步梳理了威胁图的主要特性</strong>：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181507209.png" alt="img" style="zoom:50%;"></p>
<p>https://www.crowdstrike.com/cybersecurity-101/indicators-of-compromise/ioa-vs-ioc/</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-STIX协议 《网络威胁情报协议》</title>
    <url>/posts/RDNYV/</url>
    <content><![CDATA[<h2><span id="网络威胁情报之-stix-21">网络威胁情报之 STIX 2.1</span></h2>
<blockquote>
<p>https://zhuanlan.zhihu.com/p/365563090</p>
</blockquote>
<h3><span id="一-说明">一、说明</span></h3>
<p>STIX（Structured Threat Information
Expression）是一种用于交换网络威胁情报（cyber threat
intelligence，CTI）的语言和序列化格式。STIX的应用场景包括：<strong>协同威胁分析、自动化威胁情报交换、自动化威胁检测和响应</strong>等。</p>
<h5><span id="stix对网络威胁情报的描述方法如下">STIX对网络威胁情报的描述方法如下：</span></h5>
<figure>
<img src="https://pic4.zhimg.com/80/v2-c9e59ff49083188d1bf41879c9e1756b_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>STIX Domain
Objects</strong>（SDO）：威胁情报主要的分类对象，包含了一些威胁的behaviors和construct，共有18种类型：<strong>Attack
Pattern</strong>, Campaign, <strong>Course of Action</strong>, Grouping,
Identity, Indicator, Infrastructure, Intrusion Set, Location, Malware,
Malware Analysis, Note, Observed Data, Opinion, Report, Threat Actor,
Tool, and Vulnerability.</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-e5fbd4d7693f6dae450a18d6e5981c6a_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic2.zhimg.com/80/v2-acb4fcb44a2a7d8dd065c75aa848cdc1_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>STIX Cyber-observable
Objects</strong>（SCO）：威胁情报中具体的可观察对象，用于刻画<strong>基于主机或基于网络的信息</strong>。</p>
<ul>
<li>SCO会被多种SDO所使用，以提供上下文支持，如<em>Observed Data</em>
SDO，表示在特定时间观察到的raw
data；在STIX2.0中，SCO在SDO中出现时只会以Observed
Data的形式出现，在STIX2.1则不限于此。</li>
<li>SCO本身不包括who，when和why的信息，但是将SCO和SDO关联起来，可能会得到这些信息以及对威胁更高层面的理解。</li>
<li>SCO可以捕获的对象包括文件、进程、IP之间的流量等。</li>
</ul>
<p><strong>STIX Relationship
Objects</strong>（SRO）：用于SDO之间、SCO之间、SDO和SCO之间的关系。SRO的大类包括以下两种：</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-2e19804c43197207ae032bc991594ca0_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>generic
SRO（Relationship）</strong>：大多数关系所采用的类型，其relation_type字段包括：内置关系：如Indicator到Malware之间的关系，可以用<em>indicates</em>
表示，它描述了该Indicator可用于检测对应的恶意软件；自定义关系；</p>
<p><strong>Sighting
SRO</strong>：用于捕获实体在SDO中出现的案例，如sighting an
indicator。没有明确指明连接哪两个object。之所以将其作为独立的SRO，是因为其具有一些独有的属性，如<em>count</em>。</p>
<p>除了SRO，STIX还用ID references来表示嵌入关系（embedded
relationship）。当使用嵌入关系时，表示该属性时该对象的内置属性，从而不需要使用SRO表示，如<em>create_by_ref。</em>因此，SRO可以视为两个节点直接的边，而embedded
relationship则可以视为属性（只不过其表示了二元关系）</p>
<ul>
<li><strong>STIX Meta Objects</strong>：用于丰富或扩展STIX Core
Objects</li>
<li><strong>STIX Bundle Object</strong>：用于打包STIX内容</li>
</ul>
<p><strong>STIX是一种基于图的模型，其中SDO和SCO定义了图的节点，而STIX
relationships定义了边</strong>。</p>
<p><strong>STIX Patterning
language</strong>：STIX模式语言可以实现网络或终端的威胁检测。该语言目前使用STIX
Indicator对象，来匹配时序的observable data。</p>
<h3><span id="二-通用数据类型">二、<strong>通用数据类型</strong></span></h3>
<p><img src="https://pic3.zhimg.com/80/v2-2d7ff334fee36adda542c0d3281c5d62_1440w.jpg" alt="img" style="zoom:67%;"></p>
<h3><span id="三-stix-通用概念">三、 <strong>STIX 通用概念</strong></span></h3>
<ul>
<li>STIX common properties</li>
</ul>
<p><img src="https://pic3.zhimg.com/80/v2-4502a49dc00fc1bfae5913c20a191a3e_1440w.jpg" alt="img" style="zoom:67%;"></p>
<h3><span id="四-stix-domainobjects"><strong>四、 STIX Domain
Objects</strong></span></h3>
<p>每个SDO对应
交换网络威胁情报CTI中的唯一概念。<strong>使用SDO，SCO和SRO作为基本模块</strong>，用户可以方便的创建和共享CTI。</p>
<p><strong>SDO</strong>：</p>
<ul>
<li>Property：通用属性、SDO转专用属性</li>
<li>Relationship：embedded relationships、common relationships</li>
</ul>
<p>一些相似的SDO可以被归为一个大类，如：</p>
<ul>
<li><strong>Attack Pattern, Malware, and
Tool可以被归为TTP，因为它们描述了攻击行为和资源</strong></li>
<li>Campaign, Intrusion Set, and Threat Actor
可以被描述为“攻击者发动攻击的原因，以及如何组织（why and how）”</li>
</ul>
<h4><span id="41-attack-pattern">4.1 <strong>Attack Pattern</strong></span></h4>
<p>TTP类型之一，它描述了攻击者试图破坏目标的<strong>方式，</strong>对应于TTP中的<strong>战术</strong>。可用于帮助对<strong>攻击进行分类</strong>，将特定的<strong>攻击概括为其遵循的模式</strong>，并提供有关<strong>如何进行攻击的详细信息</strong>。</p>
<blockquote>
<p>如spear
fishing就是一种攻击模式，而更具体的描述，如被特定攻击者实施的spear
fishing也是一种攻击模式。</p>
</blockquote>
<h4><span id="42-campaign"><strong>4.2 Campaign</strong></span></h4>
<p>表示某次具体的攻击活动。A Campaign is a grouping of adversarial
behaviors that describes a set of malicious activities or attacks
(sometimes called waves) that occur over a period of time against a
specific set of targets. Campaigns usually have well defined objectives
and may be part of an Intrusion Set.</p>
<blockquote>
<p>战役是一组敌对行为，描述了针对特定目标集在一段时间内发生的一组恶意活动或攻击（有时称为WAVE）。活动通常有明确的目标，可能是入侵集的一部分。</p>
</blockquote>
<h4><span id="43-course-of-action响应的行为">4.3 <strong>Course of Action
(响应的行为)</strong></span></h4>
<p>用于预防攻击或对攻击做出响应的行为，它回包含技术，自动化响应（补丁、重新配置防火墙），或高级别的动作（如员工培训或者策略制定）。</p>
<h4><span id="44-grouping"><strong>4.4 Grouping</strong></span></h4>
<p>Grouping表示分析和调查<strong>过程中</strong>产生的数据（待确认的线索数据）；还可以用来声明<strong>其引用的STIX对象与正在进行的分析过程有关</strong>，如当一个安全分析人员正在跟其它人合作，分析一系列Campaigns和Indicators的时，<strong>Gouping会引用一系列其它SDO、SCO和SRO（Grouping就表示协作分析吧）。</strong></p>
<p>除了embedded relationship和common
relationship之外，没有明确定义Grouping对象和其它STIX对象之间的关系。</p>
<h4><span id="45-identity"><strong>4.5 Identity</strong></span></h4>
<p><strong>Identity可以代表特定的个人、组织或团伙</strong>；也可以代表一类个人、组织、系统或团伙。Identity
SDO可以捕获基本标识信息，联系信息以及Identity所属的部门。
Identity在STIX中用于表示攻击目标，信息源，对象创建者和威胁参与者身份。</p>
<h4><span id="46-incident"><strong>4.6 Incident</strong></span></h4>
<p>stub对象，待完善，没有专门定义的property和relationship。</p>
<h4><span id="47-indicator"><strong>4.7 Indicator</strong></span></h4>
<p>Indicator表示可用于检测可疑行为的模式。如用STIX Patterning
Language来描述恶意域名集合（第九章）。</p>
<h4><span id="48-infrastructure"><strong>4.8 Infrastructure</strong></span></h4>
<p><strong>TTP的类型之一，用于描述系统、软件服务等其它的物理或虚拟资源</strong>；如攻击者使用的C2服务器，防御者使用的设备和服务器，以及作为被攻击目标的数据库服务器等；</p>
<p>基于此我们可以将受保护网络中的设备纳入知识图谱，采用类似于这样的关系：</p>
<p><img src="https://pic2.zhimg.com/80/v2-1d2970679ce3243e8ccefe0eda890351_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="49-intrusion-set"><strong>4.9 Intrusion Set</strong></span></h4>
<p>Intrusion
set是由<strong>某个组织</strong>所使用的恶意行为和资源的集合。一个Intrusion
Set可能会捕获多个Campaigns，他们共同指向一个Threat
Actor。新捕获的活动可以被归因于某个Intrusion
Set，而Actors可以在Intrusion之间跳转，甚至从属于多个Intrusion Set。</p>
<p>如在 apt1.json 中，整个报告被打包在bundle中，而Intrusion
Set用来指示APT组织：</p>
<p><img src="https://pic3.zhimg.com/80/v2-e40a11cbdf0b033063367a3d045d77ba_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p><strong>Intrusion Set和Campaigns对比：</strong></p>
<p><strong><font color="red"> 如果 Campaigns
是在一段时间内针对一组特定目标进行的一组攻击，以实现某些目标，那么入侵集就是整个攻击包，可以在多个活动中长期使用，以实现潜在的多个目的.</font></strong>由Intrusion
Set找出Threat Actors，nation state或者nation
state中的某个APT组织，是一个<strong>溯源</strong>的过程。</p>
<h4><span id="410-location"><strong>4.10 Location</strong></span></h4>
<p>表示具体地点，可以与Identity或Intrusion
Set相关联，表示其位置；与Malware或Attack Pattern相关联，表示其目标。</p>
<h4><span id="411-malware"><strong>4.11 Malware</strong></span></h4>
<p>TTP类型之一，表示<strong>恶意软件或代码。</strong></p>
<h4><span id="412-malware-analysis"><strong>4.12 Malware Analysis</strong></span></h4>
<p>捕获了在恶意软件实例或恶意软件家族分析过程中，动态分析或静态分析的结果。</p>
<h4><span id="413-note"><strong>4.13 Note</strong></span></h4>
<p>其他对象中不存在的额外信息；例如，分析人员可以在一个Campaign对象中添加注释，以表明他在黑客论坛上看到了与该Campaign相关的帖子。同样，Note对象也没有定义与其他STIX
Object之间的关系。</p>
<h4><span id="414-observed-data"><strong>4.14 Observed Data</strong></span></h4>
<p><strong>网络安全相关的可观察对象（raw
information）集合，其引用对象为SCO，包含从analyst reports, sandboxes,
and network and host-based detection tools等收集的信息。</strong></p>
<p><strong>必须包含objects或者object_refs属性，表示对SCO的引用</strong>：</p>
<p>Observed Data只有反向关系。此外，还会被Sighting SRO所指向：Sightings
represent a relationship between some intelligence entity** that was
seen** (e.g., an Indicator or Malware instance), <strong>where it was
seen</strong>, and <strong>what evidence was actually seen.</strong> The
<strong>evidence (or raw data) in that relationship is captured as
Observed Data（Sighting中的证据就是Observed Data）。</strong></p>
<h4><span id="415-opinion"><strong>4.15 Opinion</strong></span></h4>
<p>Opinion是对STIX对象中信息正确性的评估。</p>
<h4><span id="416-report"><strong>4.16 Report</strong></span></h4>
<p>威胁情报报告。</p>
<h4><span id="417-threat-actor"><strong>4.17 Threat Actor</strong></span></h4>
<p>攻击的个人、团体或组织；其与Intrusion Set不同，Threat
Actor会同时支持或附属于不同的Intrusion Set、团体或组织。</p>
<h4><span id="418-tool"><strong>4.18 Tool</strong></span></h4>
<p><strong>Tool是威胁参与者可以用来执行攻击的合法软件。与Malware不同，Tool一般是合法软件，如Namp、VNC。</strong></p>
<h4><span id="419-vulnerability"><strong>4.19 Vulnerability</strong></span></h4>
<p>漏洞。用于连接相关漏洞的外部描述（external_references），或还没有相关描述的0-day漏洞。</p>
<p><strong>Q&amp;A：</strong></p>
<ul>
<li><strong>Q1：embedded
relationship和节点property有啥区别？</strong>property是节点属性，embedded
relationship是带有二元关系的节点属性</li>
<li><strong>Q2：Observed Data和SCO有啥区别？</strong>Observed
Data观察行为与观察对象的信息，而<strong>SCO是具体可观察实体的信息，二者是引用与被引用的关系</strong></li>
<li><strong>Q3：Intrusion Set、Identity和Threat
Actor的区别？</strong>Intrusion
Set是最高层的实体，其包括Identity和Threat
Actor，如APT1（高层APT组织）为Intrusion Set，其包含一些个人（Ugly
Gorilla）或团体（SuperHard）的Threat
Actor，而Identity是用真实名称描述的个人或组织（如Ugly Gorilla指向Wang
Dong）。由此看来，Threat Actor也可以用真是名称描述（Communist Party of
China），但是明显指示了其表示威胁主体，而Identity本身不显示其角色信息。</li>
</ul>
<h3><span id="五-stix-relationshipobjects"><strong>五、 STIX Relationship
Objects</strong></span></h3>
<h4><span id="51-relationship"><strong>5.1 Relationship</strong></span></h4>
<p><strong>Type Name: relationship</strong></p>
<p>用于连接STIX中的SDO或SCO;
STIX中的Relationship在每个SDO或SCO的定义中进行了描述,
用户还可以自定义关系。STIX中所有内置的Relationship详见文档Appendix
B。注意, Relationship本身也是一个对象, 因此其也有自身的 Property 和
Relationships。</p>
<h4><span id="52-sighting"><strong>5.2 Sighting</strong></span></h4>
<p><strong>Type Name: sighting</strong></p>
<p><strong>原文定义</strong>:目击(sighting)表示认为在CTI中看到了某些东西（例如指示器、恶意软件、工具、威胁因素等）。目击用于跟踪目标是谁和什么，如何实施攻击，以及跟踪攻击行为的趋势。</p>
<blockquote>
<p>A Sighting denotes the belief that something in CTI (e.g., an
indicator, malware, tool, threat actor, etc.) was seen. Sightings are
used to track who and what are being targeted, how attacks are carried
out, and to track trends in attack behavior.</p>
</blockquote>
<p>Sighting 没有连接两个对象, 但却被定义为关系,
原因是:目击包括三部分的内容:•
发现的内容，如指示器、恶意软件、活动或其他SDO（sightingfef）•发现者和/或发现地点，表示为身份（whereightedefs）•系统和网络上实际看到的内容，表示为观察数据（SECUREDataefs）</p>
<blockquote>
<p>Sighting is captured as a relationship because you cannot have a
sighting unless you have something that has been sighted. Sighting does
not make sense without the relationship to what was sighted</p>
</blockquote>
<p>Sighting包括三部分的内容:</p>
<ul>
<li><strong>What</strong> was sighted, such as the <strong>Indicator,
Malware, Campaign, or other SDO</strong> (<em>sighting_of_ref</em>)</li>
<li><strong>Who</strong> sighted it and/or where it was sighted,
represented as an <strong>Identity</strong>
(<em>where_sighted_refs</em>)</li>
<li><strong>What</strong> was actually seen on systems and networks,
represented as <strong>Observed Data</strong>
(<em>observed_data_refs</em>)</li>
</ul>
<p>Sighting和Observed Data的区别:</p>
<p><strong>目击与观察到的数据不同，因为目击是一种情报断言（“我看到了这个威胁参与者”）</strong>，而观察到的数据只是信息（“我看到了这个文件”）。当您通过包含来自目击的链接观测数据（Observedataefs）来组合它们时，您可以说“我看到了这个文件，这让我觉得我看到了这个威胁参与者”。</p>
<blockquote>
<p>Sighting is distinct from Observed Data in that Sighting is an
<strong>intelligence assertion</strong> ("I saw this threat actor")
while Observed Data is simply information ("I saw this file"). When you
combine them by including the linked Observed Data (observed_data_refs)
from a Sighting, you can say "I saw this file, and that makes me think I
saw this threat actor".</p>
</blockquote>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-蚂蚁安全-柳星《FXY：Security-Scenes-Feature-Engineering-Toolkit》</title>
    <url>/posts/1QB4KAB/</url>
    <content><![CDATA[<h2><span id="fxysecurity-scenes-feature-engineering-toolkit">FXY：<em>Security-Scenes-Feature-Engineering-Toolkit</em></span></h2>
<blockquote>
<p>https://github.com/404notf0und/FXY/blob/master/docs/%E9%9C%80%E6%B1%82%E5%92%8C%E8%AE%BE%E8%AE%A1.md</p>
</blockquote>
<h3><span id="介绍">介绍</span></h3>
<p>FXY是一款特征工程框架，用于安全场景中数据预处理、数据预分析、数据特征化和向量化等任务。FXY这个名字一方面代表这款工具的目的是从原始安全数据中获取Feature
X和Feature
Y用于对接人工智能算法，另一方面寓意着人工智能的本质，函数Y=F(X)。FXY的特性是支持多种安全场景多种安全数据的预处理和特征化，内置多种NLP通用特征提取方法，内置脚本扩展支持二次开发。</p>
<h3><span id="需求">需求</span></h3>
<p>无论机器学习、深度学习还是强化学习应用在哪个领域，<strong>其处理流程主要有五个环节：问题-&gt;数据-&gt;特征化-&gt;算法-&gt;结果</strong>，数据的数字化，狭义的来说是数据的特征化，在整个流程中起到了承上启下的关键作用，承上，<strong>特征化的好坏直接反映了对问题本质的理解深入与否</strong>，启下，作为算法的输入，一定程度上决定了最终结果的天花板。这是FXY定位于安全场景下特征工程环节的一点原因。另一点原因是考虑到算法环节的不确定性因素和确定性因素，不确定性因素导致难以形成统一的范式，确定性因素导致问题已被解决。就算法的应用来说，机器学习算法、深度学习算法和超参数众多，在同一特征化方法下，难以客观比较不同算法的性能，并且找到泛化性强的SOTA算法。<strong>就算法本身来说，现有的框架tensorflow、keras等对算法的封装已经很完美了，重复造轮子意义不大。如果给算法环节盖上安全场景的帽子，问题依然如此，这是FXY不选择定位于安全场景下算法环节的原因。</strong></p>
<h3><span id="架构设计">架构设计</span></h3>
<p><img src="https://i.imgur.com/d2Rq9hc.png"></p>
<p>因为机器学习解决安全问题的流程固定为安全问题-&gt;数据-&gt;数字化-&gt;算法-&gt;结果，<strong>具体到FXY的架构设计，从下到上依次是安全场景层-&gt;数据的数据层-&gt;数据清洗层-&gt;特征层-&gt;算法层-&gt;API层</strong>，对应的FXY各模块层次结构依次为内置函数模块-&gt;数据预处理模块-&gt;特征工程模块-&gt;tensorflow/keras-&gt;控制器模块。</p>
<p>扩展可扩展的，因为安全场景较多且杂，完全不可能用一种或少数几种特征方法解决所有问题，想到的一种解决方式是针对安全问题做特征方法的插件化扩展，把每个安全问题对应每个CMS，每个feature
engineering方法对应每个POC，那么就可以像写CMS
POC一样专注于安全场景的底层数据feature engineering。</p>
<h3><span id="集成">集成</span></h3>
<p>笔者Github上AI-for-Security-Learning仓库专注于知识，而此FXY仓库专注于工具，现依赖前者仓库，笔者开始二刷，站在前人的肩膀上，不断集成优质方法到FXY框架中，此框架不做未知的创新。现已集成4种安全场景，4种特征工程方法，四种安全场景分别是<strong>LSTM识别恶意HTTP请求@cdxy，AI-Driven-WAF@exp-db，Phishing
URL
Classification@surajr，使用深度学习检测XSS@Webber，基于深度学习的恶意样本行为检测@ApplePig<span class="citation" data-cites="360云影实验室">@360云影实验室</span></strong>，四种特征工程方法分别是<strong>钓鱼url的统计特征，恶意url和恶意软件api的词典索引特征，恶意url的TF-IDF特征，xss的word2vec词嵌入向量</strong>。</p>
<p>在二刷并集成的过程中，需要彻底读懂原作者的文章思路和代码，然后改写到FXY限定的框架中，学到了很多。同时输出一份二刷笔记，里面不但包括已集成代码到框架中的原文理解，还包括一些暂时无法集成的文章的理解，文档化记录了原作者用到的安全场景、解决的思路、数据的构成、数据预处理方法、特征的方法、使用的模型、有无监督分类，二刷笔记持续更新。</p>
<h3><span id="潜在问题">潜在问题</span></h3>
<p><strong>FXY框架专注于安全问题、数据和特征化三个环节</strong>:这其中数据环节存在数据源难获取的问题，有些文章中的数据属于公司级数据不会开源，较难获取，这导致只能使用开源数据集或自己采集数据集复现原作者的实验，集成并测试框架，虽说不会影响FXY框架的预处理、预分析和特征化等主要功能，但这会导致数据环节数据本身的价值变小，一定程度上减小了FXY框架的价值，因为可能大多数人遇到的问题不是没有方法，而是没有数据，数据本身的价值和数据分析的价值都很高，前者价值甚至大于后者。而CMS的POC框架可以靠各种搜索引擎和爬虫来获取数据源，输送给POC脚本，就不会存在此问题。</p>
<p>这促使我们是不是可以通过爬虫爬取更多异源开源数据，用开源弥补闭源，或是本地搭建环境采集数据，缓解数据源缺失的问题，从而使FXY框架的价值不只在于数据分析，更在于数据集本身，采集数据集是个脏活累活，在规划中。</p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-蚂蚁安全-柳星《我对安全与NLP的实践和思考》</title>
    <url>/posts/2QJPFS5/</url>
    <content><![CDATA[<h1><span id="柳星-我对安全与nlp的实践和思考">柳星-我对安全与NLP的实践和思考</span></h1>
<blockquote>
<p><a href="https://github.com/404notf0und">404notf0und</a>/<strong><a href="https://github.com/404notf0und/FXY">FXY</a></strong></p>
</blockquote>
<h3><span id="一-个人思考">一、个人思考</span></h3>
<p><strong><font color="red">
通过对安全与NLP的实践和思考，有以下三点产出：</font></strong></p>
<ul>
<li><strong>首先，产出一种通用解决方案和轮子，一把梭实现对各种安全场景的安全检测。</strong>通用解决方案给出一类安全问题的解决思路，打造轮子来具体解决这一类问题，而不是使用单个技术点去解决单个问题。<strong>具体来说，将安全与NLP结合，在各种安全场景中，将其安全数据统一视作文本数据，从NLP视角，统一进行文本预处理、特征化、预训练和模型训练。</strong>例如，在Webshell检测中，Webshell文件内容，在恶意软件检测中，API序列，都可以视作长文本数据，使用NLP技术进行分词、向量化、预训练等操作，同理，在Web安全中，SQl、XSS等URL类安全数据，在DNS安全中，DGA域名、DNS隧道等域名安全数据，同样可以视作短文本数据。因此，只要安全场景中安全数据可以看作文本数据，<a href="https://github.com/404notf0und/FXY">FXY：<em>Security-Scenes-Feature-Engineering-Toolkit</em></a>
中，内置多种通用特征化方法和多种通用深度学习模型，以支持多种安全场景的特征化和模型训练，达到流水线式作业。</li>
<li><strong>其次，是对应用能力和底层能力的思考</strong>。之前写过一篇文章《<a href="https://4o4notfound.org/index.php/archives/188/">应用型安全算法工程师的自我修养</a>》，在我当时预期想法中，我理解的应用型，重点在于解决实际安全问题，不必苛求于对使用技术本身的理解深度，可以不具备研究型、轮子型的底层能力。映射到我自身，我做安全和算法，最初想法很好，安全和算法两者我都要做好，这里做好，仅仅指用好。之后，面试时暴露了问题，主管给出的建议是两者都要做好。这里做好，不单单指用好，还要知其所以然。举个例子，就是不仅要调包调参玩的6，还要掌握算法的底层原理，这就是底层能力。当时，懂，也不懂，似懂非懂，因为，说，永远是别人的，悟，才是自己的。在实现通用解决方案和轮子的过程中，遇到关于word2vec底层的非预期问题，才深刻体会到，底层能力对应用能力的重要性。过程中遇到的预期和非预期问题，下文会详述。<strong>现在我理解的应用型，重点还是在解决安全问题，以及对安全问题本身的理解，但应用型还需具备研究型、轮子型等上下游岗位的底层能力。</strong>安全算法是这样，其他细分安全领域也是一样，都需要底层能力，以发展技术深度。</li>
<li>最后，带来思考和认识的提升。<strong>从基于机器学习的XX检测，基于深度学习的XX检测，等各种单点检测，到基于NLP的通用安全检测，是一个由点到面的认知提升</strong>。从安全和算法都要做好，到安全和算法都要做好，其中蕴含着认知的提升。从之前写过一篇安全与NLP的文章《<a href="https://www.4o4notfound.org/index.php/archives/190/">当安全遇上NLP</a>》，到现在这篇文章。对一件事物的认识，在不同阶段应该是不一样的，甚至可能完全推翻自己之前的认识。我们能做的，是保持思考，重新认识过去的经历，提升对事物的认知和认知能力。这个提升认知的过程，类似boosting的残差逼近和强化学习的奖惩，是一个基于不知道不知道-&gt;知道不知道&gt;知道知道-&gt;不知道知道的螺旋式迭代上升过程。</li>
</ul>
<h3><span id="二-预期问题">二、预期问题</span></h3>
<h4><span id="21-分词粒度">2.1 分词粒度</span></h4>
<p><strong>首先是分词粒度，粒度这里主要考虑字符粒度和词粒度。在不同的安全场景中，安全数据不同，采用的分词粒度也可能不同：</strong></p>
<ul>
<li><strong><font color="red">恶意样本检测的动态API行为序列数据，需要进行单词粒度的划分。</font></strong></li>
<li><strong>域名安全检测中的域名数据，最好采用字符粒度划分。</strong></li>
<li><strong>URL安全检测中的URL数据，使用字符和单词粒度划分都可以。</strong></li>
<li><strong>XSS检测文中，是根据具体的XSS攻击模式，写成正则分词函数，对XSS数据进行划分，这是一种基于攻击模式的词粒度分词模式，但这种分词模式很难扩展到其他安全场景中。</strong></li>
</ul>
<p><strong>FXY特征化类wordindex和word2vec中参数char_level实现了该功能</strong>。在其他安全场景中，可以根据此思路，写自定义的<strong>基于攻击模式的分词</strong>，但适用范围有限。我这里提供了两种通用词粒度分词模式，第一种是忽略特殊符号的简洁版分词模式，第二种是考虑全量特殊符号的完整版分词模式，这两种分词模式可以适用于各种安全场景中。FXY特征化类word2vec中参数punctuation的值‘concise’，‘all’和‘define’实现了两种通用分词和自定义安全分词功能。下文的实验部分，会测试不同安全场景中，使用字符粒度和词粒度，使用不同词粒度分词模式训练模型的性能对比。</p>
<h4><span id="22-语料库">2.2 语料库</span></h4>
<p><strong>关于预训练前字典的建立（语料库）</strong>。特征化类word2vec的预训练需求直接引发了字典建立的相关问题。在word2vec预训练前，需要考虑预训练数据的产生。基于深度学习的XSS检测文中，是通过<strong>建立一个基于黑样本数据的指定大小的字典，不在字典内的数据全部泛化为一个特定词，将泛化后的数据作为预训练的数据</strong>。这里我们将此思路扩充，增加使用全量数据建立任意大小的字典。具体到word2vec类中，参数one_class的True
or
False决定了预训练的数据来源是单类黑样本还是全量黑白样本，参数vocabulary_size的值决定了字典大小，如果为None，就不截断，为全量字典数据。下文的实验部分会测试是<strong>单类黑样本预训练</strong>word2vec好，还是<strong>全量数据预训练</strong>更占优势，是<strong>字典截断</strong>好，还是用全量字典来预训练好。</p>
<h4><span id="23-序列">2.3 序列</span></h4>
<p><font color="red">
<strong>关于序列的问题，具体地说，是长文本数据特征化需求</strong>。</font><strong>webshell检测等安全场景，引发了序列截断和填充的问题。</strong>短文本数据的特征化，可以保留所有原始信息。而在某些安全场景中的长文本数据，特征化比较棘手，保留全部原始信息不太现实，需要对其进行截断，截断的方式主要有<strong>字典截断、序列软截断、序列硬截断</strong>。</p>
<ul>
<li><strong>序列软截断</strong>是指对不在某个范围内（参数num_words控制范围大小）的数据，直接去除或填充为某值，长文本选择直接去除，缩短整体序列的长度，尽可能保留后续更多的原始信息。如果长本文数据非常非常长，那么就算有字典截断和序列软截断，截断后的序列也可能非常长，超出了模型和算力的承受范围;</li>
<li><strong>序列硬截断</strong>（参数max_length控制）可以发挥实际作用，直接整整齐齐截断和填充序列，保留指定长度的序列数据。这里需要注意的是，为了兼容后文将说到的“预训练+微调”训练模式中的<strong>预训练矩阵</strong>，序列填充值默认为0。</li>
</ul>
<h4><span id="24-词向量">2.4 词向量</span></h4>
<p>词向量的问题，具体说，是词嵌入向量问题。词嵌入向量的产生有三种方式：</p>
<ul>
<li>词序列索引+有嵌入层的深度学习模型</li>
<li>word2vec预训练产生词嵌入向量+无嵌入层的深度学习模型</li>
<li><strong>word2vec预训练产生预训练矩阵+初始化参数为预训练矩阵的嵌入层的深度学习模型。</strong></li>
</ul>
<p>这里我把这三种方式简单叫做微调、预训练、预训练+微调，从特征工程角度，这三种方式是产生词嵌入向量的方法，从模型角度，也可以看作是模型训练的三种方法。第一种微调的方式实现起来比较简单，直接使用keras的文本处理类Tokenizer就可以分词，转换为词序列，得到词序列索引，输入到深度学习模型中即可。第二种预训练的方式，调个gensim库中word2vec类预训练，对于不在预训练字典中的数据，其词嵌入向量直接填充为0，第三种预训练+微调的方式，稍微复杂一点，简单来说就是前两种方式的组合，用第二种方式得到预训练矩阵，作为嵌入层的初始化权重矩阵参数，用第一种方式得到词序列索引，作为嵌入层的原始输入。下文的实验部分会测试并对比按这三种方式训练模型的性能，<strong>先说结论：预训练+微调&gt;预训练&gt;微调</strong>。</p>
<h3><span id="三-非预期问题">三、非预期问题</span></h3>
<h4><span id="31已知的库和函数不能满足我们的需求">3.1
已知的库和函数不能满足我们的需求</span></h4>
<p>使用keras的文本处理类Tokenizer预处理文本数据，得到词序列索引，完全没有问题。<strong>但类Tokenizer毕竟是文本数据处理类，没有考虑到安全领域的需求。</strong>
+ <strong><font color="red">
类Tokenizer的单词分词默认会过滤所有的特殊符号，仅保留单词，而特殊符号在安全数据中是至关重要的，很多payload的构成都有着大量特殊符号，忽略特殊符号会流失部分原始信息。</font></strong>
+
<strong>首先阅读了keras的文本处理源码和序列处理源码</strong>，不仅搞懂了其结构和各函数的底层实现方式，还学到了一些trick和优质代码的特性。搞懂了其结构和各函数的底层实现方式，还学到了一些trick和优质代码的特性。下图为Tokenizer类的结构。借鉴并改写Tokenizer类，加入了多种分词模式，我们实现了wordindex类。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181514240.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h4><span id="32-对word2vec的理解不到位">3.2 对word2vec的理解不到位</span></h4>
<p>第二个非预期问题是，对word2vec的理解不到位，尤其是其底层原理和代码实现，导致会有一些疑惑，无法得到验证，这是潜在的问题。虽然可以直接调用gensim库中的word2vec类暂时解决问题，但我还是决定把word2vec深究深究，一方面可以答疑解惑，另一方面，就算不能调用别人的库，自己也可以造轮子自给自足。限于篇幅问题，不多讲word2vec的详细原理，原理是我们私下里花时间可以搞清楚的，不算是干货，对原理有兴趣的话，这里给大家推荐几篇优质文章，在github仓库<a href="https://github.com/404notf0und/Always-Learning">Always-Learning</a>中。</p>
<p><strong>word2vec本质上是一个神经网络模型，具体来说此神经网络模型是一个输入层-嵌入层-输出层的三层结构，我们用到的词嵌入向量只是神经网络模型的副产物，是模型嵌入层的权重矩阵。</strong>以word2vec实现方式之一的skip-gram方法为例，此方法本质是通过中心词预测周围词。如果有一段话，要对这段话训练一个word2vec模型，那么很明显需要输入数据，还要是打标的数据。以这段话中的某个单词为中心词为例，在一定滑动窗口内的其他单词都默认和此单词相关，此单词和周围其他单词，一对多产生多个组合，默认是相关的，因此label为1，即是输入数据的y为1，而这些单词组合的one-hot编码是输入数据的x。<strong>那么很明显label全为1，全为positive
sample，需要负采样来中和。这里的负采样不是简单地从滑动窗口外采样，而是按照词频的概率，取概率最小的一批样本来做负样本（这个概念下面马上要用到），因为和中心词毫不相关，自然label为0。</strong></p>
<p><strong><font color="red">
tensorflow中的nce_loss函数实现了负采样。</font></strong></p>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-青藤云安全-安全狩猎</title>
    <url>/posts/3QVJK2E/</url>
    <content><![CDATA[<h2><span id="青藤云安全">青藤云安全</span></h2>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181517940.png" alt="image-20221105221126284"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181517783.png" alt="image-20221105221329660"></p>
<ul>
<li>护网检测的角度：交叉验证？？？</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181517592.png" alt="image-20221105232013125"></p>
<ul>
<li>索引的效率，压缩率</li>
<li>上下文，攻击树</li>
<li><strong>开源的解决方案？？？</strong></li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181518268.png" alt="image-20221105232149561"></p>
<h4><span id="可视化">可视化</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181518127.png" alt="image-20221105233353542"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181518088.png" alt="image-20221105235633129"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181518279.png" alt="image-20221105235813988"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181518619.png" alt="image-20221106150043663"></p>
<h4><span id="attck实战书">ATTCK，实战书</span></h4>
<h4><span id="attampck-数据源">ATT&amp;CK 数据源</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519913.png" alt="image-20221106001624464"></p>
<h4><span id="attampck-12-中一个套动作">ATT&amp;CK 12 中：一个套动作</span></h4>
<h4><span id="攻击链路的弱点">攻击链路的弱点</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519458.png" alt="image-20221106001713487"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519329.png" alt="image-20221106002243403"></p>
<h4><span id="告警确认">告警确认</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519141.png" alt="image-20221106150625666"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519976.png" alt="image-20221106150704168"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519449.png" alt="image-20221106002701972"></p>
<h4><span id="威胁搜猎案例分析">威胁搜猎案例分析</span></h4>
<p>在发现切入点之后，怎么把整个告警链路描绘出来？</p>
<ul>
<li>起点一般是？？</li>
<li>无文件攻击内存马；</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519752.png" alt="image-20221106151139571"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519579.png" alt="image-20221106151211979"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519132.png" alt="image-20221106151330278"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519605.png" alt="image-20221106151451348"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519493.png" alt="image-20221106151557997"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519890.png" alt="image-20221106151644322"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519379.png" alt="image-20221106151759583"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519323.png" alt="image-20221106151841034"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519370.png" alt="image-20221106152030094"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520074.png" alt="image-20221106152054691"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520806.png" alt="image-20221106152157892"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520002.png" alt="image-20221106152227941"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520733.png" alt="image-20221106152258258"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520422.png" alt="image-20221106152429497"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520270.png" alt="image-20221106153100491"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520679.png" alt="image-20221106153126202"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520651.png" alt="image-20221106153149463"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520518.png" alt="image-20221106153209441"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520470.png" alt="image-20221106153342379"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520137.png" alt="image-20221106153413544"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520587.png" alt="image-20221106153521553"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520102.png" alt="image-20221106153714241"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520726.png" alt="image-20221106153749604"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520328.png" alt="image-20221106153855615"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520996.png" alt="image-20221106153825021"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521998.png" alt="image-20221106154040458"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521246.png" alt="image-20221106154854666"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304221745446.png" alt="image-20221106154914480"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521152.png" alt="image-20221106154934078"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521895.png" alt="image-20221106155005831"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521565.png" alt="image-20221106155018946"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521464.png" alt="image-20221106155119929"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521605.png" alt="image-20221106155856100"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521537.png" alt="image-20221106160005755"></p>
<ul>
<li>sigma 社区；
<ul>
<li>情报转换；</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（7）【draft】CADE: Detecting and Explaining Concept Drift Samples for Security Applications</title>
    <url>/posts/3JZF773/</url>
    <content><![CDATA[<h2><span id="cadedetecting-and-explaining-concept-drift-samples-for-securityapplications">CADE:
Detecting and Explaining Concept Drift Samples for Security
Applications</span></h2>
<p>原文作者：Limin Yang, <em>University of Illinois at
Urbana-Champaign</em></p>
<p>原文链接：https://www.usenix.org/conference/usenixsecurity21/presentation/yang-limin</p>
<p>发表会议：USENIXSec 2021</p>
<p><strong>代码地址</strong>：https://github.com/whyisyoung/CADE</p>
<h3><span id="摘要">摘要</span></h3>
<p>概念漂移对部署机器学习模型来解决实际的安全问题提出了严峻的挑战。<strong>由于攻击者（和/或良性对手）的动态行为变化，随着时间的推移，测试数据分布往往会从原始的训练数据转移，从而导致部署的模型出现重大故障</strong>。</p>
<p>为了对抗概念漂移，我们提出了一种新的系统CADE，旨在（1）<strong>检测偏离现有类别的漂移样本</strong>；（2）<strong>解释检测到漂移的原因</strong>。与传统方法不同（需要大量新标签来统计确定概念漂移），我们的目标是在单个漂移样本到达时识别它们。认识到高维离群空间带来的挑战，我们建议将数据样本映射到低维空间，并自动学习距离函数来度量样本之间的相异性。通过对比学习，我们可以充分利用训练数据集中现有的标签来学习如何对样本进行比较和对比。<strong>为了解释检测到的漂移的意义，我们开发了一种基于距离的解释方法</strong>。我们表明，在这个问题背景下，解释“距离”比传统方法更有效，传统方法侧重于解释“决策边界”。我们通过两个案例来评估CADE：Android恶意软件分类和网络入侵检测。我们进一步与一家安全公司合作，在其恶意软件数据库上测试CADE。我们的结果表明，CADE可以有效地检测漂移样本，并提供语义上有意义的解释。</p>
<h3><span id="一-说明">一、说明</span></h3>
<p>由于概念漂移，部署基于机器学习的安全应用程序可能非常具有挑战性。无论是恶意软件分类、入侵检测还是在线滥用检测[6、12、17、42、48]，基于学习的模型都是在“封闭世界”假设下工作的，期望测试数据分布与训练数据大致匹配。然而，部署模型的环境通常会随着时间的推移而动态变化。这种变化可能既包括良性玩家的有机行为变化，也包括攻击者的恶意突变和适应。因此，测试数据分布从原始训练数据转移，这可能会导致模型出现严重故障[23]。</p>
<blockquote>
<p>[23] A survey on concept drift adaptation. ACM computing surveys
(CSUR), 2014.</p>
</blockquote>
<p>为了解决概念漂移问题，大多数基于学习的模型需要<strong>定期重新培训</strong>[36、39、52]。然而，再培训通常需要标记大量新样本（昂贵）。更重要的是，还很难确定何时应该对模型进行再培训。延迟的再培训会使过时的模型容易受到新的攻击。</p>
<p><font color="red"><strong>我们设想，对抗概念漂移需要建立一个监控系统来检查传入数据流和训练数据（和/或当前分类器）之间的关系</strong></font>。图1说明了高级思想。当原始分类器在生产空间中工作时，另一个系统应定期检查分类器对传入数据样本做出决策的能力。<strong>A检测模块(1)
可以过滤正在远离训练空间的漂移样本</strong>。更重要的是，为了<strong>解释漂移的原因（例如，攻击者突变、有机行为变化、以前未知的系统错误）</strong>，我们需要一种解释方法(2)
将检测决策与语义上有意义的特征联系起来。这两项功能对于为开放世界环境准备基于学习的安全应用程序至关重要。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550835.png" alt="image-20220605202728095" style="zoom: 67%;"></p>
<p>之前的工作已经探索了通过直接检查原始分类器（0）的预测置信度来检测漂移样本的方法
<strong>[32]</strong>。置信度较低可能表明传入样本是漂移样本。然而，该置信度得分是基于所有类别已知（封闭世界）的假设计算的概率（总和为1.0）。不属于任何现有类别的漂移样本可能会被分配到错误的类别，并具有很高的置信度（已通过现有工作验证[25、32、37]）。最近的一项工作提出了计算传入样本和每个现有类之间的不一致性度量的想法，以确定适合度[38]。<strong>该不合格度量基于距离函数计算，以量化样本之间的不相似性</strong>。<strong>然而，我们发现这种距离函数很容易失效，尤其是当数据稀疏且维数较高时。</strong></p>
<blockquote>
<p><strong>[32] A baseline for detecting misclassified and
out-of-distribution examples in neural networks.</strong></p>
</blockquote>
<p><strong>我们的方法</strong>。在本文中，我们提出了一种检测漂移样本的新方法，并结合一种解释检测决策的新方法。我们共同构建了一个称为CADE的系统，它是“用于漂移检测和解释的对比自动编码器
(“<strong>Contrastive Autoencoder for Drifting detection and
Explanation</strong>)”的缩写关键的挑战是<strong>推导一个有效的距离函数来衡量样本的相异性</strong>。我们没有随意选取距离函数，而是利用对比学习的思想[29]，根据现有的标签，从现有的训练数据中学习距离函数。给定原始分类器的训练数据（多个类别），我们将训练样本映射到低维潜在空间。映射函数通过对比样本来学习，以扩大不同类样本之间的距离，同时减少同一类样本之间的距离。<strong>我们证明了在潜在空间中得到的距离函数可以有效地检测和排序漂移样本。</strong></p>
<p>评价我们使用两个数据集评估我们的方法，包括<strong>Android恶意软件数据集[7]和2018年发布的入侵检测数据集[57]</strong>。我们的评估表明，我们的漂移检测方法具有很高的准确性，F1平均得分为0.96或更高，优于各种基线和现有方法。我们的分析还表明，使用对比学习可以减少检测决策的模糊性。对于解释模型，我们进行了定量和定性评估。案例研究还表明，所选特征与漂移样本的语义行为相匹配。</p>
<p>此外，我们还与一家安全公司的合作伙伴合作，在其内部恶意软件数据库上测试CADE。作为初步测试，我们从395个家庭中获得了2019年8月至2020年2月出现的20613个Windows
PE恶意软件样本。这使我们能够在不同的环境中测试更多恶意软件系列的系统性能。结果很有希望。<font color="red"><strong>例如，CADE在10个家庭中进行训练并在160个以前未见过的家庭中进行测试时，F1成绩达到0.95分。这使得人们有兴趣在生产系统中进一步测试和部署CADE。</strong>
</font></p>
<h4><span id="贡献">贡献：</span></h4>
<p>本文有三个主要贡献。</p>
<ul>
<li>我们提出CADE来补充现有的基于监督学习的安全应用程序，以对抗概念漂移。提出了<strong>一种基于对比表征学习的漂移样本检测方法</strong>。</li>
<li>我们说明了监督解释方法在解释异常样本方面的局限性，并<strong>介绍了一种基于距离的解释方法</strong>。</li>
<li>我们通过两个应用对所提出的方法进行了广泛的评估。我们与一家安保公司的初步测试表明，CADE是有效的。我们在此处发布了CADE代码1，以支持未来的研究。</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>恶意软件检测（14）MALWARE综述</title>
    <url>/posts/2GBZRTM/</url>
    <content><![CDATA[<h1><span id="malware">MALWARE</span></h1>
<h2><span id="1-survey-overview">1. Survey Overview</span></h2>
<blockquote>
<p>Period :2014-2021</p>
</blockquote>
<ul>
<li><h5><span id="platform">Platform</span></h5>
<ul>
<li>Windows [13,32]</li>
<li>Android [1-3,11,14,16,18,23,25,33,35-37,40]</li>
<li>Linux</li>
</ul></li>
<li><h5><span id="direction">Direction</span></h5>
<ul>
<li>Malware features from various aspects [1,9,24,28,31,40]</li>
<li>Malware propagation(传播) [2,25]</li>
<li>System mechanisms or services against malware [3,37]</li>
<li>Malware behaviors [5,15]
<ul>
<li>Obfuscation [8,37]</li>
<li>Packing [8]</li>
<li>Stealth technologies [3,6]</li>
<li>Hook</li>
<li>Evasion from dynamic analysis [10,17,20,31,62]</li>
</ul></li>
<li>Dataset challenges, such as aging problem [21,23,41,51]</li>
<li>Performance metrics[14,23]</li>
<li>Specific malware：such as IoT malware[25,26,39], fileless[30] and
PDF malware[43,54]</li>
<li>Visualization [15]</li>
<li>Graph representation [22]</li>
<li><strong>Detection Methods</strong> [3-4,8,9,11,12,14,16,19,31,33,36]
<ul>
<li>ML based techniques [13,18,21,29,38,40]</li>
<li>DL based techniques [22,29,35]</li>
</ul></li>
<li><strong>APT</strong>(Advanced Persistent Threats) [20]</li>
<li><strong>Adversarial malware example generation</strong> [27,32]</li>
<li>ML/DL flaws [7,28]</li>
<li>ML/DL interpretability [34]</li>
</ul></li>
</ul>
<h2><span id="2-android-malware-detection">2. Android Malware detection</span></h2>
<h3><span id="21-behavior-detection-6364">2.1 Behavior detection [63,64]</span></h3>
<table>
<colgroup>
<col style="width: 27%">
<col style="width: 1%">
<col style="width: 26%">
<col style="width: 21%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Malton:Towards On-Device Non-Invasive Mobile Malware Analysis for
ART</td>
<td>2017</td>
<td>Toprovide a comprehensive view of malware’s behaviors</td>
<td>Detectingeffectively</td>
<td>multi-layermonitoring &amp; information flow tracking</td>
</tr>
<tr class="even">
<td>CopperDroid:Automatic Reconstruction of Android Malware
Behaviors</td>
<td>2015</td>
<td>Toidentify OS- and high-level Android-specific behaviors.</td>
<td>Toreconstruct the behaviors of Android malware</td>
<td>VMI-baseddynamic analysis</td>
</tr>
</tbody>
</table>
<h3><span id="22-signature-based-6566">2.2 Signature based [65,66]</span></h3>
<table>
<colgroup>
<col style="width: 27%">
<col style="width: 1%">
<col style="width: 20%">
<col style="width: 23%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>EnMobile: Entity-based Characterization and Analysis of Mobile</td>
<td>2018</td>
<td>Tocharacaterize malware comprehensively</td>
<td>Detectingeffectively</td>
<td>entity-based characterization and static analysis; signature based
approach</td>
</tr>
<tr class="even">
<td>Screening smartphone applications using malware family
signatures</td>
<td>2015</td>
<td>Toimprove the robustness of signature matching</td>
<td>Toautomaticly extract family signature and matching</td>
<td>family signature</td>
</tr>
</tbody>
</table>
<h3><span id="23-rule-based6768">2.3 Rule based[67,68]</span></h3>
<table>
<colgroup>
<col style="width: 37%">
<col style="width: 2%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Toward a more dependable hybrid analysis of android malware using
aspect-oriented programming</td>
<td>2018</td>
<td>None.</td>
<td>Detectingeffectively</td>
<td>dataflowanalysis, detection of resource abuse;rule based</td>
</tr>
<tr class="even">
<td>DroidNative: Automating and optimizing detection of Android native
code malware variants</td>
<td>2017</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>specific control flow patterns;rule based</td>
</tr>
</tbody>
</table>
<h3><span id="24-similarity-based">2.4 Similarity based</span></h3>
<h4><span id="241-model-similarity69-73">2.4.1 Model similarity[69-73]</span></h4>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 2%">
<col style="width: 21%">
<col style="width: 11%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>An HMM and structural entropy based detector for Android malware: An
empirical study</td>
<td>2016</td>
<td>Todefeat hiding</td>
<td>Detectingeffectively</td>
<td>HiddenMarkov Model, structural entropy.</td>
</tr>
<tr class="even">
<td>Scalable and robust unsupervised android malware fingerprinting
using community-based network partitioning</td>
<td>2020</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>maliciouscommunity</td>
</tr>
<tr class="odd">
<td>On the use of artificial malicious patterns for android malware
detection</td>
<td>2020</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>malwarepatterns; Genetic Algorithm (GA); Apriori algorithm</td>
</tr>
<tr class="even">
<td>Andro-Dumpsys: Anti-malware system based on the similarity of
malware creator and malware centric information</td>
<td>2016</td>
<td>Todefeat packing, dynamic loading etc.</td>
<td>Detectingeffectively</td>
<td>similarity matching of malware creator-centric</td>
</tr>
<tr class="odd">
<td>Bayesian Active Malware Analysis</td>
<td>2020</td>
<td>None.</td>
<td>Detectingeffectively</td>
<td>the Markov chain models</td>
</tr>
</tbody>
</table>
<h4><span id="242-graph-similarity74-79">2.4.2 Graph similarity[74-79]</span></h4>
<table>
<colgroup>
<col style="width: 30%">
<col style="width: 2%">
<col style="width: 23%">
<col style="width: 12%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PermPair: Android Malware Detection Using Permission Pairs</td>
<td>2020</td>
<td>Tomake use of permission information</td>
<td>Todetect Android malware</td>
<td>The comparasion of the graph of permission pairs.</td>
</tr>
<tr class="even">
<td>Apposcopy: Semantics-Based Detection of Android Malware through
Static Analysis</td>
<td>2014</td>
<td>Toimprove signature based methods</td>
<td>Detectingeffectively</td>
<td>combination of static taint analysis and program representation
called Inter-Component Call Graph</td>
</tr>
<tr class="odd">
<td>Profiling user-trigger dependence for Android malware detection</td>
<td>2015</td>
<td>Tocapture stealthily launch operation</td>
<td>Detectingeffectively</td>
<td>Graphcomparision</td>
</tr>
<tr class="even">
<td>Identifying Android Malware Using Network-Based Approaches</td>
<td>2019</td>
<td>Tomake use of network information</td>
<td>Detectingeffectively</td>
<td>aweighted network to compare closeness</td>
</tr>
<tr class="odd">
<td>Cypider: Building Community-Based Cyber-Defense Infrastructure for
Android Malware Detection</td>
<td>2016</td>
<td>Todeal with endless new malware</td>
<td>Detectingeffectively</td>
<td>scalablesimilarity network infrastructure;malicious community</td>
</tr>
<tr class="even">
<td>Semantics-Aware Android Malware Classification Using Weighted
Contextual API Dependency Graphs</td>
<td>2014</td>
<td>Tocharacaterize malware from program semantics</td>
<td>Detectingeffectively</td>
<td>a weighted contextual API dependency graph as program
semantics;graphsimilarity metrics</td>
</tr>
</tbody>
</table>
<h3><span id="25-ml-based-6080-101">2.5 ML based [60,80-101]</span></h3>
<table>
<colgroup>
<col style="width: 24%">
<col style="width: 1%">
<col style="width: 24%">
<col style="width: 24%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>MAMADROID:Detecting Android Malware by Building Markov
Chains of Behavioral Models</strong></td>
<td>2017</td>
<td>Todesign robust malware mitigation techniques</td>
<td>Constructinga classifier</td>
<td>BuildingMarkov Chains of Behavioral Models;Random Forests , Nearest
Neighbor (1-NN) ,3-Nearest Neighbor (3-NN) ,and Support Vector Machines
(SVM)</td>
</tr>
<tr class="even">
<td><strong>Drebin:Effective and Explainable Detection of Android
Malware in Your Pocket</strong></td>
<td>2014</td>
<td>Tomitigate the influence on limited resources in Android
platform</td>
<td>To propose a lightweight method to detect malware at run-time</td>
<td>Staticanalysis and SVM</td>
</tr>
<tr class="odd">
<td>MakeEvasion Harder: An Intelligent Android Malware Detection
System</td>
<td>2018</td>
<td>Todetect evolving Android malware</td>
<td>Higherdetection rate</td>
<td>APIcalls and higher-level semantics; SVM</td>
</tr>
<tr class="even">
<td>UsingLoops For Malware Classification Resilient to Feature-unaware
Perturbations</td>
<td>2018</td>
<td>Tosolve feature-unaware perturbation</td>
<td>Todetect malware resilient to feature-unaware perturbation</td>
<td>Looplocating and random forest</td>
</tr>
<tr class="odd">
<td>SemanticModelling of Android Malware for Effective Malware
Comprehension, Detection,and Classification</td>
<td>2016</td>
<td>Tomake use of semantic information</td>
<td>Todetect Android malware</td>
<td>Semanticmodel; Random forest</td>
</tr>
<tr class="even">
<td>Detecting Android Malware Leveraging Text Semantics of Network
Flows</td>
<td>2018</td>
<td>Tomake use of network information</td>
<td>Todetect Android malware</td>
<td>Usingthe text semantics of network traffic; SVM</td>
</tr>
<tr class="odd">
<td>Improving Accuracy of Android Malware Detection with Lightweight
Contextual Awareness</td>
<td>2018</td>
<td>Toreduce redundant metadata in modeling</td>
<td>ImprovingAccuracy of Android Malware Detection</td>
<td>KNN;RF;MLP</td>
</tr>
<tr class="even">
<td>MalScan: Fast Market-Wide Mobile Malware Scanning by Social-Network
Centrality Analysis</td>
<td>2019</td>
<td>Toreduce the cost of semantic analysis</td>
<td>To propose a lightweight method to detect malware</td>
<td>social-network-basedcentrality analysis; kNN and random forest</td>
</tr>
<tr class="odd">
<td>PIndroid: A novel Android malware detection system using ensemble
learning methods</td>
<td>2017</td>
<td>Tofight against covert technique of malware</td>
<td>Detectingeffectively</td>
<td>Permissionsand Intents based framework supplemented with Ensemble
methods:Nave Bayesian,Decision Tree, Decision Table, Random Forest,
Sequential Minimal Optimization and Multi Lateral Perceptron(MLP)</td>
</tr>
<tr class="even">
<td>A pragmatic android malware detection procedure</td>
<td>2017</td>
<td>Todesign a new ML model</td>
<td>Detectingeffectively</td>
<td>Atomic Naive Bayes classifiers used as inputs for the Support Vector
Machine ensemble.</td>
</tr>
<tr class="odd">
<td>ICCDetector: ICC-Based Malware Detection on Android</td>
<td>2016</td>
<td>Tocapture communication among components or cross boundaries to
supplymentfeatures</td>
<td>Detectingeffectively</td>
<td>SVM</td>
</tr>
<tr class="even">
<td>A Probabilistic Discriminative Model for Android Malware Detection
with Decompiled Source Code</td>
<td>2015</td>
<td>None.</td>
<td>Detectingeffectively</td>
<td>the 2-class Naive Bayes with Prior (2-PNB) and a discriminative
model,the regularized logistic regression</td>
</tr>
<tr class="odd">
<td>DroidCat: Effective Android Malware Detection and Categorization via
App-Level Profiling</td>
<td>2019</td>
<td>Tofight against systemcall obfuscation</td>
<td>Detectingeffectively</td>
<td>Dynamicanalysis based on method calls and inter-component
communication; RandomForest</td>
</tr>
<tr class="even">
<td>MADAM: Effective and Efficient Behavior-based Android Malware
Detection and Prevention</td>
<td>2018</td>
<td>None.</td>
<td>Detectingeffectively</td>
<td>KNN</td>
</tr>
<tr class="odd">
<td>Android Malware Detection via (Somewhat) Robust Irreversible Feature
Transformations</td>
<td>2020</td>
<td>Toavoid ML classifier evading</td>
<td>Transferingfeatures to a new feature domain</td>
<td>Classifiers used:(1) Bernoulli Naive Bayes, (2) Random Forest, (3)
NearestNeighbors, (4) Logistic Regression, (5) Gaussian Naive Bayes, (6)
AdaBoost Classifier, (7) Gradient Boosting Decision Tree, (8) XGB
Classifier and (9)SVM.</td>
</tr>
<tr class="even">
<td>Leveraging ontologies and machine-learning techniques for malware
analysis into Android permissions ecosystems</td>
<td>2018</td>
<td>None.</td>
<td>Detectingeffectively</td>
<td>ontology-basedframework;random forest</td>
</tr>
<tr class="odd">
<td>Lightweight, Obfuscation-Resilient Detection and Family
Identification of Android Malware</td>
<td>2018</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>familyidentification;linear SVM</td>
</tr>
<tr class="even">
<td>A multi-view context-aware approach to Android malware detection and
malicious code localization</td>
<td>2018</td>
<td>To characaterize malware comprehensively</td>
<td>Detectingeffectively</td>
<td>multipleviews of apps;SVM</td>
</tr>
<tr class="odd">
<td>DroidFusion: A Novel Multilevel Classifier Fusion Approach for
Android Malware Detection</td>
<td>2019</td>
<td>Toimprove classifier</td>
<td>Detectingeffectively</td>
<td>CLASSIFIER FUSION:J48, REPTree, voted perceptron, and random
tree</td>
</tr>
<tr class="even">
<td>DL-Droid: Deep learning based android malware detection using real
devices</td>
<td>2020</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>input generation;MLP</td>
</tr>
<tr class="odd">
<td>JOWMDroid: Android malware detection based on feature weighting with
joint optimization of weight-mapping and classifier parameters</td>
<td>2021</td>
<td>Tocharacaterize malware from feature importance</td>
<td>Detectingeffectively</td>
<td>featureweighting with the joint optimization of weight-mapping;SVM,
LR, MLP</td>
</tr>
<tr class="even">
<td>Towards using unstructured user input request for malware
detection</td>
<td>2020</td>
<td>Todefeat privacy analysis evading</td>
<td>Detectingeffectively</td>
<td>decision tree</td>
</tr>
</tbody>
</table>
<h3><span id="26-dl-based-102-109">2.6 DL based [102-109]</span></h3>
<table>
<colgroup>
<col style="width: 32%">
<col style="width: 2%">
<col style="width: 32%">
<col style="width: 11%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Toward s an interpretable deep learning model for mobile malware
detection and family identification</td>
<td>2021</td>
<td>Topropose a interpretable DL model</td>
<td>Detectingreasonablely</td>
<td>DL:Grad-CAM</td>
</tr>
<tr class="even">
<td>AMalNet: A deep learning framework based on graph convolutional
networks for malware detection</td>
<td>2020</td>
<td>Tohave a lower cost</td>
<td>Detectingeffectively</td>
<td>DL:GCNsand IndRNN</td>
</tr>
<tr class="odd">
<td>Disentangled Representation Learning in Heterogeneous Information
Network for Large-scale Android Malware Detection in the COVID-19 Era
and Beyond</td>
<td>2021</td>
<td>Tosolve the problem that society relys on the complex
cyberspace</td>
<td>Detectingeffectively</td>
<td>heterogeneousinformation network (HIN);DNN</td>
</tr>
<tr class="even">
<td>A Multimodal Deep Learning Method for Android Malware Detection
Using Various Features</td>
<td>2019</td>
<td>Tocharacaterize malware comprehensively</td>
<td>Detectingeffectively</td>
<td>multimodaldeep learning method;DNN</td>
</tr>
<tr class="odd">
<td>Android Fragmentation in Malware Detection</td>
<td>2019</td>
<td>Todeal with multiple Android version</td>
<td>Detectingeffectively</td>
<td>Deep Neural Network</td>
</tr>
<tr class="even">
<td>An Image-inspired and CNN-based Android Malware Detection
Approach</td>
<td>2019</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>CNN</td>
</tr>
<tr class="odd">
<td>A Performance-Sensitive Malware Detection System Using Deep Learning
on Mobile Devices</td>
<td>2021</td>
<td>Toreduce time cost of download and upload</td>
<td>Detectingfastly</td>
<td>customized DNN</td>
</tr>
<tr class="even">
<td>Byte-level malware classification based on markov images and deep
learning</td>
<td>2020</td>
<td>Toimprove the accuracy of gray image based methods</td>
<td>Detectingeffectively</td>
<td>deep convolutional neural network</td>
</tr>
</tbody>
</table>
<h2><span id="3-windows-malware-detection">3 Windows Malware detection</span></h2>
<h3><span id="31-behavior-detection-110111">3.1 Behavior detection [110,111]</span></h3>
<table style="width:100%;">
<colgroup>
<col style="width: 68%">
<col style="width: 4%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>API Chaser: Anti-analysis Resistant Malware Analyzer</td>
<td>2013</td>
<td>API call feature capture</td>
</tr>
<tr class="even">
<td>MalViz: An Interactive Visualization Tool for Tracing Malware</td>
<td>2018</td>
<td>Behavior visualization</td>
</tr>
</tbody>
</table>
<h3><span id="32-signature-based-112">3.2 Signature based [112]</span></h3>
<table>
<colgroup>
<col style="width: 76%">
<col style="width: 5%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CloudEyes: Cloud-based malware detection with reversible sketch for
resource-constrained internet of things (IoT) devices</td>
<td>2017</td>
<td>Based on cloud</td>
</tr>
</tbody>
</table>
<h3><span id="33-rule-based113">3.3 Rule based[113]</span></h3>
<table>
<colgroup>
<col style="width: 77%">
<col style="width: 5%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A fast malware detection algorithm based on objective-oriented
association mining</td>
<td>2013</td>
<td>API selection</td>
</tr>
</tbody>
</table>
<h3><span id="34-similarity-based">3.4 Similarity based</span></h3>
<h4><span id="341-model-similarity114-122">3.4.1 Model similarity[114-122]</span></h4>
<table>
<colgroup>
<col style="width: 48%">
<col style="width: 3%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PoMMaDe: Pushdown Model-checking for Malware Detection</td>
<td>2013</td>
<td>model checking</td>
</tr>
<tr class="even">
<td>Growing Grapes in Your Computer to Defend Against Malware</td>
<td>2014</td>
<td>clustering and template matching</td>
</tr>
<tr class="odd">
<td>Hypervisor-based malware protection with AccessMiner</td>
<td>2015</td>
<td>system-centric behavioral detector</td>
</tr>
<tr class="even">
<td>Probabilistic Inference on Integrity for Access Behavior Based
Malware Detection</td>
<td>2015</td>
<td>probabilistic model of integrity</td>
</tr>
<tr class="odd">
<td>Probabilistic analysis of dynamic malware traces</td>
<td>2018</td>
<td>1.Features of system interaction 2. interpretability</td>
</tr>
<tr class="even">
<td>A malware detection method based on family behavior graph</td>
<td>2018</td>
<td>common behavior graph</td>
</tr>
<tr class="odd">
<td>Malware classification using self organising feature maps and
machine activity data</td>
<td>2018</td>
<td>1.The improvement of ML. to reduce over-fitting 2. Self Organizing
Feature Maps</td>
</tr>
<tr class="even">
<td>Volatile memory analysis using the MinHash method for efficient and
secured detection of malware in private cloud</td>
<td>2019</td>
<td>Based on memory features</td>
</tr>
<tr class="odd">
<td>A dynamic Windows malware detection and prediction method based on
contextual understanding of API call sequence</td>
<td>2020</td>
<td>1.Contextual relationship between API call features 2.
Marcovchain</td>
</tr>
</tbody>
</table>
<h4><span id="342-graph-similarity123-127">3.4.2 Graph similarity[123-127]</span></h4>
<table>
<colgroup>
<col style="width: 55%">
<col style="width: 3%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Deriving common malware behavior through graph clustering</td>
<td>2013</td>
<td>common behavior graph</td>
</tr>
<tr class="even">
<td>Enhancing the detection of metamorphic malware using call
graphs</td>
<td>2014</td>
<td>API call graph matching</td>
</tr>
<tr class="odd">
<td>Minimal contrast frequent pattern mining for malware detection</td>
<td>2016</td>
<td>Graph matching</td>
</tr>
<tr class="even">
<td><strong>Heterogeneous Graph Matching Networks for Unknown Malware
Detection</strong></td>
<td>2019</td>
<td>Graph matching similarity of benign software</td>
</tr>
<tr class="odd">
<td>Random CapsNet for est model for imbalanced malware type
classification task</td>
<td>2021</td>
<td>The improvement of the Model</td>
</tr>
</tbody>
</table>
<h3><span id="35-ml-based-128-143">3.5 ML based [128-143]</span></h3>
<table>
<colgroup>
<col style="width: 46%">
<col style="width: 6%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A Scalable Approach for Malware Detection through Bounded Feature
Space Behavior Modeling</td>
<td>2013</td>
<td>Scalable feature space</td>
</tr>
<tr class="even">
<td>SigMal: A Static Signal Processing Based Malware Triage</td>
<td>2013</td>
<td>noise-resistant similarity signatures</td>
</tr>
<tr class="odd">
<td>Unsupervised Anomaly-Based Malware Detection Using Hardware
Features</td>
<td>2014</td>
<td>hardware supported lower-level features</td>
</tr>
<tr class="even">
<td>Control flow-based opcode behavior analysis for Malware
detection</td>
<td>2014</td>
<td>Based on control flow method features</td>
</tr>
<tr class="odd">
<td>Employing Program Semantics for Malware Detection</td>
<td>20152021</td>
<td>Extracting information-rich call sequence based on AEPThe
improvement of the Model</td>
</tr>
<tr class="even">
<td>AMAL: High-fidelity, behavior-based automated malware analysis and
classification</td>
<td>2015</td>
<td>Based on behavior analysis</td>
</tr>
<tr class="odd">
<td>Optimized Invariant Representation of Network Traffic for Detecting
Unseen Malware Variants</td>
<td>2016</td>
<td>Network features</td>
</tr>
<tr class="even">
<td>DYNAMINER: Leveraging Offline Infection Analytics for On-the-Wire
Malware Detection</td>
<td>2017</td>
<td>Network features</td>
</tr>
<tr class="odd">
<td>Security importance assessment for system objects and malware
detection</td>
<td>2017</td>
<td>Based on importance of system objects</td>
</tr>
<tr class="even">
<td>From big data to knowledge: A spatiotemporal approach to malware
detection</td>
<td>2018</td>
<td>cloud based security service features</td>
</tr>
<tr class="odd">
<td>From big data to knowledge: A spatiotemporal approach to malware
detection</td>
<td>2018</td>
<td>cloud based security service features</td>
</tr>
<tr class="even">
<td>MalDAE: Detecting and explaining malware based on correlation and
fusion of static and dynamic characteristics</td>
<td>2019</td>
<td>fusion of static and dynamic API sequence features</td>
</tr>
<tr class="odd">
<td>Leveraging Compression-Based Graph Mining for Behavior-Based Malware
Detection</td>
<td>2019</td>
<td>Based on data flow graph</td>
</tr>
<tr class="even">
<td>Advanced Windows Methods on Malware Detection and
Classification</td>
<td>2020</td>
<td>API based Features extraction.</td>
</tr>
<tr class="odd">
<td>Sub-curve HMM: A malware detection approach based on partial
analysis of API call sequences</td>
<td>2020</td>
<td>1.Subset of API call feature 2. HMM</td>
</tr>
<tr class="even">
<td>Multiclass malware classification via first- and second-order
texture statistics</td>
<td>2020</td>
<td>visualization</td>
</tr>
<tr class="odd">
<td>Catch them alive: A malware detection approach through memory
forensics, manifoldlearning and computer vision</td>
<td>2021</td>
<td>Visualization</td>
</tr>
</tbody>
</table>
<h3><span id="36-dl-based-144-156">3.6 DL based [144-156]</span></h3>
<table>
<colgroup>
<col style="width: 57%">
<col style="width: 3%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Auto-detection of sophisticated malware using lazy-binding control
flow graph and deep learning</td>
<td>2018</td>
<td>1.The improvement of CFG 2. Visualizaiton</td>
</tr>
<tr class="even">
<td>Malware identification using visualization images and deep
learning</td>
<td>2018</td>
<td>1.SimHash of features 2. Visualization</td>
</tr>
<tr class="odd">
<td>Classification of Malware by Using Structural Entropy on
Convolutional Neural Networks</td>
<td>2018</td>
<td>visual similarity</td>
</tr>
<tr class="even">
<td>Classifying Malware Represented as Control Flow Graphs using Deep
Graph Convolutional Neural Network</td>
<td>2019</td>
<td>The improvement of CFG</td>
</tr>
<tr class="odd">
<td><strong>Neurlux: Dynamic Malware Analysis Without Feature
Engineering</strong></td>
<td>2019</td>
<td>Based on dynamic analysis reports</td>
</tr>
<tr class="even">
<td>A feature-hybrid malware variants detection using CNN based opcode
embedding and BPNN based API embedding</td>
<td>2019</td>
<td>Hybrid features</td>
</tr>
<tr class="odd">
<td>Effective analysis of malware detection in cloud computing</td>
<td>2019</td>
<td>The improvement of the DL.</td>
</tr>
<tr class="even">
<td>Recurrent neural network for detecting malware</td>
<td>2020</td>
<td>The improvement of RNN</td>
</tr>
<tr class="odd">
<td><strong>Dynamic Malware Analysis with Feature Engineering and
Feature Learning</strong></td>
<td>2020</td>
<td>Feature hashing to encode API call info.</td>
</tr>
<tr class="even">
<td>An improved two-hidden-layer extreme learning machine for malware
hunting</td>
<td>2020</td>
<td>Improvement of the DL.</td>
</tr>
<tr class="odd">
<td>HYDRA: A multimodal deep learning framework for malware
classification</td>
<td>2020</td>
<td>Hybrid features</td>
</tr>
<tr class="even">
<td>A novel method for malware detection on ML-based visualization
technique</td>
<td>2020</td>
<td>visualization</td>
</tr>
<tr class="odd">
<td>Image-Based malware classification using ensemble of CNN
architectures (IMCEC)</td>
<td>2020</td>
<td>visualization</td>
</tr>
</tbody>
</table>
<h2><span id="4-mldl-flaws-overview">4. ML/DL flaws Overview</span></h2>
<ul>
<li>Ensemble classifier evasion [42]</li>
<li>Performance degradation [42,46,53,54]</li>
<li>Adversarial example generation [43,44,45,48,55,56,57,58]</li>
<li>Poisoning Attack [47]</li>
<li>Feature weights [49]</li>
<li>Cost analysis [50]</li>
<li>ML bias from dataset [51]</li>
<li>Influence of packing [52]</li>
<li>Methods reproduction [59]</li>
</ul>
<h2><span id="5-references">5. References</span></h2>
<ol type="1">
<li><p>2014 A Survey of Android Malware Characterisitics and Mitigation
Techniques</p></li>
<li><p>2014 Smartphone Malware and Its Propagation Modeling:A
Survey</p></li>
<li><p>2015 Android Security: A Survey of Issues, Malware Penetration,
and Defenses</p></li>
<li><p>2014 Evolution and Detection of Polymorphic and Metamorphic
Malwares: A Survey</p></li>
<li><p>2015 Kernel Malware Core Implementation: A Survey</p></li>
<li><p>2016 A Survey of Stealth Malware Attacks, Mitigation Measures,
and Steps Toward Autonomous Open World Solutions</p></li>
<li><p>2016 On the Security of Machine Learning in Malware C&amp;C
Detection: A Survey</p></li>
<li><p>2017 Malware Methodologies and Its Future: A Survey</p></li>
<li><p>2017 A Survey on Malware Detection Using Data Mining
Techniques</p></li>
<li><p>2018 Malware Dynamic Analysis Evasion Techniques: A
Survey</p></li>
<li><p>2018 Android Malware Detection: A Survey</p></li>
<li><p>2018 A Survey on Metamorphic Malware Detection based on Hidden
Markov Model</p></li>
<li><p>2018 Machine Learning Aided Static Malware Analysis: A Survey and
Tutorial</p></li>
<li><p>2018 A survey on dynamic mobile malware detection</p></li>
<li><p>2018 A survey of malware behavior description and
analysis</p></li>
<li><p>2019 A Survey on Android Malware Detection Techniques Using
Machine Learning Algorithms</p></li>
<li><p>2019 Dynamic Malware Analysis in the Modern Era—A State of the
Art Survey</p></li>
<li><p>2019 Data-Driven Android Malware Intelligence: A Survey</p></li>
<li><p>2019 A survey of zero-day malware attacks and itsdetection
methodology</p></li>
<li><p>2019 A Survey on malware analysis and mitigation
techniques</p></li>
<li><p><strong>2019 Survey of machine learning techniques for malware
analysis</strong></p></li>
<li><p>2020 Deep Learning and Open Set Malware Classification: A
Survey</p></li>
<li><p>2020 A Comprehensive Survey on Machine Learning Techniques for
Android Malware Detection</p></li>
<li><p>2015 A Survey on Mining Program-Graph Features for Malware
Analysis</p></li>
<li><p>2020 Stochastic Modeling of IoT Botnet Spread: A Short Survey on
Mobile Malware Spread Modeling</p></li>
<li><p>2020 A survey of IoT malware and detection methods based on
static features</p></li>
<li><p>2020 A survey on practical adversarial examples for malware
classifiers</p></li>
<li><p>2020 A Survey of Machine Learning Methods and Challenges for
Windows Malware Classification</p></li>
<li><p>2020 A Survey on Malware Detection with Deep Learning</p></li>
<li><p>2020 An emerging threat Fileless malware: a survey and research
challenges</p></li>
<li><p>2021 Malware classification and composition analysis: A survey of
recent developments</p></li>
<li><p><strong>2021 Adversarial EXEmples: A Survey and Experimental
Evaluation of Practical Attacks on Machine Learning for Windows Malware
Detection</strong></p></li>
<li><p>2020 A Survey on Mobile Malware Detection Techniques</p></li>
<li><p>2021 Towards interpreting ML-based automated malware detection
models: a survey</p></li>
<li><p>2021 A Survey of Android Malware Detection with Deep Neural
Models</p></li>
<li><p>2021 A survey of malware detection in Android apps:
Recommendations and perspectives for future research</p></li>
<li><p>2021 A survey of android application and malware
hardening</p></li>
<li><p>2021 A survey on machine learning-based malware detection in
executable files</p></li>
<li><p>2021 The evolution of IoT Malwares, from 2008 to 2019: Survey,
taxonomy, process simulator and perspectives</p></li>
<li><p>2021 A Survey of Android Malware Static Detection Technology
Based on Machine Learning</p></li>
<li><p>2016 Empirical assessment of machine learning-based malware
detectors for Android Measuring the gap between in-the-lab and
in-the-wild validation scenarios</p></li>
<li><p>2016 When a Tree Falls: Using Diversity in Ensemble Classifiers
to Identify Evasion in Malware Detectors</p></li>
<li><p><strong>2016 Automatically Evading Classifiers A Case Study on
PDF Malware Classifiers</strong></p></li>
<li><p>2017 SecureDroid: Enhancing Security of Machine Learning-based
Detection against Adversarial Android Malware Attacks</p></li>
<li><p>2017 How to defend against adversarial attack</p></li>
<li><p><strong>2017 Transcend: Detecting Concept Drift in Malware
Classification Models</strong></p></li>
<li><p><strong>2018 Automated poisoning attacks and defenses in malware
detection systems: An adversarial machine learning
approach</strong></p></li>
<li><p><strong>2018 Generic Black-Box End-to-End Attack Against State of
the Art API Call Based Malware Classifiers</strong></p></li>
<li><p><strong>2019 Yes, Machine Learning Can Be More Secure! A Case
Study on Android Malware Detection</strong></p></li>
<li><p>2019 A cost analysis of machine learning using dynamic runtime
opcodes for malware detection</p></li>
<li><p><strong>2019 TESSERACT: Eliminating Experimental Bias in Malware
Classification across Space and Time</strong></p></li>
<li><p>2020 When Malware is Packin’ Heat; Limits of Machine Learning
Classifiers Based on Static Analysis Features</p></li>
<li><p>2020 Assessing and Improving Malware Detection Sustainability
through App Evolution Studies</p></li>
<li><p>2020 On Training Robust PDF Malware Classifiers</p></li>
<li><p>2020 Adversarial Deep Ensemble: Evasion Attacks and Defenses for
Malware Detection</p></li>
<li><p>2020 Intriguing Properties of Adversarial ML Attacks in the
Problem Space Fabio</p></li>
<li><p>2020 Query-Efficient Black-Box Attack Against Sequence-Based
Malware Classifiers</p></li>
<li><p>2020 Enhancing State-of-the-art Classifiers with API Semantics to
Detect Evolved Android Malware</p></li>
<li><p>2021 Lessons Learnt on Reproducibility in Machine Learning Based
Android Malware Detection</p></li>
<li><p>2016 Semantics-Based Online Malware Detection: Towards Efficient
Real-Time Protection Against Malware</p></li>
<li><p>2018 Understanding Linux Malware</p></li>
<li><p>2017 Droid-AntiRM: Taming Control Flow Anti-analysis to Support
Automated Dynamic Analysis of Android Malware</p></li>
<li><p>2017 Malton: Towards On-Device Non-Invasive Mobile Malware
Analysis for ART</p></li>
<li><p>2015 CopperDroid: Automatic Reconstruction of Android Malware
Behaviors</p></li>
<li><p>2018 EnMobile: Entity-based Characterization and Analysis of
Mobile</p></li>
<li><p>2015 Screening smartphone applications using malware family
signatures</p></li>
<li><p>2018 Toward a more dependable hybrid analysis of android malware
using aspect-oriented programming</p></li>
<li><p>2017 DroidNative: Automating and optimizing detection of Android
native code malware variants</p></li>
<li><p>2016 An HMM and structural entropy based detector for Android
malware: An empirical study</p></li>
<li><p>2020 Scalable and robust unsupervised android malware
fingerprinting using community-based network partitioning</p></li>
<li><p>2020 On the use of artificial malicious patterns for android
malware detection</p></li>
<li><p>2016 Andro-Dumpsys: Anti-malware system based on the similarity
of malware creator and malware centric information</p></li>
<li><p>2020 Bayesian Active Malware Analysis</p></li>
<li><p>2020 PermPair: Android Malware Detection Using Permission
Pairs</p></li>
<li><p>2014 Apposcopy: Semantics-Based Detection of Android Malware
through Static Analysis</p></li>
<li><p>2015 Profiling user-trigger dependence for Android malware
detection</p></li>
<li><p>2019 Identifying Android Malware Using Network-Based
Approaches</p></li>
<li><p>2016 Cypider: Building Community-Based Cyber-Defense
Infrastructure for Android Malware Detection</p></li>
<li><p>2014 Semantics-Aware Android Malware Classification Using
Weighted Contextual API Dependency Graphs</p></li>
<li><p>2017 MAMADROID: Detecting Android Malware by Building Markov
Chains of Behavioral Models</p></li>
<li><p>2014 Drebin: Effective and Explainable Detection of Android
Malware in Your Pocket</p></li>
<li><p>2018 Make Evasion Harder: An Intelligent Android Malware
Detection System</p></li>
<li><p>2018 Using Loops For Malware Classification Resilient to
Feature-unaware Perturbations</p></li>
<li><p>2016 Semantic Modelling of Android Malware for Effective Malware
Comprehension, Detection, and Classification</p></li>
<li><p>2018 Detecting Android Malware Leveraging Text Semantics of
Network Flows</p></li>
<li><p>2018 Improving Accuracy of Android Malware Detection with
Lightweight Contextual Awareness</p></li>
<li><p>2019 MalScan: Fast Market-Wide Mobile Malware Scanning by
Social-Network Centrality Analysis</p></li>
<li><p>2017 PIndroid: A novel Android malware detection system using
ensemble learning methods</p></li>
<li><p>2017 A pragmatic android malware detection procedure</p></li>
<li><p>2016 ICCDetector: ICC-Based Malware Detection on Android</p></li>
<li><p>2015 A Probabilistic Discriminative Model for Android Malware
Detection with Decompiled Source Code</p></li>
<li><p>2019 DroidCat: Effective Android Malware Detection and
Categorization via App-Level Profiling</p></li>
<li><p>2018 MADAM: Effective and Efficient Behavior-based Android
Malware Detection and Prevention</p></li>
<li><p>2020 Android Malware Detection via (Somewhat) Robust Irreversible
Feature Transformations</p></li>
<li><p>2018 Leveraging ontologies and machine-learning techniques for
malware analysis into Android permissions ecosystems</p></li>
<li><p>2018 Lightweight, Obfuscation-Resilient Detection and Family
Identification of Android Malware</p></li>
<li><p>2018 A multi-view context-aware approach to Android malware
detection and malicious code localization</p></li>
<li><p>2019 DroidFusion: A Novel Multilevel Classifier Fusion Approach
for Android Malware Detection</p></li>
<li><p>2020 DL-Droid: Deep learning based android malware detection
using real devices</p></li>
<li><p>2021 JOWMDroid: Android malware detection based on feature
weighting with joint optimization of weight-mapping and classifier
parameters</p></li>
<li><p>2020 Towards using unstructured user input request for malware
detection</p></li>
<li><p>2021 Toward s an interpretable deep learning model for mobile
malware detection and family identification</p></li>
<li><p>2020 AMalNet: A deep learning framework based on graph
convolutional networks for malware detection</p></li>
<li><p>2021 Disentangled Representation Learning in Heterogeneous
Information Network for Large-scale Android Malware Detection in the
COVID-19 Era and Beyond</p></li>
<li><p>2019 A Multimodal Deep Learning Method for Android Malware
Detection Using Various Features</p></li>
<li><p>2019 Android Fragmentation in Malware Detection</p></li>
<li><p>2019 An Image-inspired and CNN-based Android Malware Detection
Approach</p></li>
<li><p>2021 A Performance-Sensitive Malware Detection System Using Deep
Learning on Mobile Devices</p></li>
<li><p>2020 Byte-level malware classification based on markov images and
deep learning</p></li>
<li><p>2013 API Chaser: Anti-analysis Resistant Malware
Analyzer</p></li>
<li><p>2018 MalViz: An Interactive Visualization Tool for Tracing
Malware</p></li>
<li><p>2017 CloudEyes: Cloud-based malware detection with reversible
sketch for resource-constrained internet of things (IoT)
devices</p></li>
<li><p>2013 A fast malware detection algorithm based on
objective-oriented association mining</p></li>
<li><p>2013 PoMMaDe: Pushdown Model-checking for Malware
Detection</p></li>
<li><p>2014 Growing Grapes in Your Computer to Defend Against
Malware</p></li>
<li><p>2015 Hypervisor-based malware protection with
AccessMiner</p></li>
<li><p>2015 Probabilistic Inference on Integrity for Access Behavior
Based Malware Detection</p></li>
<li><p>2018 Probabilistic analysis of dynamic malware traces</p></li>
<li><p>2018 A malware detection method based on family behavior
graph</p></li>
<li><p>2018 Malware classification using self organising feature maps
and machine activity data</p></li>
<li><p>2019 Volatile memory analysis using the MinHash method for
efficient and secured detection of malware in private cloud</p></li>
<li><p>2020 A dynamic Windows malware detection and prediction method
based on contextual understanding of API call sequence</p></li>
<li><p>2013 Deriving common malware behavior through graph
clustering</p></li>
<li><p>2014 Enhancing the detection of metamorphic malware using call
graphs</p></li>
<li><p>2016 Minimal contrast frequent pattern mining for malware
detection</p></li>
<li><p>2019 Heterogeneous Graph Matching Networks for Unknown Malware
Detection</p></li>
<li><p>2021 Random CapsNet for est model for imbalanced malware type
classification task</p></li>
<li><p>2013 A Scalable Approach for Malware Detection through Bounded
Feature Space Behavior Modeling</p></li>
<li><p>2013 SigMal: A Static Signal Processing Based Malware
Triage</p></li>
<li><p>2014 Unsupervised Anomaly-Based Malware Detection Using Hardware
Features</p></li>
<li><p>2014 Control flow-based opcode behavior analysis for Malware
detection</p></li>
<li><p>2015 Employing Program Semantics for Malware Detection</p></li>
<li><p>2015 AMAL: High-fidelity, behavior-based automated malware
analysis and classification</p></li>
<li><p>2016 Optimized Invariant Representation of Network Traffic for
Detecting Unseen Malware Variants</p></li>
<li><p>2017 DYNAMINER: Leveraging Offline Infection Analytics for
On-the-Wire Malware Detection</p></li>
<li><p>2017 Security importance assessment for system objects and
malware detection</p></li>
<li><p>2018 From big data to knowledge: A spatiotemporal approach to
malware detection</p></li>
<li><p>2019 MalDAE: Detecting and explaining malware based on
correlation and fusion of static and dynamic characteristics</p></li>
<li><p>2019 Leveraging Compression-Based Graph Mining for Behavior-Based
Malware Detection</p></li>
<li><p>2020 Advanced Windows Methods on Malware Detection and
Classification</p></li>
<li><p>2020 Sub-curve HMM: A malware detection approach based on partial
analysis of API call sequences</p></li>
<li><p>2020 Multiclass malware classification via first- and
second-order texture statistics</p></li>
<li><p>2021 Catch them alive: A malware detection approach through
memory forensics, manifold learning and computer vision</p></li>
<li><p>2018 Auto-detection of sophisticated malware using lazy-binding
control flow graph and deep learning</p></li>
<li><p>2018 Malware identification using visualization images and deep
learning</p></li>
<li><p>2018 Classification of Malware by Using Structural Entropy on
Convolutional Neural Networks</p></li>
<li><p>2019 Classifying Malware Represented as Control Flow Graphs using
Deep Graph Convolutional Neural Network</p></li>
<li><p>2019 Neurlux: Dynamic Malware Analysis Without Feature
Engineering</p></li>
<li><p>2019 A feature-hybrid malware variants detection using CNN based
opcode embedding and BPNN based API embedding</p></li>
<li><p>2019 Effective analysis of malware detection in cloud
computing</p></li>
<li><p>2020 Recurrent neural network for detecting malware</p></li>
<li><p>2020 Dynamic Malware Analysis with Feature Engineering and
Feature Learning</p></li>
<li><p>2020 An improved two-hidden-layer extreme learning machine for
malware hunting</p></li>
<li><p>2020 HYDRA: A multimodal deep learning framework for malware
classification</p></li>
<li><p>2020 A novel method for malware detection on ML-based
visualization technique</p></li>
<li><p>2020 Image-Based malware classification using ensemble of CNN
architectures (IMCEC)</p></li>
</ol>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>学术前沿</category>
        <category>网络安全</category>
        <category>恶意软件检测</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地-【draft】安全知识图谱 | 绿盟</title>
    <url>/posts/28WW17E/</url>
    <content><![CDATA[<h2><span id="安全知识图谱-绿盟">安全知识图谱 | 绿盟</span></h2>
<p>本文为<strong>安全知识图谱技术白皮书</strong>《<a href="https://www.zhihu.com/search?q=践行安全知识图谱，携手迈进认知智能&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22442423245%22%7D">践行安全知识图谱，携手迈进认知智能</a>》精华解读系列<strong>第四篇</strong>，介绍了如何利用知识图谱相关技术实现攻击路径调查，主要依据图表示学习与图谱推理实现攻击路径评估与路径修复。</p>
<h3><span id="三-知识图谱视角下的威胁评估">三、知识图谱视角下的威胁评估</span></h3>
<p>本文为安全知识图谱技术白皮书《践行安全知识图谱，携手迈进认知智能》精华解读系列第三篇——利用知识图谱助力攻击画像与威胁评估。主要利用知识图谱<strong>表示学习技术</strong>，<strong>对攻击源或攻击行为进行威胁评估</strong>。</p>
<h4><span id="31-攻击画像的痛点">3.1 攻击画像的痛点</span></h4>
<p><strong>攻击画像及风险评估是针对复杂的企业环境，利用采集到的日志或设备告警构建相关的威胁图谱，以图的形式来刻画攻击和攻击源，然后利用图的相关方法对攻击源和企业运行环境进行风险与威胁评估</strong>。</p>
<p>企业为了应对网络威胁，通常会部署多个检测设备（如<strong>网络入侵检测系统IDS/IPS、全流量检测和网络应用防护系统WAF</strong>等）。由于检测设备规则的敏感性，企业安全运营每天需要面临大量威胁告警关联分析，海量告警远远超出了运营人员的事件排查能力。当前的<strong><font color="red">攻击检测设备缺少对这种事件关联的分析能力，从而导致高误报问题</font></strong>，检测设备产生的告警日志通常是低级的、孤立的，安全运营人员需要丰富的安全知识和经验才能针对告警做出相关地研判，这进一步增加了企业安全运营的挑战。</p>
<p>因此，在安全大数据涌现与高级威胁对抗的大背景下，将安全知识图谱应用到企业智能安全运营中，对提升安全运营的自动化水平，减少对人力投入与专家经验的依赖，降低威胁分析与响应的周期等方面具有至关重要的作用。</p>
<h4><span id="32-知识图谱表示学习">3.2 知识图谱表示学习</span></h4>
<p>在安全知识图谱的应用中，知识图谱表示学习具有关键作用。<strong>知识图谱表示学习通过让机器尽可能全面地学习知识，从而表现出类似于人类的行为，同时采用知识图谱表示方法来表示知识</strong>。知识图谱表示方法是研究计算机表示知识的可行性、有效性的一般方法，是把人类知识表示成机器能处理的数据结构和系统控制结构的策略。</p>
<p>安全知识图谱借鉴通用知识图谱的高效知识图谱表示方法，充分利用安全知识图谱中的知识，提升安全知识获取、融合和推理的性能。近年来，基于知识图谱表示学习方法主要分为两种：<strong>基于结构的知识图谱表示学习方法</strong>和<strong>基于语义的表示学习方法</strong>。</p>
<ul>
<li>基于结构的知识图谱表示学习方法大多采用三元组（head，relation，tail可简写为h，r，t）表示方法，具有一定的稀疏性，且无法进行语义层面的计算，主要方法有TransE[1]模型以及变体模型TransH[2]，TransD[3]，TransA[4]和KG2E[5]等。</li>
<li>基于语义的表示学习方法往往存在参数多，处理大型知识图谱效率较差的问题，相对降低复杂度后仅能在部分场景中应用。基于语义的表示学习主要研究工作有RESCAL[6]以及其变体[7-9]。</li>
</ul>
<p>随着知识图谱表示学习技术的不断发展，如何有效地获取全面的知识特征，更好地融合空间时间维度的知识图谱表示，同时避免知识的表示学习导致语义缺失的问题，成为此类研究的关键。</p>
<h4><span id="33-知识图谱助力企业威胁评估">3.3 知识图谱助力企业威胁评估</span></h4>
<figure>
<img src="https://pica.zhimg.com/v2-62721519f735f7fc5105a2eb8011b119_720w.jpg?source=d16d100b" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>在企业环境中，<strong>安全设备每日产生海量告警，这给安全分析带来了巨大挑战</strong>。为此，针对企业环境存在的问题，需要通过构建安全属性图模型来从不同维度对攻击源的威胁度进行评估。</p>
<p>威胁建模选用属性图对整个企业运行环境进行建模。这里以<strong>IP地址、端口、网段、告警、文件、日志等实体为图模型的节点</strong>，<strong>边则表示实体之间的关系</strong>，关系通常分为显式关系与隐式关系。显式关系是通过对日志解析直接可以得到的关系，而隐式关系是通过数据挖掘方法得到的节点之间暗含的关联关系。</p>
<p>企业环境中，安全运营人员通常是<strong>基于告警信息识别攻击者与攻击行为</strong>。针对单一告警，很难做出预判，这就需要一种有效的关联告警上下文的评估方法来辅助安全分析和运维。为了挖掘告警之间的因果依赖关系，需要构建告警因果关联图，并<strong>利用图表示学习方法DeepWalk学习告警的向量表示</strong>，详细过程如图
2所示。</p>
<p>针对属性知识图谱模型，可以参考深度图神经网络的一些方法，如图自编码器等来实现威胁评估。图自编码器就是在编码过程中使用了图表示学习技术，这里采用TransE模型来学习图谱中节点与边的向量表示。TransE模型属于翻译模型：直观上，将每个三元组实例（head，relation，tail
简写为
h，r，t）中的关系relation看作从实体head到实体tail的transform，通过不断调整head、relation和tail的向量，使（h
+ r） 尽可能与 tail 相等，即 h + r = t，如图3所示。</p>
<h3><span id="参看文献">参看文献</span></h3>
<ul>
<li><a href="https://www.zhihu.com/column/c_1446900744649240576">安全知识图谱 -
知乎</a>
：本文为安全知识图谱技术白皮书《践行安全知识图谱，携手迈进认知智能》精华解读系列</li>
</ul>
]]></content>
      <categories>
        <category>【draft】应用</category>
        <category>工业落地</category>
        <category>网络安全</category>
        <category>高级威胁发现</category>
      </categories>
  </entry>
</search>
