<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>hadoop&amp;spark的</title>
    <url>/posts/2T4G0D4/</url>
    <content><![CDATA[<h1><span id="hadoop和spark的区别和联系">hadoop和spark的区别和联系</span></h1><blockquote>
<p>  ==<strong>总结一句话：spark在hadoop肩膀上可以让大数据跑的更快</strong>==</p>
</blockquote>
<h3><span id="一-hadoop">一、 hadoop</span></h3><h4><span id="11-hadoop简介">1.1 hadoop简介</span></h4><p><strong>Hadoop是一个由Apache基金会所开发的分布式系统基础架构</strong>。 <strong>Hadoop实现了一个分布式文件系统HDFS</strong>。HDFS有高容错性的特点，并且设计用来部署在低廉的硬件上；而且它提供高吞吐量来访问应用程序的数据，适合那些有着超大数据集的应用程序。Hadoop的框架最核心的设计就是：HDFS和MapReduce。<strong>HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算</strong>。</p>
<h4><span id="12-hadoop优点">1.2 hadoop优点</span></h4><p><strong>Hadoop 以一种可靠、高效、可伸缩的方式进行数据处理。</strong></p>
<ul>
<li><p><strong>可靠性</strong>: Hadoop将数据存储在多个备份，Hadoop提供高吞吐量来访问应用程序的数据。</p>
</li>
<li><p><strong>高扩展性</strong>： Hadoop是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。</p>
</li>
<li><p><strong>高效性</strong>： Hadoop以并行的方式工作，通过并行处理加快处理速度。</p>
</li>
<li><p><strong>高容错性</strong>： Hadoop能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。</p>
</li>
<li><p><strong>低成本</strong>： Hadoop能够部署在低廉的（low-cost）硬件上。</p>
</li>
</ul>
<h3><span id="二-spark"><strong>二、spark</strong></span></h3><h4><span id="21-spark简介">2.1 spark简介</span></h4><p><strong>Spark 是专为大规模数据处理而设计的快速通用的计算引擎</strong>。Spark拥有Hadoop MapReduce所具有的优点，Spark在Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark性能以及运算速度高于MapReduce。</p>
<h4><span id="22-spark优点">2.2 spark优点</span></h4><p><strong>计算速度快</strong>: 因为spark从磁盘中读取数据，把<strong>中间数据放到内存中</strong>，，完成所有必须的分析处理，将结果写回集群，所以spark更快。</p>
<ul>
<li><p><strong>Spark 提供了大量的库</strong>: 包括Spark Core、Spark SQL、Spark Streaming、MLlib、GraphX。</p>
</li>
<li><p><strong>支持多种资源管理器</strong>: Spark 支持 Hadoop YARN，及其自带的独立集群管理器</p>
</li>
<li><p><strong>操作简单</strong>: 高级 API 剥离了对集群本身的关注，Spark 应用开发者可以专注于应用所要做的计算本身</p>
</li>
</ul>
<h3><span id="三-spark与hadoop的不同点">三、spark与hadoop的不同点</span></h3><h4><span id="31-应用场景不同">3.1 应用场景不同</span></h4><p>Hadoop和Spark两者都是大数据框架，但是各自应用场景是不同的。<strong>Hadoop是一个分布式数据存储架构，它将巨大的数据集分派到一个由普通计算机组成的集群中的多个节点进行存储，降低了硬件的成本</strong>。<strong>Spark是那么一个专门用来对那些分布式存储的大数据进行处理的工具，它要借助hdfs的数据存储</strong>。</p>
<h4><span id="32-处理速度不同">3.2 处理速度不同</span></h4><p><strong>hadoop的MapReduce是分步对数据进行处理的，从磁盘中读取数据，进行一次处理，将结果写到磁盘</strong>，然后在从磁盘中读取更新后的数据，再次进行的处理，最后再将结果存入磁盘，这存取磁盘的过程会影响处理速度。<strong>spark从磁盘中读取数据，把中间数据放到内存中</strong>，，完成所有必须的分析处理，将结果写回集群，所以spark更快。</p>
<h4><span id="33-容错性不同">3.3 容错性不同</span></h4><p><strong>Hadoop将每次处理后的数据都写入到磁盘上，基本谈不上断电或者出错数据丢失的情况</strong>。Spark的数据对象存储在弹性分布式数据集 RDD，RDD是分布在一组节点中的只读对象集合，如果数据集一部分丢失，则可以根据于数据衍生过程对它们进行重建。而且RDD 计算时可以通过 CheckPoint 来实现容错。</p>
<h3><span id="四-spark与hadoop的联系">四、spark与hadoop的联系</span></h3><p>Hadoop提供分布式数据存储功能HDFS，还提供了用于数据处理的MapReduce。 MapReduce是可以不依靠spark数据的处理的。当然spark也可以不依靠HDFS进行运作，它可以依靠其它的分布式文件系统。但是两者完全可以结合在一起，<strong>hadoop提供分布式集群和分布式文件系统</strong>，<strong>spark可以依附在hadoop的HDFS代替MapReduce弥补MapReduce计算能力不足的问题。</strong></p>
]]></content>
      <categories>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>hadoop基础</title>
    <url>/posts/3NVTGC1/</url>
    <content><![CDATA[<blockquote>
<p>  应该是指可以打通整个项目开发过程的，比如基于BS架构的话，就是熟悉前后端，知道怎么把算法模型部署到后端服务器，熟悉分布式计算，能玩转mapreduce，spark，hadoop，能熟练搭建项目框架</p>
</blockquote>
<p>三、大数据（简单了解其中一二个）</p>
<p>Hadoop基础、MapReduce、spark、hive、flink</p>
]]></content>
      <categories>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>大数据处理Q&amp;A</title>
    <url>/posts/10D4W42/</url>
    <content><![CDATA[<h4><span id="面试常见的大数据相关问题">面试常见的大数据相关问题</span></h4><ul>
<li><a href="https://anchorety.github.io/2019/08/14/%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/">https://anchorety.github.io/2019/08/14/%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/</a></li>
</ul>
<h4><span id="海量日志数据提取出某日访问百度次数最多的那个ip">海量日志数据，提取出某日访问百度次数最多的那个IP？</span></h4><ul>
<li><a href="http://zoeyyoung.github.io/get-most-visit-ip.html">http://zoeyyoung.github.io/get-most-visit-ip.html</a></li>
</ul>
<p>具体做法如下：</p>
<ol>
<li>按照IP地址的Hash(IP)%1024值, 把海量IP日志分别存储到1024个小文件中.</li>
<li>对于每一个小文件, 构建一个以IP为key, 出现次数为value的HashMap, 同时记录当前出现次数最多的那个IP地址;</li>
<li>得到1024个小文件中的出现次数最多的IP, 再依据常规的排序算法得到总体上出现次数最多的IP.</li>
</ol>
]]></content>
      <categories>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>大数据处理（1）高维向量相似度匹配</title>
    <url>/posts/DTTFVX/</url>
    <content><![CDATA[<h2><span id="文本相似度匹配">文本相似度匹配</span></h2><blockquote>
<p>  from 《Scaling Up All Pairs Similarity Search》</p>
<p>  海量文本的成对相似度的高性能计算（待续） - 马东什么的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/457947482">https://zhuanlan.zhihu.com/p/457947482</a></p>
</blockquote>
<h4><span id="摘要">摘要：</span></h4><p>对于高维空间中的大量稀疏向量数据，我们研究了寻找相似性分数(由余弦距离等函数确定)高于给定阈值的所有向量对的问题。我们提出了一个简单的算法<strong>，基于新的索引和优化策略，解决了这个问题，而不依赖于近似方法或广泛的参数调整</strong>。我们展示了该方法在广泛的相似阈值设置中有效地处理各种数据集，与以前的最先进的方法相比有很大的加速。</p>
<p>(海量成对文本相似度问题对于反欺诈而言非常重要，因为无论是电商中重要的地址信息，还是设备或用户的离散features之间的相似度计算和构图，都依赖于高性能的文本相似度计算方法，在实践中，我们不可能直接写双循环去做计算，即使是离线也往往需要耗费大量的时间)</p>
<h3><span id="一-介绍">一、介绍</span></h3><p>许多现实世界的应用程序需要解决一个相似度搜索问题，在这个问题中，人们对所有相似度高于指定阈值的对象对都感兴趣。</p>
<ul>
<li>web搜索的查询细化:搜索引擎通常会建议其他查询公式（例如你在百度中输入百，会给你推荐百度）。生成此类查询建议的一种方法是根据查询[19]的搜索结果的相似性来查找所有的相似查询对。由于目标是只提供高质量的建议，所以我们只需要找到相似度高于阈值的查询对（topk问题）。</li>
<li>协同过滤:协同过滤算法通过确定哪些用户有相似的品味来进行推荐。因此，算法需要计算相似度高于某个阈值的相似用户对。</li>
<li>接近重复的文档检测和消除:特别是在文档索引领域，检测和清除等价的文档是重要的。在许多情况下，由于简单的相等性检验不再满足要求，微小修改的存在使这种检测变得困难。通过具有很高的相似度阈值的相似度搜索，可以实现近重复检测（这方面的工作之前看过simhash，google做海量网页去重的方法）。</li>
<li>团伙检测:最近的工作已经应用算法在一个应用程序中寻找所有相似的用户，以识别点击欺诈者[13]团伙。</li>
</ul>
]]></content>
      <categories>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>局部敏感哈希LSH</title>
    <url>/posts/R9HZV9/</url>
    <content><![CDATA[<h2><span id="一-局部敏感哈希函数">一、局部敏感哈希函数</span></h2><blockquote>
<p>  python_mmdt:ssdeep、tlsh、vhash、mmdthash对比 : <a href="https://www.freebuf.com/sectool/321011.html">https://www.freebuf.com/sectool/321011.html</a></p>
<p>  局部敏感哈希(Locality Sensitive Hashing，LSH)总结：<a href="http://yangyi-bupt.github.io/ml/2015/08/28/lsh.html">http://yangyi-bupt.github.io/ml/2015/08/28/lsh.html</a></p>
</blockquote>
<h3><span id="11-局部敏感哈希的基本概念">1.1 局部敏感哈希的基本概念</span></h3><p>局部敏感哈希(Locality Sensitive Hashing，LSH)的基本思想类似于一种空间域转换思想，LSH算法基于一个假设，<strong>如果两个文本在原有的数据空间是相似的，那么分别经过哈希函数转换以后的它们也具有很高的相似度</strong>；相反，如果它们本身是不相似的，那么经过转换后它们应仍不具有相似性。</p>
<h3><span id="12-hash方法">1.2 hash方法</span></h3><p><strong><a href="https://ssdeep-project.github.io/ssdeep/index.html">CTPH(ssdeep)</a>：Context Triggered Piecewise Hashes(CTPH)</strong>，又叫模糊哈希，最早由Jesse Kornblum博士在2006年提出，论文地址点击<a href="https://ssdeep-project.github.io/ssdeep/index.html">这里</a>。CTPH可用于文件/数据的<strong>同源性判定</strong>。据官方文档介绍，其计算速度是<code>tlsh</code>的两倍（测试了一下，好像并没有）。</p>
<blockquote>
<p>  当使用传统的加密散列时，会为整个文件创建一个散列。单个位的变化会对输出哈希值产生雪崩效应。另一方面，CTPH 为文件的多个固定大小段计算多个传统加密哈希。它使用<em>滚动哈希</em>。</p>
</blockquote>
<p><strong><a href="https://tlsh.org/index.html">tlsh</a>：是趋势科技开源的一款模糊哈希计算工具</strong>，将50字节以上的数据计算生成一个哈希值，通过计算哈希值之间的相似度，从而得到原始文件之间的同源性关联。据官方文档介绍，<code>tlsh</code>比<code>ssdeep</code>和<code>sdhash</code>等其他模糊哈希算法更难攻击和绕过。</p>
<p><a href="https://developers.virustotal.com/reference/files">vhash</a>：（翻遍了整个virustotal的文档，就找到这么一句话）“an in-house similarity clustering algorithm value, based on a simple structural feature hash allows you to find similar files”，大概就是说是个内部相似性聚类算法，允许你通过这个简单的值，找到相似的样本。</p>
<p><a href="https://github.com/a232319779/python_mmdt">mmdthash</a>：是开源的一款模糊哈希计算工具，将任意数据计算生成一个模糊哈希值，通过计算模糊哈希值之间的相似度，从而判断两个数据之间的关联性。详情前文1-5篇。</p>
<blockquote>
<h4><span id="mmdthash">mmdthash：</span></h4><p>  通过重采样之后的数据，我们假设其满足独立同分布。同时，我们将重采样的数据，平均分成N块，每块之间的数据进行累计求和，和值分布近似服从正态分布，我们取和值高x位的一个byte做为本块数据的敏感哈希值。</p>
<p>  51030000:D6E26822530202020202020202020202：</p>
<ul>
<li><code>51030000</code>是4字节<strong>索引</strong>敏感哈希</li>
<li><code>D6E26822530202020202020202020202</code>是16字节敏感哈希</li>
</ul>
</blockquote>
<h3><span id="13-应用">1.3 应用</span></h3><p>简单应用如，索引敏感哈希可以转成一个int32的数字，当<strong>索引敏感哈希相等</strong>时，<strong>再比较敏感哈希的距离</strong>（如曼哈顿距离，将敏感哈希转成N个<code>unsigned char</code>类型计算敏感哈希，此时<code>00</code>和<code>FF</code>之间的距离可算作1，也可算作255，具体看实现）。</p>
<p>由于特征向量的维度是固定的，因此可以很方便的使用其他数学方法，进行大规模计算。</p>
<ul>
<li>如结合矩阵运算，快速得到上万特征向量（样本）的相似度矩阵，</li>
<li>如用于机器学习的分类（KNN）、聚类（Kmeans）等</li>
</ul>
<h2><span id>#</span></h2>]]></content>
      <categories>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>数据湖</title>
    <url>/posts/16YPX72/</url>
    <content><![CDATA[<h1><span id="数据湖data-lake-总结">数据湖（Data Lake） 总结</span></h1><ul>
<li><a href="https://zhuanlan.zhihu.com/p/91165577">https://zhuanlan.zhihu.com/p/91165577</a></li>
</ul>
<blockquote>
<p>  数据湖从本质上来讲，是一种企业数据架构方法，物理实现上则是一个数据存储平台，用来集中化存储企业内海量的、多来源，多种类的数据，并支持对数据进行快速加工和分析。</p>
</blockquote>
<p>数据湖是一种在系统或存储库中以自然格式存储数据的方法，它有助于以各种模式和结构形式配置数据，通常是对象块或文件。<strong>数据湖的主要思想是对企业中的所有数据进行统一存储，从原始数据（源系统数据的精确副本）转换为用于报告、可视化、分析和机器学习等各种任务的目标数据。数据湖中的数据包括==结构化数据==（关系数据库数据），==半结构化数据==（CSV、XML、JSON等），==非结构化数据==（电子邮件，文档，PDF）和==二进制数据==（图像、音频、视频），从而形成一个容纳所有形式数据的==集中式数据存储==。</strong></p>
<p>从实现方式来看，目前Hadoop是最常用的部署数据湖的技术，但并不意味着数据湖就是指Hadoop集群。为了应对不同业务需求的特点，MPP数据库+Hadoop集群+传统数据仓库这种“混搭”架构的数据湖也越来越多出现在企业信息化建设规划中。</p>
]]></content>
      <categories>
        <category>大数据处理</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（10）图机器学习在蚂蚁推荐业务中的应用</title>
    <url>/posts/25Z7M1R/</url>
    <content><![CDATA[<h2><span id="图机器学习在蚂蚁推荐业务中的应用">图机器学习在蚂蚁推荐业务中的应用</span></h2><blockquote>
<p>  <a href="https://mp.weixin.qq.com/s/BgNQdW3RvLw6rS1Wy-emzA">https://mp.weixin.qq.com/s/BgNQdW3RvLw6rS1Wy-emzA</a></p>
</blockquote>
<h3><span id="一-相关背景">一、相关背景</span></h3><p><strong>导读：</strong>本文将介绍图机器学习在蚂蚁推荐系统中的应用。<strong>在蚂蚁的实际业务中，有大量的额外信息，比如知识图谱、其他业务的用户行为等，这些信息通常对推荐业务很有帮助，我们利用图算法连接这些信息和推荐系统，来增强用户兴趣的表达。</strong></p>
<p>==全文主要围绕以下几方面内容展开：==</p>
<ul>
<li>背景</li>
<li>基于图谱的推荐</li>
<li>基于社交和文本的推荐</li>
<li>基于跨域的推荐</li>
</ul>
<p><img src="640.png" alt="图片" style="zoom:50%;"></p>
<p>支付宝除了最主要的支付功能外还有大量的推荐场景，包括腰封推荐、基金推荐和消费券推荐等等。支付宝域内的推荐相比于其他推荐最大的区别是用户的行为稀疏，活跃度较低，很多用户打开支付宝只是为了支付，不会关注其他东西。所以<strong><em>推荐网络中UI边的记录是非常少的，我们的关注点也是低活目标的推荐。</em></strong>比如为了提升DAU，可能只会给低活用户在腰封投放内容，正常用户是看不到的；基金推荐板块我们更关注的是那些没有理财或理财持仓金额较低的用户，引导他们买一些基金进行交易；消费券的推荐也是为了促进低活用户的线下消费。</p>
<p><strong>低活用户历史行为序列信息很少，一些直接根据UI历史行为序列来推荐的方法可能不太适用于我们的场景</strong>。因此我们引入了下面三个场景信息来增强支付宝域内的UI关系信息：</p>
<ul>
<li><strong>社交网络的UU关系</strong></li>
<li><strong>II图谱关系</strong></li>
<li><strong>其他场景的UI关系</strong></li>
</ul>
<p>通过社交网络的UU关系可以获取低活用户好友的点击偏好，根据同质性就可以推断出该用户的点击偏好，物品与物品之间的图谱关系可以发现、扩展用户对相似物品的喜好信息，最后跨域场景下的用户行为对当前场景的推荐任务也有很大帮助。</p>
<h3><span id="二-基于图谱的推荐">二、<strong>基于图谱的推荐</strong></span></h3><p><strong>很多推荐场景中用户的行为是稀疏的，尤其是在对新用户进行刻画时，可利用的行为信息很少，所以通常要引入很多辅助信息</strong>，比如attribute、contexts、images等等，我们这里引入的是knowledge graph—知识图谱。</p>
<p>知识图谱是一个大而全的历史专家知识，有助于我们的算法推荐，但是还存在两个问题：</p>
<ul>
<li><p><strong>一是图谱本身可能并不是为了这个业务而设计的，所以里面包含很多无用信息，训练过程也非常耗时。</strong>一个常用的解决办法是只保留图谱中能关联上我们商品的边，把其他边都删掉，但这又可能会造成一些信息损失，因为其他边也是有用的。</p>
</li>
<li><p><strong>二是图谱用做辅助信息时，没办法将用户的偏好聚合到图谱内部的边上</strong>。==如上图所示，用户1喜欢电影1和电影2的原因可能是因为它们有同一个主演，而用户2喜欢电影2和电影3的原因是它们的类型相同==。如果只用普通的图模型的UI、II关系来建模，只能得到用户和电影的相关性，而没办法将用户的这些潜在意图聚合到图谱中。</p>
</li>
</ul>
<p>所以我们后面主要解决图谱蒸馏和图谱精炼这两个问题。</p>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（11）青藤云安全-安全狩猎</title>
    <url>/posts/285K7D8/</url>
    <content><![CDATA[<h2><span id="青藤云安全">青藤云安全</span></h2><p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181517940.png" alt="image-20221105221126284"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181517783.png" alt="image-20221105221329660"></p>
<ul>
<li>护网检测的角度：交叉验证？？？</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181517592.png" alt="image-20221105232013125"></p>
<ul>
<li>索引的效率，压缩率</li>
<li>上下文，攻击树</li>
<li><strong>开源的解决方案？？？</strong></li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181518268.png" alt="image-20221105232149561"></p>
<h4><span id="可视化">可视化</span></h4><p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181518127.png" alt="image-20221105233353542"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181518088.png" alt="image-20221105235633129"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181518279.png" alt="image-20221105235813988"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181518619.png" alt="image-20221106150043663"></p>
<h4><span id="attck实战书">ATTCK，实战书</span></h4><h4><span id="attampck-数据源">ATT&amp;CK 数据源</span></h4><p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519913.png" alt="image-20221106001624464"></p>
<h4><span id="attampck-12-中一个套动作">ATT&amp;CK 12 中：一个套动作</span></h4><h4><span id="攻击链路的弱点">攻击链路的弱点</span></h4><p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519458.png" alt="image-20221106001713487"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519329.png" alt="image-20221106002243403"></p>
<h4><span id="告警确认">告警确认</span></h4><p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519141.png" alt="image-20221106150625666"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519976.png" alt="image-20221106150704168"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519449.png" alt="image-20221106002701972"></p>
<h3><span id="二-威胁搜猎案例分析">二、威胁搜猎案例分析</span></h3><p>在发现切入点之后，怎么把整个告警链路描绘出来？</p>
<ul>
<li>起点一般是？？</li>
<li>无文件攻击内存马；</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519752.png" alt="image-20221106151139571"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519579.png" alt="image-20221106151211979"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519132.png" alt="image-20221106151330278"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519605.png" alt="image-20221106151451348"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519493.png" alt="image-20221106151557997"></p>
<h4><span id="案例二">案例二</span></h4><p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519890.png" alt="image-20221106151644322"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519379.png" alt="image-20221106151759583"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519323.png" alt="image-20221106151841034"> </p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181519370.png" alt="image-20221106152030094"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520074.png" alt="image-20221106152054691"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520806.png" alt="image-20221106152157892"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520002.png" alt="image-20221106152227941"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520733.png" alt="image-20221106152258258"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520422.png" alt="image-20221106152429497"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520270.png" alt="image-20221106153100491"></p>
<p>  <img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520679.png" alt="image-20221106153126202"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520651.png" alt="image-20221106153149463"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520518.png" alt="image-20221106153209441"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520470.png" alt="image-20221106153342379"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520137.png" alt="image-20221106153413544"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520587.png" alt="image-20221106153521553"></p>
<p> <img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520102.png" alt="image-20221106153714241"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520726.png" alt="image-20221106153749604"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520328.png" alt="image-20221106153855615"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181520996.png" alt="image-20221106153825021"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521998.png" alt="image-20221106154040458"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521246.png" alt="image-20221106154854666"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521644.png" alt="image-20221106154914480"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521152.png" alt="image-20221106154934078"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521895.png" alt="image-20221106155005831"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521565.png" alt="image-20221106155018946"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521464.png" alt="image-20221106155119929">  </p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521605.png" alt="image-20221106155856100"></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521537.png" alt="image-20221106160005755"></p>
<ul>
<li>sigma 社区；<ul>
<li>情报转换；</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（12）2023 BlackHat：利用基于流的离群值检测和 SliceLine 来阻止分布广泛的机器人攻击</title>
    <url>/posts/1WG0TJH/</url>
    <content><![CDATA[<h2><span id="leveraging-streaming-based-outlier-detection-and-sliceline-to-stop-heavily-distributed-bot-attacks">Leveraging Streaming-Based Outlier Detection and SliceLine to Stop Heavily Distributed Bot Attacks</span></h2><blockquote>
<ul>
<li>利用基于流的离群值检测和 SliceLine 来阻止分布广泛的机器人攻击:</li>
<li>DataDome:<a href="https://datadome.co/">https://datadome.co/</a></li>
</ul>
</blockquote>
<p>在此演示文稿中，我们将讨论如何利用基于流的异常值检测和 SliceLine 来快速安全地生成大量可用于阻止恶意流量的规则/签名。</p>
<p>虽然 ML 的使用变得越来越广泛，但规则仍然相关。事实上，公司在能够快速评估大量规则的高效规则引擎方面投入了大量资金。此外，规则通常更便于创建、操作和解释，这使得它们除了 ML 方法之外仍然有价值。</p>
<p>我们证明，虽然 SliceLine 最初设计用于识别 ML 模型表现不佳的数据子集，但它的使用可以适应以无监督方式生成大量与攻击相关的规则，即不使用标记数据。此外，我们利用机器人检测问题来说明如何使用 SliceLine 即时生成大量恶意签名。</p>
<p>我们还将展示我们优化的 SliceLine Python 开源实现，并展示如何将其用于特定但困难的机器人检测子集：分布式凭证填充攻击，攻击者利用数千个受感染的 IP 地址进行攻击和绕过传统的安全机制，例如速率限制策略。</p>
<p>通过一个真实世界的例子，我们将首先解释如何使用基于流的检测来检测此类攻击，以及我们如何使用数据建模在服务器端信号（HTTP 标头、TLS 指纹、IP 地址等）上应用 <strong>SliceLine</strong> 来识别并生成与分布式攻击相关的阻止签名。这种方法使我们能够在去年阻止 59 位客户超过 2.85 亿次恶意登录尝试。</p>
<p>最后，我们将解释这种方法如何推广到除机器人检测之外的其他安全用例，以及如何在不同的规则引擎中使用它。</p>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（1）kaspersky《Machine Learning for Malware Detection》解析</title>
    <url>/posts/NVF6XT/</url>
    <content><![CDATA[<h2><span id="machine-learning-for-malware-detection">Machine Learning for Malware Detection</span></h2><blockquote>
<p>本文总结了 kaspersky 利用机器学习为客户建立高级保护的丰富经验。</p>
</blockquote>
<h3><span id="一-基本方法检测恶意软件">一、基本方法检测恶意软件</span></h3><p>一个高效、健壮、可扩展的恶意软件识别模块是每个网络安全产品的关键组成部分。恶意软件识别模块会根据其在该对象上所收集的数据来决定该对象是否构成威胁。这些数据可以在不同的阶段进行收集：</p>
<ul>
<li><p><strong>需要有代表性的大型数据集</strong></p>
<blockquote>
<p>必须强调这种方法的数据驱动特性。一个创建的模型在很大程度上依赖于它在训练阶段看到的数据，以确定哪些特征与预测正确的标签有统计关联。让我们来看看为什么制作一个具有代表性的数据集如此重要。</p>
</blockquote>
</li>
<li><p><strong>训练的模型必须是可解释的</strong></p>
<blockquote>
<p>目前使用的大多数模型家族，如深度神经网络，都被称为黑盒模型。黑盒子模型被给予输入X，它们将通过一个难以被人类解释的复杂操作序列产生Y。这可能会在现实生活中的应用程序中带来一个问题。例如，当出现错误警报时，我们想理解为什么会发生它，我们会问这是训练集还是模型本身的问题。模型的可解释性决定了我们管理它、评估其质量和纠正其操作的容易程度。</p>
</blockquote>
</li>
<li><p><strong><font color="red"> 假阳性率必须非常低</font></strong></p>
<blockquote>
<p><strong>当算法将良性文件错误地标记恶意标签时，就会发生误报。我们的目标是使假阳性率尽可能低，或为零</strong>。这在机器学习应用程序中并不常见。这是很重要的，因为即使在一百万个良性文件中出现一个误报，也会给用户带来严重的后果。这是复杂的事实，有许多干净的文件在世界上，他们不断出现。</p>
<p>为了解决这个问题，重要的是要对机器学习模型和指标施加高要求，并在<strong>训练期间进行优化，并明确关注低假阳性率(FPR)【FP/(FP+TN)】模型</strong>。</p>
<p>这还不够，因为之前看不见的新良性文件可能会被错误检测到。我们考虑到这一点，并实现了一个<strong>灵活的模型设计，允许我们动态地修复假阳性，而不需要完全重新训练模型</strong>。这些示例在我们的执行前和执行后的模型中实现，这将在以下章节中描述。</p>
</blockquote>
</li>
<li><p><strong><font color="red"> 算法必须允许我们快速调整它们以适应恶意软件作者的反击</font></strong></p>
<blockquote>
<p>在恶意软件检测领域之外，机器学习算法经常在<strong>固定数据分布的假设下工作，这意味着它不随时间变化</strong>。当我们有一个足够大的训练集时，我们可以训练模型，以便它将有效地推理测试集中的任何新样本。随着时间的推移，该模型将继续按预期进行工作。</p>
<p>在将机器学习应用于恶意软件检测后，我们必须面对我们的数据分布没有固定的事实：</p>
<ul>
<li>活跃的对手（恶意软件编写者）不断努力避免检测和发布新版本的恶意软件文件，这与在培训阶段看到的文件有显著不同。</li>
<li>成千上万的软件公司生产的新型良性可执行文件与以前已知的可执行文件显著不同。在训练集中缺乏关于这些类型的数据，但该模型需要识别出它们是良性的。</li>
</ul>
<p>这就导致了数据分布的严重变化，并提出了在任何机器学习实现中检测率随着时间的推移而下降的问题。在其反恶意软件解决方案中实现机器学习的网络安全供应商面临着这个问题，并需要克服它。<strong>该体系结构需要灵活，并且必须允许在再训练（retrain）之间“动态”更新模型</strong>。供应商还必须有<strong>有效的流程来收集和标记新样本，丰富训练数据集和定期的再训练模型。</strong></p>
</blockquote>
</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181501281.png" alt="image-20220429233456832" style="zoom:50%;"></p>
<h3><span id="二-卡巴斯基实验室机器学习应用">二、卡巴斯基实验室机器学习应用</span></h3><blockquote>
<p>上述真实世界恶意软件检测的特性使机器学习技术的直接应用成为一项具有挑战性的任务。<strong>在将机器学习方法应用于信息安全应用方面，卡巴斯基实验室拥有近十年的经验</strong>。</p>
<p>  在执行前检测新的恶意软件的<strong>相似性哈希</strong></p>
</blockquote>
<p>在杀毒行业的初期，计算机上的恶意软件检测是<strong>基于启发式特征</strong>，识别特定的恶意软件文件:</p>
<ul>
<li>代码段</li>
<li>代码片段或整个文件的哈希值</li>
<li>文件属性</li>
<li>以及这些特征的组合</li>
</ul>
<p>我们的主要目标是创建一个可靠的恶意文件指纹——一个功能的组合，可以快速检查。在此之前，这个工作流需要通过仔细选择指示恶意软件的代表性字节序列或其他特征来手动创建检测规则。在检测过程中，产品中的抗病毒引擎针对存储在防病毒数据库中的已知恶意软件指纹，检查文件中是否存在恶意软件指纹。</p>
<p>然而，恶意软件编写者发明了像服务器端多态性这样的技术。这导致每天都有成千十万的恶意样本被发现。同时，所使用的指纹对文件中的微小变化也很敏感。现有恶意软件的微小变化使它失去了雷达注意。前一种方法很快就变得无效了，因为：</p>
<ul>
<li>手动创建检测规则无法跟上新出现的恶意软件流。</li>
<li>针对已知恶意软件库检查每个文件的指纹意味着，在分析人员手动创建检测规则之前，您才能检测到新的恶意软件。</li>
</ul>
<p>我们感兴趣的是那些对文件中的小变化具有<strong>鲁棒性</strong>的特性。这些特性将检测到恶意软件的新修改，但不需要更多的资源来进行计算。性能和可伸缩性是反恶意软件引擎处理的第一阶段的关键优先事项。</p>
<p>为了解决这个问题，我们专注于提取以下特性：</p>
<ul>
<li>快速计算，如从<strong>文件字节内容</strong>或代码反汇编导出的统计数据</li>
<li>直接从可执行文件的结构中检索，比如<strong>文件格式描述</strong></li>
</ul>
<p><strong><font color="red"> 使用这些数据，我们计算了一种特定类型的哈希函数，称为局部敏感哈希(LSH)。</font></strong></p>
<blockquote>
<p>  ssdeep, TLSN 局部哈希</p>
</blockquote>
<p>两个几乎相同的文件的常规加密哈希和两个非常不同的文件的哈希差异一样大。文件的相似性和哈希值之间没有联系。然而，几乎相同的文件的LSHs映射到相同的二进制桶——它们的LSHs非常相似——而且概率非常高。两个不同文件的LSHs有很大差异。</p>
<blockquote>
<p><strong>LSH的基本思想是</strong>：将原始数据空间中的两个相邻数据点通过相同的映射或投影变换（projection）后，这两个数据点在新的数据空间中仍然相邻的概率很大，而不相邻的数据点被映射到同一个桶的概率很小。</p>
<ul>
<li><a href="https://colobu.com/2018/08/16/locality-sensitive-hashing/">https://colobu.com/2018/08/16/locality-sensitive-hashing/</a></li>
</ul>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502195.png" alt="image-20220429233512068" style="zoom: 33%;"></p>
<p>但我们走得更远。LSH的计算是无监督的。它没有考虑到我们对每个样本都是恶意软件或良性的额外知识。</p>
<p>有一个相似和非相似对象的数据集，我们通过引入一个训练阶段来增强了这种方法。我们实现了一种相似性哈希方法。<strong>它类似于LSH，但它是==有监督==的，并且能够利用关于相似和非相似对象对的信息</strong>。在这种情况下：</p>
<ul>
<li>我们的训练数据X将是一对文件特征表示[X1, X2]</li>
<li>Y将是一个可以告诉我们这些物体在语义上是否真的相似的标签。</li>
<li>在训练过程中，该算法拟合哈希映射h(X)的参数，以最大化训练集中的对数，其中h(X1)和h(X2)对于相似的对象是相同的，而对于其他的对象是不同的。</li>
</ul>
<p>该算法正在应用于可执行文件特性，它提供了具有有用检测功能的特定相似性哈希映射。事实上，我们训练了这种映射的几个版本，它们对不同特征集的局部变化的敏感性不同。例如，一个版本的相似性散列映射可以更专注于捕获<strong>可执行文件结构</strong>，而较少关注实际内容。另一种方法可能更专注于捕获文件中的<strong>ascii字符串</strong>。</p>
<p>这就抓住了这样一种观点，即不同的特性子集可能或多或少可以区分不同类型的恶意软件文件。对于其中一个，文件内容统计数据可能显示未知恶意包装器的存在。对于其他方面，关于潜在行为的最重要信息集中在表示已使用的OSAPI、已创建的文件名、已访问的url或其他特性子集的字符串中。<strong>为了更精确的产品检测，将相似度哈希算法的结果与其他基于机器学习的检测方法相结合。</strong></p>
<blockquote>
<p>  <strong>基于局部敏感哈希（有监督）+ 决策树集成的用户计算机两阶段预执行检测</strong></p>
</blockquote>
<p>为了分析在预执行阶段的文件，我们的产品将相似性哈希方法与其他训练过的算法结合在一个两阶段的方案中。为了训练这个模型，我们使用了大量我们知道是恶意软件和良性的文件。</p>
<p><strong>两阶段分析设计解决了减少用户系统的==计算负载==和==防止误报==的问题。</strong>一些对检测很重要的文件特性需要更大的计算资源来计算它们。这些功能被称为“重的”。为了避免对所有扫描文件的计算，我们引入了一个称为预检测的初步阶段。当使用“轻量级”特性分析文件，并在系统上没有大量负荷的情况下提取文件时，就会发生==预检测==。<strong>在许多情况下，预检测为我们提供了足够的信息，以知道一个文件是否是良性的，并结束了文件扫描</strong>。有时它甚至会检测到一个文件是恶意软件。如果第一阶段不够，则文件将进入第二阶段的分析，即提取“重”特征以进行精确检测。</p>
<p>在我们的产品中，两阶段分析的工作方式如下。在<strong>预检测阶</strong>段，对扫描文件的<strong>轻量级特征</strong>计算学习到的相似度<strong>哈希映射</strong>。然后，检查是否有其他文件具有相同的哈希映射，以及它们是恶意软件还是良性的。一组具有类似哈希映射值的文件被称为哈希桶。根据扫描文件所属的散列桶，可能会出现以下结果：</p>
<ul>
<li><p>在一个简单的区域案例中，文件落入一个只包含一种对象的桶中：恶意软件或良性的。如果一个文件落入一个“纯恶意软件桶”，我们会检测到它是恶意软件。如果它落入一个“纯良性的桶”，我们不会扫描它更深。在这两种情况下，我们都不提取任何新的“重”特性。</p>
</li>
<li><p>在硬区域中，哈希桶同时包含恶意软件和良性文件。这是系统唯一可以从扫描文件中提取“重”特征以进行精确检测的情况。<strong>对于每个硬区域，都有一个单独的特定区域的分类器训练。</strong>目前，我们使用<strong>决策树集成</strong>或基于“<strong>重”特征的相似性哈希</strong>，这取决于哪个队硬区域更有效。</p>
</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502256.png" alt="image-20220429233534859" style="zoom: 33%;"></p>
<blockquote>
<p><strong>对象空间的分割</strong>：</p>
<p>使用相似性散列映射创建的对象空间的分割的示意图表示。为简单起见，该插图只有两个维度。每个单元格的一个索引对应于特定的<strong>相似度哈希映射值</strong>。网格中的每个单元格都说明了一个具有相同相似性哈希映射值的对象区域，也称为<strong>哈希桶</strong>。点颜色：恶意（<strong>红色</strong>）和良性/未知（<strong>绿色</strong>）。有两种选项可用的：将一个区域的散列添加到恶意软件数据库（简单区域）中，或者将其作为两阶段检测器的第一部分，并与特定区域的分类器（硬区域）结合使用。</p>
</blockquote>
<p>在现实中，有一些困难的区域不适合用这种两阶段的技术进行进一步的分析，因为它们<strong>包含了太多流行的良性文件</strong>。用这种方法处理它们会产生假阳性和性能下降的高风险。对于这种情况，我们不训练特定区域的分类器，也不通过该模型扫描该区域中的文件。为了在这样的区域进行正确的分析，我们使用了<strong>其他的检测技术</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502023.png" alt="image-20220429233555509" style="zoom:50%;"></p>
<p>预检测阶段的实现大大减少了在第二步中被大量扫描的文件的数量。这个过程提高了性能，因为在预检测阶段通过相似哈希映射查找可以快速完成。</p>
<p>我们的两阶段设计也降低了假阳性的风险：</p>
<ul>
<li>在第一个（预检测）阶段，我们不能在假阳性风险较高的区域使用特定区域的分类器进行检测。正因为如此，传递到第二阶段的对象的分布偏向于“恶意软件”类。这也降低了假阳性率。</li>
<li>在第二阶段，<strong>每个硬区域的分类器只从一个桶上对恶意软件进行训练，但在训练集的所有桶中可用的所有干净对象上。这使得区域分类器能够更精确地检测特定硬区域桶的恶意软件</strong>。当模型在具有真实数据的产品中工作时，它还可以防止任何意外的假阳性。</li>
</ul>
<p>两阶段模型的可解释性来自于数据库中的每个散列都与训练中的一些恶意软件样本子集相关联。<strong>整个模型可以通过添加检测来适应一个新的恶意软件流，包括散列映射和一个以前未观察到的区域的树集成模型。这允许我们撤销和重新训练特定区域的分类器，而不显著降低整个产品的检测率</strong>。如果没有这个，我们将需要对整个模型重新培训所有我们知道的恶意软件，我们想要做的每一个改变。话虽如此，两阶段恶意软件检测适用于在介绍中讨论的机器学习的细节。</p>
<h3><span id="三-针对罕见攻击的深度学习">三、针对罕见攻击的深度学习</span></h3><p>通常，当恶意和良性样本在训练集中大量表示时，机器学习会面对任务。但是有些攻击是如此罕见，以至于我们只有一个恶意软件进行训练的例子。这是针对性高调的有针对性攻击的典型情况。在这种情况下，我们使用了一个非常特定的基于深度学习的模型架构。我们将这种方法称为<strong>exemplar network( ExNet)</strong>。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502308.png" alt="image-20220429233615467"></p>
<p>这里的想法是，我们训练模型来构建<strong>输入特征的紧凑表示</strong>。然后，我们使用它们来同时训练多个<strong>单范例的分类器（per-exemplar classifiers）</strong>——这些都是检测特定类型的恶意软件的算法。深度学习允许我们将这些多个步骤（对象特征提取、紧凑的特征表示和局部的，或每个范例的模型创建）结合到一个神经网络管道中，它可以提取各种类型的恶意软件的鉴别特征。</p>
<p>该模型可以有效地<strong>推广关于单个恶意软件样本</strong>和大量干净样本收集的知识。然后，它可以检测到相应的恶意软件的新修改。</p>
<h3><span id="四-在执行后行为检测中的深度学习">四、在执行后行为检测中的深度学习</span></h3><p>前面描述的方法是在静态分析的框架中考虑的，即在真实用户环境中执行对象之前提取和分析对象描述。</p>
<p>执行阶段的静态分析有许多显著的优势。其主要优点是它对用户来说是安全的。一个对象可以在它开始作用于真实用户的机器之前被检测到。但它面临着高级加密、混淆技术以及使用各种高级脚本语言、容器和无文件攻击场景的问题。这些情况都是当执行后的行为检测开始发挥作用的情况。</p>
<p>我们还使用深度学习方法来解决<strong>行为检测的任务</strong>。在执行后阶段，我们正在使用<strong>威胁行为引擎</strong>提供的<strong>行为日志</strong>。行为日志是在进程执行过程中发生的系统事件的序列，以及相应的参数。为了检测观察到的日志数据中的恶意活动，我们的模型将得到的事件序列压缩为一组二进制向量。然后，它训练一个深度神经网络来区分干净的和恶意的日志。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502002.png" alt="image-20220429233634048"></p>
<p><strong>日志的压缩阶段</strong>包括以下几个步骤：</p>
<ul>
<li><p>将该日志转换为一个二部行为图。此图包含两种类型的顶点：事件和参数。在每个事件和参数之间绘制边，它们一起出现在日志中的同一行中。这样的图表示比初始的原始数据要紧凑得多。它对跟踪同一多处理程序的不同运行或分析过程的行为混淆所导致的任何行排列保持鲁棒性</p>
</li>
<li><p>之后，我们将自动从该图中提取特定的子图或行为模式。每个模式都包含与进程的特定活动相关的事件和相邻参数的子集，如网络通信、文件系统探索、系统寄存器的修改等</p>
</li>
<li>我们将每个“行为模式”压缩为一个稀疏的二进制向量。此向量的每个组件负责在模板中包含一个特定的事件或参数的令牌(与web、文件和其他类型的活动相关)。</li>
<li>训练后的深度神经网络将行为模式的稀疏二进制向量转换为称为<strong>模式嵌入</strong>的紧凑表示。然后将它们组合成一个单个向量，或进行<strong>日志嵌入</strong></li>
<li>最后，在日志嵌入的基础上，网络预测了日志的可疑性。</li>
</ul>
<p>所使用的神经网络的主要特征是所有的权值都是正的，所有的激活函数都是单调的。这些特性为我们提供了许多重要的优势：</p>
<ul>
<li><strong>在处理日志中的新行时，我们的模型的怀疑分数输出只随着时间的推移而增长。因此，恶意软件不能通过与它的主有效负载并行地执行额外的噪声或“干净的”活动来逃避检测</strong>。</li>
<li>由于模型的输出在时间上是稳定的，我们可能会免受由于在扫描干净日志时的预测波动而导致的最终错误警报。</li>
<li>在单调空间中处理日志样本，允许我们自动选择导致检测的事件，并更方便地管理假警报</li>
</ul>
<p>这样的方法使我们能够训练一个能够使用高级可解释的行为概念进行操作的深度学习模型。这种方法可以安全地应用于整个用户环境的多样性，并在其架构中集成了假告警修复能力。总之，所有这些都为我们提供了一种对行为检测最复杂的现代威胁的有力手段。</p>
<h3><span id="五-基础设施中的应用malware-hunter">五、基础设施中的应用（Malware Hunter）</span></h3><p>从有效处理卡巴斯基实验室的恶意软件流到维护大规模检测算法，<strong>机器学习在建立适当的实验室基础设施中发挥着同样重要的作用</strong>。</p>
<h4><span id="51-聚类传入的对象流">5.1 聚类传入的对象流</span></h4><p><strong>每天都有成千上万的样本进入卡巴斯基实验室，同时人工对新型样本进行注释的高昂成本，减少分析师需要查看的数据量成为一项至关重要的任务</strong>。使用有效的聚类算法，我们可以从难以忍受的独立的未知文件数量增加到合理数量的对象组。这些对象组的部分将根据其中已注释的对象自动处理。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502650.png" alt="image-20220429232153712" style="zoom:50%;"></p>
<p>所有最近收到的传入文件都通过我们的实验室恶意软件检测技术进行分析，包括执行前和执行后。我们的目标是标记尽可能多的对象，但有些对象仍然未分类。我们想给它们贴上标签。为此，所有的对象，包括已标记的对象，都由<strong>多个特征提取器</strong>进行<strong>处理</strong>。然后，根据<strong>文件类型</strong>，它们通过几种聚类算法(例如k-means和dbscan)一起传递。这将产生类似的对象组。</p>
<p>在本文的这一点上，我们将面对四种不同类型的具有未知文件的结果集群：</p>
<ol>
<li>包含恶意软件和未知文件的集群；</li>
<li>包含干净和未知文件的集群；</li>
<li>包含恶意软件、干净和未知文件的集群；</li>
<li>仅包含未知文件的集群。</li>
</ol>
<p>对于类型1-3簇中的对象，我们使用额外的机器学习算法，如<strong>贝叶斯网络（belief propagation）</strong>，<strong>来验证未知样本与分类样本的相似性</strong>。在某些情况下，这甚至在第3类集群中也是有效的。这使我们能够自动标记未知文件，只为人类留下4型和部分3型的集群。这导致了每天所需的人类注释的急剧减少。</p>
<h4><span id="蒸馏工艺包装更新内容">蒸馏工艺：包装更新内容</span></h4><p>我们在实验室中检测恶意软件的方式不同于针对用户产品的最佳算法。一些最强大的分类模型需要大量的资源，如CPU/GPU的时间和内存，以及昂贵的特性提取器。</p>
<p>例如，由于大多数现代恶意软件编写者使用<strong>高级包装器和混淆器</strong>来隐藏有效负载功能，机器学习模型确实受益于使用具有高级行为日志的实验室内沙箱的执行日志。同时，在用户的机器上的预执行阶段收集这类日志的计算量可能会很高。它可能会导致显著的系统性能下降。</p>
<blockquote>
<p>对于加壳的恶意样本，需要沙箱分析，在用户终端</p>
</blockquote>
<p>在实验室中保存和运行那些<strong>“重型”</strong>模型更有效。一旦我们知道一个特定的文件是恶意软件，我们就会使用我们从模型中获得的知识来训练将在我们的产品中工作的<strong>轻量</strong>级分类器（to 用户）。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181502687.png" alt="image-20220429232807391" style="zoom:50%;"></p>
<p>在机器学习中，这个过程被称为<strong>蒸馏</strong>。我们用它来教我们的产品检测新的恶意软件：</p>
<ul>
<li>在我们的实验室中，我们首先从标记的文件中提取一些耗时的特征，并对它们训练一个“沉重的”在实验室内的模型。</li>
<li>我们取一个未知文件集群，并使用我们的“重”实验室模型来对它们进行标签。</li>
<li>然后，我们使用新标记的文件来扩充轻量级分类模型的训练集。</li>
<li>我们向用户的产品提供了这个轻量级的模型。</li>
</ul>
<p>蒸馏使我们能够有效地输出我们的知识的新的和未知的威胁给我们的用户。</p>
<h4><span id="总结">总结</span></h4><p>将常规任务传递给算法会给我们留下更多的时间来研究和创建。这使我们能够为客户提供更好的保护。通过我们的努力、失败和胜利，我们已经了解到什么对于让机器学习对恶意软件检测产生它的卓越影响是重要的。</p>
<h5><span id="亮点">亮点：</span></h5><ul>
<li><strong>有正确的数据</strong>：这是机器学习的燃料。这些数据必须具有代表性，与当前的恶意软件环境相关，并在需要时正确标记。我们成为了在提取和准备数据以及训练我们的算法方面的专家。我们用数十亿个文件样本进行了有效的收集，以增强机器学习的能力。</li>
<li><p><strong>了解理论机器学习以及如何将其应用于网络安全。</strong>我们了解机器学习是如何工作的，并跟踪该领域出现的最先进的方法。另一方面，我们也是网络安全方面的专家，我们认识到每一种创新的理论方法给网络安全实践带来的价值。</p>
</li>
<li><p><strong>了解用户的需求，并成为将机器学习实现到帮助用户满足其实际需求的产品中的关键</strong>。我们使机器学习有效和安全地工作。我们建立了网络安全市场所需要的创新解决方案</p>
</li>
<li><p><strong>建立一个足够的用户基础</strong>：这引入了“群众”检测质量的力量，并给我们需要的反馈，告诉我们是对是错。</p>
</li>
<li><strong>保持检测方法的多层协同作用</strong>。只要当今的先进威胁攻击载体如此多样化，网络安全解决方案就应该提供<strong>多层的保护</strong>。在我们的产品中，<strong>基于机器学习的检测与其他类型的检测协同工作，以一种多层的现代网络安全保护方法进行工作。</strong></li>
</ul>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（13）微信UFA-Unveiling Fake Accounts at the Time of Registration: An Unsupervised Approach</title>
    <url>/posts/1BJ949D/</url>
    <content><![CDATA[<h1><span id="ufa-在注册环节识别虚假账户的无监督检测算法">UFA-在注册环节识别虚假账户的无监督检测算法</span></h1><blockquote>
<p>  <strong>2021 KDD 论文</strong>：<strong>Unveiling Fake Accounts at the Time of Registration: An Unsupervised Approach</strong></p>
<ul>
<li><p><a href="https://dl.acm.org/doi/10.1145/3447548.3467094">https://dl.acm.org/doi/10.1145/3447548.3467094</a></p>
<p>参考：小伍哥聊风控：<a href="https://mp.weixin.qq.com/s/PE4OSByfngPEJOW8UWVkMw">https://mp.weixin.qq.com/s/PE4OSByfngPEJOW8UWVkMw</a></p>
</li>
</ul>
</blockquote>
<h3><span id="引言">引言</span></h3><p>今天分享一篇腾讯的论文，是一篇非常偏工程化的文章，其中也有很多技术的创新，但是工程上的一些实践感觉还是非常有价值的，<strong><font color="red"> 其实在风控业务中，业务的抽象和提取方法，可能远大于算法本身，特别是图学习领域，一个垃圾的图，算法学的越准，错的越离谱。</font></strong></p>
<span id="more"></span>
<h3><span id="一-概述">一、概述</span></h3><p>在线社交网络（OSN）充斥着虚假账户。现有的虚假账户检测方法要么需要手动标记的训练集，这既耗时又昂贵，要么依赖于OSN账户的丰富信息，例如内容和行为，这会导致检测虚假账户的显著延迟。在这项工作中，我们提出了UFA（揭开虚假账户的面纱）来在虚假账户以无监督的方式注册后立即检测它们。</p>
<p>首先，通过对真实世界注册数据集上的注册模式的测量研究，我们观察到虚假账户倾向于聚集在异常注册模式上，例如IP和电话号码。然后，我们设计了一种无监督学习算法来学习所有注册账户的权重及其特征，以揭示异常注册模式。</p>
<p><strong>接下来，我们构建了一个注册图来捕捉注册帐户之间的相关性，并通过分析注册图结构，利用社区检测方法来检测虚假帐户</strong>。我们使用真实世界的微信数据集评估UFA。我们的结果表明，UFA在召回率为80%的情况下达到了94%的精度，<strong>而监督变体需要600K手动标签才能获得可比较的性能</strong>。此外，微信已经部署UFA来检测虚假账户一年多了。UFA检测到500𝐾 通过微信安全团队的手动验证，每天伪造账户的准确率平均为93%。</p>
<p><strong>本文主要有四大贡献：</strong></p>
<ol>
<li>本文基于微信数据提出了大规模的<strong>度量学习</strong>的方法，并使用注册数据发现了虚假账号在异常注册模式的聚集趋势</li>
<li>本文基于微信注册数据，提出了非监督UFA模型用以识别虚假账户</li>
<li>系统性的评估了UFA和其他监督和非监督模型的效果</li>
<li>UFA模型在微信已经部署超过一年，在线上取得了很好的效果</li>
</ol>
<h3><span id="二-数据探索">二、<strong>数据探索</strong></span></h3><h4><span id="21-ip地址分析">2.1 <strong>IP地址分析</strong></span></h4><p>在论文使用的数据集中，总共有895,879个不同的IP地址。我们将使用同一IP地址注册的所有帐户组合在一起。因此，组的大小表示从一致的IP地址注册的帐户数量。图8a 显示了注册给定数量账户计数的IP地址数。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181521354.png" alt="图片" style="zoom: 50%;"></p>
<p>当给定的帐户数从0-5增加到5-10时，我们观察到IP地址数会有一个数量级的下降。这表明大多数IP地址注册了少量帐户（少于5个帐户），而少数IP地址注册了大量帐户。此外，假冒帐户更有可能使用相同的IP地址注册。</p>
<p>图8b显示了从IP地址注册的帐户中假冒帐户的比例，该IP地址注册了给定数量的帐户。我们观察到，当一个IP地址注册了少量帐户（例如10个）时，很难仅仅根据这些帐户共享IP地址的事实来判断这些帐户是否为假帐户。但是，当大量（例如100）帐户从同一IP地址注册时，这些帐户更有可能是伪造帐户。（量变引起质变）</p>
<h4><span id="22-手机号码分析">2.2 <strong>手机号码分析</strong></span></h4><p>用户在注册微信账号时必须提供电话号码。由于我们只能访问电话号码的前 7 位数字（运营商加区号），因此我们将使用电话号码的前缀来研究假帐户和良性帐户之间的区别。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522297.png" alt="图片" style="zoom: 50%;"></p>
<p>图 9a 显示了注册给定数量账户的电话号码前缀的数量，而图 9b 显示了从注册给定数量账户的电话号码前缀注册的账户中虚假账户的比例。与 IP 地址一样，我们观察到大多数电话前缀只具有少量注册帐户，而少数电话前缀具有大量注册帐户。更具体地说，如果一个电话前缀有超过 30 个注册帐户，这些帐户中的大部分可能是假帐户。</p>
<h4><span id="23-设备的device-id这里用的imei码">2.3 <strong>设备的device id（这里用的imei码</strong>）</span></h4><p>图10a显示了注册给定数量帐户的设备（由IMEI标识）的数量，图10b显示了注册给定数量帐户的设备中注册的帐户中伪造帐户的比例。我们观察到相似的异常模式，也就是说，伪帐户可能是从相同的设备注册的。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522769.png" alt="图片" style="zoom:50%;"></p>
<h4><span id="24-注册时间">2.4 <strong>注册时间</strong></span></h4><p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522140.png" alt="图片" style="zoom:50%;"></p>
<p>图11显示了在一天中注册的帐户的注册时间的分布。我们观察到大多数良性用户从早上八点开始注册帐户，到晚上24点左右停止注册，午夜时很少有用户活跃。然而，假账户的数量似乎一整天都没有变化。大多数在午夜注册的账户可能是假账户。</p>
<h4><span id="25-不一致的地理位置"><strong>2.5 不一致的地理位置</strong></span></h4><p>IP地址和电话号码都可以映射到一个大概的地理位置。因此，我们可以分析每个注册的用户的两个地理位置是否相同（ip和电话号码可以查询到用户的归属地）。我们观察到65%的假帐户具有不同的基于IP的位置和基于电话号码的位置。一个可能的原因是攻击者利用云服务和从本地获取的电话号码注册假帐户。此外，用户还可以在注册帐户时在配置文件中指定其位置（例如国家）。我们发现96%的伪造账户指定的国家与基于IP的定位不一致。一个可能的原因是这些假账户的目的是攻击来自特定地点的良性账户。</p>
<h4><span id="26-微信和设备的版本"><strong>2.6 微信和设备的版本</strong></span></h4><p>我们分析了微信版本和操作系统版本，发现大多数从过时的微信或/和操作系统版本注册的账户都是假账户。例如，从某个过时的Android版本注册的账户只有2K个，其中96.5%是假的。同样的现象也发生在iOS中。例如，我们发现从iOS 8（过期的DOS版本）注册的99%的帐户都是假帐户。一个可能的原因是，攻击者使用脚本自动注册假帐户，其中微信和操作系统版本尚未更新。</p>
<h4><span id="27-道德和隐私"><strong>2.7 道德和隐私</strong></span></h4><p>微信在隐私政策中规定，用户注册帐户时将收集用户数据。此外，在提交微信服务器之前，所有注册属性都已匿名，以保护用户隐私。例如，电话号码的客户代码（即最后四位数字）将被删除。IP地址逐段散列，WiFi MAC和设备ID全部散列。特别是，我们有一个与WeChat合作的实习计划，因此我们可以访问存储在微信服务器上的上述数据。</p>
<h3><span id="三-相关研究">三、相关研究</span></h3><p>paper中的related部分其实就类似于我们平常做项目之前的一些解决方案的调研，传统的检测方法：这些方法可以分为基于特征的方法和基于结构的方法。</p>
<h4><span id="31-基于特征的方法">3.1 <strong>基于特征的方法</strong></span></h4><p>通常将虚假账户检测的建模转化为为一个二分类问题，并利用机器学习技术进行解决。具体来说，<strong>首先从每个账户的内容（如推特中的URL）、行为（如点击流和喜欢的行为记录）、注册信息（如IP地址和代理）中提取特征</strong>。然后，基于这些提取的特征和标记的训练集（由标记的假账户和标记的良性账户组成）训练监督分类器（如logistic回归），并使用训练的分类器检测假账户。</p>
<h4><span id="32-基于结构的方法">3.2 <strong>基于结构的方法</strong></span></h4><p>利用社交图的结构来检测假账户，并且通常基于这样一个观察结果，即如果一个账户与其他假账户相关联，该账户可能也是虚假的账户。这些基于扩展图的机器学习技术的方法，例如<strong>随机行走</strong>和<strong>信念传播</strong>，分析用户之间社交图的结构。</p>
<p><strong><font color="red"> 上述传统检测方法的主要局限性在于检测假账户时存在严重延迟，因为这些方法需要获取假账户生成的足够信息进行分析，例如，丰富的内容、行为，和/或社交图。</font></strong>因此，当检测到伪造帐户时，它们可能已经进行了各种恶意活动。</p>
<h3><span id="四-模型的原型设计">四、模型的原型设计</span></h3><p>UFA旨在以无监督的方式在注册时检测出虚假账户。图1概述了UFA。它由四个关键部分组成，即<strong>特征提取、无监督的权重学习、注册图的构建和假账户检测</strong>。在特征提取方面，受注册模式测量研究的启发，我们提取了揭示虚假账户异常注册模式的特征。<strong><font color="red"> 在无监督的权重学习中，我们首先构建了一个注册-特征大图来捕捉注册账户和特征之间的关系。大图中的每个节点都代表一个注册账户或一个特征，注册节点和特征节点之间的每条边都表示该注册账户具有该特征。</font></strong></p>
<h4><span id="41-整体框架">4.1 整体框架</span></h4><p>接下来，我们设计了一种统计方法来初始化大图中每个节点的权重。节点的权重量化了该节点的异常情况。我们的统计方法不需要标记的虚假账户或/和标记的良性账户，因此它是无监督的。这里，初始权重没有考虑特征之间和注册账户之间的关系。为了解决这个问题，我们采用了一种最先进的基于结构的方法，称为线性化信念传播[26]，来传播注册-特征大图中节点的初始权重，并迭代更新每个节点的权重。每个注册账户的最终权重表示该账户被伪造的概率。</p>
<p>UFA主要包括了四个步骤：特征提取、无监督权重学习、注册图构造、虚假账户检测</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522237.png" alt="图片"></p>
<p>在特征提取中，受之前的数据挖掘部分得到的分析结果的启发，我们提取了可以反应假账户异常注册模式的特征。在无监督权重学习中，我们<strong>首先构造一个注册特征-用户 的二部图来捕捉注册账户和特征之间的关系</strong>。二部图中的每个节点表示注册帐户或特征，注册节点和特征节点之间的每个边表示注册帐户具有该特征。我们初始化Bigraph中每个节点权重使用了基于统计的方法。节点的权重量化了节点的异常。我们的统计方法不需要标记假账户或/和标记良性账户，因此不是有监督的方法。在这里，初始权值不考虑特征和注册账户之间的关系。为了解决这个问题，我们采用了一种最先进的基于结构的方法，称为线性化置信传播（《Structure-based sybil detection in social networks via local rule-based propagation》），在注册特征bigraph中传播节点的初始权重，并迭代更新每个节点的权重。每个注册帐户的最终权重表示该帐户被伪造的可能性。</p>
<p>无监督权重学习无法学习注册帐户之间的相关性，因为注册特征-用户的bigraph中注册帐户之间没有边。因此，我们构建了一个图来直接捕获注册帐户之间的相关性。具体来说，我们将注册特征的bigraph映射到一个注册图中，其中每个节点都是注册帐户，如果两个注册帐户之间的相似度高于阈值，则在它们之间添加一条边（还是相似度构图的思路啊。。。）。两个注册帐户之间的相似性定义为两个帐户共享的特征权重之和。在构建的注册图中，假账户可能紧密连接，而真账户可能稀疏连接。最后，由于假账户在注册图中紧密连接，我们使用<strong>社区检测算法</strong>进行社群检测。如果社区中的节点的规模大于阈值，则我们将社区中的所有帐户视为假帐户。</p>
<h4><span id="42-特征提取">4.2 <strong>特征提取</strong></span></h4><p>注册阶段的用户特征，当用户注册一个微信账号时，微信会收集该账号的多个注册属性。表1列出了具有代表性的注册属性。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522816.png" alt="图片" style="zoom:50%;"></p>
<p>例如，电话号码是用户用来注册帐户的号码。每个电话号码只能用于注册一个帐户和作为帐户ID。WiFi MAC是手机用于注册帐户的WiFi路由器的MAC地址，DeviceID是用于注册帐户的手机的IMEI/Adsource。根据数据挖掘部分的分析结果，与良性账户相比，虚假账户倾向于具有异常值注册模式。特别是，假账户可能使用相同的IP，使用相同地区的相同电话号码，从相同的设备注册，在午夜活跃，使用罕见且过时的微信和操作系统版本。一个可能的原因是攻击者的资源有限（例如IP、电话号码和设备），只能使用脚本自动注册假帐户。</p>
<p>那么我们怎么做特征提取呢？我们提取了可以用来反映虚假帐户异常注册模式的特征。<strong>具体来说，我们将每个注册表的属性和属性值解析为一个字符串，格式为“%%FeaturePrefix%%.%%value%%”</strong>。表2中列出了所有特性前缀。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522987.png" alt="图片" style="zoom:50%;"></p>
<p>每个特征前缀只与一个属性相关，并表示该属性的预处理函数；并且每个值都是预处理后生成的结果。为了简单起见，我们只展示如何提取特征前缀为“TimeAbnormal”的特征，因为其他特征可以从其特征前缀和描述中轻松理解：</p>
<p>TimeAbnormal：根据我们的数据挖掘的结果，我们观察到在深夜注册的账户很可能是假账户，而良性账户主要在白天注册。因此，我们定义了一个特征Prefix TimeAbnormal，它使用时间戳特征。时间异常用于指示帐户的注册时间是否异常。也就是说，如果账户在白天注册，则时间异常值为假，如果账户在午夜晚些时候注册，则时间异常值为真，在我们的工作中，我们将午夜定义为凌晨2点到5点之间。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522169.png" alt="图片" style="zoom:50%;"></p>
<p>这里的意思是根据注册时间构建一个节点，这个节点的id为 timeanomaly true，如上图。</p>
<p><strong><font color="red"> 整体来看，特征提取的思路很简单，其实本质上就是通过将用户的属性转化为节点，从而将单个用户节点分裂为以用户节点为中心的用户-属性的k部图，不过文中用的描述是2部图，其实就是把所有的特征都定义为类型为“特征”的节点，问题不大。</font></strong></p>
<p>在构图之前，对于特征论文中进行统一的string话处理，格式为 “%%FeaturePrefix%%_%%Value%%”，假设我们现在手头有两个用户uid001和uid002，对于特征的处理和图的构建就像下图这样：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">data = <span class="punctuation">&#123;</span></span><br><span class="line">    &#x27;uid001&#x27;<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        &#x27;PHONE&#x27;<span class="punctuation">:</span> <span class="number">123456</span><span class="punctuation">,</span></span><br><span class="line">        &#x27;MAC&#x27; <span class="punctuation">:</span> <span class="string">&quot;abcd&quot;</span><span class="punctuation">,</span></span><br><span class="line">        &#x27;IP&#x27; <span class="punctuation">:</span> &#x27;<span class="number">11.22</span><span class="number">.33</span><span class="number">.44</span>&#x27;</span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    &#x27;uid002&#x27;<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        &#x27;PHONE&#x27; <span class="punctuation">:</span> <span class="number">123456</span><span class="punctuation">,</span></span><br><span class="line">        &#x27;MAC&#x27; <span class="punctuation">:</span> &#x27;dcba&#x27;<span class="punctuation">,</span></span><br><span class="line">        &#x27;IP&#x27;<span class="punctuation">:</span> &#x27;<span class="number">44.33</span><span class="number">.22</span><span class="number">.11</span>&#x27;</span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>构图数据预处理过程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">feature_to_node</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line">    </span><br><span class="line">    result = defaultdict(<span class="built_in">set</span>)</span><br><span class="line">    <span class="keyword">for</span> uid, features <span class="keyword">in</span> data.items():</span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> features:</span><br><span class="line">            node = <span class="string">f&#x27;<span class="subst">&#123;feature&#125;</span>_<span class="subst">&#123;features[feature]&#125;</span>&#x27;</span></span><br><span class="line">            result[uid].add(node)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">feature_to_node(data)</span><br><span class="line">defaultdict(<span class="built_in">set</span>,</span><br><span class="line">            &#123;<span class="string">&#x27;uid001&#x27;</span>: &#123;<span class="string">&#x27;IP_11.22.33.44&#x27;</span>, <span class="string">&#x27;MAC_abcd&#x27;</span>, <span class="string">&#x27;PHONE_123456&#x27;</span>&#125;,</span><br><span class="line">             <span class="string">&#x27;uid002&#x27;</span>: &#123;<span class="string">&#x27;IP_44.33.22.11&#x27;</span>, <span class="string">&#x27;MAC_dcba&#x27;</span>, <span class="string">&#x27;PHONE_123456&#x27;</span>&#125;&#125;)</span><br></pre></td></tr></table></figure>
<h4><span id="43-无监督的权重学习">4.3 <strong>无监督的权重学习</strong></span></h4><p><strong>在无监督权重学习中，我们的目标是学习每个提取特征和每个注册帐户的权重。</strong>权重量化异常，范围在0到1之间。较高的权重表示异常的可能性较大。具体来说，我们首先构造一个图来捕获特征和注册帐户之间的关系，其中每个节点表示一个特征或一个注册帐户，两个节点之间的每条边表示注册帐户具有该特征。<strong><font color="red"> 我们设计了一种统计方法，以无监督的方式初始化构造图中每个节点的权重，并采用基于结构的方法在构造的图中传播节点的初始权重，并迭代更新每个节点的权重。每个注册节点的最终权重可被视为该注册帐户的伪造概率。</font></strong></p>
<p>我们构造用户-特征的二部图来捕获注册帐户和提取特征之间的关系：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522902.png" alt="图片" style="zoom:50%;"></p>
<p>如上图所示。<strong>具体来说，我们用 （R，F，E）来表示这个图</strong>，其中R表示一组注册节点，就是注册用户的意思，F 表示一组特征节点，就是每个F节点都表示某个特征（当然这里的特征都是离散的，连续特征没法直接作为节点需要离散化之后才能作为节点），E，就表示edge了，（因为注册账户节点和特征节点之间都是 注册账户节点“拥有”特征节点 这么一个抽象的关系，所以edge的权重默认均为1.）注册节点和特征节点之间的边表示注册节点，即注册用户具有这个特征。</p>
<p>例如，在上图中， 节点连接了 如“IP32_10.xxx.xxx.10”、“PN_+861585321xxxx”、“OSV_Android 7.0”这三个特征节点，这意味着 注册时，使用IP地址“10.xxx.xxx.10”、电话号码“+861585321xxxx”和手机操作系统版本“Android 7.0”。</p>
<p>特征节点的权重的初始化策略，（<strong>这篇paper的思路是先通过无监督的方法给特征节点的权重进行初始化，然后通过信念传播的方式给注册账户节点进行权重的传播赋值</strong>）。我们设计了一种统计方法，为每个特征节点和每个注册帐户节点分配初始权重，这个过程无需手动打标虚假账户。我们的统计方法依赖于三个概念：<strong><font color="red"> 特征频率、特征比率和特征模式</font></strong>。</p>
<ul>
<li><strong>特征频率</strong>：特征频率表示某个特征有多少个注册账户有，比如有100个注册账户在注册的时候都使用了“IP32_10.xxx.xxx.10”，则“IP32_10.xxx.xxx.10”这个特征节点的特征频率为100；</li>
<li><strong>特征比率</strong>：其实就是同类特征的占比啦。比如说我们的手机号这个特征下有10000个手机号，其中“PN_+861585321xxxx”有5000个，则“PN_+861585321xxxx”这个特征节点的特征比率为0.5.</li>
<li><strong>特征模式：</strong>特征模式不是相对于某个特征节点的，而是对于某个特征下所有的特征节点的，还是举个例子，假设OSV前缀的，即手机系统版本这个特征下有Android 7.0，Android 8.0，Android 9.0，占比分别为0.25，0.25，0.5，则最终我们得到 OSV 这个特征的特征模式为 Android 9.0,其实就是某个特征下某个最大取值对应的特征节点的名字。</li>
</ul>
<p>现在我们可以通过使用上述的特征频率，特征比率和特质模式来定义每个特征的权重。<strong>我们通过定义特征的权重来量化特征的异常。</strong></p>
<p>为了描述清晰，这里还是强调一下，特征频率和特征比率都是针对于特征节点的，而特征模式是针对于某一类特征节点的群体的，以性别为例（因为性别特征就两个取值，比较好理解），性别有男女，则按照上述的思路，我们会有一个 “sex_男”和“sex_女”的这两种特征节点，“sex_男”和“sex_女”的特征频率假设分别60和40，则其特征比率分别为0.6和0.4，性别这个特征的特征模式为0.6.具体地说，是这么做的，首先，我们将所有的特质划分为两个组，一个pre-A，一个pre-B。我们以数据挖掘分析部分的一个case为例：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522966.png" alt="图片"></p>
<p>deviceid的共享情况，这个图解释一下，左边的直方图，横轴表示device id 共享的账户的数量，按照直方图的划分可以知道，每一个device id根据其共享的账户数量打上了标签，分别为“ 0～5”，“5～10”.。。。“&gt;=30”，然后我们统计每一种标签下的device的数量，就是纵轴的取值了，可以看到，deviceid这种东西反映出来的趋势是 deviceid 一般情况下不太可能被多个账户共享，大部分的device 所共享的账户很少，极少部分的deivce id 存在大量账户共享的情况，所以我们把device id 这种特征分到 pre-B 组中去；像ip，phone 这些的反应出来的情况都是一样的，所以都放到pre-B中去了，显然，我们可以知道，放到pre-B中的特征都是不太容易产生高账户共享问题的字段。</p>
<p>原文提到了pre-A中的特征有一个是osv，即手机的版本号，比如android 7.0 ，ios xxx 这类的。pre-A中的特征就是比较容易产生大量账户共享的，比如手机版本，app的版本，时间上的异常等等（<strong>我以前对于这种容易产生大量账户共享的特征都是删除不拿来建图的，因为容易产生很稠密的图，坏处就是损失了一部分信息，这里给到的思路还可以。</strong>）而对于pre-B中的特征，例如phone number 手机号这种东西，一般不太容易被大量的账户共享，那么对于手机号这种特征，其特征节点，例如“861585321xxx” 这个号段，如果被大量账户共享，则我们认为这种情况很异常，因为手机号本上就趋向于被很少的账户共享或不被共享。文中的pre-A和pre-B的选择为：Pre_A={ , ℎ , , }andPre_B={ 32, , , }</p>
<p>我们这么来定义特征节点的权重，可以看到，上述的公式应该是很清晰了，对于pre-A中的特征，特征节点的节点权重为1-ratio（x），即这个特征节点共享的账户越多，越正常，节点权重越小；对于pre-B中的特征，特征节点的权重为ratio（x），即这个特征节点共享的账户越多，越不正常，节点权重越大。</p>
<p><strong><font color="red"> 然而，有一个严重的问题，上述定义的特征节点的权重，不能用于直接比较不同特征下的不同特征节点的节点权重</font></strong>，例如经过这样的计算，android7.0 这样的特征节点和“861585321xxx” 这样的特征节点没有可比性，比如手机系统版本和手机号这两个特征的特征分布，前者的特征比分布是比较集中的（大部分用户都是集中使用比较新的几个版本），而手机号的特征比分布则比较均匀（用户均匀的分配到不同的手机号段上），这个时候算出来的ratio肯定差别很大的。为了解决这个问题，对上图的公式进行优化和重新定义，使用了一种称为类别特征的“特征匹配”的技术（《Guansong Pang, Longbing Cao, and Ling Chen. 2016. Outlier Detection inComplex Categorical Data by Modeling the Feature Value Couplings.. InIJCAI.》），具体来说，是这么做的。</p>
<p>特征节点的节点权重wx的公式转化如下：</p>
<script type="math/tex; mode=display">
w_x=\frac{1}{2}(\operatorname{dev}(x)+\operatorname{base}(x))</script><p>where</p>
<script type="math/tex; mode=display">
\operatorname{dev}(x)= \begin{cases}1-\frac{\operatorname{ratio}(x)}{\text { ratio }(\text { mode }(\text { pre }(x)))} & \text { if } \operatorname{pre}(x) \in \text { Pre-A } \\ 1-\frac{1-\operatorname{Aatio}(x)}{\text { ratio }(\text { mode }(\text { pre }(x)))} & \text { if } \operatorname{pre}(x) \in \text { Pre-B}\end{cases}</script><p>and</p>
<script type="math/tex; mode=display">
\operatorname{base}(x)= \begin{cases}1-\operatorname{ratio}(\operatorname{mode}(\operatorname{pre}(x))) & \text { if } \operatorname{pre}(x) \in \text { Pre-A } \\ \operatorname{ratio}(\operatorname{mode}(\operatorname{pre}(x))) & \text { if } \operatorname{pre}(x) \in \text { Pre-B }\end{cases}</script><p>本质上就是做了一个标准化的操作, 使得不同特征下的特征节点的权重统一到一个量纲下（<strong>对于离散特征的这种权重的处理在图中具有很好的推广作用, 有时间再看看文中提到的这几篇论文, 很不错</strong>)<br>$\operatorname{dev}(\mathrm{x})$ 考虑了特征节点的异常，base $(x)$ 考虑了特征的异常。因为 $\operatorname{dev}(x)$ 的取值必然是0~1之间的， base (x)也必然是0~1之间的, 因此, 最终我们的特征节点权重w $(x)$ 也必然是0~1之间的。然后, 注册账户节点的初始化权重就是和这个注册账户节点连接的所有的特征节点的权重的平均值。</p>
<script type="math/tex; mode=display">
w_r=\frac{\sum_{x \in \Gamma(r) w_x}}{|\Gamma(r)|}</script><p><strong>初始化了权重之后, 使用线性的信念传播来进行特征节点和注册账户节点的权重的更新迭代,</strong></p>
<script type="math/tex; mode=display">
p_u^{(t)}=w_u+2 \sum_{v \in \Gamma(u)}\left(p_v^{(t-1)}-0.5\right) \cdot\left(h_{v u}-0.5\right)</script><p>文中提到了，作者做了10次的迭代来更新所有节点的权重。(<strong>信念传播还不太懂, 暂时可以先理解类似于用户自定义初始权重的个性化pagerank</strong>)</p>
<h4><span id="44-注册信息构图">4.4 注册信息构图</span></h4><p><strong>我们构建了一个加权图来直接捕捉注册账户之间的关联性。构建的图是由注册-特征图而来的</strong>。具体来说, 对于注册特征图中的每一对注册节点 $u, v \in \mathbb{R}$, 我们在 $u$ 和 $v$ 之间创建一条边 $(u, v)$ ，只要 $u$ 和 $v$ 的相似度大于阈值。特别是, 我们把 $u$ 和 $v$ 之间的相似性 $\operatorname{sim}(u, v)$ 定义为 $u$ 和 $v$ 的共享特征的最终权重之和。这背后的直觉是，如果两个注册节点共享许多特征, 而且这些特征的最终权重很大（异常概率大），那么这两个注册 账户也有很大的相似性, 倾向于是假账户。如下图:</p>
<script type="math/tex; mode=display">
\operatorname{sim}(u, v)=\sum_{s \in \Gamma(u) \bigcap \Gamma(v)} p_s</script><p>此外，我们设置了边的权重$(𝑢,𝑣)$ 在新的图中成为相似性$sim(𝑢,𝑣)$. 我们将构建的加权图称为注册图，因为图中的所有节点都是注册帐户。虚假账户更有可能以较大的边缘权重相互连接，良性账户更有可能通过较小的边缘权重稀疏连接。最终我们将注册账户节点-特征节点的异构图转化为了<strong>注册账户节点-注册账户节点的基于相似度的同构图。</strong></p>
<h4><span id="45-社区发现">4.5 <strong>社区发现</strong></span></h4><p>在注册图中，我们注意到虚假账户密集连接，而良性账户稀疏连接。<strong>为了检测欺诈账户，我们需要识别注册图中的密集子图</strong>。自然的选择是利用社区发现算法。我们首先采用社区检测方法，例如<strong>Louvain方法[2]</strong>，将节点分为不同的社区（即密集子图）。其次，我们检测发现出来的社区中的所有注册帐户的数量，如果其大小超过了我们设定的阈值，则认为这个社群中所有的注册账户都是有问题的虚假账户。</p>
<ul>
<li>我们首先采用社区检测方法将节点聚集到不同的社区（即密集子图）。</li>
<li>其次，我们预测社区中所有规模大于阈值的注册账户都是假账户。</li>
</ul>
<h3><span id="五-模型评估">五、模型评估</span></h3><h4><span id="51-实验设置">5.1 实验设置</span></h4><ul>
<li><strong>数据集</strong></li>
</ul>
<p>我们从微信中获得了七个数据集。每个数据集都包括一天内的注册信息。表3显示了这些数据集的细节。这些标签是由微信安全团队提供的，他们手工验证了这些标签（大厂就是牛逼），并发现这些标签的准确率大于95%。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522980.png" alt="图片" style="zoom:50%;"></p>
<ul>
<li><strong>评价指标</strong></li>
</ul>
<p>我们使用三个指标，即<strong>准确率、召回率和 F-score 来评估性能</strong>。对于一个检测方法来说，精确率是其预测的假账户在测试集中为真实假账户的比例，召回率是测试集中真实假账户被该方法预测为假账户的比例，而F分数是精确率和召回率的调和平均值。比较的方法。我们将UFA与几种无监督的变体进行比较，包括UFA-naive、UFA-noLBP、UFA-noRG和超级视觉方法，包括Ianus[35]、XGBoost[6]和深度神经网络（DNN）。</p>
<h4><span id="52-实验结果">5.2 实验结果</span></h4><p>表4显示了ufa在七个数据集上的预测结果。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522407.png" alt="图片" style="zoom:50%;"></p>
<p>UFA可以在所有数据集中检测到约80%的假帐户，其精确度约为90%。一个关键原因是，通过无监督的权重学习和注册图构造，注册图中的假账户连接紧密，而良性账户连接稀疏。</p>
<p>例如，在第五天由构建出来的注册图中（从这里可以看出，腾讯构图的方式是构建天级别的图），平均而言，一个假帐户与22.32个其他假帐户存在连接，而与1个良性账户存在连接，而对于一个良性帐户而言，仅与2.04个其他良性账户相互连接。</p>
<p>然后，Louvain的方法可以很容易地检测到这些密集连接的假帐户。我们发现大约85%的假账户聚集在一起，剩下的15%的假账户是分散的，也就是说，他们与其他人没有共同的特征（这种就没办法了，毕竟ufa是完全从关联上出发去检测的）。因此，根据ufa的80%左右召回表现，证明了其在检测假账户方面的有效性。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522512.png" alt="图片" style="zoom:50%;"></p>
<ul>
<li><h5><span id="相似阈值的影响"><strong>相似阈值的影响</strong></span></h5></li>
</ul>
<p>回顾一下，<strong>UFA预先定义了一对注册账户之间的相似度阈值，以确定两个注册账户之间是否添加了一条边。一个自然的问题是这个相似度阈值对UFA的检测性能有什么影响</strong>。图3a显示了UFA与1.0和1.5之间的相似度阈值的结果。我们观察到，当阈值增加时，精确度增加，召回率下降，而F-Score首先增加，然后下降。原因是较大的阈值使一对注册账户在我们的注册图中更难连接。当使用较高的阈值时，注册图中的连接节点更有可能是假账户，所以我们可以有更高的精度。同时，更少的假账户可以相互连接，因此召回率下降。我们还注意到，当相似度阈值在1.2左右时，F-Score达到最大值。因此，我们在实验中选择默认的相似度阈值为1.2。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522878.png" alt="图片" style="zoom:50%;"></p>
<p>我们观察到，当阈值增加时，精度增加，而F分数先增加后减少。原因是阈值越大，在注册图中连接一对注册帐户就越困难。当使用更高的阈值时，注册图中连接的节点更有可能是假帐户，因此我们可以获得更高的精确度。同时，可以相互连接的假帐户更少，从而减少了recall。我们还注意到，当相似性阈值在1左右时，F分数达到最大值。因此，我们在实验中选择了一个默认的相似性阈值为1.2。</p>
<ul>
<li><h5><span id="社区规模的影响">社区规模的影响</span></h5></li>
</ul>
<p>UFA使用Louvain方法检测社区并预测社区中的注册帐户，这些帐户的大小大于预定义的阈值，即假帐户。我们研究了不同社区规模对UFA的检测性能的影响，结果如图3b所示。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522494.jpeg" alt="图片" style="zoom:50%;"></p>
<p>我们观察到，随着社区规模的阈值变大，精确度和F分数先增加后降低。当阈值大于15时，所有三个指标都是稳定的。所以，我们在实验中选择了社区规模的默认阈值为15。</p>
<h3><span id="六-在微信场景的实际部署">六、<strong>在微信场景的实际部署</strong></span></h3><p>UFA已经被微信部署了一年多，用于检测虚假账户。它是在Spark上用Python实现的，并被部署在微信的内部云计算平台YARD上。UFA以流程模式工作，其部署图如图6所示。具体来说，UFA系统有两个阶段：<strong>系统初始化和系统更新。</strong></p>
<h4><span id="61-系统初始化">6.1 <strong>系统初始化</strong></span></h4><p>微信最初部署时，UFA收集一定数量的注册账号，提取特征，构建注册特征bigraph，学习特征权重和注册帐户，并构建注册图。微信在部署后第一周使用所有注册账号完成系统初始化。初始化后，我们拥有特征节点和注册帐户的权重。系统初始化中的所有步骤都在流式处理服务器上执行。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181522379.png" alt="图片"></p>
<h4><span id="62-系统更新">6.2 <strong>系统更新</strong></span></h4><p>系统初始化后，当WeChatserver收到新的注册帐户时，UFA先提取帐户特征，然后执行以下步骤。</p>
<ul>
<li>在注册特征的Bigraph中创建新节点/边。UFA先为不在当前注册特征的bigraph中的特征创建新注册节点和新特征节点。然后，UFA在注册节点及其特征节点之间创建新边。此步骤在流数据服务器上运行。</li>
<li>在注册图中创建新节点/边。UFA在此步骤中检索与新注册帐户接近的现有注册帐户。具体而言，UFA寻找所有现有注册帐户与新注册帐户之间共享的注册节点。然后，UFA使用特征节点的当前权重计算新注册帐户和找到的注册帐户之间的相似性。接下来，在注册图中，如果两个帐户之间的相似性大于预定义阈值，UFA将为新注册帐户创建一个新节点，并在新注册帐户和找到的每个注册帐户之间创建一条边。此步骤在流式处理服务器上运行。</li>
<li>定期更新特征/注册节点的权重并检测假帐户。<strong>为了减轻计算负担，UFA更新特征/注册节点的权重，并每小时检测一次假帐户</strong>。权重更新和伪造帐户检测都定期在检测服务器上执行。<strong>具体来说，流式处理服务器上的UFA会每小时更新注册-特征节点bigraph和注册-注册节点的同构图，并将这些图保存到数据库中。</strong>然后，从数据库加载图，并运行无监督权重学习算法和社区检测算法来检测假帐户。接下来，UFA将更新的特征/注册节点的权重和检测到的假帐户从检测服务器传输到流处理服务器。检测到的假帐户存储在数据库中。流服务器使用更新的特征/注册节点权重进行下一次定期系统更新。</li>
</ul>
<h4><span id="63-ufa在真实场景中的表现">6.3 <strong>UFA在真实场景中的表现</strong></span></h4><p>微信所有检测到的假帐户，其中一些可能是良性帐户。如果良性帐号被封禁，微信安全团队会收到注册该帐号的用户的投诉。微信使用投诉数量来评估UFA的表现。</p>
<p>具体来说，微信安全团队有6名安全分析师来处理用户的投诉。总体而言，申请解锁账户在被封禁的账户中不到6%。此外，微信安全团队随机抽取了200个被UFA检测到的虚假账户，对UFA的性能进行评估，UFA的精度达到93%，与投诉测得的结果一致。</p>
<p>综上所述，UFA 平均每天检测 50 万个假账户，自 UFA部署以来总共检测到 1.8 亿个假账户（在 4 亿个注册账户中）。</p>
<p>Ianus 在现实世界中的部署限制，在 UFA 之前，微信已经部署了 Ianus [35] 大约六个月。<strong>Ianus 是一种监督式虚假账户检测方法，它也利用了账户的注册信息。然而，Ianus在部署一段时间后就暴露了它的弱点</strong>。</p>
<ul>
<li>首先，手动标记非常耗时。微信安全团队有6名安全分析师，他们的职责是对注册账号进行标记，每个分析师每天可以标记大约1000个注册。人工标注，比如600K个虚假账户，大概需要100天左右，很费时间。很难获得准确的标注，毕竟人也会犯错。许多虚假帐户仅在检查其注册信息，类似于良性帐户。</li>
<li>而在一定数量的噪音标签下，Ianus的性能将下降。</li>
<li>除此之外，需要经常对Ianus进行retraining，以保持较高的检测性能。</li>
</ul>
<p>图7显示了Ianus在连续14天的预测中的表现，不进行retraining。为了简单起见，我们只展示了分数，我们在精度和调用方面也有类似的观察结果。我们看到，Ianua的F-Score从第七天开始大幅下降。68%对55%。92%，在14天内。<strong>一个可能的原因是攻击者不断改变他们的注册模式以逃避Ianus的检测。</strong>因此，基于旧注册模式训练的Ianus不足以检测具有新注册模式的假帐户。为了保持较高的检测性能，需要经常使用新注册模式上的准确标签对Ianus进行重新训练。然而，正如我们上面提到的，它是耗时的，并且很难准确地标记注册帐户，所以靠谱的retraining需要的标签也不多。相比之下，UFA的分数相对稳定，表明UFA在实际部署中要比Ianus更好。</p>
<h3><span id="七-总结">七、 总结</span></h3><p>在本文中，我们开发了一种无监督的方法UFA来检测虚假账户，在他们被注册后立即检测。我们首先提取了揭示假账户异常注册模式的特征，其灵感来自于对微信中真实世界注册数据集的测量研究。然后，我们设计了一种无监督的权重学习算法来学习提取的特征和注册账户的权重。此外，我们构建了一个注册图来直接捕捉注册账户之间的关联性，如虚假账户是密集连接的，而良性账户是稀疏连接的。最后，我们采用了一种社区检测算法，通过分析注册图结构来检测虚假账户。我们使用微信的真实世界数据集对UFA进行了评估。我们的结果显示，UFA取得了94%的精度和80%的召回率。UFA已经被微信部署在检测虚假账户上一年多了，并且达到了93%的精度。</p>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（3）Sophos《Learning from Context: Exploiting and Interpreting File Path Information for Better Malware Detection》</title>
    <url>/posts/3PHFHZZ/</url>
    <content><![CDATA[<h2><span id="learning-from-context-exploiting-and-interpreting-file-path-information-for-better-malware-detection">Learning from Context: Exploiting and Interpreting File Path Information for Better Malware Detection</span></h2><ul>
<li><a href="https://ai.sophos.com/presentations/learning-from-context-a-multi-view-deep-learning-architecture-for-malware-detection/">https://ai.sophos.com/presentations/learning-from-context-a-multi-view-deep-learning-architecture-for-malware-detection/</a></li>
</ul>
<blockquote>
<p>  用于静态可移植可执行（PE）恶意软件检测的机器学习（ML）通常使用每个文件的数字特征向量表示作为训练期间一个或多个目标标签的输入。然而，可以从查看文件的上下文中收集到许多正交信息。在本文中，我们<strong>建议使用静态上下文信息源（PE文件的路径）作为分类器的辅助输入</strong>。虽然文件路径本身不是恶意或良性的，但它们确实为恶意/良性判断提供了有价值的上下文。与动态上下文信息不同，文件路径的可用开销很小，并且可以无缝集成到多视图静态ML检测器中，在非常高的吞吐量下产生更高的检测率，同时基础结构的更改也很小。在这里，我们提出了一种多视图神经网络，它从PE文件内容以及相应的文件路径中提取特征向量作为输入并输出检测分数。为了确保真实的评估，我们使用了大约1000万个样本的数据集—来自实际安全供应商网络的用户端点的文件和文件路径。<strong>然后，我们通过LIME建模进行可解释性分析，以确保我们的分类器已学习到合理的表示，并查看文件路径的哪些部分对分类器得分的变化贡献最大</strong>。我们发现，我们的模型学习了文件路径的有用方面以进行分类，同时还学习了测试供应商产品的客户的工件，例如，通过下载恶意软件样本目录，每个样本都命名为其哈希。我们从我们的测试数据集中删减了这些工件，并证明在10−3假阳性率（FPR），10时为33.1%−4 FPR，基于类似拓扑的单输入PE文件内容模型。</p>
</blockquote>
<h3><span id="摘要">摘要</span></h3><p>用于恶意软件检测的机器学习（ML）分类器通常在进行恶意/良性判断时使用每个文件内容的数字表示。<strong>然而，也可以从文件所在的上下文中收集相关信息，这些信息通常被忽略。<font color="red"> 上下文信息的一个来源是文件在磁盘上的位置。</font></strong>例如，如果检测器可以清楚地利用有关其所在路径的信息，则伪装为已知良性文件（例如Windows系统DLL）的恶意文件更有可能显得可疑。了解文件路径信息还可以更容易地检测那些试图通过将自己放置在特定位置来逃避磁盘扫描的文件**。文件路径也可以使用，开销很小，并且可以无缝集成到多视图静态ML检测器中，在非常高的吞吐量和最小的基础结构更改下，可能产生更高的检测率。</p>
<p>在这项工作中，我们提出了一种 <strong>multi-view</strong> 深度神经网络结构，该结构将PE文件内容中的特征向量以及相应的文件路径作为输入并输出检测分数。我们对大约1000万个样本的商业规模数据集进行了评估，这些样本是来自实际安全供应商提供服务的用户端点的文件和文件路径。<strong>然后，我们通过LIME建模进行可解释性分析，以确保我们的分类器已学习到合理的表示，并检查文件路径如何在不同情况下改变分类器的分数</strong>。我们发现，与只对PE文件内容进行操作的模型相比，<strong>我们的模型学习了文件路径的有用方面，在0.001假阳性率（FPR）下，真阳性率提高了26.6%，在0.0001 FPR下，提高了64.6%</strong>。</p>
<p><strong>keyword</strong> : 静态PE检测、文件路径、深度学习、多视图学习、模型解释</p>
<h3><span id="一-说明">一、说明</span></h3><p>商用便携式可执行（PE）恶意软件检测器由静态和动态分析引擎组成。<strong>静态检测通常首先用于标记可疑样本，它可以快速有效地检测大部分恶意软件</strong>。它涉及分析磁盘上的原始PE映像，可以非常快速地执行，但易受代码混淆技术的影响，例如压缩和多态/变形转换<strong>[1]</strong>。相比之下，动态检测需要在模拟器中运行PE，并在运行时分析行为[2]。当动态分析工作时，它不太容易受到代码混淆的影响，但与静态方法相比，它需要更大的计算容量和执行时间。此外，有些文件很难在仿真环境中执行，但仍然可以进行静态分析。<strong>因此，静态检测方法通常是端点恶意软件预防（在执行恶意软件之前阻止恶意软件）管道中最关键的部分</strong>。最近，由于采用了机器学习，静态检测方法的性能有所提高[3]，其中高度表达的分类器（例如深层神经网络）适合于数百万个文件的标记数据集。训练这些分类器时，它们使用静态文件内容作为输入，但不使用辅助数据。<strong>然而，我们注意到，由于辅助数据（例如网络流量、系统调用等），动态分析工作得很好。</strong>在这项工作中，我们试图使用文件路径作为正交输入信息来增强静态ML检测器。<strong>文件路径是静态可用的，无需操作系统的任何附加工具</strong>。通过将文件路径作为辅助输入，我们希望能够将有关文件的信息与在特定位置看到此类文件的可能性的信息结合起来，<strong>并识别与已知恶意软件和良性文件相关的常见目录层次结构和命名模式。</strong></p>
<blockquote>
<p>  <strong>静态检测</strong>：通用模块，快速有效地标记可疑样本；易受代码混淆技术（压缩和多态/变形转换）的影响。</p>
<p>  [1] A. Moser, C. Kruegel, and E. Kirda, “Limits of static analysis for malware detection,” in Twenty-Third Annual Computer Security Applications Conference (ACSAC 2007). IEEE, 2007, pp. 421–430.</p>
<p>  <strong>动态检测</strong>：分析模块，需要更大的计算容量和执行时间；有些文件很难在仿真环境中执行。</p>
</blockquote>
<p>我们将分析重点放在三个模型上：</p>
<ul>
<li>仅基线文件内容（PE）模型，仅将PE功能作为输入并输出恶意软件置信度得分。</li>
<li>另一个基准文件路径仅内容（FP）模型，仅将文件的文件路径作为输入，并输出恶意软件置信度得分。</li>
<li>我们提出的多视图PE文件内容+上下文文件路径（PE+FP）模型，该模型同时考虑PE文件内容特征和文件路径，并输出恶意软件置信度得分。</li>
</ul>
<p>三个模型的示意图如图1所示。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181509919.png" alt="image-20220528162748125" style="zoom:50%;"></p>
<p>我们对从一家大型反恶意软件供应商的遥测数据中收集的时间分割数据集进行分析，发现我们在文件内容和上下文文件路径上训练的分类器在ROC曲线上，尤其是在低误报率（FPR）区域，产生了统计上显著更好的结果。</p>
<p><strong>本文的贡献如下：</strong></p>
<ul>
<li>我们从安全供应商的客户端点（而不是恶意软件/供应商标签聚合服务）获得一组真实、精心策划的文件和文件路径数据集。</li>
<li>我们证明，我们的多视图PE+FP恶意软件分类器在我们的数据集上的性能明显优于单独使用文件内容的模型。</li>
<li>我们将本地可解释模型不可知解释（LIME）<strong>[4]</strong>扩展到PE+FP模型，并使用它分析文件路径如何影响模型的恶意/良性决策。</li>
</ul>
<blockquote>
<p>  [4] M. T. Ribeiro, S. Singh, and C. Guestrin, “Why should i trust you?: Explaining the predictions of any classifier,” in Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 2016, pp. 1135–1144.</p>
</blockquote>
<p>本手稿的其余部分结构如下：第二节涵盖重要的背景概念和相关工作。第三节讨论数据集收集和模型制定。第四节将我们的新多视图方法与拓扑结构相似的纯内容基线模型进行了比较，并对我们的模型进行了可解释性分析。第五节结束。</p>
<h3><span id="二-背景和相关工作">二、背景和相关工作</span></h3><p>在本节中，我们将描述机器学习如何普遍应用于静态PE检测，以及我们的方法如何通过提供上下文信息作为辅助输入而在高层意义上有所不同。然后，我们介绍了其他机器学习领域的相关工作。</p>
<h4><span id="21-静态ml恶意软件检测">2.1 静态ML恶意软件检测</span></h4><p>机器学习已经应用于计算机安全领域多年了[5]，但在商业规模上使用ML的静态PE模型的破坏性性能突破是一个较新的现象。商业模型通常依赖深度神经网络[6]或增强的决策树集合[7]，并已扩展到其他静态文件类型，包括web内容[8]、[9]、office文档[10]和档案[10]。</p>
<p>大多数用于信息安全的静态ML（ML-Sec）分类器操作的是文件部分（例如，标题）上的学习嵌入[11]，整个文件上的学习嵌入[12]，或者最常见的是，操作的是设计用于总结每个文件内容的预设计数字特征向量[6]、[13]–[19]。预先构建的特征向量表示往往更具可伸缩性，可以快速从每个文件中提取内容，同时保留有用的信息。有很多方法可以构建特征向量，包括在滑动窗口上跟踪每字节统计信息【6】、【18】、字节直方图【7】、【18】、ngram直方图【13】、将字节视为图像中的像素值（文件内容的可视化）【13】、【18】、操作码和函数调用图统计信息【18】、符号统计信息【18】、哈希/数字元数据值【6】、【7】、【18】–例如。，入口点作为文件的一部分，或散列导入和导出，以及分隔标记的散列[10]、[19]。在实际应用中，从文件内容中提取的几种不同类型的特征向量通常连接在一起，以获得优异的性能。</p>
<h4><span id="22-learning-from-multiple-sources">2.2 Learning from Multiple Sources</span></h4><p>使用深度神经网络进行静态ML恶意软件检测的相关研究已经检验了从多个信息源学习的方法，但这些方法与我们的方法有根本不同：Huang等人【20】和Rudd等人【21】对多个辅助损失函数使用多目标学习【22】，【23】，他们发现这些函数在主要恶意软件检测任务中的性能有所提高。这两项工作都在培训期间使用元数据作为辅助目标标签，为模型提供额外的信息，并在部署时使用单个输入来做出分类决策。我们的方法利用了多种输入类型/模式——一种是以类似于[6]的PE特征向量的形式描述恶意样本的内容，另一种是将原始字符串提供给一个字符嵌入层（类似于[8]），该层提供了有关该样本出现位置的信息。这种技术是一种多视图学习方法[24]。顾名思义，多视图学习的大多数应用都是在计算机视觉中进行的，在计算机视觉中，多个视图实际上是由来自不同输入摄像头/传感器的视图或来自同一摄像头/传感器在不同时间的不同视图组成的。<strong>在ML-Sec空间中，我们只能找到两种专门将自己称为多视图的方法：即[25]，Narayanan等人将多内核学习依赖图应用于Android恶意软件分类，以及[26]，</strong>Bai等人将多视图集合用于PE恶意软件检测。虽然这些方法在某些方面与我们的方法相似，但据我们所知，我们是第一个在商业规模上使用外部上下文反馈到深层神经网络并结合文件内容特征来执行恶意软件检测多视图建模的方法。</p>
<blockquote>
<p>  [25] A. Narayanan, M. Chandramohan, L. Chen, and Y. Liu, “A multi-view context-aware approach to android malware detection and malicious code localization,” Empirical Software Engineering, pp. 1–53, 2018.</p>
<p>  [26] J. Bai and J. Wang, “Improving malware detection using multi-view ensemble learning,” Security and Communication Networks, vol. 9, no. 17, pp. 4227–4241, 2016.</p>
</blockquote>
<h3><span id="三-实施细节">三、实施细节</span></h3><p>在本节中，我们将介绍我们的方法的实现细节，包括从客户端点获取PE文件和文件路径的数据收集过程、我们的特征化策略以及我们的多视图深度神经网络和比较基线的体系结构。</p>
<h4><span id="31-数据集">3.1 数据集</span></h4><p>在我们的实验中，我们从一家著名反恶意软件供应商的遥测数据中收集了三个不同的数据集：一个训练集、一个验证集和一个测试集。培训集由9148143个样本组成，这些样本首次出现在2018年6月1日至11月15日之间，其中693272个样本被标记为恶意样本。验证集包括在2018年11月16日至12月1日期间观察到的2225094个不同样本，其中85041个被标记为恶意样本。最后，测试集在2019年1月1日至1月30日期间共有249783个样本，其中38767个被标记为恶意。这些文件的恶意/良性标签是使用类似于[6]、[8]的标准计算的，但结合其他专有信息可以生成更准确的标签。</p>
<h4><span id="32-特征工程">3.2 特征工程</span></h4><p><strong>为了使用文件路径作为神经网络模型的输入，我们首先将可变长度字符串转换为固定长度的数字向量</strong>。我们使用类似于<strong>[8]</strong>的矢量化方案来实现这一点，方法是在每个字符上创建一个键控的查找表，该表用一个表示每个字符的数值（介于0和字符集大小之间）来表示。实际上，我们将此表实现为Python字典。在遥测和早期实验数据的指导下，我们将文件路径缩减到最后100个字符。短于100个字符的文件路径的功能用零填充。对于字符集，我们考虑整个Unicode字符集，但将词汇限制为150个最常见的字符。见附录？？供进一步讨论。作为PE文件内容的特征，我们使用了由四种不同特征类型组成的浮点1024维特征向量，类似于[6]。总的来说，我们将每个样本表示为两个特征向量：<strong>1024维的PE内容特征向量和100维的上下文文件路径特征向量。</strong></p>
<blockquote>
<p>  [8] J. Saxe and K. Berlin, “expose: <strong>A character-level convolutional neural network with embeddings for detecting malicious urls, file paths and registry keys</strong>,” arXiv preprint arXiv:1702.08568, 2017.</p>
<p>  <img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181509845.png" alt="image-20220530152922273" style="zoom: 25%;"></p>
</blockquote>
<h4><span id="33-网络体系结构">3.3 网络体系结构</span></h4><p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181509415.png" alt="image-20220528204724740" style="zoom:50%;"></p>
<p>我们的多视图体系结构如图2所示。该模型有两个输入，<strong>1024个元素的PE内容特征向量xPE和100个元素的文件路径整数向量xFP</strong>，如第III-B节所述。每个不同的输入分别通过一系列具有各自参数θPE和θFP的层，用于PE特征和FP用于文件路径特征，并在训练期间联合优化。然后将这些层的输出连接（串联）并通过一系列最终隐藏层，即参数θO的联合输出路径。网络的最终输出由密集层和sigmoid激活组成。</p>
<ul>
<li><strong>PE 特征</strong>：PE输入臂θPE使xPE通过一系列块，每个块由四层组成：一个完全连接的层，一个使用[27]中所述技术实现的层规范化层，一个丢失概率为0.05的丢失层，以及一个校正线性单元（ReLU）激活。其中五个块依次连接，密集层大小分别为1024、768、512、512和512个节点。</li>
<li><strong>文件路径</strong>：<ul>
<li>文件路径输入arm θFP 将 xFP（<strong>长度为100的向量</strong>）传递到嵌入层 ？？？</li>
<li><strong>该嵌入层将文件路径的每个字符转换为32维向量，从而为整个文件路径生成100x32的嵌入张量</strong>。</li>
<li><strong>然后将该嵌入馈入4个单独的卷积块</strong>，其中包含一个具有128个滤波器的1D卷积层、一个层归一化层和一个1D求和层，以将输出平坦化为向量。4个卷积块包含卷积层，卷积层的大小分别为2、3、4和5，用于处理2、3、4和5克的输入文件路径。</li>
<li>然后将这些卷积块的平坦输出<strong>串联</strong>起来，作为大小为1024和512个神经元的两个密集块的输入（与PE输入臂中的形式相同）。</li>
</ul>
</li>
<li><strong>输出层</strong>：PE arm和文件路径arm的完全连接块的输出随后被连接并传递到由θO参数化的联合输出路径。该路径由层大小为512、256和128的密集连接块（与PE输入arm中的形式相同）组成。然后将这些块的128D输出馈送至致密层，该致密层将输出投射至1D，然后进行sigmoid激活，以提供模型的最终输出。</li>
</ul>
<p>仅PE模型只是PE+FP模型，但没有FP臂，输入xPE并拟合θPE和θO参数。类似地，FP模型是PE+FP模型，但没有3个授权的许可PE arm，采用输入xFP拟合θFP和θO参数。适当调整输出子网络的第一层，以匹配前一层的输出。我们使用二进制交叉熵损失函数拟合所有模型。给定标签为y的输入x的深度学习模型f（x；θ）的输出∈ {0，1}，模型参数θ损失为：</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220528171648185.png" alt="image-20220528171648185" style="zoom:50%;"></p>
<p>通过优化器，我们求解ˆθ的最佳参数集，以最小化数据集上的组合损失：</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220528171710886.png" alt="image-20220528171710886" style="zoom:50%;"></p>
<p>其中M是数据集中的样本数，y（i）和x（i）分别是第i个训练样本的标签和特征向量。我们使用Keras框架构建和训练模型，使用Adam优化器和Keras的默认参数和1024个小批量。每个模型都经过15个阶段的训练，我们确定这些阶段足以使结果收敛。</p>
<h3><span id="4-实验分析">4、实验分析</span></h3><p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181509685.png" alt="image-20220528172252766" style="zoom:50%;"></p>
<h3><span id="5-总结">5、总结</span></h3><p>我们已经证明，深度神经网络恶意软件检测器可以从合并来自文件路径的上下文信息中获益，即使这些信息本身不是恶意或良性的。<strong>将文件路径添加到我们的检测模型中不需要任何额外的端点检测，并且在整个相关FPR区域的总体ROC曲线中提供了统计上显著的改善</strong>。我们直接在客户端点分布上测量模型的性能这一事实表明，我们的多视图模型实际上可以部署到端点以检测恶意软件。我们在第IV-B节中进行的LIME分析表明，多视图模型能够提取暗示实际恶意/良性概念的上下文信息；不只是数据集的统计伪影，尽管正如我们所观察到的，它还可以学习这些伪影。除了端点部署之外，这项研究可以应用的另一个潜在领域是端点检测和响应（EDR）环境，在该环境中，我们的模型的输出可以用于根据事件的可疑程度对磁盘上的事件进行排序。有趣的是，石灰等技术在这方面也有应用。使用从LIME或类似方法得出的解释，可以创建分析工具，允许非恶意软件/取证专家的用户执行某种程度的威胁搜寻。如图4所示，重要性突出显示不仅对用户有用，而且是最近邻/相似性可视化方法的替代方法，该方法不会显示其他用户的潜在可识别信息（PII）。</p>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（4）阿里云-郑翰-安全智能应用</title>
    <url>/posts/1CZSV4N/</url>
    <content><![CDATA[<h2><span id="安全智能应用的一些迷思"></span></h2><h4><span id="1-文章主旨">1、文章主旨</span></h4><p>本文是一个面向安全学术圈和工业界同行的介绍性和探讨性议题，议题的前半部分会介绍一些工业实践中被证明有效的落地实践，后半部分更多地是希望抛砖引玉，通过抽象和定义最新的问题，吸引更多学术研究员的关注和合作。</p>
<h4><span id="2-目前可以做到哪些">2、目前可以做到哪些</span></h4><p>第一部分，本次演讲从目前工业界中智能算法的一些落地实践情况切入说起，总结目前智能安全从概念到落地的应用情况，主要目的是希望阐述，有哪些问题是已经得到解决，或者部分解决的，包括:</p>
<ol>
<li><strong>在海量、富类型的样本集支持下，现有的深度学习和机器学习框架已经可以很好的实现有监督学习和预测的目标</strong>，复杂模型结构层面的调整对最终结果的提升非常有限，更多的瓶颈是在如何发现更多的打标数据上，即<strong>样本集概率空间覆盖度问题</strong>。</li>
<li><strong>文本内容检测</strong>是现在落地应用最多的场景之一(例如<strong>WAF</strong>、<strong>Webshell检测</strong>、<strong>二进制病毒检测</strong>、<strong>网页敏感内容检测</strong>、<strong>明码流量检测</strong>等)，<strong>传统的NLP和图形领域的特征工程和建模方法可以较好发挥作用</strong>。</li>
<li>针对<strong>简单场景问题</strong>(例如<strong>暴力破解攻击检测</strong>、<strong>异地登录检测</strong>、<strong>真实入侵证据发现</strong>)，<strong>简单统计</strong>和<strong>假设检验</strong>可以发挥较好作用。</li>
<li><strong>时序建模</strong>和<strong>时序异常检测算法</strong>在<strong>ddos、cc、定点API接口爆破检测</strong>上可以发挥较好效果，但受限于安全领域中存在较多的突然性、偶然性事件，时序周期性假设常常无法成立，这点极大限制了时序异常检测算法在安全领域内的应用。</li>
<li><strong>相似性匹配算法</strong>(例如<strong>simhash、ssdeep、kmeans</strong>)目前的主要落地场景主要是，扩展原有规则模型的泛化能力。纯粹无监督的相似性聚类由于缺乏可解释性，目前更多用于辅助专家决策。</li>
</ol>
<p>总结来说，当前工业界和学术界智能算法的应用可以综合概括为，”<strong>基于历史经验样本下的的拟合学习</strong>“，即”<strong>基于知识的对抗</strong>“，机器学习在其中充当的角色更多地是一种记忆学习，缺点是难以提供更多的泛化检测和0day发现能力。</p>
<h4><span id="3-还未解决的难题">3、还未解决的难题</span></h4><p>第二部分，笔者希望将我们在企业一线工作的经历进行总结和抽象，将目前智能安全中的一些未解决问题，用学术课题的方式明确地定义出来，将智能安全中的问题转化为学术研究课题，目标是争取更广大的国内科研高效和机构的研究力量，将更多的研究重点投入在实际的问题上，避免对历史老问题的重复研究和建设，包括:</p>
<ol>
<li><strong>安全风险定量评估函数建模</strong>: 以恶意样本检测为例，恶意样本检测0day发现能力(对未知的未知发现能力)本质上是一个搜索优化问题，如何对每一个样本的威胁性(值越大表示恶意性越大，0或负值表示是正常样本)进行定量的定义和分析，是问题的关键。<strong>定义了明确的量化损失函数，恶意样本的检测就会从有监督学习问题转化为搜索优化问题。</strong></li>
<li><strong>基于威胁性定量评估损失函数下的随机搜索问题</strong>: 在基于对各个场景建立了明确的损失函数(例如某个ttp的风险分值、某个http payload的恶意分值、某个文本文件的恶意分值)之后。接下来的工作就是结合安全问题的特点，开发针对性的优化搜索算法，例如<strong>蒙特卡洛搜索</strong>、<strong>随机梯度下降搜索</strong>。</li>
<li>非完整观测下的复杂事件动态推理过程: 入侵检测是安全攻防领域一个很重要的问题，这个问题本质上是一个<strong>复杂事件马尔科夫推理过程</strong>，各种日志采集点代表了可观测量，但实际情况是，我们永远不可能获得一个安全事件的完整观测视角(受限于日志采集的种类和完整性)。所以安全研究员要解决的问题是，<strong>如果在不完整观测的条件下，进行贝叶斯信念网络的建模，并基于该信念网络进行复杂事件推理</strong>。</li>
<li><strong>模型衰减对抗问题</strong>: 类似于自然界所有物理都在朝着熵增的方向演进，安全攻防中的所有模型都存在”性能衰退“的问题，在开发测试阶段完美适配了当前问题场景的模型在上线运行一段时间后，面临误报和漏报的风险会不断提高。</li>
<li>针对攻击入侵链路回溯的有向无环图推理问题: 入侵回溯场景中面对的主要问题有如下几不同事件节点之间的因果依赖推导: 因为攻击在逻辑上是存在逻辑先后关系的多条路径(攻击事件链路)的合并: 一台机器可能不只遭到一次和一个攻击者的攻击异构节点的融合: 一次成功的入侵回溯包括对已知告警节点的因果串联，以及融合其他可以提供更多线索证据的日志节点这两项工作子图融合: 从不同的日志视角可能获得多条攻击链路，入侵回溯师需要能够识别出其中的底层联系，将多条攻击链路合成到一个大的攻击视角中，为后续的决策提供更丰富的攻击者和攻击面信息。</li>
</ol>
<h4><span id="4-我们目前在尝试的项目">4、我们目前在尝试的项目</span></h4><p>第三部分，笔者会介绍一些目前我们公司团队在进行的课题研究方向，包括，</p>
<ol>
<li>通过LSTM自动生成webshell黑样本</li>
<li>基于<strong>GAN网络绕过</strong>现有深度学习AV检测模型</li>
<li>基于<strong>遗传优化算法</strong>的的自动化0day样本生成</li>
<li><strong>基于贝叶斯信念网络的入侵回溯推理</strong></li>
<li><strong>==通过攻击链路中已回溯出来的信息（进程、网络、文件）横向关联其他被这个团伙入侵的机器，然后继承他们的入侵原因==</strong></li>
</ol>
<h4><span id="5-历史外部演讲">5、历史外部演讲</span></h4><ul>
<li>《云环境自动化入侵溯源实战》, KCon 2019 <a href="http://link.zhihu.com/?target=https%3A//static.cdxy.me/201908-%E4%BA%91%E7%8E%AF%E5%A2%83%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E4%BE%B5%E6%BA%AF%E6%BA%90%E5%AE%9E%E6%88%98-KCon.pdf">[slides]</a></li>
<li>“Hunting zero-days for millions of websites on Alibaba Cloud”, XCon 2019 <a href="http://link.zhihu.com/?target=https%3A//static.cdxy.me/XCON-2019-EN.pdf">[slides]</a></li>
<li>“Webshell Detection via Attention-Based Opcode Sequence Classification”, Artificial Intelligence for Business Security Workshop (AIBS @ IJCAI-19). Macao, CN. 10-12 Aug 2019. <a href="http://link.zhihu.com/?target=https%3A//static.cdxy.me/AIBS_2019_paper_3.pdf">[paper]</a></li>
<li>“Enhance Security Awareness with Data Mining”, BlueHat Shanghai 2019</li>
<li><a href="http://link.zhihu.com/?target=https%3A//www.butian.net/datacon">[DataCon 2019]</a> 1st place solution of malicious DNS traffic &amp; DGA analysis. <a href="http://link.zhihu.com/?target=https%3A//www.cdxy.me/%3Fp%3D806">[writeup]</a></li>
<li>《企业安全数据分析思考与实践》, FreeBuf公开课 <a href="http://link.zhihu.com/?target=http%3A//static.cdxy.me/data-knowledge-action_cdxy.pdf">[slides]</a></li>
<li>《从数据视角探索安全威胁》, 先知白帽大会2018 <a href="http://link.zhihu.com/?target=https%3A//xzfile.aliyuncs.com/upload/zcon/2018/10_%E4%BB%8E%E6%95%B0%E6%8D%AE%E8%A7%86%E8%A7%92%E6%8E%A2%E7%B4%A2%E5%AE%89%E5%85%A8%E5%A8%81%E8%83%81_cdxy.pdf">[slides]</a></li>
</ul>
<h2><span id="企业安全数据分析实践与思考">企业安全数据分析实践与思考</span></h2><p><a href="https://live.freebuf.com/detail/c5e504cf96a4e1826a609553bf6054f9">https://live.freebuf.com/detail/c5e504cf96a4e1826a609553bf6054f9</a></p>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（5）蚂蚁安全-柳星《FXY：Security-Scenes-Feature-Engineering-Toolkit》</title>
    <url>/posts/2A4A099/</url>
    <content><![CDATA[<h2><span id="fxysecurity-scenes-feature-engineering-toolkit">FXY：<em>Security-Scenes-Feature-Engineering-Toolkit</em></span></h2><blockquote>
<p>  <a href="https://github.com/404notf0und/FXY/blob/master/docs/%E9%9C%80%E6%B1%82%E5%92%8C%E8%AE%BE%E8%AE%A1.md">https://github.com/404notf0und/FXY/blob/master/docs/%E9%9C%80%E6%B1%82%E5%92%8C%E8%AE%BE%E8%AE%A1.md</a></p>
</blockquote>
<h3><span id="介绍">介绍</span></h3><p>FXY是一款特征工程框架，用于安全场景中数据预处理、数据预分析、数据特征化和向量化等任务。FXY这个名字一方面代表这款工具的目的是从原始安全数据中获取Feature X和Feature Y用于对接人工智能算法，另一方面寓意着人工智能的本质，函数Y=F(X)。FXY的特性是支持多种安全场景多种安全数据的预处理和特征化，内置多种NLP通用特征提取方法，内置脚本扩展支持二次开发。</p>
<h3><span id="需求">需求</span></h3><p>无论机器学习、深度学习还是强化学习应用在哪个领域，<strong>其处理流程主要有五个环节：问题-&gt;数据-&gt;特征化-&gt;算法-&gt;结果</strong>，数据的数字化，狭义的来说是数据的特征化，在整个流程中起到了承上启下的关键作用，承上，<strong>特征化的好坏直接反映了对问题本质的理解深入与否</strong>，启下，作为算法的输入，一定程度上决定了最终结果的天花板。这是FXY定位于安全场景下特征工程环节的一点原因。另一点原因是考虑到算法环节的不确定性因素和确定性因素，不确定性因素导致难以形成统一的范式，确定性因素导致问题已被解决。就算法的应用来说，机器学习算法、深度学习算法和超参数众多，在同一特征化方法下，难以客观比较不同算法的性能，并且找到泛化性强的SOTA算法。<strong>就算法本身来说，现有的框架tensorflow、keras等对算法的封装已经很完美了，重复造轮子意义不大。如果给算法环节盖上安全场景的帽子，问题依然如此，这是FXY不选择定位于安全场景下算法环节的原因。</strong></p>
<h3><span id="架构设计">架构设计</span></h3><p><img src="https://i.imgur.com/d2Rq9hc.png" alt></p>
<p>因为机器学习解决安全问题的流程固定为安全问题-&gt;数据-&gt;数字化-&gt;算法-&gt;结果，<strong>具体到FXY的架构设计，从下到上依次是安全场景层-&gt;数据的数据层-&gt;数据清洗层-&gt;特征层-&gt;算法层-&gt;API层</strong>，对应的FXY各模块层次结构依次为内置函数模块-&gt;数据预处理模块-&gt;特征工程模块-&gt;tensorflow/keras-&gt;控制器模块。</p>
<p>扩展可扩展的，因为安全场景较多且杂，完全不可能用一种或少数几种特征方法解决所有问题，想到的一种解决方式是针对安全问题做特征方法的插件化扩展，把每个安全问题对应每个CMS，每个feature engineering方法对应每个POC，那么就可以像写CMS POC一样专注于安全场景的底层数据feature engineering。</p>
<h3><span id="集成">集成</span></h3><p>笔者Github上AI-for-Security-Learning仓库专注于知识，而此FXY仓库专注于工具，现依赖前者仓库，笔者开始二刷，站在前人的肩膀上，不断集成优质方法到FXY框架中，此框架不做未知的创新。现已集成4种安全场景，4种特征工程方法，四种安全场景分别是<strong>LSTM识别恶意HTTP请求@cdxy，AI-Driven-WAF@exp-db，Phishing URL Classification@surajr，使用深度学习检测XSS@Webber，基于深度学习的恶意样本行为检测@ApplePig@360云影实验室</strong>，四种特征工程方法分别是<strong>钓鱼url的统计特征，恶意url和恶意软件api的词典索引特征，恶意url的TF-IDF特征，xss的word2vec词嵌入向量</strong>。</p>
<p>在二刷并集成的过程中，需要彻底读懂原作者的文章思路和代码，然后改写到FXY限定的框架中，学到了很多。同时输出一份二刷笔记，里面不但包括已集成代码到框架中的原文理解，还包括一些暂时无法集成的文章的理解，文档化记录了原作者用到的安全场景、解决的思路、数据的构成、数据预处理方法、特征的方法、使用的模型、有无监督分类，二刷笔记持续更新。</p>
<h3><span id="潜在问题">潜在问题</span></h3><p><strong>FXY框架专注于安全问题、数据和特征化三个环节</strong>:这其中数据环节存在数据源难获取的问题，有些文章中的数据属于公司级数据不会开源，较难获取，这导致只能使用开源数据集或自己采集数据集复现原作者的实验，集成并测试框架，虽说不会影响FXY框架的预处理、预分析和特征化等主要功能，但这会导致数据环节数据本身的价值变小，一定程度上减小了FXY框架的价值，因为可能大多数人遇到的问题不是没有方法，而是没有数据，数据本身的价值和数据分析的价值都很高，前者价值甚至大于后者。而CMS的POC框架可以靠各种搜索引擎和爬虫来获取数据源，输送给POC脚本，就不会存在此问题。</p>
<p>这促使我们是不是可以通过爬虫爬取更多异源开源数据，用开源弥补闭源，或是本地搭建环境采集数据，缓解数据源缺失的问题，从而使FXY框架的价值不只在于数据分析，更在于数据集本身，采集数据集是个脏活累活，在规划中。</p>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（2）CrowdStrike《无文件攻击白皮书》解析</title>
    <url>/posts/17SDQ9V/</url>
    <content><![CDATA[<h2><span id="the-forrester-wavetm-endpoint-detection-and-response-providers-q2-2022"><strong>The Forrester Wave™: Endpoint Detection And Response Providers, Q2 2022</strong></span></h2><p>在我们对端点检测和响应提供商的 20 个标准评估中，我们确定了 15 个最重要的——Bitdefender、BlackBerry Cylance、Check Point Software Technologies、CrowdStrike、Cybereason、Elastic、FireEye、Fortinet、McAfee、Microsoft、Palo Alto Networks、SentinelOne 、Sophos、趋势科技和 VMware Carbon Black — 并对它们进行了研究、分析和评分。该报告显示了每个供应商如何衡量并帮助安全专业人员根据他们的需求选择合适的供应商。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181505869.png" alt="image-20220426183404208" style="zoom: 33%;"></p>
<h1><span id="crowdstrike无文件攻击白皮书解析">CrowdStrike《无文件攻击白皮书》解析</span></h1><blockquote>
<p>  原文链接：<a href="https://www.secrss.com/articles/26671">https://www.secrss.com/articles/26671</a></p>
</blockquote>
<p>CrowdStrike是端点保护平台（EPP）的最强者，是云交付的下一代端点保护的领导者。由于CrowdStrike邮件推送了“<strong>无文件攻击白皮书</strong>”《谁需要恶意软件？<strong>对手如何使用无文件攻击来规避你的安全措施</strong>》（Who Needs Malware? How Adversaries Use Fileless Attacks To Evade Your Security），笔者顺手对其进行了<strong>全文翻译</strong>。</p>
<p><strong>无文件攻击（Fileless attack）</strong>是<strong>不向磁盘写入可执行文件</strong>的攻击方法，难以被常规方法检测出来。根据CrowdStrike统计，“10个成功突破的攻击向量中有8个使用了无文件攻击技术。”即 <strong>80%的成功入侵都使用了无文件攻击</strong> <strong>。</strong> 根据二八原理，这显然是安全人员应该高度关注的技术类型。</p>
<p><strong>无文件攻击白皮书</strong>解释了<strong>无文件攻击的工作原理、传统解决方案失效的原因，以及CrowdStrike解决该难题的方法</strong>。CrowdStrike的解决方案是<strong>应用程序清单、漏洞利用阻断、攻击指标（IOA）、托管狩猎、无签名人工智能等技术的集成化方法</strong>。</p>
<p>除了全文翻译外，笔者主要在文末做了两块内容增补：一是关于CrowdStrike<strong>Threat Graph（威胁图</strong>）的技术思想<strong>，因为威胁图 是 CrowdStrike Falcon（猎鹰）端点保护平台的“ </strong>大脑” ；二是 关于CrowdStrike提出的<strong>攻击指标</strong>（IOA）<strong>与传统的失陷指标（IOC）</strong>的对比。<strong>笔者认为，这两类技术领域具有战略价值</strong>。如果说全文翻译只花费一小时的话，这些增补内容反而消耗了笔者两个小时。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181505079.png" alt="img" style="zoom:33%;"></p>
<p>随着安全措施在检测和阻止恶意软件和网络攻击方面越来越出色，对手和网络犯罪分子被迫不断开发新技术来逃避检测。其中一种高级技术涉及<strong><font color="red"> “无文件”（fileless）攻击，即不向磁盘写入可执行文件。</font></strong>这类攻击特别有效地躲避了传统防病毒（AV）解决方案，因为传统防病毒（AV）方法寻找被保存到磁盘上的文件并扫描这些文件以确定它们是否恶意。</p>
<p>虽然无文件攻击并不新鲜，但它们正变得越来越普遍。在2016年的调查中，CrowdStrike Services事件响应团队发现，<strong>10个成功入侵的攻击向量中有8个使用了无文件攻击技术</strong>。为了帮助您了解无文件攻击所带来的风险，本白皮书解释了无文件攻击的工作原理、当前解决方案对其无能为力的原因，以及CrowdStrike解决这一难题的行之有效的方法。</p>
<h3><span id="什么是无文件攻击">什么是无文件攻击？</span></h3><p>当攻击者通过消除将PE（可移植可执行文件）复制到磁盘驱动器的传统步骤来逃避检测时，就会发生无文件或无恶意软件的攻击。<strong>有多种技术可以采取这种方式危害系统</strong>。</p>
<ul>
<li><p><strong>漏洞利用和漏洞利用工具包</strong>，通常通过利用操作系统（OS）或已安装应用程序中存在的漏洞，直接在内存中执行攻击。</p>
</li>
<li><p><strong>使用盗用的凭证</strong>，是发起无文件攻击的另一种普遍方法。Verizon在其2017年的DBIR（数据泄露调查报告）中发现，81%的数据泄露涉及弱口令、默认口令或被盗口令，比上一年增加了18%。这使得攻击者能够像普通用户一样访问系统。</p>
</li>
<li><p>一旦实现初步突破，对手就可以<strong>依赖操作系统本身提供的工具</strong>，如Windows管理工具和Windows <strong>PowerShell</strong>，以执行进一步的操作，而不必将文件保存到磁盘。例如，它们可以通过在注册表、内核中隐藏代码，或者通过创建允许它们随意访问系统的用户帐户来<strong>建立持久化</strong>，而无需向磁盘写入任何内容。</p>
</li>
</ul>
<p>在安全行业，对上述这些技术的使用，通常被称为“<strong>living off the land</strong>”（离地生存？生存手段？）。</p>
<h4><span id="真实案例一个无文件入侵的解剖">真实案例：一个无文件入侵的解剖</span></h4><p>通过展示CrowdStrike Services事件响应团队发现的一个真实的案例，我们可以检查端到端的无恶意软件入侵是什么样子。</p>
<p>在本例中，首个目标是<strong>使用Microsoft ISS并运行SQL服务器数据库的web服务器</strong>。对于最初的入侵，攻击者使用了一个web shell，一个可以被上传到web服务器并在其上执行的简短脚本。脚本可以用web服务器支持的任何语言编写，比如Perl、Python、ASP或PHP。Web Shell在此类攻击中很流行，因为它们可以通过<strong>利用系统上存在的漏洞直接加载到内存中</strong>，而无需将任何内容写入磁盘。在这一特定的攻击中，对手使用SQL注入，将其web shell嵌入到服务器。</p>
<blockquote>
<p>  WEB Shell允许使用web浏览器来远程访问系统。它们可以用ASP或PHP或任何其他web脚本语言编写，代码可以非常小。如下所示：</p>
<p>  <img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181506159.png" alt="img" style="zoom:50%;"></p>
<p>  由于web服务器<strong>没有正确检查转义字符</strong>，攻击者能够简单地将web shell回传到服务器上。所用的web shell，名为“<strong>China Chopper</strong>”（中国菜刀/直升机），包含了JavaScript命令，值得注意的是它只使用了72个字符。在内存中执行web shell，使攻击者能够使用Chopper用户界面，对web服务器执行任意命令。通过对web服务器的完全远程访问，攻击者通过执行编码的PowerShell命令，来窃取凭据。</p>
</blockquote>
<p>第一步是从远程服务器下载脚本，将脚本直接加载到内存中，然后执行它。这个脚本反过来窃取了缓存在web服务器内存中的所有纯文本密码。在几秒钟内，攻击者获得了系统上所有帐户的多个用户名和密码。</p>
<p><strong>PowerShell是一个合法的Windows工具</strong>，它允许攻击者在受损系统上执行任何操作，而不必在磁盘上写入恶意软件。为了进一步做混淆，攻击者可以对其PowerShell脚本进行编码，如下所示：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181506444.png" alt="img" style="zoom:50%;"></p>
<p>下一步是让攻击者在服务器上实现<strong>持久化</strong>。为了在不需要任何恶意软件的情况下执行此操作，攻击者使用了一种称为“<strong>粘滞键</strong>”（Sticky Keys）的技术。通过修改Windows注册表中的一行，攻击者可以使用PowerShell或WMI命令，轻松完成此操作，从而将Windows屏幕键盘进程，设置为<strong>调试模式</strong>。</p>
<p><strong>粘滞键（Sticky Keys）</strong>是使攻击者<strong>无需登录凭据</strong>即可<strong>访问命令shell</strong>的注册表项。如下所示：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181506654.png" alt="img" style="zoom:50%;"></p>
<p>当设置为调试模式时，屏幕键盘允许具有远程访问权限的任何人，以系统权限打开命令行，而无需登录。一旦设置了该注册表项，攻击者可以通过打开到web服务器的远程桌面连接，随时返回。此外，访问系统而<strong>不在Windows事件历史记录中生成登录事件</strong>，会使攻击者的行为几乎无法追踪。</p>
<blockquote>
<p>  现在小结一下，本案例中，<strong>在不同的攻击阶段所使用的文件技术</strong>包括：</p>
<ul>
<li><p><strong>初始入侵</strong>：针对Web服务器的<strong>SQL注入</strong>攻击；</p>
</li>
<li><p><strong>命令与控制（C2）</strong>：“中国菜刀/直升机”的<strong>Web Shell</strong>；</p>
</li>
<li><p><strong>提升权限</strong>：使用<strong>PowerShell脚本</strong>转储<strong>凭据</strong>；</p>
</li>
<li><p><strong>建立持久化</strong>：修改<strong>注册表</strong>粘滞键技术。</p>
</li>
</ul>
</blockquote>
<h3><span id="作案工具真实世界的无文件恶意软件">作案工具：真实世界的无文件恶意软件</span></h3><p>无文件恶意软件经常使用的工具和技术包括：</p>
<ul>
<li><strong>漏洞利用工具包</strong></li>
<li><strong>利用合法工具，如WMI和PowerShell</strong></li>
<li><strong>使用被盗凭证</strong></li>
<li><strong>注册表驻留恶意软件</strong></li>
<li><strong>内存型（Memory-only）恶意软件</strong></li>
</ul>
<p><strong>1）漏洞利用工具包（Exploit kits）</strong></p>
<p>漏洞利用是一种允许攻击者利用操作系统或应用程序漏洞来访问系统的技术。<strong>漏洞利用是一种高效的无文件技术</strong>，因为它们可以直接注入内存中，而无需将任何内容写入磁盘。</p>
<p>通过允许攻击者自动化和大规模执行初始突破，漏洞利用工具包使得攻击者的生活更轻松、工作更高效。<strong>所需要做的只是，诱使受害者进入漏洞利用工具包服务器</strong>，办法通常是网络钓鱼或社会工程。</p>
<p>这些工具包通常提供对许多漏洞的攻击，以及一个管理控制台，一旦成功利用漏洞，攻击者就可以控制失陷的系统。有些漏洞利用工具包甚至提供了扫描受害者系统中的漏洞的功能，因此可以快速构建并启动成功的漏洞攻击。</p>
<p><strong>2）注册表驻留恶意软件</strong></p>
<p>注册表驻留恶意软件是安装在Windows注册表中的恶意软件，以便在逃避检测的同时，保持持久性。第一种是<strong>Poweliks</strong>，此后就出现了许多变体。一些变体，如Kovter，使用了类似的注册表隐藏技术，来保持不被发现。Poweliks<strong>调用C2（命令和控制）服务器</strong>，攻击者可以从该服务器向受损系统发送进一步的指令。所有这些操作，都可以在没有任何文件写入磁盘的情况下进行。</p>
<p><strong>3）内存型（Memory-only）恶意软件</strong></p>
<p>有些恶意软件只存在于内存中，以逃避检测。新版本的<strong>Duqu蠕虫</strong>就是这种情况，它只驻留在内存中，不会被发现。Duqu 2.0有两个版本：第一个是后门，它允许攻击者在组织中站稳脚跟。如果攻击者认为目标值得攻击，他可以使用Duqu 2.0的高级版本，该版本提供了诸如侦察、横向移动、数据渗出等附加功能。Duqu2.0以成功攻破电信行业的公司以及至少一家知名的安全软件提供商而闻名。</p>
<p><strong>4）无文件型勒索软件</strong></p>
<p>甚至勒索软件攻击者，现在也在使用无文件技术，来实现他们的目标。在这类勒索软件中，<strong>恶意代码要么嵌入文档中以使用本机脚本语言（如宏），要么使用漏洞直接写入内存</strong>。然后，勒索软件<strong>使用合法的管理工具如PowerShell，来加密人质文件</strong>，而所有这些都不需要写入磁盘。</p>
<h3><span id="为何传统技术无法抵御无文件攻击">为何传统技术无法抵御无文件攻击</span></h3><p>由于传统安全解决方案极难检测到无文件攻击，因此无文件攻击正在增加。让我们来看看，为什么当今市场上的一些端点保护技术，对这些无恶意软件入侵如此脆弱。</p>
<p><strong>1）传统防病毒（AV）</strong>旨在寻找已知恶意软件的特征码。由于无文件攻击没有恶意软件，所以AV没有可检测的特征码。</p>
<p><strong>2）基于机器学习（ML）</strong>的反恶意软件方法，在应对无文件攻击时，面临着与传统AV相同的挑战。<strong>ML动态分析</strong>未知文件，并将其区分为好的或坏的。但是我们已经注意到，在无文件攻击中，<strong>没有要分析的文件</strong>，因此ML无法提供帮助。</p>
<p><strong>3）白名单方法</strong>包括列出一台机器上所有良好的进程，以防止未知进程执行。无文件攻击的问题在于，它们利用易受攻击的合法白名单应用程序，并利用内置的操作系统可执行文件。阻止用户和操作系统共同依赖的应用程序，并不是一个好的选项。</p>
<p><strong>4）使用失陷指标（IOC）工具</strong>来防止无文件攻击也不是很有效。本质上，<strong>IOC类似于传统的AV签名，因为它们是攻击者留下的已知恶意制品</strong>。然而，由于它们利用合法的进程，并且在内存中操作，所以无文件攻击不会留下制品，因此IOC工具几乎找不到任何东西。</p>
<p><strong>5）另一种方法涉及沙箱</strong>，它可以采取多种形式，包括基于网络的爆破和微虚拟化。由于无文件攻击不使用PE文件，因此沙盒没有什么可爆破的。即便真有东西被发送到沙箱，因为无文件攻击通常会劫持合法进程，大多数沙箱也都会忽略它。</p>
<h3><span id="crowdstrike的解决方案">CrowdStrike的解决方案</span></h3><p>正如我们所看到的，如果您依赖基于签名的方法、沙盒、白名单甚至机器学习保护方法，那么想检测无文件技术是非常有挑战性的。</p>
<p>为了抵御秘密的、无文件的攻击，<strong>CrowdStrike独特地将多种方法结合到一个强大的集成式方法中，提供了无与伦比的端点保护</strong>。CrowdStrikeFalcon平台通过单个的轻量级代理提供了云原生的下一代端点保护，并提供一系列互补的预防和检测方法：</p>
<ul>
<li><p><strong>应用程序清单（Application inventory）</strong>：可以发现在您的环境中运行的任何应用程序，帮助您找到漏洞，以便您可以修补或更新它们，使之不会成为漏洞利用工具包的目标。</p>
</li>
<li><p><strong>漏洞利用阻断（Exploit blocking）</strong>：通过未修补漏洞的漏洞利用方法，来阻断无文件攻击的执行。</p>
</li>
<li><p><strong><font color="red"> 攻击指标（IOA，Indicators of Attack）：</font></strong>在攻击的早期阶段，识别并阻止恶意活动，以免其完全执行并造成损害。此能力还可以防止那些新的勒索软件类别，那些勒索软件不使用文件加密受害者系统。**</p>
</li>
<li><p><strong>托管狩猎（Managed hunting）</strong>：全天候地主动搜索由于无文件技术而产生的恶意活动。</p>
</li>
</ul>
<h4><span id="ioa攻击指标的力量">IOA（攻击指标）的力量</span></h4><blockquote>
<p>  <strong>IOA检测恶意软件或攻击完成其任务所必须执行的事件序列, IOA关注的是所执行的行为、它们之间的关系、它们的顺序、它们的依赖性，将它们视为揭示一系列事件背后真实意图和目的的指标。IOA不关注攻击者使用的特定工具和恶意软件。</strong></p>
</blockquote>
<p>IOA之所以引人注目，是因为它们提供了<strong>针对无文件攻击的独特的主动预防能力</strong>。<strong>IOA寻找攻击可能正在进行的迹象，而不是关心攻击的步骤是如何执行的</strong>。<strong>迹象可以包括代码执行、试图隐身、横向移动等等</strong>。<strong>如何启动或执行这些步骤对IOAs来说并不重要</strong>。</p>
<p><strong><font color="red"> IOA关注的是所执行的行为、它们之间的关系、它们的顺序、它们的依赖性，将它们视为揭示一系列事件背后真实意图和目的的指标。IOA不关注攻击者使用的特定工具和恶意软件。</font></strong></p>
<p>此外，在无文件攻击的情况下，恶意代码可以利用诸如PowerShell之类的合法脚本语言，而无需写入磁盘。正如我们所看到的，这对于基于签名的方法、白名单、沙箱甚至机器学习来说都是一个挑战。相比之下，<strong>IOA检测恶意软件或攻击完成其任务所必须执行的事件序列。</strong>这可以暴露最隐秘的无文件方法，因此它们可以被迅速处理。</p>
<p>最后，由于IOA会查看意图、上下文、活动序列，因此<strong>即使恶意活动是使用合法帐户实施的，也可以检测和阻止这些活动</strong>，攻击者使用窃取的凭据时通常会出现这种情况。</p>
<p>所有这些使得<strong>IOA成为防止无文件恶意软件攻击的突破口</strong>。IOA不再基于磁盘上可执行文件的存在与否，来开展无文件攻击这场徒劳的战斗，而是在<strong>造成任何损害之前监视、检测、阻止此类攻击的影响</strong>。</p>
<h4><span id="托管狩猎">托管狩猎</span></h4><p>托管狩猎（Managed Hunt）是针对文件攻击的另一种独特而有效的防御措施。<strong>Falcon OverWatch</strong>（猎鹰看守）是Falcon平台的<strong>威胁搜索组件</strong>，它提供了一个<strong>额外的保护层</strong>，来抵御无文件攻击。</p>
<p><strong>利用Falcon平台的强大功能，OverWatch（看守）团队全天候主动狩猎威胁，监控客户的环境，并狩猎那些标准安全技术无法检测到但可能表明正在发生攻击的狡猾活动。</strong>Falcon OverWatch确保即使是最复杂和最隐蔽的攻击，也能在发生时被发现。它通过狩猎和识别难以检测的、复杂的、尖端的攻击，生成有意义的警报和精确的指导性补救建议，从而提高您对抗无文件技术的效率。</p>
<h4><span id="结论">结论</span></h4><p>由于漏洞利用工具包的存在，导致了攻击组合的高效性和易创建性，很可能会提高无文件黑客技术的普及率。不幸的是，鉴于传统杀毒软件无法阻止无文件攻击，犯罪黑客越来越可能将注意力集中在这些隐形技术上。因此，安全专家需要在他们的安全策略中，考虑无文件恶意软件和无文件攻击的存在。</p>
<p>正如本文所解释的那样，传统的安全措施在面对无文件攻击时可能不够有效，需要新的保护方法。CrowdStrike Falcon（猎鹰平台）提供了一种全面的解决方案，不仅可以防御无文件攻击，而且还可以很好地防御已知和未知的恶意软件威胁。</p>
<h3><span id="威胁图和攻击指标">威胁图和攻击指标</span></h3><p>CrowdStrike将自身定位为<strong>云交付</strong>的<strong>下一代端点保护</strong>的领导者。CrowdStrike是第一家也是唯一一家统一了<strong>下一代防病毒、端点检测和响应（EDR）、IT卫生、漏洞评估、全天候托管狩猎服务</strong>的公司——全部通过<strong>一个轻量级代理</strong>提供，彻底革新了端点保护。CrowdStrike的<strong>端点保护平台</strong>（EPP）如下图所示：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181507229.png" alt="img" style="zoom:50%;"></p>
<h4><span id="威胁图threat-graph">威胁图（Threat Graph）</span></h4><p>CrowdStrike Falcon（猎鹰）平台由两种紧密集成的<strong>专有技术</strong>组成：一个是易于部署的智能<strong>轻量级代理</strong>；另一个是基于云的动态<strong>图数据库</strong>，即上面提到的<strong>威胁图</strong>（Threat Graph）。</p>
<p><strong>下表进一步梳理了威胁图的主要特性</strong>：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181507209.png" alt="img" style="zoom:50%;"></p>
<p><a href="https://www.crowdstrike.com/cybersecurity-101/indicators-of-compromise/ioa-vs-ioc/">https://www.crowdstrike.com/cybersecurity-101/indicators-of-compromise/ioa-vs-ioc/</a></p>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（5）蚂蚁安全-柳星《我对安全与NLP的实践和思考》</title>
    <url>/posts/3DTA3RC/</url>
    <content><![CDATA[<h1><span id="柳星-我对安全与nlp的实践和思考">柳星-我对安全与NLP的实践和思考</span></h1><blockquote>
<p>  <a href="https://github.com/404notf0und">404notf0und</a>/<strong><a href="https://github.com/404notf0und/FXY">FXY</a></strong></p>
</blockquote>
<h3><span id="一-个人思考">一、个人思考</span></h3><p><strong><font color="red"> 通过对安全与NLP的实践和思考，有以下三点产出：</font></strong></p>
<ul>
<li><strong>首先，产出一种通用解决方案和轮子，一把梭实现对各种安全场景的安全检测。</strong>通用解决方案给出一类安全问题的解决思路，打造轮子来具体解决这一类问题，而不是使用单个技术点去解决单个问题。<strong>具体来说，将安全与NLP结合，在各种安全场景中，将其安全数据统一视作文本数据，从NLP视角，统一进行文本预处理、特征化、预训练和模型训练。</strong>例如，在Webshell检测中，Webshell文件内容，在恶意软件检测中，API序列，都可以视作长文本数据，使用NLP技术进行分词、向量化、预训练等操作，同理，在Web安全中，SQl、XSS等URL类安全数据，在DNS安全中，DGA域名、DNS隧道等域名安全数据，同样可以视作短文本数据。因此，只要安全场景中安全数据可以看作文本数据，<a href="https://github.com/404notf0und/FXY">FXY：<em>Security-Scenes-Feature-Engineering-Toolkit</em></a> 中，内置多种通用特征化方法和多种通用深度学习模型，以支持多种安全场景的特征化和模型训练，达到流水线式作业。</li>
<li><strong>其次，是对应用能力和底层能力的思考</strong>。之前写过一篇文章《<a href="https://4o4notfound.org/index.php/archives/188/">应用型安全算法工程师的自我修养</a>》，在我当时预期想法中，我理解的应用型，重点在于解决实际安全问题，不必苛求于对使用技术本身的理解深度，可以不具备研究型、轮子型的底层能力。映射到我自身，我做安全和算法，最初想法很好，安全和算法两者我都要做好，这里做好，仅仅指用好。之后，面试时暴露了问题，主管给出的建议是两者都要做好。这里做好，不单单指用好，还要知其所以然。举个例子，就是不仅要调包调参玩的6，还要掌握算法的底层原理，这就是底层能力。当时，懂，也不懂，似懂非懂，因为，说，永远是别人的，悟，才是自己的。在实现通用解决方案和轮子的过程中，遇到关于word2vec底层的非预期问题，才深刻体会到，底层能力对应用能力的重要性。过程中遇到的预期和非预期问题，下文会详述。<strong>现在我理解的应用型，重点还是在解决安全问题，以及对安全问题本身的理解，但应用型还需具备研究型、轮子型等上下游岗位的底层能力。</strong>安全算法是这样，其他细分安全领域也是一样，都需要底层能力，以发展技术深度。</li>
<li>最后，带来思考和认识的提升。<strong>从基于机器学习的XX检测，基于深度学习的XX检测，等各种单点检测，到基于NLP的通用安全检测，是一个由点到面的认知提升</strong>。从安全和算法都要做好，到安全和算法都要做好，其中蕴含着认知的提升。从之前写过一篇安全与NLP的文章《<a href="https://www.4o4notfound.org/index.php/archives/190/">当安全遇上NLP</a>》，到现在这篇文章。对一件事物的认识，在不同阶段应该是不一样的，甚至可能完全推翻自己之前的认识。我们能做的，是保持思考，重新认识过去的经历，提升对事物的认知和认知能力。这个提升认知的过程，类似boosting的残差逼近和强化学习的奖惩，是一个基于不知道不知道-&gt;知道不知道&gt;知道知道-&gt;不知道知道的螺旋式迭代上升过程。</li>
</ul>
<h3><span id="二-预期问题">二、预期问题</span></h3><h4><span id="21-分词粒度">2.1 分词粒度</span></h4><p><strong>首先是分词粒度，粒度这里主要考虑字符粒度和词粒度。在不同的安全场景中，安全数据不同，采用的分词粒度也可能不同：</strong></p>
<ul>
<li><strong><font color="red">恶意样本检测的动态API行为序列数据，需要进行单词粒度的划分。</font></strong></li>
<li><strong>域名安全检测中的域名数据，最好采用字符粒度划分。</strong></li>
<li><strong>URL安全检测中的URL数据，使用字符和单词粒度划分都可以。</strong></li>
<li><strong>XSS检测文中，是根据具体的XSS攻击模式，写成正则分词函数，对XSS数据进行划分，这是一种基于攻击模式的词粒度分词模式，但这种分词模式很难扩展到其他安全场景中。</strong></li>
</ul>
<p><strong>FXY特征化类wordindex和word2vec中参数char_level实现了该功能</strong>。在其他安全场景中，可以根据此思路，写自定义的<strong>基于攻击模式的分词</strong>，但适用范围有限。我这里提供了两种通用词粒度分词模式，第一种是忽略特殊符号的简洁版分词模式，第二种是考虑全量特殊符号的完整版分词模式，这两种分词模式可以适用于各种安全场景中。FXY特征化类word2vec中参数punctuation的值‘concise’，‘all’和‘define’实现了两种通用分词和自定义安全分词功能。下文的实验部分，会测试不同安全场景中，使用字符粒度和词粒度，使用不同词粒度分词模式训练模型的性能对比。</p>
<h4><span id="22-语料库">2.2 语料库</span></h4><p><strong>关于预训练前字典的建立（语料库）</strong>。特征化类word2vec的预训练需求直接引发了字典建立的相关问题。在word2vec预训练前，需要考虑预训练数据的产生。基于深度学习的XSS检测文中，是通过<strong>建立一个基于黑样本数据的指定大小的字典，不在字典内的数据全部泛化为一个特定词，将泛化后的数据作为预训练的数据</strong>。这里我们将此思路扩充，增加使用全量数据建立任意大小的字典。具体到word2vec类中，参数one_class的True or False决定了预训练的数据来源是单类黑样本还是全量黑白样本，参数vocabulary_size的值决定了字典大小，如果为None，就不截断，为全量字典数据。下文的实验部分会测试是<strong>单类黑样本预训练</strong>word2vec好，还是<strong>全量数据预训练</strong>更占优势，是<strong>字典截断</strong>好，还是用全量字典来预训练好。</p>
<h4><span id="23-序列">2.3 序列</span></h4><p><font color="red"> <strong>关于序列的问题，具体地说，是长文本数据特征化需求</strong>。</font><strong>webshell检测等安全场景，引发了序列截断和填充的问题。</strong>短文本数据的特征化，可以保留所有原始信息。而在某些安全场景中的长文本数据，特征化比较棘手，保留全部原始信息不太现实，需要对其进行截断，截断的方式主要有<strong>字典截断、序列软截断、序列硬截断</strong>。</p>
<ul>
<li><strong>序列软截断</strong>是指对不在某个范围内（参数num_words控制范围大小）的数据，直接去除或填充为某值，长文本选择直接去除，缩短整体序列的长度，尽可能保留后续更多的原始信息。如果长本文数据非常非常长，那么就算有字典截断和序列软截断，截断后的序列也可能非常长，超出了模型和算力的承受范围;</li>
<li><strong>序列硬截断</strong>（参数max_length控制）可以发挥实际作用，直接整整齐齐截断和填充序列，保留指定长度的序列数据。这里需要注意的是，为了兼容后文将说到的“预训练+微调”训练模式中的<strong>预训练矩阵</strong>，序列填充值默认为0。</li>
</ul>
<h4><span id="24-词向量">2.4 词向量</span></h4><p>词向量的问题，具体说，是词嵌入向量问题。词嵌入向量的产生有三种方式：</p>
<ul>
<li>词序列索引+有嵌入层的深度学习模型</li>
<li>word2vec预训练产生词嵌入向量+无嵌入层的深度学习模型</li>
<li><strong>word2vec预训练产生预训练矩阵+初始化参数为预训练矩阵的嵌入层的深度学习模型。</strong></li>
</ul>
<p>这里我把这三种方式简单叫做微调、预训练、预训练+微调，从特征工程角度，这三种方式是产生词嵌入向量的方法，从模型角度，也可以看作是模型训练的三种方法。第一种微调的方式实现起来比较简单，直接使用keras的文本处理类Tokenizer就可以分词，转换为词序列，得到词序列索引，输入到深度学习模型中即可。第二种预训练的方式，调个gensim库中word2vec类预训练，对于不在预训练字典中的数据，其词嵌入向量直接填充为0，第三种预训练+微调的方式，稍微复杂一点，简单来说就是前两种方式的组合，用第二种方式得到预训练矩阵，作为嵌入层的初始化权重矩阵参数，用第一种方式得到词序列索引，作为嵌入层的原始输入。下文的实验部分会测试并对比按这三种方式训练模型的性能，<strong>先说结论：预训练+微调&gt;预训练&gt;微调</strong>。</p>
<h3><span id="三-非预期问题">三、非预期问题</span></h3><h4><span id="31-已知的库和函数不能满足我们的需求">3.1 已知的库和函数不能满足我们的需求</span></h4><p>使用keras的文本处理类Tokenizer预处理文本数据，得到词序列索引，完全没有问题。<strong>但类Tokenizer毕竟是文本数据处理类，没有考虑到安全领域的需求。</strong></p>
<ul>
<li><strong><font color="red"> 类Tokenizer的单词分词默认会过滤所有的特殊符号，仅保留单词，而特殊符号在安全数据中是至关重要的，很多payload的构成都有着大量特殊符号，忽略特殊符号会流失部分原始信息。</font></strong></li>
<li><strong>首先阅读了keras的文本处理源码和序列处理源码</strong>，不仅搞懂了其结构和各函数的底层实现方式，还学到了一些trick和优质代码的特性。搞懂了其结构和各函数的底层实现方式，还学到了一些trick和优质代码的特性。下图为Tokenizer类的结构。借鉴并改写Tokenizer类，加入了多种分词模式，我们实现了wordindex类。</li>
</ul>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304181514240.png" alt="img"></p>
<h4><span id="32-对word2vec的理解不到位">3.2 对word2vec的理解不到位</span></h4><p>第二个非预期问题是，对word2vec的理解不到位，尤其是其底层原理和代码实现，导致会有一些疑惑，无法得到验证，这是潜在的问题。虽然可以直接调用gensim库中的word2vec类暂时解决问题，但我还是决定把word2vec深究深究，一方面可以答疑解惑，另一方面，就算不能调用别人的库，自己也可以造轮子自给自足。限于篇幅问题，不多讲word2vec的详细原理，原理是我们私下里花时间可以搞清楚的，不算是干货，对原理有兴趣的话，这里给大家推荐几篇优质文章，在github仓库<a href="https://github.com/404notf0und/Always-Learning">Always-Learning</a>中。</p>
<p><strong>word2vec本质上是一个神经网络模型，具体来说此神经网络模型是一个输入层-嵌入层-输出层的三层结构，我们用到的词嵌入向量只是神经网络模型的副产物，是模型嵌入层的权重矩阵。</strong>以word2vec实现方式之一的skip-gram方法为例，此方法本质是通过中心词预测周围词。如果有一段话，要对这段话训练一个word2vec模型，那么很明显需要输入数据，还要是打标的数据。以这段话中的某个单词为中心词为例，在一定滑动窗口内的其他单词都默认和此单词相关，此单词和周围其他单词，一对多产生多个组合，默认是相关的，因此label为1，即是输入数据的y为1，而这些单词组合的one-hot编码是输入数据的x。<strong>那么很明显label全为1，全为positive sample，需要负采样来中和。这里的负采样不是简单地从滑动窗口外采样，而是按照词频的概率，取概率最小的一批样本来做负样本（这个概念下面马上要用到），因为和中心词毫不相关，自然label为0。</strong></p>
<p><strong><font color="red"> tensorflow中的nce_loss函数实现了负采样。</font></strong></p>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（6）滴滴安全《安全运营之自动编排SOAR的探索》</title>
    <url>/posts/26TF5T6/</url>
    <content><![CDATA[<h2><span id="滴滴安全运营之自动编排-soar-的探索">滴滴安全运营之自动编排 (SOAR) 的探索</span></h2><blockquote>
<p>  DiDi:<a href="https://www.secrss.com/articles/25896">https://www.secrss.com/articles/25896</a></p>
</blockquote>
<h4><span id="困难和挑战">困难和挑战</span></h4><ul>
<li><strong>海量异构的日志数据源</strong><ul>
<li><strong>覆盖广</strong>：通过各类sensor采集的数据，覆盖了办公网和客服网的终端，以及测试网生产网的服务器，还有公有云的虚拟机等等。</li>
<li><strong>来源多</strong>：HIDS，网络层的NTA，终端EDR，还有VPN的认证日志，DNS的解析记录，802.1x的认证，AD域控的日志，还有防火墙邮件服务器密罐的日志等等。</li>
<li><strong>量级大</strong>：每天用于安全审计的原始日志达到了10Tb及以上的量级。</li>
<li><strong>异构性</strong>：Hive、ElasticSearch、Kafka等等，而有些日志是设备通过Syslog和Webhook的方式打给我们的，这些日志都是异构的。</li>
</ul>
</li>
<li><strong>有效的告警会淹没在误报当中</strong><ul>
<li>黑名单的规则来定义异常，无法感知未知；白名单规则，通过定义正常来发现异常；</li>
<li><strong>统计规则阈值的选取也和误报息息相关</strong>；</li>
<li><strong>在甲方日常的安全运营中，团队可能会受 KPI的影响</strong></li>
</ul>
</li>
<li><strong>告警研判推理的挑战</strong><ul>
<li><strong><font color="red"> 如果我们缺少有效的关联分析能力，就很难从各个孤立的告警中还原出攻击者的一次战术动作。</font></strong></li>
<li><strong>告警研判过程中存在重复低效的二次取证的工作</strong></li>
<li><strong>不完备的资产实体库</strong></li>
<li><strong>研判过程中还缺乏知识的指引</strong></li>
</ul>
</li>
</ul>
<h4><span id="如何针对事件检测响应去建构知识体系"><strong>如何针对事件检测响应去建构知识体系？</strong></span></h4><ul>
<li><strong>知识模型</strong>：STRIDE的模型、kill Chain杀链模型、ATT&amp;CK模型</li>
<li><strong>知识交换</strong>：指交换威胁情报和lOC识别的知识，目前业内比较通用的有像<strong>==STIX2.0==，还有TAXll协议</strong>。</li>
<li><strong>知识运用</strong>：如何运用知识来指导我们做lOC规则的开发，如何做研判策略的设计，以及如何制定事件处置的SOP流程等等。</li>
<li><strong>知识迭代</strong>：知识模型自身的迭代，比如说近期ATT&amp;CK模型也推出了<strong>Sub-techniques</strong>，就是子技术的概念。另一方面就是日常运营的案件如何反馈到知识模型来做迭代。</li>
</ul>
<h4><span id="如何建立科学的度量和评价体系"><strong>如何建立科学的度量和评价体系？</strong></span></h4><p>我们在事件检测运营中有很多指标，比如<strong>围绕资产实体的，有HIDS部署的覆盖率，比如终端EDR的安装覆盖率，还有跨网络、跨安全域网络边界、南北向流量检测覆盖率</strong>等等。</p>
<p>还有围绕运营流程的，比如像比较核心的MTTD/MTTR指标。还有围绕能力矩阵的，比如ATT&amp;CK矩阵的覆盖率。<strong>指标的选取，它关系到能否把控安全态势的全局以及能否做好牵引能力的建设，因此选取有效的度量和评价体系，也是存在挑战的。</strong></p>
<blockquote>
<p>  <strong>MTTD = 故障与检测之间的总时间/事件数量</strong></p>
<p>  <strong>MTTA = 指从系统产生告警到人员开始注意并处理的平均时间。</strong></p>
</blockquote>
<h3><span id="安全编排自动化与响应soar它能为安全事件检测与响应流程带来哪些改善"><strong>安全编排自动化与响应SOAR，它能为安全事件检测与响应流程带来哪些改善?</strong></span></h3><blockquote>
<p>  <strong>SOAR分为安全编排自动化，安全事件响应平台，以及威胁情报平台三种技术工具的融合。</strong></p>
</blockquote>
<h4><span id="soar如何加速事件检测和响应"><strong>SOAR如何加速事件检测和响应</strong></span></h4><p>首先在IDR运营流程中，我们接收到一个异常的事件Event，我们如何通过SOAR的思想来处理这个事件，从而提升IDR流程的效率？</p>
<ul>
<li><strong>告警分诊</strong>:一个原始的告警里边可能只包含了少量的事件信息，我们需要在这个阶段使<strong>告警丰富化</strong>，也就是 Enrichment概念——<strong>将原始告警中的IP服务器，终端ID这样的字段，在我们内部的资产库当中查询出详细的信息，并且自动补充到告警信息中。</strong></li>
<li><strong>初步决策</strong>，比如有些字段命中了<strong>白名单库</strong>，或者威胁情报显示这是一个非恶意的良性的特征。将告警作为误报直接关闭，减少后面人工审计的运营负担。</li>
<li><strong>调查取证</strong>：通过SOAR的自动调用能力，可以调用后台的数据，收集更多的IOC信息，我们也可以调用沙箱这个能力对可疑文件进行动态的检测，得到检测结果，从而实现证据的自动收集。</li>
<li><strong>溯源关联分析</strong>：实现告警事件的上下文相关联事件的聚合。</li>
</ul>
<blockquote>
<p>  比如说同一个告警事件，它发生在不同的资产实体上，或者说同一个资产实体，它在一定的时间段内，发生了多类的告警事件.</p>
</blockquote>
<p><strong>经过前期的告警分诊、误报关闭、调查取证的几个阶段，原始的事件event就转化为了一个需要人工验证的incident案件</strong>。在这个环节安全工程师会根据前面SOAR自动补充和取证的信息做出研判，进入到对这个事件的响应的流程。<strong>响应阶段也可以利用SOAR自动地执行安全处置的动作，包括邮件IM通知员工，或创建处置或漏洞工单，或是向防火墙/终端EDR下发安全策略（比如封禁）等等</strong>。这样我们就通过SOAR完成了一次告警事件的检测与响应的流程。</p>
<h4><span id="剧本编排的概念"><strong><font color="red"> 剧本编排的概念</font></strong></span></h4><p><strong>以钓鱼邮件检测与响应的剧本为例。</strong></p>
<ul>
<li><strong>检测钓鱼邮件</strong>时，首先是提取<strong>邮件的信息</strong>，包括<strong>发件人</strong>、<strong>收件人</strong>、正文里可点击的<strong>url链接列表</strong>、<strong>附件</strong>等等。<ul>
<li>从AD里查询出<strong>员工的相关信息</strong>，可以自动去邮件服务器的访问日志里面去查看员工近期有没有<strong>异常的登录行为</strong>，比如说异地登录，或者是使用非常设备登录等等。</li>
<li><strong>URL链接</strong>，我们首先去威胁情报里查一下有没有命中情报样本。针对可疑的URL链接，我们可以结合像Whois信息，像域名的信息，对 URL进行评分。</li>
<li><strong>针对邮件的附件</strong>也可以做静态分析，看是否包含 office鱼叉。我们还可以利用Cuckoo这样的动态沙箱对邮件附件里的可执行文件做行为检测。我们还可以利用外部的比如Virus Total这样的样本分析平台，来看是否命中恶意样本。</li>
</ul>
</li>
<li>经过信息的自动化收集和分析的动作，我们进入到最后的<strong>人工审计环节</strong>。这个时候安全工程师会结合前面自动收集的信息去做研判。一旦安全工程师识别出这是一个有效的钓鱼邮件，也会通过<strong>剧本的方式去执行后续的这些自动化的动作，包括向员工发送告警工单，要求他修改域账号的密码</strong>。我们还可以将发件人的邮箱加入邮件安全网关的发件人黑名单列表里，防止他再给其他员工继续发邮件。我们也可以将恶意的或可疑的钓鱼邮件链接的域名加入到我们DNS封禁列表里，<strong>来防止进一步的扩散</strong>。</li>
</ul>
<h4><span id="结合滴滴的实践经验和探索介绍贴合甲方实际场景的soar建设思路"><font color="red"> 结合滴滴的实践经验和探索，介绍贴合甲方实际场景的SOAR建设思路</font></span></h4><p><strong>需要明确SOAR</strong>在事件检测响应体系中的定位，也就是它<strong>与SIEM/SOC/安全事件响应平台SIRP之间的关系</strong>，还有它<strong>与TIP威胁情报平台之间的关系</strong>。SOAR可以理解为是事件响应平台或者是SOC的扩展能力。 当然SOAR也可以作为一个独立的平台，与SOC和TIP实现打通。</p>
<blockquote>
<p>  根据Gartner的定义，SOAR是一系列技术的合集，它能够帮助企业和组织收集安全运营团队监控到的各种信息，也包括各种安全系统产生的告警，并对这些信息进行告警分诊和事件分析。</p>
</blockquote>
<p><strong>SOAR在甲方如何落地，主要考虑三方面：</strong></p>
<ul>
<li><strong>实现路径</strong>:<ul>
<li>可以采用商业化的产品，近期我们也看到很多国内外知名安全厂商陆续推出了SOAR这款产品。</li>
<li>我们也可以基于开源工具做二次开发，比如说剧本编排引擎，它特别类似于一个<strong>Workflow的工作流引擎</strong>，我们可以基于开源的像Activity或者是Airflow这样的工作流引擎去做二次的开发。</li>
<li>使用自研的方式。</li>
</ul>
</li>
<li><strong>技术选型</strong>：主要是考虑可视化剧本的编排引擎，还有剧本的执行引擎。</li>
<li><strong>系统设计</strong>：SOAR虽然是一个扩展的能力，但是从系统设计的角度来说，一旦我们引入SOAR，就会将它串联到我们整个的 IDR流程当中。所以SOAR自身的稳定性，还有一些其他的技术指标，比如像EPS每秒处理的事件数，SLA，包括一些其他的benchmark等等，这些也是我们关注的重点。刚才也提到SOAR会串联到IDR流程里，所以它有可能会引入或导致一个单点问题，所以我们也会考虑分布式的部署。还有降级，一旦SOAR不可用的时候，我们的SOC或者事件响应平台能否降级到没有SOAR的状态。</li>
</ul>
<h4><span id="如何评估soar的效果和收益"><strong><font color="red"> 如何评估SOAR的效果和收益？</font></strong></span></h4><ul>
<li><strong>对IDR核心运营指标MTTD和MTTR的提升</strong>，它能让我们技术运营投入更少的人力去做更多的事，提升人效。</li>
<li><strong><font color="red"> 他能否通过SOAR来识别攻击者完整的战术动作，也就是TTP。</font></strong></li>
<li>通过将剧本的引入，将流程案件知识固化下来，牵引我们能力侧的建设。</li>
</ul>
<h4><span id="结合滴滴的经验和探索介绍一下soar的系统设计思想"><strong>结合滴滴的经验和探索，介绍一下SOAR的系统设计思想？</strong></span></h4><p><strong>首先我们从各个sensor采集到的数据经过ETL存储在大数据的组件当中</strong>。我们的策略规则是作用在这些大数据的计算引擎上，像 Spark，Hadoop，还有Flink这样实时的引擎，也包括我们自研的异常检测的引擎，最终产生的异常告警事件会打到我们的event gateway通用事件网关上。这一阶段被我们称为异常检测阶段。</p>
<p>事件网关主要做两个事：一，做<strong>标准化</strong>，将这些异构的数据源产生的各种类型的告警里的字段格式和数据类型做标准化，以便后面我们在做SOAR编排的时候降低成本。二，<strong><font color="red"> 在这个环节我们会做 index，把原始的告警事件索引到数据库里，以便我们后面做关联分析，或者我们可以回溯的时候去实时地查询历史的告警事件数据。</font></strong></p>
<p>【<strong>告警分诊</strong>】经过事件网关以后，我们紧接着做两个事情，<strong>一个是做Enrichment丰富化</strong>，第二个是做<strong>威胁情报</strong>。我们在丰富化这个阶段会补齐像服务器地址、员工信息、终端信息和调研我们内部的核心的资产库，将告警信息做丰富化。 第二就是我们会初步匹配告警字段里边比如像域名，像文件哈希，去我们本地的威胁情报库里面做匹配。</p>
<p>【<strong>调查取证</strong>】接下来就进入到我们的核心检测阶段SOAR编排环节，在这个环节我们将各种检测能力抽象成为各种检测引擎，比如像攻击检测引擎、误报检测引擎、调查取证引擎和关联分析引擎等等。</p>
<ul>
<li><p>【<strong>黑名单</strong>】<strong>攻击检测</strong>引擎是做什么？主要是根据告警事件里的一些字段去我们本地的黑名单库列表里做匹配，一旦确认命中我们的黑名单，就可以不需要做后面一些列复杂的调查取证和关联分析工作，可以直接交给人工来做研判，甚至对它可以绕过人工来做自动化响应。</p>
</li>
<li><p>【<strong>白名单</strong>】<strong>误报检测</strong>是根据字段里边的一些特征，以及我们之前配置的白名单规则，命中了白名单，这个事件我们可以把它自动关闭掉，以减少后面调查取证的负担。</p>
</li>
<li><strong>调查取证</strong>我们是将一些通用的外部接口和能力封装成一些函数或者脚本，来做自动化的调用。而这些封装的能力之间，我们也是以一个子剧本的方式来进行编排，它可以根据剧本流程的配置来做自动化的执行和调用。</li>
<li><strong><font color="red"> 关联分析引擎也是基于我们配置好的一些关联分析的规则，来针对这一个告警事件的上下文，或者一段时间内它同资产的一些其他告警事件来做关联和聚合，上报给人工去做研判。</font></strong></li>
</ul>
<p><strong>这些不同的检测引擎之间，我们也是通过剧本的方式把它进行一个整体的编排</strong>。有些我们可以先经过攻击检测引擎，误报检测引擎，再做调查取证和关联分析；而有一些告警类型，我们通过剧本的编排，它就不需要去做攻击检测了，比如他通过误报检测就可以直接到调查取证检测。这些其实都是通过剧本来实现一个动态编排。</p>
<p>【<strong>人工验证</strong>】经过这个阶段的检测，原始事件就形成了一个具体的需要人工验证的案件，也就是<strong>incident</strong>。从原始的事件到案件，这个阶段我们称它为是检测阶段的SOAR编排。【<strong>自动处置</strong>】这阶段经过人工的验证，如果是一个有效的案件需要经过处置的话，它就会进入到后续的自动处置的流程里面。而这一阶段我们也是通过剧本的方式，将各种处置能力封装来自动编排上。这里边包括像通过邮件和IM消息的方式来通知用户，也包括我们调用工单系统，还有就是我们调用 EDR/IPS/防火墙的一些封禁策略等等，把它封装成自动的脚本，通过剧本的方式做编排，做自动的调用。</p>
<h4><span id="在做soar系统设计的时候是如何把知识体系来融合到系统设计里的呢"><strong>在做SOAR系统设计的时候，是如何把知识体系来融合到系统设计里的呢？</strong></span></h4><p>在上文提到的情报交互里有一个<strong>STIX2.0协议</strong>，STIX2.0有很多个构件，其中有几个构件其实是可以指导我们去做异常检测规则的开发，以及SOAR编排里的关联分析和处置动作的。</p>
<ul>
<li><p><strong>indicator</strong>，就可以指导我们去做异常检测阶段的IOC规则开发；</p>
</li>
<li><p><strong>Attack Pattern</strong>，描述的其实就是TTP，可以指导我们在SOAR检测阶段去做关联分析规则；</p>
</li>
<li><strong>course of action</strong>构件，它是指导我们在做响应处置阶段的SOP的流程。</li>
</ul>
<p>我们前面也提到了ATT&amp;CK模型，其实<strong>ATT&amp;CK模型和STIX2.0之间是有映射关系的</strong>，我们可以将我们的异常检测规则映射到ATT&amp;CK模型上，主要是做两个事，第一个就是我们根据现有的检测点，可以总体来看我们<strong>对ATT&amp;CK的覆盖率</strong>，这样它能牵引我们去做能力侧的建设，也就是<strong>检测策略建设</strong>。<strong>当我们发现缺少哪一部分的检测能力，我们就可以去部署新的sensor，开发新的IOC规则。</strong></p>
<p><strong>我们也可以结合ATT&amp;CK模型去和我们的真实的日常运营中的案件做结合，去查看我们ATT&amp;CK热力图，去从整体安全态势上看我们哪些场景是经常会被攻击的</strong>。我们也可以结合资产的重要性、等级和实际发生的案件，通过一个公式来计算出我们整体的风险值。</p>
<p>【<strong>异常检测评估指标</strong>】整个SOAR流程和指标体系也是紧密结合的，包括我们在异常检测阶段有能力矩阵的覆盖率这样的指标。还有我们在检测阶段的SOAR编排决定了我们的MTTD（平均检测时间）的指标，以及在响应阶段SOAR关联了我们的MTTR（平均响应时间）指标。</p>
<p>这样我们就围绕着SOAR的系统设计，将IDR事件检测与响应流程、SOAR的自动编排、知识体系和指标体系，都融合在了我们整个的SOAR的系统设计思想里。</p>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（7）AVClass2-自动恶意软件标记工具</title>
    <url>/posts/169EKJ8/</url>
    <content><![CDATA[<h1><span id="如何利用多杀软结果提取恶意软件标签">如何利用多杀软结果提取恶意软件标签</span></h1><ul>
<li>secrss.com/articles/33242</li>
<li><strong>通过多杀软结果挖掘得到更多关于样本的上下文信息是一个经久不衰的研究点</strong></li>
</ul>
<p><strong>从杀软标签中自动提取标签是对大量样本进行分类和索引的有效方法</strong>。此前的 AVClass 和 Euphony 等工作已经能够从杀软标签中提取家族名称。而杀软标签包含有价值的信息不止是家族，还有类别（例如勒索软件、下载器、广告软件）和行为（例如垃圾邮件、DDoS、信息窃取）等。</p>
<p><strong>恶意软件属性枚举和表征（MAEC）等标准定义了一种用于共享恶意软件分析结果的语言</strong>。然而，由于使用严格的受控词汇表（即预定义标签），这些词汇表可能并不总是符合分析师的需求，需要频繁更新，并且必然是不完整的，因此它们的采用率很低，例如，MAEC 中就不包括<strong>恶意软件家族</strong>。</p>
<p>杀软引擎有一些通用标签，标明恶意软件的类别、家族、文件属性和动态行为。也有一个通用标签（malicious, application）和特定杀软引擎（deepscan, cloud）才有的，或者是恶意软件家族变种（aghr, bcx）标签。</p>
<h3><span id="工作设计">工作设计</span></h3><p><strong>AVClass2 的目标是分辨提供有用信息的 Token，识别不同杀软引擎 Token 之间的关系，最后转换成分类法的标签。</strong></p>
<p>AVClass2 是一个自动恶意软件标记工具，可为样本提取一组干净的标签。AVClass2 附带一个默认的开放分类法，可将杀软标签的名词分类到不同的类别，捕获标签之间关系的默认标记规则和扩展规则。AVClass2 有一个更新模块，使用标签共现来识别标签之间的关系，以在杀软厂商引入新标签时保持工具更新。</p>
<p>AVCalss2 基于 AVClass 进行了最少必要更改，继承了 AVClass 的主要特点：可扩展性好、杀软引擎独立性好、平台无关性好、不需要样本文件、开源。</p>
<p>基本架构如下所示：</p>
<p><img src="https://s.secrss.com/anquanneican/13c4e4d7d81462e10c618bee59fbf971.png" alt="img"></p>
<p><strong>主要是两大模块：Labeling 模块和 Update 模块。</strong></p>
<ul>
<li>Labeling 模块将<strong>多个杀软的标签结果作为输入</strong>，同时可以提供使用的杀软引擎列表，如果不提供默认使用所有杀软引擎的标签结果。给出一组<strong>标记规则</strong>、一个<strong>可选扩展规则</strong>以及可将标签<strong>分类合并</strong>的分类法。</li>
<li>Update 模块将<strong>共现统计、标记规则、扩展规则和分类法作为输入</strong>。识别标签之间的<strong>强关联</strong>，生成新的标记规则、扩展规则和分类法。</li>
</ul>
<h3><span id="标签">标签</span></h3><p><strong>Labeling 模块分为三部分：标记化（Tokenization）、标记（Tagging）、扩展（Expansion）。</strong></p>
<ul>
<li><strong>标记化（Tokenization）将每个杀软标签拆分为一个 Token 列表</strong>。标记化是与厂商无关的，VirusTotal 现在已经支持超过一百个引擎。每个厂商的格式也不完全一致，经常修改。如果尝试为引擎的标签定义格式或者自动推断格式，可能会得到数百个格式模板。不仅选择正确格式进行解析很困难，遇到未知格式的标签还可能出现错误。</li>
<li><strong>标记（Tagging）会用分类法中的一组 Tag 替换杀软标签中的 Token，即将杀软标签中的 Token 转换为分类法中概念明确的 Tag</strong>。大多数标记规则会映射到单个标记，例如 downldr、dloader 会被映射到 downloader 上；finloski 和 fynloski 会被映射到 darkkomet 上。也存在一对多的关系，比如 ircbot 会映射到 irc 和 bot。</li>
<li><strong>扩展（Expansion）用于处理未知的 Token，使用扩展规则定义一个标签隐含一组其他标签</strong>。例如有 95% 的标签在带有 virut 的同时也带有 virus，virut 就会是 virus 的扩展规则。扩展规则一共分为两类，一类是类内规则一类是类间规则，处理顺序是先类间规则再类内规则。类内规则由分类法中统一类别的父子关系隐式定义，例如 adware 是 grayware 的子类。类间规则由分类法中不同类别的隐式关系定义，例如 filemodify 行为归属于 virus 类。</li>
</ul>
<p><strong>整体流程如下所示：</strong></p>
<p><img src="https://s.secrss.com/anquanneican/018d45d7ed61a0cca153cfd53d145ade.png" alt="img"></p>
<h3><span id="分类法">分类法</span></h3><blockquote>
<p>  <strong>行为、类型、文件属性和家族</strong></p>
</blockquote>
<p>分类法定义了标记规则使用的标签之间的父子关系。AVClass2 的分类法被构造为树型结构，默认包含四个类型（<strong>行为 BEH、类型 CLASS、文件属性 FILE、家族 FAM</strong>）。</p>
<p><img src="https://s.secrss.com/anquanneican/070902d5885e1c46d17142d43813a9fe.png" alt="img"></p>
<p>标签是自上而下进行描述的，例如 CLASS:grayware:adware。</p>
<p><strong>自带的默认分类法如下所示：</strong></p>
<p><img src="https://s.secrss.com/anquanneican/45bbf65333720324166aeab69f49ece1.png" alt="img"></p>
<ul>
<li><strong>行为</strong>：例如 infosteal（信息窃取）、sendssms（发送短信）、spam（垃圾邮件）、mining（挖矿）等</li>
<li><strong>类别</strong>：例如 worm（蠕虫）、virus（病毒）、ransomware（勒索）、downloader（下载）。Trojan 问题很大，原来特指某类，后来变成了默认类型，故而认为 Trojan 为通用 Token。</li>
<li><strong>文件属性</strong>：例如<strong>文件类型</strong>（例如 pdf、flash、msword）、<strong>操作系统</strong>（android、linux、windows）、<strong>壳类型</strong>（pecompact、themida、vmprotect）、<strong>编程语言</strong>（autoit、delphi、java）</li>
<li><strong>家族</strong>：默认分类家族不包括父子关系</li>
</ul>
<h3><span id="update">Update</span></h3><p>为了新的家族、新的行为都能够通过 AVClass2 自动更新，需要根据共现关系识别数据集中的强关系，迭代更新到规则中。基于 VAMO 引用的杀软标签共现关系，在 AVClass 和 Euphony 中也用于合并家族。（Roberto Perdisci and U. ManChon. 2012. VAMO: Towards a Fully Automated Malware Clustering Validity Analysis. In Annual Computer Security Applications Conference.）。共现的判断需要确定阈值，以AVClass的经验选择 𝑛 = 20 和 𝑇 = 0.94。</p>
<p><img src="https://s.secrss.com/anquanneican/9d67ba609a2c45feb86dcd605dd5c06f.png" alt="img"></p>
<h3><span id="工作准备">工作准备</span></h3><p>使用 11 个数据集进行评估，数据集之间存在重复（例如 Drebin 是 MalGenome 的超集）但并未去重，为了便于单独映射结果。</p>
<p><img src="https://s.secrss.com/anquanneican/18030348ab876b5fed8137aa52b61655.png" alt="img"></p>
<h3><span id="工作评估">工作评估</span></h3><p>通过在 4200 万恶意样本中评估 AVClass2，并且与 AVClass 和 Euphony 进行了比较，测试其效果。</p>
<h3><span id="标记覆盖">标记覆盖</span></h3><p>标签覆盖率如下所示：</p>
<p><img src="https://s.secrss.com/anquanneican/0060066c74a362e126f439c6efc4b669.png" alt="img"></p>
<ul>
<li><p>选择至少四个杀软引擎标记为恶意的样本，最近的研究表明 2-14 个杀软引擎判定的筛选范围有利于平衡精度和召回率。</p>
<blockquote>
<p>  Shuofei Zhu, Jianjun Shi, Limin Yang, Boqin Qin, Ziyi Zhang, Linhai Song, and Gang Wang. 2020. <strong>Measuring and Modeling the Label Dynamics of Online Anti-Malware Engines</strong></p>
</blockquote>
</li>
<li><p>AVClass2 可以为 89% 以上的样本提取至少一个标签，无法提取的基本都是检测结果较少的文件</p>
</li>
<li><p>测试时可识别的 975 个标签已经超过了 VirusTotal 的 335 个标签，VirusTotal 的标签基本都对应于文件属性和样本行为。其中，与 VirusTotal 重合的共有 259 个标签</p>
</li>
</ul>
<p>每个类别 TOP10 的标签如下所示：</p>
<p><img src="https://s.secrss.com/anquanneican/9a1f118fb14f2944de07888d2beb9a08.png" alt="img"></p>
<ul>
<li>超过 10% 的样本对应了四个类别的标签。例如 CLASS:grayware:adware:multiplug 是通过浏览器插件进行广告推广的软件。</li>
<li>Trojan 如果不是通用Token被剔除的话，会被分配给 86% 的样本。</li>
<li>最多的家族是 vobfus，占到了总数的十分一。</li>
<li>除了恶意软件外，grayware 也是常见家族的大赢家（loadmoney、softpulse、installererex、domaiq、firseria）。</li>
</ul>
<h3><span id="知识更新">知识更新</span></h3><p>使用 Andropup 数据集举例说明 update 模块的用法。首次测试观察到 65% 的样本包含一个未知标签，执行 update 模块后会下降到 16%。</p>
<p><img src="https://s.secrss.com/anquanneican/78fad75a47f80238fc0ca5a40ea263b4.png" alt="img"></p>
<p>共现关系共计 30107 个，有归属于 11 类的 968 个强关联。96% 的强关联涉及未知 Token，从中自动识别出了 486 个新类别实体、216 个新标记规则、461 个扩展规则。处理完成后只剩下 3 个强关联不能自动更新，需要手动处理。</p>
<p>手动检查了更新的内容，1163 个更新中只有 11 个（0.9%）是需要调整的、3 个是需要手动检查的。</p>
<h4><span id="执行速度">执行速度</span></h4><p><img src="https://s.secrss.com/anquanneican/3cee7fc69bc91ff6f01b24c764ed46ef.png" alt="img"></p>
<ul>
<li>AVClass2 和 AVClass* 在四个数据集中获得了最好的 F1 成绩，而 AVClass 在 Malheur 上排名第一。</li>
<li>AVClass 最快，AVClass2 其次，Euphony 则比 AVClass 慢 7 到 34 倍。对特大的数据集 Euphony 会很慢或者因内存不足而崩溃。</li>
</ul>
<h2><span id="工作思考">工作思考</span></h2><p>AVClass2 对通过多杀软结果处理实现提取 VirusTotal 类的 Tag 标签很有帮助，实际上没有必要合并成一个完整的分类法的语法树结构。<strong>通过多杀软结果挖掘得到更多关于样本的上下文信息是一个经久不衰的研究点</strong>，本文作者也在 AVClass 的基础上再进一步做出了 AVClass2，<strong>==两个工作分别发表在 RAID 2016 与 ACSAC 2020 都是很不错的成绩。==</strong></p>
<p>像 AVClass++ 指出的那样，AVClass 在杀软引擎结果较少时效果较差，那些新提交到 VirusTotal 的样本会因此效果较差。另外就是杀软结果中也存在随机生成类的结果，这两点实际上都可能是未来在这条路上的研究进展，AVClass++ 的解决方法是否很优则见仁见智，但仍不失为一个极佳的参考。</p>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（8）STIX协议 《网络威胁情报协议》</title>
    <url>/posts/3X70Q09/</url>
    <content><![CDATA[<h2><span id="网络威胁情报之-stix-21">网络威胁情报之 STIX 2.1</span></h2><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/365563090">https://zhuanlan.zhihu.com/p/365563090</a></p>
</blockquote>
<h3><span id="一-说明">一、说明</span></h3><p>STIX（Structured Threat Information Expression）是一种用于交换网络威胁情报（cyber threat intelligence，CTI）的语言和序列化格式。STIX的应用场景包括：<strong>协同威胁分析、自动化威胁情报交换、自动化威胁检测和响应</strong>等。</p>
<h5><span id="stix对网络威胁情报的描述方法如下">STIX对网络威胁情报的描述方法如下：</span></h5><p><img src="https://pic4.zhimg.com/80/v2-c9e59ff49083188d1bf41879c9e1756b_1440w.jpg" alt="img"></p>
<p><strong>STIX Domain Objects</strong>（SDO）：威胁情报主要的分类对象，包含了一些威胁的behaviors和construct，共有18种类型：<strong>Attack Pattern</strong>, Campaign, <strong>Course of Action</strong>, Grouping, Identity, Indicator, Infrastructure, Intrusion Set, Location, Malware, Malware Analysis, Note, Observed Data, Opinion, Report, Threat Actor, Tool, and Vulnerability.</p>
<p><img src="https://pic3.zhimg.com/80/v2-e5fbd4d7693f6dae450a18d6e5981c6a_1440w.jpg" alt="img"></p>
<p><img src="https://pic2.zhimg.com/80/v2-acb4fcb44a2a7d8dd065c75aa848cdc1_1440w.jpg" alt="img"></p>
<p><strong>STIX Cyber-observable Objects</strong>（SCO）：威胁情报中具体的可观察对象，用于刻画<strong>基于主机或基于网络的信息</strong>。</p>
<ul>
<li>SCO会被多种SDO所使用，以提供上下文支持，如<em>Observed Data</em> SDO，表示在特定时间观察到的raw data；在STIX2.0中，SCO在SDO中出现时只会以Observed Data的形式出现，在STIX2.1则不限于此。</li>
<li>SCO本身不包括who，when和why的信息，但是将SCO和SDO关联起来，可能会得到这些信息以及对威胁更高层面的理解。</li>
<li>SCO可以捕获的对象包括文件、进程、IP之间的流量等。</li>
</ul>
<p><strong>STIX Relationship Objects</strong>（SRO）：用于SDO之间、SCO之间、SDO和SCO之间的关系。SRO的大类包括以下两种：</p>
<p><img src="https://pic1.zhimg.com/80/v2-2e19804c43197207ae032bc991594ca0_1440w.jpg" alt="img"></p>
<p><strong>generic SRO（Relationship）</strong>：大多数关系所采用的类型，其relation_type字段包括：内置关系：如Indicator到Malware之间的关系，可以用<em>indicates</em> 表示，它描述了该Indicator可用于检测对应的恶意软件；自定义关系；</p>
<p><strong>Sighting SRO</strong>：用于捕获实体在SDO中出现的案例，如sighting an indicator。没有明确指明连接哪两个object。之所以将其作为独立的SRO，是因为其具有一些独有的属性，如<em>count</em>。</p>
<p>除了SRO，STIX还用ID references来表示嵌入关系（embedded relationship）。当使用嵌入关系时，表示该属性时该对象的内置属性，从而不需要使用SRO表示，如<em>create_by_ref。</em>因此，SRO可以视为两个节点直接的边，而embedded relationship则可以视为属性（只不过其表示了二元关系）</p>
<ul>
<li><strong>STIX Meta Objects</strong>：用于丰富或扩展STIX Core Objects</li>
<li><strong>STIX Bundle Object</strong>：用于打包STIX内容</li>
</ul>
<p><strong>STIX是一种基于图的模型，其中SDO和SCO定义了图的节点，而STIX relationships定义了边</strong>。</p>
<p><strong>STIX Patterning language</strong>：STIX模式语言可以实现网络或终端的威胁检测。该语言目前使用STIX Indicator对象，来匹配时序的observable data。</p>
<h3><span id="二-通用数据类型">二、<strong>通用数据类型</strong></span></h3><p><img src="https://pic3.zhimg.com/80/v2-2d7ff334fee36adda542c0d3281c5d62_1440w.jpg" alt="img" style="zoom:67%;"></p>
<h3><span id="三-stix-通用概念">三、 <strong>STIX 通用概念</strong></span></h3><ul>
<li>STIX common properties</li>
</ul>
<p><img src="https://pic3.zhimg.com/80/v2-4502a49dc00fc1bfae5913c20a191a3e_1440w.jpg" alt="img" style="zoom:67%;"></p>
<h3><span id="四-stix-domain-objects"><strong>四、 STIX Domain Objects</strong></span></h3><p>每个SDO对应 交换网络威胁情报CTI中的唯一概念。<strong>使用SDO，SCO和SRO作为基本模块</strong>，用户可以方便的创建和共享CTI。</p>
<p><strong>SDO</strong>：</p>
<ul>
<li>Property：通用属性、SDO转专用属性</li>
<li>Relationship：embedded relationships、common relationships</li>
</ul>
<p>一些相似的SDO可以被归为一个大类，如：</p>
<ul>
<li><strong>Attack Pattern, Malware, and Tool可以被归为TTP，因为它们描述了攻击行为和资源</strong></li>
<li>Campaign, Intrusion Set, and Threat Actor 可以被描述为“攻击者发动攻击的原因，以及如何组织（why and how）”</li>
</ul>
<h4><span id="41-attack-pattern">4.1 <strong>Attack Pattern</strong></span></h4><p>TTP类型之一，它描述了攻击者试图破坏目标的<strong>方式，</strong>对应于TTP中的<strong>战术</strong>。可用于帮助对<strong>攻击进行分类</strong>，将特定的<strong>攻击概括为其遵循的模式</strong>，并提供有关<strong>如何进行攻击的详细信息</strong>。</p>
<blockquote>
<p>  如spear fishing就是一种攻击模式，而更具体的描述，如被特定攻击者实施的spear fishing也是一种攻击模式。</p>
</blockquote>
<h4><span id="42-campaign"><strong>4.2 Campaign</strong></span></h4><p>表示某次具体的攻击活动。A Campaign is a grouping of adversarial behaviors that describes a set of malicious activities or attacks (sometimes called waves) that occur over a period of time against a specific set of targets. Campaigns usually have well defined objectives and may be part of an Intrusion Set.</p>
<blockquote>
<p>  战役是一组敌对行为，描述了针对特定目标集在一段时间内发生的一组恶意活动或攻击（有时称为WAVE）。活动通常有明确的目标，可能是入侵集的一部分。</p>
</blockquote>
<h4><span id="43-course-of-action-响应的行为">4.3 <strong>Course of Action (响应的行为)</strong></span></h4><p>用于预防攻击或对攻击做出响应的行为，它回包含技术，自动化响应（补丁、重新配置防火墙），或高级别的动作（如员工培训或者策略制定）。</p>
<h4><span id="44-grouping"><strong>4.4 Grouping</strong></span></h4><p>Grouping表示分析和调查<strong>过程中</strong>产生的数据（待确认的线索数据）；还可以用来声明<strong>其引用的STIX对象与正在进行的分析过程有关</strong>，如当一个安全分析人员正在跟其它人合作，分析一系列Campaigns和Indicators的时，<strong>Gouping会引用一系列其它SDO、SCO和SRO（Grouping就表示协作分析吧）。</strong></p>
<p>除了embedded relationship和common relationship之外，没有明确定义Grouping对象和其它STIX对象之间的关系。</p>
<h4><span id="45-identity"><strong>4.5 Identity</strong></span></h4><p><strong>Identity可以代表特定的个人、组织或团伙</strong>；也可以代表一类个人、组织、系统或团伙。Identity SDO可以捕获基本标识信息，联系信息以及Identity所属的部门。 Identity在STIX中用于表示攻击目标，信息源，对象创建者和威胁参与者身份。</p>
<h4><span id="46-incident"><strong>4.6 Incident</strong></span></h4><p>stub对象，待完善，没有专门定义的property和relationship。</p>
<h4><span id="47-indicator"><strong>4.7 Indicator</strong></span></h4><p>Indicator表示可用于检测可疑行为的模式。如用STIX Patterning Language来描述恶意域名集合（第九章）。</p>
<h4><span id="48-infrastructure"><strong>4.8 Infrastructure</strong></span></h4><p><strong>TTP的类型之一，用于描述系统、软件服务等其它的物理或虚拟资源</strong>；如攻击者使用的C2服务器，防御者使用的设备和服务器，以及作为被攻击目标的数据库服务器等；</p>
<p>基于此我们可以将受保护网络中的设备纳入知识图谱，采用类似于这样的关系：</p>
<p><img src="https://pic2.zhimg.com/80/v2-1d2970679ce3243e8ccefe0eda890351_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="49-intrusion-set"><strong>4.9 Intrusion Set</strong></span></h4><p>Intrusion set是由<strong>某个组织</strong>所使用的恶意行为和资源的集合。一个Intrusion Set可能会捕获多个Campaigns，他们共同指向一个Threat Actor。新捕获的活动可以被归因于某个Intrusion Set，而Actors可以在Intrusion之间跳转，甚至从属于多个Intrusion Set。</p>
<p>如在 apt1.json 中，整个报告被打包在bundle中，而Intrusion Set用来指示APT组织：</p>
<p><img src="https://pic3.zhimg.com/80/v2-e40a11cbdf0b033063367a3d045d77ba_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p><strong>Intrusion Set和Campaigns对比：</strong></p>
<p><strong><font color="red"> 如果 Campaigns 是在一段时间内针对一组特定目标进行的一组攻击，以实现某些目标，那么入侵集就是整个攻击包，可以在多个活动中长期使用，以实现潜在的多个目的.</font></strong>由Intrusion Set找出Threat Actors，nation state或者nation state中的某个APT组织，是一个<strong>溯源</strong>的过程。</p>
<h4><span id="410-location"><strong>4.10 Location</strong></span></h4><p>表示具体地点，可以与Identity或Intrusion Set相关联，表示其位置；与Malware或Attack Pattern相关联，表示其目标。</p>
<h4><span id="411-malware"><strong>4.11 Malware</strong></span></h4><p>TTP类型之一，表示<strong>恶意软件或代码。</strong></p>
<h4><span id="412-malware-analysis"><strong>4.12 Malware Analysis</strong></span></h4><p>捕获了在恶意软件实例或恶意软件家族分析过程中，动态分析或静态分析的结果。</p>
<h4><span id="413-note"><strong>4.13 Note</strong></span></h4><p>其他对象中不存在的额外信息；例如，分析人员可以在一个Campaign对象中添加注释，以表明他在黑客论坛上看到了与该Campaign相关的帖子。同样，Note对象也没有定义与其他STIX Object之间的关系。</p>
<h4><span id="414-observed-data"><strong>4.14 Observed Data</strong></span></h4><p><strong>网络安全相关的可观察对象（raw information）集合，其引用对象为SCO，包含从analyst reports, sandboxes, and network and host-based detection tools等收集的信息。</strong></p>
<p><strong>必须包含objects或者object_refs属性，表示对SCO的引用</strong>：</p>
<p>Observed Data只有反向关系。此外，还会被Sighting SRO所指向：Sightings represent a relationship between some intelligence entity<strong> that was seen</strong> (e.g., an Indicator or Malware instance), <strong>where it was seen</strong>, and <strong>what evidence was actually seen.</strong> The <strong>evidence (or raw data) in that relationship is captured as Observed Data（Sighting中的证据就是Observed Data）。</strong></p>
<h4><span id="415-opinion"><strong>4.15 Opinion</strong></span></h4><p>Opinion是对STIX对象中信息正确性的评估。</p>
<h4><span id="416-report"><strong>4.16 Report</strong></span></h4><p>威胁情报报告。</p>
<h4><span id="417-threat-actor"><strong>4.17 Threat Actor</strong></span></h4><p>攻击的个人、团体或组织；其与Intrusion Set不同，Threat Actor会同时支持或附属于不同的Intrusion Set、团体或组织。</p>
<h4><span id="418-tool"><strong>4.18 Tool</strong></span></h4><p><strong>Tool是威胁参与者可以用来执行攻击的合法软件。与Malware不同，Tool一般是合法软件，如Namp、VNC。</strong></p>
<h4><span id="419-vulnerability"><strong>4.19 Vulnerability</strong></span></h4><p>漏洞。用于连接相关漏洞的外部描述（external_references），或还没有相关描述的0-day漏洞。</p>
<p><strong>Q&amp;A：</strong></p>
<ul>
<li><strong>Q1：embedded relationship和节点property有啥区别？</strong>property是节点属性，embedded relationship是带有二元关系的节点属性</li>
<li><strong>Q2：Observed Data和SCO有啥区别？</strong>Observed Data观察行为与观察对象的信息，而<strong>SCO是具体可观察实体的信息，二者是引用与被引用的关系</strong></li>
<li><strong>Q3：Intrusion Set、Identity和Threat Actor的区别？</strong>Intrusion Set是最高层的实体，其包括Identity和Threat Actor，如APT1（高层APT组织）为Intrusion Set，其包含一些个人（Ugly Gorilla）或团体（SuperHard）的Threat Actor，而Identity是用真实名称描述的个人或组织（如Ugly Gorilla指向Wang Dong）。由此看来，Threat Actor也可以用真是名称描述（Communist Party of China），但是明显指示了其表示威胁主体，而Identity本身不显示其角色信息。</li>
</ul>
<h3><span id="五-stix-relationship-objects"><strong>五、 STIX Relationship Objects</strong></span></h3><h4><span id="51-relationship"><strong>5.1 Relationship</strong></span></h4><p><strong>Type Name: relationship</strong></p>
<p>用于连接STIX中的SDO或SCO; STIX中的Relationship在每个SDO或SCO的定义中进行了描述, 用户还可以自定义关系。STIX中所有内置的Relationship详见文档Appendix B。注意, Relationship本身也是一个对象, 因此其也有自身的 Property 和 Relationships。</p>
<h4><span id="52-sighting"><strong>5.2 Sighting</strong></span></h4><p><strong>Type Name: sighting</strong></p>
<p><strong>原文定义</strong>:目击(sighting)表示认为在CTI中看到了某些东西（例如指示器、恶意软件、工具、威胁因素等）。目击用于跟踪目标是谁和什么，如何实施攻击，以及跟踪攻击行为的趋势。</p>
<blockquote>
<p>  A Sighting denotes the belief that something in CTI (e.g., an indicator, malware, tool, threat actor, etc.) was seen. Sightings are used to track who and what are being targeted, how attacks are carried out, and to track trends in attack behavior.</p>
</blockquote>
<p>Sighting 没有连接两个对象, 但却被定义为关系, 原因是:目击包括三部分的内容:• 发现的内容，如指示器、恶意软件、活动或其他SDO（sighting\u of\u ref）•发现者和/或发现地点，表示为身份（where\u sighted\u refs）•系统和网络上实际看到的内容，表示为观察数据（SECURED\u Data\u refs）</p>
<blockquote>
<p>  Sighting is captured as a relationship because you cannot have a sighting unless you have something that has been sighted. Sighting does not make sense without the relationship to what was sighted</p>
</blockquote>
<p>Sighting包括三部分的内容:</p>
<ul>
<li><strong>What</strong> was sighted, such as the <strong>Indicator, Malware, Campaign, or other SDO</strong> (<em>sighting_of_ref</em>)</li>
<li><strong>Who</strong> sighted it and/or where it was sighted, represented as an <strong>Identity</strong> (<em>where_sighted_refs</em>)</li>
<li><strong>What</strong> was actually seen on systems and networks, represented as <strong>Observed Data</strong> (<em>observed_data_refs</em>)</li>
</ul>
<p>Sighting和Observed Data的区别:</p>
<p><strong>目击与观察到的数据不同，因为目击是一种情报断言（“我看到了这个威胁参与者”）</strong>，而观察到的数据只是信息（“我看到了这个文件”）。当您通过包含来自目击的链接观测数据（Observed\u Data\u refs）来组合它们时，您可以说“我看到了这个文件，这让我觉得我看到了这个威胁参与者”。</p>
<blockquote>
<p>  Sighting is distinct from Observed Data in that Sighting is an <strong>intelligence assertion</strong> (“I saw this threat actor”) while Observed Data is simply information (“I saw this file”). When you combine them by including the linked Observed Data (observed_data_refs) from a Sighting, you can say “I saw this file, and that makes me think I saw this threat actor”.</p>
</blockquote>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>工业落地（9）阿里云恶意软件检测平台</title>
    <url>/posts/2A5FQTF/</url>
    <content><![CDATA[<h2><span id="一-阿里云恶意文件检测平台">一、阿里云恶意文件检测平台</span></h2><p>Linux沙箱 ｜ 阿里云恶意文件检测平台开放Linux二进制文件检测：<a href="https://www.anquanke.com/post/id/276349#10006-weixin-1-52626-6b3bffd01fdde4900130bc5a2751b6d1">https://www.anquanke.com/post/id/276349#10006-weixin-1-52626-6b3bffd01fdde4900130bc5a2751b6d1</a></p>
<h3><span id="11-简介">1.1 简介</span></h3><p>在病毒检测方向，一直以来常见的两种手段就是<strong>静态特征检测</strong>与<strong>动态行为检测</strong>。两者各有优势与不足，<strong>静态特征检测方案实施成本更低，检出结果也更精准，但是其泛化能力不足</strong>，针对具有高级对抗能力的恶意文件显得力不从心，并且天然地处于被动的地位，人力运营成本会更高。</p>
<p>动态行为检测实施成本相对较高，需要有足够的资源，而且检出的结果在一定程度上不如静态检测精准，但是它最大的优势是可以从<strong>恶意行为、技术手段</strong>的角度识别恶意文件，具有极大的泛化能力。对于需要检测大量恶意文件的安全厂商来说，人工运营所有样本并提取静态特征是不现实的，而沙箱的作用也就显现出来了：在海量的文件中，识别出最值得关注的恶意文件。</p>
<h3><span id="12-沙箱优势">1.2 沙箱优势</span></h3><h4><span id="高性能的环境仿真">高性能的环境仿真</span></h4><p><strong>云沙箱依托于阿里云神龙架构，在具备高性能的仿真的同时，还支持资源池化和自动化运维的能力</strong>。利用自定义的虚拟化技术和定制的沙箱OS内核，对恶意样本使用的反虚拟化的技术具备天然的对抗能力，配合上专门打造的二进制检测探针，可以在安全、高效、仿真的隔离环境中对二进制进行深度的行为分析。</p>
<h4><span id="全面的动态行为分析">全面的动态行为分析</span></h4><p><strong>基于虚拟化构建的沙箱深度分析技术，对进程、文件、网络、敏感系统调用、rootkit、漏洞利用等进行全面监控</strong>，配合智能模型规则检测引擎，快速分析出样本潜在的恶意行为。</p>
<h4><span id="海量的数据积累">海量的数据积累</span></h4><p>阿里云沙箱服务于阿里云安全云上恶意文件检测，积累了海量样本数据，提炼出大量有独检优势的行为检测规则。</p>
<h3><span id="33-检测优势">3.3 检测优势</span></h3><h4><span id="算法模型覆盖未知威胁">算法模型——覆盖未知威胁</span></h4><p>基于阿里云平台海量样本数据和强劲计算能力，<strong>采用“机器智能(神经网络)”与“专家智能(行为标签、ATT&amp;CK)”结合的智能安全思想</strong>，挖掘海量样本数据中可疑内容信息和行为标签威胁值，构建智能的威胁检测模型发现新威胁。</p>
<p>将专家知识与海量数据结合智能化构建以<strong>ATT&amp;CK为核心的多模态特征表示</strong>，对样本行为从技术战术度量、敏感信息表征、意图逻辑推理等角度进行多维度刻画、分析，同时依赖机器智能的学习泛化能力、检测模型能覆盖更多的未知，拓展威胁发现边界。</p>
<p><img src="https://p2.ssl.qhimg.com/t019938cd9a1afcd563.png" alt="img"></p>
]]></content>
      <categories>
        <category>工业落地</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（18）TF-IDF</title>
    <url>/posts/2MXAK3G/</url>
    <content><![CDATA[<h2><span id="tf-idf">TF-IDF</span></h2><blockquote>
<p>  <a href="https://blog.csdn.net/u010417185/article/details/87905899">https://blog.csdn.net/u010417185/article/details/87905899</a></p>
</blockquote>
<p><strong>TF-IDF(Term Frequency-Inverse Document Frequency, 词频-逆文件频率)</strong>是一种用于资讯检索与资讯探勘的常用<a href="https://www.zhihu.com/search?q=加权技术&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;97273457&quot;}">加权技术</a>。TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。</p>
<p>上述引用总结就是, <strong>一个词语在一篇文章中出现次数越多, 同时在所有文档中出现次数越少, 越能够代表该文章。</strong>这也就是TF-IDF的含义。</p>
<h4><span id="11-tf"><strong>1.1 TF</strong></span></h4><p><strong>TF(Term Frequency, ==词频==)</strong>表示词条在文本中出现的频率，这个数字通常会被归一化(一般是词频除以文章总词数), 以防止它偏向长的文件（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否）。TF用公式表示如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=TF_%7Bi%2Cj%7D%3D%5Cfrac%7Bn_%7Bi%2Cj%7D%7D%7B%5Csum_%7Bk%7D%7Bn_%7Bk%2Cj%7D%7D%7D%5Ctag%7B1%7D+%5C%5C" alt="[公式]"></p>
<p>其中，<img src="https://www.zhihu.com/equation?tex=n_%7Bi%2Cj%7D" alt="[公式]"> 表示词条 <img src="https://www.zhihu.com/equation?tex=t_i" alt="[公式]"> 在文档 <img src="https://www.zhihu.com/equation?tex=d_j" alt="[公式]"> 中出现的次数，<img src="https://www.zhihu.com/equation?tex=TF_%7Bi%2Cj%7D" alt="[公式]"> 就是表示词条 <img src="https://www.zhihu.com/equation?tex=t_i" alt="[公式]"> 在文档 <img src="https://www.zhihu.com/equation?tex=d_j" alt="[公式]"> 中出现的频率。</p>
<p>但是，需要注意， 一些<strong>通用的词语对于主题并没有太大的作用</strong>， <strong>反倒是一些出现频率较少的词才能够表达文章的主题</strong>， 所以单纯使用是TF不合适的。权重的设计必须满足：一个词预测主题的能力越强，权重越大，反之，权重越小。所有统计的文章中，一些词只是在其中很少几篇文章中出现，那么这样的词对文章的主题的作用很大，这些词的权重应该设计的较大。IDF就是在完成这样的工作。</p>
<h4><span id="12-idf"><strong>1.2 IDF</strong></span></h4><p><strong>IDF(Inverse Document Frequency, ==逆文件频率==)</strong>表示关键词的普遍程度。如果包含词条 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]"> 的文档越少， <strong>IDF</strong>越大，则说明该词条具有很好的类别区分能力。某一特定词语的<strong>IDF</strong>，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到:</p>
<p><img src="https://www.zhihu.com/equation?tex=IDF_i%3D%5Clog%5Cfrac%7B%5Cleft%7CD+%5Cright%7C%7D%7B1%2B%5Cleft%7Cj%3A+t_i+%5Cin+d_j%5Cright%7C%7D%5Ctag%7B2%7D+%5C%5C" alt="[公式]"></p>
<p>其中，<img src="https://www.zhihu.com/equation?tex=%5Cleft%7CD+%5Cright%7C" alt="[公式]"> 表示所有<strong>文档的数量</strong>，<img src="https://www.zhihu.com/equation?tex=%5Cleft%7Cj%3A+t_i+%5Cin+d_j%5Cright%7C" alt="[公式]"> 表示包<strong>含词条 <img src="https://www.zhihu.com/equation?tex=t_i" alt="[公式]"> 的文档数量</strong>，为什么这里要加 1 呢？主要是<strong>防止包含词条 <img src="https://www.zhihu.com/equation?tex=t_i" alt="[公式]"> 的数量为 0 从而导致运算出错的现象发生</strong>。</p>
<p>某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于<strong>过滤掉常见的词语，保留重要的词语</strong>，表达为</p>
<p><img src="https://www.zhihu.com/equation?tex=TF+%5Ctext%7B-%7DIDF%3D+TF+%5Ccdot+IDF%5Ctag%7B3%7D+%5C%5C" alt="[公式]"></p>
<p>==<strong>最后</strong>在计算完文档中每个字符的tfidf之后，对其进行归一化，将值保留在0-1之间，并保存成稀疏矩阵。==</p>
<h2><span id="tf-idf-qampa">TF-IDF Q&amp;A</span></h2><h3><span id="1-究竟应该是对整个语料库进行tf-idf呢还是先对训练集进行tf-idf然后再对xtest进行tf-idf呢两者有什么区别"><strong>1、究竟应该是对整个语料库进行tf-idf呢？还是先对训练集进行tf-idf，然后再对xtest进行tf-idf呢？两者有什么区别？</strong></span></h3><blockquote>
<h4><span id="fit">fit</span></h4><p>  学习输入的数据有多少个不同的单词，以及每个单词的idf</p>
<h4><span id="transform-训练集">transform 训练集</span></h4><p>  返回我们一个document-term matrix.</p>
<h4><span id="transform-测试集">transform 测试集</span></h4></blockquote>
<p>transform的过程也很让人好奇。要知道，他是将测试集的数据中的文档数量纳入进来，重新计算每个词的idf呢，还是<strong>直接用训练集学习到的idf去计算测试集里面每一个tf-idf</strong>呢？</p>
<p><strong>如果纳入了测试集新词，就等于预先知道测试集中有什么词，影响了idf的权重。这样预知未来的行为，会导致算法丧失了泛化性。</strong></p>
<h3><span id="2-tf-idf-模型加载太慢">2、TF-IDF 模型加载太慢</span></h3><blockquote>
<p>  <a href="https://thiagomarzagao.com/2015/12/08/saving-TfidfVectorizer-without-pickles/">https://thiagomarzagao.com/2015/12/08/saving-TfidfVectorizer-without-pickles/</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> idfs <span class="keyword">import</span> idfs <span class="comment"># numpy array with our pre-computed idfs</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># subclass TfidfVectorizer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyVectorizer</span>(<span class="title class_ inherited__">TfidfVectorizer</span>):</span><br><span class="line">    <span class="comment"># plug our pre-computed IDFs</span></span><br><span class="line">    TfidfVectorizer.idf_ = idfs</span><br><span class="line"></span><br><span class="line"><span class="comment"># instantiate vectorizer</span></span><br><span class="line">vectorizer = MyVectorizer(lowercase = <span class="literal">False</span>,</span><br><span class="line">                          min_df = <span class="number">2</span>,</span><br><span class="line">                          norm = <span class="string">&#x27;l2&#x27;</span>,</span><br><span class="line">                          smooth_idf = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plug _tfidf._idf_diag</span></span><br><span class="line">vectorizer._tfidf._idf_diag = sp.spdiags(idfs,</span><br><span class="line">                                         diags = <span class="number">0</span>,</span><br><span class="line">                                         m = <span class="built_in">len</span>(idfs),</span><br><span class="line">                                         n = <span class="built_in">len</span>(idfs))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程 vs 表示学习</title>
    <url>/posts/S0Q57W/</url>
    <content><![CDATA[<h2><span id="特征工程与表示学习"></span></h2><h3><span id="1-表示学习"><strong>1. 表示学习</strong></span></h3><p>当我们学习一个复杂概念时，总想有一条捷径可以化繁为简。机器学习模型也不例外，如果有经过提炼的对于原始数据的更好表达，往往可以使得后续任务事倍功半。<strong>这也是表示学习的基本思路，即找到对于原始数据更好的表达，以方便后续任务（比如分类）</strong>。</p>
<p>举个简单的例子，假设我们有 <img src="https://www.zhihu.com/equation?tex=%5C%7B%7Bx%2Cy%5C%7D%7D" alt="[公式]"> ，想要寻找<em>x</em>与<em>y</em>之间的关系。</p>
<p><img src="https://www.zhihu.com/equation?tex=%5C%5B+x%3D+%5Cbegin%7Bbmatrix%7D+1+%26+2+%26+1+%26+0+%5C%5C+2+%26+3+%26+2+%26+1+%5C%5C+1+%26+6+%26+1+%26+4+%5C%5C+0+%26+0+%26+0+%26+1+%5C%5C+1+%26+1+%26+1+%26+17+%5Cend%7Bbmatrix%7D+%5C%5D" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=%5C%5B+y%3D+%5Cbegin%7Bbmatrix%7D+6+%5C%5C+10+%5C%5C+14+%5C%5C+18+%5C%5C+22+%5Cend%7Bbmatrix%7D+%5C%5D" alt="[公式]"> </p>
<p>如果单用肉眼看的话，<em>x</em>这个矩阵其实还是比较复杂的，无法直接发现与<em>y</em>间的关系。但如果我们非常幸运，发现<em>x</em>每行相加后的结果 <img src="https://www.zhihu.com/equation?tex=%5B4%2C8%2C12%2C16%2C20%5D%5ET" alt="[公式]"> ，就可以直接看出<em>x</em>与<em>y</em>之间的关系是 <img src="https://www.zhihu.com/equation?tex=y%3Dx%2B2" alt="[公式]"> 。这个例子是为了说明：<strong>同样的数据的不同表达，会直接决定后续任务的难易程度，==因此找到好的数据表示往往是机器学习的核心任务==</strong>。值得注意的是，在现实情况中我们所提炼的到表示往往是很复杂的，往往对于高维矩阵提取到特征也是高维矩阵。这个例子仅供抛砖引玉之用，表示学习不等于维度压缩或者特征选择。</p>
<h3><span id="2-特征工程与表示学习人工-vs-自动"><strong>2. 特征工程与表示学习：人工 vs. 自动</strong></span></h3><p><strong>正因为数据表示的重要性，机器学习一般有两种思路来提升原始数据的表达</strong>：</p>
<ol>
<li>特征<strong>学习</strong>(feature <strong>learning</strong>)，又叫<strong>表示学习</strong>(representation learning)或者表征学习，一般指的是<strong>自动</strong>学习有用的数据特征。<strong>深度学习的最终目标，就是完全自动化的广义数据处理。</strong></li>
<li>特征<strong>工程</strong>(feature <strong>engineering</strong>)，主要指对于数据的<strong>人为</strong>处理提取，有时候也代指“洗数据”。</li>
</ol>
<p>不难看出，两者的主要区别在于前者是“<strong>学习的过程</strong>”，而后者被认为是一门“<strong>人为的工程</strong>”。用更加白话的方式来说，<strong>特征学习是</strong>从数据中自动抽取特征或者表示的方法，这个学习过程是<strong>模型自主的</strong>。而<strong>特征工程</strong>的过程是<strong>人为的</strong>对数据进行处理，<strong>得到我们认为的、适合后续模型使用的样式</strong>。根据这个思路，机器学习模型对于数据的处理可以被大致归类到两个方向：</p>
<ul>
<li>表示学习：<strong>模型自动</strong>对输入数据进行学习，得到更有利于使用的特征(*可能同时做出了预测)。代表的算法大致包括：<ul>
<li>深度学习，包括大部分常见的模型如CNN/RNN/DBN等。</li>
<li>某些无监督学习算法，如<strong>主成分分析(PCA) </strong>及 <strong>自编码器（autoencoder）</strong>通过对数据转化而使得输入数据更有意义。</li>
<li>某些树模型可以自动的学习到数据中的特征并同时作出预测。</li>
</ul>
</li>
<li>特征工程：模型依赖<strong>人为处理</strong>的数据特征，而模型的主要任务是预测，比如简单的线性回归期待良好的输入数据(如离散化后的数据)</li>
</ul>
<h3><span id="3-模型选择"><strong>3. 模型选择</strong></span></h3><p>回归到问题的本质，就要谈谈什么时候用「手工提取」什么时候用「表示学习」。一种简单的看法是，<strong>要想自动学习到数据的良好表达，就需要大量的数据。这个现象也解释了为什么「特征工程」往往在中小数据集上表现良好，而「表示学习」在大量复杂数据上更有用武之地。</strong></p>
<p>而一切的根本，其实在于<strong>假设</strong>。比如我们会假设数据分布，会假设映射函数的性质，也会假设预测值与输入值间的关系。<strong>这一切假设其实并非凭空猜想，而是基于我们对于问题的理解，从某种角度来看，这是一种先验，是贝叶斯模型</strong>。在中小数据集上的机器学习往往使用的就是强假设模型（人类知识先验）+一个简单线性分类器。当数据愈发复杂，数据量逐渐加大后，我们对于数据的理解越来越肤浅，做出的假设也越来越倾向于随机，那么此时人工特征工程往往是有害的，而需要使用摆脱了人类先验的模型，比如深度学习或者集成模型。</p>
<p><strong>换句话说，模型选择的过程其实也是在衡量我们对于问题及数据的理解是否深刻，是在人类先验与数据量之间的一场博弈。</strong>从这个角度来看，深度学习首先革的是传统机器学习模型的命：最先被淘汰的不是工人，而是特定场景下的传统机器学习模型。</p>
<p>但话说回来，在很多领域数据依然是稀缺的，我们依然需要人工的手段来提炼数据。而这样的尝试其实并不罕见，我也写过一篇<a href="https://zhuanlan.zhihu.com/p/32896968">「Stacking」与「神经网络」</a>介绍如何模拟神经网络在中小数据集上无监督的抽取特征，并最终提升数据的表示。另一个相关的问题是，到底多少数据才算多？可以参考这篇文章：<a href="https://zhuanlan.zhihu.com/p/34523880">「机器学习」到底需要多少数据？</a>。</p>
<p>然而，<strong>相同的数据对于不同的任务也要求不同的数据表达，最优的数据表示并非是绝对的</strong>。类比来看，人类是由细胞组成的，器官也是由细胞组成的。在器官层面来看，细胞是很好的表达。而从人类角度来看，器官是比较好的表达，因为我们可以通过身高体重来区分人，而无法直观地通过细胞来区分人。然而再往前看一步，每个人的细胞携带不同的遗传信息，因此也可以被认为是一种很强的数据表达。讲这个故事的目的是说明，<strong>什么是好的数据表达，其实是非常模棱两可的问题，在不同语境下可能大不相同</strong>。</p>
]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（0）【Nan】数据清洗</title>
    <url>/posts/29WR3P/</url>
    <content><![CDATA[<h2><span id="特征工程-数据清洗">特征工程-数据清洗</span></h2><blockquote>
<p>  特征工程 - 未来达摩大师的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/476659737">https://zhuanlan.zhihu.com/p/476659737</a></p>
<p>  这9个特征工程使用技巧，解决90%机器学习问题！ - Python与数据挖掘的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/462744763">https://zhuanlan.zhihu.com/p/462744763</a></p>
<p>  有哪些精彩的特征工程案例？ - 京东科技风险算法与技术的回答 - 知乎 <a href="https://www.zhihu.com/question/400064722/answer/1308358333">https://www.zhihu.com/question/400064722/answer/1308358333</a></p>
</blockquote>
<p><img src="https://pic1.zhimg.com/v2-3baead31deae5b339481aa843a13e21c_b.jpg" alt="img"></p>
<p>数据格式内容错误数据来源有多种，有些是传感器采集，然后算法提取的特征数据；有些是采集的控制器的数据；还有一些应用场合，则是用户/访客产生的，数据肯定存在格式和内容上不一致的情况，所以在进行模型构建之前需要先进行数据的格式内容清洗操作。逻辑错误清洗主要是通过简单的逻辑推理发现数据中的问题数据，防止分析结果走偏，主要包含以下几个步骤：</p>
<p><strong><em>1.数据去重，去除或替换不合理的值；</em></strong></p>
<p><strong><em>2.去除或重构不可靠的字段值（修改矛盾的内容）；</em></strong></p>
<p><strong><em>3.去除异常点数据。</em></strong></p>
<h2><span id="采样">采样</span></h2><blockquote>
<p>  随机采样方法整理与讲解（MCMC、Gibbs Sampling等） - 向阳树的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/109978580">https://zhuanlan.zhihu.com/p/109978580</a></p>
</blockquote>
]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（3）不平衡数据集*</title>
    <url>/posts/XZ18TA/</url>
    <content><![CDATA[<h2><span id="不平衡数据问题">不平衡数据问题</span></h2><blockquote>
<p>  <strong>实际上，很多时候，数据不平衡并没有啥负面影响，并不是数据不平衡了，就一定要处理。如果你只是为了做而做，我有99%的自信告诉你，你做了也是白做，啥收益都没有。</strong></p>
<ul>
<li>机器学习中不平衡数据的预处理：<a href="https://capallen.gitee.io/2019/Deal-with-imbalanced-data-in-ML.html">https://capallen.gitee.io/2019/Deal-with-imbalanced-data-in-ML.html</a></li>
<li>如何处理数据中的「类别不平衡」？：<a href="https://zhuanlan.zhihu.com/p/32940093">https://zhuanlan.zhihu.com/p/32940093</a></li>
<li><strong>==不平衡数据集处理方法==</strong>：<a href="https://blog.csdn.net/asialee_bird/article/details/83714612">https://blog.csdn.net/asialee_bird/article/details/83714612</a></li>
<li><strong>==不平衡数据究竟出了什么问题？==</strong>：<a href="https://www.zhihu.com/column/jiqizhixin">https://www.zhihu.com/column/jiqizhixin</a></li>
<li>数据挖掘时，当正负样本不均，代码如何实现改变正负样本权重? - 十三的回答 - 知乎 <a href="https://www.zhihu.com/question/356640889/answer/2299286791">https://www.zhihu.com/question/356640889/answer/2299286791</a></li>
<li><strong>样本权重对逻辑回归评分卡的影响探讨</strong> - 求是汪在路上的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/110982479">https://zhuanlan.zhihu.com/p/110982479</a></li>
</ul>
</blockquote>
<h4><span id="为什么很多模型在训练数据不均衡时会出问题">为什么很多模型在训练数据不均衡时会出问题？</span></h4><p><strong>本质原因是</strong>：<strong>模型在训练时优化的目标函数和在测试时使用的评价标准不一致。</strong>这种”不一致“可能是训练数据的样本分布与测试数据分布不一致；</p>
<h2><span id="一-不平衡数据集的主要处理方式"><strong>一、不平衡数据集的主要处理方式？</strong></span></h2><h3><span id="11-数据的角度">1.1 <strong>数据的角度</strong></span></h3><p>主要方法为采样，分为<strong>欠采样</strong>和<strong>过采样</strong>以及对应的一些改进方法。[<strong>python imblearn库</strong>]<strong><font color="red">尊重真实样本分布，人为主观引入样本权重，反而可能得出错误的结论。</font></strong></p>
<h4><span id="业务角度"><strong><font color="red"> 业务角度</font></strong>：</span></h4><ul>
<li><strong>时间因素</strong>，对近期样本提高权重，较远样本降低权重。这是考虑近期样本与未来样本之间的“相似度”更高，希望模型学到更多近期样本的模式。</li>
<li><strong>贷款类型</strong>，不同额度、利率、期限的样本赋予不同权重，这需要结合业务未来的发展方向。例如，未来业务模式希望是小额、短期、低利率，那就提高这批样本的权重。</li>
<li><strong>样本分群</strong>，不同群体赋予不同权重。例如，按流量获客渠道，如果未来流量渠道主要来自平台A，那么就提高这批样本权重。</li>
</ul>
<h4><span id="技术角度"><strong><font color="red"> 技术角度：</font></strong></span></h4><ul>
<li><p><strong>欠采样</strong>：</p>
<ul>
<li><p><strong>EasyEnsemble</strong>：从多数类$S_{max}$上随机抽取一个子集，与其他类训练一个分类器；重复若干次，多个分类器融合。</p>
</li>
<li><p><font color="red"><strong>BalanceCascade</strong></font>：从多数类$S_{max}$上随机抽取一个子集，与其他类训练一个分类器；<strong>剔除能被分类正确的分类器</strong>，重复若干次，多个分类器融合。</p>
</li>
<li><p>==<strong>NearMIss</strong>：利用K邻近信息挑选具有代表性的样本==。</p>
</li>
<li><p>==<strong>one-side Selection</strong>：采用数据清洗技术==。</p>
</li>
</ul>
</li>
<li><p><strong>==过采样==</strong>：</p>
<ul>
<li><p><strong>随机采样</strong></p>
</li>
<li><p><strong>SMOTE算法</strong>：对少数类$S_{min}$中每个样本x的K近邻随机选取一个样本y，在x，y的连线上随机选取一个点作为新的样本点。</p>
</li>
<li><p>==<strong>Borderline-SMOTE、ADASYN改进算法等</strong>==</p>
</li>
</ul>
</li>
<li><h5><span id="分层抽样技术批量训练分类器的分层抽样技术-当面对不平衡类问题时这种技术通过消除批次内的比例差异可使训练过程更加稳定">==分层抽样技术==：批量训练分类器的「分层抽样」技术。当面对不平衡类问题时，这种技术（通过消除批次内的比例差异）可使训练过程更加稳定。</span></h5></li>
</ul>
<h3><span id="1-2-算法的角度"><strong>1. 2 算法的角度</strong></span></h3><p>考虑<strong>不同误分类情况代价的差异性</strong>对算法进行优化，主要是基于<strong>代价敏感学习算法</strong>(Cost-Sensitive Learning)，代表的算法有<strong>==adacost==</strong>。<a href="实现基于代价敏感的AdaCost算法">实现基于代价敏感的AdaCost算法</a></p>
<ul>
<li><p><strong>代价函数</strong>：可以增加小类样本的权值，降低大类样本的权值（这种方法其实是产生了新的数据分布，即产生了新的数据集），从而使得分类器将重点集中在小类样本身上。刚开始，可以设置每个类别的权值与样本个数比例的倒数，然后可以使用过采样进行调优。</p>
<blockquote>
<p>  这种方法的难点在于设置合理的权重，实际应用中一般让各个分类间的加权损失值近似相等。当然这并不是通用法则，还是需要具体问题具体分析。</p>
</blockquote>
</li>
<li><h5><span id="xgb自定义损失函数-jhwjhw0123imbalance-xgboost-focal-loss">XGB自定义损失函数 /<strong><a href="https://github.com/jhwjhw0123/Imbalance-XGBoost">Imbalance-XGBoost </a></strong>【Focal Loss】：</span></h5><p> <img src="https://camo.githubusercontent.com/d79dd87cc30238a9124e1d26f787aed887a587d6061dcba4cdea9ebaec84836a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f5c6470697b3135307d2673706163653b4c5f7b777d2673706163653b3d2673706163653b2d5c73756d5f7b693d317d5e7b6d7d5c6861747b797d5f7b697d28312d795f7b697d295e7b5c67616d6d617d5c746578747b6c6f677d28795f7b697d292673706163653b2b2673706163653b28312d5c6861747b797d5f7b697d29795f7b697d5e7b5c67616d6d617d5c746578747b6c6f677d28312d795f7b697d29" alt="img" style="zoom: 67%;"></p>
</li>
</ul>
<h3><span id="13-分类方式">1.3 <strong>分类方式</strong></span></h3><p>可以把小类样本作为<strong>异常点</strong>(outliers)，把问题转化为<strong>异常点检测问题(anomaly detection)</strong>。此时分类器需要学习到大类的决策分界面，即分类器是一个<strong>单个类分类器（One Class Classifier）</strong>。代表的算法有<font color="red"> <strong>One-class SVM</strong></font>。</p>
<blockquote>
<h4><span id="一类分类算法">一类分类算法:</span></h4><p>  不平衡数据集的一类分类算法:<a href="https://machinelearningmastery.com/one-class-classification-algorithms/">https://machinelearningmastery.com/one-class-classification-algorithms/</a></p>
<p>  一类分类是机器学习的一个领域，它提供了异常值和异常检测的技术,如何使一类分类算法适应具有严重偏斜类分布的不平衡分类,如何拟合和评估 SVM、隔离森林、椭圆包络、局部异常因子等一类分类算法。</p>
<h4><span id="不平数据集的划分方法">不平数据集的划分方法？</span></h4><ul>
<li>K折交叉验证？</li>
<li><p>自助法？</p>
<h4><span id="不平数据集的评价方法">不平数据集的评价方法？</span></h4><p>G-Mean和ROC曲线和AUC。Topk@P</p>
</li>
<li><p><strong>AP衡量的是学出来的模型在每个类别上的好坏，==mAP衡量==的是学出的模型在所有类别上的好坏，得到AP后mAP的计算就变得很简单了，就是取所有AP的平均值。</strong></p>
</li>
</ul>
</blockquote>
<h3><span id="二-类别不平衡如何得到一个不错的分类器">二、「类别不平衡」如何得到一个不错的分类器？</span></h3><blockquote>
<p>  <strong>微调</strong>：<a href="https://zhuanlan.zhihu.com/p/32940093">如何处理数据中的「类别不平衡」？</a></p>
</blockquote>
<p>机器学习中常常会遇到数据的<strong>类别不平衡（class imbalance）</strong>，也叫数据偏斜（class skew）。以常见的二分类问题为例，我们希望预测病人是否得了某种罕见疾病。但在历史数据中，阳性的比例可能很低（如百分之0.1）。在这种情况下，学习出好的分类器是很难的，而且在这种情况下得到结论往往也是很具迷惑性的。</p>
<p>以上面提到的场景来说，如果我们的分类器<strong>总是</strong>预测一个人未患病，即预测为反例，那么我们依然有高达99.9%的预测准确率。然而这种结果是没有意义的，这提出了今天的第一个问题，如何有效在类别不平衡的情况下评估分类器？</p>
<p><strong>当然，本文最终希望解决的问题是：在数据偏斜的情况下，如何得到一个不错的分类器？如果可能，是否可以找到一个较为简单的解决方法，而规避复杂的模型、数据处理，降低我们的工作量。</strong></p>
<h4><span id="21-类别不平衡下的评估问题"><strong>2.1 类别不平衡下的评估问题</strong>?</span></h4><p>而<strong>当类别不平衡时，准确率就非常具有迷惑性</strong>，而且意义不大。给出几种主流的评估方法：</p>
<ul>
<li><strong>ROC</strong>是一种常见的替代方法，全名receiver operating curve，计算ROC曲线下的面积是一种主流方法</li>
<li><strong>Precision-recall curve</strong>和ROC有相似的地方，但定义不同，计算此曲线下的面积也是一种方法</li>
<li><strong>Precision@n</strong>是另一种方法，特制将分类阈值设定得到恰好n个正例时分类器的precision</li>
<li>Average precision也叫做平均精度，主要描述了precision的一般表现，在异常检测中有时候会用</li>
<li>直接使用Precision也是一种想法，但此时的假设是分类器的阈值是0.5，因此意义不大</li>
</ul>
<blockquote>
<p>  本文的目的不是介绍一般的分类评估标准，简单的科普可以参看：<a href="https://www.zhihu.com/question/19645541">如何解释召回率与准确率？</a></p>
</blockquote>
<h4><span id="22-解决类别不平衡中的奇淫巧技有什么"><strong>2.2 解决类别不平衡中的“奇淫巧技”有什么？</strong></span></h4><p>对于类别不平衡的研究已经有很多年了，在资料[1]中就介绍了很多比较复杂的技巧。结合我的了解举几个简单的例子：</p>
<blockquote>
<p>  [1] He, H. and Garcia, E.A., 2009. Learning from imbalanced data. <em>IEEE Transactions on knowledge and data engineering</em>, <em>21</em>(9), pp.1263-1284.</p>
</blockquote>
<ul>
<li>对数据进行采用的过程中通过相似性同时生成并插样“少数类别数据”，叫做SMOTE算法</li>
<li>对数据先进行聚类，再将大的簇进行随机欠采样或者小的簇进行数据生成</li>
<li>把监督学习变为无监督学习，舍弃掉标签把问题转化为一个无监督问题，如异常检测</li>
<li><strong>先对多数类别进行随机的欠采样，并结合boosting算法进行集成学习</strong></li>
</ul>
<h4><span id="23-简单通用的算法有哪些">==<strong>2.3 简单通用的算法有哪些？</strong>==</span></h4><ul>
<li>对较多的那个类别进行欠采样(under-sampling)，舍弃一部分数据，使其与较少类别的数据相当</li>
<li>对较少的类别进行过采样(over-sampling)，重复使用一部分数据，使其与较多类别的数据相当</li>
<li><strong>阈值调整（threshold moving）</strong>，将原本默认为0.5的阈值调整到 较少类别/（较少类别+较多类别）即可</li>
</ul>
<p>当然很明显我们可以看出，<strong>第一种和第二种方法都会明显的改变数据分布，我们的训练数据假设不再是真实数据的无偏表述</strong>。在第一种方法中，我们<strong>浪费了很多数据</strong>。而第二类方法中有无中生有或者重复使用了数据，会导致过拟合的发生。</p>
<p><strong>因此欠采样的逻辑中往往会结合集成学习来有效的使用数据，假设正例数据n，而反例数据m个。我们可以通过欠采样，随机无重复的生成（k=n/m）个反例子集，并将每个子集都与相同正例数据合并生成k个新的训练样本。我们在k个训练样本上分别训练一个分类器，最终将k个分类器的结果结合起来，比如求平均值。这就是一个简单的思路，也就是==Easy Ensemble== [5]。</strong></p>
<p>但不难看出，其实这样的过程是需要花时间处理数据和编程的，对于很多知识和能力有限的人来说难度比较大。特此推荐两个简单易行且效果中上的做法：</p>
<ul>
<li>简单的调整阈值，不对数据进行任何处理。此处特指将分类阈值从0.5调整到正例比例</li>
<li>使用现有的集成学习分类器，如随机森林或者xgboost，<strong>==并调整分类阈值==</strong></li>
</ul>
<p><strong>提出这样建议的原因有很多。首先，==简单的阈值调整从经验上看往往比过采样和欠采样有效==</strong> [6]。其次，如果你对统计学知识掌握有限，而且编程能力一般，在集成过程中更容易出错，还不如使用现有的集成学习并调整分类阈值。</p>
<h4><span id="24-一个简单但有效的方案"><strong>2.4 一个简单但有效的方案</strong></span></h4><p>经过了上文的分析，我认为一个比较靠谱的解决方案是：</p>
<ul>
<li>不对数据进行过采样和欠采样，但使用现有的集成学习模型，如随机森林</li>
<li>输出随机森林的预测概率，<strong>调整阈值得到最终结果</strong></li>
<li><strong>选择合适的评估标准，如precision@n</strong></li>
</ul>
<h3><span id="三-脉脉数据集不平衡应该思考什么">三、脉脉：数据集不平衡应该思考什么</span></h3><p>首先, 猜测一下, 你研究的数据存在着较 大的不平衡, 你还是比较关注正类(少数类) 样本的, 比如【想要识别出 有信用风险 的 人】那么就要谈一下你所说的【模型指标还行】这个问题。<strong>auc这种复合指标先不提, precision代表的是, 你预测的信用风险人群, 其中有多少是真的信用风险人群。recall 代表的是, “真的信用风险人群”有多少被你识别出来了</strong>；</p>
<ul>
<li>所以, 倘若你比较关注的是【我想要找出 所有”可能有违约风险的人”】宁可错杀也不 放过。那么你应该重点关注的就是召回率 recall。在此基础上, 尽量提高precision。</li>
<li>你把训练集的正负样本控制在64左右, 那 么你是怎么控制的呢, 是单纯用了数据清理技术, 还是单纯生成了一些新的样本, 还是怎么做的？</li>
<li><font color="red">**如果条件允许, 可以查看一下你被错分的 样本, 看看被错分的原因可能是什么, 是因为类重叠, 还是有少数类的分离还是单纯的因为不平衡比太夸张所以使分类器产生偏倚?** </font></li>
<li><font color="red">不知道你用的什么模型, 但是现在有一些把重采样和分类器结合在一起的集成学习方法, 可以试试看。</font></li>
<li>维度太高的时候, <strong>特征的提取很重要</strong>呀！</li>
<li>当做异常检测问题可能会好一些?</li>
</ul>
<h3><span id="四-样本准备与权重指标">四、样本准备与权重指标</span></h3><blockquote>
<p>  样本权重对逻辑回归评分卡的影响探讨: <a href="https://zhuanlan.zhihu.com/p/110982479">https://zhuanlan.zhihu.com/p/110982479</a></p>
</blockquote>
<h4><span id="风控业务背景"><strong>风控业务背景</strong></span></h4><p><strong>在统计学习建模分析中，样本非常重要，它是我们洞察世界的窗口</strong>。在建立逻辑回归评分卡时，我们也会考虑对样本赋予不同的权重weight，希望模型学习更有侧重点。</p>
<p>诚然，我们可以通过实际数据测试来检验赋权前后的差异，但我们更希望从理论上分析其合理性。毕竟理论可以指导实践。本文尝试探讨样本权重对逻辑回归评分卡的影响，以及从业务和技术角度分析样本权重调整的操作方法。</p>
<h4><span id="part-1-样本加权对woe的影响"><strong>Part 1. 样本加权对WOE的影响</strong></span></h4><p>在<strong>《</strong><a href="https://zhuanlan.zhihu.com/p/80134853">WOE与IV指标的深入理解应用</a><strong>》</strong>一文中，我们介绍了WOE的概念和计算方法。在逻辑回归评分卡中，其具有重要意义。其公式定义如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=++WOE_i+%3D+ln%28+%5Cfrac%7BGood_i%7D%7BGood_T%7D%2F+%5Cfrac%7BBad_i%7D%7BBad_T%7D+%29+%3D+ln%28%5Cfrac%7BGood_i%7D%7BBad_i%7D%29+-+ln%28%5Cfrac%7BGood_T%7D%7BBad_T%7D%29+%5Ctag%7B1%7D" alt="[公式]"></p>
<p><strong>现在，我们思考在计算WOE时，是否要考虑样本权重呢？</strong></p>
<p>如图1所示的样本，我们希望对某些样本加强学习，因此对年龄在46岁以下的样本赋予权重1.5，而对46岁以上的样本赋予权重1.0，也就是加上权重列weight。此时再计算WOE值，我们发现数值发生变化。这是因为权重的改变，既影响了局部bucket中的 <img src="https://www.zhihu.com/equation?tex=odds" alt="[公式]"> ，也影响了整体的 <img src="https://www.zhihu.com/equation?tex=odds" alt="[公式]"> 。</p>
<p><img src="https://pic1.zhimg.com/80/v2-538659592a96c40bd4098f29d30d144c_1440w.jpg" alt="img">我们有2种对样本赋权后的模型训练方案，如图2所示。</p>
<ul>
<li>方案1：WOE变换利用原训练集，LR模型训练时利用加权后的样本。</li>
<li>方案2: WOE变换和LR模型训练时，均使用加权后的样本。</li>
</ul>
<p><img src="https://pic2.zhimg.com/80/v2-af2b686a4cdddff60556e90545378f91_1440w.jpg" alt="img"></p>
<p>个人更倾向于第一种方案，原因在于：<strong>WOE变换侧重变量的可解释性，引入样本权重会引起不可解释的困扰。</strong></p>
<h4><span id="part-2-采样对lr系数的影响"><strong>Part 2. 采样对LR系数的影响</strong></span></h4><p>我们定义特征向量 <img src="https://www.zhihu.com/equation?tex=%5Ctextbf%7Bx%7D+%3D+x_1%2C+x_2%2C...%2C+x_n" alt="[公式]"> 。记 <img src="https://www.zhihu.com/equation?tex=G+%3D+Good%2C+B+%3D+Bad" alt="[公式]"> ，那么逻辑回归的公式组成便是：</p>
<p><img src="https://www.zhihu.com/equation?tex=Ln%28odds%28G%7C%5Ctextbf%7Bx%7D%29%29+%3D+Ln%28%5Cfrac%7Bp_Gf%28%5Ctextbf%7Bx%7D%7CG%29%7D%7Bp_Bf%28%5Ctextbf%7Bx%7D%7CB%29%7D%29+%3D+Ln%28%5Cfrac%7Bp_G%7D%7Bp_B%7D%29+%2B+Ln%28%5Cfrac%7Bf%28%5Ctextbf%7Bx%7D%7CG%29%7D%7Bf%28%5Ctextbf%7Bx%7D%7CB%29%7D%29+%5C%5C+%3D+Ln%28%5Cfrac%7Bp_G%7D%7Bp_B%7D%29+%2B+Ln%28%5Cfrac%7Bf%28x_1%2Cx_2%2C...%2Cx_n%7CG%29%7D%7Bf%28x_1%2Cx_2%2C...%2Cx_n%7CB%29%7D%29+%5C%5C+%3D+Ln%28%5Cfrac%7Bp_G%7D%7Bp_B%7D%29+%2B+Ln%28%5Cfrac%7Bf%28x_1%7CG%29%7D%7Bf%28x_1%7CB%29%7D%29+%2B+Ln%28%5Cfrac%7Bf%28x_2%7CG%29%7D%7Bf%28x_2%7CB%29%7D+%2B+%5Cspace+...+%5Cspace+%2B+Ln%28%5Cfrac%7Bf%28x_n%7CG%29%7D%7Bf%28x_n%7CB%29%7D%5C%5C+%3D+Ln%28odds_%7Bpop%7D%29+%2B+Ln%28odds_%7Binfo%7D+%28%5Ctextbf%7Bx%7D%29%29+%5Ctag%7B2%7D" alt="[公式]"></p>
<p>其中，第2行到第3行的变换是基于朴素贝叶斯假设，即<strong>自变量 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 之间相互独立</strong>。</p>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=odds_%7Bpop%7D" alt="[公式]"> 是指总体（训练集）的 <img src="https://www.zhihu.com/equation?tex=odds" alt="[公式]">，指<strong>先验信息</strong><img src="https://www.zhihu.com/equation?tex=odds" alt="[公式]">。</li>
<li><img src="https://www.zhihu.com/equation?tex=odds_%7Binfo%7D+%28%5Ctextbf%7Bx%7D%29" alt="[公式]"> 是指自变量引起的 <img src="https://www.zhihu.com/equation?tex=odds" alt="[公式]"> 变化，我们称为<strong>后验信息</strong><img src="https://www.zhihu.com/equation?tex=odds" alt="[公式]"> 。</li>
</ul>
<p><strong><font color="red"> 因此，随着观察信息的不断加入，对群体的好坏 <img src="https://www.zhihu.com/equation?tex=odds" alt="[公式]"> 判断将越来越趋于客观。</font></strong></p>
<p><img src="https://pic2.zhimg.com/80/v2-0021358b05ebb5fea25073cceea1da2d_1440w.jpg" alt="img"></p>
<h5><span id="样本权重调整直接影响先验项也就是截距-那对系数的影响呢">样本权重调整直接影响先验项，也就是截距。那对系数的影响呢？</span></h5><p>接下来，我们以过采样（Oversampling）和欠采样（Undersampling）为例，分析采样对LR系数的影响。如图4所示，对于不平衡数据集，过采样是指对正样本简单复制很多份；欠采样是指对负样本随机抽样。最终，正负样本的比例将达到1:1平衡状态。<br><img src="https://pic4.zhimg.com/80/v2-c49197fdd37023e75daabd7e74feb11b_1440w.jpg" alt="img">图 4 - 欠采样（左）和过采样（右）</p>
<p>我们同样从贝叶斯角度进行解释：</p>
<h2><span id><img src="https://www.zhihu.com/equation?tex=P%28B%7C%5Ctextbf%7Bx%7D%29+%3D+%5Cfrac%7BP%28%5Ctextbf%7Bx%7D%7CB%29P%28B%29%7D%7BP%28%5Ctextbf%7Bx%7D%29%7D++%3D+%5Cfrac%7BP%28%5Ctextbf%7Bx%7D%7CB%29P%28B%29%7D%7BP%28%5Ctextbf%7Bx%7D%7CB%29P%28B%29+%2B+P%28%5Ctextbf%7Bx%7D%7CG%29P%28G%29%7D+%5C%5C+%5CLeftrightarrow+%5Cfrac%7B1%7D%7BP%28B%7C%5Ctextbf%7Bx%7D%29%7D+%3D++1+%2B+%5Cfrac%7BP%28%5Ctextbf%7Bx%7D%7CG%29P%28G%29%7D%7BP%28%5Ctextbf%7Bx%7D%7CB%29P%28B%29%7D+%5C%5C+%5CLeftrightarrow++Ln%28%5Cfrac%7BP%28%5Ctextbf%7Bx%7D%7CG%29%7D%7BP%28%5Ctextbf%7Bx%7D%7CB%29%7D%29+%3D+Ln%28%5Cfrac%7B1%7D%7BP%28B%7C%5Ctextbf%7Bx%7D%29%7D+-+1%29++-+Ln%28%5Cfrac%7BP%28G%29%7D%7BP%28B%29%7D%29+%5C%5C+%5CLeftrightarrow++Ln%28%5Cfrac%7BP%28G%7C%5Ctextbf%7Bx%7D%29%7D%7BP%28B%7C%5Ctextbf%7Bx%7D%29%7D%29++%3D+Ln%28%5Cfrac%7BP%28%5Ctextbf%7Bx%7D%7CG%29%7D%7BP%28%5Ctextbf%7Bx%7D%7CB%29%7D%29+%2B+Ln%28%5Cfrac%7BP%28G%29%7D%7BP%28B%29%7D%29+%5Ctag%7B3%7D" alt="[公式]"></span></h2><p>假设采样处理后的训练集为 <img src="https://www.zhihu.com/equation?tex=%5Ctextbf%7Bx%7D%27" alt="[公式]"> 。记 <img src="https://www.zhihu.com/equation?tex=%5C%23+B" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5C%23+G" alt="[公式]"> 分别表示正负样本数，那么显然：</p>
<p><img src="https://www.zhihu.com/equation?tex=odds+%3D+%5Cfrac%7B%5C%23+G%7D%7B%5C%23+B%7D+%5Cne+%5Cfrac%7B%5C%23+G%27%7D%7B%5C%23+B%27%7D+%3D+odds%27+%5Ctag%7B4%7D" alt="[公式]"></p>
<p>由于 <img src="https://www.zhihu.com/equation?tex=Ln%28%5Cfrac%7BP%28G%29%7D%7BP%28B%29%7D%29++%3D+Ln%28%5Cfrac%7B%5C%23+G%7D%7B%5C%23+B%7D%29+" alt="[公式]"> ，因此对应<strong>截距将发生变化</strong>。</p>
<p>无论是过采样，还是欠采样，处理后的新样本都和原样本服从同样的分布，即满足：</p>
<p><img src="https://www.zhihu.com/equation?tex=P%28%5Ctextbf%7Bx%7D%7CG%29+%3D+P%28%5Ctextbf%7Bx%7D%27%7CG%27%29+%5C%5C+P%28%5Ctextbf%7Bx%7D%7CB%29+%3D+P%28%5Ctextbf%7Bx%7D%27%7CB%27%29+%5Ctag%7B5%7D" alt="[公式]"></p>
<p>因此， <img src="https://www.zhihu.com/equation?tex=Ln%28%5Cfrac%7BP%28%5Ctextbf%7Bx%7D%7CG%29%7D%7BP%28%5Ctextbf%7Bx%7D%7CB%29%7D%29++%3D+Ln%28%5Cfrac%7BP%28%5Ctextbf%7Bx%7D%27%7CG%27%29%7D%7BP%28%5Ctextbf%7Bx%7D%27%7CB%27%29%7D%29+" alt="[公式]"> ，即<strong>系数不发生变化</strong>。</p>
<p><strong>实践证明，按照做评分卡的方式，做WOE变换，然后跑LR，单变量下确实只有截距影响。而对于多变量，理想情况下，当各自变量相互独立时，LR的系数是不变的，但实际自变量之间多少存在一定的相关性，所以还是会有一定的变化。</strong></p>
<h4><span id="part-3-样本准备与权重指标"><strong><font color="red"> Part 3. 样本准备与权重指标</font></strong></span></h4><p>风控建模的基本假设是<strong>未来样本和历史样本的分布是一致</strong>的。模型从历史样本中拟合 <img src="https://www.zhihu.com/equation?tex=X_%7Bold%7D" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 之间的关系，并根据未来样本的 <img src="https://www.zhihu.com/equation?tex=X_%7Bnew%7D" alt="[公式]"> 进行预测。因此，我们总是在思考，<strong>如何选择能代表未来样本的训练样本。</strong></p>
<p>如图5所示，不同时间段、不同批次的样本总是存在差异，即<strong>服从不同的总体分布</strong>。因此，我们需要<strong>从多个维度来衡量两个样本集之间的相似性。</strong></p>
<p>从迁移学习的角度看，这是一个从源域（source domain）中学习模式，并应用到目标域（target domain）的过程。在这里，源域是训练集，目标域指测试集，或者未来样本。</p>
<p>这就会涉及到一些难点：</p>
<ul>
<li>假设测试集OOT与未来总体分布样本基本一致，但未来样本是不可知且总是在发生变化。</li>
<li>面向测试集效果作为评估指标，会出现在测试集上过拟合现象。<br><img src="https://pic4.zhimg.com/80/v2-b40bd56da51ab37d01fbffbdb8bc91f7_1440w.jpg" alt="img"></li>
</ul>
<p><strong>那么，建模中是否可以考虑建立一个权重指标体系，即综合多方面因素进行样本赋权？我们采取2种思路来分析如何开展。</strong></p>
<p><strong><font color="red"> 业务角度</font></strong>：</p>
<ol>
<li><strong>时间因素</strong>，对近期样本提高权重，较远样本降低权重。这是考虑近期样本与未来样本之间的“相似度”更高，希望模型学到更多近期样本的模式。</li>
<li><strong>贷款类型</strong>，不同额度、利率、期限的样本赋予不同权重，这需要结合业务未来的发展方向。例如，未来业务模式希望是小额、短期、低利率，那就提高这批样本的权重。</li>
<li><strong>样本分群</strong>，不同群体赋予不同权重。例如，按流量获客渠道，如果未来流量渠道主要来自平台A，那么就提高这批样本权重。</li>
</ol>
<p>结合以上各维度，可得到总体采样权重的一种融合方式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=w+%3D+w_1+%2A+w_2+%2A+w_3+%5Ctag%7B6%7D" alt="[公式]"></p>
<p><strong>这种业务角度的方案虽然解释性强，但实际拍定多大的权重显得非常主观，实践中往往需要不断尝试，缺少一些理论指导。</strong></p>
<p><strong><font color="red"> 技术角度：</font></strong></p>
<ol>
<li><strong>过采样、欠采样等，从样本组成上调整正负不平衡</strong>。</li>
<li>代价敏感学习，在损失函数对好坏样本加上不同的代价。比如，坏样本少，分错代价更高。</li>
<li>借鉴Adaboost的做法，对误判样本在下一轮训练时提高权重。</li>
</ol>
<p>在机器学习中，有一个常见的现象——<strong>Covariate Shift</strong>，是指当训练集的样本分布和测试集的样本分布不一致的时候，训练得到的模型无法具有很好的泛化 (Generalization) 能力。</p>
<p>其中一种做法，既然是希望让训练集尽可能像测试集，那就让模型帮助我们做这件事。如图6所示，将测试集标记为1，训练集标记为0，训练一个LR模型，在训练集上预测，概率越高，说明这个样例属于测试集的可能性越大。以此达到样本权重调整的目的。</p>
<p><img src="https://pic1.zhimg.com/80/v2-6a218af9de452a4c58e36a9e8e6d4bb0_1440w.jpg" alt="img"></p>
<h4><span id="part-4-常见工具包的样本赋权"><strong>Part 4. 常见工具包的样本赋权</strong></span></h4><p>现有Logistic Regression模块主要来自sklearn和scipy两个包。很不幸，scipy包并不支持直接赋予权重列。这是为什么呢？有统计学家认为，<strong><font color="red"> 尊重真实样本分布，人为主观引入样本权重，反而可能得出错误的结论。</font></strong></p>
<p><img src="https://pic1.zhimg.com/80/v2-4942078e60d225438f77362c675bec20_1440w.jpg" alt="img"></p>
<p>因此，我们只能选择用scikit-learn。样本权重是如何体现在模型训练过程呢？查看源码后，发现目前主要是体现在<strong>损失函数</strong>中，即<strong>代价敏感学习。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Logistic loss is the negative of the log of the logistic function.</span></span><br><span class="line"><span class="comment"># 添加L2正则项的逻辑回归对数损失函数</span></span><br><span class="line">out = -np.<span class="built_in">sum</span>(sample_weight * log_logistic(yz)) + <span class="number">.5</span> * alpha * np.dot(w, w)</span><br></pre></td></tr></table></figure>
<p><strong><font color="red"> 样本权重对决策分割面的影响:</font></strong></p>
<p><img src="https://pic1.zhimg.com/80/v2-699ad7ac670c27a5b0963b8b104ad7fc_1440w.jpg" alt="img"></p>
<p>以下是scikit-learn包中的逻辑回归参数列表说明，可以发现调节样本权重的方法有两种：</p>
<ul>
<li>在class_weight参数中使用balanced</li>
<li>在调用fit函数时，通过sample_weight调节每个样本权重。</li>
</ul>
<p>如果同时设置上述2个参数，<strong>那么样本的真正权重是class_weight * sample_weight.</strong></p>
<p><strong>那么，在评估模型的指标时，是否需要考虑抽样权重，即还原真实场景下的模型评价指标？</strong>笔者认为，最终评估还是需要还原到真实场景下。例如，训练集正负比例被调节为1:1，但这并不是真实的 <img src="https://www.zhihu.com/equation?tex=odds" alt="[公式]"> ，在预测时将会偏高。因此，仍需要进行模型校准。</p>
<h4><span id="part-5-总结"><strong>Part 5. 总结</strong></span></h4><p>本文系统整理了样本权重的一些观点，但目前仍然没有统一的答案。据笔者所知，目前在实践中还是采取以下几种方案：</p>
<ol>
<li>尊重原样本分布，不予处理，LR模型训练后即为真实概率估计。</li>
<li>结合权重指标综合确定权重，训练完毕模型后再进行校准，还原至真实概率估计。</li>
</ol>
<p>值得指出的是，大环境总是在发生变化，造成样本分布总在偏移。因此，尽可能增强模型的鲁棒性，以及策略使用时根据实际情况灵活调整，两者相辅相成，可能是最佳的使用方法。欢迎大家一起讨论业界的一些做法。</p>
]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（5）特征融合</title>
    <url>/posts/2TRK228/</url>
    <content><![CDATA[<h2><span id="特征工程数据清洗预处理-特征生成-特征拼接">特征工程｜数据清洗（预处理）、特征生成、特征拼接</span></h2><ul>
<li>这或许是全网最全机器学习模型融合方法总结！：<a href="https://zhuanlan.zhihu.com/p/511246278">https://zhuanlan.zhihu.com/p/511246278</a></li>
</ul>
<p>特征工程的完整流程是：特征设计 -&gt; 特征获取 -&gt; 特征处理 -&gt; 特征存储 -&gt; 特征监控。前边介绍了那么多，相当于是对特征设计、特征获取、特征存储进行了说明，而特征工程中最重要的环节则是特征处理。特征处理中还包括：数据清洗、特征生成、特征拼接、特征处理、特征转换、特征选择。本篇主要介绍<strong>数据清洗、特征生成、特征拼接</strong>。</p>
<h3><span id="一-数据清洗">一、数据清洗：</span></h3><p>从特征工程角度讲，数据清洗是特征工程的前置阶段（但是也会贯穿整个数据应用过程），其本义是对数据进行重新的<strong>审查和校验</strong>，目的在于<strong>删除重复信息</strong>、纠正存在的错误数据，并保证数据的一致性。数据清洗是整个数据分析过程中不可缺少的一个环节，其结果质量直接关系到模型效果和最终结论。</p>
<p>一个特征处理的完整流程可以表示为：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/02kicEWsInicg2tpfKoZNzmSRj6mXo9Ppic3w2e5VGe7PqXlEiaibdcgmj8PMZqUOcLCrcDLNVkERGvib4MYOjJDu4Lw/640?wx_fmt=png" alt="img"></p>
<p>因此基础数据的准确性、完备性、一致性决定了后续特征数据的有效性。在我们日常使用的公开数据集中，很多都是已经被处理后的了，比如学术界中使用很广泛的MovieLens数据集，但是在真实的业务场景中，我们拿到的数据其实直接是没有办法使用的，可能包含了<strong>大量的缺失值</strong>，可能包含<strong>大量的噪音</strong>，也可能因为人工录入错误导致有异常点存在，对我们挖据出有效信息造成了一定的困扰，所以我们需要通过一些方法，尽量提高数据的质量。</p>
<p><strong>初期数据清洗更多的是针对单条样本数据的清洗和检测</strong>，包括：</p>
<ul>
<li>数据表示一致性处理</li>
<li>逻辑错误值处理</li>
<li>缺失值处理</li>
<li>非必要性数据剔除</li>
</ul>
<p>在实际的业务场景中，数据是由系统收集或用户填写而来，有很大可能性在格式和内容上存在一些问题，同样类型的数据在不同的团队上报过程中产出的内容或格式会不一致，同样不同数据源采集而来的数据内容和格式也会不一致。</p>
<blockquote>
<p>  数据格式的一致性。比如<strong>时间信息</strong>（以2020年6月18日，11点11分12秒为例），有的用毫秒时间戳表示（1592449872000），有的用秒时间戳表示（1592449872），有的用带横线的时间表示（2020-06-18 11:11:12），有的则用不带横线的时间表示（20200618 11:11:12）。</p>
<p>  数据类型的一致性。比如不同的数据表中，同样表示用户ID的字段，有的可能是string类型，有的是int类型。如果用string类型表示，如果用户id缺失的话，正常可以留空，但是不同团队，不同人对于缺失的id处理方式也会不一致，比如有的用None，有的用Null，有的则用0表示，可谓是千奇百怪。小编在日常工作中也会经常遇到这种情况，被折磨的体无完肤。</p>
</blockquote>
<h3><span id="二-特征生成">二、特征生成</span></h3><p>对基础数据进行清理之后需要做的就是生成我们需要的特征，在特征设计部分提到特征主要分为四大维度，根据小编的经验特征又可以根据其值的属性划分为：</p>
<ul>
<li><strong>类别特征</strong>：即特征的属性值是一个有限的集合，比如用户性别、事物的类别、事物的ID编码类特征等</li>
<li><strong>连续特征</strong>：即用户行为、类别、组合特征之类的统计值，比如用户观看的视频部数、某类别下事物的个数等</li>
<li><strong>时间序列特征</strong>：即和时间相关的特征，比如用户来访时间、用户停留时长、当前时间等。</li>
<li>组合特征：即多种类别的组合特征，比如用户在某个类别下的行为统计特征、当天内事物被访问次数特征等</li>
<li><strong>文本特征</strong>：即和文本相关的特征，比如评论数据、商品描述、新闻内容等。</li>
<li><strong>Embedding特征</strong>：即一些基础特征的高层次表示，比如用户ID编码的Embedding表示、事物ID编码的Embedding表示、<strong>用户访问事物序列的Embedding编码</strong>等。</li>
</ul>
<h3><span id="三-特征融合">==三、特征融合==</span></h3><blockquote>
<p>  多模态特征融合三部曲: <a href="https://zhuanlan.zhihu.com/p/390668652">https://zhuanlan.zhihu.com/p/390668652</a></p>
<p>  推荐系统（六）—— 特征融合 :  <a href="https://zhuanlan.zhihu.com/p/459012483">https://zhuanlan.zhihu.com/p/459012483</a></p>
</blockquote>
<h4><span id="31-特征处理">3.1 特征处理</span></h4><p>假设你有三种类型数据，或者说可以是三个不同维度的向量</p>
<p><img src="https://www.zhihu.com/equation?tex=x_1%5Cin%5Cmathbb%7BR%7D%5E%7Bn_1%7D%2Cx_2%5Cin%5Cmathbb%7BR%7D%5E%7Bn_2%7D%2Cx_3%5Cin%5Cmathbb%7BR%7D%5E%7Bn_3%7D" alt="[公式]"></p>
<p>第一种融合手段就是在训练前进行的</p>
<ol>
<li><strong>三个向量直接concat，可能维度会比较高，再进行个PCA</strong></li>
<li><strong>自编码器结构</strong>：三个向量通过MLP映射成一个维度后相加，用还原回去；融合特征再用来做后续的模型设计和训练就好了。</li>
</ol>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220519212856682.png" alt="image-20220519212856682" style="zoom: 33%;"></p>
<h4><span id="32-模型结构">3.2 模型结构</span></h4><p>一种直接的思想就是分而治之，多分支网络；还有一种比较出名的在中间层进行融合的方法，多模态双线性矩阵分解池化方法（MFB），本质上就是对不同模态数据进行双线性融合，借助矩阵分解的思想，再对原始特征进行高维映射，然后element-wise相乘后再做pooling操作。</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220519220722481.png" alt="image-20220519220722481" style="zoom: 33%;"></p>
<p><img src="https://pic3.zhimg.com/80/v2-c4ecc29092d26822fef3f420c2bf5bb2_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="33-后处理">3.3 后处理</span></h4><p>后处理其实也是分而治之的思想，多模态数据分别训练不同的模型，再将不同模型的预测输出进行融合，比如平均、加权，或者fix住原来的多个网络，后面再加一层进行微调。</p>
<p><img src="https://pic3.zhimg.com/80/v2-3e0669ac057b924e8814f34578d4acee_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h4><span id="34-特征融合是什么和特征交叉有什么区别呢">3.4 特征融合是什么？和特征交叉有什么区别呢？</span></h4><p>在上一篇文章（<a href="https://zhuanlan.zhihu.com/p/457853657">yu-lzn：推荐系统（五）—— 特征交叉</a>）中，我们讨论了特征交叉，特征交叉也称为特征组合，旨在提高模型对非线性的建模能力，从而提高模型的性能。<strong>特征融合</strong>和特征交叉有相同的目的，都是为了提高模型的性能。特征融合是想更好地利用不同特性的特征。</p>
<blockquote>
<p>  随着信息时代的发展，<strong>在推荐系统中，多模态信息的融合也变得越来越重要</strong>。以淘宝购物为例，用户在决策是否购买物品时，会考虑<strong>物品的属性</strong>、<strong>物品图片的展示</strong>、其他<strong>用户的评论信息</strong>、甚至是观看<strong>物品的介绍视频</strong>等等。换句话说，这些<strong>多模态信息（文本、图片、视频）会影响用户的行为</strong>。所以如何利用这些多模态信息来建模，是提高推荐系统准确度的一个途径。那么如何去融合这些不同来源的信息便是一个关键的问题。</p>
</blockquote>
]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（2）特征选择</title>
    <url>/posts/T8EY5H/</url>
    <content><![CDATA[<h2><span id="二-特征选择">二、特征选择</span></h2><blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/74198735">【机器学习】特征选择(Feature Selection)方法汇总</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/306057603"><em>特征选择方法</em>全面总结</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/479948993"><em>特征选择</em>的基本<em>方法</em>总结</a></p>
</blockquote>
<p> <img src="https://pic4.zhimg.com/v2-05756baf02bd7a023f7b27842594bc2b_b.jpg" alt="img"></p>
<p>训练数据包含许多冗余或无用的特征，移除这些特征并不会导致丢失信息。其中冗余是指一个本身很有用的特征与另外一个有用的特征强相关，或它包含的信息能从其它特征推演出来; 特征很多但样本相对较少</p>
<ul>
<li><p>产生过程：产生特征或特征子集候选集合；</p>
</li>
<li><p>评价函数：衡量特征或特征子集的重要性或者好坏程度，即量化特征变量和目标变量之间的联系以及特征之间的相互联系。为了避免过拟合，可用交叉验证的方式来评估特征的好坏；</p>
</li>
<li><p>停止准则：为了减少计算复杂度，需设定一个阈值，当评价函数值达到阈值后搜索停止</p>
</li>
<li><p>验证过程：在验证数据集上验证选出来的特征子集的有效性</p>
</li>
</ul>
<h3><span id="21-特征选择的目的"><strong>2.1 特征选择的目的</strong></span></h3><p>1.<strong>简化模型</strong>，使模型更易于理解：去除不相关的特征会降低学习任务的难度。并且可解释性能对模型效果的稳定性有更多的把握</p>
<p>2.<strong>改善性能</strong>：节省存储和计算开销</p>
<p>3.<strong>改善通用性、降低过拟合风险</strong>：减轻维数灾难，特征的增多会大大增加模型的搜索空间，大多数模型所需要的训练样本随着特征数量的增加而显著增加。特征的增加虽然能更好地拟合训练数据，但也可能增加方差</p>
<h3><span id="22-特征选择常见方法">2.2 特征选择常见方法</span></h3><ul>
<li><p>==<strong>Filter(过滤法)</strong>==</p>
<ul>
<li><strong>覆盖率</strong></li>
<li><strong>方差选择</strong></li>
<li><strong>Pearson(皮尔森)相关系数</strong></li>
<li><strong>卡方检验</strong></li>
<li><strong>互信息法(KL散度、相对熵)和最大信息系数</strong> </li>
<li>Fisher得分</li>
<li>相关特征选择</li>
<li>最小冗余最大相关性</li>
</ul>
</li>
<li><p><strong>Wrapper(包装法)</strong></p>
<ul>
<li>完全搜索</li>
<li>启发搜索</li>
<li>随机搜索</li>
</ul>
</li>
<li>==<strong>Embedded(嵌入法)</strong>==<ul>
<li>L1 正则项</li>
<li>树模型选择</li>
<li>不重要性特征选择</li>
</ul>
</li>
</ul>
<h3><span id="221-filter过滤法-特征集">2.2.1 <strong>Filter(过滤法)</strong> 【特征集】</span></h3><p><img src="https://pic4.zhimg.com/v2-d91b1bdb2bf6034b9e26b3620bf8a233_b.jpg" alt="img"></p>
<h4><span id="定义"><strong>定义</strong></span></h4><ul>
<li><strong>过滤法的思想就是不依赖模型，仅从特征的角度来做特征的筛选</strong>，具体又可以分为两种方法，一种是根据特征里面包含的信息量，如方差选择法，如果一列特征的方差很小，每个样本的取值都一样的话，说明这个特征的作用不大，可以直接剔除。另一种是对每一个特征，都计算关于目标特征的<a href="https://www.zhihu.com/search?q=相关度&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;479948993&quot;}">相关度</a>，然后根据这个相关度来筛选特征，只保留高于某个阈值的特征，这里根据相关度的计算方式不同就可以衍生出一下很多种方法。</li>
</ul>
<h4><span id="分类"><strong>分类</strong></span></h4><ul>
<li><strong>单变量过滤方法</strong>：不需要考虑特征之间的相互关系，按照特征变量和目标变量之间的相关性或互信息对特征进行排序，过滤掉最不相关的特征变量。优点是计算效率高、不易过拟合。</li>
<li><strong>多变量过滤方法</strong>：考虑特征之间的相互关系，常用方法有基于相关性和一致性的特征选择</li>
</ul>
<h4><span id="覆盖率">==覆盖率==</span></h4><ul>
<li>即特征在训练集中出现的比例。若覆盖率很小，如有10000个样本，但某个特征只出现了5次，则次覆盖率对模型的预测作用不大，可删除</li>
</ul>
<h4><span id="方差选择法">==<strong>方差选择法</strong>==</span></h4><ul>
<li>先计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"><span class="comment"># 方差选择法，返回值为特征选择后的数据</span></span><br><span class="line"><span class="comment"># 参数threshold为方差的阈值</span></span><br><span class="line">VarianceThreshold(threshold=<span class="number">3</span>).fit_transform(iris.data)</span><br></pre></td></tr></table></figure>
<h4><span id="pearson皮尔森相关系数用于度量两个变量x和y之间的线性相关性">==Pearson皮尔森相关系数==:用于度量两个变量X和Y之间的线性相关性</span></h4><ul>
<li><strong>用于度量两个变量X和Y之间的线性相关性</strong>，结果的取值区间为[-1, 1]， -1表示完全的负相关(这个变量下降，那个就会上升)，+1表示完全的正相关，0表示没有线性相关性</li>
<li>计算方法为两个变量之间的<strong>协方差</strong>和<strong>标准差</strong>的商</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line">  <span class="comment"># 选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line">  <span class="comment"># 第一个参数为计算评估特征是否好的函数，该函数输入特征矩阵和目标向量，</span></span><br><span class="line">  <span class="comment"># 输出二元组（评分，P值）的数组，数组第i项为第i个特征的评分和P值。</span></span><br><span class="line">  <span class="comment"># 在此为计算相关系数</span></span><br><span class="line">  <span class="comment"># 其中参数k为选择的特征个数</span></span><br><span class="line">SelectKBest(<span class="keyword">lambda</span> X, Y: array(<span class="built_in">map</span>(<span class="keyword">lambda</span> x:pearsonr(x, Y), X.T)).T, </span><br><span class="line">              k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<h4><span id="卡方检验自变量对因变量的相关性">==<strong>卡方检验</strong>==:自变量对因变量的相关性</span></h4><ul>
<li><strong>检验定性自变量对定性因变量的相关性</strong>。假设自变量有N种取值，因变量有M种取值，考虑自变量等于i且因变量等于j的样本频数的观察值与期望的差距，构建统计量:</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=%5Cchi%5E%7B2%7D%3D%5Csum+%5Cfrac%7B%28A-E%29%5E%7B2%7D%7D%7BE%7D+%5C%5C" alt="[公式]"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line"><span class="comment">#选择K个最好的特征，返回选择特征后的数据</span></span><br><span class="line">SelectKBest(chi2, k=<span class="number">2</span>).fit_transform(iris.data, iris.target)</span><br></pre></td></tr></table></figure>
<h4><span id="psi互信息法kl散度-相对熵和最大信息系数-mutual-information-and-maximal-information-coefficient-mic">==PSI互信息法==(KL散度、相对熵)和==最大信息系数== Mutual information and maximal information coefficient (MIC)</span></h4><blockquote>
<p>  <strong><font color="red"> 风控模型—群体稳定性指标(PSI)深入理解应用</font></strong>:<a href="https://zhuanlan.zhihu.com/p/79682292">https://zhuanlan.zhihu.com/p/79682292</a></p>
</blockquote>
<ul>
<li>评价定性自变量对定性因变量的相关性，评价类别型变量对类别型变量的相关性，互信息越大表明两个变量相关性越高，互信息为0时，两个变量相互独立。互信息的计算公式为</li>
<li><img src="https://www.zhihu.com/equation?tex=I%28X+%3B+Y%29%3D%5Csum%5Climits_%7Bx+%5Cin+X%7D+%5Csum%5Climits_%7By+%5Cin+Y%7D+p%28x%2C+y%29+%5Clog+%5Cfrac%7Bp%28x%2C+y%29%7D%7Bp%28x%29+p%28y%29%7D%3DD_%7BK+L%7D%28p%28x%2C+y%29+%5C%7C+p%28x%29+p%28y%29%29+%5C%5C" alt="[公式]"></li>
</ul>
<h4><span id="fisher得分">==<strong>Fisher得分</strong>==</span></h4><p>对于分类问题，<strong>好的特征应该是在同一个类别中的取值比较相似</strong>，<strong>而在不同类别之间的取值差异比较大</strong>。因此特征i的重要性可用Fiser得分<img src="https://www.zhihu.com/equation?tex=S_i" alt="[公式]">来表示</p>
<p><img src="https://www.zhihu.com/equation?tex=S_%7Bi%7D%3D%5Cfrac%7B%5Csum_%7Bj%3D1%7D%5E%7BK%7D+n_%7Bj%7D%5Cleft%28%5Cmu_%7Bi+j%7D-%5Cmu_%7Bi%7D%5Cright%29%5E%7B2%7D%7D%7B%5Csum_%7Bj%3D1%7D%5E%7BK%7D+n_%7Bj%7D+%5Crho_%7Bi+j%7D%5E%7B2%7D%7D+%5C%5C" alt="[公式]"> </p>
<p>其中，<img src="https://www.zhihu.com/equation?tex=u_%7Bij%7D" alt="[公式]">和<img src="https://www.zhihu.com/equation?tex=%5Crho_%7Bij%7D" alt="[公式]">分别是特征i在类别j中均值和方差，<img src="https://www.zhihu.com/equation?tex=%5Cmu_i" alt="[公式]">为特征i的均值，<img src="https://www.zhihu.com/equation?tex=n_j" alt="[公式]">为类别j中的<a href="https://www.zhihu.com/search?q=样本数&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;306057603&quot;}">样本数</a>。Fisher得分越高，<strong>特征在不同类别之间的差异性越大、在同一类别中的差异性越小，则特征越重要</strong>;</p>
<h4><span id="相关特征选择">==<strong>相关特征选择</strong>==</span></h4><p>该方法基于的假设是，好的特征集合包含跟目标变量非常相关的特征，但这些特征之间彼此不相关</p>
<h4><span id="最小冗余最大相关性-mrmr">==<strong>最小冗余最大相关性( mRMR)</strong>==</span></h4><p>由于单变量过滤法只考虑了单特征变量和目标变量之间的相关性，因此选择的特征子集可能过于冗余。mRMR在进行特征时考虑到了特征之间的冗余性，具体做法是对跟已选择特征相关性较高的冗余特征进行惩罚;</p>
<h3><span id="222-wrapper包装法-特征集模型"><strong>2.2.2 Wrapper(包装法)</strong> 【特征集+模型】</span></h3><p><img src="https://pic4.zhimg.com/v2-bd321ff1e16c011d1a2bce86a5939a17_b.jpg" alt="img"></p>
<ul>
<li><p>使用<strong>机器学习算法评估特征子集</strong>的效果，可以检测两个或多个特征之间的交互关系，而且选择的特征子集让模型的效果达到最优。</p>
</li>
<li><p>这是<strong>特征子集搜索</strong>和<strong>评估指标相结合</strong>的方法。前者提供候选的新特征子集，后者基于新特征子集训练一个模型，并用验证集进行评估，为每一组特征子集进行打分。</p>
</li>
<li><p>最简单的方法是在<strong>每一个特征子集上训练并评估模型</strong>，从而找出最优的特征子集</p>
</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>需要对每一组特征子集训练一个模型，<strong>计算量很大</strong></li>
<li>样本不够充分的情况下<strong>容易过拟合</strong></li>
<li>特征变量较多时计算复杂度太高</li>
</ul>
<h4><span id="完全搜索">==完全搜索==</span></h4><ul>
<li>即穷举法，<strong>遍历所有可能的组合达到全局最优</strong>，时间复杂度<img src="https://www.zhihu.com/equation?tex=2%5En" alt="[公式]"></li>
</ul>
<h4><span id="启发式搜索">==<strong>启发式搜索</strong>==</span></h4><ul>
<li>序列向前选择：特征子集从空集开始，每次只加入一个特征，时间复杂度为<img src="https://www.zhihu.com/equation?tex=O%28n%2B%28n-1%29%2B%28n-2%29%2B%5Cldots%2B1%29%3DO%5Cleft%28n%5E%7B2%7D%5Cright%29" alt="[公式]"></li>
<li>序列向后选择：特征子集从全集开始，每次删除一个特征，时间复杂度为<img src="https://www.zhihu.com/equation?tex=O%28n%5E%7B2%7D%29" alt="[公式]"></li>
</ul>
<h4><span id="随机搜索">==<strong>随机搜索</strong>==</span></h4><ul>
<li>执行序列向前或向后选择时，随机选择特征子集</li>
</ul>
<h4><span id="递归特征消除法">==<strong>递归特征消除法</strong>==</span></h4><ul>
<li>使用一个基模型进行多轮训练，每轮训练后通过学习器返回的<strong>coef</strong>_或者<strong>feature_importances</strong>_消除若干权重较低的特征，再基于新的特征集进行下一轮训练</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment">#递归特征消除法，返回特征选择后的数据</span></span><br><span class="line"><span class="comment">#参数estimator为基模型</span></span><br><span class="line"><span class="comment">#参数n_features_to_select为选择的特征个数</span></span><br><span class="line">RFE(estimator=LogisticRegression(), </span><br><span class="line">    n_features_to_select=<span class="number">2</span>).fit_transform(iris.data, </span><br><span class="line">                                          iris.target)</span><br></pre></td></tr></table></figure>
<h3><span id="223-embedded嵌入法">2.2.3 Embedded(嵌入法)</span></h3><p><img src="https://pic4.zhimg.com/v2-9420bbe9f86094fd683ff1fb8919631f_b.jpg" alt="img"></p>
<p>将特征选择嵌入到模型的构建过程中，具有<strong>包装法与机器学习算法相结合的优点</strong>，也具有<strong>过滤法计算效率高的优点</strong></p>
<h4><span id="lasso方法-l1正则项">==<strong>LASSO方法</strong>== L1正则项</span></h4><p>通过对回归系数添加<img src="https://www.zhihu.com/equation?tex=L_1" alt="[公式]">惩罚项来防止过拟合，可以让特定的回归系数变为0，从而可以选择一个不包含那些系数的更简单的模型；实际上，L1惩罚项降维的原理是，在多个对实际上，L1惩罚项降维的原理是，在多个对<a href="https://www.zhihu.com/search?q=目标值&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;306057603&quot;}">目标值</a>具有同等相关性的特征中，只保留一个，所以没保留的特征并不代表不重要具有同等相关性的特征中，只保留一个，所以没保留的特征并不代表不重要。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment">#带L1惩罚项的逻辑回归作为基模型的特征选择</span></span><br><span class="line">SelectFromModel(LogisticRegression(</span><br><span class="line">          penalty=<span class="string">&quot;l1&quot;</span>, C=<span class="number">0.1</span>)).fit_transform(</span><br><span class="line">               iris.data,iris.target)</span><br></pre></td></tr></table></figure>
<h4><span id="基于树模型的特征选择方法">==<strong>基于树模型的特征选择方法</strong>==</span></h4><ul>
<li>在<a href="https://www.zhihu.com/search?q=决策树&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;306057603&quot;}">决策树</a>中，深度较浅的节点一般对应的特征分类能力更强(可以将更多的样本区分开)</li>
<li>对于基于决策树的算法，如<strong>随机森林</strong>，重要的特征更有可能出现在深度较浅的节点，而且出现的次数可能越多</li>
<li>即可基于树模型中<strong>特征出现次数</strong>等指标对特征进行重要性排序</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="comment">#GBDT作为基模型的特征选择</span></span><br><span class="line">SelectFromModel(</span><br><span class="line">    GradientBoostingClassifier()).fit_transform(</span><br><span class="line">      iris.data,iris.target)</span><br></pre></td></tr></table></figure>
<h4><span id="使用特征重要性来筛选特征的缺陷">使用特征重要性来筛选特征的缺陷？</span></h4><p>1、特征重要性只能说明哪些特征在训练时起到作用了，<strong>并不能说明特征和目标变量之间一定存在依赖关系</strong>。举例来说，随机生成一大堆没用的特征，然后用这些特征来训练模型，一样可以得到特征重要性，但是这个特征重要性并不会全是0，这是完全没有意义的。</p>
<p>2、<strong>特征重要性容易高估数值特征和基数高的类别特征的重要性</strong>。这个道理很简单，特征重要度是根据决策树分裂前后节点的不纯度的减少量（基尼系数或者MSE）来算的，那么对于数值特征或者基础高的类别特征，不纯度较少相对来说会比较多。</p>
<p>3、<strong>特征重要度在选择特征时需要决定阈值</strong>，要保留多少特征、删去多少特征，这些需要人为决定，并且删掉这些特征后模型的效果也不一定会提升。</p>
<h4><span id="non-importance-选择">==Non importance 选择==</span></h4>]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（4）Auto工具</title>
    <url>/posts/GTE114/</url>
    <content><![CDATA[<h2><span id="四-autoeda-工具">四、AutoEDA 工具</span></h2><blockquote>
<p>  盘点Kaggle中常见的AutoEDA工具库： <a href="https://zhuanlan.zhihu.com/p/444405236">https://zhuanlan.zhihu.com/p/444405236</a></p>
</blockquote>
<h4><span id="41-pandas-profiling">4.1 <strong>Pandas Profiling</strong></span></h4><ul>
<li><a href="http://link.zhihu.com/?target=https%3A//pandas-profiling.github.io/pandas-profiling/docs/master/index.html">https://pandas-profiling.github.io/pandas-profiling/docs/master/index.html</a></li>
</ul>
<p><strong>Pandas Profiling</strong>是款比较成熟的工具，可以直接传入DataFrame即可完成分析过程，将结果展示为HTML格式，同时分析功能也比较强大。</p>
<ul>
<li>功能：<strong>字段类型分析、变量分布分析、相关性分析、缺失值分析、重复行分析</strong></li>
<li>耗时：较少</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-97af4843870e76e9d9ef1a4518a27bb2_720w.jpg?source=d16d100b" alt="img" style="zoom: 67%;"></p>
<h4><span id="42-autoviz"><strong>4.2 AutoViz</strong></span></h4><ul>
<li><a href="http://link.zhihu.com/?target=https%3A//github.com/AutoViML/AutoViz">https://github.com/AutoViML/AutoViz</a></li>
</ul>
<p><strong>AutoViz是款美观的数据分析工具</strong>，在进行可视化的同时将结果保存为图片格式。</p>
<ul>
<li>功能：<strong>相关性分析、数值变量箱线图、数值变量分布图</strong></li>
<li>耗时：较多</li>
</ul>
<p><img src="https://pic2.zhimg.com/80/v2-cc73734146a68cd619ed33dd8e5525b1_1440w.jpg?source=d16d100b" alt="img" style="zoom: 67%;"></p>
<h4><span id="43-dataprep">==4.3 <strong>Dataprep</strong>==</span></h4><ul>
<li><a href="http://link.zhihu.com/?target=https%3A//dataprep.ai/">https://dataprep.ai/</a></li>
</ul>
<p><strong>Dataprep是款比较灵活也比较强大的工具，也是笔者最喜欢的。它可以指定列进行分析，同时也可以在Notebook中进行交互式分析。</strong></p>
<ul>
<li>功能：<strong>字段类型分析、变量分布分析、相关性分析、缺失值分析、交互式分析</strong>。</li>
<li>耗时：较多</li>
</ul>
<p><img src="https://pic1.zhimg.com/80/v2-622241d523ff43ded380d414d040c5d7_1440w.jpg?source=d16d100b" alt="img" style="zoom: 67%;"></p>
<h4><span id="44-sweetviz"><strong>4.4 SweetViz</strong></span></h4><ul>
<li><a href="http://link.zhihu.com/?target=https%3A//github.com/fbdesignpro/sweetviz">https://github.com/fbdesignpro/sweetviz</a></li>
</ul>
<p><strong>SweetViz是款强大的数据分析工具，可以很好的分析训练集和测试集，以及目标标签与特征之间的关系</strong>。</p>
<ul>
<li>功能：数据集对比分析、字段类型分析、变量分布分析、目标变量分析</li>
<li>耗时：中等<img src="https://pica.zhimg.com/80/v2-45b365b953f62a41680381891eedca9b_1440w.jpg?source=d16d100b" alt="img" style="zoom:67%;"></li>
</ul>
<h4><span id="45-d-tale">4.5 D-Tale</span></h4><ul>
<li><a href="http://link.zhihu.com/?target=https%3A//github.com/man-group/dtale">https://github.com/man-group/dtale</a></li>
</ul>
<p><code>D-Tale</code>是款功能最为强大的数据分析工具，对单变量的分析过程支持比较好。</p>
<ul>
<li>功能：字段类型分析、变量分布分析、相关性分析、缺失值分析、交互式分析。</li>
<li>耗时：中等</li>
</ul>
<p><img src="https://pic2.zhimg.com/80/v2-7c66f31393a92e6ba7c87e03478277e1_1440w.jpg?source=d16d100b" alt="img" style="zoom:67%;"></p>
<h2><span id="五-警惕特征工程中的陷阱">五、</span></h2><blockquote>
<p>  特征工程(Feature Engineering)是机器学习中的重要环节。在传统的项目中，百分之七十以上的时间都花在了预处理数据上(Data Preprocessing)，其中特征工程消耗了很多时间。</p>
<p>  一般来说，特征工程涵盖的内容非常广泛，包括从<strong>缺失值补全、特征选择、维度压缩，到对输入数据的范围进行变换（Data Scaling）等</strong>。举个简单的例子，一个K-近邻算法的输入数据有两个特征 <img src="https://www.zhihu.com/equation?tex=%7BX_1%2CX_2%7D" alt="[公式]"> ，但 <img src="https://www.zhihu.com/equation?tex=X_1" alt="[公式]"> 这个特征的取值范围在 <img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[公式]"> 而 <img src="https://www.zhihu.com/equation?tex=X_2" alt="[公式]"> 的范围在<img src="https://www.zhihu.com/equation?tex=%5B-1000%2C1000%5D" alt="[公式]"> 。不可避免的，K-近邻的结果取决于距离，那么很容易被取值范围大的特征，也就是此处的 <img src="https://www.zhihu.com/equation?tex=X_2" alt="[公式]"> 所“垄断”。在这种情况下，把 <img src="https://www.zhihu.com/equation?tex=%7BX_1%2CX_2%7D" alt="[公式]"> 的取值调整到可比较的范围上就成了必须。常见的做法有归一化或者标准化，此处不再赘述，可以参考[1]。为了简化内容，本文中的例子仅以归一化作为唯一的特征工程。今天主要说的是：特征工程中的面临的进退两难。</p>
</blockquote>
<h4><span id="51-如何保证-训练集-测试集-预测数据-有相同的输入">5.1 <strong>如何保证 训练集、测试集、预测数据 有相同的输入？</strong></span></h4><p>以刚才的例子为基础，我们把所有数据按照70:30的比例分为训练集和测试集，并打算使用K-近邻进行训练。那么一个令人困扰的问题是，对训练集的特征做归一化后，测试集的特征怎么办？这是一个非常关键的问题，因为训练集<strong>特征归一化</strong>后，测试集的特征范围可能就不同了，因此模型失效。一般有几种思路：</p>
<ul>
<li><strong>方法1：把训练集和测试集合在一起做归一化</strong>，这样特征范围就统一了。之后用训练集做训练，那测试集做测试。<strong>但很明显的，在训练模型时，不应该包括任何测试集的信息</strong>。这种做法会导致存在人为偏差的模型，不能用。</li>
<li><strong>方法2：对训练集单独做归一化，之后对测试集单独做归一化</strong>。这种看法看似也可以，重点在于数据量以及数据的排列顺序。<strong>在数据量大且数据被充分打乱的前提下，这种做法是可行的</strong>。但换句话说，如果有这样的前提假设，那么方法1的结论也是可行的。</li>
<li><strong>方法3：对训练集先做归一化，并保留其归一化参数（如最大、最小值），之后用训练集的归一化参数对测试集做处理。</strong>这种做法看似是可以的。<strong>但风险在于数据量有限的前提下，训练集的参数会导致测试集的结果异常，如产生极大或者极小的数值</strong>。</li>
</ul>
<blockquote>
<p>  其实不难看出，从某种意义上说，三种做法是等价的。在数据量大且充分打乱的前提下，训练集和验证集有相同的分布假设，因此用任意一种其实差别不大。然而这样的假设过于乐观，<strong>且我们在真实情况下应该只有{==训练集+1个测试数据==}，因此方法2是明显不行的</strong>。</p>
<p>  方法1常常被认为是错误的操作，原因是在训练阶段引入了测试数据，这属于未知数据。即使仅仅引入了1个测试数据，如果取值非常极端，依然会导致输出范围有较大的波动。其次，如果对于每一个测试数据都需要用整个训练集来归一的话，那么运算开销会非常大。</p>
<p>  那么似乎备选的只有方案3，即保<strong>留验证集上的归一化参数</strong>，并运用于测试集。这样的做法看似可以，但有不少风险：</p>
<ul>
<li><strong>不是每种特征工程都可以保存参数，很多特征工程是非常繁复的</strong>。</li>
<li>如果测试集数据和训练集数据有很大的差别，那么用测试集的参数会产生异常数据。</li>
</ul>
</blockquote>
<h4><span id="52-可能的解决方案">5.2 可能的解决方案</span></h4><p>在<strong>模型评估阶段</strong>，如果我们假设拥有大量数据，且充分打乱其顺序。那么在划分训练集和测试集前，可以对整体数据进行统一的特征工程。不难看出，这和统计学的大数定理有异曲同工之妙。这种做法是最为高效的，需要的运算量最小。而将“测试数据”暴露给训练模型的风险也并不大，因为大数据量使得分布比较稳定，可以忽略。换个角度来看，当数据量非常大的时候，使用其他方法进行特征工程的开销会过大，不利于模型评估。因此，在<strong>模型评估阶段</strong>，如果符合以上假设，可以用这种方法（也就是上文的方法1）。但退一步说，如果满足这个条件，那么方法3也是等价的。</p>
<p>在<strong>预测阶段</strong>，每次假设我们只有1个测试点，那么最佳方案还是保存训练集上特征工程的参数或者模型，并直接用于未知数据的特征工程（也就是上文的方法3）。</p>
<p>但在<strong>预测阶段</strong>，一个一个数据的预测是非常昂贵的，我们一般会做<strong>“批处理”(batch operation)</strong>。换句话说，就是攒够一定量的预测数据后统一进行预测。在这种情况下，我们：</p>
<ul>
<li>利用方法3，按照顺序对每个训练数据进行处理</li>
<li>利用方法1，风险在于（方法1）会影响训练数据且需要重新训模型</li>
<li><strong>利用方法2，此时较为稳妥</strong>。在批的尺寸较大，且与训练数据分布相同（接近）时，效果应该与方法3一致，但效率可以得到提升</li>
</ul>
<h3><span id="53-总结"><strong>5.3 总结</strong></span></h3><p>这篇文章的重点是：“特征工程虽然重要，但极容易在使用中带来风险。”比如在训练时同时误用了测试数据进行特征工程，也叫做数据泄露(data leakage)。但数据泄露其实也是个伪命题，<strong>当数据量大且分布相同时，使用哪一种方法得到结果应该都近似等价，而更重要的是运行效率</strong>。分类讨论的话，方法1、2、3都有可能是适合的方法。</p>
<p>但我们依然希望能避免类似的风险，因此尽量避免不必要的特征工程，有以下建议：</p>
<ul>
<li><strong>选择对于特征学习能力强的模型，在数据量允许的情况下可以选择深度学习</strong></li>
<li><strong>避免不必要的特征工程，数据范围比较良好的情况下省略某些特征工程</strong></li>
<li><strong>优先选择对于特征工程要求低的模型，如xgboost等</strong></li>
</ul>
<h2><span id="六-业务角度看特征工程">六、业务角度看特征工程</span></h2><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/505480353">如何从业务角度看特征工程</a></p>
</blockquote>
<p>前两天刷某知名社交软件的时候看到有人问特征工程现在还重要吗？觉得是个很有意思的事情。其实工业界能够支持的起大规模稀疏向量的场景大概并不是想象中的那么多，大多数场景面对极为稀疏的行为数据下都很难在ID层面得到很好的emb表达。在这个前提下，没有好的特征工程，其余的模型结构优化或者各种花里胡哨的模型结构都是纸上谈兵。真正被小场景捶打过的朋友，比如我，绝对会在一次又一次的生活毒打中明白，抛弃那些ppt上的高级多塔多注意力，直面特征工程的人生吧！</p>
<p>有竞赛经验的小伙伴都明白，一个强特能一飞冲天，一个灵机一动能直上top榜。但是，长久的可持续的特征工程决不能够靠简单的灵机一动来实现，特别是当手上有无数的芝麻大小的场景时，一个系统的特征工程思维就尤为重要了。本文将从以下几个方面来阐述特征工程中的方方面面。提前说明的是，一般的特征工程常用方法，例如one-hot，hash-encoding，分桶等等不会作为本文的重点，因为这是器的维度，文末有一篇非常全面的文章供参考，本文主要聚焦在术的维度，也就是怎么去思考和选用方法的层面。<strong>首先，我会给出一个特征工程树，这个属于一个主流版本，希望在屏蔽场景特殊性的情况下，给出一般场景的思考方法</strong>。接下来，我会介绍上文提到的特征树的细节，包括涉及到的具体特征例子。第三部分，则包括特征之间可能存在的相互作用和不同特征适合的模型类型。最后，我给出了一个具体场景的具体例子，并说明这个场景的一般性和特殊性，给出针对具体业务场景的特征工程思路。</p>
<p>此外，一个基础认知是，这里的特征是指输入模型的信息，包括偏置或者先验，这些特征的使用方式除了作为模型的输入，也可以通过其他的方式引入，例如样本工程或者损失函数，这个就不在本文讨论范围之内了。当然还是那句老话，个人的认知是有限的，欢迎有经验的小伙伴交流和指正。</p>
<h3><span id="6-1-基础特征树">6. 1 基础特征树</span></h3><p>不管是基于已有的模型迭代优化，又或者是从0到1构建一个场景的全部特征，都需要自己梳理一个完整的基础特征树。这是了解一个场景的开始。做这件事情我推荐的方法是<strong>先体验这个场景，然后分类列出所有可能影响你优化目标决策的因素以及优化目标的历史信息</strong>。</p>
<p>对于绝大多数业务来讲，基础的特征树都可以分为以下3大部分。</p>
<ul>
<li><strong>供给侧</strong>：对于大部分to c的互联网应用，供给侧都是item，可能是音乐，doc或者一条推送消息。</li>
<li><strong>消费侧</strong>：有关用户的一切描述，其中比较特殊的是序列特征。</li>
<li><strong>上下文</strong>：场景测的因素，包括特定的时刻，特定的展现形式等。</li>
<li><strong>交叉特征</strong>：以上三个部分任意两部分或全部的交叉特征。</li>
</ul>
]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（6）【Nan】时间序列处理</title>
    <url>/posts/35TG484/</url>
    <content><![CDATA[<h2><span id="时间序列数据的预处理">时间序列数据的预处理</span></h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/466086665"><em>时间序列</em>数据的预<em>处理</em></a></li>
<li><a href="https://mp.weixin.qq.com/s/vyDZfDdaH2Y7k75NNsMNJA">如何在实际场景中使用异常检测？阿里云Prometheus智能检测算子来了</a> </li>
</ul>
<blockquote>
<p>  在本文中，我们将主要讨论以下几点：</p>
<ul>
<li>时间序列数据的定义及其重要性。</li>
<li>时间序列数据的预处理步骤。</li>
<li>构建时间序列数据，查找缺失值，对特征进行去噪，并查找数据集中存在的异常值。</li>
</ul>
</blockquote>
<h3><span id="时间序列的定义">时间序列的定义</span></h3><p><strong>时间序列是在特定时间间隔内记录的一系列均匀分布的观测值</strong>。时间序列的一个例子是黄金价格。在这种情况下，我们的观察是在固定时间间隔后一段时间内收集的黄金价格。时间单位可以是分钟、小时、天、年等。但是任何两个连续样本之间的时间差是相同的。</p>
]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（1）特征预处理*</title>
    <url>/posts/3PJZDND/</url>
    <content><![CDATA[<h2><span id="特征工程-特征处理">特征工程-特征处理</span></h2><blockquote>
<p>  <strong>机器学习中的特征工程（四）—— ==特征离散化处理方法==：</strong><a href="https://www.jianshu.com/p/918649ce379a">https://www.jianshu.com/p/918649ce379a</a></p>
<p>  <strong>机器学习中的特征工程（三）—— ==序数和类别特征处理方法==</strong>：<a href="https://www.jianshu.com/p/3d828de72cd4">https://www.jianshu.com/p/3d828de72cd4</a></p>
<p>  <strong>机器学习中的特征工程（二）—— ==数值类型数据处理==</strong>：<a href="https://www.jianshu.com/p/b0cc0710ef55">https://www.jianshu.com/p/b0cc0710ef55</a></p>
<p>  机器学习中的特征工程（一）—— 概览：<a href="https://www.jianshu.com/p/172677f4ea4c">https://www.jianshu.com/p/172677f4ea4c</a></p>
<p>  特征工程完全手册 - 从预处理、构造、选择、降维、不平衡处理，到放弃：<a href="https://zhuanlan.zhihu.com/p/94994902">https://zhuanlan.zhihu.com/p/94994902</a></p>
<p>  <strong>这9个特征工程使用技巧，解决90%机器学习问题！</strong> - Python与数据挖掘的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/462744763">https://zhuanlan.zhihu.com/p/462744763</a></p>
</blockquote>
<h3><span id="一-数值类型处理">一、 数值类型处理</span></h3><blockquote>
<p>  <strong>pandas 显示所有列：</strong></p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#显示所有列</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_columns&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment">#显示所有行</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;display.max_rows&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"><span class="comment">#设置value的显示长度为100，默认为50</span></span><br><span class="line">pd.set_option(<span class="string">&#x27;max_colwidth&#x27;</span>,<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<p>  <strong>pandas 查看缺失特征:</strong></p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train.isnull().<span class="built_in">sum</span>().sort_values(ascending = <span class="literal">False</span>) / train.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>  <strong>pandas 查看某一列的分布:</strong></p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.loc[:,col_name].value_counts()</span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>特征提取方式是可以深挖隐藏在数据背后更深层次的信息的</strong>。其次，数值类型数据也并不是直观看上去那么简单易用，因为不同的数值类型的计量单位不一样，比如个数、公里、千克、DB、百分比之类，同样数值的大小也可能横跨好几个量级，比如小到头发丝直径约为0.00004米， 大到热门视频播放次数成千上万次。</p>
<h4><span id="11-数据归一化">1.1 数据归一化</span></h4><blockquote>
<p>  <strong>为什么要数据归一化？</strong></p>
<p>   <a href="../../AI深度学习/深度学习（3）Normalization*.md">深度学习（3）Normalization*.md</a> </p>
<ul>
<li><strong>可解释性</strong>：<strong>回归模型【无正则化】</strong>中自变量X的量纲不一致导致了<strong>==回归系数无法直接解读==</strong>或者错误解读；需要将X都处理到统一量纲下，这样才可比【可解释性】；<strong>取决于我们的逻辑回归是不是用了正则化</strong>。如果你不用正则，标准化并不是必须的，如果用正则，那么标准化是必须的。</li>
<li><strong>距离计算</strong>：机器学习任务和统计学任务中有很多地方要用到<strong>==“距离”的计算==</strong>，比如<strong>PCA、KNN，kmeans和SVM</strong>等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果；</li>
<li><p><strong>加速收敛</strong>：参数估计时使用<strong>==梯度下降==</strong>，在使用梯度下降的方法求解最优化问题时， 归一化/标准化后可以加快梯度下降的求解速度，即<strong>==提升模型的收敛速度==</strong>。</p>
<p><strong>需要归一化的模型：</strong>利用梯度下降法求解的模型一般需要归一化，<strong>线性回归、LR、SVM、KNN、神经网络</strong></p>
</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">
\tilde{x}=\frac{x-\min (x)}{\max (x)-\min (x)}</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># define data </span></span><br><span class="line">data = np.asarray([[<span class="number">100</span>, <span class="number">0.001</span>], </span><br><span class="line">                   [<span class="number">8</span>, <span class="number">0.05</span>], </span><br><span class="line">                   [<span class="number">50</span>, <span class="number">0.005</span>], </span><br><span class="line">                   [<span class="number">88</span>, <span class="number">0.07</span>], </span><br><span class="line">                   [<span class="number">4</span>, <span class="number">0.1</span>]])</span><br><span class="line"><span class="comment"># define min max scaler</span></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line"><span class="comment"># transform data</span></span><br><span class="line">scaled = scaler.fit_transform(data) </span><br></pre></td></tr></table></figure>
<h4><span id="12-数据标准化">1.2 数据标准化</span></h4><p>数据标准化是指通过改变数据的分布得到均值为0，标准差为1的服从标准正态分布的数据。主要目的是为了让不同特征之间具有相同的尺度（Scale），这样更有理化模型训练收敛。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="comment"># define standard scaler</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line"><span class="comment"># transform data</span></span><br><span class="line">scaled = scaler.fit_transform(data) </span><br><span class="line"><span class="built_in">print</span>(scaled)</span><br></pre></td></tr></table></figure>
<h4><span id="13-对数转换">==1.3 对数转换==</span></h4><p>log函数的定义为<img src="https://math.jianshu.com/math?formula=log_a(%5Calpha%5Ex" alt="log_a(\alpha^x) = x">%20%3D%20x)，其中a是log函数的底数，<img src="https://math.jianshu.com/math?formula=%5Calpha" alt="\alpha">是一个正常数，<img src="https://math.jianshu.com/math?formula=x" alt="x">可以是任何正数。由于<img src="https://math.jianshu.com/math?formula=%5Calpha%5E0%20%3D%201" alt="\alpha^0 = 1">，我们有<img src="https://math.jianshu.com/math?formula=log_a(1" alt="log_a(1) = 0">%20%3D%200)。这意味着log函数可以将一些介于0~1之间小范围的数字映射到<img src="https://math.jianshu.com/math?formula=(-%5Cinfty%2C%200" alt="(-\infty, 0)">)范围内。比如当a=10时，函数<img src="https://math.jianshu.com/math?formula=log_%7B10%7D(x" alt="log_{10}(x)">)可以将[1,10]映射到[0,1]，将[1,100]映射到[1,2]。<strong>换句话说，log函数压缩了大数的范围，扩大了小数的范围</strong>。x越大，log(x)增量越慢。log(x)函数的图像如下：</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220426154119370.png" alt="image-20220426154119370" style="zoom: 25%;"></p>
<p><strong>Log函数可以极大压缩数值的范围，相对而言就扩展了小数字的范围。该转换方法适用于长尾分布且值域范围很大的特征，变换后的特征趋向于正态分布。</strong>对数值类型使用对数转换一般有以下几种好处：</p>
<ul>
<li>缩小数据的绝对数值</li>
<li>取对数后，可以将乘法计算转换成加法计算</li>
<li>在数据的整个值域中不同区间的差异带来的影响不同</li>
<li>取对数后不会改变数据的性质和相关关系，但压缩了变量的尺度。</li>
<li>得到的数据易消除异方差问题</li>
</ul>
<h3><span id="二-序数和类别特征处理">二、序数和类别特征处理</span></h3><p>本文主要说明特征工程中关于<strong>序数特征</strong>和<strong>类别特征</strong>的常用处理方法。主要包含<strong>LabelEncoder</strong>、<strong>One-Hot编码</strong>、<strong>DummyCoding</strong>、<strong>FeatureHasher</strong>以及要重点介绍的<strong>WOE编码</strong>。</p>
<h4><span id="21-序数特征处理">2.1 序数特征处理</span></h4><p><strong>序数特征指的是有序但无尺度的特征</strong>。比如表示‘学历’的特征，’高中’、’本科’、’硕士’，这些特征彼此之间是有顺序关系的，但是特征本身无尺度，并且也可能不是数值类型。在实际应用中，一般是字符类型居多，为了将其转换成模型能处理的形式，通常需要先进行编码，比如LabelEncoding。如果序数特征本身就是数值类型变量，则可不进行该步骤。下面依次介绍序数特征相关的处理方式。</p>
<ul>
<li><h4><span id="label-encoding">Label Encoding</span></h4></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">x = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">encoder = LabelEncoder()</span><br><span class="line">x1 = encoder.fit_transform(x)</span><br><span class="line"></span><br><span class="line">x2 = pd.Series(x).astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">x2.cat.codes.values</span><br><span class="line"><span class="comment"># pandas 因子化</span></span><br><span class="line">x2, uniques = pd.factorize(x)</span><br><span class="line"><span class="comment"># pandas 二值化</span></span><br><span class="line">x2 = pd.Series(x)</span><br><span class="line">x2 = (x2 &gt;= <span class="string">&#x27;b&#x27;</span>).astype(<span class="built_in">int</span>) <span class="comment">#令大于等于&#x27;b&#x27;的都为1</span></span><br></pre></td></tr></table></figure>
<h4><span id="22-类别特征处理">2.2 类别特征处理</span></h4><p><strong>类别特征由于没有顺序也没有尺度</strong>，因此处理较为麻烦，但是在CTR等领域却是非常常见的特征。比如<strong>商品的类型，颜色，用户的职业，兴趣</strong>等等。类别变量编码方法中最常使用的就是<strong>One-Hot编码</strong>，接下来结合具体实例来介绍。</p>
<ul>
<li><h4><span id="one-hot编码">One-Hot编码</span></h4></li>
</ul>
<p>One-Hot编码，又称为’独热编码’，其变换后的单列特征值只有一位是1。如下例所示，一个特征中包含3个不同的特征值(a,b,c)，编码转换后变成3个子特征，其中每个特征值中只有一位是有效位1。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, OneHotEncoder</span><br><span class="line"></span><br><span class="line">one_feature = [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">feature = label_encoder.fit_transform(one_feature)</span><br><span class="line">onehot_encoder = OneHotEncoder(sparse=<span class="literal">False</span>)</span><br><span class="line">onehot_encoder.fit_transform(feature.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<ul>
<li><h4><span id="labelbinarizer">LabelBinarizer</span></h4></li>
</ul>
<p>sklearn中的LabelBinarizer也具有同样的作用，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line">feature = np.array([<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">LabelBinarizer().fit_transform(feature)</span><br></pre></td></tr></table></figure>
<ul>
<li><h4><span id="虚拟编码dummy-coding">虚拟编码Dummy Coding</span></h4></li>
</ul>
<p>同样，<strong>pandas中也内置了对应的处理方式,使用起来比Sklearn更加方便</strong>，产生n-1个特征。实例如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">one_feature = [<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line">pd.get_dummies(one_feature, prefix=<span class="string">&#x27;test&#x27;</span>) <span class="comment"># 设置前缀test</span></span><br></pre></td></tr></table></figure>
<ul>
<li><h4><span id="特征哈希feature-hashing"><strong><font color="red"> 特征哈希（feature hashing）</font></strong></span></h4></li>
</ul>
<p>按照上述编码方式，如果某个特征具有100个类别值，那么经过编码后将产生100个或99个新特征，这极大地增加了特征维度和特征的稀疏度，同时还可能会出现内存不足的情况。<strong>sklearn中的FeatureHasher接口采用了hash的方法，将不同的值映射到用户指定长度的数组中，使得输出特征的维度是固定的，该方法占用内存少，效率高，可以在多类别变量值中使用，但是由于采用了Hash函数的方式，所以具有冲突的可能，即不同的类别值可能映射到同一个特征变量值中。</strong></p>
<blockquote>
<p>  Feature hashing(特征哈希): <a href="https://blog.csdn.net/laolu1573/article/details/79410187">https://blog.csdn.net/laolu1573/article/details/79410187</a></p>
<p>  <a href="https://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing">https://scikit-learn.org/stable/modules/feature_extraction.html#feature-hashing</a></p>
<p>  <a href="https://www.zhihu.com/question/264165760/answer/277634591">如何用通俗的语言解释CTR和推荐系统中常用的<em>Feature</em> <em>Hashing</em>技术以及其对应的优缺点？</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> FeatureHasher</span><br><span class="line"></span><br><span class="line">h = FeatureHasher(n_features=<span class="number">5</span>, input_type=<span class="string">&#x27;string&#x27;</span>)</span><br><span class="line">test_cat = [<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;e&#x27;</span>,<span class="string">&#x27;f&#x27;</span>,<span class="string">&#x27;g&#x27;</span>,<span class="string">&#x27;h&#x27;</span>,<span class="string">&#x27;i&#x27;</span>,<span class="string">&#x27;j&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line">f = h.transform(test_cat)</span><br><span class="line">f.toarray()</span><br></pre></td></tr></table></figure>
<p><strong>如果hash的目标空间足够大，并且hash函数本身足够散列，不会损失什么特征信息。</strong></p>
<p>feature hashing简单来说和<strong>kernal的思想</strong>是类似的，就是把输入的特征映射到一个具有一些我们期望的较好性质的空间上去。在feature hasing这个情况下我们希望目标的空间具有如下的性质：</p>
<ol>
<li><strong>样本无关的维度大小，因为当在线学习，或者数据量非常大，提前对数据观察开销非常大的时候，这可以使得我们能够提前给算法分配存储和切分pattern。大大提高算法的工程友好性</strong>。</li>
<li>这个空间一般来说比输入的特征空间维度小很多。</li>
<li>另外我们假设在原始的特征空间里，样本的分布是非常稀疏的，只有很少一部分子空间是被取值的。</li>
<li><strong>保持内积的无偏</strong>（不变肯定是不可能的，因为空间变小了），否则很多机器学习方法就没法用了。</li>
</ol>
<blockquote>
<p>  <strong>原理</strong>：假设输入特征是一个N维的0/1取值的向量x。一个N-&gt;M的<a href="https://www.zhihu.com/search?q=哈希函数&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A&quot;277634591&quot;}">哈希函数</a>h。那么 <img src="https://www.zhihu.com/equation?tex=%5Cphi_j%3D%5Csum_%7Bh%28i%29%3Dj%7D%7Bx_i%7D" alt="[公式]"></p>
<p>  好处：</p>
<ul>
<li>从某种程度上来讲，使得训练样本的特征在对应空间里的<strong>分布更均匀</strong>了。这个好处对于实际训练过程是非常大的，某种程度上起到了<strong>shuffle的作用</strong>。</li>
<li>特征的空间变小了，而且是一个可以预测的大小。比如说加入输入特征里有个东西叫做user_id，那么显然你也不知道到底有多少<a href="https://www.zhihu.com/search?q=userid&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A&quot;277634591&quot;}">userid</a>的话，你需要先扫描一遍并且分配足够的空间给到它不然学着学着oom了。你也不能很好地提前优化<a href="https://www.zhihu.com/search?q=分片&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A&quot;277634591&quot;}">分片</a>。</li>
<li><p>对在线学习非常友好。</p>
<p>坏处：</p>
</li>
<li><p>会给debug增加困难，为了debug你要保存记录h计算的过程数据，否则如果某个特征有毛病，你怎么知道到底是哪个原始特征呢？</p>
</li>
<li>没选好哈希函数的话，<strong>可能会造成碰撞</strong>，如果原始特征很稠密并且碰撞很严重，那可能会带来坏的训练效果。</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">hashing_vectorizer</span>(<span class="params">features, N</span>):</span><br><span class="line">  	x = [<span class="number">0</span>] * N</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> features:</span><br><span class="line">      	h = <span class="built_in">hash</span>(f)</span><br><span class="line">        idx = h % N</span><br><span class="line">        <span class="keyword">if</span> xt(f) == <span class="number">1</span>: <span class="comment"># xt 2值hash函数减少hash冲突</span></span><br><span class="line">          	x[idx] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">         		x[idx] -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<ul>
<li><h4><span id="多类别值处理方式-基于统计的编码方法">多类别值处理方式 -==- 基于统计的编码方法==</span></h4></li>
</ul>
<p>当类别值过多时，<strong>One-Hot 编码或者Dummy Coding都可能导致编码出来的特征过于稀疏</strong>，其次也会占用过多内存。<strong>如果使用FeatureHasher，n_features的设置不好把握，可能会造成过多冲突，造成信息损失</strong>。这里提供一种基于统计的编码方法，包括<strong>基于特征值的统计</strong>或者<strong>基于标签值的统计</strong>——基于标签的编码。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">import seaborn as sns</span><br><span class="line"></span><br><span class="line"><span class="built_in">test</span> = [<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;e&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;c&#x27;</span>]</span><br><span class="line"><span class="built_in">df</span> = pd.DataFrame(<span class="built_in">test</span>, columns=[<span class="string">&#x27;alpha&#x27;</span>])</span><br><span class="line">sns.countplot(<span class="built_in">df</span>[<span class="string">&#x27;alpha&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220426130800412.png" alt="image-20220426130800412" style="zoom:50%;"></p>
<p>首先我们将每个类别值出现的频数计算出来，比如我们设置阈值为1，那么所有小于阈值1的类别值都会被编码为同一类，大于1的类别值会分别编码，如果出现频数一样的类别值，既可以都统一分为一个类，也可以按照某种顺序进行编码，这个可以根据业务需要自行决定。那么根据上图，可以得到其编码值为：</p>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220426130824066.png" alt="image-20220426130824066" style="zoom:50%;"></p>
<p> <strong>即（a,c）分别编码为一个不同的类别，（e,b,d）编码为同一个类别。</strong></p>
<h3><span id="23-二阶">2.3 二阶</span></h3><blockquote>
<p>  w * h = s</p>
</blockquote>
<h3><span id="三-特征离散化处理方法">三、 特征离散化处理方法</span></h3><p><strong>特征离散化指的是将连续特征划分离散的过程</strong>：将原始定量特征的一个区间一一映射到单一的值。离散化过程也被表述成分箱（Binning）的过程。特征离散化常应用于<strong>逻辑回归</strong>和金融领域的评分卡中，同时在规则提取，特征分类中也有对应的应用价值。本文主要介绍几种常见的分箱方法，包括<strong>等宽分箱、等频分箱、信息熵分箱</strong>、<strong>基于决策树分箱、卡方分箱</strong>等。</p>
<p><strong>可以看到在分箱之后，数据被规约和简化，有利于理解和解</strong>释。总来说特征离散化，即 分箱之后会带来如下优势：</p>
<ul>
<li>有助于模型部署和应用，加快模型迭代</li>
<li>增强模型鲁棒性</li>
<li>增加非线性表达能力：连续特征不同区间对模型贡献或者重要程度不一样时，分箱后不同的权重能直接体现这种差异，离散化后的特征再进行特征 交叉衍生能力会进一步加强。</li>
<li>提升模型的泛化能力</li>
<li><strong>扩展数据在不同各类型算法中的应用范围</strong></li>
</ul>
<p>当然特征离散化也有其缺点，总结如下：</p>
<ul>
<li>分箱操作必定会导致一定程度的信息损失</li>
<li>增加流程：建模过程中加入了额外的的离散化步骤</li>
<li>影响模型稳定性： 当一个特征值处于分箱点的边缘时，此时微小的偏差会造成该特征值的归属从一箱跃迁到另外一箱，影响模型的稳定性。</li>
</ul>
<h4><span id="31-等宽分箱equal-width-binning">3.1 等宽分箱（Equal-Width Binning)</span></h4><p><strong>等宽分箱指的是每个分隔点或者划分点的距离一样，即等宽</strong>。实践中一般指定分隔的箱数，等分计算后得到每个分隔点。例如将数据序列分为n份，则 分隔点的宽度计算公式为：</p>
<p><img src="https://math.jianshu.com/math?formula=w%20%3D%20%5Cfrac%20%7Bmax%20-%20min%7D%20%7Bn%7D" alt="w = \frac {max - min} {n}"></p>
<p>这样就将原始数据划分成了n个等宽的子区间，一般情况下，分箱后每个箱内的样本数量是不一致的。使用pandas中的cut函数来实现等宽分箱，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">value, cutoff = pd.cut(df[<span class="string">&#x27;mean radius&#x27;</span>], bins=<span class="number">4</span>, retbins=<span class="literal">True</span>, precision=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p><strong>等宽分箱计算简单，但是当数值方差较大时，即数据离散程度很大，那么很可能出现没有任何数据的分箱</strong>，这个问题可以通过自适应数据分布的分箱方法—等频分箱来避免</p>
<h4><span id="32-等频分箱equal-frequency-binning">3.2 等频分箱（Equal-Frequency Binning）</span></h4><p><strong>等频分箱理论上分隔后的每个箱内得到数据量大小一致</strong>，但是当某个值出现次数较多时，会出现等<strong>分边界是同一个值</strong>，导致同一数值分到不同的箱内，这是不正确的。具体的实现可以<strong>去除分界处的重复值</strong>，但这也导致每箱的数量不一致。如下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s1 = pd.Series([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">value, cutoff = pd.qcut(s1, <span class="number">3</span>, retbins=<span class="literal">True</span>)</span><br><span class="line">sns.countplot(value)</span><br></pre></td></tr></table></figure>
<p><strong>上述的等宽和等频分箱容易出现的问题是每箱中信息量变化不大</strong>。例如，等宽分箱不太适合分布不均匀的数据集、离群值；等频方法不太适合特定的值占比过多的数据集，如<strong>长尾分布</strong>。</p>
<h4><span id="33-信息熵分箱有监督">3.3 信息熵分箱【有监督】</span></h4><p><strong>如果分箱后箱内样本对y的区分度好，那么这是一个好的分箱</strong>。通过信息论理论，我们可知信息熵衡量了这种区分能力。当特征按照某个分隔点划分为上下两部分后能达到最大的信息增益，那么这就是一个好的分隔点。由上可知，信息熵分箱是有监督的分箱方法。<strong><font color="red"> 其实决策树的节点分裂原理也是基于信息熵。</font></strong></p>
<p>首先我们需要明确信息熵和信息增益的计算方式，分别如下：<br><img src="https://math.jianshu.com/math?formula=Entropy(y" alt="Entropy(y) = - \sum_{i=1}^m p_i log_2{p_i} \\ Gain(x) = Entropy(y) - Info_{split}(x)">%20%3D%20-%20%5Csum_%7Bi%3D1%7D%5Em%20p_i%20log_2%7Bp_i%7D%20%5C%5C%20Gain(x)%20%3D%20Entropy(y)%20-%20Info_%7Bsplit%7D(x))</p>
<p>在二分类问题中，<img src="https://math.jianshu.com/math?formula=m%3D2" alt="m=2">。 信息增益的物理含义表达为：x的分隔带来的信息对y的不确定性带来的增益。<br>对于二值化的单点分隔，如果我们找到一个分隔点将数据一分为二，分成<img src="https://math.jianshu.com/math?formula=P_1" alt="P_1">和<img src="https://math.jianshu.com/math?formula=P_2" alt="P_2">两部分，那么划分后的信息熵的计算方式为：</p>
<p><img src="https://math.jianshu.com/math?formula=Info_%7Bsplit%7D(x" alt="Info_{split}(x) = P1_{ratio}Entropy(x_{p1}) + P2_{ratio}Entropy(x_{p2})">%20%3D%20P1_%7Bratio%7DEntropy(x_%7Bp1%7D)%20%2B%20P2_%7Bratio%7DEntropy(x_%7Bp2%7D))</p>
<p>同时也可以看出，当分箱后，某个箱中的标签y的类别（0或者1）的比例相等时，其熵值最大，表明此特征划分几乎没有区分度。而当某个箱中的数据的标签y为单个类别时，那么该箱的熵值达到最小的0，即纯度最纯，最具区分度。从结果上来看，最大信息增益对应分箱后的总熵值最小。</p>
<h4><span id="34-决策树分箱有监督">3.4 决策树分箱【有监督】</span></h4><p><strong>由于决策树的结点选择和划分也是根据信息熵来计算的，因此我们其实可以利用决策树算法来进行特征分箱</strong>，具体做法如下：</p>
<p>还是以乳腺癌数据为例，首先取其中‘mean radius’字段，和标签字段‘target’来拟合一棵决策树，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt = DecisionTreeClassifier(criterion=<span class="string">&#x27;entropy&#x27;</span>, max_depth=<span class="number">3</span>) <span class="comment"># 树最大深度为3</span></span><br><span class="line">dt.fit(df[<span class="string">&#x27;mean radius&#x27;</span>].values.reshape(-<span class="number">1</span>, <span class="number">1</span>), df[<span class="string">&#x27;target&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>接着我们取出这课决策树的所有叶节点的分割点的阈值，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">qts = dt.tree_.threshold[np.where(dt.tree_.children_left &gt; -<span class="number">1</span>)]</span><br><span class="line">qts = np.sort(qts)</span><br><span class="line">res = [np.<span class="built_in">round</span>(x, <span class="number">3</span>) <span class="keyword">for</span> x <span class="keyword">in</span> qts.tolist()]</span><br></pre></td></tr></table></figure>
<h4><span id="35-卡方分箱-有监督">3.5 卡方分箱 【有监督】</span></h4><blockquote>
<p>  <strong>特征选择之卡方分箱、WOE/IV</strong> - 云水僧的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/101771771">https://zhuanlan.zhihu.com/p/101771771</a></p>
</blockquote>
<p><strong><font color="red"> 卡方检验可以用来评估两个分布的相似性，因此可以将这个特性用到数据分箱的过程中。卡方分箱认为：理想的分箱是在同一个区间内标签的分布是相同的</font>;</strong> <strong>卡方分布是概率统计常见的一种概率分布，是卡方检验的基础。卡方分布定义为</strong>：若n个独立的随机变量<img src="https://math.jianshu.com/math?formula=Z_1%2C%20Z_2%2C%20...%2CZ_k" alt="Z_1, Z_2, ...,Z_k">满足标准正态分布<img src="https://math.jianshu.com/math?formula=N(0%2C1" alt="N(0,1)">)，则n个随机变量的平方和<img src="https://math.jianshu.com/math?formula=X%3D%5Csum_%7Bi%3D0%7D%5Ek%20Z_i%5E2" alt="X=\sum_{i=0}^k Z_i^2">为服从自由度为k的卡方分布，记为<img src="https://math.jianshu.com/math?formula=X%20%5Csim%20%5Cchi%5E2" alt="X \sim \chi^2">。参数n称为自由度（样本中独立或能自由变化的自变量的个数)，不同的自由度是不同的分布。</p>
<p><strong>卡方检验</strong> ：卡方检验属于非参数假设检验的一种，其本质都是度量频数之间的差异。其假设为：<strong>观察频数与期望频数无差异或者两组变量相互独立不相关。</strong></p>
<p><img src="https://math.jianshu.com/math?formula=%5Cchi%5E2%20%3D%20%5Csum%20%5Cfrac%20%7B(O-E" alt="\chi^2 = \sum \frac {(O-E)^2}{E}">%5E2%7D%7BE%7D)</p>
<ul>
<li>卡方拟合优度检验：用于检验样本是否来自于某一个分布，比如检验某样本是否为正态分布</li>
<li>独立性卡方检验，查看两组类别变量分布是否有差异或者相关，以列联表的形式比较。以列联表形式的卡方检验中，卡方统计量由上式给出。</li>
</ul>
<h4><span id="步骤">步骤：</span></h4><p>卡方分箱是自底向上的(即基于合并的)数据离散化方法。它依赖于卡方检验:具有最小卡方值的相邻区间合并在一起,直到满足确定的停止准则。基本思想: 对于精确的离散化，相对类频率在一个区间内应当完全一致。因此,如果两个相邻的区间具有非常类似的类分布，则这两个区间可以合并；否则，它们应当保持分开。而低卡方值表明它们具有相似的类分布。</p>
<p><strong>理想的分箱是在同一个区间内标签的分布是相同的</strong>。卡方分箱就是不断的计算相邻区间的卡方值（卡方值越小表示分布越相似），将分布相似的区间（卡方值最小的）进行合并，直到相邻区间的分布不同，达到一个理想的分箱结果。下面用一个例子来解释：</p>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20220708173638301.png" alt="image-20220708173638301" style="zoom: 33%;"></p>
<p> 由上图，第一轮中初始化是5个区间，分别计算相邻区间的卡方值。找到1.2是最小的，合并2、3区间，为了方便，将合并后的记为第2区间，因此得到4个区间。第二轮中，由于合并了区间，影响该区间与前面的和后面的区间的卡方值，因此重新计算1和2,2和4的卡方值，由于4和5区间没有影响，因此不需要重新计算，这样就得到了新的卡方值列表，找到最小的取值2.5，因此该轮会合并2、4区间，并重复这样的步骤，一直到满足终止条件。</p>
<h4><span id="36-woe编码-有监督"><strong><font color="red"> 3.6 WOE编码 【有监督】</font></strong></span></h4><blockquote>
<p>  <strong><font color="red"> 风控模型—WOE与IV指标的深入理解应用</font></strong>: <a href="https://zhuanlan.zhihu.com/p/80134853">https://zhuanlan.zhihu.com/p/80134853</a></p>
</blockquote>
<p><strong>WOE（Weight of Evidence，证据权重）编码利用了标签信息，属于有监督的编码方式。该方式广泛用于金融领域信用风险模型中，是该领域的经验做法。</strong>下面先给出WOE的计算公式：<br> <img src="https://math.jianshu.com/math?formula=WOE_i%20%3D%20ln%5Clbrace%20%5Cfrac%20%7BP_%7By1%7D%7D%7BP_%7By0%7D%7D%20%5Crbrace%20%3D%20ln%5Clbrace%20%5Cfrac%20%7BB_i%20%2F%20B%7D%7BG_i%2FG%7D%20%5Crbrace" alt="WOE_i = ln\lbrace \frac {P_{y1}}{P_{y0}} \rbrace = ln\lbrace \frac {B_i / B}{G_i/G} \rbrace"><br> ==<strong><img src="https://math.jianshu.com/math?formula=WOE_i" alt="WOE_i">值可解释为第<img src="https://math.jianshu.com/math?formula=i" alt="i">类别中好坏样本分布比值的对数</strong>==。其中各个分量的解释如下：</p>
<ul>
<li><img src="https://math.jianshu.com/math?formula=P_%7By1%7D" alt="P_{y1}">表示该类别中坏样本的分布</li>
<li><img src="https://math.jianshu.com/math?formula=P_%7By0%7D" alt="P_{y0}">表示该类别中好样本的分布</li>
<li><img src="https://math.jianshu.com/math?formula=B_i%2FB" alt="B_i/B">表示该类别中坏样本的数量在总体坏样本中的占比</li>
<li><img src="https://math.jianshu.com/math?formula=G_i%2FG" alt="G_i/G">表示该类别中好样本的数量在总体好样本中的占比</li>
</ul>
<p>很明显，如果整个分数的值大于1，那么WOE值为正，否则为负，所以WOE值的取值范围为正负无穷。<br> <strong>WOE值直观上表示的实际上是“当前分组中坏客户占所有坏客户的比例”和“当前分组中好客户占所有坏客户的比例”的差异。</strong>转化公式以后，也可以理解为：当前这个组中坏客户和好客户的比值，和所有样本中这个比值的差异。这个差异为这两个比值的比值，再取对数来表示的。 WOE越大，这种差异越大，这个分组里的样本坏样本可能性就越大，WOE越小，差异越小，这个分组里的坏样本可能性就越小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 随机生成1000行数据</span></span><br><span class="line">df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;x&#x27;</span>: np.random.choice([<span class="string">&#x27;R&#x27;</span>,<span class="string">&#x27;G&#x27;</span>,<span class="string">&#x27;B&#x27;</span>], <span class="number">1000</span>),</span><br><span class="line">    <span class="string">&#x27;y&#x27;</span>: np.random.randint(<span class="number">2</span>, size=<span class="number">1000</span>)</span><br><span class="line">&#125;)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<h3><span id="四-缺失值处理解析">四、缺失值处理解析</span></h3><blockquote>
<p>  看不懂你打我，史上最全的缺失值解析: <a href="https://zhuanlan.zhihu.com/p/379707046">https://zhuanlan.zhihu.com/p/379707046</a></p>
<p>  <a href="https://zhuanlan.zhihu.com/p/137175585">https://zhuanlan.zhihu.com/p/137175585</a></p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>机器学习模型</th>
<th>是否支持缺失值</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>XGBoost</strong></td>
<td>是</td>
</tr>
<tr>
<td><strong>LightGBM</strong></td>
<td>是</td>
</tr>
<tr>
<td>线性回归</td>
<td>否</td>
</tr>
<tr>
<td>逻辑回归（LR）</td>
<td>否</td>
</tr>
<tr>
<td>随机森林（RF）</td>
<td>否</td>
</tr>
<tr>
<td>SVM</td>
<td>否</td>
</tr>
<tr>
<td>因子分解机(FM)</td>
<td>否</td>
</tr>
<tr>
<td>朴实贝叶斯（NB）</td>
<td>否</td>
</tr>
</tbody>
</table>
</div>
<h4><span id="41-缺失值的替换">4.1 <strong>缺失值的替换</strong></span></h4><p><strong>scikit-learn中填充缺失值的API是Imputer类，使用方法如下：</strong></p>
<p>参数strategy有三个值可选：mean(平均值)，median(中位数)，most_frequent(众数)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rom sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 缺失值填补的时候必须得是float类型</span></span><br><span class="line"><span class="comment"># 缺失值要填充为np.nan，它是浮点型，strategy是填充的缺失值类型，这里填充平均数，axis代表轴，这里第0轴是列</span></span><br><span class="line">im = Imputer(missing_values=<span class="string">&#x27;NaN&#x27;</span>,strategy=<span class="string">&#x27;mean&#x27;</span>,axis=<span class="number">0</span>)</span><br><span class="line">data = im.fit_transform([[<span class="number">1</span>, <span class="number">2</span>], </span><br><span class="line">                         [np.nan, <span class="number">3</span>], </span><br><span class="line">                         [<span class="number">7</span>, <span class="number">6</span>]])</span><br></pre></td></tr></table></figure>
<h4><span id="42-缺失值的删除">4.2 缺失值的删除</span></h4><h3><span id="五-异常值处理">五、异常值处理</span></h3><h2><span id="数据预处理qampa">数据预处理Q&amp;A</span></h2><h3><span id="1-lr为什么要离散化"><strong><font color="red"> 1、LR为什么要离散化？</font></strong></span></h3><h4><span id="学习-连续特征的离散化在什么情况下将连续的特征离散化之后可以获得更好的效果"></span></h4><p><strong>问题描述：</strong>发现CTR预估一般都是用LR，而且特征都是离散的，为什么一定要用离散特征呢？这样做的好处在哪里？求大拿们解答。</p>
<h4><span id="答案一严林"><strong>答案一（<a href="https://www.zhihu.com/search?q=严林&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;122387176&quot;}">严林</a>）：</strong></span></h4><p>在工业界，很少直接将连续值作为逻辑回归模型的特征输入，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：</p>
<ol>
<li>离散特征的增加和减少都很容易，易于模型的快速迭代；</li>
<li>稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；</li>
<li>【鲁棒性】离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则为0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；</li>
<li>【模型假设】<strong>逻辑回归属于广义线性模型，表达能力受限</strong>；单变量离散化为N个后，每个变量有独立的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合；</li>
<li>【特征交叉】离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力；</li>
<li>特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻的样本会刚好相反，所以怎么划分区间是门学问；</li>
<li>特征离散化以后，起到了简化逻辑回归模型的作用，降低了模型过拟合的风险；</li>
</ol>
<p><strong><font color="red"> <a href="https://www.zhihu.com/search?q=李沐&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;122387176&quot;}">李沐</a>曾经说过：模型是使用离散特征还是连续特征，其实是一个“海量离散特征+简单模型”同“少量连续特征+复杂模型”的权衡。</font></strong></p>
<blockquote>
<p>  这里我写下我关于上面某些点的理解，有问题的欢迎指出：</p>
<ol>
<li><p>假设目前有两个连续的特征：『年龄』和『收入』，预测用户的『魅力指数』；</p>
<p>第三点: <strong>LR是广义线性模型</strong>，因此如果特征『年龄』不做离散化直接输入，那么只能得到『年龄』和魅力指数的一个线性关系。但是这种线性关系是不准确的，并非年龄越大魅力指一定越大；如果将年龄划分为M段，则可以针对每段有一个对应的权重；这种分段的能力为模型带来类似『折线』的能力，也就是所谓的非线性<br><strong>连续变量的划分，naive的可以通过人为先验知识划分，也可以通过训练单特征的决策树桩，根据Information Gain/Gini系数等来有监督的划分。</strong><br>假如『年龄』离散化后，共有N段，『收入』离散化后有M段；此时这两个离散化后的特征类似于<strong>CategoryFeature</strong>，对他们进行<strong>OneHotEncode</strong>，即可以得到 M + N的 01向量；例如： 0 1 0 0， 1 0 0 0 0；<br>第四点: <strong>特征交叉</strong>，可以理解为上述两个向量的互相作用，作用的方式可以例如是 &amp;和|操作（这种交叉方式可以产生一个 M * N的01向量；）<br>上面特征交叉，可以类比于决策树的决策过程。例如进行&amp;操作后，得到一个1，则可以认为产生一个特征 （a &lt; age &lt; b &amp;&amp; c &lt; income &lt; d）;将特征空间进行的非线性划分，也就是所谓的引入非线性；</p>
</li>
</ol>
</blockquote>
<h4><span id="答案二周开拓"><strong>答案二（周开拓）：</strong></span></h4><p><strong><font color="red"> 机器学习里当然并没有free lunch，一个方法能work，必定是有假设的。如果这个假设和真实的问题及数据比较吻合，就能work。</font></strong></p>
<p>对于LR这类的模型来说，假设基本如下：</p>
<ul>
<li><strong>局部<a href="https://www.zhihu.com/search?q=平坦性&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;122387176&quot;}">平坦性</a>，或者说连续性</strong>。对于连续特征x来说，在任何一个取值x0的邻域附近，这个特征对预估目标y的影响也在一个足够小的邻域内变化。比如，人年龄对点击率的影响，x0=30岁假设会产生一定的影响，那么x=31或者29岁，这个影响和x0=30岁的影响差距不会太大；</li>
<li><strong>x对y的影响，这个函数虽然局部比较平坦，但是不太规律，如果你知道这个影响是个严格的直线</strong>（或者你有先验知识知道这个影响一定可以近似于一个参数不太多的函数），<strong>显然也没必要去做离散化</strong>。当然这条基本对于绝大多数问题都是成立的，因为基本没有这种好事情。</li>
</ul>
<p>假设一个最简单的问题，binary classification，y=0/1，x是个连续值。你希望学到一个logloss足够小的y=f(x)。</p>
<p>那么有一种做法就是，在数据轴上切若干段，每一段观察训练样本里y为1的比例，以这个比例作为该段上y=f(x)的值。这个当然不是LR训练的过程，但是就是离散化的思想。你可以发现：</p>
<ul>
<li><strong>如果每一段里面都有足够多的样本，那么在这一段里的y=f(x)值的点估计就比较可信</strong>；</li>
<li><font color="red">如果x在数轴上分布不太均匀，比如是<strong>指数分布或者周期分布</strong>的，这么做可能会有问题，因而你要先<strong>对x取个log，或者去掉周期性</strong></font>；</li>
</ul>
<p>这就告诉了你应该怎么做离散化：<strong><font color="red"> 尽可能保证每个分段里面有足够多的样本，尽量让样本的分布在数轴上均匀一些。</font></strong></p>
<p>结语：<strong>本质上连续特征离散化，可以理解为连续信号怎么转化为数字信号，好比我们计算机画一条曲线，也是变成了画一系列线段的问题。</strong>用分段函数来表达一个连续的函数在大多数情况下，都是work的。想取得好的效果需要：</p>
<ul>
<li>你的分段足够小，以使得在每个分段内x对y的影响基本在一个不大的邻域内，或者你可以忍受这个变化的幅度；</li>
<li>你的分段足够大，以使得在每个分段内有足够的样本，以获得可信的f(x)也就是权重；</li>
<li>你的分段策略使得在每个x的分段中，样本的分布尽量均匀（当然这很难），一般会根据先验知识先对x做一些变化以使得变得均匀一些；</li>
<li>如果你有非常强的x对y的先验知识，比如严格线性之类的，也未必做离散化，但是这种先验在计算广告或者推荐系统里一般是不存在的，也许其他领域比如CV之类的里面是可能存在的；</li>
</ul>
<p>最后还有个特别大的<strong>LR用离散特征的好处就是LR的特征是并行的，每个特征是并行同权的</strong>，如果有异常值的情况下，如果这个异常值没见过，那么LR里因为没有这个值的权重，最后对<a href="https://www.zhihu.com/search?q=score&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;122387176&quot;}">score</a>的贡献为0，最多效果不够好，但是不会错的太离谱。另外，如果你debug，很容易查出来是哪个段上的权重有问题，比较好定位和解决。</p>
<h3><span id="2-树模型为什么离散化"><strong><font color="red">2、树模型为什么离散化？</font></strong></span></h3><h4><span id="cart树的离散化">Cart树的离散化：</span></h4><p><strong>分类：</strong></p>
<ul>
<li><p><strong><font color="red">如果特征值是连续值：CART的处理思想与C4.5是相同的，即将连续特征值离散化。唯一不同的地方是度量的标准不一样，</font></strong> <strong>CART采用基尼指数，而C4.5采用信息增益比</strong>。</p>
</li>
<li><p>如果当前节点为连续属性，<strong>CART树中该属性（剩余的属性值）后面还可以参与子节点的产生选择过程</strong>。</p>
</li>
</ul>
<p><strong>回归：</strong></p>
<p>对于连续值的处理，<strong>CART 分类树采用基尼系数的大小来度量特征的各个划分点</strong>。<strong>在回归模型中，我们使用常见的和方差度量方式</strong>，对于任意划分特征 A，对应的任意划分点 s 两边划分成的数据集 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> ，求出使 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> 各自<strong>集合的均方差最小</strong>，同时 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> 的均方差之和最小所对应的特征和特征值划分点。表达式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=+%5Cmin%5Climits_%7Ba%2Cs%7D%5CBigg%5B%5Cmin%5Climits_%7Bc_1%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_1%7D%28y_i+-+c_1%29%5E2+%2B+%5Cmin%5Climits_%7Bc_2%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_2%7D%28y_i+-+c_2%29%5E2%5CBigg%5D+%5C%5C" alt="[公式]"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=c_1" alt="[公式]"> 为 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 数据集的样本输出均值， <img src="https://www.zhihu.com/equation?tex=c_2" alt="[公式]"> 为 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> 数据集的样本输出均值。</p>
<h4><span id="lgb直方图算法优点">LGB直方图算法优点：</span></h4><p><strong>内存小、复杂度降低、直方图加速【分裂、并行通信、缓存优化】</strong></p>
<ul>
<li><p><strong>内存消耗降低</strong>。预排序算法需要的内存约是训练数据的两倍（2x样本数x维度x4Bytes），它需要用32位浮点来保存特征值，并且对每一列特征，都需要一个额外的排好序的索引，这也需要32位的存储空间。对于 直方图算法，则只需要(1x样本数x维 度x1Bytes)的内存消耗，仅为预排序算法的1/8。因为直方图算法仅需要存储特征的 bin 值(离散化后的数值)，不需要原始的特征值，也不用排序，而bin值用8位整型存储就足够了。</p>
</li>
<li><p><strong>算法时间复杂度大大降低</strong>。决策树算法在节点分裂时有两个主要操作组成，一个是“寻找分割点”，另一个是“数据分割”。从算法时间复杂度来看，在“寻找分割点”时，预排序算法对于深度为$k$的树的时间复杂度：对特征所有取值的排序为$O(NlogN)$，$N$为样本点数目，若有$D$维特征，则$O(kDNlogN)$，而直方图算法需要$O(kD \times bin)$ (bin是histogram 的横轴的数量，一般远小于样本数量$N$)。</p>
</li>
<li><p><strong>直方图算法还可以进一步加速</strong>【<strong>==两个维度==</strong>】。一个容易观察到的现象：<strong>一个叶子节点的直方图可以直接由父节点的直方图和兄弟节点的直方图做差得到（分裂时左右集合）</strong>。通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的$k$个bin。利用这个方法，LightGBM可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。</p>
</li>
<li><p><strong>数据并行优化</strong>，用 histgoram 可以大幅降低通信代价。用 pre-sorted 算法的话，通信代价是非常大的（几乎是没办法用的）。所以 xgoobst 在并行的时候也使用 histogram 进行通信。</p>
</li>
<li><p><strong>缓存优化</strong>：上边说到 XGBoost 的预排序后的特征是通过索引给出的样本梯度的统计值，因其索引访问的结果并不连续，XGBoost 提出缓存访问优化算法进行改进。<strong><font color="red"> LightGBM 所使用直方图算法对 Cache 天生友好所有的特征都采用相同的方法获得梯度，构建直方图时bins字典同步记录一阶导、二阶导和个数，大大提高了缓存命中</font></strong>；因为<strong>不需要存储特征到样本的索引</strong>，降低了存储消耗，而且也不存在 Cache Miss的问题。</p>
</li>
</ul>
<h3><span id="3-归一化">3、归一化？</span></h3><h3><span id="4-赵兄-特征处理">4、赵兄-特征处理</span></h3><p><img src="../../../../../Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/076b7987d1501ed1ebeee6aecab0dccc/Message/MessageTemp/f381afde205729b015fb0a76a283f729/Image/891647863651_.pic.jpg" alt="891647863651_.pic"></p>
<ul>
<li>滑动窗口、随机采样、加权差分特征</li>
<li>均值插补插补，稀疏矩阵技术问题</li>
<li>分层统计、差分特征</li>
<li><strong>二阶交叉统计</strong></li>
</ul>
]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>特征工程（7）【Nan】特征重要性</title>
    <url>/posts/3MAMQRP/</url>
    <content><![CDATA[<h2><span id="特征重要性-模型的可解释性">特征重要性 - 模型的可解释性</span></h2><blockquote>
<p>  机器学习模型可解释性进行到底 —— <strong>SHAP值理论</strong>（一） - 悟乙己的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/364919024">https://zhuanlan.zhihu.com/p/364919024</a></p>
<p>  <strong>Permutation Importance</strong></p>
<p>  机器学习模型可解释性进行到底——特征重要性（四） - 悟乙己的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/364922142">https://zhuanlan.zhihu.com/p/364922142</a></p>
</blockquote>
]]></content>
      <categories>
        <category>特征工程</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（14）【Nan】LDA(主题模型)</title>
    <url>/posts/322BXWN/</url>
    <content><![CDATA[<h2><span id="ldalatent-dirichlet-allocation-主题模型"></span></h2><p><strong>同一个主题，在不同的文章中，他出现的比例(概率)是不同的</strong>，看到这里，读者可能已经发现，文档和主题之间的关系和主题和词汇的关系是多么惊人的类似！</p>
<blockquote>
<p>  LDA于2003年由 David Blei, Andrew Ng和 Michael I. Jordan提出，因为模型的简单和有效，掀起了主题模型研究的波浪。虽然说LDA模型简单，但是它的数学推导却不是那么平易近人，一般初学者会深陷数学细节推导中不能自拔。于是牛人们看不下去了，纷纷站出来发表了各种教程。国内方面rickjin有著名的《<a href="https://link.zhihu.com/?target=http%3A//www.52nlp.cn/author/rickjin">LDA数学八卦</a>》，国外的Gregor Heinrich有著名的《<a href="https://link.zhihu.com/?target=https%3A//users.soe.ucsc.edu/~amichelo/docs/text-est2.pdf">Parameter estimation for text analysis</a>》。其实有了这两篇互补的通俗教程，大家沉住心看个4、5遍，基本就可以明白LDA为什么是简单的了。那么其实也没我什么事了，然而心中总有一种被大牛点播的豁然开朗的快感，实在是不吐不快啊。</p>
</blockquote>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>概率图模型</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-SVM</title>
    <url>/posts/2P4PT4T/</url>
    <content><![CDATA[<h2><span id="支持向量机-svm">支持向量机 SVM</span></h2><p><strong>以几何的角度，在丰富的数据理论的基础上，简化了通常的分类和回归问题。</strong></p>
<h2><span id><img src="https://s2.loli.net/2023/04/17/mxOqbNtTMPoSyRz.jpg" alt="【机器学习】支持向量机 SVM（非常详细）" style="zoom:51%;"></span></h2><p>SVM 是一个非常优雅的算法，具有完善的数学理论，虽然如今工业界用到的不多，但还是决定花点时间去写篇文章整理一下。</p>
<span id="more"></span>
<h2><span id="1-支持向量">1. 支持向量</span></h2><blockquote>
<p>  <strong>本质：SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</strong>为了对数据中的噪声有一定的容忍能力。</p>
<p>  <strong>几何意义</strong>：找到一个超平面将特征空间的正负样本分开，最大分隔（对噪音有一定的容忍能力）</p>
<p>  <strong>间隔表示</strong>：划分超平面到属于不同标记的最近样本的距离之和</p>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/52168498">https://zhuanlan.zhihu.com/p/52168498</a></p>
<p><strong>KKT条件</strong>：<strong>判断不等式约束问题是否为最优解的必要条件</strong></p>
</li>
</ul>
</blockquote>
<h3><span id="11-线性可分">1.1 线性可分</span></h3><p>首先我们先来了解下什么是线性可分。</p>
<p><img src="https://s2.loli.net/2023/04/17/ycmF6werxUvYLh5.jpg" alt="img" style="zoom:50%;"></p>
<p>在二维空间上，两类点被一条直线完全分开叫做线性可分。</p>
<p>严格的数学定义是：</p>
<p><img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 是 n 维欧氏空间中的两个点集。如果存在 n 维向量 w 和实数 b，使得所有属于 <img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 的点 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 都有 <img src="https://www.zhihu.com/equation?tex=wx_i+%2B+b+%3E+0" alt="[公式]"> ，而对于所有属于 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 的点 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 则有 <img src="https://www.zhihu.com/equation?tex=wx_j+%2B+b+%3C+0" alt="[公式]"> ，则我们称 <img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 线性可分。</p>
<h3><span id="12-最大间隔超平面">1.2 最大间隔超平面</span></h3><p>从二维扩展到多维空间中时，将 <img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 完全正确地划分开的 <img src="https://www.zhihu.com/equation?tex=wx%2Bb%3D0" alt="[公式]"> 就成了一个超平面。</p>
<p>为了使这个超平面更具鲁棒性，我们会去找最佳超平面，以最大间隔把两类样本分开的超平面，也称之为最大间隔超平面。</p>
<ul>
<li>两类样本分别分割在该超平面的两侧；</li>
<li><strong>两侧距离超平面最近的样本点到超平面的距离被最大化了。</strong>【附近点】</li>
</ul>
<h3><span id="13-支持向量-距离超平面最近的点">1.3 支持向量 【距离超平面最近的点】</span></h3><p><img src="https://s2.loli.net/2023/04/17/HDlAed2wZf8cXi1.jpg" alt="img" style="zoom:50%;"></p>
<p>样本中距离超平面最近的一些点，这些点叫做支持向量。</p>
<h3><span id="14-svm-最优化问题">1.4 SVM 最优化问题</span></h3><p><strong>==SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面==</strong>。任意超平面可以用下面这个线性方程来描述：</p>
<p>​                                 <img src="https://www.zhihu.com/equation?tex=w%5ETx%2Bb%3D0+%5C%5C" alt="[公式]"></p>
<p>二维空间点 <img src="https://www.zhihu.com/equation?tex=%28x%2Cy%29" alt="[公式]"> 到直线 <img src="https://www.zhihu.com/equation?tex=Ax%2BBy%2BC%3D0" alt="[公式]"> 的距离公式是：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7CAx%2BBy%2BC%7C%7D%7B%5Csqrt%7BA%5E2%2BB%5E2%7D%7D+%5C%5C" alt="[公式]"></p>
<p><strong>扩展到 n 维空间后，点 <img src="https://www.zhihu.com/equation?tex=x%3D%28x_1%2Cx_2%E2%80%A6x_n%29" alt="[公式]"> 到直线 <img src="https://www.zhihu.com/equation?tex=w%5ETx%2Bb%3D0" alt="[公式]"> 的距离为</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7Cw%5ETx%2Bb%7C%7D%7B%7C%7Cw%7C%7C%7D+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%7C%7Cw%7C%7C%3D%5Csqrt%7Bw_1%5E2%2B%E2%80%A6w_n%5E2%7D" alt="[公式]"> 。</p>
<p>如图所示，根据支持向量的定义我们知道，支持向量到超平面的距离为 d，其他点到超平面的距离大于 d。</p>
<p><img src="https://s2.loli.net/2023/04/17/2yZRMfWemFcoX75.jpg" alt="img" style="zoom:50%;"></p>
<p>于是我们有这样的一个公式：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+%5Cbegin%7Baligned%7D+%5Cfrac%7Bw%5ETx%2Bb%7D%7B%7C%7Cw%7C%7C%7D+%26%5Cgeq+d+%5Cquad++y%3D1+%5C%5C+%5Cfrac%7Bw%5ETx%2Bb%7D%7B%7C%7Cw%7C%7C%7D+%26%5Cleq+-d++%5Cquad+y%3D-1++%5Cend%7Baligned%7D+%5Cright.+%5C%5C" alt="[公式]"></p>
<p>将两个方程合并，我们可以简写为：</p>
<p><img src="https://www.zhihu.com/equation?tex=y%28w%5ETx%2Bb%29+%5Cgeq+1+%5C%5C" alt="[公式]"></p>
<p>至此我们就可以得到最大间隔超平面的上下两个超平面：</p>
<p><img src="https://s2.loli.net/2023/04/17/aZbmfK4zWsSjyo2.png" alt="image-20220409203050568" style="zoom:50%;"></p>
<p><strong>间隔</strong>：<strong>训练集中离划分超平面最近的样本到划分超平面距离的两倍</strong>。有了间隔的定义，划分超平面“离正负样本都比较远”这一目标可以等价描述为正负样本里划分超平面的距离尽可能远。即<strong>让离划分超平面最近的样本到划分超平面距离尽可能远</strong>。==优化目标==：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\max _{\boldsymbol{w}, b} \gamma &=\max _{\boldsymbol{w}, b}\left(2 \min _{i} \frac{1}{\|\boldsymbol{w}\|}\left|\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right|\right) \\
&=\max _{\boldsymbol{w}, b} \min _{i} \frac{2}{\|\boldsymbol{w}\|}\left|\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right|
\end{aligned}</script><p><strong>简化过程</strong>：</p>
<ul>
<li><p><strong>缩放</strong>：为了简化优化问题, 我们可以通过调整 $(\boldsymbol{w}, b)$ 使得：</p>
<script type="math/tex; mode=display">
\min _{i}\left|\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right|=1 .</script></li>
<li><p><strong>标签替换绝对值</strong>：</p>
<script type="math/tex; mode=display">
s.t. \min _{i} y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)=1</script></li>
<li><p><strong>简化约束条件</strong>【<strong>反正法</strong>】</p>
</li>
</ul>
<h4><span id="硬间隔线性svm的基本型"><strong><font color="red"> 硬间隔线性SVM的基本型：</font></strong></span></h4><script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w} \\
\text { s.t. } & y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right) \geq 1, \quad i=1,2, \ldots, m
\end{array}</script><p><img src="https://s2.loli.net/2023/04/17/l4WjzV7smKBoe8f.png" alt="image-20220423163130805" style="zoom:50%;"></p>
<p><strong>二次规划是指目标函数是==二次函数==，约束是==线性不等式约束==的一类优化问题</strong> + 凸函数</p>
<h2><span id="2-硬间隔线性svm对偶型">2. 硬间隔线性SVM对偶型</span></h2><blockquote>
<p>  本科高等数学学的<strong>拉格朗日程数法</strong>是<strong>等式约束优化问题</strong>：</p>
<p>  <img src="https://www.zhihu.com/equation?tex=%5Cmin+f%28x_%7B1%7D+%2Cx_%7B2%7D+%2C...%2Cx_%7Bn%7D+%29+%5C%5C+s.t.+%5Cquad+h_%7Bk%7D+%28x_%7B1%7D+%2Cx_%7B2%7D+%2C...%2Cx_%7Bn%7D+%29%3D0+%5Cquad+k+%3D1%2C2%2C...%2Cl%5C%5C" alt="[公式]"></p>
<p>  我们令 <img src="https://www.zhihu.com/equation?tex=L%28x%2C%5Clambda+%29+%3D+f%28x%29+%2B+%5Csum%5Climits_%7Bk+%3D+1%7D%5El+%5Clambda+_k+h_k+%28x%29" alt="[公式]"> ，函数 <img src="https://www.zhihu.com/equation?tex=L%28x%2Cy%29" alt="[公式]"> 称为 Lagrange 函数，参数 <img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="[公式]"> 称为 Lagrange 乘子<strong>==没有非负要求。==</strong></p>
<p>  利用必要条件找到可能的极值点：</p>
<p>  <img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+%5Cbegin%7Baligned%7D++%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+x_i%7D+%3D+0+%5Cquad+i%3D1%2C2%2C...%2Cn+%5C%5C+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+%5Clambda_k%7D+%3D+0+%5Cquad+k%3D1%2C2%2C...%2Cl++%5Cend%7Baligned%7D+%5Cright.+%5C%5C" alt="[公式]"></p>
<p>  具体是否为极值点需根据问题本身的具体情况检验。这个方程组称为等式约束的极值必要条件。</p>
<p>  等式约束下的 Lagrange 乘数法引入了 <img src="https://www.zhihu.com/equation?tex=l" alt="[公式]"> 个 Lagrange 乘子，我们将 <img src="https://www.zhihu.com/equation?tex=x_%7Bi%7D" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bk%7D" alt="[公式]"> 一视同仁，把 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bk%7D+" alt="[公式]"> 也看作优化变量，共有 <img src="https://www.zhihu.com/equation?tex=%28n%2Bl%29" alt="[公式]"> 个优化变量。</p>
</blockquote>
<h5><span id="1写成约束优化问题的基本型">（1）写成约束优化问题的基本型</span></h5><script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w} \\
\text { s.t. } & 1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right) \leq 0, \quad i=1,2, \ldots, m
\end{array}</script><h5><span id="2-构建基本型的拉格朗日函数">（2） 构建基本型的拉格朗日函数</span></h5><script type="math/tex; mode=display">
\mathcal{L}(\boldsymbol{w}, b, \boldsymbol{\alpha}):=\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right)</script><h5><span id="3交换min-max顺序">（3）交换min, max顺序</span></h5><blockquote>
<p>  ==<strong>解得最优解 $\boldsymbol{u}^{\star}$ 。这样两层优化问题将变为一层最大化（max）问题, 问题难度大大降低, 称为对偶问题 (Dual Problem) :</strong>==【<strong>对偶问题是原问题的下界</strong>】</p>
<ul>
<li><script type="math/tex; mode=display">
\max _{\boldsymbol{\alpha}, \boldsymbol{\beta}} \min _{\boldsymbol{u}} \mathcal{L}(\boldsymbol{u}, \boldsymbol{\alpha}, \boldsymbol{\beta}) \leq \min _{\boldsymbol{u}} \max _{\boldsymbol{\alpha}, \boldsymbol{\beta}} \mathcal{L}(\boldsymbol{u}, \boldsymbol{\alpha}, \boldsymbol{\beta})</script></li>
<li><p>硬间隔线性SVM满足<strong>Slater条件</strong>， <strong>因此原问题和对偶问题等价</strong></p>
</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">
\begin{array}{cl}
\max _{\boldsymbol{\alpha}} \min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right) \\
\text { s.t. } & \alpha_{i} \geq 0, \quad i=1,2, \ldots, m .
\end{array}</script><p>首先计算 $\boldsymbol{w}$ 的最优值, 令 $\frac{\partial \mathcal{L}}{\partial \boldsymbol{w}}=\mathbf{0}$</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial \boldsymbol{w}} &=\frac{\partial}{\partial \boldsymbol{w}}\left(\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right)\right) \\
&=\boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(-y_{i} \boldsymbol{x}_{i}\right) \\
&=\boldsymbol{w}-\sum_{i=1}^{m} \alpha_{i} y_{i} \boldsymbol{x}_{i} \\
&=\mathbf{0}
\end{aligned}</script><p>==可以解得最优值==$\boldsymbol{w}$</p>
<script type="math/tex; mode=display">
\boldsymbol{w}^{\star}=\sum_{i=1}^{m} \alpha_{i} y_{i} \boldsymbol{x}_{i}</script><p>然后计算 $b$ 的最优值, 令 $\frac{\partial \mathcal{L}}{\partial b}=0$</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial b} &=\frac{\partial}{\partial b}\left(\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right)\right) \\
&=\sum_{i=1}^{m} \alpha_{i}\left(-y_{i}\right) \\
&=-\sum_{i=1}^{m} \alpha_{i} y_{i} \\
&=0
\end{aligned}</script><p>==可以得到一个等式== $b^{\star}$ </p>
<script type="math/tex; mode=display">
\sum_{i=1}^{m} \alpha_{i} y_{i}=0</script><p>注意到这里并没有给出最优值 $b^{\star}$ 应该是多少, 而是一个等式, 该等式是一个约束项, 而最优值通过后面的 <strong>KKT 条件</strong>的互补松弛可以计算得到。</p>
<h4><span id="硬性间隔线性svm的对偶型"><strong><font color="red"> 硬性间隔线性SVM的对偶型：</font></strong></span></h4><script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{\alpha}} & \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j} \boldsymbol{x}_{i}^{\top} \boldsymbol{x}_{j}-\sum_{i=1}^{m} \alpha_{i} \\
\text { s.t. } & \alpha_{i} \geq 0, \quad i=1,2, \ldots, m \\
& \sum_{i=1}^{m} \alpha_{i} y_{i}=0
\end{array}</script><h5><span id="4利用kkt条件得到主问题的最优解">==（4）利用KKT条件得到主问题的最优解==</span></h5><p><strong>KKT 条件是指优化问题在最优处（包括基本型的最优值，对偶问题的最优值）必须满足的条件</strong>。</p>
<p>线性支持向量机的 <strong>KKT 条件</strong>:</p>
<ul>
<li><strong>主问题可行</strong>: $g_{i}\left(\boldsymbol{u}^{\star}\right)=1-y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right) \leq 0$ ；</li>
<li><strong>对偶问题可行</strong>: $\alpha_{i}^{\star} \geq 0$;</li>
<li><strong>主变量最优</strong>: $\boldsymbol{w}^{\star}=\sum_{i=1}^{m} \alpha_{i} y_{i} \boldsymbol{x}_{i}, \sum_{i=1}^{m} \alpha_{i} y_{i}=0$;</li>
<li><strong><font color="red"> 互补松弛: $\alpha_{i}^{\star} g_{i}\left(\boldsymbol{u}^{\star}\right)=\alpha_{i}^{\star}\left(1-y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right)\right)=0$ ；</font></strong></li>
</ul>
<p><strong>根据 KKT 条件中的 $\alpha_{i}^{\star} \geq 0$, 我们可以根据 $\alpha_{i}^{\star}$ 的取值将训练集 $D$ 中所有的样本分成两类</strong>, 如 图 17 所示。</p>
<ul>
<li>如果 $\alpha_{i}^{\star}&gt;0$, <strong>对应的样本称为支持向量 (Support Vector)</strong>, 根据 $\alpha_{i}^{\star}\left(1-y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right)\right)=0$ , 那么一定有 $y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right)=1$, 该样本是距离划分超平面最近的样本, 位于最大间隔边界 （见第 $2.3$ 节）;</li>
<li>如果 $\alpha_{i}^{\star}=0$, 对应的样本不是非支持向量, 那么有 $y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right) \geq 1$, 该样本不一定是距离 划分超平面最近的样本, <strong>位于最大间隔边界或之外</strong>。</li>
</ul>
<p><img src="https://s2.loli.net/2023/04/17/Gkx9AygPfvXmheq.png" alt="image-20220409212350705" style="zoom:50%;"></p>
<p><strong>结论</strong>：</p>
<ul>
<li><strong><font color="red"> 参数 w， b 仅由支持向量决定，与训练集的其他样本无关；</font></strong></li>
<li><strong><font color="red"> 对偶性是非参数模型，预测阶段不仅需要$\alpha_{i}$参数，还支持向量；</font></strong></li>
</ul>
<script type="math/tex; mode=display">
\begin{aligned}
&h(\boldsymbol{x}):=\operatorname{sign}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}+b^{\star}\right) \quad \text { （硬间隔线性 SVM 的基本型的假设函数） }\\
&=\operatorname{sign}\left(\sum_{i \in S V} \alpha_{i}^{\star} y_{i} \boldsymbol{x}_{i}^{\top} \boldsymbol{x}+b^{\star}\right) \text {.(硬间隔线性 SVM 的对偶型的假设函数） }
\end{aligned}</script><h3><span id="3-svm优化方法">3、SVM优化方法</span></h3><h5><span id="smo算法求解">==SMO算法求解==</span></h5><p>我们可以看出来这是一个<strong>二次规划问题</strong>，问题规模正比于训练样本数，我们常用 SMO(Sequential Minimal Optimization) 算法求解。</p>
<p><strong>==SMO(Sequential Minimal Optimization)，序列最小优化算法【基于坐标下降算法】，其核心思想非常简单：每次只优化一个参数，其他参数先固定住，仅求当前这个优化参数的极值。我们来看一下 SMO 算法在 SVM 中的应用。==</strong></p>
<p>我们刚说了 SMO 算法每次只优化一个参数，但我们的优化目标有约束条件： <img src="https://www.zhihu.com/equation?tex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bn%7D%5Clambda_iy_i+%3D+0" alt="[公式]"> ，没法一次只变动一个参数。所以我们选择了一次选择两个参数。具体步骤为：</p>
<ol>
<li>选择两个需要更新的参数 <img src="https://www.zhihu.com/equation?tex=%5Clambda_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Clambda_j" alt="[公式]"> ，固定其他参数。于是我们有以下约束：</li>
</ol>
<p>这样约束就变成了：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Clambda_i+y_i%2B%5Clambda_j+y_j+%3D+c+%5Cquad+%5Clambda_i+%5Cgeq+0%2C%5Clambda_j+%5Cgeq+0+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=c%3D-%5Csum%5Climits_%7Bk+%5Cne+i%2Cj%7D%5Clambda_ky_k" alt="[公式]"> ，由此可以得出 <img src="https://www.zhihu.com/equation?tex=%5Clambda_j%3D%5Cfrac%7Bc-%5Clambda_iy_i%7D%7By_j%7D" alt="[公式]"> ，也就是说我们可以用 <img src="https://www.zhihu.com/equation?tex=%5Clambda_i" alt="[公式]"> 的表达式代替 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bj%7D" alt="[公式]"> 。这样就相当于把目标问题转化成了仅有一个约束条件的最优化问题，仅有的约束是 <img src="https://www.zhihu.com/equation?tex=%5Clambda_i+%5Cgeq+0" alt="[公式]"> 。</p>
<ol>
<li><p>对于仅有一个约束条件的最优化问题，我们完全可以在 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi%7D" alt="[公式]"> 上对优化目标求偏导，令导数为零，从而求出变量值 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi_%7Bnew%7D%7D" alt="[公式]"> ，然后根据 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi_%7Bnew%7D%7D" alt="[公式]"> 求出 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bj_%7Bnew%7D%7D" alt="[公式]"> 。</p>
</li>
<li><p>多次迭代直至收敛。</p>
</li>
</ol>
<p>通过 SMO 求得最优解 <img src="https://www.zhihu.com/equation?tex=%5Clambda%5E%2A" alt="[公式]"> 。</p>
<h3><span id="4-软间隔线性svm">4. 软间隔线性SVM</span></h3><p>在实际应用中，完全线性可分的样本是很少的，如果遇到了不能够完全线性可分的样本，我们应该怎么办？比如下面这个：</p>
<p><img src="https://s2.loli.net/2023/04/17/zDNf9QWoTs2JxVp.jpg" alt="img" style="zoom: 33%;"></p>
<p>于是我们就有了软间隔，相比于硬间隔的苛刻条件，我们允许个别样本点出现在间隔带里面，比如：</p>
<p><img src="https://s2.loli.net/2023/04/17/ha4zMrmIS9Z7jnW.jpg" alt="img" style="zoom: 33%;"></p>
<p>我们允许部分样本点不满足约束条件：</p>
<p><img src="https://www.zhihu.com/equation?tex=1-y_i%28w%5ETx_i+%2B+b%29+%5Cleq+0+%5C%5C" alt="[公式]"></p>
<p>为了度量这个间隔软到何种程度，我们为每个样本引入一个松弛变量 <img src="https://www.zhihu.com/equation?tex=%5Cxi_%7Bi%7D" alt="[公式]"> ，令 <img src="https://www.zhihu.com/equation?tex=%5Cxi_%7Bi%7D+%5Cgeq+0" alt="[公式]"> ，且 <img src="https://www.zhihu.com/equation?tex=1+-+y_i%28w%5ETx_i+%2B+b%29-%5Cxi_i+%5Cleq+0" alt="[公式]"> 。对应如下图所示：</p>
<p><img src="https://s2.loli.net/2023/04/17/GlPvqnUM7FDeTyX.jpg" alt="img" style="zoom: 33%;"></p>
<p><strong>这边要注意一个问题，在间隔内的那部分样本点是不是支持向量？</strong></p>
<p>我们可以由求参数 w 的那个式子可看出，只要 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi%7D+%3E+0" alt="[公式]"> 的点都能够影响我们的超平面，因此都是支持向量。</p>
<p><strong>==硬间隔线性SVM的基本型：==</strong>【凸二次规划问题， 具有全局最小值】</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w} \\
\text { s.t. } & y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right) \geq 1, \quad i=1,2, \ldots, m
\end{array}</script><p>约束中要求所有的样本都满足 $y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1$, 也就是让所有的样本都满足 $y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right)&gt;0$。<br>现在我们想对<strong>该约束进行一点放松</strong>, 我们希望在优化间隔的同时, 允许分类错误的样本出现, 但这类样本应尽可能少:</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+C \sum_{i=1}^{m} \mathbb{I}\left(y_{i} \neq \operatorname{sign}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right)\right) \\
\text { s.t. } & y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1, \quad \text { 若 } y_{i}=\operatorname{sign}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) .
\end{array}</script><p>其中, 优化目标的第一项 $\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}$ 源自硬间隔核化 SVM 的基本型, 即优化间隔。优化目标的第二项 中的 $\mathbb{I}(\cdot)$ 是指示函数, 函数的参数通常是一个条件, 如果条件为真（True）, 则指示函数值为 1 ; 如果条件为假 (False), 则指示函数值为 0 。<br>$\sum_{i=1}^{m} \mathbb{I}\left(y_{i} \neq \operatorname{sign}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right)\right)$ 的含义是统计训练集 $D$ 中所有<strong>预测错误的样本总数</strong>。因此, 公式 162 的目标函数是同时优化间隔和最小化训练集预测错误的样本总数, <strong>==$C$ 是个可调节的超参数, 用于权衡优化间隔和出现少量分类错误的样本这两个目标。==</strong></p>
<p>但是, 由于<strong>==指示函数 $I(\cdot)$ 不是连续函数, 更不是凸函数, 使得优化问题不再是二次规划问题==</strong>, 求解起来十分困难, 所以我们需要对其进行简化。另外<strong>==指示函数没有区分预测错误的不同程度==</strong>,因此, 我们<strong>引入松他变量</strong> (Slack Variable) $\xi_{i} \in \mathbb{R}$, 用于<strong>度量训练集 $D$ 中第 $i$ 个样本违背约束的程度</strong>。当第 $i$ 个样本<strong>==违背约束的程度==</strong>越大, 松弛变量 $\xi_{i}$ 的值越大</p>
<script type="math/tex; mode=display">
\xi_{i}:= \begin{cases}0 & \text { 若 } y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1 ; \\ 1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) & \text { 否则. }\end{cases}</script><p>基于以上定义, 松弛变量 $\xi_{i}$ 的取值有以下四种情况, 如图 27 所示, 注意图 27 只是示意图, 用于理 解概念, 不表示用图中数据训练得到的分类边界一定是这样:</p>
<ul>
<li>当 $\xi_{i}=0$ 时, 训练集 $D$ 中第 $i$ 个样本分类正确 $h\left(\boldsymbol{x}_{i}\right)=y_{i}$, 且满足大间隔约束 $y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1$;</li>
<li>当 $0&lt;\xi_{i}&lt;1$ 时, 训练集 $D$ 中第 $i$ 个样本分类正确 $h\left(\boldsymbol{x}_{i}\right)=y_{i}$, 但是不满足大间隔约束;</li>
<li>当 $\xi_{i}=1$ 时, 训练集 $D$ 中第 $i$ 个样本恰好位于划分超平面 $\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b=0$ 上, 且不满足大间 隔约束;</li>
<li>当 $\xi&gt;0$ 时, 训练集 $D$ 中第 $i$ 个样本分类错误 $h\left(\boldsymbol{x}_{i}\right) \neq y_{i}$, 且不满足大间隔约束。</li>
</ul>
<p><img src="https://s2.loli.net/2023/04/17/LPukQfqKiBNToV5.png" alt="image-20220409230106609" style="zoom:50%;"></p>
<h4><span id="软间隔核化svm基本型合页损失函数"><strong>==软间隔核化SVM基本型==：</strong>（<strong>==合页损失函数==</strong>）</span></h4><p><img src="https://s2.loli.net/2023/04/17/ROQk4xowVb7Fu39.png" alt="image-20220401163522598" style="zoom:50%;"></p>
<p><img src="https://s2.loli.net/2023/04/17/CvTiDaHNeWm3q6E.png" alt="image-20220401164527480" style="zoom:50%;"></p>
<p><strong>变为：</strong></p>
<p><img src="https://s2.loli.net/2023/04/17/bsWvAUQaM29RzNP.png" alt="image-20220401164354384" style="zoom:50%;"></p>
<p>令<img src="https://s2.loli.net/2023/04/17/3j4TyoqNfcnBrLW.png" alt="image-20220401164559373" style="zoom:50%;">：<strong>==合页损失==</strong></p>
<p><img src="https://s2.loli.net/2023/04/17/XIRKolZvQGECYAw.png" alt="image-20220401164608500" style="zoom:50%;"></p>
<blockquote>
<h5><span id="回顾对数几率回归">回顾：对数几率回归：</span></h5><p>  <img src="https://s2.loli.net/2023/04/17/ZtVDeIKydQsNhTM.png" alt="image-20220401164913393" style="zoom:50%;"></p>
</blockquote>
<p>==<strong>软间隔核化SVM对偶性：</strong>== <strong>软间隔的对偶性是在硬间隔的对偶性对拉格朗日参数添加一个上界</strong>。</p>
<p><img src="https://s2.loli.net/2023/04/17/hMnsiJqL59xYduO.png" alt="image-20220401161707141" style="zoom:50%;"></p>
<h3><span id="5-核函数对偶性">5. 核函数【对偶性】</span></h3><h4><span id="51-线性不可分">5.1 线性不可分</span></h4><blockquote>
<p>  <strong>==对于在有限维度向量空间中线性不可分的样本，我们将其映射到更高维度的向量空间里，再通过间隔最大化的方式，学习得到支持向量机，就是非线性 SVM。==</strong></p>
</blockquote>
<p>我们刚刚讨论的<strong>硬间隔</strong>和<strong>软间隔</strong>都是在说样本的完全线性可分或者大部分样本点的线性可分。</p>
<p>但我们可能会碰到的一种情况是样本点不是线性可分的，比如：</p>
<p><img src="https://s2.loli.net/2023/04/17/BpDe2wT9zZQrJVn.jpg" alt="img" style="zoom:50%;"></p>
<p>这种情况的解决方法就是：将<strong>==二维线性不可分样本映射到高维空间中，让样本点在高维空间线性可分==</strong>，比如：</p>
<p><img src="https://s2.loli.net/2023/04/17/JhEDzmfuGyPK7A6.jpg" alt="img" style="zoom:50%;"></p>
<p>对于在有限维度向量空间中线性不可分的样本，我们将其映射到更高维度的向量空间里，再通过间隔最大化的方式，学习得到支持向量机，就是非线性 SVM。</p>
<p>我们用 x 表示原来的样本点，用 <img src="https://www.zhihu.com/equation?tex=%5Cphi%28x%29" alt="[公式]"> 表示 x 映射到特征新的特征空间后到新向量。那么分割超平面可以表示为： <img src="https://www.zhihu.com/equation?tex=f%28x%29%3Dw+%5Cphi%28x%29%2Bb" alt="[公式]"> 。</p>
<p>对于非线性 SVM 的对偶问题就变成了：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cmin%5Climits_%7B%5Clambda%7D+%5B%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%5Clambda_i+%5Clambda_j+y_i+y_j+%28%5Cphi%28x_i%29+%5Ccdot+%5Cphi%28x_j%29%29-%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%5Clambda_i%5D+%5C%5C+s.t.++%5Cquad+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Clambda_iy_i+%3D+0%2C+%5Cquad+%5Clambda_i+%5Cgeq+0%2C+%5Cquad+C-%5Clambda_i-%5Cmu_i%3D0+%5C%5C" alt="[公式]"></p>
<p>可以看到与线性 SVM 唯一的不同就是：之前的 <img src="https://www.zhihu.com/equation?tex=%28x_i+%5Ccdot+x_j%29" alt="[公式]"> 变成了 <img src="https://www.zhihu.com/equation?tex=%28%5Cphi%28x_i%29+%5Ccdot+%5Cphi%28x_j%29%29" alt="[公式]"> 。</p>
<h3><span id="52-核函数的作用">5.2 核函数的作用</span></h3><p>我们不禁有个疑问：只是做个内积运算，为什么要有核函数的呢？</p>
<p>这是因为<strong>低维空间映射到高维空间后维度可能会很大，如果将全部样本的点乘全部计算好，这样的计算量太大</strong>了。</p>
<p>但如果我们有这样的一==核函数== <img src="https://www.zhihu.com/equation?tex=k%28x%2Cy%29+%3D+%28%5Cphi%28x%29%2C%5Cphi%28y%29%29" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 在特征空间的内积等于它们在原始样本空间中通过函数 <img src="https://www.zhihu.com/equation?tex=k%28+x%2C+y%29" alt="[公式]"> 计算的结果，我们就不需要计算高维甚至无穷维空间的内积了。</p>
<p>举个例子：假设我们有一个<strong>==多项式核函数==</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x%2Cy%29%3D%28x+%5Ccdot+y+%2B+1%29%5E2+%5C%5C" alt="[公式]"></p>
<p>带进样本点的后：</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x%2Cy%29+%3D+%28%5Csum_%7Bi%3D1%7D%5En%28x_i+%5Ccdot+y_i%29+%2B+1%29%5E2+%5C%5C" alt="[公式]"></p>
<p>而它的展开项是：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi%3D1%7D%5Enx_i%5E2y_i%5E2%2B%5Csum_%7Bi%3D2%7D%5En%5Csum_%7Bj%3D1%7D%5E%7Bi-1%7D%28%5Csqrt2x_ix_j%29%28%5Csqrt2y_iy_j%29%2B%5Csum_%7Bi%3D1%7D%7Bn%7D%28%5Csqrt2x_i%29%28%5Csqrt2y_i%29%2B1+%5C%5C" alt="[公式]"></p>
<p>如果没有核函数，我们则需要把向量映射成：</p>
<p><img src="https://www.zhihu.com/equation?tex=x%5E%7B%27%7D+%3D+%28x_1%5E2%2C...%2Cx_n%5E2%2C...%5Csqrt2x_1%2C...%2C%5Csqrt2x_n%2C1%29+%5C%5C" alt="[公式]"></p>
<p>然后在进行内积计算，才能与多项式核函数达到相同的效果。</p>
<p>可见核函数的引入一方面减少了我们计算量，另一方面也减少了我们存储数据的内存使用量。</p>
<h3><span id="53-常见核函数">5.3 常见核函数</span></h3><p>我们常用核函数有：</p>
<p><strong>线性核函数</strong>【无映射】</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x_i%2Cx_j%29+%3D+x_i%5ETx_j+%5C%5C" alt="[公式]"></p>
<ul>
<li>优点：有加速算法库、没有特征映射、过拟合风险低</li>
<li>缺点：只能处理线性</li>
</ul>
<p><strong>多项式核函数</strong>【映射，超参数】</p>
<p><img src="https://www.zhihu.com/equation?tex=+k%28x_i%2Cx_j%29+%3D+%28x_i%5ETx_j%29%5Ed%5C%5C" alt="[公式]"></p>
<p><strong>高斯核函数</strong>【映射，超参数】</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x_i%2Cx_j%29+%3D+exp%28-%5Cfrac%7B%7C%7Cx_i-x_j%7C%7C%7D%7B2%5Cdelta%5E2%7D%29+%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>表示能力强，但容易过拟合</strong></li>
<li><strong>高斯核没有多项核不稳定的问题</strong></li>
<li><strong>只有一个超参数</strong></li>
</ul>
<h3><span id="54-如何选择核函数">==5.4 <strong>如何选择核函数？</strong>==</span></h3><blockquote>
<p>  <strong>其他核函数：拉普拉斯、sigmod、卡方、直方图交叉</strong></p>
<p>  可自定义和组合核函数</p>
</blockquote>
<ul>
<li>如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM；</li>
<li>如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数；</li>
<li>如果特征的数量小，而样本的数量很大，则需要手工添加一些特征从而变成第一种情况。</li>
</ul>
<p><img src="https://s2.loli.net/2023/04/17/uFims1jZcWSPBRx.png" alt="image-20220331203905843" style="zoom:50%;"></p>
<h3><span id="55-核方法">5.5 核方法</span></h3><h4><span id="核化lr-非线性">核化LR [非线性]</span></h4><p>正类: y = +1 负类 y= -1</p>
<p><img src="https://s2.loli.net/2023/04/17/mvX4dbSUTuzYKAq.png" alt="image-20220331205845613" style="zoom:50%;"></p>
<p><img src="https://s2.loli.net/2023/04/17/UGMhET5quOZiVLn.png" alt="image-20220331211740625" style="zoom:50%;"></p>
<p><img src="https://s2.loli.net/2023/04/17/6HjbuOyVkhNDmAL.png" alt="image-20220331211757367" style="zoom:50%;"></p>
<p><strong>梯度下降求解：</strong></p>
<p>核化LR的参数通常都非0，并且几乎用到所有训练的样本，预测效率比较低。</p>
<p><img src="https://s2.loli.net/2023/04/17/8d9UGWZyzBoAhjJ.png" alt="image-20220331212433609" style="zoom:50%;"></p>
<h3><span id="56-支持向量回归-svr-核化岭回归">5.6 支持向量回归 SVR = ？核化岭回归？</span></h3><blockquote>
<p>  <a href="https://blog.csdn.net/ch18328071580/article/details/94168411">https://blog.csdn.net/ch18328071580/article/details/94168411</a></p>
<p>  <strong>支持向量在隔代之外</strong></p>
</blockquote>
<h4><span id="svr与一般线性回归的区别">SVR与一般线性回归的区别</span></h4><div class="table-container">
<table>
<thead>
<tr>
<th>SVR</th>
<th>线性回归</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据在间隔带内则不计算损失，<strong>当且仅当f(x)与y之间的差距的绝对值大于ϵ才计算损失</strong></td>
<td>只要f(x)与y不相等时，就计算损失</td>
</tr>
<tr>
<td><strong>通过最大化间隔带的宽度与最小化总损失</strong>来优化模型</td>
<td>通过梯度下降之后求均值来优化模型</td>
</tr>
</tbody>
</table>
</div>
<p><strong>岭回归：</strong><img src="https://s2.loli.net/2023/04/17/tHg4BJuNZzcX7Yd.png" alt="image-20220401144206172" style="zoom:50%;"></p>
<h5><span id="支持向量回归我们假设fx与y之间最多有一定的偏差大于偏差才计数损失">支持向量回归：==我们假设f(x)与y之间最多有一定的偏差，大于偏差才计数损失==</span></h5><script type="math/tex; mode=display">
\min _{w, b} \frac{1}{2}\|w\|^{2}+C \sum_{i=1}^{m} l_{\epsilon}\left(f\left(x_{i}\right), y_{i}\right)</script><p>其中C为正则化常数, $l_{\epsilon}$ 是图中所示的 $\epsilon$-不敏感损失 ( $\epsilon$-insensitive loss)函数:</p>
<script type="math/tex; mode=display">
l_{\epsilon}(\mathrm{z})= \begin{cases}0, & \text { if }|z| \leq \epsilon \\ |z|-\epsilon, & \text { otherwise }\end{cases}</script><p>引入松弛变量 $\xi_{i}$ 和 $\left(\xi_{i}\right)$, 可将式重写为:</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\min _{w, b, \xi_{i}, \xi_{i}} & \frac{1}{2}\|w\|^{2}+C \sum_{i=1}^{m}\left(\xi_{i}, \widehat{\xi}_{i}\right) \\
\text { s.t. } & f\left(x_{i}\right)-y_{i} \leq \epsilon+\xi_{i} \\
& y_{i}-f\left(x_{i}\right) \leq \epsilon+\widehat{\xi}_{i} \\
& \xi_{i} \geq 0, \hat{\xi}_{i} \geq 0, i=1,2, \ldots m
\end{array}</script><p>引入拉格朗日乘子 $\mu_{i}$,</p>
<p>$L(w, b, \alpha, \hat{\alpha}, \xi, \hat{\xi}, \mu, \hat{\mu})$<br>$=\frac{1}{2}|w|^{2}+C \sum_{i=1}^{m}\left(\xi_{i}+\widehat{\xi}_{i}\right)-\sum_{i=1}^{m} \xi_{i} \mu_{i}-\sum_{i=1}^{m} \widehat{\xi}_{i} \widehat{\mu_{i}}$<br>$+\sum_{i=1}^{m} \alpha_{i}\left(f\left(x_{i}\right)-y_{i}-\epsilon-\xi_{i}\right)+\sum_{i=1}^{m} \widehat{\alpha_{i}}\left(y_{i}-f\left(x_{i}\right)-\epsilon-\widehat{\xi}_{i}\right)$</p>
<p>再令 $L(w, b, a, \hat{a}, \xi, \hat{\xi}, \mu, \mu)$ 对 $w, b, \xi_{i}, \hat{\xi}_{i}$ 的偏导为零可得:</p>
<script type="math/tex; mode=display">
w=\sum_{i=1}^{m}\left(\widehat{\alpha_{i}}-\alpha_{i}\right) x_{i}</script><p>上述过程中需满足KKT条件, 即要求:</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{c}
\alpha_{i}\left(f\left(x_{i}\right)-y_{i}-\epsilon-\xi_{i}\right)=0 \\
\widehat{\alpha_{i}}\left(y_{i}-f\left(x_{i}\right)-\epsilon-\widehat{\xi}_{i}\right)=0 \\
\alpha_{i} \widehat{\alpha_{i}}=0, \xi_{i} \widehat{\xi}_{i}=0 \\
\left(C-\alpha_{i}\right) \xi_{i}=0,\left(C-\widehat{\alpha_{i}}\right) \widehat{\xi}_{i}=0 .
\end{array}\right.</script><h3><span id="57-多分类-svm">5.7 多分类 SVM</span></h3><h4><span id="571-多分类问题">5.7.1 多分类问题</span></h4><ul>
<li>多分类问题拆解成若干个二分类问题，对于每个二分类训练一个分类器。<ul>
<li><strong>one vs one 拆解</strong>：K(K-1)/2 个分类器。</li>
<li><strong>one vs Rest 拆解</strong>：K个分类器</li>
</ul>
</li>
</ul>
<p><img src="https://s2.loli.net/2023/04/17/OJqX539ByWxSDVN.png" alt="image-20220401192909167" style="zoom:50%;"></p>
<ul>
<li><p><strong>根据模型特点设计：多分类线性SVM</strong></p>
<ul>
<li><p><strong>层次支持向量机</strong></p>
</li>
<li><p><strong>回顾二分类</strong>；</p>
<p><img src="https://s2.loli.net/2023/04/17/YJLzqnSQGTyXFc3.png" alt="image-20220401193645250" style="zoom:50%;"></p>
</li>
<li><p><strong>多分类线性SVM</strong>：</p>
<p><img src="https://s2.loli.net/2023/04/17/kZ19DcBfzWuMAaG.png" alt="image-20220401194059380" style="zoom:50%;"></p>
</li>
</ul>
</li>
</ul>
<h2><span id="6-优缺点">6. 优缺点</span></h2><h3><span id="61-优点">6.1 优点</span></h3><ul>
<li>有严格的<strong>==数学理论支持==</strong>，<strong>==可解释性强==</strong>，<strong>==不依靠统计方法==</strong>，从而<strong>简化了通常的分类和回归问题</strong>；</li>
<li>能找出对任务至关重要的<strong>==关键样本==</strong>（即：<strong>支持向量</strong>）；</li>
<li>采用<strong>==核技巧==</strong>之后，<strong>==可以处理非线性分类/回归任务==</strong>；</li>
<li><strong>==最终决策函数只由少数的支持向量所确定，计算的复杂性取决于支持向量的数目，而不是样本空间的维数，这在某种意义上避免了“维数灾难”。==</strong></li>
</ul>
<h3><span id="62-缺点">6.2 缺点</span></h3><ul>
<li><strong>训练时间长</strong>：当采用 SMO 算法时，由于每次都需要挑选一对参数，因此时间复杂度为 <img src="https://www.zhihu.com/equation?tex=O%28N%5E2%29" alt="[公式]"> ，其中 N 为训练样本的数量；</li>
<li><strong>存储空间大</strong>：当采用核技巧时，如果需要存储核矩阵，则空间复杂度为 <img src="https://www.zhihu.com/equation?tex=O%28N%5E2%29" alt="[公式]"> ；</li>
<li><strong>预测时间长</strong>：模型预测时，预测时间与支持向量的个数成正比。当支持向量的数量较大时，预测计算复杂度较高。</li>
</ul>
<p><strong>==因此支持向量机目前只适合小批量样本的任务，无法适应百万甚至上亿样本的任务。==</strong></p>
<h2><span id="svm-qampa">SVM Q&amp;A</span></h2><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/93715996">https://zhuanlan.zhihu.com/p/93715996</a></p>
</blockquote>
<h3><span id="1-原理">1、原理：</span></h3><ul>
<li>简单介绍SVM（详细原理）：从分类平面，到求两类间的最大间隔，到转化为求间隔分之一，等优化问题，然后就是优化问题的解决办法，首先是用拉格拉日乘子把约束优化转化为无约束优化，对各个变量求导令其为零，得到的式子带入拉格朗日式子从而转化为对偶问题， 最后再利用SMO（序列最小优化）来解决这个对偶问题。<strong>svm里面的超参数c有啥用：软间隔SVM去权衡优化目标和少量分错样本的目标。</strong></li>
<li><p>SVM的推导，解释原问题和对偶问题，<strong>SVM原问题和对偶问题的关系</strong>，<strong>KKT限制条件</strong>，<strong>KKT条件用哪些</strong>，完整描述；软间隔问题，解释支持向量、核函数（哪个地方引入、画图解释高维映射，高斯核可以升到多少维，如何选择核函数），引入拉格朗日的优化方法的原因，最大的特点，损失函数解释</p>
<ul>
<li><strong>KKT限制</strong>：主问题可行、对偶问题可行、主变量最优、<strong>互补松弛</strong></li>
</ul>
</li>
<li><p><strong>为什么要把原问题转换为对偶问题？</strong></p>
<ul>
<li>因为原问题是凸二次规划问题，转换为对偶问题更加高效。为什么求解对偶问题更加高效？因为只用求解alpha系数，而alpha系数只有支持向量才非0，其他全部为0.alpha系数有多少个？样本点的个数</li>
</ul>
</li>
</ul>
<h3><span id="2-svm与lr最大区别lr和svm对于outlier的敏感程度分析逻辑回归与svm的区别">2、SVM与LR最大区别，LR和SVM对于outlier的敏感程度分析，逻辑回归与SVM的区别？</span></h3><h3><span id="3-svm如何解决多分类问题-可以做回归吗怎么做">3、SVM如何解决==多分类问题==、可以做==回归==吗，怎么做？</span></h3><h3><span id="4-机器学习有很多关于核函数的说法核函数的定义和作用是什么">4、机器学习有很多关于核函数的说法，核函数的定义和作用是什么？</span></h3><p><a href="https://www.zhihu.com/question/24627666">https://www.zhihu.com/question/24627666</a></p>
<h3><span id="5-linear-svm-和-lr-有什么异同">5、Linear SVM 和 LR 有什么异同？</span></h3><h4><span id="svm和lr相同点">SVM和LR相同点：</span></h4><ul>
<li>SVM和LR都属于机器学习的监督学习中的<strong>判别式模型</strong>（判别式模型对$p(y|x)$进行建模或直接基于x预测y，生成模型：$p(x|y)$和$p(y)$进行建模,预测后验概率）。</li>
<li>SVM和LR都是线性二分类模型，<strong>分类边界为一个超平面</strong>。</li>
<li>线性SVM和对数几率回归都可以基于表示定理和<strong>核技巧处理非线性可分问题</strong>。</li>
<li><strong>SVM的基本型和对数几率函数都属于参数模型。SVM的对偶性和核化对数几率回归都属于非参数模型</strong>。</li>
<li>SVM和LR优化目标都表示成：经验风险+结构风险（正则项）的形式；均是0，1损失的替代函数。风险结构都是L2正则化。</li>
<li><strong>SVM和LR都是凸优化问题，都能收敛到全局最优解。</strong></li>
<li>SVM和对数几率函数的优化目标相似，性能相当。</li>
<li><strong>SVM多分类：多分类SVM；LR多分类：Softmax回归。</strong></li>
</ul>
<h3><span id="svm和lr的区别"><strong><font color="red"> SVM和LR的区别：</font></strong></span></h3><blockquote>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>SVM</th>
<th>LR</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>思想</strong></td>
<td><strong>SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面</strong>。</td>
<td><strong>逻辑回归</strong>是使用线性回归模型的预测值逼近分类任务真实标记的对数几率。</td>
</tr>
<tr>
<td><strong>输出</strong></td>
<td><strong>非概率方法</strong>；</td>
<td><strong>概率方法</strong>；需要对进行假设，具有概率意义。</td>
</tr>
<tr>
<td><strong>经验损失函数</strong></td>
<td><strong>合页损失函数</strong>；有一段平的零区域、使得SVM的对偶性有稀疏性。</td>
<td><strong>交叉熵损失函数</strong></td>
</tr>
<tr>
<td><strong>训练样本</strong></td>
<td>支持向量（少数样本），SVM的参数和假设函数只和支持向量有关。</td>
<td>全样本</td>
</tr>
<tr>
<td><strong>优化方法</strong></td>
<td>次梯度下降和坐标梯度下降 【<strong>SMO算法</strong>】</td>
<td><strong>梯度下降</strong></td>
</tr>
<tr>
<td>多分类</td>
<td><strong>多分类SVM</strong></td>
<td><strong>Softmax回归</strong></td>
</tr>
<tr>
<td><strong>敏感程度</strong></td>
<td>SVM考虑分类边界线附近的样本（决定分类超平面的样本）。在支持向量外添加或减少任何样本点对分类决策面没有任何影响；</td>
<td>LR受所有数据点的影响。直接依赖数据分布，每个样本点都会影响决策面的结果。如果训练数据不同类别严重不平衡。</td>
</tr>
</tbody>
</table>
</div>
<p><a href="https://www.zhihu.com/question/26768865">https://www.zhihu.com/question/26768865</a></p>
<h3><span id="6-支持向量机svm是否适合大规模数据速度">6、支持向量机(SVM)是否适合大规模数据？【速度】</span></h3><p><a href="https://www.zhihu.com/question/19591450">https://www.zhihu.com/question/19591450</a></p>
<h3><span id="7-svm和逻辑斯特回归对同一样本a进行训练如果某类中增加一些数据点那么原来的决策边界分别会怎么变化">7、SVM和逻辑斯特回归对同一样本A进行训练，如果某类中增加一些数据点，那么原来的决策边界分别会怎么变化？</span></h3><p><a href="https://www.zhihu.com/question/30123068">https://www.zhihu.com/question/30123068</a></p>
<h3><span id="8-各种机器学习的应用场景分别是什么例如k近邻贝叶斯决策树svm逻辑斯蒂回归和最大熵模型">8、各种机器学习的应用场景分别是什么？例如，k近邻,贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。</span></h3><p><a href="https://www.zhihu.com/question/26726794">https://www.zhihu.com/question/26726794</a></p>
<h3><span id="9-svm与感知器的联系和优缺点比较">==9、SVM与感知器的联系和优缺点比较==</span></h3><p><strong>感知机用误分类样本点的几何距离之和</strong>来表示模型的损失函数，用梯度下降算法优化，直至没有误分类点。</p>
<script type="math/tex; mode=display">
L(w, b)=-\sum_{x^{(i)} \in M} y^{(i)}\left(w^{T} x^{(i)}+b\right)</script><h4><span id="感知机与svm区别">==感知机与SVM区别：==</span></h4><p><strong>SVM可以视为对感知器的二阶改进</strong>：第一阶改进是加入了 <img src="https://www.zhihu.com/equation?tex=%5Cgamma" alt="[公式]"> 获得hinge loss，从而具备了产生大间隔的潜质；第二阶改进是加入了权向量的L2正则化项，从而避免产生无意义的大函数间隔，而是产生大的几何间隔。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>感知机</th>
<th>SVM</th>
</tr>
</thead>
<tbody>
<tr>
<td>思想</td>
<td>分离超平面基于误分类的损失函数<img src="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5En+max%280%2C+-y_i%28w%5ETx_i%2Bb%29%29%5C%5C" alt="[公式]"></td>
<td><img src="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5En+max%280%2C+1-y_i%28w%5ETx_i%2Bb%29%29+%2B+%5Calpha+%7C%7Cw%7C%7C_2%5E2+%5C%5C" alt="[公式]" style="zoom:150%;"></td>
</tr>
<tr>
<td>超平面</td>
<td>因采用的初值不同而得到不同的超平面</td>
<td>让离划分超平面最近的样本到划分超平面距离尽可能远</td>
</tr>
<tr>
<td>关键样本</td>
<td>每步的分错样本</td>
<td><strong>支持向量</strong></td>
</tr>
<tr>
<td>非线性问题</td>
<td>无</td>
<td>核化</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>支持向量机</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（9）决策树</title>
    <url>/posts/3AGJJRV/</url>
    <content><![CDATA[<h2><span id="机器学习决策树上id3-c45-cart">【机器学习】决策树（上）——ID3、C4.5、CART</span></h2><p><strong>决策树</strong>是一个非常常见并且优秀的机器学习算法，它易于理解、可解释性强，其可作为分类算法，也可用于回归模型。本文将分三篇介绍决策树，第一篇介绍基本树（包括 <strong>ID3、C4.5、CART</strong>），第二篇介绍 <strong>Random Forest、Adaboost、GBDT</strong>，第三篇介绍 <strong>Xgboost</strong> 和 <strong>LightGBM</strong>。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>ID3（==分类==）</th>
<th>C4.5（==分类==）</th>
<th>CART（==分类和回归==）</th>
</tr>
</thead>
<tbody>
<tr>
<td>思想</td>
<td>奥卡姆剃刀：越是小型的决策树越优于大的决策树;ID3 算法的核心思想就是以<strong>信息增益</strong>来度量特征选择，选择信息增益最大的特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间。</td>
<td>C4.5 算法最大的特点是<strong>克服了 ID3 对特征数目的偏重</strong>这一缺点，引入<strong>信息增益率</strong>来作为分类标准。</td>
<td>CART 算法的二分法可以<strong>简化决策树的规模</strong>，提高生成决策树的效率。CART 包含的基本过程有<strong>分裂</strong>，<strong>剪枝</strong>和<strong>树选择</strong>。</td>
</tr>
<tr>
<td><strong>划分标准</strong></td>
<td><strong>信息增益</strong>  =  类别熵 - 特征类别熵                                <strong>类别熵</strong>：$H(D)=-\sum_{k=1}^{K} \frac{\left</td>
<td>C_{k}\right</td>
<td>}{</td>
<td>D</td>
<td>} \log _{2} \frac{\left</td>
<td>C_{k}\right</td>
<td>}{</td>
<td>D</td>
<td>}$                 <strong>特征类别熵</strong>：$H(D \mid A)=\sum_{i=1}^{n} \frac{\left</td>
<td>D_{i}\right</td>
<td>}{</td>
<td>D</td>
<td>} H\left(D_{i}\right)$</td>
<td>先从候选划分特征中找到信息增益高于平均值的特征，再从中选择<strong>增益率</strong>最高的。</td>
<td><strong>Gini 系数</strong>作为变量的<strong>不纯度量</strong>，<strong>减少了大量的对数运算</strong>；$G i n i(D)=\sum_{k=1}^{K} \frac{\left</td>
<td>C_{k}\right</td>
<td>}{</td>
<td>D</td>
<td>}\left(1-\frac{\left</td>
<td>C_{k}\right</td>
<td>}{</td>
<td>D</td>
<td>}\right)$</td>
</tr>
<tr>
<td>剪枝策略</td>
<td><strong>无</strong></td>
<td><strong>悲观剪枝策略</strong></td>
<td>基于<strong>代价复杂度剪枝</strong></td>
</tr>
<tr>
<td>数据差异</td>
<td><strong>离散</strong>数据且<strong>缺失值</strong>敏感</td>
<td><strong>离散</strong>、<strong>连续特征离散化</strong>；【排序+离散化】</td>
<td><strong>连续型、离散型</strong></td>
</tr>
<tr>
<td><strong>连续值处理</strong></td>
<td>无</td>
<td><strong>排序</strong>并取相邻两样本值的<strong>平均数</strong>。</td>
<td><strong>排序</strong>并取相邻两样本值的<strong>平均数</strong>。<strong>CART 分类树</strong>【<strong>基尼系数</strong>】。<strong>回归树</strong>【<strong>和方差度量</strong>】。</td>
</tr>
<tr>
<td>缺失值处理</td>
<td><strong>无</strong></td>
<td>1、有缺失值特征，用没有缺失的样本子集所占比重来折算；2、将样本同时划分到所有子节点</td>
<td><strong>代理测试</strong>来估计缺失值</td>
</tr>
<tr>
<td>类别不平衡</td>
<td><strong>无</strong></td>
<td><strong>无</strong></td>
<td><strong>先验机制</strong>：其作用相当于对数据自动重加权，对类别进行均衡。</td>
</tr>
<tr>
<td><strong>==缺点==</strong></td>
<td>1、ID3 没有剪枝策略，容易过拟合；2、信息增益准则对可取值<strong>数目较多的特征有所偏好</strong>，类似“编号”的特征其信息增益接近于 1； 3、只能用于处理离散分布的特征； 没有考虑缺失值。</td>
<td>1、<strong>多叉树</strong>。2、<strong>只能用于分类</strong>。3、熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>。4、驻留于内存的数据集。</td>
<td>熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>。</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><strong>划分标准的差异：</strong>ID3 使用信息增益偏向特征值多的特征，C4.5 使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART 使用基尼指数克服 C4.5 需要求 log 的巨大计算量，偏向于特征值较多的特征。</li>
<li><strong>使用场景的差异：</strong>ID3 和 C4.5 都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5 是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li>
<li><strong>样本数据的差异：</strong>ID3 只能处理离散数据且缺失值敏感，C4.5 和 CART 可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议 C4.5、大样本建议 CART。C4.5 处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART 本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li>
<li><strong>样本特征的差异：</strong>ID3 和 C4.5 层级之间只使用一次特征，==CART 可多次重复使用特征==；</li>
<li><strong>剪枝策略的差异：</strong>ID3 没有剪枝策略，C4.5 是通过<strong>悲观剪枝策略</strong>来修正树的准确性，而 CART 是通过<strong>代价复杂度</strong>剪枝。</li>
</ul>
<h2><span id="1-id3删特征">1. ID3【删特征】</span></h2><p>ID3 算法是建立在奥卡姆剃刀[<strong>“切勿浪费较多东西去做，用较少的东西，同样可以做好的事情”</strong>]（用较少的东西，同样可以做好事情）的基础上：越是小型的决策树越优于大的决策树。</p>
<h3><span id="11-思想">1.1 思想</span></h3><p>从信息论的知识中我们知道：信息熵越大，从而样本纯度越低，。ID3 算法的核心思想就是以<strong>信息增益</strong>来度量特征选择，选择信息增益最大的特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间（C4.5 也是贪婪搜索）。 其大致步骤为：</p>
<ol>
<li>初始化特征集合和数据集合；</li>
<li>计算数据集合信息熵和所有特征的条件熵，选择信息增益最大的特征作为当前决策节点；</li>
<li>更新数据集合和特征集合（删除上一步使用的特征，并按照特征值来划分不同分支的数据集合）；</li>
<li>重复 2，3 两步，若子集值包含单一特征，则为分支叶子节点。</li>
</ol>
<h3><span id="12-划分标准">1.2 划分标准</span></h3><p>ID3 使用的分类标准是信息增益，它表示得知特征 A 的信息而使得样本集合不确定性减少的程度。</p>
<p>数据集的<strong>信息熵</strong>：</p>
<p>$H(D)=-\sum_{k=1}^{K} \frac{\left|C_{k}\right|}{|D|} \log _{2} \frac{\left|C_{k}\right|}{|D|}$</p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=C_k" alt="[公式]"> 表示集合 D 中属于第 k 类样本的样本子集。针对某个特征 A，对于数据集 D 的条件熵 $H(D \mid A)$为：</p>
<p>$\begin{aligned} H(D \mid A) &amp;=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} H\left(D_{i}\right) \\ &amp;=-\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|}\left(\sum_{k=1}^{K} \frac{\left|D_{i k}\right|}{\left|D_{i}\right|} \log _{2} \frac{\left|D_{i k}\right|}{\left|D_{i}\right|}\right) \end{aligned}$</p>
<p><strong>信息增益</strong> = 信息熵 - 条件熵。信息增益越大表示使用特征 A 来划分所获得的“纯度提升越大”。</p>
<p><img src="https://www.zhihu.com/equation?tex=Gain%28D%2CA%29%3DH%28D%29-H%28D%7CA%29++%5C%5C" alt="[公式]"></p>
<p>信息增益越大表示使用特征 A 来划分所获得的“纯度提升越大”。</p>
<h3><span id="13-缺点没有剪枝-特征偏好-缺失值">1.3 缺点【没有剪枝、特征偏好、缺失值】</span></h3><ul>
<li>ID3 没有剪枝策略，容易过拟合；</li>
<li>信息增益准则==对可取值数目较多的特征==有所偏好，类似“编号”的特征其信息增益接近于 1；</li>
<li>只能用于处理离散分布的特征；</li>
<li>没有考虑缺失值。</li>
</ul>
<h2><span id="2-c45">2. C4.5</span></h2><p>C4.5 算法最大的特点是克服了 ID3 对==特征数目的偏重==这一缺点，引入信息增益率来作为分类标准。</p>
<p>C4.5 相对于 ID3 的缺点对应有以下改进方式： </p>
<ul>
<li>引入<strong>悲观剪枝策略进行后剪枝</strong>； </li>
<li>引入<strong>信息增益率</strong>作为划分标准； </li>
<li><strong>将连续特征离散化</strong>，假设 n 个样本的连续特征 A 有 m 个取值，C4.5 将其排序并取相邻两样本值的平均数共 m-1 个划分点，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点； </li>
<li>对于<strong>缺失值的处理</strong>可以分为两个子问题：</li>
<li>问题一：在特征值缺失的情况下进行划分特征的选择？（即如何计算特征的信息增益率）<ul>
<li>C4.5 的做法是：对于具有缺失值特征，用没有缺失的样本子集所占比重来折算；</li>
</ul>
</li>
<li>问题二：选定该划分特征，对于缺失该特征值的样本如何处理？（即到底把这个样本划分到哪个结点里） <ul>
<li>C4.5 的做法是：将样本同时划分到所有子节点，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</li>
</ul>
</li>
</ul>
<h3><span id="22-划分标准">2.2 划分标准</span></h3><p>利用信息增益率可以克服信息增益的缺点，其公式为</p>
<p>$\begin{aligned} \operatorname{Gain}_{\text {ratio }}(D, A) &amp;=\frac{\operatorname{Gain}(D, A)}{H_{A}(D)}     \\ H_{A}(D)=-\sum_{i=1}^{n}   \frac{\left|D_{i}\right|}{|D|} \log _{2} \frac{\left|D_{i}\right|}{|D|} \end{aligned}$</p>
<p>信息增益率对可取值较少的特征有所偏好（分母越小，整体越大），因此 C4.5 并不是直接用增益率最大的特征进行划分，而是使用一个<strong>启发式方法</strong>：先从候选划分特征中找到信息增益高于平均值的特征，再从中选择增益率最高的。</p>
<h3><span id="23-剪枝策略">2.3 剪枝策略</span></h3><p>为什么要剪枝：<strong>过拟合的树在泛化能力的表现非常差。</strong></p>
<p><strong>预剪枝和悲观剪枝</strong></p>
<h4><span id="231-预剪枝"><strong>2.3.1 预剪枝</strong></span></h4><p>在节点划分前来确定是否继续增长，及早停止增长的主要方法有：</p>
<ul>
<li>节点内数据样本低于<strong>某一阈值</strong>；</li>
<li>所有节点特征都已分裂；</li>
<li>节点划分前准确率比划分后准确率高。</li>
</ul>
<p>预剪枝不仅可以降低过拟合的风险而且还可以减少训练时间，但另一方面它是基于“贪心”策略，会带来欠拟合风险。</p>
<h4><span id="232-后剪枝悲观剪枝方法-httpgitlinuxnet2019-06-04-c45"><strong>2.3.2 后剪枝</strong>【悲观剪枝方法】  </span></h4><p>在已经生成的决策树上进行剪枝，从而得到简化版的剪枝决策树。</p>
<p>C4.5 采用的<strong>悲观剪枝方法</strong>，用递归的方式从低往上针对每一个非叶子节点，评估用一个最佳叶子节点去代替这课子树是否有益。如果剪枝后与剪枝前相比其错误率是保持或者下降，则这棵子树就可以被替换掉。<strong>C4.5 通过训练数据集上的错误分类数量来估算未知样本上的错误率</strong>。</p>
<p>后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但同时其训练时间会大的多。</p>
<h3><span id="24-缺点">2.4 缺点</span></h3><ul>
<li><strong>剪枝策略</strong>可以再优化；</li>
<li>C4.5 用的是<strong>多叉树</strong>，用二叉树效率更高；</li>
<li>C4.5 只能用于<strong>分类</strong>；</li>
<li>C4.5 使用的熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>；</li>
<li>C4.5 在构造树的过程中，<strong>对数值属性值需要按照其大小进行排序</strong>，从中选择一个分割点，所以只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时，程序无法运行。</li>
</ul>
<h2><span id="3-cart">3. CART</span></h2><p>ID3 和 C4.5 虽然在对训练样本集的学习中可以尽可能多地挖掘信息，但是其生成的决策树分支、规模都比较大，CART 算法的二分法可以简化决策树的规模，提高生成决策树的效率。</p>
<h3><span id="31-思想">3.1 思想</span></h3><p>CART 包含的基本过程有分裂，剪枝和树选择。 </p>
<ul>
<li><strong>分裂：</strong>分裂过程是一个二叉递归划分过程，其输入和预测特征既可以是连续型的也可以是离散型的，CART 没有停止准则，会一直生长下去； </li>
<li><strong>剪枝：</strong>采用<strong>代价复杂度剪枝</strong>，从最大树开始，每次选择训练数据熵对整体性能贡献最小的那个分裂节点作为下一个剪枝对象，直到只剩下根节点。CART 会产生一系列嵌套的剪枝树，需要从中选出一颗最优的决策树； </li>
<li><strong>树选择：</strong>用单独的测试集评估每棵剪枝树的预测性能（也可以用交叉验证）。</li>
</ul>
<p>CART 在 C4.5 的基础上进行了很多提升。 </p>
<ul>
<li>C4.5 为多叉树，运算速度慢，CART 为<strong>二叉树</strong>，运算速度快； </li>
<li>C4.5 只能分类，CART 既可以分类也可以<strong>回归</strong>； </li>
<li>CART 使用 ==<strong>Gini 系数作为变量的不纯度量</strong>，减少了<strong>大量的对数运算</strong>；== </li>
<li>CART 采用<strong>代理测试来估计缺失值</strong>，而 C4.5 以不同概率划分到不同节点中； </li>
<li>CART 采用<strong>“基于代价复杂度剪枝”方法进行剪枝，而 C4.5 采用悲观剪枝方法</strong>。</li>
</ul>
<h3><span id="32-划分标准">3.2 划分标准</span></h3><p><strong>熵模型拥有大量耗时的对数运算</strong>，基尼指数在简化模型的同时还保留了熵模型的优点。基尼指数代表了模型的不纯度，基尼系数越小，不纯度越低，特征越好。这和信息增益（率）正好相反。</p>
<p>$\begin{aligned} \operatorname{Gini}(D) &amp;=\sum_{k=1}^{K} \frac{\left|C_{k}\right|}{|D|}\left(1-\frac{\left|C_{k}\right|}{|D|}\right) =1- \sum_{k=1}^{K}\left(\frac{\left|C_{k}\right|}{|D|}\right)^{2}  &amp;\operatorname{Gini}(D \mid A) =\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} \operatorname{Gini}\left(D_{i}\right) \end{aligned}$</p>
<p>==<strong>基尼指数</strong>反映了从<strong>数据集中随机抽取两个样本，其类别标记不一致的概率</strong>==。因此基尼指数越小，则数据集纯度越高。基尼指数偏向于特征值较多的特征，类似信息增益。基尼指数可以用来度量任何不均匀分布，是介于 0~1 之间的数，0 是完全相等，1 是完全不相等，<strong>基尼指数可以理解为熵模型的一阶泰勒展开。</strong></p>
<blockquote>
<p>  <strong><em>基尼指数是信息熵中﹣logP在P=1处一阶泰勒展开后的结果！所以两者都可以用来度量数据集的纯度</em></strong></p>
</blockquote>
<h3><span id="33-缺失值处理">3.3 缺失值处理</span></h3><p>上文说到，模型对于缺失值的处理会分为两个子问题：</p>
<ul>
<li><strong>如何在特征值缺失的情况下进行划分特征的选择？</strong></li>
</ul>
<p>对于问题 1，<strong>CART 一开始严格要求分裂特征评估时只能使用在该特征上没有缺失值的那部分数据，在后续版本中，CART 算法使用了一种惩罚机制来抑制提升值，从而反映出缺失值的影响</strong>（例如，如果一个特征在节点的 20% 的记录是缺失的，那么这个特征就会减少 20% 或者其他数值）。</p>
<ul>
<li><strong>选定该划分特征，模型对于缺失该特征值的样本该进行怎样处理？</strong></li>
</ul>
<p>对于问题 2，CART 算法的机制是为树的每个节点都找到<strong>代理分裂器</strong>，无论在训练数据上得到的树是否有缺失值都会这样做。在代理分裂器中，特征的分值必须超过默认规则的性能才有资格作为代理（即代理就是<strong>代替缺失值特征作为划分特征的特征</strong>），<strong>当 CART 树中遇到缺失值时，这个实例划分到左边还是右边是决定于其排名最高的代理，如果这个代理的值也缺失了，那么就使用排名第二的代理</strong>，以此类推，如果所有代理值都缺失，那么默认规则就是把样本划分到较大的那个子节点。代理分裂器可以确保无缺失训练数据上得到的树可以用来处理包含确实值的新数据。</p>
<h3><span id="34-剪枝策略">3.4 剪枝策略</span></h3><p><strong>基于代价复杂度的剪枝</strong>:<a href="https://www.bilibili.com/read/cv11066239">https://www.bilibili.com/read/cv11066239</a></p>
<p>采用一种<strong>“基于代价复杂度的剪枝</strong>”方法进行<strong>后剪枝</strong>，这种方法会生成一系列树，每<strong>个树都是通过将前面的树的某个或某些子树替换成一个叶节点而得到的，这一系列树中的最后一棵树仅含一个用来预测类别的叶节点</strong>。然后用一种成本复杂度的度量准则来判断哪棵子树应该被一个预测类别值的叶节点所代替。<strong>这种方法需要使用一个单独的测试数据集来评估所有的树，根据它们在测试数据集熵的分类性能选出最佳的树</strong>。</p>
<blockquote>
<p>  从完整子树 $T0$ 开始， 通过在 $Ti$ 子树序列中裁剪真实误差最小【考虑叶子节点的个数】的子树，得到 $Ti+1$。 </p>
<p>  <img src="image-20220321203204744.png" alt="image-20220321203204744" style="zoom: 25%;">【剪枝之后的误差 - 剪枝前的误差 / 叶子节点数 - 1】</p>
<p>  每次误差增加率最小的节点，得到一系列的子树，从中选择效果最好的【独立剪枝数据集】和【K折交叉验证】</p>
</blockquote>
<p><img src="image-20220320215056933.png" alt="image-20220320215056933" style="zoom:50%;"></p>
<p>我们来看具体看一下代价复杂度剪枝算法：</p>
<p>首先我们将最大树称为 <img src="https://www.zhihu.com/equation?tex=T_0" alt="[公式]"> ，我们希望减少树的大小来防止过拟合，但又担心去掉节点后预测误差会增大，所以我们定义了一个损失函数来达到这两个变量之间的平衡。损失函数定义如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=C_%5Calpha%28T%29%3DC%28T%29%2B%5Calpha%7CT%7C++%5C%5C" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=T" alt="[公式]"> 为任意子树， <img src="https://www.zhihu.com/equation?tex=C%28T%29" alt="[公式]"> 为预测误差， <img src="https://www.zhihu.com/equation?tex=%7CT%7C" alt="[公式]"> 为子树 <img src="https://www.zhihu.com/equation?tex=T" alt="[公式]"> 的叶子节点个数， <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> 是参数， <img src="https://www.zhihu.com/equation?tex=C%28T%29" alt="[公式]"> 衡量训练数据的拟合程度， <img src="https://www.zhihu.com/equation?tex=%7CT%7C" alt="[公式]"> 衡量树的复杂度， <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> <strong>权衡拟合程度与树的复杂度</strong>。</p>
<h3><span id="35-类别不平衡">3.5 类别不平衡</span></h3><p>CART 的一大优势在于：无论训练数据集有多失衡，它都可以将其子冻消除不需要建模人员采取其他操作。</p>
<p>CART 使用了一种先验机制，其作用相当于对类别进行加权。这种先验机制嵌入于 CART 算法判断分裂优劣的运算里，在 CART 默认的分类模式中，总是要计算每个节点关于根节点的类别频率的比值，这就相当于对数据自动重加权，对类别进行均衡。</p>
<p>对于一个二分类问题，节点 node 被分成类别 1 当且仅当：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7BN_1%28node%29%7D%7BN_1%28root%29%7D+%3E+%5Cfrac%7BN_0%28node%29%7D%7BN_0%28root%29%7D++%5C%5C" alt="[公式]"></p>
<p>比如二分类，根节点属于 1 类和 0 类的分别有 20 和 80 个。在子节点上有 30 个样本，其中属于 1 类和 0 类的分别是 10 和 20 个。如果 10/20&gt;20/80，该节点就属于 1 类。</p>
<p>通过这种计算方式就无需管理数据真实的类别分布。假设有 K 个目标类别，就可以确保根节点中每个类别的概率都是 1/K。这种默认的模式被称为“先验相等”。</p>
<p>先验设置和加权不同之处在于先验不影响每个节点中的各类别样本的数量或者份额。先验影响的是每个节点的类别赋值和树生长过程中分裂的选择。</p>
<h3><span id="36-连续值处理">3.6 连续值处理</span></h3><h4><span id="361-分类树">3.6.1 分类树</span></h4><ul>
<li><p><strong><font color="red">如果特征值是连续值：CART的处理思想与C4.5是相同的，即将连续特征值离散化。唯一不同的地方是度量的标准不一样，</font></strong> <strong>CART采用基尼指数，而C4.5采用信息增益比</strong>。</p>
</li>
<li><p>如果当前节点为连续属性，<strong>CART树中该属性（剩余的属性值）后面还可以参与子节点的产生选择过程</strong>。</p>
</li>
</ul>
<h3><span id="37-回归树">3.7 回归树</span></h3><p><strong>CART（Classification and Regression Tree，分类回归树），从名字就可以看出其不仅可以用于分类，也可以应用于回归</strong>。其回归树的建立算法上与分类树部分相似，这里简单介绍下不同之处。</p>
<h5><span id="连续值处理rss残差平方和"><strong>连续值处理</strong>：==RSS<strong>残差平方和</strong>==</span></h5><p>对于连续值的处理，<strong>CART 分类树采用基尼系数的大小来度量特征的各个划分点</strong>。<strong>在回归模型中，我们使用常见的和方差度量方式</strong>，对于任意划分特征 A，对应的任意划分点 s 两边划分成的数据集 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> ，求出使 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> 各自<strong>集合的均方差最小</strong>，同时 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> 的均方差之和最小所对应的特征和特征值划分点。表达式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=+%5Cmin%5Climits_%7Ba%2Cs%7D%5CBigg%5B%5Cmin%5Climits_%7Bc_1%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_1%7D%28y_i+-+c_1%29%5E2+%2B+%5Cmin%5Climits_%7Bc_2%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_2%7D%28y_i+-+c_2%29%5E2%5CBigg%5D+%5C%5C" alt="[公式]"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=c_1" alt="[公式]"> 为 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 数据集的样本输出均值， <img src="https://www.zhihu.com/equation?tex=c_2" alt="[公式]"> 为 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> 数据集的样本输出均值。</p>
<h5><span id="预测方式"><strong>预测方式</strong></span></h5><p>对于决策树建立后做预测的方式，上面讲到了 CART 分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。而回归树输出不是类别，它采用的是用最终叶子的均值或者中位数来预测输出结果。</p>
<h3><span id="37-cart分类树建模时预测变量中存在连续和离散时会自动分别进行处理吗">3.7 CART分类树建模时，预测变量中存在连续和离散时，会自动分别进行处理吗？</span></h3><blockquote>
<p>  在使用sklearn的决策树CART建模时，预测变量中存在连续和离散时，会自动分别进行处理吗？ - 月来客栈的回答 - 知乎 <a href="https://www.zhihu.com/question/472579561/answer/2002434993">https://www.zhihu.com/question/472579561/answer/2002434993</a></p>
</blockquote>
<p><strong>对于这种连续型的特征变量，Sklearn中的具体做法（包括ID3、CART、随机森林等）是先对连续型特征变量进行排序处理</strong>，<strong><font color="red"> 然后取所有连续两个值的均值来离散化整个连续型特征变量。</font></strong></p>
<p>假设现在某数据集其中一个特征维度为：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5B0.5%2C+0.2%2C+0.8%2C+0.9%2C+1.2%2C+2.1%2C+3.2%2C+4.5%5D+%5C%5C" alt="[公式]"></p>
<p>则首先需要对其进行排序处理，排序后的结果为：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5B0.2%2C+0.5%2C+0.8%2C+0.9%2C+1.2%2C+2.1%2C+3.2%2C+4.5%5D+%5C%5C" alt="[公式]"></p>
<p>接着再计算所有连续两个值之间的平均值：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5B0.35%2C+0.65%2C+0.85%2C+1.05%2C+1.65%2C+2.65%2C+3.85%5D+%5C%5C" alt="[公式]"></p>
<p>这样，便得到了该特征离散化后的结果。最后在构造<a href="https://www.zhihu.com/search?q=决策树&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A&quot;2002434993&quot;}">决策树</a>时，只需要使用式最后离散化后的特征进行划分指标的计算即可。同时，值得一说的地方是<strong>目前Sklearn在实际处理时，会把所有的特征均看作连续型变量进行处理</strong>。</p>
<p>下图所示为iris数据集根据sklearn中CART算法所建模的决策树的可视化结果：</p>
<p><img src="https://picx.zhimg.com/v2-9081bc3cd5f2ec069212b79d5c5ff7d3_b.jpg" alt="img" style="zoom:50%;"></p>
<p>从图中可以看到，<code>petal width</code>这个特征在前两次分类时的分割点分别为0.8和1.75。下面先来看看原始特征<code>petal width</code>的取值情况：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">1.</span>  <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">1.4</span> <span class="number">2.5</span> <span class="number">1.3</span> <span class="number">2.1</span> <span class="number">1.5</span> <span class="number">0.2</span> <span class="number">2.</span>  <span class="number">1.</span>  <span class="number">0.2</span> <span class="number">0.3</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">0.2</span> <span class="number">0.5</span> <span class="number">1.3</span> <span class="number">0.2</span> <span class="number">1.2</span> <span class="number">2.2</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">2.</span>  <span class="number">0.2</span> <span class="number">1.8</span> <span class="number">1.9</span> <span class="number">1.</span>  <span class="number">1.5</span> <span class="number">2.3</span> <span class="number">1.3</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">1.9</span> <span class="number">0.2</span> <span class="number">0.2</span> <span class="number">1.1</span> <span class="number">1.7</span> <span class="number">0.2</span> <span class="number">2.4</span> <span class="number">0.2</span> <span class="number">0.6</span> <span class="number">1.8</span> <span class="number">1.1</span> <span class="number">2.3</span> <span class="number">1.6</span> <span class="number">1.4</span> <span class="number">2.3</span> <span class="number">1.3</span> <span class="number">0.2</span> <span class="number">0.1</span> <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">0.3</span> <span class="number">0.2</span> <span class="number">1.5</span> <span class="number">2.4</span> <span class="number">0.3</span> <span class="number">2.1</span> <span class="number">2.5</span> <span class="number">0.2</span> <span class="number">1.4</span> <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">1.4</span> <span class="number">2.3</span> <span class="number">0.2</span> <span class="number">2.1</span> <span class="number">1.5</span> <span class="number">2.</span>  <span class="number">1.</span>  <span class="number">1.4</span> <span class="number">1.4</span> <span class="number">0.3</span> <span class="number">1.3</span> <span class="number">1.2</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">1.8</span> <span class="number">2.1</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">2.5</span> <span class="number">1.6</span> <span class="number">0.1</span> <span class="number">2.4</span> <span class="number">0.2</span> <span class="number">1.5</span> <span class="number">1.9</span> <span class="number">1.8</span> <span class="number">1.3</span> <span class="number">1.8</span> <span class="number">1.3</span> <span class="number">1.3</span> <span class="number">2.</span>  <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">1.7</span> <span class="number">0.2</span> <span class="number">1.2</span> <span class="number">2.1</span>]</span><br></pre></td></tr></table></figure>
<p>可以发现上面并没有0.8和1.75这两个取值。接着按上面的方法先排序，再取相邻两个值的平均作为离散化的特征，其结果为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">0.1</span>, <span class="number">0.15000000000000002</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, </span><br><span class="line"><span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.25</span>, <span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.35</span>, <span class="number">0.4</span>, <span class="number">0.4</span>,</span><br><span class="line"> <span class="number">0.45</span>, <span class="number">0.55</span>, <span class="number">0.8</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.05</span>, <span class="number">1.1</span>, <span class="number">1.15</span>, <span class="number">1.2</span>, <span class="number">1.2</span>, <span class="number">1.25</span>, <span class="number">1.3</span>,</span><br><span class="line"> <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.35</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.45</span>, <span class="number">1.5</span>, </span><br><span class="line"><span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.55</span>, <span class="number">1.6</span>, <span class="number">1.65</span>, <span class="number">1.7</span>, <span class="number">1.75</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, </span><br><span class="line"><span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.85</span>, <span class="number">1.9</span>, <span class="number">1.9</span>, <span class="number">1.95</span>, <span class="number">2.0</span>, <span class="number">2.0</span>, <span class="number">2.0</span>, <span class="number">2.05</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, </span><br><span class="line"><span class="number">2.1500000000000004</span>, <span class="number">2.25</span>, <span class="number">2.3</span>, <span class="number">2.3</span>, <span class="number">2.3</span>, <span class="number">2.3499999999999996</span>, <span class="number">2.4</span>, <span class="number">2.4</span>, <span class="number">2.45</span>, <span class="number">2.5</span>, <span class="number">2.5</span>]</span><br></pre></td></tr></table></figure>
<h2><span id="4-总结">4. 总结</span></h2><p>最后通过总结的方式对比下 ID3、C4.5 和 CART 三者之间的差异。</p>
<p>除了之前列出来的划分标准、剪枝策略、连续值确实值处理方式等之外，我再介绍一些其他差异：</p>
<ul>
<li><strong>划分标准的差异：</strong>ID3 使用信息增益偏向特征值多的特征，C4.5 使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART 使用基尼指数克服 C4.5 需要求 log 的巨大计算量，偏向于特征值较多的特征。</li>
<li><strong>使用场景的差异：</strong>ID3 和 C4.5 都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5 是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li>
<li><strong>样本数据的差异：</strong>ID3 只能处理离散数据且缺失值敏感，C4.5 和 CART 可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议 C4.5、大样本建议 CART。C4.5 处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART 本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li>
<li><strong>样本特征的差异：</strong>ID3 和 C4.5 层级之间只使用一次特征，CART 可多次重复使用特征（连续型）；</li>
<li><strong>剪枝策略的差异：</strong>ID3 没有剪枝策略，C4.5 是通过悲观剪枝策略来修正树的准确性，而 CART 是通过代价复杂度剪枝。</li>
</ul>
<h2><span id="一-决策树">一、决策树</span></h2><h3><span id="11-介绍决策树id2-c45-cart-3种决策树及其区别和适应场景">1.1 介绍决策树ID2、C4.5、CART, 3种决策树及其区别和适应场景？</span></h3><h3><span id="12-决策树处理连续值的方法">1.2 决策树处理连续值的方法?</span></h3><p><strong>ID3 只能离散型</strong>。<strong>C4.5 将连续特征离散化</strong>，假设 n 个样本的连续特征 A 有 m 个取值，<strong>C4.5 将其排序并取相邻两样本值的平均数共 m-1 个划分点</strong>，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点； </p>
<p><strong>CART分类树：离散化+基尼指数，</strong></p>
<p><strong>CART回归树：均方差之和度量方式</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=+%5Cmin%5Climits_%7Ba%2Cs%7D%5CBigg%5B%5Cmin%5Climits_%7Bc_1%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_1%7D%28y_i+-+c_1%29%5E2+%2B+%5Cmin%5Climits_%7Bc_2%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_2%7D%28y_i+-+c_2%29%5E2%5CBigg%5D+%5C%5C" alt="[公式]"></p>
<h3><span id="13-决策树处理缺失值的方式">1.3 决策树处理缺失值的方式？</span></h3><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/84519568">ID3、c4.5、cart、rf到底是如何处理缺失值的？</a></p>
</blockquote>
<h4><span id="131-在特征值缺失的情况下进行划分特征的选择">1.3.1 <strong>在特征值缺失的情况下进行划分特征的选择？</strong></span></h4><p><strong>ID3</strong> 没有缺失值处理；</p>
<p><strong>C4.5</strong>：对于具有缺失值特征，用没有缺失的<strong>样本子集所占比重来折算</strong>；</p>
<p><strong>CART</strong>：<strong>初期</strong>：分裂特征评估时只能使用在该特征上没有缺失值的那部分数据<strong>；后续</strong>：CART 算法使用了一种惩罚机制来抑制提升值，从而反映出缺失值的影响。</p>
<h4><span id="132-选定该划分特征对于缺失该特征值的样本如何处理">1.3.2 <strong>选定该划分特征，对于缺失该特征值的样本如何处理？</strong></span></h4><p><strong>ID3</strong> 没有缺失值处理；</p>
<p><strong>C4.5</strong>：<strong>将样本同时划分到所有子节点</strong>，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</p>
<p>==<strong>CART</strong>：==sklearn中的cart的实现是没有对缺失值做任何处理的，也就是说sklearn的cart无法处理存在缺失值的特征。</p>
<h3><span id="14-决策树如何剪枝">1.4 决策树如何剪枝？</span></h3><ul>
<li><strong>预剪枝</strong>：在树的生成过程中，提前停止生长。简单，适合解决大规模问题。<ul>
<li>深度</li>
<li>节点样本数</li>
<li>对测试集准确率的提升过小</li>
</ul>
</li>
<li><strong>后剪枝</strong>：生成一颗完全生长的二叉树，从低向上剪枝，将子树删除用叶子节点代替。【类别：多数投票】常见的剪枝方法：错误率降低剪枝（REP）、<strong>悲观剪枝（PEP）、代价复杂度剪枝（CCP）</strong>、最小误差剪枝（MEP）等。</li>
</ul>
<p><strong>代价复杂度剪枝（CCP）【CART树】</strong></p>
<p>从完整子树 $T0$ 开始， 通过在 $Ti$ 子树序列中裁剪真实误差最小【考虑叶子节点的个数】的子树，得到 $Ti+1$。 </p>
<p><img src="image-20220321203204744.png" alt="image-20220321203204744" style="zoom: 25%;">【剪枝之后的误差 - 剪枝前的误差 / 叶子节点数 - 1】</p>
<p>每次误差增加率最小的节点，得到一系列的子树，从中选择效果最好的【独立剪枝数据集】和【K折交叉验证】</p>
<h3><span id="15-决策树特征选择特征重要性判断">1.5 决策树特征选择？特征重要性判断？</span></h3><p><strong>XGBoost</strong>：</p>
<ul>
<li><p>该特征在所有树中被用作分割样本的特征的总次数。</p>
</li>
<li><p>该特征在其出现过的所有树中产生的平均增益。</p>
</li>
<li><p>该特征在其出现过的所有树中的平均覆盖范围。</p>
<blockquote>
<p>  注意：覆盖范围这里指的是一个特征用作分割点后，其影响的样本数量，即有多少样本经过该特征分割到两个子节点。</p>
</blockquote>
</li>
</ul>
<h3><span id="16-svm-lr-决策树的对比">1.6 SVM、LR、决策树的对比？</span></h3><blockquote>
<p>  逻辑回归，决策树，支持向量机 选择方案: <a href="https://cloud.tencent.com/developer/article/1435642">https://cloud.tencent.com/developer/article/1435642</a></p>
<p>  广义线性模型？</p>
<p>  sigmod、softmax</p>
<p>  为什么逻辑回归的连续值也需要离散化？</p>
<p>  为什么逻辑回归要用交叉熵？</p>
<p>  交叉熵和KL散度（相对熵）和GAN的损失函数的区别？</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>线性回归</th>
<th>LR 逻辑回归</th>
<th>SVM</th>
<th>朴素贝叶斯</th>
<th>决策树</th>
</tr>
</thead>
<tbody>
<tr>
<td>场景</td>
<td>【回归问题】</td>
<td>逻辑回归 = 线性回归 + Sigmoid 函数（非线形）【分类问题】==【参数模型】==【统计方法】</td>
<td>【分类问题】【几何方法】【非参数模型】</td>
<td>【生成式模型】</td>
<td>【分类问题】【回归问题】【非参数模型】</td>
</tr>
<tr>
<td><strong>思想</strong></td>
<td></td>
<td><strong>思路：</strong>先拟合决策边界(不局限于线性，还可以是多项式)，再建立这个边界与分类的概率联系，从而得到了二分类情况下的概率。<strong>细节</strong>：通过<strong>非线性映射减小了离分类平面较远的点的权重</strong>，相对提升了与分类最相关的数据点的权重；</td>
<td><strong>思想</strong>：SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</td>
<td></td>
<td><strong>思想</strong>：用启发算法来度量特征选择，选择特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间。</td>
</tr>
<tr>
<td><strong>关键样本</strong></td>
<td></td>
<td><strong>所有样本</strong>（通过非线性映射，大大减小了离分类平面较远的点的权重）</td>
<td><strong>支持向量</strong>（超平面到距离最近的不同标记样本集合）</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>目标函数</strong></td>
<td></td>
<td>$y=\frac{1}{1+e^{-\left(w^{T} x+b\right)}}$ 【极大似然函数】</td>
<td><img src="image-20220322131856478.png" alt="image-20220322131856478" style="zoom:150%;"> <img src="https://pic2.zhimg.com/80/v2-0e87b3bf410cd798efd05a2837b83589_1440w.png" alt="img"></td>
<td></td>
<td>信息增益、信息增益率、Gini指数</td>
</tr>
<tr>
<td><strong>损失函数</strong></td>
<td></td>
<td><img src="https://pic3.zhimg.com/80/v2-ee1ddd22da5171fa44e079582cefe20a_1440w.png" alt="img" style="zoom:150%;"></td>
<td><strong><a href="https://www.zhihu.com/question/47746939">HingeLoss</a></strong>【合页损失函数】：<img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi%3D1%7D%5EN%5B1-y_i%28w%C2%B7x_i+%2B+b%29%5D_%2B+%2B+%5Clambda%7C%7Cw%7C%7C%5E2+%5C%5C+%5Bz%5D_%2B+%3D+%5Cbegin%7Bequation%7D+%5Cleft%5C%7B++++++++++++++%5Cbegin%7Barray%7D%7Blr%7D+++++++++++z%2C+z%3E0+%26++%5C%5C++++++++++++++0.z%5Cleq0+%26+++++++++++++++%5Cend%7Barray%7D++%5Cright.+%5Cend%7Bequation%7D+%5C%5C+" alt="[公式]" style="zoom:150%;"></td>
<td></td>
<td>信息增益、信息增益率、Gini指数【方差和】</td>
</tr>
<tr>
<td>决策面</td>
<td></td>
<td>线性可分</td>
<td>【核函数映射】从而使得样本数据线性可分</td>
<td></td>
<td>矩形【非线性】</td>
</tr>
<tr>
<td>连续值处理</td>
<td></td>
<td>==离散化？==</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>输出</strong></td>
<td></td>
<td>类别的概率</td>
<td>类别</td>
<td></td>
<td>类别、回归</td>
</tr>
<tr>
<td>过拟合</td>
<td></td>
<td><strong>正则化</strong> L1: <img src="image-20220316144906846.png" alt="image-20220316144906846" style="zoom:50%;"> L2: <img src="image-20220316145437180.png" alt="image-20220316145437180" style="zoom:50%;"></td>
<td>\</td>
<td></td>
<td>预剪枝和后剪枝</td>
</tr>
<tr>
<td>优势</td>
<td></td>
<td><strong>本质其实是为了模型参数服从某一分布</strong>；1、对观测样本的概率值输出 2、实现简单高效3、<strong>多重共线性的问题可以通过L2正则化来应对</strong>。 4、大量的工业界解决方案5、支持online learning</td>
<td>1、可以处理<strong>高维特征</strong> 2、使用<strong>核函数</strong>轻松应对非线的性特征空间 3、分类面不依赖于所有数据4、关重要的<strong>关键样本</strong></td>
<td></td>
<td>1、直观的决策过程 2、能够处理非线性特征 3、考虑了<strong>特征相关性</strong></td>
</tr>
<tr>
<td>劣势</td>
<td></td>
<td>1、特征空间太大时表现不太好 2、对于大量的分类变量无能为力 3、对于非线性特征需要做特征变换 4、依赖所有的样本数据</td>
<td>1、<strong>对于大量的观测样本，效率会很低</strong> 2、找到一个“合适”的核函数还是很tricky的</td>
<td></td>
<td>1、极易过拟合 2、无法输出score，只能给出直接的分类结果</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>  <strong><a href="https://blog.csdn.net/Alphonse_Huang/article/details/114278377">多重共线性问题</a></strong></p>
<p>  多重共线性问题就是指一个解释变量的变化引起另一个解释变量地变化。多重共<a href="https://so.csdn.net/so/search?q=线性&amp;spm=1001.2101.3001.7020">线性</a>是使用线性回归算法时经常要面对的一个问题。在其他算法中，例如决策树或者朴素贝叶斯，前者的建模过程时逐渐递进，每次都只有一个变量参与，这种机制含有抗多重共线性干扰的功能；后者假设变量之间是相互独立的。但对于回归算法来说，都要同时考虑多个预测因子，因此多重共线性不可避免。</p>
<ul>
<li>PCA等降维方法。因为在原始特征空间中变量之间相关性大，很容易想到通过降低维度的形式来去除这种共线性。</li>
<li>正则化。使用<strong>岭回归（L2</strong>）或者lasso回归（L1）或者elasticnet回归（L1+L2）</li>
<li><p>逐步回归法</p>
<p><strong><a href="https://blog.csdn.net/FrankieHello/article/details/94022594">机器学习中参数模型和非参数模型理解</a></strong></p>
<p>参数模型通常假设总体服从某个分布，这个分布可以由一些参数确定，如正态分布由均值和标准差确定，在此基础上构建的模型称为参数模型；非参数模型对于总体的分布不做任何假设或者说是数据分布假设自由，只知道其分布是存在的，所以就无法得到其分布的相关参数，只能通过非参数统计的方法进行推断。</p>
</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>决策树</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（8）【Nan】CRF</title>
    <url>/posts/1799EFH/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>机器学习</category>
        <category>概率图模型</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（8）【Nan】马尔可夫模型</title>
    <url>/posts/16VDGF1/</url>
    <content><![CDATA[<h2><span id="马尔可夫模型">马尔可夫模型</span></h2><blockquote>
<p>  如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？ - Scofield的回答 - 知乎 <a href="https://www.zhihu.com/question/35866596/answer/236886066">https://www.zhihu.com/question/35866596/answer/236886066</a></p>
</blockquote>
<h3><span id="一-概念">一、概念</span></h3><h4><span id="11-随机过程">1.1 随机过程</span></h4><p><strong>随机过程就是一些统计模型，利用这些统计模型可以对自然界的一些事物进行预测和处理</strong>，比如天气预报，比如股票，比如市场分析，比如人工智能。它的应用还真是多了去了。</p>
<h4><span id="12-马尔可夫链-markov-chain">1.2 马尔可夫链 （Markov Chain）</span></h4><blockquote>
<p>  马尔可夫链 （Markov Chain）是什么鬼 - 车卡门的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/26453269">https://zhuanlan.zhihu.com/p/26453269</a></p>
</blockquote>
<p>马尔可夫链就是这样一个任性的过程，它将来的状态分布只取决于现在，跟过去无关！实际上就是一个随机变量随时间按照Markov性进行变化的过程。</p>
<h4><span id="13-马尔可夫模型hidden-markov-models">1.3 马尔可夫模型（Hidden Markov Models）</span></h4><p>既是马尔可夫模型，就一定存在<a href="https://www.zhihu.com/search?q=马尔可夫链&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A&quot;64187492&quot;}">马尔可夫链</a>，该马尔可夫链服从马尔可夫性质：即无记忆性。也就是说，这一时刻的状态，受且只受前一时刻的影响，而不受更往前时刻的状态的影响。在这里我们仍然使用非常简单的天气模型来做说明。</p>
<p><img src="https://picx.zhimg.com/80/648a55725e67d718d97d6a475891d70b_1440w.png" alt="img" style="zoom:50%;"></p>
<p>在这个马尔可夫模型中，存在三个状态，Sunny， Rainy， Cloudy，同时图片上标的是各个状态间的转移概率（如果不明白什么是转移概率，那建议先去学习什么是马尔可夫再来看HMM）。</p>
<p><strong><font color="red"> 现在我们要说明什么是 HMM。既是隐形，说明这些状态是观测不到的，相应的，我们可以通过其他方式来『猜测』或是『推断』这些状态，这也是 HMM 需要解决的问题之一。</font></strong></p>
<blockquote>
<p>  举个例子，我女朋友现在在北京工作，而我还在法国读书。每天下班之后，她会根据天气情况有相应的活动：或是去商场购物，或是去公园散步，或是回家收拾房间。我们有时候会通电话，她会告诉我她这几天做了什么，而闲着没事的我呢，则要通过她的行为猜测这几天对应的天气最有可能是什么样子的。</p>
<p>  以上就是一个简单的 HMM，天气状况属于状态序列，而她的行为则属于观测序列。天气状况的转换是一个马尔可夫序列。而根据天气的不同，有相对应的概率产生不同的行为。在这里，为了简化，把天气情况简单归结为晴天和雨天两种情况。雨天，她选择去散步，购物，收拾的概率分别是0.1，0.4，0.5， 而如果是晴天，她选择去散步，购物，收拾的概率分别是0.6，0.3，0.1。而天气的转换情况如下：这一天下雨，则下一天依然下雨的概率是0.7，而转换成晴天的概率是0.3；这一天是晴天，则下一天依然是晴天的概率是0.6，而转换成雨天的概率是0.4. 同时还存在一个初始概率，也就是第一天下雨的概率是0.6， 晴天的概率是0.4.</p>
<p>  <img src="https://pic4.zhimg.com/80/792e033ff9b0418b3b6c9bbaef30fd83_1440w.png" alt="img" style="zoom:50%;"></p>
</blockquote>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>概率图模型</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-模型融合</title>
    <url>/posts/3ZEPE93/</url>
    <content><![CDATA[<h2><span id="融合机器学习模型一种提升预测能力的方法"></span></h2><p>没有哪个机器学习模型可以常胜，如何找到当前问题的最优解是一个永恒的问题。</p>
<p>幸运的是，<strong>结合/融合/整合 (integration/ combination/ fusion)多个机器学习模型往往可以提高整体的预测能力。</strong>这是一种非常有效的提升手段，在多分类器系统(multi-classifier system)和集成学习(ensemble learning)中，融合都是最重要的一个步骤。</p>
<p>一般来说，<strong>模型融合或多或少都能提高的最终的预测能力，且一般不会比最优子模型差</strong>。举个实用的例子，Kaggle比赛中常用的stacking方法就是模型融合，通过结合多个各有所长的子学习器，我们实现了更好的预测结果。基本的理论假设是：<strong>不同的子模型在不同的数据上有不同的表达能力，我们可以结合他们擅长的部分，得到一个在各个方面都很“准确”的模型</strong>。当然，最基本的假设是子模型的误差是互相独立的，这个一般是不现实的。但即使子模型间的误差有相关性，适当的结合方法依然可以各取其长，从而达到提升效果。</p>
<p>我们今天介绍几种简单、有效的模型结合方法。</p>
<span id="more"></span>
<h3><span id="1-案例分析"><strong>1. 案例分析</strong></span></h3><p>让我们给出一个简单的分析。假设我们有天气数据X和对应的标签y，现在希望实现一个可以预测明天天气的模型 <img src="https://www.zhihu.com/equation?tex=%5Cpsi" alt="[公式]"> 。但我们并不知道用什么算法效果最好，于是尝试了十种算法，包括</p>
<ul>
<li>算法1: 逻辑回归 - <img src="https://www.zhihu.com/equation?tex=C_%7B1%7D" alt="[公式]"></li>
<li>算法2：支持向量机（SVM）-  <img src="https://www.zhihu.com/equation?tex=C_%7B2%7D" alt="[公式]"> </li>
<li>…</li>
<li>算法10：随机森林 -  <img src="https://www.zhihu.com/equation?tex=C_%7B10%7D" alt="[公式]"> </li>
</ul>
<p>结果发现他们表现都一般，在验证集上的误分率比较高。我们现在期待找到一种方法，可以有效提高最终预测结果。</p>
<h3><span id="2-平均法投票法"><strong>2. 平均法/投票法</strong></span></h3><p>一种比较直白的方法就是对让10个算法模型同时对需要预测的数据进行预测，并对结果取平均数/众数。假设10个分类器对于测试数据 <img src="https://www.zhihu.com/equation?tex=X_%7Bt%7D" alt="[公式]"> 的预测结果是<img src="https://www.zhihu.com/equation?tex=%5BC_%7B1%7D%28X_t%29%2CC_%7B2%7D%28X_t%29%2C...%2CC_%7B10%7D%28X_t%29%5D%3D%5B0%2C1%2C1%2C1%2C1%2C1%2C0%2C1%2C1%2C0%5D" alt="[公式]"> ，那很显然少数服从多数，我们应该选择1作为 <img src="https://www.zhihu.com/equation?tex=X_%7Bt%7D" alt="[公式]"> 的预测结果。如果取平均值的话也可以那么会得到0.7，高于阈值0.5，因此是等价的。</p>
<p>但这个时候需要有几个注意的地方：</p>
<p><strong>首先，不同分类器的输出结果取值范围不同</strong>，不一定是[0,1]，而可以是无限定范围的值。举例，逻辑回归的输出范围是0-1（概率），而k-近邻的输出结果可以是大于0的任意实数，其他算法的输出范围可能是负数。<strong>因此整合多个分类器时，需要注意不同分类器的输出范围，并统一这个取值范围</strong>。</p>
<ul>
<li>比如可以先转化为如<strong>二分类结果</strong>，把输出的范围统一后再进行整合。但这种方法的问题在于我们丢失了很多信息，0.5和0.99都会被转化为1，但明显其可靠程度差别很大。</li>
<li>也可以转化为排序（ranking），再对不同的ranking进行求平均。</li>
<li>更加稳妥的方法是对每个分类器的输出结果做标准化，也就是调整到正态分布上去。之后就可以对多个调整后的结果进行整合。同理，用归一化也可以有类似的效果。</li>
</ul>
<p><strong>其次，就是整合稳定性的问题</strong>。采用平均法的另一个风险在于可能被极值所影响。正态分布的取值是 <img src="https://www.zhihu.com/equation?tex=%5B-%5Cinfty%2C%2B%5Cinfty%5D" alt="[公式]"> ，在少数情况下平均值会受到少数极值的影响。一个常见的解决方法是，用中位数（median)来代替平均数进行整合。</p>
<p><strong>同时，模型整合面临的另一个问题是子模型良莠不齐</strong>。如果10个模型中有1个表现非常差，那么会拖累最终的效果，适得其反。==因此，简单、粗暴的把所有子模型通过平均法整合起来效果往往一般。==</p>
<h3><span id="3-寻找优秀的子模型准而不同">3. 寻找优秀的子模型准而不同</span></h3><p>不难看出，一个较差的子模型会拖累整体的集成表现，那么这就涉及到另一个问题？什么样的子模型是优秀的。</p>
<p>一般来说，我们希望子模型：<strong>准而不同 -&gt; accurate but diversified</strong>。好的子模型应该首先是准确的，这样才会有所帮助。其次不同子模型间应该有差别，比如独立的误差，这样作为一个整体才能起到<strong>互补作用</strong>。</p>
<p>因此，如果想实现良好的结合效果，就必须对子模型进行筛选，去粗取精。在这里我们需要做出一点解释，我们今天说的融合方法和bagging还有boosting中的思路不大相同。==bagging和boosting中的子模型都是<strong>很简单的且基数庞大</strong>，而我们今天的模型融合是<strong>结合少量但较为复杂的模型</strong>。==</p>
<h3><span id="4-筛选方法赋予不同子模型不同的权重"><strong>4. 筛选方法：赋予不同子模型不同的权重</strong></span></h3><p>因此我们不能再简单的取平均了，而应该给优秀的子模型更大的权重。在这种前提下，一个比较直白的方法就是根据子<strong>模型的准确率给出一个参考权重</strong> <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> ，子模型越准确那么它的权重就更大，对于最终预测的影响就更强： <img src="https://www.zhihu.com/equation?tex=w_%7Bi%7D%3D%5Cfrac%7BAcc%28C_%7Bi%7D%29%7D%7B%5Csum_%7B1%7D%5E%7B10%7D%7BAcc%28C_%7Bj%7D%29%7D%7D" alt="[公式]"> 。简单取平均是这个方法的一个特例，即假设子模型准确率一致。</p>
<h3><span id="5-更进一步学习分类器权重"><strong>5. 更进一步：学习分类器权重</strong></span></h3><p>在4中提到的方法在一定程度上可以缓解问题，但效果有限。那么另一个思路是，我们是否可以学习每个分类器的权重呢？</p>
<p>答案是肯定，这也就是Stacking的核心思路。通过增加一层来学习子模型的权重。</p>
<p><img src="https://pic3.zhimg.com/v2-13396e65c2bcc1c270ca536310686d07_720w.jpg?source=d16d100b" alt="img"></p>
<p><strong>图片来源</strong>：<a href="https://www.quora.com/What-is-stacking-in-machine-learning">https://www.quora.com/What-is-stacking-in-machine-learning</a></p>
<p>更多有关于stacking的讨论可以参考我最近的文章：<a href="https://zhuanlan.zhihu.com/p/32896968">「Stacking」与「神经网络」</a>。简单来说，就是加一层逻辑回归或者SVM，把子模型的输出结果当做训练数据，来自动赋予不同子模型不同的权重。</p>
<p>==<strong>一般来看，这种方法只要使用得当，效果应该比简单取平均值、或者根据准确度计算权重的效果会更好。</strong>==</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-损失函数</title>
    <url>/posts/8Q5WCT/</url>
    <content><![CDATA[<p>机器学习中的监督学习本质上是给定一系列训练样本 $\left(x_i, y_i\right)$, 尝试学习 $x \rightarrow y$ 的映射关系, 使得给定一个 $x$ , 即便这个 $x$ 不在训练样本中, 也能够得到尽量接近真实 $y$ 的输出 $\hat{y}$ 。<strong>损失函数 (Loss Function) 则是这个过程中关键的一个组成部分, 用来衡量模型的输出 $\hat{y}$ 与真实的 $y$ 之间的差距, 给模型的优化指明方向。</strong></p>
<p>本文将介绍机器学习、深度学习中分类与回归常用的几种损失函数, 包括<strong>均方差损失 Mean Squared Loss、平 均绝对误差损失 Mean Absolute Error Loss、Huber Loss、分位数损失 Quantile Loss、交叉樀损失函数 Cross Entropy Loss、Hinge 损失 Hinge Loss</strong>。主要介绍各种损失函数的基本形式、原理、特点等方面。</p>
<span id="more"></span>
<h3><span id="前言">前言</span></h3><p>在正文开始之前, 先说下关于 Loss Function、Cost Function 和 Objective Function 的区别和联系。在机器学习 的语境下这三个术语经常被交叉使用。</p>
<ul>
<li><strong>损失函数</strong> Loss Function 通常是<strong>针对单个训练样本而言,</strong> 给定一个模型输出 $\hat{y}$ 和一个真实 $y$, 损失函数输 出一个实值损失 $L=f\left(y_i, \hat{y_i}\right)$</li>
<li><strong>代价函数</strong> Cost Function 通常是<strong>针对整个训练集</strong>（或者在使用 mini-batch gradient descent 时一个 minibatch）的总损失 $J=\sum_{i=1}^N f\left(y_i, \hat{y}_i\right)$</li>
<li><strong>目标函数</strong> Objective Function 是一个更通用的术语, 表示任意希望被优化的函数, 用于机器学习领域和非机 器学习领域 (比如运筹优化)</li>
</ul>
<p>一句话总结三者的关系就是：<font color="red"> <strong>A loss function is a part of a cost function which is a type of an objective function.</strong></font></p>
<p><img src="https://s2.loli.net/2023/04/17/BRyjpDGtWUXcJ2S.png" alt="img" style="zoom: 67%;"></p>
<p>由于损失函数和代价函数只是在针对样本集上有区别，因此在本文中统一使用了损失函数这个术语，但下文的相关公式实际上采用的是代价函数 Cost Function 的形式，请读者自行留意。</p>
<h3><span id="结构风险函数">结构风险函数</span></h3><p>损失函数（loss function）是用来估量模型的预测值f(x)与真实值$Y$不一致的程度，它是一个非负实数值函数，通常使用$L(Y,f(x))$来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数的重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下的式子：</p>
<p><img src="https://s2.loli.net/2023/04/17/TaUDLMBO5upXZEA.png" alt="image-20220821223950768" style="zoom:50%;"></p>
<p>前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的Φ是正则化项（regularizer）或者叫惩罚项（penalty term）,它可以是L1，也可以是L2等其他的正则函数。整个式子表示的意思是找到使目标函数最小时的θ值。下面列出集中常见的损失函数。</p>
<h3><span id="一-对数损失函数逻辑回归mle-交叉熵损失函数">一、 对数损失函数（逻辑回归）MLE  【交叉熵损失函数】</span></h3><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/52100927">https://zhuanlan.zhihu.com/p/52100927</a></p>
<p>  <a href="https://blog.csdn.net/tsyccnh/article/details/79163834">一文搞懂交叉熵在机器学习中的使用，透彻理解交叉熵背后的直觉</a></p>
<p>  <a href="https://zhuanlan.zhihu.com/p/35709485">损失函数｜交叉熵损失函数</a></p>
</blockquote>
<p>有些人可能觉得逻辑回归的损失函数就是平方损失，其实并不是。<strong>平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到</strong>，而逻辑回归得到的并不是平方损失。在逻辑回归的推导中，<strong>它假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数</strong>，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：</p>
<p><strong>最小化负的似然函数</strong>（即$maxF(y,f(x))—&gt;min−F(y,f(x))$)。从损失函数的视角来看，它就成了<strong>log损失函数了。</strong></p>
<h4><span id="原理解释1条件概率下方便计算极大似然估计">原理解释1：<strong>条件概率下方便计算极大似然估计</strong></span></h4><p>Log损失函数的标准形式：</p>
<p>$L(Y,P(Y|X))=−logP(Y|X)$</p>
<p>刚刚说到，<strong>取对数是为了方便计算极大似然估计</strong>，因为在MLE中，直接求导比较困难，所以通常都是先取对数再求导找极值点。损失函数$L(Y.P(Y|X))$表达的是样本在分类$Y$的情况下，使概率$P(Y|X)$达到最大值（换言之，就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者什么样的参数才能使我们观测到目前这组数据的概率最大）。因为log函数是单调递增的，所以$logP(Y|X)$也会达到最大值，因此在前面加上负号之后，最大化$P(Y|X)$就等价于最小化$L$了。</p>
<p><strong>logistic回归</strong>的$P(y|x)$表达式如下（为了将类别标签y统一为1和0，下面将表达式分开表示）：</p>
<p><img src="https://s2.loli.net/2023/04/17/kYQmSNU389DaEgW.png" alt="image-20220322202521355" style="zoom:50%;"></p>
<p>将上面的公式合并在一起，可得到第i个样本正确预测的概率：</p>
<p><img src="https://s2.loli.net/2023/04/17/H9K4sYIapf7lZqC.png" alt="image-20220322202548296" style="zoom:50%;"></p>
<p>上式是对一个样本进行建模的数据表达。对于所有的样本，假设每条样本生成过程独立，在整个样本空间中（N个样本）的概率分布为：</p>
<p><img src="https://s2.loli.net/2023/04/17/9juth32ZNkznoC6.png" alt="image-20220322202618734" style="zoom:50%;"></p>
<p>将上式代入到对数损失函数中，得到最终的损失函数为：</p>
<p><img src="https://s2.loli.net/2023/04/17/Xzdpa6StP4KgNkJ.png" alt="image-20220322202653661" style="zoom:50%;"></p>
<h4><span id="原理解释2相对熵kl散度推理">原理解释2：相对熵（KL散度）推理</span></h4><blockquote>
<p>  相对熵又称KL散度,如果我们对于同一个随机变量 x 有两个单独的概率分布 P(x) 和 Q(x)，我们可以使用 KL 散度（Kullback-Leibler (KL) divergence）来衡量这两个分布的差异.$DKL$的值越小，表示q分布和p分布越接近.</p>
</blockquote>
<h5><span id="相对熵">相对熵:</span></h5><p><img src="https://s2.loli.net/2023/04/17/Hs19MdiWOfokNuP.png" alt="image-20220330133351613" style="zoom:50%;"></p>
<h5><span id="相对熵-信息熵-交叉熵">相对熵 = 信息熵 + 交叉熵 ：</span></h5><p><img src="https://s2.loli.net/2023/04/17/WBZsoc9JwQjkG27.png" alt="image-20220330134202064" style="zoom:50%;"></p>
<p><strong>【对数损失函数（Log loss function）】和【交叉熵损失函数（Cross-entroy loss funtion）】在很多文献内是一致的，因为他们的表示式的本质是一样的。</strong></p>
<h3><span id="二-平方损失函数线性回归gbdt最小二乘法ordinary-least-squaresmse">二、 平方损失函数（线性回归，GBDT，最小二乘法，Ordinary Least Squares）MSE</span></h3><p>最小二乘法是线性回归的一种，OLS 将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（为什么假设成高斯分布呢？其实这里隐藏了一个小知识点，就是中心极限定理，可以参考【central limit theorem】），最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。换言之，OLS是基于<strong>距离</strong>的，而这个距离就是我们用的最多的欧几里得距离。为什么它会选择使用欧式距离作为误差度量呢（即Mean squared error， MSE），主要有以下几个原因：</p>
<ul>
<li>简单，计算方便；</li>
<li>欧氏距离是一种很好的相似性度量标准；</li>
<li>在不同的表示域变换后特征性质不变。</li>
</ul>
<p>平方损失（Square loss）的标准形式如下：$L(Y,f(X))=(Y−f(x))^2$当样本个数为n时，此时的损失函数变为：</p>
<p><img src="https://s2.loli.net/2023/04/17/XuAymnSOw6RhQ9a.png" alt="image-20220322202912962" style="zoom:50%;"></p>
<p>$Y−f(X)$ 表示的是<strong>残差</strong>，整个式子表示的是残差的平方和，而我们的目的就是最小化这个目标函数值（注：该式子未加入正则项），也就是最小化残差的平方和（residual sum of squares，RSS）。</p>
<p>而在实际应用中，通常会使用<strong>均方差</strong>（MSE）作为一项衡量指标，公式如下：</p>
<p><img src="https://s2.loli.net/2023/04/17/dye1NVAtOUw2BoY.png" alt="image-20220322202957484" style="zoom:50%;"></p>
<h3><span id="三-指数损失函数adaboost">三、 指数损失函数（Adaboost）</span></h3><blockquote>
<p>  Adaboost训练误差以指数下降。所以说，指数损失本身并没有带来优化上的特殊，优点在于计算和表达简单。</p>
</blockquote>
<p>学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。在Adaboost中，经过m此迭代之后，可以得到$fm(x)$:</p>
<p><img src="https://s2.loli.net/2023/04/17/fZ8APgDerkSjBIu.png" alt="image-20220322203050695" style="zoom:50%;"></p>
<p><strong>Adaboost</strong>每次迭代时的目的是为了找到最小化下列式子时的参数 $a$ 和 $G$：</p>
<p><img src="https://s2.loli.net/2023/04/17/iphlobfSa5m1cXI.png" alt="image-20220322203141435" style="zoom:50%;"></p>
<p>而指数损失函数(exp-loss）的标准形式如下:</p>
<p><img src="https://s2.loli.net/2023/04/17/hq6iCpQVFeGHnOA.png" alt="image-20220322203221432" style="zoom:50%;"></p>
<p>可以看出，Adaboost的目标式子就是指数损失，在给定N个样本的情况下，Adaboost的损失函数为：</p>
<p><img src="https://s2.loli.net/2023/04/17/ECdNvKtrjZM6o2h.png" alt="image-20220322203238853" style="zoom:50%;"></p>
<h3><span id="四-hinge-合页损失函数svmadvgan">四、 Hinge 合页损失函数（SVM，advGAN）</span></h3><p><img src="https://s2.loli.net/2023/04/17/7x8WAuHyCcMs6I5.png" alt="image-20220401165315551" style="zoom:50%;"></p>
<p>线性支持向量机学习除了原始最优化问题，还有另外一种解释，就是最优化以下目标函数：</p>
<p><img src="https://s2.loli.net/2023/04/17/UXvLs7pH9rj2qoi.png" alt="image-20220322205741804" style="zoom:50%;"></p>
<p>目标函数的第一项是经验损失或经验风险函数：</p>
<p><img src="https://s2.loli.net/2023/04/17/G4hjnsLVavBS9YR.png" alt="image-20220322205801232" style="zoom:50%;"></p>
<p>称为<strong>合页损失函数</strong>（hinge loss function）。下标”+”表示以下取正值的函数：</p>
<p><img src="https://s2.loli.net/2023/04/17/YLEMueb3kBpWxvA.png" alt="image-20220322205844003" style="zoom:50%;"></p>
<p>这就是说，当样本点$(xi,yi)$被正确分类且函数间隔（确信度）$yi(w·xi+b)$大于1时，损失是0，否则损失是$1−yi(w·xi+b)$。目标函数的第二项是系数为 $λ$ 的 $w$ 的 $L2$ 范数，是正则化项。</p>
<p>接下来证明线性支持向量机原始最优化问题：</p>
<p><img src="https://s2.loli.net/2023/04/17/B8nxPKcVfCsGJ92.png" alt="image-20220322210000477" style="zoom:50%;"></p>
<p><img src="https://s2.loli.net/2023/04/17/w1SQdeAEi6qb7c2.png" alt="image-20220322210121285" style="zoom:50%;"></p>
<p>先令$[1−yi(w·xi+b)]+=ξi$，则$ξi≥0$，第二个约束条件成立；由$[1−yi(w·xi+b)]+=ξi$，当$1−yi(w·xi+b)&gt;0$时，有$yi(w·xi+b)=1−ξi$;当$1−yi(w·xi+b)≤0$时，$ξi=0$，有$yi(w·xi+b)≥1−ξi$，所以第一个约束条件成立。所以两个约束条件都满足，最优化问题可以写作</p>
<p><img src="https://s2.loli.net/2023/04/17/Sb7qPknjhDrmAvI.png" alt="image-20220322210943775" style="zoom:50%;"></p>
<p>若取 $λ=1/2C$ 则:</p>
<p><img src="https://s2.loli.net/2023/04/17/VpbFxCN62ArYZyJ.png" alt="image-20220322211012150" style="zoom:50%;"></p>
<h3><span id="五-softmax函数和sigmoid函数的区别与联系">五、Softmax函数和Sigmoid函数的区别与联系</span></h3><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/356976844">https://zhuanlan.zhihu.com/p/356976844</a></p>
</blockquote>
<h4><span id="51-分类任务">5.1 分类任务</span></h4><h5><span id="sigmoid">sigmoid</span></h5><blockquote>
<p>  Sigmoid =<strong>多标签分类问题</strong>=多个正确答案=非独占输出（例如胸部X光检查、住院）。构建分类器，解决有多个正确答案的问题时，用Sigmoid函数分别处理各个原始输出值。</p>
<p>  Softmax =<strong>多类别分类问题</strong>=只有一个正确答案=互斥输出（例如手写数字，鸢尾花）。构建分类器，解决只有唯一正确答案的问题时，用Softmax函数处理各个原始输出值。Softmax函数的分母综合了原始输出值的所有因素，这意味着，Softmax函数得到的不同概率之间相互关联。</p>
</blockquote>
<p><strong>Sigmoid函数</strong>是一种logistic函数，它将任意的值转换到 [0, 1] 之间，如图1所示，函数表达式为:$Sigmoid(x) = \frac{1}{1-e^{-x}}$ 。它的导函数为：$Sigmoid^{‘}(x)=Sigmoid(x)\cdot(1-Sigmoid(x))$。</p>
<p><img src="https://s2.loli.net/2023/04/17/vqpA79snRahWw1F.png" alt="img" style="zoom:50%;"></p>
<p><strong>优点</strong>：</p>
<ol>
<li>Sigmoid函数的输出在(0,1)之间，输出范围有限，优化稳定，可以用作<strong>输出层</strong>。</li>
<li>连续函数，便于<strong>求导</strong>。</li>
</ol>
<p><strong>缺点</strong>：</p>
<ol>
<li><p>最明显的就是<strong>饱和性</strong>，从上图也不难看出其两侧导数逐渐趋近于0，容易造成<strong>梯度消失</strong>。</p>
<p>2.激活函数的偏移现象。Sigmoid函数的输出值均大于0，使得输出不是0的均值，这会导致后一层的神经元将得到上一层非0均值的信号作为输入，这会对梯度产生影响。</p>
</li>
<li><p>计算复杂度高，因为Sigmoid函数是指数形式。</p>
</li>
</ol>
<h5><span id="softmax">Softmax</span></h5><p><strong>Softmax函数</strong>，又称<strong>归一化指数函数</strong>，函数表达式为： $\operatorname{Softmax}(x)=\frac{e^{x_i}}{\sum_{j=1}^n e^{x_j}}$ 。</p>
<p><img src="https://s2.loli.net/2023/04/17/QVYJzvwPZtnpoBE.jpg" alt="img" style="zoom: 67%;"></p>
<p><strong>Softmax函数是二分类函数Sigmoid在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。</strong>如图2所示，Softmax直白来说就是将原来输出是3,1,-3通过Softmax函数一作用，就映射成为(0,1)的值，而这些值的累和为1（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标。</p>
<p>由于Softmax函数先拉大了输入向量元素之间的差异（通过指数函数），然后才归一化为一个概率分布，在应用到分类问题时，它使得各个类别的概率差异比较显著，最大值产生的概率更接近1，这样输出分布的形式更接近真实分布。</p>
<p><strong>Softmax可以由三个不同的角度来解释。从不同角度来看softmax函数，可以对其应用场景有更深刻的理解：</strong></p>
<ol>
<li><strong>softmax可以当作argmax的一种平滑近似</strong>，与arg max操作中暴力地选出一个最大值（产生一个one-hot向量）不同，softmax将这种输出作了一定的平滑，即将one-hot输出中最大值对应的1按输入元素值的大小分配给其他位置。</li>
<li><strong>softmax将输入向量归一化映射到一个类别概率分布</strong>，即 n 个类别上的概率分布（前文也有提到）。这也是为什么在深度学习中常常将softmax作为MLP的最后一层，并配合以交叉熵损失函数（对分布间差异的一种度量)。</li>
<li>从<strong>概率图模型</strong>的角度来看，softmax的这种形式可以理解为一个概率无向图上的联合概率。因此你会发现，条件最大熵模型与softmax回归模型实际上是一致的，诸如这样的例子还有很多。由于概率图模型很大程度上借用了一些热力学系统的理论，因此也可以从物理系统的角度赋予softmax一定的内涵。</li>
</ol>
<h4><span id="52-总结">5.2 总结</span></h4><ol>
<li>如果模型输出为非互斥类别，且可以同时选择多个类别，则采用Sigmoid函数计算该网络的原始输出值。</li>
<li>如果模型输出为<strong>互斥类别</strong>，且只能选择一个类别，则采用Softmax函数计算该网络的原始输出值。</li>
<li><strong>Sigmoid函数</strong>可以用来解决<strong>多标签问题</strong>，<strong>Softmax</strong>函数用来解决<strong>单标签问题</strong>。</li>
<li>对于某个分类场景，当Softmax函数能用时，Sigmoid函数一定可以用。</li>
</ol>
<h3><span id="六-损失函数qampa">六、损失函数Q&amp;A</span></h3><h4><span id="平方误差损失函数和交叉熵损失函数分别适合什么场景">平方误差损失函数和交叉熵损失函数分别适合什么场景？</span></h4><p>一般还说，平方损失函数更适合输出为连续，并且最后一层不含sigmod或softmax激活函数的神经网络；交叉熵损失函数更适合二分类或多分类的场景。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-模型评估</title>
    <url>/posts/7N6QMR/</url>
    <content><![CDATA[<h2><span id="六-ab-测试">六、A/B 测试</span></h2><blockquote>
<p>  【AB测试最全干货】史上最全知识点及常见面试题（上篇） - 数据分析狗一枚的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/375902281">https://zhuanlan.zhihu.com/p/375902281</a></p>
</blockquote>
<h4><span id="引言">引言</span></h4><p>科学家门捷列夫说「没有测量，就没有科学」，在AI场景下我们同样需要定量的数值化指标来指导我们更好地应用模型对数据进行学习和建模。</p>
<p>事实上，在机器学习领域，对模型的测量和评估至关重要。选择与问题相匹配的评估方法，能帮助我们快速准确地发现在模型选择和训练过程中出现的问题，进而对模型进行优化和迭代。本文我们系统地讲解一下机器学习模型评估相关知识。</p>
<span id="more"></span>
<h4><span id="61-模型评估的目标">6.1 模型评估的目标</span></h4><p><strong>模型评估的目标是选出泛化能力强的模型完成机器学习任务</strong>。实际的机器学习任务往往需要进行大量的实验，经过反复调参、使用多种模型算法（甚至多模型融合策略）来完成自己的机器学习问题，并观察哪种模型算法在什么样的参数下能够最好地完成任务。</p>
<p>但是我们无法提前获取「未知的样本」，因此我们会基于已有的数据进行切分来完成模型训练和评估，借助于切分出的数据进行评估，可以很好地判定模型状态（过拟合 or 欠拟合），进而迭代优化。</p>
<p>在建模过程中，为了获得泛化能力强的模型，我们需要一整套方法及评价指标。</p>
<ul>
<li><strong>评估方法</strong>：为保证客观地评估模型，对数据集进行的有效划分实验方法。</li>
<li><strong>性能指标</strong>：量化地度量模型效果的指标。</li>
</ul>
<h4><span id="62-离线与在线实验方法">6.2 离线与在线实验方法</span></h4><p>进行评估的实验方法可以分为「离线」和「在线」两种。</p>
<h4><span id="离线实验方法">离线实验方法：</span></h4><blockquote>
<p>  在<strong>离线评估</strong>中，经常使用<strong>准确率（Accuracy）、查准率（Precision）、召回率（Recall）、ROC、AUC、PRC</strong>等指标来评估模型。</p>
</blockquote>
<p><strong>模型评估通常指离线试验</strong>。原型设计（Prototyping）阶段及离线试验方法，包含以下几个过程：</p>
<ul>
<li>使用历史数据训练一个适合解决目标任务的一个或多个机器学习模型。</li>
<li>对模型进行验证（Validation）与离线评估（Offline Evaluation）。</li>
<li>通过评估指标选择一个较好的模型。</li>
</ul>
<h4><span id="在线实验方法">在线实验方法：</span></h4><blockquote>
<p>  <strong>在线评估</strong>与离线评估所用的评价指标不同，一般使用一些商业评价指标，如<strong>用户生命周期值（Customer Lifetime value）、广告点击率（Click Through Rate）、用户流失率</strong>（Customer Churn Rate）等标。</p>
</blockquote>
<p>除了离线评估之外，其实还有一种在线评估的实验方法。由于模型是在老的模型产生的数据上学习和验证的，而线上的数据与之前是不同的，因此离线评估并不完全代表线上的模型结果。因此我们需要在线评估，来验证模型的有效性。</p>
<p><img src="https://www.zhihu.com/equation?tex=A%2FB%20%5Cquad%20Test" alt="公式"> <strong>是目前在线测试中最主要的方法</strong>。<img src="https://www.zhihu.com/equation?tex=A%2FB%20%5Cquad%20Test" alt="公式"> 是为同一个目标制定两个方案让一部分用户使用 <img src="https://www.zhihu.com/equation?tex=A" alt="公式"> 方案，另一部分用户使用 <img src="https://www.zhihu.com/equation?tex=B" alt="公式"> 方案，记录下用户的使用情况，看哪个方案更符合设计目标。如果不做AB实验直接上线新方案，新方案甚至可能会毁掉你的产品。</p>
<h4><span id="63-模型离线评估后为什么要进行ab测试"><strong><font color="red"> 6.3 模型离线评估后，为什么要进行ab测试？</font></strong></span></h4><ul>
<li><strong>离线评估无法消除过拟合的影响</strong>，因此离线评估结果无法代替线上的评估效果</li>
<li><strong>离线评估过程中无法模拟线上的真实环境，例如数据丢失、样本反馈延迟</strong></li>
<li>线上的<strong>某些商业指标例如收益、留存等无法通过离线计算</strong></li>
</ul>
<h4><span id="64-如何进行线上ab测试">6.4 <strong>如何进行线上ab测试？</strong></span></h4><p>进行ab测试的主要手段时对用户进行分桶，即将<strong>用户分成实验组和对照组</strong>。实验组使用新模型，对照组使用base模型。<strong>分桶过程中需要保证样本的独立性和采样的无偏性</strong>，确保每个用户只划分到一个桶中，分桶过程中需要保证user id是一个<a href="https://www.zhihu.com/search?q=随机数&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;440144351&quot;}">随机数</a>，才能保证数据无偏的。</p>
<h2><span id="七-模型评估">七、模型评估</span></h2><h4><span id="71-holdout">7.1 holdout</span></h4><p><strong>留出法是机器学习中最常见的评估方法之一，它会从训练数据中保留出验证样本集，这部分数据不用于训练，而用于模型评估</strong>。</p>
<h4><span id="72-交叉验证">7.2 交叉验证</span></h4><p><strong>留出法的数据划分，可能会带来偏差</strong>。在机器学习中，另外一种比较常见的评估方法是交叉验证法—— <img src="https://www.zhihu.com/equation?tex=K" alt="公式"> <strong>折交叉验证对 <img src="https://www.zhihu.com/equation?tex=K" alt="公式"> 个不同分组训练的结果进行平均来减少方差</strong>。</p>
<h4><span id="73-自助法">7.3 自助法</span></h4><p>Bootstrap 是一种用小样本估计总体值的一种非参数方法，在进化和生态学研究中应用十分广泛。<strong>Bootstrap通过有放回抽样生成大量的伪样本，通过对伪样本进行计算，获得统计量的分布，从而估计数据的整体分布</strong>。</p>
<h2><span id="八-超参数调优">八、超参数调优</span></h2><p>神经网咯是有许多超参数决定的，例如网络深度，学习率，正则等等。如何寻找最好的超参数组合，是一个老人靠经验，新人靠运气的任务。</p>
<h4><span id="81-网格搜索">8.1 网格搜索</span></h4><h4><span id="82-随机搜索">8.2 随机搜索</span></h4><h4><span id="83-贝叶斯优化">==8.3 贝叶斯优化==</span></h4><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/390373572"><em>贝叶斯优化</em>(原理+代码解读)</a></p>
<p>  <a href="https://zhuanlan.zhihu.com/p/27916208">LightGBM调参指南(带贝叶斯优化代码)</a></p>
<ul>
<li>贝叶斯调参采用高斯过程，考虑之前的参数信息，不断地更新先验；网格搜索未考虑之前的参数信息</li>
<li>贝叶斯调参迭代次数少，速度快；网格搜索速度慢,参数多时易导致维度爆炸</li>
<li><p>贝叶斯调参针对非凸问题依然稳健；网格搜索针对非凸问题易得到局部最优</p>
<h4><span id="可用的贝叶斯优化框架">可用的贝叶斯优化框架</span></h4></li>
</ul>
<ol>
<li>BayesianOptimization：<a href="https://link.zhihu.com/?target=https%3A//github.com/fmfn/BayesianOptimization">https://github.com/fmfn/BayesianOptimization</a></li>
<li>清华开源的openbox：<a href="https://link.zhihu.com/?target=https%3A//open-box.readthedocs.io/zh_CN/latest/index.html">https://open-box.readthedocs.io/zh_CN/latest/index.html</a></li>
<li>华为开源的HEBO：<a href="https://link.zhihu.com/?target=https%3A//github.com/huawei-noah/HEBO">https://github.com/huawei-noah/HEBO</a></li>
<li><strong>Hyperopt</strong>：<a href="https://link.zhihu.com/?target=http%3A//hyperopt.github.io/hyperopt/">http://hyperopt.github.io/hype</a></li>
</ol>
</blockquote>
<h4><span id="贝叶斯优化什么黑盒优化">贝叶斯优化什么?【黑盒优化】</span></h4><p>求助 gradient-free 的优化算法了，这类算法也很多了，<strong>贝叶斯优化就属于无梯度优化算法</strong>中的一种，它希望在尽可能少的试验情况下去尽可能获得优化命题的全局最优解。</p>
<p><img src="https://pic1.zhimg.com/v2-75933a225ab1875a27188013ce0d8740_b.jpg" alt="img" style="zoom: 33%;"></p>
<ul>
<li>目标函数 <img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]"> 及其导数未知，否则就可以用梯度下降等方法求解。</li>
<li>计算目标函数时间成本大，意味着像蚁群算法、遗传算法这种方法也失效了，因为计算一次要花费很多时间。</li>
</ul>
<h4><span id="概述">概述</span></h4><p>贝叶斯优化，是一种使用<strong>贝叶斯定理来指导搜索以找到目标函数的最小值或最大值的方法</strong>，就是在每次迭代的时候，利用之前观测到的历史信息（先验知识）来进行下一次优化，通俗点讲，<strong>就是在进行一次迭代的时候，先回顾下之前的迭代结果，结果太差的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 附近就不去找了，尽量往结果好一点的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 附近去找最优解，</strong>这样一来搜索的效率就大大提高了，这其实和人的思维方式也有点像，每次在学习中试错，并且在下次的时候根据这些经验来找到最优的策略。</p>
<h4><span id="贝叶斯优化过程">贝叶斯优化过程</span></h4><p>首先，假设有一个这样的函数 <img src="https://www.zhihu.com/equation?tex=c%28x%29" alt="[公式]"> ，我们需要找到他的最小值，如下图所示，这也是我们所需要优化的目标函数，但是我们并不能够知道他的具体形状以及表达形式是怎么样的。</p>
<p><img src="https://pic3.zhimg.com/v2-ddb9527a36ddcdb539d573fa5124d576_b.jpg" alt="img"></p>
<p>贝叶斯优化是通过一种叫做代理优化的方式来进行的，就是不知道真实的目标函数长什么样，我们就用一个<strong>代理函数（surrogate function）来代替目标函数</strong>，<strong>而这个代理函数就可以通过先采样几个点，再通过这几个点来给他拟合出来</strong>，如下图虚线所示：</p>
<p><img src="https://pic2.zhimg.com/v2-53769125b87835a74445a472415c22a1_b.jpg" alt="img"></p>
<p>基于构造的代理函数，<strong>我们就可以在可能是最小值的点附近采集更多的点</strong>，或者在还没有采样过的区域来采集更多的点，有了更多点，就可以<strong>更新代理函数</strong>，使之更逼近真实的目标函数的形状，这样的话也更容易找到目标函数的最小值，这个采样的过程同样可以通过构建一个采集函数来表示，也就是知道了当前代理函数的形状，如何选择下一个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 使得收益最大。</p>
<p><strong>然后重复以上过程，最终就可以找到函数的最小值点了，这大致就是贝叶斯优化的一个过程：</strong></p>
<ol>
<li><strong>初始化一个代理函数的先验分布</strong></li>
<li><strong>选择数据点 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> ，使得采集函数 <img src="https://www.zhihu.com/equation?tex=a%28x%29" alt="[公式]"> 取最大值</strong></li>
<li><strong>在目标函数 <img src="https://www.zhihu.com/equation?tex=+c%28x%29" alt="[公式]"> 中评估数据点 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 并获取其结果 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"></strong> </li>
<li><strong>使用新数据 <img src="https://www.zhihu.com/equation?tex=%28x%2Cy%29" alt="[公式]"> 更新代理函数，得到一个后验分布（作为下一步的先验分布)</strong></li>
<li>重复2-4步，直到达到最大迭代次数</li>
</ol>
<p>举个例子，如图所示，一开始只有两个点（t=2），代理函数的分布是紫色的区域那块，然后根据代理函数算出一个采集函数（绿色线），取采集函数的最大值所在的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> （红色三角处），算出 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> ，然后根据新的点 <img src="https://www.zhihu.com/equation?tex=%28x%2Cy%29" alt="[公式]"> 更新代理函数和采集函数（t=3），继续重复上面步骤，选择新的采集函数最大值所在的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> ，算出 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> ，再更新代理函数和采集函数，然后继续迭代。</p>
<p><img src="https://pic1.zhimg.com/v2-82ed7dc24fca93f3c2c5820ab519a5f8_b.jpg" alt="img" style="zoom: 67%;"></p>
<p>问题的核心就在于代理函数和采集函数如何构建，常用的代理函数有：</p>
<ol>
<li><strong>高斯过程（Gaussian processes）</strong></li>
<li><strong>Tree Parzer Estimator</strong></li>
<li><strong>概率随机森林：针对类别型变量</strong></li>
</ol>
<p>采集函数则需要兼顾两方面的性质：</p>
<ol>
<li>利用当前已开发的区域（Exploitation）：即在当前最小值附近继续搜索</li>
<li>探索尚未开发的区域（Exploration）：即在还没有搜索过的区域里面搜索，可能那里才是全局最优解</li>
</ol>
<p><strong>常用的采集函数有：</strong></p>
<ol>
<li>Probability of improvement（PI）</li>
<li>Expected improvement（EI）</li>
<li>Confidence bound criteria，包括LCB和UCB</li>
</ol>
<h4><span id="84-hyperopt">8.4 Hyperopt</span></h4><p>Hyperopt 是一个强大的 Python 库，用于超参数优化，由 jamesbergstra 开发。Hyperopt 使用贝叶斯优化的形式进行参数调整，允许你为给定模型获得最佳参数。它可以在大范围内优化具有数百个参数的模型。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习-理论基础</title>
    <url>/posts/52716/</url>
    <content><![CDATA[<h3><span id="一-机器学习中参数模型和非参数模型理解">一、 机器学习中参数模型和非参数模型理解</span></h3><blockquote>
<p>  参考：<a href="https://blog.csdn.net/FrankieHello/article/details/94022594">https://blog.csdn.net/FrankieHello/article/details/94022594</a></p>
</blockquote>
<p><strong>参数模型通常假设总体服从某个分布，这个分布可以由一些参数确定，如正态分布由均值和标准差确定，在此基础上构建的模型称为参数模型</strong>；非参数模型对于总体的分布不做任何假设或者说是数据分布假设自由，只知道其分布是存在的，所以就无法得到其分布的相关参数，只能通过非参数统计的方法进行推断。</p>
<p><strong>参数模型</strong>：线性回归、逻辑回归、感知机、基本型的SVM</p>
<p><strong>非参数模型</strong>：决策树、对偶型的SVM、朴素贝叶斯、神经网络</p>
<span id="more"></span>
<h3><span id="二-判别模型-vs-生成模型">二、 判别模型 VS 生成模型</span></h3><blockquote>
<p>  判别模型与生成模型，概率模型与非概率模型、参数模型与非参数模型总结 - Eureka的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/37821985">https://zhuanlan.zhihu.com/p/37821985</a></p>
<p>  <strong>机器学习中的判别式模型和生成式模型</strong> - Microstrong的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/74586507">https://zhuanlan.zhihu.com/p/74586507</a></p>
</blockquote>
<p><img src="https://s2.loli.net/2023/04/17/AYyZUiraIdN5Dn1.png" alt="image-20230417171758407" style="zoom:50%;"></p>
<p><strong>判别模型：感知机、逻辑斯特回归、支持向量机、神经网络、k近邻都属于判别学习模型。判别模型分为两种:</strong></p>
<ul>
<li>直接对输入空间到输出空间的映射进行建模, 也就是学习函数 $h$ : </li>
</ul>
<script type="math/tex; mode=display">
h: X \rightarrow Y, s . t . y=h(x)</script><ul>
<li>对条件概率 $P(y \mid x)$ 进行建模, 然后根据贝叶斯风险最小化的准则进行分类: </li>
</ul>
<script type="math/tex; mode=display">
y=\arg \max _{y \in\{-1,1\}} P(y \mid x)</script><p><strong>生成模型：</strong></p>
<p>生成模型是间接地, 先对 $P(x, y)$ 进行建模, 再根据贝叶斯公式:$P(y \mid x)=\frac{P(x \mid y) P(y)}{P(x)}$</p>
<script type="math/tex; mode=display">
P(y \mid x)=\frac{P(x \mid y) P(y)}{P(x)}</script><p>算出 $P(y \mid x)$, 最后根据 $\arg \max _{y \in\{-1,1\}} P(y \mid x)$ 来做分类 (由此可知, 判别模型实际上不需要对 $P(x, y)$ 进行建模)。</p>
<h3><span id="三-概率模型-vs-非概率模型">三、概率模型 vs 非概率模型</span></h3><h4><span id="31-概率模型">3.1 概率模型</span></h4><blockquote>
<p>  <strong>线性回归（高斯分布）、LR（伯努利分布）、高斯判别分析、朴素贝叶斯</strong></p>
</blockquote>
<p><strong>概率模型指出了学习的目的是学出 $P(x, y)$ 或 $P(y \mid x)$, 但最后都是根据 $\arg \max _{y \in\{-1,1\}} P(y \mid x)$ 来做判别归类</strong>。对于 $P(x, y)$ 的估计, 一般是根据乘法公式 $P(x, y)=P(x \mid y) P(y)$ 将其拆解成 $P(x \mid y), P(y)$ 分别进行估计。无论是对 $P(x \mid y), P(y)$ 还是 $P(y \mid x)$ 的估计, 都是会先假设分布的形式, 例如逻辑斯特回归就假设了 $Y \mid X$ 服从伯努利分 布。分布形式固定以后, 剩下的就是分布参数的估计问题。<strong>常用的估计有极大似然估计(MLE)和极大后验概率估计 (MAP)等</strong>。其中, 极大后验概率估计涉及到分布参数的先验概率, 这为我们注入先验知识提供了途径。逻辑斯特回 归、高斯判别分析、朴素贝叶斯都属于概率模型。</p>
<p>在一定的条件下，非概率模型与概率模型有以下对应关系:</p>
<p><img src="https://s2.loli.net/2023/04/17/AYyZUiraIdN5Dn1.png" alt="image-20230417171758407" style="zoom:50%;"></p>
<h4><span id="32-非概率模型">3.2 非概率模型</span></h4><blockquote>
<p>  <strong>感知机、支持向量机、神经网络、k近邻都属于非概率模型</strong>。线性支持向量机可以显式地写出损失函数——hinge损失。神经网络也可以显式地写出损失函数——平方损失。</p>
</blockquote>
<p>非概率模型指的是直接学习输入空间到输出空间的映射 $h$, 学习的过程中基本不涉及概率密度的估计, 概率密度 的积分等操作, 问题的关键在于最优化问题的求解。通常, 为了学习假设 $h(x)$, 我们会先根据一些先验知识 (prior knowledge) 来选择一个特定的假设空间 $H(x)$ (函数空间), 例如一个由所有线性函数构成的空间, 然后在 这个空间中找出泛化误差最小的假设出来, |</p>
<script type="math/tex; mode=display">
h^*=\arg \min _{h \in H} \varepsilon(h)=\arg \min _{h \in H} \sum_{x, y} l(h(x), y) P(x, y)</script><p>其中 $l(h(x), y)$ 是我们选取的损失函数, 选择不同的损失函数, 得到假设的泛化误差就会不一样。由于我们并不知 道 $P(x, y)$, 所以即使我们选好了损失函数, 也无法计算出假设的泛化误差, 更别提找到那个给出最小泛化误差的 假设。于是，我们转而去找那个使得经验误差最小的假设</p>
<script type="math/tex; mode=display">
g=\arg \min _{h \in H} \hat{\varepsilon}(h)=\arg \min _{h \in H} \frac{1}{m} \sum_{i=1}^{m} l\left(h\left(x^{(i)}\right), y^{(i)}\right)</script><p><font color="red"> 这种学习的策略叫经验误差最小化(ERM)，理论依据是大数定律：当训练样例无穷多的时候，假设的经验误差会依概率收敛到假设的泛化误差。</font>要想成功地学习一个问题，必须在学习的过程中注入先验知识。前面，我们根据先验知识来选择假设空间，其实，在选定了假设空间后，先验知识还可以继续发挥作用，这一点体现在为我们的优化问题加上正则化项上，例如常用的$L1$正则化， $L2$正则化等。</p>
<script type="math/tex; mode=display">
g=\arg \min _{h \in H} \hat{\varepsilon}(h)=\arg \min _{h \in H} \frac{1}{m} \sum_{i=1}^{m} l\left(h\left(x^{(i)}\right), y^{(i)}\right)+\lambda \Omega(h)</script><h3><span id="四-过拟合和欠拟合">四、 过拟合和欠拟合</span></h3><blockquote>
<p>  欠拟合、过拟合及如何防止过拟合 - G-kdom的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/72038532">https://zhuanlan.zhihu.com/p/72038532</a></p>
</blockquote>
<h4><span id="41-欠拟合">4.1 欠拟合</span></h4><p><strong>欠拟合是指模型不能在训练集上获得足够低的误差</strong>。换句换说，就是模型复杂度低，模型在训练集上就表现很差，没法学习到数据背后的规律。</p>
<h4><span id="42-欠拟合解决方法">4.2 欠拟合解决方法</span></h4><p>欠拟合基本上都会发生在训练刚开始的时候，经过不断训练之后欠拟合应该不怎么考虑了。但是如果真的还是存在的话，可以通过<strong>增加网络复杂度</strong>或者在模型中<strong>增加特征</strong>，这些都是很好解决欠拟合的方法。</p>
<h4><span id="43-过拟合">4.3 过拟合</span></h4><p>过拟合是指训练误差和测试误差之间的差距太大。换句换说，就是模型复杂度高于实际问题，<strong>模型在训练集上表现很好，但在测试集上却表现很差</strong>。模型对训练集”死记硬背”（记住了不适用于测试集的训练集性质或特点），没有理解数据背后的规律，<strong>泛化能力差</strong>。</p>
<p>造成原因主要有以下几种：<br>1、<strong>训练数据集样本单一，样本不足</strong>。如果训练样本只有负样本，然后那生成的模型去预测正样本，这肯定预测不准。所以训练样本要尽可能的全面，覆盖所有的数据类型。<br>2、<strong>训练数据中噪声干扰过大</strong>。噪声指训练数据中的干扰数据。过多的干扰会导致记录了很多噪声特征，忽略了真实输入和输出之间的关系。<br>3、<strong>模型过于复杂。</strong>模型太复杂，已经能够“死记硬背”记下了训练数据的信息，但是遇到没有见过的数据的时候不能够变通，泛化能力太差。我们希望模型对不同的模型都有稳定的输出。模型太复杂是过拟合的重要因素。</p>
<h4><span id="44-如何防止过拟合">4.4 如何防止过拟合</span></h4><p>要想解决过拟合问题，就要显著减少测试误差而不过度增加训练误差，从而提高模型的泛化能力。</p>
<h5><span id="1-使用正则化regularization方法">1、使用正则化（Regularization）方法。</span></h5><p>那什么是<a href="https://www.zhihu.com/search?q=正则化&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">正则化</a>呢？<strong>正则化是指修改学习算法，使其降低泛化误差而非训练误差</strong>。</p>
<p>常用的正则化方法根据具体的使用策略不同可分为：（1）直接提供正则化约束的参数正则化方法，如L1/L2正则化；（2）通过工程上的技巧来实现更低泛化误差的方法，如提前终止(Early stopping)和Dropout；（3）不直接提供约束的隐式正则化方法，如数据增强等。</p>
<p><strong>L2正则化起到使得权重参数 $w$变小的效果，为什么能防止过拟合呢？</strong>因为更小的权重参数$w$意味着模型的复杂度更低，对训练数据的拟合刚刚好，不会过分拟合训练数据，从而提高模型的泛化能力。</p>
<h5><span id="2-获取和使用更多的数据数据集增强解决过拟合的根本性方法">2、获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法</span></h5><p>让机器学习或深度学习模型泛化能力更好的办法就是使用更多的数据进行训练。但是，在实践中，我们拥有的数据量是有限的。解决这个问题的一种方法就是<strong>创建“假数据”并添加到训练集中——数据集增强</strong>。通过增加训练集的额外副本来增加训练集的大小，进而改进模型的泛化能力。</p>
<p>我们以图像数据集举例，能够做：旋转图像、缩放图像、随机裁剪、加入随机噪声、平移、镜像等方式来增加数据量。另外补充一句，在物体分类问题里，<strong>CNN在图像识别的过程中有强大的“不变性”规则，即待辨识的物体在图像中的形状、姿势、位置、图像整体明暗度都不会影响分类结果</strong>。我们就可以通过图像平移、翻转、缩放、切割等手段将数据库成倍扩充。</p>
<h5><span id="3-采用合适的模型控制模型的复杂度">3. 采用合适的模型（控制模型的复杂度）</span></h5><p>过于复杂的模型会带来过拟合问题。对于模型的设计，目前公认的一个深度学习规律”deeper is better”。国内外各种大牛通过实验和竞赛发现，对于CNN来说，层数越多效果越好，但是也更容易产生过拟合，并且计算所耗费的时间也越长。</p>
<p>根据<strong>奥卡姆剃刀法则</strong>：在同样能够解释已知观测现象的假设中，我们应该挑选“最简单”的那一个。对于模型的设计而言，我们应该<strong>选择简单、合适的模型解决复杂的问题</strong>。</p>
<h5><span id="4-降低特征的数量">4. 降低特征的数量</span></h5><p>对于一些特征工程而言，可以降低特征的数量——删除冗余特征，人工选择保留哪些特征。这种方法也可以解决过拟合问题。</p>
<h5><span id="5-dropout">5. Dropout</span></h5><p>Dropout是在训练网络时用的一种技巧（trike），相当于在隐藏单元增加了噪声。<strong>Dropout 指的是在训练过程中每次按一定的概率（比如50%）随机地“删除”一部分隐藏单元（神经元）。</strong>所谓的“删除”不是真正意义上的删除，其实就是将该部分神经元的激活函数设为0（激活函数的输出为0），让这些神经元不计算而已。</p>
<p><strong>Dropout为什么有助于防止过拟合呢？</strong></p>
<p>（a）在训练过程中会产生不同的训练模型，不同的训练模型也会产生不同的的计算结果。随着训练的不断进行，计算结果会在一个范围内波动，但是均值却不会有很大变化，因此可以把最终的训练结果看作是不同模型的平均输出。</p>
<p>（b）它消除或者减弱了神经元节点间的联合，降低了网络对单个神经元的依赖，从而增强了泛化能力。</p>
<h5><span id="6-early-stopping提前终止">6. Early stopping（提前终止）</span></h5><p>对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如<a href="https://www.zhihu.com/search?q=梯度下降&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">梯度下降</a>（Gradient descent）。<strong>Early stopping是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合</strong>。</p>
<p>为了获得性能良好的神经网络，训练过程中可能会经过很多次<a href="https://www.zhihu.com/search?q=epoch&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">epoch</a>（遍历整个数据集的次数，一次为一个epoch）。如果epoch数量太少，网络有可能发生欠拟合；如果epoch数量太多，则有可能发生过拟合。Early <a href="https://www.zhihu.com/search?q=stopping&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">stopping</a>旨在解决epoch数量需要手动设置的问题。具体做法：<strong>每个epoch（或每N个epoch）结束后，在验证集上获取测试结果，随着epoch的增加，如果在验证集上发现测试误差上升，则停止训练，将停止之后的权重作为网络的最终参数。</strong></p>
<p><strong>为什么能防止过拟合？</strong>当还未在神经网络运行太多迭代过程的时候，w参数接近于0，因为随机初始化<a href="https://www.zhihu.com/search?q=w值&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">w值</a>的时候，它的值是较小的随机值。当你开始迭代过程，w的值会变得越来越大。到后面时，w的值已经变得十分大了。所以early stopping要做的就是在中间点停止迭代过程。我们将会得到一个中等大小的w参数，会得到与L2正则化相似的结果，选择了w参数较小的神经网络。</p>
<p><strong>Early Stopping缺点：没有采取不同的方式来解决优化损失函数和过拟合这两个问题</strong>，而是用一种方法同时解决两个问题 ，结果就是要考虑的东西变得更复杂。之所以不能独立地处理，因为如果你停止了优化损失函数，你可能会发现损失函数的值不够小，同时你又不希望过拟合。</p>
<h3><span id="五-损失函数loss与评价指标metric的区别">五、损失函数(loss)与评价指标(metric)的区别？</span></h3><p><strong>当建立一个学习算法时，我们希望最大化一个给定的评价指标matric（比如说准确度），但算法在学习过程中会尝试优化一个不同的损失函数loss（比如说MSE/Cross-entropy）。</strong></p>
<p><strong><font color="red"> 那为什么不把评价指标matric作为学习算法的损失函数loss呢？</font></strong></p>
<ul>
<li><p>一般来说，我认为你应该尝试优化一个与你最关心的评价指标相对应的损失函数。例如，在做分类时，我认为你需要给我一个很好的理由，让我不要优化交叉熵。也就是说，交叉熵并不是一个非常直观的指标，所以一旦你完成了训练，你可能还想知道你的分类准确率有多高，以了解你的模型是否真的能在现实世界中发挥作用，总之，在每个epoch训练完后，你都会有多个评估指标。这样作的主要原因是为了了解你的模型在做什么。这意味着你想要最大化指标A，以便得到一个接近最大化指标B的解决方案。</p>
</li>
<li><p>通常情况下，MSE/交叉熵比精度更容易优化，因为它们对模型参数是可微的，在某些情况下甚至是凸的，这使得它更容易。</p>
</li>
</ul>
<h3><span id="六-标准化和归一化">六、标准化和归一化</span></h3><blockquote>
<p>  PCA、k-means、SVM、回归模型、<strong>神经网络</strong></p>
</blockquote>
<h4><span id="61-定义">6.1 定义</span></h4><p><strong>归一化和标准化</strong>都是对<strong>数据做变换</strong>的方式，将原始的一列数据转换到某个范围，或者某种形态，具体的：</p>
<blockquote>
<p>  <strong>归一化(Normalization)</strong>：将一列数据变化到某个固定区间(范围)中，通常，这个区间是[0, 1]，广义的讲，可以是各种区间，比如映射到[0，1]一样可以继续映射到其他范围，图像中可能会映射到[0,255]，其他情况可能映射到[-1,1]；</p>
<p>  <strong>标准化(Standardization)</strong>：将数据变换为均值为0，标准差为1的分布切记，<strong>并非一定是正态的；</strong></p>
<p>  <strong>中心化</strong>：另外，还有一种处理叫做中心化，也叫零均值处理，就是将每个原始数据减去这些数据的均值。</p>
</blockquote>
<h4><span id="62-差异">6.2 差异</span></h4><blockquote>
<p>  <strong>归一化：对处理后的数据范围有严格要求;</strong></p>
<p>  <strong>标准化:  数据不为稳定，存在极端的最大最小值;  涉及距离度量、协方差计算的时候;</strong></p>
</blockquote>
<ul>
<li><strong>归一化会严格的限定变换后数据的范围</strong>，比如按之前最大最小值处理的，它的范围严格在[ 0 , 1 ]之间；而<strong>标准化</strong>就没有严格的区间，变换后的数据没有范围，只是其均值是0，标准差为1。</li>
<li><strong>归一化的缩放比例仅仅与极值有关</strong>，容易受到异常值的影响。</li>
</ul>
<h4><span id="63-用处">6.3 用处</span></h4><ul>
<li>回归模型，自变量X的量纲不一致导致了<strong>回归系数无法直接解读</strong>或者错误解读；需要将X都处理到统一量纲下，这样才可比；</li>
<li>机器学习任务和统计学任务中有很多地方要用到<strong>“距离”的计算</strong>，比如PCA，比如KNN，比如kmeans等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果；</li>
<li>参数估计时使用<strong>梯度下降</strong>，在使用梯度下降的方法求解最优化问题时， 归一化/标准化后可以加快梯度下降的求解速度，即<strong>提升模型的收敛速度</strong>。</li>
</ul>
<p><strong>其他：log、sigmod、softmax 变换</strong></p>
<h3><span id="七-回归-vs-分类">七、回归 vs 分类</span></h3><p>回归问题可以理解为是定量输出的问题，是一个连续变量预测；分类问题可以理解为是定性输出的问题，是一个离散变量预测。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
      <tags>
        <tag>理论基础</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习（15）聚类*-DBSCAN</title>
    <url>/posts/1TSFG2S/</url>
    <content><![CDATA[<h2><span id="二-dbscan算法基于密度">二、DBSCAN算法【基于密度】</span></h2><blockquote>
<p>  （3）聚类算法之DBSCAN算法 - GISer.Wang的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/77043965">https://zhuanlan.zhihu.com/p/77043965</a></p>
</blockquote>
<p>密度聚类方法的指导思想是，只要样本点的密度大于某阈值，则将该样本添加到最近的簇中。这类算法能克服基于距离的算法只能发现“类圆”（凸）的聚类的缺点，可发现任意形状的聚类，且对噪声数据不敏感。但计算密度单元的计算复杂度大，需要建立空间索引来降低计算量。其代表算法为<strong>DBSCAN算法</strong>和<strong>密度最大值</strong>算法。</p>
<h3><span id="21-dbscan算法原理">2.1 DBSCAN算法原理</span></h3><p><strong><font color="red"> DBCSAN（Density-Based Spatial Clustering of Applications with Noise）是一个比较有代表性的基于密度的聚类算法。</font></strong>与划分和层次聚类方法不同，它将簇定义为密度相连的点的最大集合，能够把具有足够高密度的区域划分为簇，并<strong>可在有“噪声”的数据中发现任意形状的聚类</strong>。</p>
<h3><span id="22-若干概念">2.2 若干概念</span></h3><p><strong>DBSCAN是基于一组邻域来描述样本集的紧密程度的，参数 <img src="https://www.zhihu.com/equation?tex=%28%CF%B5%2C+MinPts%29" alt="[公式]"> 用来描述邻域的样本分布紧密程度</strong>。其中， <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 描述了某一数据点的<strong>邻域距离阈值（半径）</strong>， <img src="https://www.zhihu.com/equation?tex=MinPts" alt="[公式]"> 描述了数据点<strong>半径为</strong> <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> <strong>的邻域</strong>中数据点个数的最小个数。下面是与密度聚类相关的定义（假设我的样本集是 <img src="https://www.zhihu.com/equation?tex=D%3D%5C%7Bx_1%2Cx_2%2C...%2Cx_m%5C%7D" alt="[公式]"> )：</p>
<ul>
<li><p><strong>对象的ε领域</strong>：给定对象在半径<strong>ε</strong>内的区域；对于 <img src="https://www.zhihu.com/equation?tex=x_j%E2%88%88D" alt="[公式]"> ，其 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域包含样本集 <img src="https://www.zhihu.com/equation?tex=D" alt="[公式]"> 中与 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 的距离不大于 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 的子样本集。即 <img src="https://www.zhihu.com/equation?tex=N_%CF%B5%28x_j%29%3D%5C%7Bx_i%E2%88%88D%7Cdistance%28x_i%2Cx_j%29%E2%89%A4%CF%B5%5C%7D" alt="[公式]"> , 这个子样本集的个数记为 <img src="https://www.zhihu.com/equation?tex=%7CN_%CF%B5%28x_j%29%7C" alt="[公式]"> 。 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域是一个集合</p>
</li>
<li><p><strong>核心对象</strong>：对于任一样本 <img src="https://www.zhihu.com/equation?tex=x_j%E2%88%88D" alt="[公式]"> ，如果其 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域对应的 <img src="https://www.zhihu.com/equation?tex=N_%CF%B5%28x_j%29" alt="[公式]"> 至少包含 <img src="https://www.zhihu.com/equation?tex=MinPts" alt="[公式]"> 个样本，即如果 <img src="https://www.zhihu.com/equation?tex=+%7CN_%CF%B5%28x_j%29%7C%E2%89%A5MinPts" alt="[公式]"> ，则 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 是核心对象。</p>
</li>
<li><p><strong>直接密度可达</strong>：如果 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 位于 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 的 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域中，且 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 是核心对象，则称 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 由 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 密度直达。反之不一定成立，即此时不能说 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 由 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 密度直达, 除非 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 也是核心对象，<strong>即密度直达不满足对称性</strong>。如图ε=1,m=5，q是一个核心对象，从对象q出发到对象p是<strong>直接密度可达</strong>的。</p>
</li>
</ul>
<p><img src="https://i.loli.net/2019/08/01/5d42afb2323b988730.jpg" alt="2019-05-18-061126.jpg" style="zoom:50%;"></p>
<ul>
<li><strong>密度可达</strong>：对于 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> ,如果存在样本样本序列 <img src="https://www.zhihu.com/equation?tex=p_1%2Cp_2%2C...%2Cp_T" alt="[公式]"> ,满足 <img src="https://www.zhihu.com/equation?tex=p1%3Dx_i%2Cp_T%3Dx_j" alt="[公式]"> , 且 <img src="https://www.zhihu.com/equation?tex=p_%7Bt%2B1%7D" alt="[公式]"> 由 <img src="https://www.zhihu.com/equation?tex=p_t" alt="[公式]"> 密度直达，则称 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 由 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 密度可达。也就是说，密度可达满足传递性。此时序列中的传递样本 <img src="https://www.zhihu.com/equation?tex=p_1%2Cp_2%2C...%2Cp_%7BT%E2%88%921%7D" alt="[公式]"><strong>均为核心对象</strong>，因为只有核心对象才能使其他样本密度直达。<strong>密度可达也不满足对称性</strong>，这个可以由密度直达的不对称性得出。</li>
</ul>
<p><img src="https://i.loli.net/2019/08/01/5d42afbfa514735525.jpg" alt="2019-05-18-061154.jpg" style="zoom:50%;"></p>
<ul>
<li><strong>密度相连</strong>：对于 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> ,如果存在核心对象样本 <img src="https://www.zhihu.com/equation?tex=x_k" alt="[公式]"> ，使<strong><img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 均由 <img src="https://www.zhihu.com/equation?tex=x_k" alt="[公式]"> 密度可达</strong>，则称 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 密度相连。<strong>密度相连关系满足对称性</strong>。</li>
</ul>
<p><img src="https://i.loli.net/2019/08/01/5d42afd32fc7340149.jpg" alt="2019-05-18-061202.jpg" style="zoom:50%;"></p>
<ul>
<li><p><strong>==簇：一个基于密度的簇是最大的密度相连对象的集合。==</strong></p>
</li>
<li><p><strong>噪声</strong>：不包含在任何簇中的对象称为噪声。</p>
</li>
</ul>
<p>从下图可以很容易看出理解上述定义，图中 <img src="https://www.zhihu.com/equation?tex=MinPts%3D5" alt="[公式]"> ，红色的点都是核心对象，因为其 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域至少有 <img src="https://www.zhihu.com/equation?tex=5" alt="[公式]"> 个样本。黑色的样本是非核心对象。所有核心对象密度直达的样本在以红色核心对象为中心的圆内，如果不在圆内，则不能密度直达。图中用绿色箭头连起来的核心对象组成了密度可达的样本序列，此序列是一个簇集。在这些密度可达的样本序列的 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域内所有的样本相互都是密度相连的 <strong>(注意，此图中有两个簇集)</strong>。</p>
<p><img src="https://pic2.zhimg.com/80/v2-7d15fc871942e0287be42a12d6d615dd_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h3><span id="23-dbscan密度聚类思想">2.3 DBSCAN密度聚类思想</span></h3><p><strong>DBSCAN的聚类定义很简单</strong>： <strong>由密度可达关系导出的最大密度相连的样本集合，即为我们最终聚类的一个类别，或者说一个簇。（注意是密度相连的集合）</strong>，簇里面可以有一个或者多个核心对象。<strong>如果只有一个核心对象，则簇里其他的非核心对象样本都在这个核心对象的</strong> <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> <strong>-邻域里；如果有多个核心对象，则簇里的任意一个核心对象的</strong> <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -<strong>邻域中一定有一个其他的核心对象，否则这两个核心对象无法密度可达</strong>。这些核心对象的 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域里所有的样本的集合组成的一个DBSCAN聚类簇。</p>
<p>那么怎么才能找到这样的簇样本集合呢？DBSCAN使用的方法很简单，它任意选择一个没有类别的核心对象作为种子，然后找到所有这个核心对象能够<strong>密度可达</strong>的样本集合，即为一个聚类簇。接着继续选择另一个没有类别的核心对象去寻找<strong>密度可达</strong>的样本集合，这样就得到另一个聚类簇 <strong>（这样的得到都肯定是密度相连的）</strong>。一直运行到<strong>所有核心对象都有类别为止。</strong></p>
<p>基本上这就是DBSCAN算法的主要内容了，是不是很简单？<strong>但是我们还是有三个问题没有考虑。</strong></p>
<ul>
<li><strong>异常点问题：</strong>一些异常样本点或者说少量游离于簇外的样本点，这些点不在任何一个核心对象在周围，在DBSCAN中，我们一般将这些样本点标记为噪音点。</li>
<li><strong>距离度量问题</strong>：<strong><font color="red"> 即如何计算某样本和核心对象样本的距离</font></strong>。在DBSCAN中，一般采用最近邻思想，采用某一种距离度量来衡量<strong>样本距离，比如欧式距离、曼哈顿距离</strong>等。</li>
<li><strong>数据点优先级分配问题</strong>：例如某些样本可能到两个核心对象的距离都小于 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> ，但是这两个核心对象由于不是密度直达，又不属于同一个聚类簇，那么如果界定这个样本的类别呢？一般来说，<strong>此时 DBSCAN采用先来后到，先进行聚类的类别簇会标记这个样本为它的类别。也就是说DBSCAN的算法不是完全稳定的算法。</strong></li>
</ul>
<h3><span id="24-算法步骤">2.4 算法步骤</span></h3><p><strong>输入：样本集 <img src="https://www.zhihu.com/equation?tex=D%3D%5C%7Bx_1%2Cx_2%2C...%2Cx_m%5C%7D" alt="[公式]"> ，邻域参数 <img src="https://www.zhihu.com/equation?tex=%28%CF%B5%2CMinPts%29" alt="[公式]"></strong></p>
<ol>
<li>初始化核心对象集合 <img src="https://www.zhihu.com/equation?tex=%CE%A9%3D%E2%88%85%2C" alt="[公式]"> 初始化类别 <img src="https://www.zhihu.com/equation?tex=k%3D0" alt="[公式]"></li>
<li>遍历 <img src="https://www.zhihu.com/equation?tex=D" alt="[公式]"> 的元素，如果是核心对象，则将其加入到核心对象集合 <img src="https://www.zhihu.com/equation?tex=%CE%A9" alt="[公式]"> 中</li>
<li>如果核心对象集合 <img src="https://www.zhihu.com/equation?tex=%CE%A9" alt="[公式]"> 中元素都已经被<strong>访问</strong>，<strong>则算法结束</strong>，<strong>否则转入步骤4</strong>.</li>
<li>在核心对象集合 <img src="https://www.zhihu.com/equation?tex=%CE%A9" alt="[公式]"> 中，随机选择一个<strong>未访问</strong>的核心对象 <img src="https://www.zhihu.com/equation?tex=o" alt="[公式]"> ，首先将 <img src="https://www.zhihu.com/equation?tex=o" alt="[公式]"> 标记为<strong>已访问</strong>，然后将 <img src="https://www.zhihu.com/equation?tex=o" alt="[公式]"> 标记类别 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> ，最后将 <img src="https://www.zhihu.com/equation?tex=o" alt="[公式]"> 的 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域中<strong>未访问</strong>的数据，存放到种子集合 <img src="https://www.zhihu.com/equation?tex=Seeds" alt="[公式]"> 中。</li>
<li>如果种子集合 <img src="https://www.zhihu.com/equation?tex=Seeds%3D%E2%88%85" alt="[公式]"> ，则当前聚类簇 <img src="https://www.zhihu.com/equation?tex=C_k" alt="[公式]"> 生成完毕, 且 <img src="https://www.zhihu.com/equation?tex=k%3Dk%2B1" alt="[公式]"> ，<strong>跳转到3</strong>。否则，从种子集合 <img src="https://www.zhihu.com/equation?tex=Seeds" alt="[公式]"> 中挑选一个种子点 <img src="https://www.zhihu.com/equation?tex=seed" alt="[公式]"> ，首先将其标记为已访问、标记类别 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> ，然后判断 <img src="https://www.zhihu.com/equation?tex=seed" alt="[公式]"> 是否为核心对象，如果是将 <img src="https://www.zhihu.com/equation?tex=seed" alt="[公式]"> 中<strong>未访问</strong>的种子点加入到种子集合中，<strong>跳转到5</strong>。</li>
</ol>
<p><strong>从上述算法可知：</strong></p>
<ul>
<li><strong>每个簇至少包含一个核心对象</strong>；</li>
<li>非核心对象可以是簇的一部分，构成了簇的边缘（edge）；</li>
<li>包含过少对象的簇被认为是噪声；</li>
</ul>
<h3><span id="25-总结">2.5 总结</span></h3><h4><span id="优点">优点</span></h4><ol>
<li><strong>可以对任意形状的稠密数据集进行聚类</strong>，相对的，K-Means之类的聚类算法一般只适用于凸数据集。</li>
<li><strong>可以在聚类的同时发现异常点</strong>，对数据集中的异常点不敏感。</li>
<li>聚类结果没有偏倚，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。</li>
</ol>
<h4><span id="缺点">缺点</span></h4><ol>
<li><strong>不能处理密度差异过大（密度不均匀）的聚类</strong>：如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合。</li>
<li>如果样本集较大时，聚类收敛时间较长;<strong>此时可以对搜索最近邻时建立的KD树或者球树进行规模限制来改进；</strong></li>
<li>调参相对于传统的K-Means之类的聚类算法稍复杂，<strong>主要需要对距离阈值ϵ，邻域样本数阈值MinPts联合调参，不同的参数组合对最后的聚类效果有较大影响</strong>。【OPTICS算法】</li>
<li><strong>边界点不完全确定性</strong></li>
</ol>
<h3><span id="26-optics算法">2.6 OPTICS算法:</span></h3><p><strong>OPTICS主要针对输入参数$ϵ$过敏感做的改进</strong>，OPTICS和DBSCNA的输入参数一样（ <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=MinPts" alt="[公式]"> ），虽然OPTICS算法中也需要两个输入参数，但该算法对 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 输入不敏感（一般将 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 固定为无穷大），同时该算法中并不显式的生成数据聚类，只是对数据集合中的对象进行排序，得到一个有序的对象列表，通过该有序列表，可以得到一个决策图，通过决策图可以不同 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 参数的数据集中检测簇集，即：<strong>先通过固定的 <img src="https://www.zhihu.com/equation?tex=MinPts" alt="[公式]"> 和无穷大的 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 得到有序列表，然后得到决策图，通过决策图可以知道当 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 取特定值时（比如 <img src="https://www.zhihu.com/equation?tex=%CF%B5%3D3" alt="[公式]"> )数据的聚类情况。</strong></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>聚类</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（14）聚类*-Kmeans</title>
    <url>/posts/26FYF9Q/</url>
    <content><![CDATA[<h2><span id="聚类算法-无监督">聚类算法 【无监督】</span></h2><blockquote>
<p>  常用聚类算法 - 小胡子的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/104355127">https://zhuanlan.zhihu.com/p/104355127</a></p>
<p>  <strong>K-means, K-medians, K-mediods and K-centers</strong> - 仲基的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/398600714">https://zhuanlan.zhihu.com/p/398600714</a></p>
</blockquote>
<p>什么是聚类算法？聚类是一种机器学习技术，它涉及到数据点的分组。给定一组数据点，我们可以使用聚类算法将每个数据点划分为一个特定的组。理论上，同一组中的数据点应该具有相似的属性和/或特征，而不同组中的数据点应该具有高度不同的属性和/或特征。<strong>聚类是一种无监督学习的方法</strong>，是许多领域中常用的统计数据分析技术。</p>
<p><strong>聚类算法主要包括以下五类：</strong></p>
<ul>
<li><strong>基于分层的聚类（hierarchical methods）</strong></li>
</ul>
<p>这种方法对给定的数据集进行逐层，直到某种条件满足为止。具体可分为合并型的“自下而上”和分裂型的“自下而上”两种方案。如在“自下而上”方案中，初始时每一个数据记录都组成一个单独的组，在接下来的迭代中，它把那些相互邻近的组合并成一个组，直到所有的记录组成一个分组或者某个条件满足为止。<strong>代表算法有：<em>BIRCH算法</em>（1996）、<em>CURE算法</em>、CHAMELEON算法等。</strong></p>
<blockquote>
<p>  层次聚类通过计算不同类别数据点间的相似度来创建一棵有层次的嵌套聚类树。在聚类树中，不同类别的原始数据点是树的最低层，树的顶层是一个聚类的根节点。</p>
<p>  <strong>最小距离的层次聚类算法</strong>通过自下而上合并创建聚类树，合并算法通过计算两类数据点间的欧式距离来计算不同类别数据点间的相似度，对所有数据点中最为相似的两个数据点进行组合，组合后，最小距离（Single Linkage）的计算方法是将两个组合数据点中距离最近的两个数据点间的距离作为这两个组合数据点的距离。并反复迭代这一过程。</p>
</blockquote>
<ul>
<li><strong>基于划分的聚类（partitioning methods）</strong></li>
</ul>
<p>给定一个有N个记录的数据集，分裂法将构造K个分组，每一个分组就代表一个聚类，K&lt;N,而且这K个分组满足下列条件：（1）每一个分组至少包含一个数据记录；（2）每一个数据记录属于且仅属于一个分组（咋某些模糊聚类算法中可以放宽条件）。对于给定的K，算法首先给出一个初始的分组方法，以后通过反复迭代的方法改变分组，使得每一次改进之后的分组方案都较前一次好，而所谓好的标准是：同一分组中的记录越近越好，而不同分组中的记录越远越好。使用这个基本思想的算法有：<strong><em>==K-means算法==</em>、<em>K-medoids算法</em>、<em>CLARANS算法</em></strong></p>
<ul>
<li><strong>基于密度的聚类（density-based methods）</strong></li>
</ul>
<p>基于密度的方法和其他方法的一个根本区别是：它不是基于各种各样的距离的，而是基于魔都的，这样就能克服基于距离的算法只能发现“类圆形”的聚类的缺点。这个方法的指导思想为：只要一个区域的点的密度大过某个阈值，就把它加到与之相近的聚类中去，代表算法有<strong>：<em>==DBSCAN（Density-Based Spatial Clustering of Applic with Noise）==算法（1996）</em>、<em>OPTICS（Ordering Points to Identify Clustering Structure）算法（1999）</em>、<em>DENCLUE算法（1998）</em>、<em>WaveCluster算法（1998，具有O（N）时间复杂性，但只适用于低维数据）</em></strong></p>
<ul>
<li><strong>基于网格的聚类（grid-based methods）</strong></li>
</ul>
<p>这种方法首先将数据空间划分成为有限个单元（cell）的网络结构，所有的处理都是以单个的单元为对象的。这么处理的一个突出的优点就是处理速度很快，通常这是与目标数据库中记录的个数无关，它只与把数据空间分成多少个单元有关。代表算法有：<strong><em>STING（Statistical Information Grid）</em>、<em>CLIQUE（Clustering In Quest）算法（1998）</em>、<em>WaveCluster算法</em>。</strong>其中STRING算法把数据空间层次地划分为单元格，依赖于存储在网格单元中的统计信息进行聚类；CLIQUE算法结合了密度和网格的方法。</p>
<ul>
<li><strong>基于模型的聚类（model-based methods）</strong></li>
</ul>
<p>基于模型的方法给每一个聚类假定一个模型，然后去寻找能够很好地满足这个模型的数据集。这样一个模型可能是数据点在空间中的密度分布函数或者其它。它的一个潜在的假定就是：目标数据集是由一系列的概率分布所决定的。通常有两种尝试方向：统计的方案和神经网络的方案。</p>
<h2><span id="一-k-means-基于划分k值的选择">一、K-means 【基于划分】[==K值的选择？==]</span></h2><p><img src="https://pic1.zhimg.com/v2-e7195b6620e2e6ec743fb77702b1d3ff_1440w.jpg?source=172ae18b" alt="【机器学习】K-means（非常详细）" style="zoom:51%;"></p>
<blockquote>
<p>  K-means 聚类的迭代算法实际上是 EM 算法。EM 算法解决的是在概率模型中含有无法观测的隐含变量情况下的参数估计问题。在 K-means 中的隐变量是每个类别所属类别。</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/20463356">K-means 笔记（三）数学原理</a></li>
<li><a href="https://link.zhihu.com/?target=http%3A//sofasofa.io/forum_main_post.php%3Fpostid%3D1000282">K-means 怎么选 K?</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/161733843">K-Means：隐变量、聚类、EM</a></li>
</ol>
</blockquote>
<p>k近邻法中，当<strong>训练集</strong>、<strong>距离度量</strong>、<strong>K值</strong>以及<strong>分类决策规则</strong>确定后，对于任何一个新的输入实例，它所属的类唯一地确定。这相当于根据上述要素将特征空间划分为一些子空间，确定子空间里的每个点所属的类。</p>
<p><strong>K-均值是一个迭代算法，假设我们想要将数据聚类成 n 个组，其方法为:</strong></p>
<ul>
<li>首先选择𝐾个<strong>随机</strong>的点，称为<strong>聚类中心</strong>（cluster centroids）；</li>
<li>对于数据集中的每一个数据，按照<strong>距离𝐾个中心点的距离</strong>，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类。</li>
<li>计算每一个组的平均值，将该组所<strong>关联的中心点移动到平均值</strong>的位置。</li>
<li>重复步骤，直至中心点不再变化。</li>
</ul>
<p>K-均值算法也可以很便利地用于将数据分为许多不同组，即使在没有非常明显区分的组群的情况下也可以。下图所示的数据集包含身高和体重两项特征构成的，利用 K-均值算法将数据分为三类，用于帮助确定将要生产的 T-恤衫的三种尺寸。</p>
<p><img src="https://camo.githubusercontent.com/86b1cfa2d801f27862bcc8cab59f04401e01defd5248311eb77ec75a02286c5f/687474703a2f2f7778332e73696e61696d672e636e2f6d773639302f30303633304465666c79316735623734367a776a676a33306668306337676e6a2e6a7067" alt="img" style="zoom: 50%;"></p>
<h3><span id="11-损失函数">1.1 损失函数</span></h3><p><strong>K-均值最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和</strong>，因此 <strong>K-均值的代价函数（又称==畸变函数 Distortion function）==为</strong>：</p>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20220707191400653.png" alt="image-20220707191400653" style="zoom:50%;"></p>
<p>其中 <a href="https://camo.githubusercontent.com/c0d78bacde143a412a432d0f2c8d1a746fc34802fec6dfd079a07708e30a98f4/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f755f25374263253545253742286929253744253744"><img src="https://camo.githubusercontent.com/c0d78bacde143a412a432d0f2c8d1a746fc34802fec6dfd079a07708e30a98f4/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f755f25374263253545253742286929253744253744" alt="img"></a>代表与 <a href="https://camo.githubusercontent.com/b14a6424262c05d4fb45a600d8fb5b4881cee4801e8699dcc0c58ef503164f94/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f78253545253742286929253744"><img src="https://camo.githubusercontent.com/b14a6424262c05d4fb45a600d8fb5b4881cee4801e8699dcc0c58ef503164f94/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f78253545253742286929253744" alt="img"></a>最近的聚类中心点。 我们的的优化目标便是找出使得代价函数最小的 <a href="https://camo.githubusercontent.com/c48ec5ec6d35ce0993ee193bc86c0d4eddb3dbac31e30fa1f38fbf56b1401083/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f632535452537422831292537442c632535452537422832292537442c2e2e2e2c63253545253742286d29253744"><img src="https://camo.githubusercontent.com/c48ec5ec6d35ce0993ee193bc86c0d4eddb3dbac31e30fa1f38fbf56b1401083/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f632535452537422831292537442c632535452537422832292537442c2e2e2e2c63253545253742286d29253744" alt="img"></a>和 <a href="https://camo.githubusercontent.com/d287d301a22d8bb905fe7e82874a282adff45c972a158b7a2cb91f0354a4ae84/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f755f312c755f322c2e2e2e2c755f6b"><img src="https://camo.githubusercontent.com/d287d301a22d8bb905fe7e82874a282adff45c972a158b7a2cb91f0354a4ae84/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f755f312c755f322c2e2e2e2c755f6b" alt="img"></a>。</p>
<h3><span id="12-k值的选择-肘部法则">1.2 k值的选择 【肘部法则】</span></h3><p>在运行 K-均值算法的之前，我们首先要随机初始化所有的聚类中心点，下面介绍怎样做：</p>
<ol>
<li>我们应该选择𝐾 &lt; 𝑚，即聚类中心点的个数要小于所有训练集实例的数量。</li>
<li>随机选择𝐾个训练实例，然后令𝐾个聚类中心分别与这𝐾个训练实例相等K-均值的一个问题在于，它有可能会<strong>停留在一个局部最小值</strong>处，而这取决于初始化的情况。</li>
</ol>
<p>为了解决这个问题，我们通常需要多次运行 K-均值算法，每一次都重新进行随机初始化，最后再比较多次运行 K-均值的结果，选择代价函数最小的结果。这种方法在𝐾较小的时候（2—10）还是可行的，<strong>但是如果𝐾较大，这么做也可能不会有明显地改善。</strong></p>
<p>没有所谓最好的选择聚类数的方法，通常是需要根据不同的问题，人工进行选择的。选择的时候思考我们运用 K-均值算法聚类的动机是什么。有一个可能会谈及的方法叫作<strong>“肘部法则”</strong>。关 于“肘部法则”，我们所需要做的是改变𝐾值，也就是聚类类别数目的总数。我们用一个聚类来运行 K 均值聚类方法。这就意味着，所有的数据都会分到一个聚类里，然后<strong>计算成本函数或者计算畸变函数</strong>𝐽。𝐾代表聚类数字。</p>
<p><a href="https://camo.githubusercontent.com/8888198abee1b3069d27a6bff19f1830a94ac4141ebe7dd300f8ee4000262c6d/687474703a2f2f7778322e73696e61696d672e636e2f6d773639302f30303633304465666c7931673562377062616561766a3330716f3063777463392e6a7067"><img src="https://camo.githubusercontent.com/8888198abee1b3069d27a6bff19f1830a94ac4141ebe7dd300f8ee4000262c6d/687474703a2f2f7778322e73696e61696d672e636e2f6d773639302f30303633304465666c7931673562377062616561766a3330716f3063777463392e6a7067" alt="img"></a></p>
<p>我们可能会得到一条类似于这样的曲线。像一个人的肘部。这就是“肘部法则”所做的，让我们来看这样一个图，看起来就好像有一个很清楚的肘在那儿。你会发现这种模式，它的畸变值会迅速下降，从 1 到 2，从 2 到 3 之后，你会在 3 的时候达到一个肘点。在此之后，畸变值就下降的非常慢，看起来就像使用 3 个聚类来进行聚类是正确的，<strong>这是因为那个点是曲线的肘点，畸变值下降得很快，𝐾 = 3之后就下降得很慢，那么我们就选𝐾 = 3。</strong>当你应用“肘部法则”的时候，如果你得到了一个像上面这样的图，那么这将是一种用来选择聚类个数的合理方法。</p>
<h3><span id="13-knn与k-means区别">1.3 KNN与K-means区别？</span></h3><p>K最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。</p>
<h4><span id="区别">区别：</span></h4><div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>KNN</th>
<th>K-Means</th>
</tr>
</thead>
<tbody>
<tr>
<td>类别</td>
<td>1.KNN是<strong>分类</strong>算法 2.属于<strong>监督学习</strong> 3.训练数据集是带label的数据</td>
<td>1.K-Means是<strong>聚类</strong>算法 2.属于<strong>非监督学习</strong> 3.训练数据集是无label的数据，是杂乱无章的，经过聚类后变得有序，先无序，后有序。</td>
</tr>
<tr>
<td></td>
<td>没有明显的前期训练过程，属于memory based learning</td>
<td>有明显的前期训练过程</td>
</tr>
<tr>
<td>k值的含义</td>
<td>K的含义：一个样本x，对它进行分类，就从训练数据集中，<strong>在x附近找离它最近的K个数据点</strong>，这K个数据点，类别c占的个数最多，就把x的label设为c。</td>
<td>K的含义：<strong>K是人工固定好的数字，假设数据集合可以分为K个蔟</strong>，那么就利用训练数据来训练出这K个分类。</td>
</tr>
</tbody>
</table>
</div>
<h4><span id="相似点"><strong>相似点</strong>：</span></h4><p>都包含这样的过程，给定一个点，在数据集中找离它最近的点。即二者都用到了NN(Nears Neighbor)算法思想。</p>
<h3><span id="14-k-means优缺点及改进">1.4 K-Means优缺点及改进</span></h3><p>k-means：在大数据的条件下，<strong>会耗费大量的时间和内存</strong>。 优化k-means的建议：</p>
<ol>
<li><p>减少聚类的数目K。因为，每个样本都要跟类中心计算距离。</p>
</li>
<li><p>减少样本的特征维度。比如说，<strong>通过PCA等进行降维</strong>。</p>
</li>
<li><p>考察其他的聚类算法，通过选取toy数据，去测试不同聚类算法的性能。</p>
</li>
<li><p><strong>hadoop集群</strong>，K-means算法是很容易进行并行计算的。</p>
</li>
<li><p>算法可能找到局部最优的聚类，而不是全局最优的聚类。使用改进的二分k-means算法。</p>
<p>二分k-means算法：首先将整个数据集看成一个簇，然后进行一次k-means（k=2）算法将该簇一分为二，并计算每个簇的误差平方和，选择平方和最大的簇迭代上述过程再次一分为二，直至簇数达到用户指定的k为止，此时可以达到的全局最优。</p>
</li>
</ol>
<h3><span id="二-k-means的调优与改进">二、K - means的调优与改进</span></h3><p>针对 K-means 算法的缺点，我们可以有很多种调优方式：如<strong>数据预处理</strong>（去除异常点），<strong>合理选择 K 值</strong>，<strong>高维映射</strong>等。以下将简单介绍：</p>
<h3><span id="21-数据预处理">2.1 数据预处理</span></h3><p>K-means 的本质是基于欧式距离的数据划分算法，均值和方差大的维度将对数据的聚类产生决定性影响。所以<strong>未做归一化处理和统一单位的数据是无法直接参与运算和比较</strong>的。常见的数据预处理方式有：<strong>数据归一化，数据标准化</strong>。</p>
<p>此外，离群点或者噪声数据会对均值产生较大的影响，导致中心偏移，因此我们还需要对数据进行异常点检测。</p>
<h3><span id="22-合理选择-k-值">2.2 合理选择 K 值</span></h3><p>K 值的选取对 K-means 影响很大，这也是 K-means 最大的缺点，常见的选取 K 值的方法有：<strong>手肘法、Gap statistic 方法</strong>。</p>
<p><strong>【手肘法】</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-5ca4a5fe0b06b25a2b97262abb401a16_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>当 K &lt; 3 时，曲线急速下降；当 K &gt; 3 时，曲线趋于平稳，通过手肘法我们认为拐点 3 为 K 的最佳值。</p>
<p>==【<strong>Gap statistic</strong>】==</p>
<p><img src="https://www.zhihu.com/equation?tex=Gap%28K%29%3D%5Ctext%7BE%7D%28%5Clog+D_k%29-%5Clog+D_k+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=D_k" alt="[公式]"> 为损失函数，这里 <img src="https://www.zhihu.com/equation?tex=E%28logD_k%29" alt="[公式]"> 指的是 <img src="https://www.zhihu.com/equation?tex=logD_k" alt="[公式]"> 的期望。这个数值通常通过<strong>蒙特卡洛模拟</strong>产生，我们在样本里所在的区域中按照<strong>均匀分布随机产生和原始样本数一样多的随机样本</strong>，并对这个<strong>随机样本做 K-Means</strong>，从而得到一个 <img src="https://www.zhihu.com/equation?tex=D_k+" alt="[公式]"> 。如此往复多次，通常 20 次，我们可以得到 20 个 <img src="https://www.zhihu.com/equation?tex=logD_k" alt="[公式]"> 。对这 20 个数值求平均值，就得到了 <img src="https://www.zhihu.com/equation?tex=E%28logD_k%29" alt="[公式]">  的近似值。最终可以计算 Gap Statisitc。而 Gap statistic 取得最大值所对应的 K 就是最佳的 K。</p>
<p><img src="https://pic3.zhimg.com/80/v2-9a39a8dad143e5dd52a506d83c2cbb36_1440w.jpg" alt="img"></p>
<p>由图可见，当 K=3 时，Gap(K) 取值最大，所以最佳的簇数是 K=3。</p>
<p>Github 上一个项目叫 <a href="https://link.zhihu.com/?target=https%3A//github.com/milesgranger/gap_statistic">gap_statistic</a> ，可以更方便的获取建议的类簇个数。</p>
<h3><span id="23-采用核函数">2.3 采用核函数</span></h3><p><strong>基于欧式距离的 K-means 假设了了各个数据簇的数据具有一样的的先验概率并呈现球形分布</strong>，但这种分布在实际生活中并不常见。面对非凸的数据分布形状时我们可以引入核函数来优化，这时算法又称为核 K-means 算法，是核聚类方法的一种。<strong>核聚类方法的主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的特征空间中进行聚类。</strong>非线性映射增加了数据点线性可分的概率，从而在经典的聚类算法失效的情况下，通过引入核函数可以达到更为准确的聚类结果。</p>
<h3><span id="24-k-means">==2.4 K-means++==</span></h3><blockquote>
<p>  <strong>K-means++ 就是选择离已选中心点最远的点</strong>。这也比较符合常理，聚类中心当然是互相离得越远越好。</p>
</blockquote>
<p>我们知道初始值的选取对结果的影响很大，对初始值选择的改进是很重要的一部分。在所有的改进算法中，K-means++ 最有名。</p>
<p>K-means++ 算法步骤如下所示：</p>
<ol>
<li>随机选取一个中心点 <img src="https://www.zhihu.com/equation?tex=a_1" alt="[公式]"> ；</li>
<li>计算数据到之前 n 个聚类中心最远的距离 <img src="https://www.zhihu.com/equation?tex=D%28x%29" alt="[公式]"> ，并以一定概率 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7BD%28x%29%5E2%7D%7B%5Csum%7BD%28x%29%5E2%7D%7D" alt="[公式]"> 选择新中心点 <img src="https://www.zhihu.com/equation?tex=a_i" alt="[公式]"> ；</li>
<li>重复第二步。</li>
</ol>
<p>简单的来说，就是 <strong>K-means++ 就是选择离已选中心点最远的点</strong>。这也比较符合常理，聚类中心当然是互相离得越远越好。</p>
<p>但是这个算法的缺点在于，难以并行化。所以 k-means II 改变取样策略，并非按照 k-means++ 那样每次遍历只取样一个样本，而是每次遍历取样 k 个，重复该取样过程 <img src="https://www.zhihu.com/equation?tex=log%28n+%29" alt="[公式]"> 次，则得到 <img src="https://www.zhihu.com/equation?tex=klog%28n%29" alt="[公式]"> 个样本点组成的集合，然后从这些点中选取 k 个。当然一般也不需要 <img src="https://www.zhihu.com/equation?tex=log%28n%29" alt="[公式]"> 次取样，5 次即可。</p>
<h3><span id="25-isodata">2.5 ISODATA</span></h3><p>ISODATA 的全称是<strong>迭代自组织数据分析法</strong>。它解决了 K 的值需要预先人为的确定这一缺点。而当遇到高维度、海量的数据集时，人们往往很难准确地估计出 K 的大小。ISODATA 就是针对这个问题进行了改进，它的思想也很直观：当属于某个类别的样本数过少时把这个类别去除，当属于某个类别的样本数过多、分散程度较大时把这个类别分为两个子类别。</p>
<h3><span id="三-收敛证明em算法">==三、 收敛证明【EM算法】==</span></h3><p>我们先来看一下 K-means 算法的步骤：先随机选择初始节点，然后计算每个样本所属类别，然后通过类别再跟新初始化节点。这个过程有没有想到之前介绍的 <a href="https://zhuanlan.zhihu.com/p/78311644">EM 算法</a> 。</p>
<p>我们需要知道的是 K-means 聚类的迭代算法实际上是 EM 算法。EM 算法解决的是在概率模型中含有无法观测的隐含变量情况下的参数估计问题。在 <strong>==K-means 中的隐变量是每个样本所属类别==</strong>。</p>
<p>K-means 算法迭代步骤中的每次确认中心点以后重新进行标记对应 EM 算法中的 <strong>E 步</strong>：<strong>求当前参数条件下的 Expectation</strong>。而根据标记重新求中心点 对应 EM 算法中的 <strong>M 步</strong>：<strong>求似然函数最大化时（损失函数最小时）对应的参数 。</strong></p>
<p>首先我们看一下损失函数的形式：</p>
<p><img src="https://www.zhihu.com/equation?tex=J%3D%5Csum_%7Bi%3D1%7D%5E%7BC%7D%7B%5Csum_%7Bj%3D1%7D%5E%7BN%7D%7Br_%7Bij%7D%5Ccdot+%7B%5Cnu%28x_j%2C%7B%5Cmu%7D_i%29%7D%7D%7D+%5C%5C" alt="[公式]"></p>
<p>其中：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cnu%28%7Bx_j%7D%2C%5Cmu_i%29%3D%7B%7C%7Cx_j-%7B%5Cmu%7D_i%7C%7C%7D%5E%7B2%7D+%2C%5Cquad++%7Br%7D_%7Bnk%7D%3D%5Cleft+%5C%7B+%5Cbegin%7Baligned%7D+%261+%5Cquad+if+%5C%3B+x_n+%5Cin+k+%5C%5C+%260+%5Cquad+else+%5Cend%7Baligned%7D+%5Cright.+%5C%5C" alt="[公式]"></p>
<p>为了求极值，我们令损失函数求偏导数且等于 0：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%7BJ%7D%7D%7B%5Cpartial+%5Cmu_k%7D%3D2+%5Csum_%7Bi%3D1%7D%5E%7BN%7D%7Br_%7Bik%7D%28x_i-%7B%5Cmu%7D_%7Bk%7D%29%7D%3D0+%5C%5C" alt="[公式]"></p>
<p>k 是指第 k 个中心点，于是我们有：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cmu_k%3D%5Cfrac%7B%5Csum_%7Bi%3D1%7D%5E%7BN%7D%7Br_%7Bik%7Dx_i%7D%7D%7B%5Csum_%7Bi%3D1%7D%5E%7BN%7D%7Br_%7Bik%7D%7D%7D+%5C%5C" alt="[公式]"></p>
<p>可以看出，新的中心点就是所有该类的<strong>质心</strong>。</p>
<p><strong>EM 算法的缺点就是，容易陷入局部极小值，这也是 K-means 有时会得到局部最优解的原因。</strong></p>
<h3><span id="四-高斯混合模型gmm">四、高斯混合模型(GMM)</span></h3><h3><span id="41-gmm的思想">4.1 GMM的思想</span></h3><p>高斯混合模型（Gaussian Mixed Model，GMM）也是一种常见的聚类算法，与K均值算法类似，同样使用了EM算法进行迭代计算。<strong>高斯混合模型假设每个簇的数据都是符合高斯分布（又叫正态分布）的</strong>，当前<strong>数据呈现的分布就是各个簇的高斯分布叠加在一起的结果。</strong></p>
<p>第一张图是一个数据分布的样例，如果只用一个高斯分布来拟合图中的数据，图 中所示的椭圆即为高斯分布的二倍标准差所对应的椭圆。直观来说，图中的数据 明显分为两簇，因此只用一个高斯分布来拟和是不太合理的，需要推广到用多个 高斯分布的叠加来对数据进行拟合。第二张图是用两个高斯分布的叠加来拟合得到的结果。<strong>这就引出了高斯混合模型，即用多个高斯分布函数的线形组合来对数据分布进行拟合。</strong>理论上，高斯混合模型可以拟合出任意类型的分布。</p>
<p>高斯混合模型的核心思想是，假设数据可以看作从多个高斯分布中生成出来 的。在该假设下，每个单独的分模型都是标准高斯模型，其均值 $u_i$ 和方差 $\sum_i$ 是待估计的参数。此外，每个分模型都还有一个参数 $\pi_i$，可以理解为权重或生成数据的概 率。高斯混合模型的公式为：</p>
<p><a href="https://camo.githubusercontent.com/4055f35cd39fe2e095b0fc70f8cccb1e3cab924a2ebd6bc56ca7bdcf026c79ec/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f702878293d25354373756d5f253742693d312537442535452537426b25374425354370695f694e2878253743755f692c25354373756d5f6929"><img src="https://camo.githubusercontent.com/4055f35cd39fe2e095b0fc70f8cccb1e3cab924a2ebd6bc56ca7bdcf026c79ec/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f702878293d25354373756d5f253742693d312537442535452537426b25374425354370695f694e2878253743755f692c25354373756d5f6929" alt="img"></a></p>
<p>通常我们并不能直接得到高斯混合模型的参数，而是观察到了一系列 数据点，给出一个类别的数量K后，希望求得最佳的K个高斯分模型。因此，<strong>高斯混合模型的计算，便成了最佳的均值μ，方差Σ、权重π的寻找</strong>，这类问题通常通过最大似然估计来求解。遗憾的是，此问题中直接使用最大似然估计，得到的是一个复杂的非凸函数，目标函数是和的对数，难以展开和对其求偏导。</p>
<p><strong>在这种情况下，可以用EM算法。 </strong>EM算法是在最大化目标函数时，先固定一个变量使整体函数变为凸优化函数，求导得到最值，然后利用最优参数更新被固定的变量，进入下一个循环。具体到高 斯混合模型的求解，EM算法的迭代过程如下。</p>
<p>首先，初始随机选择各参数的值。然后，重复下述两步，直到收敛。</p>
<ul>
<li>E步骤。根据当前的参数，计算每个点由某个分模型生成的概率。</li>
<li>M步骤。使用E步骤估计出的概率，来改进每个分模型的均值，方差和权重。</li>
</ul>
<blockquote>
<p>  高斯混合模型是一个生成式模型。可以这样理解数据的生成过程，假设一个最简单的情况，即只有两个一维标准高斯分布的分模型<em>N</em>(0,1)和<em>N</em>(5,1)，其权重分别为0.7和0.3。那么，在生成第一个数据点时，先按照权重的比例，随机选择一个分布，比如选择第一个高斯分布，接着从<em>N</em>(0,1)中生成一个点，如−0.5，便是第一个数据点。在生成第二个数据点时，随机选择到第二个高斯分布<em>N</em>(5,1)，生成了第二个点4.7。如此循环执行，便生成出了所有的数据点。</p>
</blockquote>
<p>也就是说，我们并不知道最佳的K个高斯分布的各自3个参数，也不知道每个 数据点究竟是哪个高斯分布生成的。所以每次循环时，先固定当前的高斯分布不 变，获得每个数据点由各个高斯分布生成的概率。然后固定该生成概率不变，根据数据点和生成概率，获得一个组更佳的高斯分布。循环往复，直到参数的不再变化，或者变化非常小时，便得到了比较合理的一组高斯分布。</p>
<h3><span id="42-gmm与k-means相比">4.2 GMM与K-Means相比</span></h3><p>高斯混合模型与K均值算法的相同点是：</p>
<ul>
<li><strong>都需要指定K值</strong>；</li>
<li><strong>都是使用EM算法来求解</strong>；</li>
<li>都往往只能收敛于局部最优。</li>
</ul>
<p>而它相比于K 均值算法的优点是，可以给出一个样本属于某类的<strong>概率</strong>是多少；不仅仅可以用于聚类，还可以用于概率密度的估计；<strong>并且可以用于生成新的样本点</strong>。</p>
<h3><span id="五-聚类算法如何评估">五、聚类算法如何评估</span></h3><p>由于数据以及需求的多样性，没有一种算法能够适用于所有的数据类型、数据簇或应用场景，似乎每种情况都可能需要一种不同的评估方法或度量标准。例 如，K均值聚类可以用<strong>误差平方</strong>和来评估，但是基于密度的数据簇可能不是球形， 误差平方和则会失效。在许多情况下，判断聚类算法结果的好坏强烈依赖于主观解释。尽管如此，聚类算法的评估还是必需的，它是聚类分析中十分重要的部分之一。</p>
<p>聚类评估的任务是估计在数据集上进行聚类的可行性，以及聚类方法产生结 果的质量。这一过程又分为三个子任务。</p>
<ol>
<li><p><strong>估计聚类趋势。</strong></p>
<p>这一步骤是检测数据分布中是否存在非随机的簇结构。如果数据是基本随机 的，那么聚类的结果也是毫无意义的。我们可以观察聚类误差是否随聚类类别数 量的增加而单调变化，如果数据是基本随机的，即不存在非随机簇结构，那么聚 类误差随聚类类别数量增加而变化的幅度应该较不显著，并且也找不到一个合适 的K对应数据的真实簇数。</p>
</li>
<li><p><strong>判定数据簇数。</strong></p>
<p>确定聚类趋势之后，我们需要找到与真实数据分布最为吻合的簇数，据此判定聚类结果的质量。数据簇数的判定方法有很多，例如<strong>手肘法</strong>和<strong>Gap Statistic</strong>方 法。需要说明的是，用于评估的最佳数据簇数可能与程序输出的簇数是不同的。 例如，有些聚类算法可以自动地确定数据的簇数，但可能与我们通过其他方法确定的最优数据簇数有所差别。</p>
</li>
<li><p><strong>测定聚类质量。</strong></p>
<p>在无监督的情况下，我们可以通过考察簇的分离情况和簇的紧凑情况来评估聚类的效果。定义评估指标可以展现面试者实际解决和分析问题的能力。事实上测量指标可以有很多种，以下列出了几种常用的度量指标，更多的指标可以阅读相关文献。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>聚类</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（16）聚类*-HDBSCAN</title>
    <url>/posts/1N8XMT6/</url>
    <content><![CDATA[<h2><span id="一-hdbscan聚类">一、HDBSCAN聚类</span></h2><blockquote>
<p>  <strong>图解HDBSCANS - Mr.g的文章</strong> - 知乎 <a href="https://zhuanlan.zhihu.com/p/412918565">https://zhuanlan.zhihu.com/p/412918565</a></p>
<p>  原文: <a href="https://link.zhihu.com/?target=https%3A//nbviewer.jupyter.org/github/scikit-learn-contrib/hdbscan/blob/master/notebooks/How%20HDBSCAN%20Works.ipynb">How HDBSCAN works</a></p>
<p>  聚类算法(Clustering Algorithms)之层次聚类(Hierarchical Clustering) - 小玉的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/363879425">https://zhuanlan.zhihu.com/p/363879425</a></p>
</blockquote>
<p><strong>HDBSCAN 是由 Campello、Moulavi 和 Sander 开发的聚类算法。它通过将 DBSCAN 转换为层次聚类算法，然后用一种稳定的聚类技术提取出一个扁平的聚类来扩展 DBSCAN</strong>。这篇文章的目标是让你大致了解这个算法的工作原理及其背后的动机。与 HDBSCAN 的原论文不一样，我们这里将不将 DBSCAN 进行对照分析。作者这里更倾向将这算法类比成一种扁平聚类提取方法（ Robust Single Linkage ）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets <span class="keyword">as</span> data</span><br><span class="line">%matplotlib inline</span><br><span class="line">sns.set_context(<span class="string">&#x27;poster&#x27;</span>)</span><br><span class="line">sns.set_style(<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">sns.set_color_codes()</span><br><span class="line">plot_kwds = &#123;<span class="string">&#x27;alpha&#x27;</span> : <span class="number">0.5</span>, <span class="string">&#x27;s&#x27;</span> : <span class="number">80</span>, <span class="string">&#x27;linewidths&#x27;</span>:<span class="number">0</span>&#125;</span><br><span class="line"></span><br><span class="line">moons, _ = data.make_moons(n_samples=<span class="number">50</span>, noise=<span class="number">0.05</span>)</span><br><span class="line">blobs, _ = data.make_blobs(n_samples=<span class="number">50</span>, centers=[(-<span class="number">0.75</span>,<span class="number">2.25</span>), (<span class="number">1.0</span>, <span class="number">2.0</span>)], cluster_std=<span class="number">0.25</span>)</span><br><span class="line">test_data = np.vstack([moons, blobs])</span><br><span class="line">plt.scatter(test_data.T[<span class="number">0</span>], test_data.T[<span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, **plot_kwds)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hdbscan</span><br><span class="line">clusterer = hdbscan.HDBSCAN(min_cluster_size=<span class="number">5</span>, gen_min_span_tree=<span class="literal">True</span>)</span><br><span class="line">clusterer.fit(test_data)</span><br></pre></td></tr></table></figure>
<p><strong>现在我们已经对数据聚类完了——但实际发生了什么我们还不知道。我们将拆解成下面5个步骤来进行分析：</strong></p>
<ol>
<li>根据 密度/稀疏度 进行<strong>空间转换</strong>。</li>
<li>构建基于加权距离图的最小生成树。</li>
<li>构建组件之间的层次簇结构。</li>
<li>用最小簇大小压缩层次聚类。</li>
<li>利用压缩好的生成树进行分类。</li>
</ol>
<h3><span id="11-空间转换">1.1 空间转换</span></h3><p><strong>聚类时我们希望在稀疏带噪声的数据中找到密度更高的族类——噪声的假设很重要</strong>：因为在真实情况下，数据都比较复杂，会有异常值的、缺失的数据和噪声等情况。算法的核心是单链聚类，它对噪声非常敏感：如果噪声数据点放在两个岛屿之间，可能就会将它们连在一起（也就是本来是两个族类的被分成一个）。显然，我们希望我们的算法对噪声具有鲁棒性，因此我们需要在运行单链算法之前找到一种方法来减少噪声。（作者用岛屿来比喻族类，海洋来表示噪声，下面“海洋”和“岛屿”代表这个意思。）</p>
<p><strong>我们要如何在不进行聚类的情况下找出“海洋”和“岛屿”？</strong>只要我们能够估算出样本集的密度，我们就可以认为密度较低的点都是“海洋”。要注意的是这里的目标不是完全区分出“海洋”和“岛屿”——现在只是聚类的初始步骤，并不是最终的输出——现在只是为了使我们的聚类中心对噪声更加鲁棒。因此，要识别出“海洋”的话，我们可以降低海平面（也就是加大容错范围）。出于实际目的，这意味着使每个“海洋”之间以及“海洋”与“岛屿”之间的距离会增加。</p>
<p>当然这只是直觉。它在实际中是如何工作的？我们需要一个计算量少的密度估计方式，简单到只要计算 k 个最近邻点的距离就可以。<strong><font color="red"> 我们可以直接从一个距离矩阵（不管怎样后面都要生成的）中地读取到这个距离；或者，如果我们的指标支持（并且维度较低），用 <a href="https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/neighbors.html%23k-d-tree">kd-trees</a> 来做这种检索就很适合。</font></strong>下面正式将点 x 的参数 k 定义为<strong>核心距离</strong>，并表示为 <img src="https://www.zhihu.com/equation?tex=core_k%28x%29" alt="[公式]"> （与DBSCAN、LOF 和 HDBSCAN 文献一样）。现在我们需要一种降维方法来拉开点之间的距离（相对高维距离）。简单的方法是定义一种新距离公式，我们将其称为（与论文一样)<strong>相互可达距离（mutual reachability distance)。相互可达距离的定义如下：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=d_%7B%5Cmathrm%7Bmreach-%7Dk%7D%28a%2Cb%29+%3D+%5Cmax+%5C%7B%5Cmathrm%7Bcore%7D_k%28a%29%2C+%5Cmathrm%7Bcore%7D_k%28b%29%2C+d%28a%2Cb%29+%5C%7D" alt="[公式]" style="zoom: 150%;"></p>
<p><strong>其中 d(a,b) 是 a 和 b 之间的原始距离</strong>。在这个度量下，密集点（具有低核心距离）之间的距离保持不变，但稀疏的点与其他点的距离被拉远到用core距离来计算。这有效地“降低了海平面”，减少稀疏的“海”点，同时使“陆地”保持原状。需要注意的是，显然 k 取值很关键；较大的 k 值将更多的点圈到“海”中。下面用图片来解析更容易理解，先让k=5。然后对于给定的点，我们可以为核心距离绘制一个圆刚好圈到第六个临近点（包括点本身），如下所示：</p>
<p><img src="https://pic2.zhimg.com/80/v2-dbf4559853b0d81f1c5ae2205a7b97a9_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p><strong>再选择另一个点</strong>，进行同样的操作，这次选到另一组临近点集合（其中一些点可能是上一组的临近点）。</p>
<p><img src="https://pic3.zhimg.com/80/v2-308c1bb09e8f779232aac217bee2507e_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p>我们再选一个点再做一遍，得到第三组临近点。</p>
<p><img src="https://pic4.zhimg.com/80/v2-0e0e83ecf594b202cea6d3c208e45f0f_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>如果我们现在想知道蓝绿两组之间的相互可达距离，我们可以像下图，先画一个箭头连接蓝绿两个圆心：它穿过蓝色圆心，但不穿过绿色圆圈——绿色的核心距离大于蓝色和绿色之间的距离。<strong>因此，我们认为蓝色和绿色之间的相互可达距离更大——也就是绿色圆圈的半径（如果我们将一端设在绿色点上，则最容易想象）。</strong></p>
<p>实际上，有<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1506.06422v2.pdf">基础理论</a>可以证明<strong>相互可达距离</strong>作为一种变换，在允许单链接聚类的情况下，更接近层次水平上的真实密度分布。</p>
<h3><span id="12-构建最小生成树"><strong>1.2 构建最小生成树</strong></span></h3><p><strong>为了从密集的数据集上找到“岛屿”，现在我们有了新的指标：相互可达性</strong>。当然密集区是相对的，不同的“岛屿”可能会有不同的密度。<strong><font color="red"> 理论上，我们要做的是：将数据当成是一个加权图，以数据点作为顶点，任意两点之间的边的权重等于这些点的相互可达距离。</font></strong></p>
<p>现在考虑一个阈值，一开始很高，然后逐渐变小。丢弃权重高于该阈值的任何边。我们删除边的同时，连接的组件从图里断开。最终，我们将拥有不同阈值级别的连接元件（从完全连接到完全断开）的层次结构。</p>
<p>实际当中，这样操纵非常耗时：有 <a href="https://zhuanlan.zhihu.com/p/412918565/edit#">n^2</a> 条边，我们不想多次计算连通组件算法。正确的做法是找到最小的边集，从这个集合中删除任何边都会导致组件的连接断开。但是我们还需要找到更多这样的边，使得找不到更小的边来连接组件。幸运的是，图论为我们提供了这样的东西：<strong>图的最小生成树</strong>。</p>
<p>我们可以通过 Prim 的算法非常有效地构建最小生成树——我们一次构建一条边，每次都把当前最小权重的边去连接一个尚未加入到树中的节点。可以看到下面HDBSCAN构造的树 ；请注意，这是相互可达距离的最小生成树，与图中的纯距离不同。在这种情况下，我们的 k 值为 5。 在这个例子中，存在一种更快的方法，例如用 <strong>Dual Tree Boruvka 来构建最小生成树。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">clusterer.minimum_spanning_tree_.plot(edge_cmap=<span class="string">&#x27;viridis&#x27;</span>, </span><br><span class="line">                                      edge_alpha=<span class="number">0.6</span>, </span><br><span class="line">                                      node_size=<span class="number">80</span>, </span><br><span class="line">                                      edge_linewidth=<span class="number">2</span>)   </span><br></pre></td></tr></table></figure>
<p><img src="https://pic2.zhimg.com/80/v2-a4b387ac9c43b1f681589529c82fe68d_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h3><span id="13-构建层次聚类">1.3 <strong>构建层次聚类</strong></span></h3><p><strong>给定最小生成树，下一步是将其转换为层次结构的组件</strong>。这最容易以相反的顺序完成：按距离（按递增顺序）对树的边进行排序，然后迭代，为每条边新建一个合并后的簇。这里唯一困难是识别每条边将连接在哪两个簇上，但这通过联合查找数据结构很容易。我们可以将结果视为树状图，如下所示：</p>
<p><img src="https://pic1.zhimg.com/80/v2-33a8cb27ae3ea0009e1ad77b438cf458_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>这图可以告诉我们这个鲁棒的单一链接会在哪挺下来。我们想知道；层次结构结构的聚类虽好，但我们想要的是一个扁平的聚类。我们可以通过在上图中画一条水平线并选择它穿过的聚类，来做到这一点。这实际上是 DBSCAN 里用到的操作（将只能切割成单一集群的作为噪声）。<strong>问题是，我们怎么知道在哪里画这条线？ DBSCAN 只是把它作为一个（非常不直观的）参数</strong>。更糟糕的是，我们真的要用来处理可变密度的聚类，并希望任何切割线都是通过相互可达距离选出来的，并且今后固定在一个密度水平上。理想情况下，我们希望能够在不同的地方切割树，来选择我们的聚类。这是 HDBSCAN 下一步开始的地方，并与鲁棒的单一链接产生差异。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>聚类</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（13）EM算法</title>
    <url>/posts/1D9QYCW/</url>
    <content><![CDATA[<h1><span id="em期望最大-概率模型">EM——期望最大 [概率模型]</span></h1><blockquote>
<p>  <strong>EM 算法通过引入隐含变量，使用 MLE（极大似然估计）进行迭代求解参数。通常引入隐含变量后会有两个参数，EM 算法首先会固定其中的第一个参数，然后使用 MLE 计算第二个变量值；接着通过固定第二个变量，再使用 MLE 估测第一个变量值，依次迭代，直至收敛到局部最优解。</strong></p>
<ol>
<li><a href="https://www.zhihu.com/question/27976634">怎么通俗易懂地解释 EM 算法并且举个例子?</a></li>
<li><a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/zouxy09/article/details/8537620">从最大似然到 EM 算法浅解</a></li>
<li><h5><span id="em算法"></span></h5></li>
</ol>
</blockquote>
<p><strong><font color="red"> EM 算法，全称 Expectation Maximization Algorithm。期望最大算法是一种迭代算法，用于含有隐变量（Hidden Variable）的概率参数模型的最大似然估计或极大后验概率估计。</font></strong></p>
<p>本文思路大致如下：先简要介绍其思想，然后举两个例子帮助大家理解，有了感性的认识后再进行严格的数学公式推导。</p>
<h2><span id="1-思想">1. 思想</span></h2><p>EM 算法的核心思想非常简单，分为两步：<strong>Expection-Step</strong> 和 <strong>Maximization-Step</strong>。<strong>E-Step 主要通过观察数据和现有模型来估计参数</strong>，然后用这个估计的参数值来计算似然函数的期望值；而 M-Step 是寻找似然函数最大化时对应的参数。由于算法会保证在每次迭代之后<strong>似然函数都会增加</strong>，所以函数最终会收敛。</p>
<p><img src="https://www.zhihu.com/equation?tex=EM" alt="[公式]"> <strong>算法一句话总结就是</strong>： <img src="https://www.zhihu.com/equation?tex=E" alt="[公式]"> 步固定 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 优化 <img src="https://www.zhihu.com/equation?tex=Q" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=M" alt="[公式]"> 步固定 <img src="https://www.zhihu.com/equation?tex=Q" alt="[公式]"> 优化 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 。</p>
<h3><span id="2-例子">2 例子</span></h3><h4><span id="21-例子-a">2.1 例子 A</span></h4><p>假设有两枚硬币 A 和 B，他们的随机抛掷的结果如下图所示：</p>
<p><img src="https://pic4.zhimg.com/80/v2-4e19d89b47e21cf284644b0576e9af0f_1440w.jpg" alt="img"></p>
<p>我们很容易估计出两枚硬币抛出正面的概率：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctheta_A+%3D+24%2F30+%3D0.8+%5C%5C%5Ctheta_B+%3D+9%2F20+%3D0.45++%5C%5C" alt="[公式]"></p>
<p>现在我们加入<strong>隐变量</strong>，抹去每轮投掷的硬币标记：</p>
<p><img src="https://pic1.zhimg.com/80/v2-caa896173185a8f527c037c122122258_1440w.jpg" alt="img"></p>
<p>碰到这种情况，我们该如何估计 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"> 的值？</p>
<p>我们多了一个隐变量 <img src="https://www.zhihu.com/equation?tex=Z%3D%28z_1%2C+z_2%2C+z_3%2C+z_4%2C+z_5%29" alt="[公式]"> ，代表每一轮所使用的硬币，我们需要知道每一轮抛掷所使用的硬币这样才能估计 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"> 的值，但是估计隐变量 Z 我们又需要知道 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"> 的值，才能用极大似然估计法去估计出 Z。这就陷入了一个鸡生蛋和蛋生鸡的问题。</p>
<p>其解决方法就是先<strong>随机初始化 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"></strong> ，然后用去估计 Z， 然后基于 Z 按照最大似然概率去估计新的 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"> ，循环至收敛。</p>
<h4><span id="212-计算"><strong>2.1.2 计算</strong></span></h4><p>随机初始化 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A%3D0.6" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B%3D0.5" alt="[公式]"></p>
<p>对于第一轮来说，如果是硬币 A，得出的 5 正 5 反的概率为： <img src="https://www.zhihu.com/equation?tex=0.6%5E5%2A0.4%5E5" alt="[公式]"> ；如果是硬币 B，得出的 5 正 5 反的概率为： <img src="https://www.zhihu.com/equation?tex=0.5%5E5%2A0.5%5E5" alt="[公式]"> 。我们可以算出使用是硬币 A 和硬币 B 的概率分别为：</p>
<p><img src="https://www.zhihu.com/equation?tex=P_A%3D%5Cfrac%7B0.6%5E5+%2A+0.4%5E5%7D%7B%280.6%5E5+%2A+0.4%5E5%29+%2B+%280.5%5E5+%2A+0.5%5E5%29%7D+%3D+0.45%5C%5C+P_B%3D%5Cfrac%7B0.5%5E5+%2A+0.5%5E5%7D%7B%280.6%5E5+%2A+0.4%5E5%29+%2B+%280.5%5E5+%2A+0.5%5E5%29%7D+%3D+0.55+%5C%5C" alt="[公式]"></p>
<p><img src="https://pic4.zhimg.com/80/v2-b325de65a5bcac196fc0939f346410d7_1440w.jpg" alt="img"></p>
<p>从期望的角度来看，对于第一轮抛掷，使用硬币 A 的概率是 0.45，使用硬币 B 的概率是 0.55。同理其他轮。这一步我们实际上是<strong>估计出了 Z 的概率分布</strong>，这部就是 <strong>E-Step</strong>。</p>
<p>结合硬币 A 的概率和上一张投掷结果，我们利用期望可以求出硬币 A 和硬币 B 的贡献。以第二轮硬币 A 为例子，计算方式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=H%3A+0.80%2A9+%3D7.2+%5C%5C+T%3A+0.80%2A1%3D0.8+%5C%5C" alt="[公式]"></p>
<p>于是我们可以得到：</p>
<p><img src="https://pic1.zhimg.com/80/v2-9b6e8c50c0761c6ac19909c26e0a71d4_1440w.jpg" alt="img"></p>
<p>然后用极大似然估计来估计新的 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"> 。</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctheta_A+%3D+%5Cfrac%7B21.3%7D%7B21.3%2B8.6%7D+%3D+0.71+%5C%5C+%5Ctheta_B+%3D+%5Cfrac%7B11.7%7D%7B11.7+%2B+8.4%7D+%3D+0.58+%5C%5C" alt="[公式]"></p>
<p>这步就对应了 M-Step，重新估计出了参数值。如此反复迭代，我们就可以算出最终的参数值。</p>
<p>上述讲解对应下图：</p>
<p><img src="https://pic3.zhimg.com/v2-6cac968d6500cbca58fc90347c288466_r.jpg" alt="preview" style="zoom:50%;"></p>
<h4><span id="22-例子-b">2.2 例子 B</span></h4><p>如果说例子 A 需要计算你可能没那么直观，那就举更一个简单的例子：</p>
<p>现在一个班里有 50 个男生和 50 个女生，且男女生分开。我们假定男生的身高服从正态分布： <img src="https://www.zhihu.com/equation?tex=N%28%5Cmu_1%2C+%5Csigma%5E2_1+%29" alt="[公式]"> ，女生的身高则服从另一个正态分布： <img src="https://www.zhihu.com/equation?tex=N%28%5Cmu_2%2C+%5Csigma%5E2_2+%29" alt="[公式]"> 。这时候我们可以用极大似然法（MLE），分别通过这 50 个男生和 50 个女生的样本来估计这两个正态分布的参数。</p>
<p>但现在我们让情况复杂一点，就是这 50 个男生和 50 个女生混在一起了。我们拥有 100 个人的身高数据，却不知道这 100 个人每一个是男生还是女生。</p>
<p>这时候情况就有点尴尬，因为通常来说，我们只有知道了精确的男女身高的正态分布参数我们才能知道每一个人更有可能是男生还是女生。但从另一方面去考量，我们只有知道了每个人是男生还是女生才能尽可能准确地估计男女各自身高的正态分布的参数。</p>
<p>这个时候有人就想到我们必须从某一点开始，并用迭代的办法去解决这个问题：<strong>==我们先设定男生身高和女生身高分布的几个参数（初始值），然后根据这些参数去判断每一个样本（人）是男生还是女生，之后根据标注后的样本再反过来重新估计参数。之后再多次重复这个过程，直至稳定。这个算法也就是 EM 算法。==</strong></p>
<h3><span id="3-推导">3. 推导</span></h3><p>给定数据集，假设样本间相互独立，我们想要拟合模型 <img src="https://www.zhihu.com/equation?tex=p%28x%3B%5Ctheta%29" alt="[公式]"> 到数据的参数。根据分布我们可以得到如下<strong>似然函数</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+L%28%5Ctheta%29+%26%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7Dlog+p%28x_i%3B%5Ctheta%29++%5C%5C+%26%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7Dlog+%5Csum_%7Bz%7Dp%28x_i%2C+z%3B%5Ctheta%29+%5Cend%7Baligned%7D+%5C%5C" alt="[公式]"></p>
<p>第一步是<strong>对极大似然函数取对数</strong>，第二步是对每个样本的每个可能的类别 z 求<strong>联合概率分布之和</strong>。如果这个 z 是已知的数，那么使用极大似然法会很容易。但如果 z 是隐变量，我们就需要用 EM 算法来求。<strong>事实上，隐变量估计问题也可以通过梯度下降等优化算法，但事实由于求和项将随着隐变量的数目以指数级上升，会给梯度计算带来麻烦；而 EM 算法则可看作一种非梯度优化方法。</strong></p>
<h4><span id="31-求解含有隐变量的概率模型">3.1 求解含有隐变量的概率模型</span></h4><p><strong>为了求解含有隐变量 <img src="https://www.zhihu.com/equation?tex=z" alt="[公式]"> 的概率模型</strong> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D%5Chat%7B%5Ctheta%7D%3D%5Cmathop%7B%5Carg%5Cmax%7D_%7B%5Ctheta%7D+%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Clog+%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7Dp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%5Cend%7Baligned%7D" alt="[公式]"> <strong>需要一些特殊的技巧</strong>，通过引入隐变量 <img src="https://www.zhihu.com/equation?tex=z%5E%7B%28i%29%7D" alt="[公式]"> 的概率分布为 <img src="https://www.zhihu.com/equation?tex=Q_i%28z%5E%7B%28i%29%7D%29" alt="[公式]"> ，<strong>==因为 <img src="https://www.zhihu.com/equation?tex=%5Clog+%28x%29" alt="[公式]"> 是凹函数故结合凹函数形式下的詹森不等式进行放缩处理==</strong><br> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Clog+%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7Dp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%26%3D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Clog+%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7D+Q_i%28z%5E%7B%28i%29%7D%29%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%5C%5C+%26%3D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Clog+%5Cmathbb%7BE%7D%28%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%29%5C%5C+%26%5Cge%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Cmathbb%7BE%7D%5B%5Clog%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%29%5D%5C%5C+%26%3D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%5Clog%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"><br>其中由概率分布的充要条件 <img src="https://www.zhihu.com/equation?tex=%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%3D1%E3%80%81Q_i%28z%5E%7B%28i%29%7D%29%5Cge0" alt="[公式]"> 可看成下述关于 <img src="https://www.zhihu.com/equation?tex=z" alt="[公式]"> 函数分布列的形式：</p>
<p><img src="https://pic2.zhimg.com/v2-cb7ddb5cdc34761ec70d63c97189b102_720w.jpg?source=d16d100b" alt="img" style="zoom:50%;"></p>
<p><strong>这个过程可以看作是对 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> 求了下界</strong>，假设 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 已经给定那么 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> 的值就取决于 <img src="https://www.zhihu.com/equation?tex=Q_i%28z%5E%7B%28i%29%7D%29" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=p%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%29" alt="[公式]"> 了，因此可以通过调整这两个概率使下界不断上升，以逼近 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> 的真实值，当不等式变成等式时说明调整后的概率能够等价于 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> ，所以必须找到使得等式成立的条件，即寻找<br> <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BE%7D%5B%5Clog%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%29%5D%3D%5Clog+%5Cmathbb%7BE%7D%5B%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%5D%5C%5C" alt="[公式]"><br>由期望得性质可知当<br> <img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%3DC%2C%5C+%5C+%5C+%5C+%5C+C%5Cin%5Cmathbb%7BR%7D+%5C+%5C+%5C+%5C+%5C+%28%2A%29%5C%5C" alt="[公式]"><br>等式成立，对上述等式进行变形处理可得<br> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%26p%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%3DCQ_i%28z%5E%7B%28i%29%7D%29%5C%5C+%26%5CLeftrightarrow+%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7Dp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%3DC%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%3DC%5C%5C+%26%5CLeftrightarrow+%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7Dp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%3DC+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%28%2A%2A%29+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"><br>把 <img src="https://www.zhihu.com/equation?tex=%28%2A%2A%29" alt="[公式]"> 式带入 <img src="https://www.zhihu.com/equation?tex=%28%2A%29" alt="[公式]"> 化简可知<br> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+Q_i%28z%5E%7B%28i%29%7D%29%26%3D%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7B%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7Dp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%5C%5C+%26%3D%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7Bp%28x%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%5C%5C+%26%3Dp%28z%5E%7B%28i%29%7D%7Cx%5E%7B%28i%29%7D%3B%5Ctheta%29+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"><br>至此，可以推出<strong>在固定参数 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 后</strong>， <img src="https://www.zhihu.com/equation?tex=Q_i%28z%5E%7B%28i%29%7D%29" alt="[公式]"> 的<strong>计算公式就是后验概率</strong>，解决了 <img src="https://www.zhihu.com/equation?tex=Q_i%28z%5E%7B%28i%29%7D%29" alt="[公式]"> 如何选择得问题。这一步称为 <img src="https://www.zhihu.com/equation?tex=E" alt="[公式]"> 步，建立 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> 得下界；接下来得 <img src="https://www.zhihu.com/equation?tex=M" alt="[公式]"> 步，就是在给定 <img src="https://www.zhihu.com/equation?tex=Q_i%28z%5E%7B%28i%29%7D%29" alt="[公式]"> 后，调整 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 去极大化 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> 的下界即<br> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%26%5Cmathop%7B%5Carg%5Cmax%7D_%7B%5Ctheta%7D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Clog+p%28x%5E%7B%28i%29%7D%3B%5Ctheta%29%5C%5C+%26%5CLeftrightarrow+%5Cmathop%7B%5Carg%5Cmax%7D_%7B%5Ctheta%7D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%5Clog%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%5C%5C+%26%5CLeftrightarrow+%5Cmathop%7B%5Carg%5Cmax%7D_%7B%5Ctheta%7D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%5Cleft%5B%5Clog+p%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29-%5Clog+Q_i%28z%5E%7B%28i%29%7D%29%5Cright%5D%5C%5C+%26%5CLeftrightarrow+%5Cmathop%7B%5Carg%5Cmax%7D_%7B%5Ctheta%7D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%5Clog+p%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"><br>因此EM算法的迭代形式为：</p>
<p><img src="https://pic2.zhimg.com/80/v2-8a4f41596e78bfeb1b4044212b259524_1440w.jpg?source=d16d100b" alt="img" style="zoom:50%;"></p>
<p><img src="https://pic3.zhimg.com/80/v2-2f7fc5ca144d2f85f14d46e88055dd86_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>这张图的意思就是：<strong>首先我们固定</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> <strong>，调整</strong> <img src="https://www.zhihu.com/equation?tex=Q%28z%29" alt="[公式]"> <strong>使下界</strong> <img src="https://www.zhihu.com/equation?tex=J%28z%2CQ%29" alt="[公式]"> <strong>上升至与</strong> <img src="https://www.zhihu.com/equation?tex=L%28%5Ctheta%29" alt="[公式]"> <strong>在此点</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> <strong>处相等（绿色曲线到蓝色曲线），然后固定</strong> <img src="https://www.zhihu.com/equation?tex=Q%28z%29" alt="[公式]"> <strong>，调整</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> <strong>使下界</strong> <img src="https://www.zhihu.com/equation?tex=J%28z%2CQ%29" alt="[公式]"> <strong>达到最大值（</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta_t" alt="[公式]"> <strong>到</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D" alt="[公式]"> <strong>），然后再固定</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> <strong>，调整</strong> <img src="https://www.zhihu.com/equation?tex=Q%28z%29" alt="[公式]"> <strong>，一直到收敛到似然函数</strong> <img src="https://www.zhihu.com/equation?tex=L%28%5Ctheta%29" alt="[公式]"> <strong>的最大值处的</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 。</p>
<p><strong><font color="red"> EM 算法通过引入隐含变量，使用 MLE（极大似然估计）进行迭代求解参数。通常引入隐含变量后会有两个参数，EM 算法首先会固定其中的第一个参数，然后使用 MLE 计算第二个变量值；接着通过固定第二个变量，再使用 MLE 估测第一个变量值，依次迭代，直至收敛到局部最优解。</font></strong></p>
<h4><span id="32-em算法的收敛性">3.2 EM算法的收敛性</span></h4><p>不妨假设 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%29%7D" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%2B1%29%7D" alt="[公式]"> 是EM算法第 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 次迭代和第 <img src="https://www.zhihu.com/equation?tex=k%2B1" alt="[公式]"> 次迭代的结果，要确保 <img src="https://www.zhihu.com/equation?tex=EM" alt="[公式]"> 算法收敛那么等价于证明 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%29%7D%29%5Cle%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%2B1%29%7D%29" alt="[公式]"> 也就是说极大似然估计单调增加，那么算法最终会迭代到极大似然估计的最大值。在选定 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%29%7D" alt="[公式]"> 后可以得到 <img src="https://www.zhihu.com/equation?tex=E" alt="[公式]"> 步 <img src="https://www.zhihu.com/equation?tex=Q_i%5E%7B%28k%29%7D%28z%5E%7B%28i%29%7D%29%3Dp%28z%5E%7B%28i%29%7D%7Cx%5E%7B%28i%29%7D%3B%5Ctheta%5E%7B%28k%29%7D%29" alt="[公式]"> ，这一步保证了在给定 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%29%7D" alt="[公式]"> 时，詹森不等式中的等式成立即<br> <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%29%7D%29%3D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%5E%7B%28k%29%7D%28z%5E%7B%28i%29%7D%29%5Clog+%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%5E%7B%28k%29%7D%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%5C%5C" alt="[公式]"><br>然后再进行 <img src="https://www.zhihu.com/equation?tex=M" alt="[公式]"> 步，固定 <img src="https://www.zhihu.com/equation?tex=Q_i%5E%7B%28k%29%7D%28z%5E%7B%28i%29%7D%29" alt="[公式]"> 并将 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%29%7D" alt="[公式]"> 视作变量，对上式 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%29%7D%29" alt="[公式]"> 求导后得到 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%2B1%29%7D" alt="[公式]"> 因此有如下式子成立<br> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%29%7D%29%26%3D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%5E%7B%28k%29%7D%28z%5E%7B%28i%29%7D%29%5Clog+%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%5E%7B%28k%29%7D%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%28a%29%5C%5C+%26%5Cle+%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%5E%7B%28k%29%7D%28z%5E%7B%28i%29%7D%29%5Clog+%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%5E%7B%28k%29%7D%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%28b%29%5C%5C+%26%5Cle%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%2B1%29%7D%29%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%28c%29+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"><br>首先 <img src="https://www.zhihu.com/equation?tex=%28a%29" alt="[公式]"> 式是前面 <img src="https://www.zhihu.com/equation?tex=E" alt="[公式]"> 步所保证詹森不等式中的等式成立的条件， <img src="https://www.zhihu.com/equation?tex=%28a%29" alt="[公式]"> 到 <img src="https://www.zhihu.com/equation?tex=%28b%29" alt="[公式]"> 是 <img src="https://www.zhihu.com/equation?tex=M" alt="[公式]"> 步的定义，<img src="https://www.zhihu.com/equation?tex=%28b%29" alt="[公式]"> 到 <img src="https://www.zhihu.com/equation?tex=%28c%29" alt="[公式]">对任意参数都成立，而其等式的条件是固定 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 并调整好 <img src="https://www.zhihu.com/equation?tex=Q" alt="[公式]"> 时成立，<img src="https://www.zhihu.com/equation?tex=%28b%29" alt="[公式]"> 到 <img src="https://www.zhihu.com/equation?tex=%28c%29" alt="[公式]">只是固定 <img src="https://www.zhihu.com/equation?tex=Q" alt="[公式]"> 调整 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> ，在得到 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%2B1%29%7D" alt="[公式]"> 时，只是最大化 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%29%7D%29" alt="[公式]"> ，也就是 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%2B1%29%7D%29" alt="[公式]"> 的一个下界而没有使等式成立。</p>
<h3><span id="4-另一种理解">4. 另一种理解</span></h3><p>坐标上升法（Coordinate ascent）：</p>
<p><img src="https://pic4.zhimg.com/80/v2-b28bfe68513ff86d9643fec10786b827_1440w.jpg" alt="img"></p>
<p>途中直线为迭代优化路径，因为每次只优化一个变量，所以可以看到它没走一步都是平行与坐标轴的。</p>
<p>EM 算法类似于坐标上升法，E 步：固定参数，优化 Q；M 步：固定 Q，优化参数。交替将极值推向最大。</p>
<h4><span id="5-应用">5. 应用</span></h4><p>EM 的应用有很多，比如、混合高斯模型、聚类、HMM 等等。其中 <strong>EM 在 K-means 中的用处</strong>，我将在介绍 K-means 中的给出。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>贝叶斯分类器</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（1）评价指标</title>
    <url>/posts/27302/</url>
    <content><![CDATA[<blockquote>
<p>  一文看懂机器学习指标：准确率、精准率、召回率、F1、ROC曲线、AUC曲线:<a href="https://zhuanlan.zhihu.com/p/93107394">https://zhuanlan.zhihu.com/p/93107394</a></p>
<p>  <strong>机器学习-最全面的评价指标体系: <a href="https://zhuanlan.zhihu.com/p/359997979">https://zhuanlan.zhihu.com/p/359997979</a></strong></p>
<p>  <a href="https://github.com/HaoMood/homepage/blob/master/files/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8-03-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0.pdf">机器学习工程师面试宝典-03-模型评估</a></p>
<p>  <strong><a href="http://www.china-nb.cn/gongsidongtai/17-85.html">分类模型评估指标——准确率、精准率、召回率、F1、ROC曲线、AUC曲线</a></strong></p>
</blockquote>
<span id="more"></span>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/image-20220421165422230.png" alt="image-20220421165422230" style="zoom:50%;"></p>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/image-20220421165436795.png" alt="image-20220421165436795" style="zoom:50%;"></p>
<h3><span id="一-二分类问题">一、二分类问题</span></h3><blockquote>
<p>  <strong>阈值调节问题？</strong></p>
</blockquote>
<ul>
<li><strong>准确率 (Accuracy)</strong>：<strong>预测正确的概率</strong>  【<strong>(TP+TN)/(TP+TN+FP+FN)</strong>】</li>
<li><strong>精确率（查准率 Precision )：==预测为正的样本==中实际为正的样本的概率</strong> 【<strong>TP/(TP+FP)</strong>】</li>
<li>错误发现率（FDR）= 1 - 精确率 = ==预测为正的样本==中实际为负的样本的概率 【<strong>FP/(TP+FP)</strong>】</li>
<li><strong>召回率（查全率）- Recall</strong>：<strong>==实际为正的样本==中被预测为正样本的概率</strong>【<strong>TP/(TP+FN)</strong>】</li>
<li><strong>真正率（TPR） = 灵敏度（==召回率==） =</strong> <strong>TP/(TP+FN)</strong></li>
<li><strong>假正率（FPR） = 1- 特异度 =</strong> <strong>FP/(FP+TN)</strong></li>
<li><strong>F1=是准确率和召回率的==调和平均值== (2×Precision×Recall)/（Precision+Recall）</strong></li>
<li><strong>G-mean（GM）= 是准确率和召回率的==几何平均值==</strong> <img src="https://image.jiqizhixin.com/uploads/editor/c9841ee6-28df-4eb9-aace-8902a6e525a5/640.svg" alt="img"></li>
</ul>
<h3><span id="11-f12precisionrecall-precisionrecall">1.1 <strong>F1=(2×Precision×Recall) /（Precision+Recall）</strong></span></h3><p>精确率（Precision）和召回率（Recall）之间的关系用图来表达，就是下面的PR曲线。可以发现他们俩的关系是「两难全」的关系。为了综合两者的表现，在两者之间找一个平衡点，就出现了一个 F1分数。</p>
<h4><span id="f12precisionrecall-precisionrecall"><strong>F1=(2×Precision×Recall)  /（Precision+Recall）</strong></span></h4><p>P意义类似于每通过准确预测得到TP个正例需要TP+FP个预测类别为正例的样本。</p>
<p>R意义类似于每通过成功召回得到TP个正例需要TP+FN个真实类别为正例的样本。</p>
<p>F1度量了给定一批样本，对这一批样本进行预测与召回，最终得到的正例的多少。<strong>其中一半的正例是通过预测得到的，一半的正例是通过召回得到的。</strong></p>
<p>有一种把预测所需的预测类别为正例的样本和召回所需的真实类别为正例的样本看作原料，而我们的目标正例样本看作产品的感觉。<strong>所以也能解释为什么P跟R其中一者比较低的时候，F1会偏低。因为跟算术平均数不一样，两者不能互相替代，两部分各负责一半。那么加权调和平均Fbeta也可以很好的理解了。</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7BF_%7B%5Cbeta%7D%7D%3D%5Cfrac%7B1%7D%7B1%2B%5Cbeta%5E%7B2%7D%7D%5Ccdot%5Cleft%28+%5Cfrac%7B1%7D%7BP%7D%2B+%5Cfrac%7B%5Cbeta%5E%7B2%7D%7D%7BR%7D%5Cright%29" alt="[公式]"></p>
<p>各自负责的比例不一样了。因此beta越大，Fbeta越着重考虑召回能力。</p>
<h3><span id="12-rocauc的概念">1.2 ROC/AUC的概念</span></h3><p><strong>1. 灵敏度，特异度，真正率，假正率</strong></p>
<p>在正式介绍ROC/AUC之前，我们还要再介绍两个指标，<strong>这两个指标的选择也正是ROC和AUC可以无视样本不平衡的原因。</strong> 这两个指标分别是：<strong>灵敏度和（1-特异度），也叫做真正率（TPR）和假正率（FPR）</strong>。其实我们可以发现<strong>灵敏度和召回率是一模一样的，只是名字换了而已</strong>。由于我们比较关心正样本，所以需要查看有多少负样本被错误地预测为正样本，所以使用（1-特异度），而不是特异度。</p>
<p><strong>真正率（TPR） = 灵敏度（==召回率==） =</strong> <strong>TP/(TP+FN)</strong></p>
<p><strong>假正率（FPR） = 1- 特异度 =</strong> <strong>FP/(FP+TN)</strong></p>
<p>下面是真正率和假正率的示意，我们发现<strong>TPR和FPR分别是基于实际表现1和0出发的，也就是说它们分别在实际的正样本和负样本中来观察相关概率问题。</strong> </p>
<blockquote>
<p>  正因为如此，所以无论样本是否平衡，都不会被影响。还是拿之前的例子，总样本中，90%是正样本，10%是负样本。我们知道用准确率是有水分的，但是用TPR和FPR不一样。这里，TPR只关注90%正样本中有多少是被真正覆盖的，而与那10%毫无关系，同理，FPR只关注10%负样本中有多少是被错误覆盖的，也与那90%毫无关系，</p>
</blockquote>
<p><strong>如果我们从实际表现的各个结果角度出发，就可以避免样本不平衡的问题了，这也是为什么选用TPR和FPR作为ROC/AUC的指标的原因。</strong></p>
<h4><span id="2-roc接受者操作特征曲线"><strong>2. ROC（接受者操作特征曲线）</strong></span></h4><blockquote>
<p>  ROC（Receiver Operating Characteristic）曲线，又称接受者操作特征曲线。该曲线最早应用于雷达信号检测领域，用于区分信号与噪声。后来人们将其用于评价模型的预测能力，ROC曲线是基于<strong>混淆矩阵</strong>得出的。</p>
</blockquote>
<p>ROC曲线中的主要两个指标就是<strong>真正率</strong>和<strong>假正率，</strong> 上面也解释了这么选择的好处所在。其中<strong>横坐标为假正率（FPR），纵坐标为真正率（TPR）</strong>，下面就是一个标准的ROC曲线图。</p>
<h4><span id="auc的缺陷">AUC的缺陷？</span></h4><p><strong>优点</strong>：目前普遍认为接收器工作特性曲线（ROC）曲线下的面积—AUC是评估分类模型准确性的标准方法。<strong>它避免了在阈值选择过程中假定的主观性</strong>，当连续的概率得到的分数被转换为二分类标签时，通过总结整体模型表现，其衡量模型区分正负样本的性能优于通过阈值来判断的其他方法（比如准确率、召回率等）。</p>
<ul>
<li><strong>忽略了预测的概率值和模型的拟合优度</strong></li>
<li><strong>AUC反应了太过笼统的信息。无法反应召回率、精确率等在实际业务中经常关心的指标</strong></li>
<li><font color="red"> **对FPR和TPR两种错误的代价同等看待**</font></li>
<li>它没有给出模型误差的空间分布信息</li>
<li>最重要的一点，AUC的misleading的问题</li>
</ul>
<p><strong>==auc仅反应模型的排序能力==，无法反应模型的拟合优度；auc很多时候无法直接反应细粒度的和业务目标更相关的metric信息，例如 top k的准确率，召回率等等（例如同auc的模型在不同的区间的预测能力是存在差别的）；</strong></p>
<h3><span id="13-k-s曲线">1.3、K-S曲线</span></h3><blockquote>
<p>  <strong>K-S曲线</strong>，又称作洛伦兹曲线。实际上，K-S曲线的数据来源以及本质和ROC曲线是一致的，只是ROC曲线是把真正率（ <img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> ）和假正率（ <img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> ）当作横纵轴，<strong>而K-S曲线是把真正率（ <img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> ）和假正率（ <img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> )都当作是纵轴，横轴则由选定的阈值来充当。从 </strong>K-S 曲线<strong>就能衍生出 <img src="https://www.zhihu.com/equation?tex=KS" alt="[公式]"> 值， <img src="https://www.zhihu.com/equation?tex=KS+%3D+max%28TPR+-+FPR%29" alt="[公式]"> ，即是两条曲线之间的最大间隔距离。</strong></p>
</blockquote>
<p><strong>K-S曲线的画法：</strong></p>
<ol>
<li><p><strong>排序：</strong>对于二元分类器来说，模型训练完成之后每个样本都会得到一个类概率值，把样本按这个类概率值从大到小进行排序；</p>
</li>
<li><p><strong>找阈值：</strong>取排序后前 <img src="https://www.zhihu.com/equation?tex=10%5C%25%5Ctimes+k%28k%3D1%2C2%2C3%2C...%2C9%29" alt="[公式]"> 处的值（概率值）作为阈值，分别计算出不同的 <img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> 和<img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> 值，以<img src="https://www.zhihu.com/equation?tex=10%5C%25%5Ctimes+k%28k%3D1%2C2%2C3%2C...%2C9%29" alt="[公式]">为横坐标，分别以<img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> 和<img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> 值为纵坐标，就可以画出两个曲线，这就是K-S曲线，类似于下图。</p>
</li>
<li><p><strong>KS值</strong>：</p>
<p>从 <strong>K-S 曲线</strong>就能衍生出 <img src="https://www.zhihu.com/equation?tex=KS" alt="[公式]"> 值， <img src="https://www.zhihu.com/equation?tex=KS+%3D+max%28TPR+-+FPR%29" alt="[公式]"> ，即是两条曲线之间的最大间隔距离。KS值越大表示模型 的区分能力越强。</p>
</li>
</ol>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/v2-f913b42cefcd32f9fdbfa027de2dfbc8_1440w.jpg" alt="img" style="zoom: 50%;"></p>
<h3><span id="14-lift曲线">1.4 Lift曲线</span></h3><p><strong>Lift曲线它衡量的是，与不利用模型相比，模型的预测能力“变好”了多少，lift(提升指数)越大，模型的运行效果越好。实质上它强调的是投入与产出比</strong>。</p>
<p><strong>tip:</strong>理解<strong>Lift</strong>可以先看一下Quora上的一篇文章：<strong><a href="https://link.zhihu.com/?target=https%3A//www.quora.com/Whats-Lift-curve">What’s Lift curve?</a></strong></p>
<p><strong>Lift计算公式：</strong>先介绍几个相关的指标，以免混淆：</p>
<ul>
<li><strong>准确率（accuracy，ACC）</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=ACC%3D%5Cfrac%7BTP%2BTN%7D%7BFP%2BFN%2BTP%2BTN%7D%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>正确率(Precision，PRE)，查准率</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=PRE+%3D+%5Cfrac%7BTP%7D%7BTP%2BFP%7D+%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>真阳性率(True Positive Rate，TPR)，灵敏度(Sensitivity)，召回率(Recall)</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=TPR%3D%5Cfrac%7BTP%7D%7BTP%2BFN%7D+%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>假阳性率(False Positice Rate，FPR)，误诊率( = 1 - 特异度)</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=FPR%3D%5Cfrac%7BFP%7D%7BFP%2BTN%7D%5C%5C" alt="[公式]"></p>
<p><strong>Lift计算公式：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=Lift%3D%5Cfrac%7B%5Cfrac%7BTP%7D%7BTP%2BFP%7D%7D%7B%5Cfrac%7BTP%2BFN%7D%7BTP%2BFP%2BTN%2BFN%7D%7D%3D%5Cfrac%7BPRE%7D%7B%E6%AD%A3%E4%BE%8B%E5%8D%A0%E6%AF%94%7D%5C%5C" alt="[公式]"></p>
<p>根据以上公式可知，<strong>Lift指标可以这样理解：</strong>在不使用模型的情况下，我们用先验概率估计正例的比例，即上式子分母部分，以此作为正例的命中率；利用模型后，我们不需要从整个样本中来挑选正例，只需要从我们预测为正例的那个样本的子集 <img src="https://www.zhihu.com/equation?tex=TP%2BFP" alt="[公式]"> 中挑选正例，这时正例的命中率为 <img src="https://www.zhihu.com/equation?tex=PRE" alt="[公式]"> ，后者除以前者即可得提升值<strong>Lift。</strong></p>
<h4><span id="lift曲线"><strong>Lift曲线：</strong></span></h4><p>为了作出<strong>LIft</strong>曲线，首先引入 <img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]"> 的概念：</p>
<p><img src="https://www.zhihu.com/equation?tex=depth%3D%5Cfrac%7BTP%2BFP%7D%7BTP%2BFP%2BTN%2BFN%7D%5C%5C" alt="[公式]"></p>
<p><strong>从公式可以看出</strong>，<img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]">代表的是预测为正例的样本占整个样本的比例。</p>
<p>当阈值为0时，所有的样本都被预测为正例，因此 <img src="https://www.zhihu.com/equation?tex=depth%3D1" alt="[公式]"> ，于是 <img src="https://www.zhihu.com/equation?tex=Lift%3D1" alt="[公式]"> ，模型未起提升作用。随着阈值逐渐增大，被预测为正例的样本数逐渐减少，<img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]">减小，而较少的预测正例样本中的真实正例比例逐渐增大。当阈值增大至1时，没有样本被预测为正例，此时 <img src="https://www.zhihu.com/equation?tex=depth%3D0" alt="[公式]"> ，而 <img src="https://www.zhihu.com/equation?tex=Lift%3D0" alt="[公式]"> 。由此可见， <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 与<img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]">存在相反方向变化的关系。在此基础上作出 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 图：</p>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/v2-4cfa1e77335b91d9a47acb7238383c1e_1440w.jpg" alt="img" style="zoom: 50%;"></p>
<p>一般要求，在尽量大的 <img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]"> 下得到尽量大的 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]">，所以 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 曲线的右半部分应该尽量陡峭。</p>
<h3><span id="15-p-r曲线">1.5 <strong>P-R曲线</strong></span></h3><ul>
<li><p><strong>精确率（查准率）- Precision ：==预测为正的样本==中实际为正的样本的概率</strong> 【<strong>TP/(TP+FP)</strong>】</p>
</li>
<li><p><strong>召回率（查全率）- Recall</strong>：<strong>==实际为正的样本==中被预测为正样本的概率</strong>【<strong>TP/(TP+FN)</strong>】</p>
</li>
</ul>
<p>P-R曲线刻画<strong>查准率</strong>和<strong>查全率（召回率）</strong>之间的关系，查准率指的是在所有预测为正例的数据中，真正例所占的比例，查全率是指预测为真正例的数据占所有正例数据的比例。查准率和查全率是一对矛盾的度量，一般来说，查准率高时，查全率往往偏低，查全率高时，查准率往往偏低。</p>
<p>在很多情况下，我们可以根据学习器的预测结果对样例进行排序，排在前面的是学习器认为最可能是正例的样本，排在后面的是学习器认为最不可能是正例的样本，按此顺序逐个把样本作为正例进行预测，则每次可计算当前的查全率和查准率，以查准率为y轴，以查全率为x轴，可以画出下面的P-R曲线。</p>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/v2-dc6abbb24e2dfbfefe4777408d2a8e5c_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>如果一个学习器的P-R曲线被另一个学习器的P-R曲线完全包住，则可断言后者的性能优于前者，当然我们可以根据曲线下方的面积大小来进行比较，但更常用的是<strong>平衡点</strong>或者是F1值。</p>
<ul>
<li><strong>平衡点（BEP）</strong>是查准率=查全率时的取值，如果这个值较大，则说明学习器的性能较好。F1值越大，我们可以认为该学习器的性能较好。</li>
<li><font color="red"> **F1度量**：**BEP过于简单，这个平衡点是建立在”查准率=查全率“的前提下，无法满足实际不同场景的应用。**</font>

</li>
</ul>
<p>我们先来引入加权调和平均： <img src="https://www.zhihu.com/equation?tex=F_%5Cbeta" alt="[公式]">：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+%5Cfrac+%7B1%7D%7BF_%7B%5Cbeta%7D%7D%3D%5Cfrac+%7B1%7D%7B1%2B%7B%5Cbeta%7D%5E2%7D%28%5Cfrac%7B1%7D%7BP%7D%2B%5Cfrac%7B%5Cbeta%5E2%7D%7BR%7D%29++++%5Cquad+%E5%85%AC%E5%BC%8F%281%29" alt="[公式]"></p>
<p>加权调和平均与<strong>算术平均</strong> <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7BP%2BR%7D%7B2%7D" alt="[公式]"> 和<strong>几何平均</strong> <img src="https://www.zhihu.com/equation?tex=%5Csqrt%7BP%2BR%7D" alt="[公式]"> 相比，<strong>调和平均更重视较小值（这可以从倒数上看出来）</strong>。当 <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3D1+" alt="[公式]"> ，即F1是基于查准率和查全率的调和平均定义的，F1的公式如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+%5Cfrac+%7B1%7D%7BF_%7B1%7D%7D%3D%5Cfrac+%7B1%7D%7B2%7D%28%5Cfrac%7B1%7D%7BP%7D%2B%5Cfrac%7B1%7D%7BR%7D%29" alt="[公式]"></p>
<p>我们把公式求倒数，即可得：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+F1%3D%5Cfrac%7B2%2AP%2AR%7D%7BP%2BR%7D" alt="[公式]"></p>
<p>在一些应用中，对查准率和查全率的重视程度不同。例如在商品推荐中，为了尽可能少打扰用户，更希望推荐的内容确实是用户感兴趣的，此时查准率更重要；而在罪犯信息检索或者病人检查系统中，更希望尽可能少的漏判，此时查全率更重要。F1度量的一般形式是 <img src="https://www.zhihu.com/equation?tex=F_%7B%5Cbeta%7D" alt="[公式]"> ，能让我们自定义对查准率/查全率的不同偏好：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+F_%7B%5Cbeta%7D%3D%5Cfrac%7B%281%2B%5Cbeta%5E2%29%2AP%2AR%7D%7B%28%5Cbeta%5E2%2AP%29%2BR%7D" alt="[公式]"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3E0+" alt="[公式]"> 度量了查全率对查准率的相对重要性（不明白的同学可以回看公式1）， <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3D1" alt="[公式]"> 时退化为标准F1，<img src="https://www.zhihu.com/equation?tex=%5Cbeta%3E1+" alt="[公式]">==时查全率有更大影响； <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3C1" alt="[公式]"> 时，查准率有更大影响。==</p>
<h3><span id="16-对数损失log-loss">1.6 <strong>对数损失(Log Loss)</strong></span></h3><p><strong>AUC ROC考虑用于确定模型性能的预测概率</strong>。然而，AUC ROC存在问题，它只考虑概率的顺序，因此<strong>没有考虑模型预测更可能为正样本的更高概率的能力(即考虑了大小，但没有考虑更高精度)</strong>。<strong>在这种情况下，我们可以使用对数损失，即每个实例的正例预测概率的对数的负平均值。</strong></p>
<p>对数损失（Logistic Loss，logloss）是对预测概率的似然估计，其标准形式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+logloss%3DlogP%28Y%7CX%29" alt="[公式]"></p>
<p>对数损失最小化本质是上利用样本中的已知分布，求解拟合这种分布的最佳模型参数，使这种分布出现概率最大。</p>
<p>对数损失对应的二分类的计算公式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=logloss%3D-%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_ilog%5Chat%7By_i%7D%2B%281-y_i%29log%281-%5Chat%7By_i%7D%29%29+%2C%5Cquad%5Cquad%5Cquad+y%5Cin%5B0%2C1%5D" alt="[公式]"></p>
<p>其中N为样本数， <img src="https://www.zhihu.com/equation?tex=%5Chat+y_i" alt="[公式]"> 为预测为1的概率。对数损失在多分类问题中也可以使用，其计算公式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=logloss%3D-%5Cfrac%7B1%7D%7BN%7D%5Cfrac%7B1%7D%7BC%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%5Csum_%7Bj%3D1%7D%5E%7BC%7D%28y_%7Bij%7Dlog%5Chat%7By_%7Bij%7D%7D%29+%2C%5Cquad%5Cquad%5Cquad+y%5Cin%5B0%2C1%5D" alt="[公式]"></p>
<p>其中，N为样本数，C为类别数，logloss衡量的是预测概率分布和真实概率分布的差异性，取值越小越好。</p>
<h3><span id="17-多分类">1.7 多分类</span></h3><p>很多时候我们有多个<strong>二分类混淆矩阵</strong>，例如进行多次训练/测试，每次得到一个混淆矩阵；或是在多个数据集上进行训练/测试，希望估计算法的全局性能；或者是执行分类任务，每两两类别的组合都对应一个混淆矩阵；总之是在<strong>n个二分类混淆矩阵上综合考察查准率和查全率</strong>。</p>
<ul>
<li><strong>宏观</strong>：在各个混淆军阵上分别计算出查准率和查全率，记为(P1,R1)，(P2,R2),…(Pn,Rn)，在<strong>计算平均值</strong>，这样就得到“宏观查准率”(macro-P)，“宏观查全率”(macro-R)、“宏观F1”(macro-F1)：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+macro-P+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7DP_i" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+macro-R+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7DR_i" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+macro-F1%3D%5Cfrac%7B2%2Amacro-P%2Amacro-R%7D%7Bmacro-P%2Bmacro-R%7D" alt="[公式]"></p>
<ul>
<li><strong>微观</strong>：<strong>将个混淆矩阵对应的元素进行平均，得到TP、FP、TN、FN的平均值</strong>，分别记为 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BTP%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BFP%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BFN%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BTN%7D" alt="[公式]"> ，再基于这些平均值计算出“微观查准率”(micro-P)，“微观查全率”(micro-R)、“微观F1”(micro-F1)：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+micro-P%3D%5Cfrac%7B%5Coverline%7BTP%7D%7D%7B%5Coverline%7BTP%7D%2B%5Coverline%7BFP%7D%7D" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+micro-R%3D%5Cfrac%7B%5Coverline%7BTP%7D%7D%7B%5Coverline%7BTP%7D%2B%5Coverline%7BFN%7D%7D" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+micro-F1%3D%5Cfrac%7B2%2Amicro-P%2Amicro-R%7D%7Bmicro-P%2Bmicro-R%7D" alt="[公式]"></p>
<h2><span id="二-回归问题评价指标">二、回归问题评价指标</span></h2><blockquote>
<p>  <strong>均方差损失 Mean Squared Loss、平均绝对误差损失 Mean Absolute Error Loss、Huber Loss、分位数损失 Quantile Loss</strong></p>
</blockquote>
<p>机器学习中的监督学习本质上是给定一系列训练样本 <img src="https://www.zhihu.com/equation?tex=%28x_i%2C+y_i%29" alt="[公式]"> ，尝试学习 <img src="https://www.zhihu.com/equation?tex=x%5Crightarrow+y" alt="[公式]"> 的映射关系，使得给定一个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> ，即便这个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 不在训练样本中，也能够得到尽量接近真实 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 的输出 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D" alt="[公式]"> 。而损失函数（Loss Function）则是这个过程中关键的一个组成部分，用来<strong>衡量模型的输出</strong> <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D" alt="[公式]"> <strong>与真实的</strong> <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> <strong>之间的差距</strong>，给模型的优化指明方向。</p>
<h3><span id="21-均方差损失-mse-l2-loss">2.1 均方差损失 MSE、L2 loss</span></h3><h5><span id="基本形式与原理"><strong>基本形式与原理</strong></span></h5><p><strong>均方差Mean Squared Error (MSE)损失是机器学习、深度学习回归任务中最常用的一种损失函数</strong>，也称为 <strong>L2 Loss</strong>。其基本形式如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=J_%7BMSE%7D+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_i+-+%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>从直觉上理解均方差损失，这个损失函数的最小值为 0（当预测等于真实值时），最大值为无穷大。下图是对于真实值 <img src="https://www.zhihu.com/equation?tex=y%3D0" alt="[公式]"> ，不同的预测值 <img src="https://www.zhihu.com/equation?tex=%5B-1.5%2C+1.5%5D" alt="[公式]"> 的均方差损失的变化图。横轴是不同的预测值，纵轴是均方差损失，可以看到随着预测与真实值绝对误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y-+%5Chat%7By%7D%5Crvert" alt="[公式]"> 的增加，均方差损失呈二次方地增加。</p>
<p><img src="https://pic1.zhimg.com/80/v2-f13a4355c21d16cad8b3f30e8a24b5cc_1440w.jpg" alt="img"></p>
<blockquote>
<h4><span id="背后的假设">背后的假设</span></h4><p>  <strong>【独立同分布-中心极限定理】</strong>：<br>  如果 <img src="https://www.zhihu.com/equation?tex=%5C%7BX_n%5C%7D" alt="[公式]"> 独立同分布，且 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb+EX%3D%5Cmu%2C%5Cquad+%5Cmathbb+D+X%3D%5Csigma%5E2%3E0" alt="[公式]"> ，则n足够大时 <img src="https://www.zhihu.com/equation?tex=%5Coverline+X_n" alt="[公式]"> 近似服从正态分布 <img src="https://www.zhihu.com/equation?tex=N%5Cleft%28%5Cmu%2C%5Cfrac%7B%5Csigma%5E2%7Dn%5Cright%29" alt="[公式]"> ，即</p>
<p>  <img src="https://www.zhihu.com/equation?tex=%5Clim_%7Bn%5Cto%5Cinfty%7DP%5Cleft%28%5Cfrac%7B%5Coverline+X_n-%5Cmu%7D%7B%5Csigma%2F%5Csqrt+n%7D%3Ca%5Cright%29%3D%5CPhi%28a%29%3D%5Cint_%7B-%5Cinfty%7D%5Ea%5Cfrac1%7B%5Csqrt%7B2%5Cpi%7D%7De%5E%7B-t%5E2%2F2%7Ddt%5C%5C" alt="[公式]"></p>
<p>  实际上在一定的假设下，我们可以使用最大化似然得到均方差损失的形式。假设<strong>模型预测与真实值之间的误差服从标准高斯分布</strong>（ <img src="https://www.zhihu.com/equation?tex=%5Cmu%3D0%2C+%5Csigma%3D1" alt="[公式]"> ），则给定一个 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 模型输出真实值 <img src="https://www.zhihu.com/equation?tex=y_i" alt="[公式]"> 的概率为</p>
<p>  <img src="https://www.zhihu.com/equation?tex=p%28y_i%7Cx_i%29+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%7D%5Cmathbb%7Bexp%7D%5Cleft+%28-%5Cfrac%7B%28y_i-%5Chat%7By_i%7D%29%5E2%7D%7B2%7D%5Cright+%29+%5C%5C" alt="[公式]"></p>
<p>  <strong>进一步我们假设数据集中 N 个样本点之间相互独立，则给定所有 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 输出所有真实值 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 的概率，即似然 Likelihood</strong>，为所有 <img src="https://www.zhihu.com/equation?tex=p%28y_i+%5Cvert+x_i%29" alt="[公式]"> 的累乘</p>
<p>  <img src="https://www.zhihu.com/equation?tex=L%28x%2C+y%29+%3D+%5Cprod_%7Bi%3D1%7D%5E%7BN%7D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%7D%5Cmathbb%7Bexp%7D%5Cleft+%28-%5Cfrac%7B%28y_i-%5Chat%7By_i%7D%29%5E2%7D%7B2%7D%5Cright%29+%5C%5C" alt="[公式]"></p>
<p>  通常为了计算方便，我们通常最大化对数似然 Log-Likelihood</p>
<p>  <img src="https://www.zhihu.com/equation?tex=LL%28x%2C+y%29%3D%5Cmathbb%7Blog%7D%28L%28x%2C+y%29%29%3D-%5Cfrac%7BN%7D%7B2%7D%5Cmathbb%7Blog%7D2%5Cpi+-+%5Cfrac%7B1%7D%7B2%7D+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%28y_i-%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>  去掉与 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D" alt="[公式]"> 无关的第一项，然后转化为最小化负对数似然 Negative Log-Likelihood</p>
<p>  <img src="https://www.zhihu.com/equation?tex=NLL%28x%2C+y%29+%3D+%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_i+-+%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>  可以看到这个实际上就是均方差损失的形式。也就是说<strong>在模型输出与真实值的误差服从高斯分布的假设下，最小化均方差损失函数与极大似然估计本质上是一致的</strong>，因此在这个假设能被满足的场景中（比如回归），均方差损失是一个很好的损失函数选择；当这个假设没能被满足的场景中（比如分类），均方差损失不是一个好的选择。</p>
</blockquote>
<h3><span id="hulu-百面机器学习-平方根误差的意外"><strong><font color="red"> hulu 百面机器学习 —— 平方根误差的”意外“</font></strong></span></h3><h4><span id="95的时间区间效果很好rmse指标居高不下的原因">95%的时间区间效果很好，RMSE指标居高不下的原因？</span></h4><p><img src="https://www.zhihu.com/equation?tex=J_%7BMSE%7D+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_i+-+%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>一般情况下RSME能反应预测值与真实值的偏离程度，但是<strong>易受离群点</strong>的影响；</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>数据预处理将噪音去掉</li>
<li>将离群点的产生机制建模进去</li>
<li>更鲁棒的模型评估指标：<strong>平均绝对百分比误差</strong>（MAPE），<strong>分位数损失</strong></li>
</ul>
<h4><span id="22-平均绝对误差-mae">2.2 <strong>平均绝对误差 MAE</strong></span></h4><p><strong>平均绝对误差 Mean Absolute Error (MAE）</strong> 是另一类常用的损失函数，也称为 <strong>L1 Loss</strong>。其基本形式如下</p>
<p><img src="https://www.zhihu.com/equation?tex=+J_%7BMAE%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%5Cleft+%7C+y_i+-+%5Chat%7By_i%7D+%5Cright+%7C+%5C%5C" alt="[公式]"></p>
<p>同样的我们可以对这个损失函数进行可视化如下图，MAE 损失的最小值为 0（当预测等于真实值时），最大值为无穷大。可以看到随着预测与真实值绝对误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y-+%5Chat%7By%7D%5Crvert" alt="[公式]"> 的增加，MAE 损失呈线性增长。</p>
<p><img src="https://pic3.zhimg.com/80/v2-fd248542b6b5aa9fadcab44340045dee_1440w.jpg" alt="img"></p>
<blockquote>
<h4><span id="背后的假设">背后的假设</span></h4><p>  同样的我们可以在一定的假设下通过最大化似然得到 MAE 损失的形式，假设<strong>模型预测与真实值之间的误差服从拉普拉斯分布 Laplace distribution</strong>（ <img src="https://www.zhihu.com/equation?tex=%5Cmu%3D0%2C+b%3D1" alt="[公式]"> ），则给定一个 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 模型输出真实值 <img src="https://www.zhihu.com/equation?tex=y_i" alt="[公式]"> 的概率为</p>
<p>  <img src="https://www.zhihu.com/equation?tex=p%28y_i%7Cx_i%29+%3D+%5Cfrac%7B1%7D%7B2%7D%5Cmathbb%7Bexp%7D%28-%5Cleft+%7Cy_i-%5Chat%7By_i%7D%5Cright%7C%29+%5C%5C" alt="[公式]"></p>
<p>  与上面推导 MSE 时类似，我们可以得到的负对数似然实际上就是 MAE 损失的形式</p>
<p>  <img src="https://www.zhihu.com/equation?tex=L%28x%2C+y%29+%3D+%5Cprod_%7Bi%3D1%7D%5E%7BN%7D%5Cfrac%7B1%7D%7B2%7D%5Cmathbb%7Bexp%7D%28-%7Cy_i-%5Chat%7By_i%7D%7C%29%5C%5C+++LL%28x%2C+y%29+%3D+N%5Cln%7B%5Cfrac%7B1%7D%7B2%7D%7D+-+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%7Cy_i-%5Chat%7By_i%7D%7C+%5C%5C+++NLL%28x%2C+y%29+%3D+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%7Cy_i-%5Chat%7By_i%7D%7C++%5C%5C" alt="[公式]"></p>
</blockquote>
<h3><span id="23-mae-与-mse-区别">2.3 MAE 与 MSE 区别</span></h3><p>MAE 和 MSE 作为损失函数的主要区别是：<strong>MSE 损失相比 MAE 通常可以更快地收敛，但 MAE 损失对于 outlier 更加健壮</strong>，即更加不易受到 outlier 影响。</p>
<ul>
<li><p><strong>MSE 通常比 MAE 可以更快地收敛</strong>。当使用梯度下降算法时，MSE 损失的梯度为 <img src="https://www.zhihu.com/equation?tex=-%5Chat%7By_i%7D" alt="[公式]"> ，而 MAE 损失的梯度为 <img src="https://www.zhihu.com/equation?tex=%5Cpm1" alt="[公式]"> ，即 MSE 的梯度的 scale 会随误差大小变化，而 MAE 的梯度的 scale 则一直保持为 1，即便在绝对误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y_i-%5Chat%7By_i%7D+%5Crvert" alt="[公式]"> 很小的时候 MAE 的梯度 scale 也同样为 1，这实际上是非常不利于模型的训练的。当然你可以通过在训练过程中动态调整学习率缓解这个问题，但是总的来说，损失函数梯度之间的差异导致了 MSE 在大部分时候比 MAE 收敛地更快。这个也是 MSE 更为流行的原因。</p>
</li>
<li><p><strong>MAE 对于异常值（outlier） 更加 robust</strong>。我们可以从两个角度来理解这一点：</p>
<ul>
<li>第一个角度是直观地理解，下图是 MAE 和 MSE 损失画到同一张图里面，由于MAE 损失与绝对误差之间是线性关系，MSE 损失与误差是平方关系，当误差非常大的时候，MSE 损失会远远大于 MAE 损失。<strong>因此当数据中出现一个误差非常大的 outlier 时，MSE 会产生一个非常大的损失，对模型的训练会产生较大的影响</strong>。<img src="https://pic2.zhimg.com/80/v2-c8edffe0406dafae41a042e412cd3251_1440w.jpg" alt="img"></li>
<li>第二个角度是从两个损失函数的假设出发，MSE 假设了误差服从高斯分布，MAE 假设了误差服从拉普拉斯分布。拉普拉斯分布本身对于 outlier 更加 robust。参考下图（来源：<a href="https://link.zhihu.com/?target=https%3A//www.cs.ubc.ca/~murphyk/MLbook/">Machine Learning: A Probabilistic Perspective</a> 2.4.3 The Laplace distribution Figure 2.8），当右图右侧出现了 outliers 时，拉普拉斯分布相比高斯分布受到的影响要小很多。因此以拉普拉斯分布为假设的 MAE 对 outlier 比高斯分布为假设的 MSE 更加 robust。<img src="https://pic1.zhimg.com/80/v2-93ad65845f5b0dc0327fde4ded661804_1440w.jpg" alt="img" style="zoom: 67%;"></li>
</ul>
</li>
</ul>
<h3><span id="24-huber-loss">2.4 Huber Loss</span></h3><blockquote>
<ul>
<li>在误差接近 0 时使用 MSE，使损失函数可导并且梯度更加稳定</li>
<li>在误差较大时使用 MAE 可以降低 outlier 的影响，使训练对 outlier 更加健壮。</li>
</ul>
</blockquote>
<p>上文我们分别介绍了 MSE 和 MAE 损失以及各自的优缺点，MSE 损失收敛快但容易受 outlier 影响，MAE 对 outlier 更加健壮但是收敛慢，<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Huber_loss">Huber Loss</a> 则是一种将 MSE 与 MAE 结合起来，取两者优点的损失函数，也被称作 Smooth Mean Absolute Error Loss 。其原理很简单，就是在误差接近 0 时使用 MSE，误差较大时使用 MAE，公式为</p>
<p><img src="https://www.zhihu.com/equation?tex=J_%7Bhuber%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN%5Cmathbb%7BI%7D_%7B%7C+y_i+-+%5Chat%7By_i%7D%7C+%5Cleq+%5Cdelta%7D+%5Cfrac%7B%28y_i+-+%5Chat%7By_i%7D%29%5E2%7D%7B2%7D%2B+%5Cmathbb%7BI%7D_%7B%7C+y_i+-+%5Chat%7By_i%7D%7C+%3E+%5Cdelta%7D+%28%5Cdelta+%7Cy_i+-+%5Chat%7By_i%7D%7C+-+%5Cfrac%7B1%7D%7B2%7D%5Cdelta%5E2%29+%5C%5C" alt="[公式]"></p>
<p>上式中 <img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="[公式]"> 是 Huber Loss 的一个超参数，<img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="[公式]"> 的值是 MSE 和 MAE 两个损失连接的位置。上式等号右边第一项是 MSE 的部分，第二项是 MAE 部分，在 MAE 的部分公式为 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+%5Clvert+y_i+-+%5Chat%7By_i%7D%5Crvert+-+%5Cfrac%7B1%7D%7B2%7D%5Cdelta%5E2" alt="[公式]"> 是为了保证误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y+-+%5Chat%7By%7D%5Crvert%3D%5Cpm+%5Cdelta" alt="[公式]"> 时 MAE 和 MSE 的取值一致，进而保证 Huber Loss 损失连续可导。</p>
<p>下图是 <img src="https://www.zhihu.com/equation?tex=%5Cdelta%3D1.0" alt="[公式]"> 时的 Huber Loss，可以看到在 <img src="https://www.zhihu.com/equation?tex=%5B-%5Cdelta%2C+%5Cdelta%5D" alt="[公式]"> 的区间内实际上就是 MSE 损失，在 <img src="https://www.zhihu.com/equation?tex=%28-%5Cinfty%2C+%5Cdelta%29" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%28%5Cdelta%2C+%5Cinfty%29" alt="[公式]"> 区间内为 MAE损失。</p>
<p><img src="https://pic4.zhimg.com/80/v2-b4260d38f70dd920fa46b8717596bda7_1440w.jpg" alt="img"></p>
<h3><span id="25-分位数损失-quantile-loss">2.5 分位数损失 Quantile Loss</span></h3><blockquote>
<p>  <strong>MAE 中分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong></p>
</blockquote>
<p><strong>分位数回归 Quantile Regression 是一类在实际应用中非常有用的回归算法</strong>，通常的回归算法是拟合目标值的期望或者中位数，而分位数回归可以通过给定不同的分位点，<strong>拟合目标值的不同分位数</strong>。</p>
<p><img src="https://pic1.zhimg.com/80/v2-8eb8ecfcdd8031a16a471905217934a0_1440w.jpg" alt="img"></p>
<p>分位数回归是通过使用分位数损失 Quantile Loss 来实现这一点的，分位数损失形式如下，式中的 r 分位数系数。</p>
<p><img src="https://www.zhihu.com/equation?tex=J_%7Bquant%7D+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%5Cmathbb%7BI%7D_%7B%5Chat%7By_i%7D%5Cgeq+y_i%7D%281-r%29%7Cy_i+-+%5Chat%7By_i%7D%7C+%2B+%5Cmathbb%7BI%7D_%7B%5Chat%7By_i%7D%3C+y_i%7Dr%7Cy_i-%5Chat%7By_i%7D%7C+%5C%5C" alt="[公式]"></p>
<p>我们如何理解这个损失函数呢？这个损失函数是一个分段的函数 ，将 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D+%5Cgeq+y_i" alt="[公式]"> （高估） 和 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D+%3C+y_i" alt="[公式]"> （低估） 两种情况分开来，并分别给予不同的系数。当 <img src="https://www.zhihu.com/equation?tex=r%3E0.5" alt="[公式]"> 时，低估的损失要比高估的损失更大，反过来当 <img src="https://www.zhihu.com/equation?tex=r+%3C+0.5" alt="[公式]"> 时，高估的损失比低估的损失大；分位数损失实现了<strong>分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong>。特别地，当 <img src="https://www.zhihu.com/equation?tex=r%3D0.5" alt="[公式]"> 时，分位数损失退化为 MAE 损失，从这里可以看出 MAE 损失实际上是分位数损失的一个特例 — 中位数回归。</p>
<p>下图是取不同的分位点 0.2、0.5、0.6 得到的三个不同的分位损失函数的可视化，可以看到 0.2 和 0.6 在高估和低估两种情况下损失是不同的，而 0.5 实际上就是 MAE。</p>
<p><img src="https://pic4.zhimg.com/80/v2-f8ed385f32a517c784bce841e6da1daf_1440w.jpg" alt="img"></p>
<h3><span id="26-平均绝对百分误差-mape">2.6  平均绝对百分误差 MAPE</span></h3><p>虽然平均绝对误差能够获得一个评价值，但是你并不知道这个值代表模型拟合是优还是劣，只有通过对比才能达到效果。当需要以相对的观点来衡量误差时，则使用MAPE。</p>
<p><strong>平均绝对百分误差</strong>（<strong>Mean Absolute Percentage Error，MAPE</strong>）是对 MAE 的一种改进，考虑了绝对误差相对真实值的比例。</p>
<ul>
<li><strong>优点</strong>：考虑了预测值与真实值的误差。考虑了误差与真实值之间的比例。</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=MAPE%3D%5Cfrac%7B100%7D%7Bm%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20%5Cleft%20%7C%20%20%5Cfrac%7By_%7Bi%7D-f%5Cleft%28x_%7Bi%7D%5Cright%29%7D%7By_%7Bi%7D%7D%20%5Cright%20%7C" alt="公式"></p>
<blockquote>
<p>  在某些场景下，如房价从 <img src="https://www.zhihu.com/equation?tex=5K" alt="公式"> 到 <img src="https://www.zhihu.com/equation?tex=50K" alt="公式"> 之间，<img src="https://www.zhihu.com/equation?tex=5K" alt="公式"> 预测成 <img src="https://www.zhihu.com/equation?tex=10K" alt="公式"> 与 <img src="https://www.zhihu.com/equation?tex=50K" alt="公式"> 预测成 <img src="https://www.zhihu.com/equation?tex=45K" alt="公式"> 的差别是非常大的，而平均绝对百分误差考虑到了这点。</p>
</blockquote>
<h2><span id="三-相似性度量指标">三、相似性度量指标</span></h2><blockquote>
<p>  机器学习中的相似性度量方法 - 天下客的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/411876558">https://zhuanlan.zhihu.com/p/411876558</a></p>
</blockquote>
<p>描述样本之间相似度的方法有很多种，一般来说常用的有相关系数和欧式距离。本文对机器学习中常用的相似性度量方法进行了总结。<strong>在做分类时，常常需要估算不同样本之间的相似性度量（Similarity Measurement），</strong>这时通常采用的方法就是计算样本间的“距离”（distance）。采用什么样的方法计算距离是很讲究的，甚至关系到分类的正确与否。</p>
<ul>
<li><strong>欧式距离</strong>：k-means</li>
<li><strong>曼哈顿距离</strong>：</li>
<li><strong>切比雪夫距离</strong>：</li>
<li>闵可夫斯基距离</li>
<li>标准化欧氏距离</li>
<li>马氏距离</li>
<li><a href="https://www.zhihu.com/search?q=夹角余弦&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;55493039&quot;}">夹角余弦</a></li>
<li><strong>汉明距离</strong>：simhash</li>
<li><strong>杰卡德距离&amp;杰卡德相似系数</strong>: <strong>杰卡德相似系数是衡量两个集合的相似度一种指标。</strong></li>
<li>相关系数&amp;相关距离</li>
<li>信息熵</li>
</ul>
<h2><span id="四-推荐算法评价指标">四、推荐算法评价指标</span></h2><ul>
<li>推荐算法评价指标 - 一干正事就犯困的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/359528909">https://zhuanlan.zhihu.com/p/359528909</a></li>
</ul>
<h4><span id="41-ap">4.1 AP</span></h4><p><code>AP</code> 衡量的是训练好的模型在每个类别上的好坏；</p>
<p><img src="https://pic2.zhimg.com/80/v2-e8656365e7eee25065d6bdfec33368e5_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p><strong>AP总结了一个精确召回曲线，作为在每个阈值处获得的精度的加权平均值，并且与以前的阈值相比，召回率的增加用作权重</strong>：</p>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20220711160205051.png" alt="image-20220711160205051" style="zoom:50%;"></p>
<p>其中和分别是第n个阈值[1]时的精度和召回率。此实现未进行插值，并且与使用梯形规则计算精确调用曲线下的面积有所不同，后者使用线性插值并且可能过于乐观。</p>
<h4><span id="42-map">4.2 MAP</span></h4><p><strong>MAP（Mean Average Precision）常用于排序任务，MAP的计算涉及另外两个指标：Precision和Recall</strong></p>
<ul>
<li><strong>Precision和Precision@k</strong></li>
</ul>
<p>推荐算法中的精度precision计算如下： </p>
<p><img src="https://www.zhihu.com/equation?tex=precision%3D%5Cfrac%7B%E7%AE%97%E6%B3%95%E7%BB%93%E6%9E%9C%E4%B8%AD%E7%9B%B8%E5%85%B3%E7%9A%84item%E6%95%B0%E9%87%8F%7D%7B%E6%8E%A8%E8%8D%90%E7%9A%84item%E6%80%BB%E6%95%B0%E9%87%8F%7D+%5C%5C" alt="[公式]"></p>
<p>可以看出Precision的计算没有考虑结果列表中item的顺序，Precision@k则通过切片的方式将顺序隐含在结果中。Precision@k表示列表前k项的Precision，随着k的变化，可以得到一系列precision值，用 <img src="https://www.zhihu.com/equation?tex=P%28k%29" alt="[公式]"> 表示。</p>
<ul>
<li><strong>Recall和Recall@k</strong></li>
</ul>
<p>推荐算法中的召回率recall计算如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=+recall%3D%5Cfrac%7B%E7%AE%97%E6%B3%95%E7%BB%93%E6%9E%9C%E4%B8%AD%E7%9B%B8%E5%85%B3%E7%9A%84item%E6%95%B0%E9%87%8F%7D%7B%E6%89%80%E6%9C%89%E7%9B%B8%E5%85%B3%E7%9A%84item%E6%95%B0%E9%87%8F%7D%5C%5C" alt="[公式]"></p>
<p>与Precision@k相似，recall@k表示结果列表前k项的recall，随着k的变化，可以得到一系列的recall值，用 <img src="https://www.zhihu.com/equation?tex=r%28k%29" alt="[公式]"> 表示。</p>
<ul>
<li><h5><span id="apn">AP@N</span></h5></li>
</ul>
<p>AP（Average Precision）平均精度的计算以Precision@k为基础，可以体现出结果列表中item顺序的重要性，其计算过程如下： </p>
<p><img src="https://www.zhihu.com/equation?tex=AP%40N%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum%5EN_%7Bk%3D1%7D%28P%28k%29%5Cquad+if%5C%2C+kth%5C%2C+item%5C%2C+is%5C%2C+relevant%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum%5EN_%7Bk%3D1%7DP%28k%29%5Ccdot+rel%28k%29+%5C%5C" alt="[公式]"></p>
<p>其中，N表示要求推荐的N个item，m表示所有相关的item总数， <img src="https://www.zhihu.com/equation?tex=rel%28k%29" alt="[公式]"> 表示第k个item是否相关，相关为1，反之为0</p>
<p><strong>AP@N的值越大，表示推荐列表中相关的item数量越多以及相关item的排名越靠前</strong></p>
<ul>
<li><h5><span id="mapn">MAP@N</span></h5></li>
</ul>
<p><strong>AP@N评价了算法对单个用户的性能，MAP@N则是算法对多个用户的平均值，是平均数的平均，其计算过程如下</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=MAP%40N%3D%5Cfrac%7B1%7D%7B%7CU%7C%7D%5Csum_%7Bu%3D1%7D%5E%7B%7CU%7C%7D%28AP%40N%29u%3D%5Cfrac%7B1%7D%7B%7CU%7C%7D%5Csum%7Bu%3D1%7D%5E%7B%7CU%7C%7D%28%5Cfrac%7B1%7D%7Bm%7D%5Csum%5EN_%7Bk%3D1%7DP_u%28k%29%5Ccdot+rel_u%28k%29%29+%5C%5C" alt="[公式]"></p>
<h2><span id="五-聚类算法评价指标">五、聚类算法评价指标</span></h2><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/343667804">https://zhuanlan.zhihu.com/p/343667804</a></p>
<p>  十分钟掌握聚类算法的评估指标：<a href="https://juejin.cn/post/6997913127572471821">https://juejin.cn/post/6997913127572471821</a></p>
</blockquote>
<h4><span id="前言">前言</span></h4><p>如同之前介绍的其它算法模型一样，对于聚类来讲我们同样会通过一些评价指标来衡量聚类算法的优与劣。在聚类任务中，常见的评价指标有：<strong>纯度（Purity）</strong>、<strong>兰德系数（Rand Index, RI）</strong>、<strong>F值（F-score）</strong>和<strong>调整兰德系数（Adjusted Rand Index,ARI）</strong>。同时，这四种评价指标也是聚类相关论文中出现得最多的评价方法。下面，我们就来对这些算法一一进行介绍。</p>
<p><img src="https://pic3.zhimg.com/80/v2-e62c8b4b793c89b1cd70f2aaebf690c6_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>好的聚类算法，一般要求类簇具有：</p>
<ul>
<li><strong>簇内 (intra-cluster) 相似度高</strong></li>
<li><strong>簇间 (inter-cluster) 相似度底</strong></li>
</ul>
<p>一般来说，评估聚类质量有两个标准，内部评估评价指标和外部评估指标。</p>
<h3><span id="外部评估">【外部评估】</span></h3><h3><span id="51聚类纯度-聚类的准确率"><strong>5.1聚类纯度</strong> - 聚类的准确率</span></h3><p>在聚类结果的评估标准中，一种最简单最直观的方法就是计算它的<strong>聚类纯度</strong>（purity），别看纯度听起来很陌生，但实际上和<strong>分类问题中的准确率有着异曲同工之妙</strong>。因为聚类纯度的总体思想也<strong>用聚类正确的样本数除以总的样本数，因此它也经常被称为聚类的准确率</strong>。只是对于聚类后的结果我们并不知道每个簇所对应的真实类别，因此需要取每种情况下的最大值。具体的，纯度的计算公式定义如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+P%3D%28%5COmega%2C%5Cmathbb%7BC%7D%29%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bk%7D%5Cmax_%7Bj%7D%7C%5Comega_k%5Ccap+c_j%7C+%5Cend%7Baligned%7D%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%281%29+%5C%5C" alt="[公式]"></p>
<p>其中<img src="https://www.zhihu.com/equation?tex=N" alt="[公式]">表示总的样本数；<img src="https://www.zhihu.com/equation?tex=%5COmega%3D%5C%7B%5Comega_1%2C%5Comega_2%2C...%2C%5Comega_K%5C%7D" alt="[公式]">表示一个个聚类后的簇，而<img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BC%7D%3D%5C%7Bc_1%2C_2%2C...c_J%5C%7D" alt="[公式]">表示正确的类别；<img src="https://www.zhihu.com/equation?tex=%5Comega_k" alt="[公式]">表示聚类后第<img src="https://www.zhihu.com/equation?tex=k" alt="[公式]">个簇中的所有样本，<img src="https://www.zhihu.com/equation?tex=c_j" alt="[公式]">表示第<img src="https://www.zhihu.com/equation?tex=j" alt="[公式]">个类别中真实的样本。在这里<img src="https://www.zhihu.com/equation?tex=P" alt="[公式]">的取值范围为<img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[公式]">，越大表示聚类效果越好。</p>
<h3><span id="52-兰德系数与f值-同簇混淆矩阵"><strong>5.2 兰德系数与F值</strong>  [同簇混淆矩阵]</span></h3><p>在介绍完了纯度这一评价指标后，我们再来看看兰德系数（Rand Index）和F值。虽然兰德系数听起来是一个陌生的名词，但它的计算过程却也与准确率的计算过程类似。同时，虽然这里也有一个叫做F值的指标，并且它的计算过程也和分类指标中的F值类似，但是两者却有着本质的差别。说了这么多，那这两个指标到底该怎么算呢？同分类问题中的混淆矩阵类似，这里我们也要先定义四种情况进行计数，然后再进行指标的计算。</p>
<p><strong>为了说明兰德系数背后的思想，我们还是以图1中的聚类结果为例进行说明（为了方便观察，我们再放一张图在这里）:</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-e62c8b4b793c89b1cd70f2aaebf690c6_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=TP" alt="[公式]">：表示两个<strong>同类样本点</strong>在<strong>同一个簇</strong>（布袋）中的情况数量；</li>
<li><img src="https://www.zhihu.com/equation?tex=FP" alt="[公式]">：表示两个<strong>非同类样本点</strong>在<strong>同一个簇</strong>中的情况数量；</li>
<li><img src="https://www.zhihu.com/equation?tex=TN" alt="[公式]">：表示两个<strong>非同类样本点</strong>分别在<strong>两个簇</strong>中的情况数量；</li>
<li><img src="https://www.zhihu.com/equation?tex=FN" alt="[公式]">：表示两个同类样本点分别在<strong>两个簇</strong>中的情况数量；</li>
</ul>
<p>由此，我们便能得到如下所示的对<strong>混淆矩阵（Pair Confusion Matrix）</strong>：</p>
<p><img src="https://pic3.zhimg.com/80/v2-a9e709a995b006be04d026aebc721c4e_1440w.png" alt="img" style="zoom:75%;"></p>
<p>有了上面各种情况的统计值，我们就可以定义出兰德系数和F值的计算公式：</p>
<p><img src="https://www.zhihu.com/equation?tex=RI%3D%5Cfrac%7BTP%2BTN%7D%7BTP%2BFP%2BFN%2BTN%7D%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%283%29+%5C%5C" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+Precision%26%3D%5Cfrac%7BTP%7D%7BTP%2BFP%7D%5C%5C%5B2ex%5D+Recall%26%3D%5Cfrac%7BTP%7D%7BTP%2BFN%7D%5C%5C%5B2ex%5D+F_%7B%5Cbeta%7D%26%3D%281%2B%5Cbeta%5E2%29%5Cfrac%7BPrecision%5Ccdot+Recall%7D%7B%5Cbeta%5E2%5Ccdot+Precision%2BRecall%7D+%5Cend%7Baligned%7D%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%284%29+%5C%5C" alt="[公式]"></p>
<p>从上面的计算公式来看，<img src="https://www.zhihu.com/equation?tex=%283%29%284%29" alt="[公式]">从形式上看都非常像分类问题中的准确率与F值，但是有着本质的却别。同时，在这里<img src="https://www.zhihu.com/equation?tex=RI" alt="[公式]">和<img src="https://www.zhihu.com/equation?tex=F_%7B%5Cbeta%7D" alt="[公式]">的取值范围均为<img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[公式]">，越大表示聚类效果越好。</p>
<h4><span id="53-调整兰德系数adjusted-rand-index归一化">5.3 调整兰德系数（Adjusted Rand index）【归一化】</span></h4><p>对于随机结果，RI并不能保证分数接近零。<strong>为了实现“在聚类结果随机产生的情况下，指标应该接近零”</strong>，调整兰德系数（Adjusted rand index）被提出，它具有更高的区分度。</p>
<p>其公式为：</p>
<script type="math/tex; mode=display">
\mathrm{ARI}=\frac{\mathrm{RI}-E[\mathrm{RI}]}{\max (\mathrm{RI})-E[\mathrm{RI}]}</script><p>$A R$ 取值范围为 $[-1,1]$, 值越大意味着聚类结果与真实情况越吻合。从广义的角度来讲, ARI衡量的是两个数据分布的吻合程度。</p>
<p>优点:</p>
<ul>
<li>对任意数量的聚类中心和样本数, 随机聚类的ARI都非常接近于 0 。</li>
<li>取值在 $[-1,1]$ 之间, 负数代表结果不好, 越接近于1越好。</li>
<li>对簇的结构不需作出任何假设：可以用于比较聚类算法。</li>
</ul>
<p>缺点:</p>
<ul>
<li>ARI 需要 ground truth classes 的相关知识, ARI需要真实标签, 而在实践中几乎不可用, 或者需要人工 标注者手动分配（如在监督学习环境中）。</li>
</ul>
<h3><span id="54-标准化互信息nmi-normalized-mutual-information">5.4 <strong><font color="red"> 标准化互信息（NMI, Normalized Mutual Information）</font></strong></span></h3><p>互信息是用来衡量两个数据分布的吻合程度。它也是一有用的信息度量，它是指两个事件集合之间的相关性。互信息越大，词条和类别的相关程度也越大。</p>
<h3><span id="内部指标">【内部指标】</span></h3><p>内部评估指标主要基于数据集的集合结构信息从紧致性、分离性、连通性和重叠度等方面对聚类划分进行评价。即基于数据聚类自身进行评估的。</p>
<h3><span id="55-轮廓系数silhouette-coefficient">5.5 <strong><font color="red"> 轮廓系数（Silhouette Coefficient）</font></strong></span></h3><p>轮廓系数适用于实际类别信息未知的情况。</p>
<p>对于单个样本，设<strong>a是与它同类别中其他样本的平均距离</strong>，<strong>b是与它距离最近不同类别中样本的平均距离</strong>，其轮廓系数为：</p>
<p>$s = \frac {b-a} {max(a, b)}$</p>
<p>对于一个样本集合，它的轮廓系数是所有样本轮廓系数的平均值。轮廓系数的取值范围是[-1,1]，同类别样本距离越相近，不同类别样本距离越远，值越大。当值为负数时，说明聚类效果很差。</p>
<h3><span id="56-calinski-harabaz指数calinski-harabaz-index">5.6 Calinski-Harabaz指数（Calinski-Harabaz Index）</span></h3><p>在真实的分群label不知道的情况下，Calinski-Harabasz可以作为评估模型的一个指标。</p>
<p>Calinski-Harabasz指数通过<strong>计算类中各点与类中心的距离平方和来度量类内的紧密度</strong>，通过<strong>==计算各类中心点与数据集中心点距离平方和来度量数据集的分离度==</strong>，CH指标<strong>由分离度与紧密度的比值得到</strong>。从而，CH越大代表着类自身越紧密，类与类之间越分散，即更优的聚类结果。</p>
<p><strong>优点</strong></p>
<ul>
<li>当簇的密集且分离较好时，分数更高。</li>
<li>得分计算很快，与轮廓系数的对比，最大的优势：快！相差几百倍！毫秒级。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>凸的簇的CH指数通常高于其他类型的簇。例如，通过 DBSCAN 获得基于密度的簇；所以，不适合基于密度的聚类算法（DBSCAN）。</li>
</ul>
<h3><span id="57-戴维森堡丁指数dbi-davies-bouldin-index">5.7 戴维森堡丁指数（DBI, Davies-Bouldin Index）</span></h3><p><strong>DB指数是计算任意两类别的类内距离平均距离之和除以两聚类中心距离求最大值</strong>。DB越小，意味着类内距 离越小同时类间距离越大。<strong>零是可能的最低值, 接近零的值表示更好的分区</strong>。</p>
<script type="math/tex; mode=display">
\begin{gathered}
R_{i j}=\frac{s_{i}+s_{j}}{d_{i j}} \\
D B=\frac{1}{k} \sum_{i=1}^{k} \max _{i \neq j} R_{i j}
\end{gathered}</script><p>其中, $s_{i}$ 表示簇的每个点与该簇的质心之间的平均距离, 也称为簇直径。 $d_{i j}$ 表示聚类和的质心之间的距 离。<br>算法生成的聚类结果越是朝着簇内距离最小（类内相似性最大）和笶间距离最大（类间相似性最小）变化， 那么Davies-Bouldin指数就会越小。<br><strong>缺点</strong>:</p>
<ul>
<li>因使用欧式距离, 所以对于环状分布聚类评测很差。</li>
</ul>
<h2><span id="六-评分总结sklearn">六、评分总结（sklearn）</span></h2><blockquote>
<p>  sklearn.metrics - 回归/分类模型的评估方法:<a href="https://zhuanlan.zhihu.com/p/408078074">https://zhuanlan.zhihu.com/p/408078074</a></p>
</blockquote>
<h3><span id="61-分类模型">6.1 分类模型</span></h3><h4><span id="accuracy_score"><strong>accuracy_score</strong></span></h4><p><strong>分类准确率分数是指所有分类正确的百分比</strong>。分类准确率这一衡量分类器的标准比较容易理解，但是它不能告诉你响应值的潜在分布，并且它也不能告诉你分类器犯错的类型。所以在使用的时候，一般需要搭配matplotlib等数据可视化工具来观察预测的分类情况，与实际的结果做更加直观的比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score  </span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>]  </span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]  </span><br><span class="line">accuracy_score(y_true, y_pred)  <span class="comment"># 默认normalization = True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.5</span></span><br><span class="line">accuracy_score(y_true, y_pred, normalize=<span class="literal">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">2</span></span><br></pre></td></tr></table></figure>
<h4><span id="recall_score"><strong>recall_score</strong></span></h4><p>召回率 =<strong>提取出的正确信息条数 /样本中的信息条数</strong>。通俗地说，就是所有准确的条目有多少被检索出来了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">recall_score(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>,average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">参数average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br></pre></td></tr></table></figure>
<p>将一个二分类matrics拓展到多分类或多标签问题时，我们可以将数据看成多个二分类问题的集合，每个类都是一个二分类。接着，我们可以通过跨多个分类计算每个二分类metrics得分的均值，这在一些情况下很有用。你可以使用<strong>average参数</strong>来指定。 </p>
<ul>
<li>macro：计算二分类metrics的均值，为每个类给出相同权重的分值。</li>
<li>weighted:对于不均衡数量的类来说，计算二分类metrics的平均，通过在每个类的score上进行加权实现。 </li>
<li>micro：给出了每个样本类以及它对整个metrics的贡献的pair（sample-weight），而非对整个类的metrics求和，它会每个类的metrics上的权重及因子进行求和，来计算整个份额。</li>
<li>samples：应用在multilabel问题上。它不会计算每个类，相反，它会在评估数据中，通过计算真实类和预测类的差异的metrics，来求平均（sample_weight-weighted） </li>
<li>average：average=None将返回一个数组，它包含了每个类的得分.</li>
</ul>
<h4><span id="roc_curve"><strong>roc_curve</strong></span></h4><p>ROC曲线指受试者工作特征曲线/接收器操作特性(receiver operating characteristic，ROC)曲线,是<strong>反映灵敏性和特效性连续变量的综合指标</strong>,是用构图法揭示敏感性和特异性的相互关系，它通过将连续变量设定出多个不同的临界值，从而计算出一系列敏感性和特异性。ROC曲线是根据一系列不同的二分类方式（分界值或决定阈），<strong>以真正例率（也就是灵敏度）（True Positive Rate,TPR）为纵坐标，假正例率（1-特效性）（False Positive Rate,FPR）为横坐标</strong>绘制的曲线。</p>
<p>通过ROC我们可以观察到模型正确识别的正例的比例与模型错误地把负例数据识别成正例的比例之间的权衡。TPR的增加以FPR的增加为代价。ROC曲线下的面积是模型准确率的度量，<strong>AUC</strong>（Area under roc curve）。</p>
<p><strong>TPR</strong> = TP /（TP + FN） （正样本<strong>预测数</strong> / 正样本<strong>实际数</strong>）</p>
<p><strong>FPR</strong> = FP /（FP + TN） （负样本<strong>预测数</strong> /负样本<strong>实际数</strong>）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics  </span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>])  </span><br><span class="line">scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=<span class="number">2</span>)  </span><br><span class="line">fpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.</span> ,  <span class="number">0.5</span>,  <span class="number">0.5</span>, <span class="number">1.</span> ])  </span><br><span class="line">tpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.5</span>,  <span class="number">0.5</span>,  <span class="number">1.</span> , <span class="number">1.</span> ])  </span><br><span class="line">thresholds  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.8</span> ,  <span class="number">0.4</span> ,  <span class="number">0.35</span>, <span class="number">0.1</span> ])  </span><br><span class="line"></span><br><span class="line"><span class="comment"># check auc score</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> auc   </span><br><span class="line">metrics.auc(fpr, tpr)   </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以直接根据预测值+真实值来计算出auc值，略过roc的计算过程</span></span><br><span class="line">‘’‘</span><br><span class="line">sklearn.metrics.roc_auc_score(y_true, y_score, average=<span class="string">&#x27;macro&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br><span class="line">’‘’</span><br><span class="line"><span class="comment"># 真实值（必须是二值）、预测值（可以是0/1,也可以是proba值）</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score  </span><br><span class="line">y_true = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])  </span><br><span class="line">y_scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">roc_auc_score(y_true, y_scores)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>  </span><br></pre></td></tr></table></figure>
<h4><span id="confusion-metric"><strong>confusion metric</strong></span></h4><p>混淆矩阵（confusion matrix），又称为可能性表格或是错误矩阵。它是一种特定的矩阵用来呈现算法性能的可视化效果。其每一列代表预测值，每一行代表的是实际的类别。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">confusion_matric(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>, average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="precision_score"><strong>precision_score</strong></span></h4><p>计算精确度——precision <img src="https://www.zhihu.com/equation?tex=%3DTP%2F%28TP%2FFP%29" alt="[公式]"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">precision_score(y_true, y_pred, labels=None, pos_label=1, average=&#x27;binary&#x27;)</span><br></pre></td></tr></table></figure>
<p><img src="https://pic2.zhimg.com/v2-a3b6092e30d2eab7d2372007aec15105_r.jpg" alt="preview"></p>
<h2><span id="评价指标qampa">评价指标Q&amp;A</span></h2><h4><span id="精度指标存在的问题"><strong>精度指标存在的问题</strong>？</span></h4><ul>
<li>有倾向性的问题。比如，判断空中的飞行物是导弹还是其他飞行物，很显然为了减少损失，我们更倾向于相信是导弹而采用相应的防护措施。此时判断为导弹实际上是其他飞行物与判断为其他飞行物实际上是导弹这两种情况的重要性是不一样的；</li>
<li>样本类别数量严重不均衡的情况。比如银行客户样本中好客户990个，坏客户10个。如果一个模型直接把所有客户都判断为好客户，得到精度为99%，但这显然是没有意义的。</li>
</ul>
<h4><span id="为什么-roc-和-auc-都能应用于非均衡的分类问题"><strong>为什么 ROC 和 AUC 都能应用于非均衡的分类问题？</strong></span></h4><p><strong>ROC曲线只与横坐标 (FPR) 和 纵坐标 (TPR) 有关系</strong> 。我们可以发现TPR只是正样本中预测正确的概率，而FPR只是负样本中预测错误的概率，和正负样本的比例没有关系。因此 ROC 的值与实际的正负样本比例无关，因此既可以用于均衡问题，也可以用于非均衡问题。而 AUC 的几何意义为ROC曲线下的面积，因此也和实际的正负样本比例无关。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>理论基础</category>
      </categories>
      <tags>
        <tag>评价指标</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习（7）朴素贝叶斯</title>
    <url>/posts/25V46VQ/</url>
    <content><![CDATA[<h2><span id="朴素贝叶斯">朴素贝叶斯</span></h2><p><a href="https://scikit-learn.org/dev/modules/naive_bayes.html#naive-bayes">https://scikit-learn.org/dev/modules/naive_bayes.html#naive-bayes</a></p>
<ul>
<li><p><a href="https://plushunter.github.io/2017/02/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%8810%EF%BC%89%EF%BC%9A%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/">FREE WILL 机器学习算法系列（10）：朴素贝叶斯</a></p>
</li>
<li><h5><span id="最大似然估计-最大后验估计-贝叶斯估计的对比"></span></h5></li>
</ul>
<h3><span id="一-朴素贝叶斯的学习与分类">一、朴素贝叶斯的学习与分类</span></h3><blockquote>
<p>  朴素贝叶斯（Naive Bayes）是基于<strong>贝叶斯定理</strong>与<strong>特征条件假设</strong>的<strong>分类</strong>方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入、输出的联合分布；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。朴素贝叶斯是<strong>选出各个分类类别后验概率最大</strong>的作为最终分类。</p>
<ul>
<li><strong>优点</strong>：对小规模的数据表现很好，适合多分类任务，<strong>适合增量式训练</strong>。</li>
<li><strong>缺点</strong>：对输入数据的表达形式很敏感<strong>（离散、连续，值极大极小之类的）</strong>。</li>
</ul>
</blockquote>
<h4><span id="11贝叶斯定理">1.1贝叶斯定理</span></h4><p><strong>条件概率:</strong></p>
<p>$P(A|B)$  表示事件B已经发生的前提下，事件B已经发生的前提下，事件A发生的概率，叫做事件 $B$<br>发生下事件 $A$ 的条件概率。其基本求解公式为</p>
<p><img src="image-20220325172121116.png" alt="image-20220325172121116" style="zoom:50%;"></p>
<p><strong>贝叶斯定理</strong>便是基于<strong>条件概率</strong>，通过$P(A|B)$来求$P(B|A)$：【通过<strong>先验概率</strong>计算<strong>后验概率</strong>】</p>
<p><img src="image-20220325172351101.png" alt="image-20220325172351101" style="zoom:50%;"></p>
<p>顺便提一下，上式中的分母，可以根据<strong>全概率公式</strong>分解为：</p>
<p><img src="image-20220325172306652.png" alt="image-20220325172306652" style="zoom:50%;"></p>
<h4><span id="12-特征条件独立假设">1.2 特征条件独立假设</span></h4><p>这一部分开始朴素贝叶斯的理论推导，从中你会深刻地理解什么是特征条件<strong>独立假设</strong>。给定训练数据集$(X,Y)$，其中每个样本$X$都包括 $n$ 维特征，即$x=(x1,x2,···,xn)$，类标记集合含有$K$种类别，即$y=(y1,y2,···,yk)$.</p>
<p>如果现在来了一个新样本 $x$ 我们要怎么判断它的类别?从概率的角度来看，这个问题就是给定$x$，它属于哪个类别的概率更大。那么问题就转化为求解 $P(y1|x),P(y2|x),P(yk|x)P(y1|x),P(y2|x),P(yk|x)$ 中最大的那个，即求<strong>后验概率最大</strong>的输出：==$arg max_{y_k}P(y_k|x)$==</p>
<p><img src="image-20220325203314162.png" alt="image-20220325203314162" style="zoom:50%;"></p>
<p>根据<strong>全概率公式</strong>，可以进一步分解上式中的分母：</p>
<p><img src="image-20220325203335825.png" alt="image-20220325203335825" style="zoom:50%;"></p>
<ul>
<li><p><img src="image-20220325205350669.png" alt="image-20220325205350669" style="zoom:50%;">：<strong>先验概率</strong> 【训练集计算】</p>
</li>
<li><p><img src="image-20220325205444531.png" alt="image-20220325205444531" style="zoom:50%;">：<strong>条件概率</strong>，它的参数规模是<strong>指数</strong>数量级别的。假设第i维特征xi可取值的个数有Si个，类别取值个数为k个，那么参数个数为$k∏S_j$。</p>
</li>
<li><p><strong>独立性的假设</strong>：通俗地讲就是说假设各个维度的特征互相独立，这样<strong>参数规模</strong>就降到了$∑S_ik$, 【积-&gt;和】</p>
<p><img src="image-20220325211846297.png" alt="image-20220325211846297" style="zoom:50%;"></p>
</li>
<li><p>代入公式1得出：</p>
<p><img src="image-20220325213643901.png" alt="image-20220325213643901" style="zoom:50%;"></p>
</li>
<li><p>于是朴素贝叶斯分类器可表示为：</p>
<p><img src="image-20220325213705861.png" alt="image-20220325213705861" style="zoom:50%;"></p>
</li>
<li><p>由于分母值都是一样的：<strong>==极大后验概率估计==</strong></p>
</li>
</ul>
<p><img src="image-20220325213802190.png" alt="image-20220325213802190" style="zoom:50%;"></p>
<h4><span id="13-朴素贝叶斯法的参数估计求解">1.3 朴素贝叶斯法的参数估计【求解】</span></h4><p>朴素贝叶斯要学习的东西就是：<img src="image-20220325215221520.png" alt="image-20220325215221520" style="zoom:50%;"> 和 <img src="image-20220325215238733.png" alt="image-20220325215238733" style="zoom:50%;">【极大似然函数 + 拉格朗日乘数法】</p>
<ul>
<li><p><strong>先验概率</strong>$P(Y=ck)$的极大似然估计是, <strong>样本在$c_k$出现的次数除以样本容量</strong>：</p>
<p><img src="image-20220325215849572.png" alt="image-20220325215849572" style="zoom:50%;"></p>
</li>
<li><p>$设第 j 个特征x(j)可能取值的集合为a_{j1},a_{j2},···,a_{jl}, 条件概率P(X_j=a_{jl} |Y=ck)的极大似然估计是$：</p>
<p><img src="image-20220325221320810.png" alt="image-20220325221320810" style="zoom:50%;"></p>
</li>
</ul>
<h4><span id="14-贝叶斯估计缺失值处理拉普拉斯平滑">1.4 贝叶斯估计【缺失值处理】【拉普拉斯平滑】</span></h4><p><strong>先验概率</strong>的贝叶斯估计：</p>
<p><img src="image-20220325222259483.png" alt="image-20220325222259483" style="zoom:50%;"></p>
<p><strong>条件概率</strong>的贝叶斯估计：【<strong>离散型</strong>】</p>
<p><img src="image-20220325222226643.png" alt="image-20220325222226643" style="zoom:50%;"></p>
<h4><span id="15-朴素贝叶斯有什么优缺点"><strong><font color="red"> 1.5 朴素贝叶斯有什么优缺点？</font></strong></span></h4><h5><span id="优点数学理论-缺失异常不敏感-快-增量式训练">优点：【数学理论、缺失异常不敏感、快、增量式训练】</span></h5><ul>
<li>朴素贝叶斯模型<strong>发源于古典数学理论</strong>，有稳定的分类效率。</li>
<li><strong>对缺失数据和异常数据不太敏感</strong>，算法也比较简单，常用于文本分类。</li>
<li><strong>分类准确度高，速度快</strong>。</li>
<li><strong>对小规模的数据表现很好，能处理多分类任务，适合增量式训练，当数据量超出内存时，我们可以一批批的去增量训练</strong>(朴素贝叶斯在训练过程中只需要计算各个类的概率和各个属性的类条件概率，这些概率值可以快速地根据增量数据进行更新，无需重新全量计算)。</li>
</ul>
<h5><span id="缺点">缺点：</span></h5><ul>
<li><strong>对输入数据的表达形式很敏感（离散、连续，值极大极小之类的）</strong>。</li>
<li><strong>对训练数据的依赖性很强</strong>，如果训练数据误差较大，那么预测出来的效果就会不佳。</li>
<li>理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。 但是在实际中，因为朴素贝叶斯“朴素，”的特点，<strong>导致在属性个数比较多或者属性之间相关性较大时，分类效果不好。</strong>而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。</li>
<li>需要知道<strong>先验概率</strong>，且先验概率很多时候是基于假设或者已有的训练数据所得的，这在某些时候可能会因为假设先验概率的原因出现分类决策上的错误。</li>
</ul>
<h2><span id="二-高斯贝叶斯模型">二、高斯贝叶斯模型</span></h2><blockquote>
<p>  classifier = naive_bayes.MultinomialNB()</p>
</blockquote>
<h4><span id="21-朴素贝叶斯连续型数据处理">2.1 朴素贝叶斯(连续型数据处理)</span></h4><ul>
<li>每一个连续的<strong>数据离散化</strong>，然后用相应的离散区间替换连续数值。这种方法对于划分离散区间的粒度要求较高，不能太细，也不能太粗。</li>
<li>假设<strong>连续数据服从某个概率分布</strong>，<strong>使用训练数据估计分布参数</strong>，通常我们用<strong>高斯分布</strong>来表示<strong>连续数据的类条件概率分布</strong>。</li>
</ul>
<p><strong>==GaussianNB 的条件概率密度计算：其中均值和方差可以通过极大似然估计得出。==</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
&p\left(X^{(j)}=a_{j l} \mid y=c_{k}\right)=\frac{1}{\sqrt{2 \pi} \sigma_{j k}} e^{-\frac{\left(a_{j l}-\mu_{j k}\right)^{2}}{2 \sigma_{j k}^{2}}}
\end{aligned}</script><h2><span id="三-贝叶斯网络">三、贝叶斯网络</span></h2><h4><span id="31-概率图模型">3.1 概率图模型</span></h4><p>概率图模型分为<strong>贝叶斯网络（Bayesian Network）和马尔可夫网络（Markov Network）</strong>两大类。贝叶斯网络可以用一个有向图结构表示，马尔可夫网络可以表示成一个无向图的网络结构。更详细地说，<strong>概率图模型包括了朴素贝叶斯模型、最大熵模型、隐马尔可夫模型、条件随机场、主题模型</strong>等，在机器学习的诸多场景中都有着广泛的应用。</p>
<ul>
<li><strong>贝叶斯网络</strong> — 结点与结点之间是以有向箭头相连接，代表是这个结点会影响下一个结点</li>
<li><strong>马尔可夫网络</strong> — 结点与结点之间是以无向箭头相连接，代表是结点与结点之间会相互影响</li>
</ul>
<h2><span id="四-最大似然估计-最大后验估计-贝叶斯估计的对比">四、最大似然估计、最大后验估计、贝叶斯估计的对比</span></h2><h4><span id="41-贝叶斯公式">4.1 <strong>贝叶斯公式</strong></span></h4><p>这三种方法都和贝叶斯公式有关，所以我们先来了解下贝叶斯公式：</p>
<script type="math/tex; mode=display">
p(\theta \mid X)=\frac{p(X \mid \theta) p(\theta)}{p(X)}</script><p>每一项的表示如下:</p>
<script type="math/tex; mode=display">
\text { posterior }=\frac{\text { likehood } * \text { prior }}{\text { evidence }}</script><ul>
<li>posterior: 通过样本X得到参数 $\theta$ 的概率, 也就是后验概率。</li>
<li>likehood: 通过参数 $\theta$ 得到样本X的概率, 似然函数, 通常就是我们的数据集的表现。</li>
<li>prior: 参数 $\theta$ 的先验概率, 一般是根据人的先验知识来得出的。</li>
</ul>
<h4><span id="42-极大似然估计-mle">4.2 极大似然估计 (MLE)</span></h4><p>极大似然估计的核心思想是: 认为当前发生的事件是概率最大的事件。<strong>因此就可以给定的数据集, 使得该数据集发生的概率最大来求得模型中的参数</strong>。似然函数如下:</p>
<script type="math/tex; mode=display">
p(X \mid \theta)=\prod_{x 1}^{x n} p(x i \mid \theta)</script><p>为了便于计算, 我们对似然函数两边取对数, 生成新的对数似然函数（因为对数函数是单调增函数, 因此求似然函数最大化就可 以转换成对数似然函数最大化）：</p>
<script type="math/tex; mode=display">
p(X \mid \theta)=\prod_{x 1}^{x n} p(x i \mid \theta)=\sum_{x 1}^{x n} \log p(x i \mid \theta)</script><p>求对数似然函数最大化, 可以通过导数为 0 来求解。<strong><font color="red"> 极大似然估计只关注当前的样本, 也就是只关注当前发生的事情, 不考虑事情的先验情况</font></strong>。由于计算简单, 而且不需要关注先验 知识, 因此在机器学习中的应用非常广, 最常见的就是逻辑回归。</p>
<h4><span id="43-最大后验估计-map">4.3 最大后验估计 (MAP)</span></h4><p>和最大似然估计不同的是, 最大后验估计中引入了<strong>先验概率</strong>（先验分布属于贝叶斯学派引入的, 像L1, L2正则化就是对参数引入 了拉普拉斯先验分布和高斯先验分布）, 而且最大后验估计要求的是 $p(\theta \mid X)$<br>最大后验估计可以写成下面的形式:</p>
<script type="math/tex; mode=display">
\operatorname{argmaxp}(\theta \mid X)=\operatorname{argmax} \frac{p(X \mid \theta) p(\theta)}{p(X)}=\operatorname{argmaxp}(X \mid \theta) p(\theta)=\operatorname{argmax}\left(\prod_{x 1}^{x n} p(x i \mid \theta)\right) p(\theta)</script><p>在求最大后验概率时, 可以忽略分母 $p(x)$, 因为该值不影响对 $\theta$ 的估计。同样为了便于计算, 对两边取对数, 后验概率最大化就变成了:</p>
<script type="math/tex; mode=display">
\operatorname{argmax}\left(\sum_{x 1}^{x n} \operatorname{logp}(x i \mid \theta)+\log p(\theta)\right)</script><p><strong><font color="red"> 最大后验估计不只是关注当前的样本的情况，还关注已经发生过的先验知识。在朴素贝叶斯中会有最大后验概率的应用，但并没有用上最大后验估计来求参数（因为朴素贝叶斯中的θ其实就是分类的类别）。</font></strong></p>
<p><strong>最大后验估计和最大似然估计的区别：</strong>最大后验估计允许我们把先验知识加入到估计模型中，<strong>这在样本很少的时候是很有用的（因此朴素贝叶斯在较少的样本下就能有很好的表现）</strong>，因为样本很少的时候我们的观测结果很可能出现偏差，此时先验知识会把估计的结果“拉”向先验，实际的预估结果将会在先验结果的两侧形成一个顶峰。通过调节先验分布的参数，比如beta分布的α，β，我们还可以调节把估计的结果“拉”向先验的幅度，α，β越大，这个顶峰越尖锐。这样的参数，我们叫做预估模型的“超参数”。</p>
<h2><span id="朴素贝叶斯-qampa">朴素贝叶斯 Q&amp;A</span></h2><blockquote>
<ul>
<li>朴素贝叶斯分类器原理以及公式，出现估计概率值为 0 怎么处理（拉普拉斯平滑），缺点；</li>
<li>解释贝叶斯公式和朴素贝叶斯分类。</li>
<li>贝叶斯分类，这是一类分类方法，主要代表是朴素贝叶斯，朴素贝叶斯的原理，重点在假设各个属性类条件独立。然后能根据贝叶斯公式具体推导。考察给你一个问题，如何利用朴素贝叶斯分类去分类，比如：给你一个人的特征，判断是男是女，比如身高，体重，头发长度等特征的的数据，那么你要能推到这个过程。给出最后的分类器公式。</li>
<li>那你说说贝叶斯怎么分类啊？<strong>比如说看看今天天气怎么样？</strong>我：blabla，，，利用天气的历史数据，可以知道天气类型的先验分布，以及每种类型下特征数据（比如天气数据的特征：温度啊，湿度啊）的条件分布，这样我们根据贝叶斯公式就能求得天气类型的后验分布了。。。。面试官：en（估计也比较满意吧）<strong>那你了解关于求解模型的优化方法吗？一般用什么优化方法来解？</strong></li>
<li>贝叶斯分类器的优化和特殊情况的处理</li>
</ul>
</blockquote>
<h3><span id="1-朴素贝叶斯-svm和lr的区别"><strong><font color="red"> 1、朴素贝叶斯、SVM和LR的区别？</font></strong></span></h3><p><strong>朴素贝叶斯是生成模型</strong>，根据已有样本进行贝叶斯估计学习出先验概率P(Y)和条件概率P(X|Y)，进而求出联合分布概率P(XY),最后利用贝叶斯定理求解P(Y|X)。</p>
<p><strong>LR是判别模型</strong>，根据极大化对数似然函数直接求出条件概率P(Y|X)；朴素贝叶斯是基于很强的条件独立假设（在已知分类Y的条件下，各个特征变量取值是相互独立的），而LR则对此没有要求；<strong>朴素贝叶斯适用于数据集少的情景，而LR适用于大规模数据集。</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>SVM</th>
<th>LR</th>
<th>朴素贝叶斯</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>思想</strong></td>
<td><strong>想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面</strong>。</td>
<td>使用线性回归模型的预测值逼近分类任务真实标记的对数几率。</td>
<td>基于<strong>贝叶斯定理</strong>与<strong>特征条件假设</strong>的<strong>分类</strong>方法。选出各个分类类别后验概率最大的作为最终分类。</td>
</tr>
<tr>
<td><strong>输出</strong></td>
<td>判别模型、<strong>非概率方法</strong>；</td>
<td><strong>概率方法</strong>；需要对$p(y</td>
<td>x)$进行假设，具有概率意义。</td>
<td>生成模型</td>
</tr>
<tr>
<td><strong>经验损失函数</strong></td>
<td><strong>合页损失函数</strong>；有一段平的零区域、使得SVM的对偶性有稀疏性。</td>
<td><strong>交叉熵损失函数</strong></td>
<td><strong>后验概率最大</strong></td>
</tr>
<tr>
<td><strong>训练样本</strong></td>
<td><strong>支持向量</strong>（少数样本），SVM的参数和假设函数只和支持向量有关。</td>
<td>全样本</td>
<td>全样本</td>
</tr>
<tr>
<td><strong>优化方法</strong></td>
<td>次梯度下降和坐标梯度下降 【<strong>SMO算法</strong>】</td>
<td><strong>梯度下降</strong></td>
<td>无</td>
</tr>
<tr>
<td>多分类</td>
<td><strong>多分类SVM</strong></td>
<td><strong>Softmax回归</strong></td>
<td>后验概率最大</td>
</tr>
<tr>
<td><strong>敏感程度</strong></td>
<td><strong>SVM考虑分类边界线附近的样本</strong>（决定分类超平面的样本）。在支持向量外添加或减少任何样本点对分类决策面没有任何影响；【不敏感】</td>
<td><strong>LR受所有数据点的影响</strong>。直接依赖数据分布，每个样本点都会影响决策面的结果。如果训练数据不同类别严重不平衡。【敏感】</td>
<td><strong>特征值是基于频数进行统计的。</strong>一个值的异常（变成了别的数），<strong>只是贝叶斯公式里的计算概率的分子或者分母发生微小的变化，整体结果影响不大</strong>，不敏感【概率排序】</td>
</tr>
</tbody>
</table>
</div>
<h3><span id="2-朴素贝叶斯朴素在哪里">2、<strong>朴素贝叶斯“朴素”在哪里？</strong></span></h3><p>简单来说：它假定<strong>所有的特征在数据集中的作用是同样重要和独立的</strong>，正如我们所知，这个假设在现实世界中是很不真实的，因此，说朴素贝叶斯真的很“朴素”。</p>
<p>利用贝叶斯定理求解联合概率P(XY)时，需要计算条件概率P(X|Y)。在计算P(X|Y)时，朴素贝叶斯做了一个很强的条件独立假设（当Y确定时，X的各个分量取值之间相互独立），即P(X1=x1,X2=x2,…Xj=xj|Y=yk) = P(X1=x1|Y=yk)P(X2=x2|Y=yk)…*P(Xj=xj|Y=yk)。 多个特征全是独立的，需要分别相乘。</p>
<h3><span id="3-在估计条件概率pxy时出现概率为0的情况怎么办">3、<strong>在估计条件概率P(X|Y)时出现概率为0的情况怎么办？</strong></span></h3><p><strong>拉普拉斯平滑法</strong>是朴素贝叶斯中处理零概率问题的一种修正方式。在进行分类的时候，可能会出现某个属性在训练集中没有与某个类同时出现过的情况，如果直接基于朴素贝叶斯分类器的表达式进行计算的话就会出现<strong>零概率现象</strong>。</p>
<p>为了避免其他属性所携带的信息被训练集中未出现过的属性值“抹去”，所以才使用拉普拉斯估计器进行修正。具体的方法是：<strong>在分子上加1,对于先验概率，在分母上加上训练集中label的类别数；对于特征i 在label下的条件概率，则在分母上加上第i个属性可能的取值数（特征 i 的unique()）</strong></p>
<p><strong>先验概率</strong>的贝叶斯估计：</p>
<p><img src="image-20230129161943432.png" alt="image-20230129161943432" style="zoom:50%;"></p>
<p><strong>条件概率</strong>的贝叶斯估计：【<strong>离散型</strong>】</p>
<p><img src="image-20230129162002522.png" alt="image-20230129162002522" style="zoom:50%;"></p>
<h3><span id="4-先验概率和后验概率都是">4、<strong>先验概率和后验概率都是？</strong></span></h3><p><strong>先验概率是指根据以往经验和分析得到的概率</strong>,如全概率公式,它往往作为”由因求果”问题中的”因”出现.<strong>后验概率是基于新的信息，修正原来的先验概率后所获得的更接近实际情况的概率估计。</strong></p>
<p><strong>先验概率和后验概率是相对的。</strong>如果以后还有新的信息引入，更新了现在所谓的后验概率，得到了新的概率值，那么这个新的概率值被称为后验概率。</p>
<h3><span id="5-朴素贝叶斯算法的前提假设是什么">5、<strong>朴素贝叶斯算法的前提假设是什么？</strong></span></h3><ol>
<li>特征之间相互独立</li>
<li>每个特征同等重要</li>
</ol>
<h3><span id="6-面试的时候怎么标准回答朴素贝叶斯呢">6、<strong>面试的时候怎么标准回答朴素贝叶斯呢？</strong></span></h3><p>首先朴素贝斯是一个<strong>生成模型（很重要）</strong>，其次它通过学习已知样本，计算出联合概率，再求条件概率。</p>
<h4><span id="生成模式和判别模式的区别常见"><strong>生成模式和判别模式的区别(常见)：</strong></span></h4><p><strong>生成模式</strong>：由数据学得<strong>联合概率分布，求出条件概率分布P(Y|X)的预测模型</strong>；<strong>比较在乎数据是怎么生成的</strong>；常见的生成模型有：朴素贝叶斯、隐马尔可夫模型、高斯混合模型、文档主题生成模型（LDA）、限制玻尔兹曼机。</p>
<p><strong>判别模式</strong>：由数据学得<strong>决策函数或条件概率分布作为预测模型</strong>，<strong>要关注在数据的差异分布上，而不是生成</strong>；常见的判别模型有：K近邻、SVM、决策树、感知机、线性判别分析（LDA）、线性回归、传统的神经网络、逻辑斯蒂回归、boosting、条件随机场。</p>
<h3><span id="7-为什么属性独立性假设在实际情况中很难成立但朴素贝叶斯仍能取得较好的效果排序能力">7、<strong>为什么属性独立性假设在实际情况中很难成立，但朴素贝叶斯仍能取得较好的效果?</strong>【排序能力】</span></h3><p>首先独立性假设在实际中不存在，确实会导致朴素贝叶斯不如一些其他算法，但是就算法本身而言，朴素贝叶斯也会有不错的分类效果，原因是：</p>
<ul>
<li><strong>分类问题看中的是类别的条件概率的排序</strong>，而不是具体的概率值，所以这里面对精准概率值的计算是有一定的容错的。</li>
<li>如果特征属性之间的依赖对所有类别影响相同，或依赖关系的影响能相互抵消，则属性条件独立性假设在降低计算开销的同时不会对性能产生负面影响。</li>
</ul>
<h3><span id="8-朴素贝叶斯中概率计算的下溢问题如何解决"><strong><font color="red"> 8、朴素贝叶斯中概率计算的下溢问题如何解决？</font></strong></span></h3><p><strong>在朴素贝叶斯的计算过程中，需要对特定分类中各个特征出现的概率进行连乘</strong>，小数相乘，越乘越小，这样就造成下溢出。在程序中，在相应小数位置进行四舍五入，计算结果可能就变成0了。</p>
<p>为了解决这个问题，<strong>对乘积结果取自然对数</strong>。将小数的乘法操作转化为取对数后的加法操作，规避了变为0的风险同时并不影响分类结果。</p>
<h3><span id="9-朴素贝叶斯分类器对异常值和缺失值敏感吗">9、<strong>朴素贝叶斯分类器对异常值和缺失值敏感吗？</strong></span></h3><p>回想朴素贝叶斯的计算过程，它在推理的时候，输入的某个特征组合，<strong>他们的特征值在训练的时候在贝叶斯公式中都是基于频数进行统计的。</strong>所以一个值的异常（变成了别的数），<strong>只是贝叶斯公式里的计算概率的分子或者分母发生微小的变化，整体结果影响不大</strong>，就算微微影响最终概率值的获得，由于<strong>分类问题只关注概率的排序而不关注概率的值，所以影响不大</strong>，保留异常值还可以提高模型的泛化性能。</p>
<p>缺失值也是一样，如果一个数据实例缺失了一个属性的数值，在建模的时将被忽略，不影响类条件概率的计算，在预测时，计算数据实例是否属于某类的概率时也将忽略缺失属性，不影响最终结果。</p>
<h3><span id="10-朴素贝叶斯中有没有超参数可以调">10、<strong>朴素贝叶斯中有没有超参数可以调？</strong></span></h3><p><strong>朴素贝叶斯是没有超参数可以调的，所以它不需要调参</strong>，朴素贝叶斯是根据训练集进行分类，分类出来的结果基本上就是确定了的，拉普拉斯估计器不是朴素贝叶斯中的参数，不能通过拉普拉斯估计器来对朴素贝叶斯调参。</p>
<h3><span id="11-朴素贝叶斯有哪三个模型">11、<strong>朴素贝叶斯有哪三个模型？</strong></span></h3><ul>
<li><strong>多项式模型对应于离散变量</strong>，其中离散变量指的是category型变量，也就是类别变量，比如性别；连续变量一般是数字型变量，比如年龄，身高，体重。</li>
<li><strong>高斯模型 对应于连续变量</strong>（每一维服从正态分布）</li>
<li><strong>伯努利模型</strong> <strong>对应于文本分类</strong> （特征只能是0或者1）</li>
</ul>
<h3><span id="12-朴素贝叶斯为什么适合增量计算"><strong><font color="red"> 12、朴素贝叶斯为什么适合增量计算？</font></strong></span></h3><p>朴素贝叶斯在训练过程中实际上需要<strong>计算出各个类别的概率和各个特征的条件概率</strong>，这些概率以频数统计比值（对于多项式模型而言）的形式产生概率值，<strong>可以快速根据增量数据进行更新，无需重新全量训练，所以其十分适合增量计算。</strong></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>贝叶斯分类器</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（12）降维</title>
    <url>/posts/16HRCXQ/</url>
    <content><![CDATA[<h2><span id="降维">降维</span></h2><blockquote>
<ul>
<li>数据降维算法: <a href="https://www.zhihu.com/column/c_1194552337170214912">https://www.zhihu.com/column/c_1194552337170214912</a></li>
</ul>
</blockquote>
<p><img src="https://pic2.zhimg.com/v2-e47296e78fff3d97eea11d0657ddcb81_1440w.jpg?source=172ae18b" alt="【机器学习】降维——PCA（非常详细）" style="zoom:51%;"></p>
<h2><span id="一-pca">一、PCA</span></h2><blockquote>
<p>  <strong><font color="red"> 降维问题的优化目标：将一组 N 维向量降为 K 维，其目标是选择 K 个单位正交基，使得原始数据变换到这组基上后，各变量两两间协方差为 0，而变量方差则尽可能大（在正交的约束下，取最大的 K 个方差）。</font></strong></p>
<p>  要找的 <strong>==P 是能让原始协方差矩阵对角化的 P==</strong>。换句话说，优化目标变成了<strong>寻找一个矩阵 P，满足</strong> <img src="https://www.zhihu.com/equation?tex=PCP%5ET" alt="[公式]"> <strong>是一个对角矩阵，并且对角元素按从大到小依次排列，那么 P 的前 K 行就是要寻找的基，用 P 的前 K 行组成的矩阵乘以 X 就使得 X 从 N 维降到了 K 维并满足上述优化条件</strong>。</p>
</blockquote>
<p><strong>PCA（Principal Component Analysis） 是一种常见的数据分析方式，常用于高维数据的降维，可用于提取数据的主要特征分量</strong>。PCA 的数学推导可以从<strong>==最大可分型==</strong>和<strong>最近重构性</strong>两方面进行，前者的优化条件为划分后方差最大，后者的优化条件为点到划分平面距离最小，这里我将从最大可分性的角度进行证明。</p>
<h3><span id="1-向量表示与基变换">1. 向量表示与基变换</span></h3><p>我们先来介绍些线性代数的基本知识。</p>
<h3><span id="11-内积">1.1 内积</span></h3><p><strong>两个向量的 A 和 B 内积</strong>我们知道形式是这样的：</p>
<p><img src="https://www.zhihu.com/equation?tex=%28a_1%2Ca_2%2C%5Ccdots%2Ca_n%29%5Ccdot+%28b_1%2Cb_2%2C%5Ccdots%2Cb_n%29%5E%5Cmathsf%7BT%7D%3Da_1b_1%2Ba_2b_2%2B%5Ccdots%2Ba_nb_n+%5C%5C" alt="[公式]"></p>
<p>内积运算将两个向量映射为实数，其计算方式非常容易理解，但我们无法看出其物理含义。接下来我们从几何角度来分析，为了简单起见，我们假设 A 和 B 均为二维向量，则：</p>
<p><img src="https://www.zhihu.com/equation?tex=A%3D%28x_1%2Cy_1%29%EF%BC%8CB%3D%28x_2%2Cy_2%29+%5C+A+%5Ccdot+B+%3D+%7CA%7C%7CB%7Ccos%28%5Calpha%29+%5C%5C" alt="[公式]"></p>
<p>其几何表示见下图：</p>
<p><img src="https://pic3.zhimg.com/80/v2-cf4c0041c8459d2894b9a57d8f679a0a_1440w.jpg" alt="img"></p>
<p>我们看出 A 与 B 的内积等于 <strong>A 到 B 的投影长度乘以 B 的模</strong>。</p>
<p>如果假设 B 的模为 1，即让 <img src="https://www.zhihu.com/equation?tex=%7CB%7C%3D1" alt="[公式]"> ，那么就变成了：</p>
<p><img src="https://www.zhihu.com/equation?tex=A%5Ccdot+B%3D%7CA%7Ccos%28a%29+%5C%5C" alt="[公式]"></p>
<p>也就是说，<strong>A 与 B 的内积值等于 A 向 B 所在直线投影的标量大小。</strong></p>
<h3><span id="12-基">1.2 基</span></h3><p>在我们常说的坐标系种，向量 (3,2) 其实隐式引入了一个定义：以 x 轴和 y 轴上正方向长度为 1 的向量为标准。向量 (3,2) 实际是说在 x 轴投影为 3 而 y 轴的投影为 2。<strong>注意投影是一个标量，所以可以为负。</strong></p>
<p>所以，对于向量 (3, 2) 来说，如果我们想求它在 <img src="https://www.zhihu.com/equation?tex=%281%2C0%29%2C%280%2C1%29" alt="[公式]"> 这组基下的坐标的话，分别内积即可。当然，内积完了还是 (3, 2)。</p>
<p>所以，我们大致可以得到一个结论，我们<strong>要准确描述向量，首先要确定一组基，然后给出在基所在的各个直线上的投影值，就可以了</strong>。为了方便求坐标，我们希望这组基向量模长为 1。因为向量的内积运算，当模长为 1 时，内积可以直接表示投影。然后还需要这组基是线性无关的，我们一般用正交基，非正交的基也是可以的，不过正交基有较好的性质。</p>
<h3><span id="13-基变换的矩阵表示">1.3 基变换的矩阵表示</span></h3><p>这里我们先做一个练习：对于向量 (3,2) 这个点来说，在 <img src="https://www.zhihu.com/equation?tex=%28%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%2C%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%29" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%28-%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%2C+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%29" alt="[公式]"> 这组基下的坐标是多少？</p>
<p>我们拿 (3,2) 分别与之内积，得到 <img src="https://www.zhihu.com/equation?tex=%28%5Cfrac%7B5%7D%7B%5Csqrt%7B2%7D%7D%2C-%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%29" alt="[公式]"> 这个新坐标。</p>
<p>我们可以用矩阵相乘的形式简洁的表示这个变换：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bpmatrix%7D++1%2F%5Csqrt%7B2%7D+%26+1%2F%5Csqrt%7B2%7D+%5C%5C+-1%2F%5Csqrt%7B2%7D+%26+1%2F%5Csqrt%7B2%7D+%5Cend%7Bpmatrix%7D+%5Cbegin%7Bpmatrix%7D+3+%5C%5C+2+%5Cend%7Bpmatrix%7D+%3D+%5Cbegin%7Bpmatrix%7D+5%2F%5Csqrt%7B2%7D+%5C%5C+-1%2F%5Csqrt%7B2%7D++%5Cend%7Bpmatrix%7D++%5C%5C" alt="[公式]"></p>
<p>左边矩阵的两行分别为两个基，乘以原向量，其结果刚好为新基的坐标。推广一下，如果我们有 m 个二维向量，只要将二维向量按列排成一个两行 m 列矩阵，然后用“基矩阵”乘以这个矩阵就可以得到了所有这些向量在新基下的值。例如对于数据点 <img src="https://www.zhihu.com/equation?tex=%281%2C1%29%EF%BC%8C%282%2C2%29%EF%BC%8C%283%2C3%29" alt="[公式]"> 来说，想变换到刚才那组基上，则可以这样表示：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bpmatrix%7D+1%2F%5Csqrt%7B2%7D+%26+1%2F%5Csqrt%7B2%7D+%5C%5C+-1%2F%5Csqrt%7B2%7D+%26+1%2F%5Csqrt%7B2%7D+%5Cend%7Bpmatrix%7D+%5Cbegin%7Bpmatrix%7D+1+%26+2+%26+3+%5C%5C+1+%26+2+%26+3+%5Cend%7Bpmatrix%7D+%3D+%5Cbegin%7Bpmatrix%7D+2%2F%5Csqrt%7B2%7D+%26+4%2F%5Csqrt%7B2%7D+%26+6%2F%5Csqrt%7B2%7D+%5C%5C+0+%26+0+%26+0+%5Cend%7Bpmatrix%7D+%5C%5C" alt="[公式]"></p>
<p>我们可以把它写成通用的表示形式：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bpmatrix%7D+p_1+%5C%5C+p_2+%5C%5C+%5Cvdots+%5C%5C+p_R+%5Cend%7Bpmatrix%7D+%5Cbegin%7Bpmatrix%7D+a_1+%26+a_2+%26+%5Ccdots+%26+a_M+%5Cend%7Bpmatrix%7D+%3D+%5Cbegin%7Bpmatrix%7D+p_1a_1+%26+p_1a_2+%26+%5Ccdots+%26+p_1a_M+%5C%5C+p_2a_1+%26+p_2a_2+%26+%5Ccdots+%26+p_2a_M+%5C%5C+%5Cvdots+%26+%5Cvdots+%26+%5Cddots+%26+%5Cvdots+%5C%5C+p_Ra_1+%26+p_Ra_2+%26+%5Ccdots+%26+p_Ra_M+%5Cend%7Bpmatrix%7D+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=p_i" alt="[公式]"> 是一个行向量，表示第 i 个基， <img src="https://www.zhihu.com/equation?tex=a_j" alt="[公式]"> 是一个列向量，表示第 j 个原始数据记录。实际上也就是做了一个向量矩阵化的操作。</p>
<p>==上述分析给矩阵相乘找到了一种物理解释：<strong>两个矩阵相乘的意义是将右边矩阵中的每一列向量</strong> <img src="https://www.zhihu.com/equation?tex=a_i" alt="[公式]"> <strong>变换到左边矩阵中以每一行行向量为基所表示的空间中去。</strong>也就是说一个矩阵可以表示一种线性变换。==</p>
<h3><span id="2-最大可分性">2. 最大可分性</span></h3><p>上面我们讨论了选择不同的基可以对同样一组数据给出不同的表示，<strong>如果基的数量少于向量本身的维数，则可以达到降维的效果</strong>。</p>
<p><strong>但是我们还没回答一个最关键的问题：如何选择基才是最优的。或者说，如果我们有一组 N 维向量，现在要将其降到 K 维（K 小于 N），那么我们应该如何选择 K 个基才能最大程度保留原有的信息？</strong></p>
<p>一种直观的看法是：<strong><font color="red"> 希望投影后的投影值尽可能分散，因为如果重叠就会有样本消失。当然这个也可以从熵的角度进行理解，熵越大所含信息越多。</font></strong></p>
<h4><span id="21-方差">2.1 方差</span></h4><p>我们知道数值的分散程度，可以用数学上的方差来表述。<strong>一个变量的方差可以看做是每个元素与变量均值的差的平方和的均值</strong>，即：</p>
<p><img src="https://www.zhihu.com/equation?tex=Var%28a%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7B%28a_i-%5Cmu%29%5E2%7D+%5C%5C" alt="[公式]"></p>
<p><strong>为了方便处理，我们将每个变量的均值都化为 0</strong> ，因此方差可以直接用每个元素的平方和除以元素个数表示：</p>
<p><img src="https://www.zhihu.com/equation?tex=Var%28a%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Ba_i%5E2%7D+%5C%5C" alt="[公式]"></p>
<p>于是上面的问题被形式化表述为：<strong>寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，方差值最大。</strong></p>
<h4><span id="22-协方差">2.2 协方差</span></h4><p>在一维空间中我们可以用方差来表示数据的分散程度。而对于高维数据，我们用协方差进行约束，<strong>协方差可以表示两个变量的相关性</strong>。<strong><font color="red"> 为了让两个变量尽可能表示更多的原始信息，我们希望它们之间不存在线性相关性</font></strong>，因为相关性意味着两个变量不是完全独立，必然存在重复表示的信息。</p>
<p>协方差公式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=Cov%28a%2Cb%29%3D%5Cfrac%7B1%7D%7Bm-1%7D%5Csum_%7Bi%3D1%7D%5Em%7B%28a_i-%5Cmu_a%29%28b_i-%5Cmu_b%29%7D+%5C%5C" alt="[公式]"></p>
<p>由于均值为 0，所以我们的协方差公式可以表示为：</p>
<p><img src="https://www.zhihu.com/equation?tex=Cov%28a%2Cb%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Ba_ib_i%7D+%5C%5C" alt="[公式]"></p>
<p>当样本数较大时，不必在意其是 m 还是 m-1，为了方便计算，我们分母取 m。</p>
<p><strong><font color="red"> 协方差为 0 时，表示两个变量完全不相关</font></strong>。为了让协方差为 0，我们选择第二个基时只能在与第一个基正交的方向上进行选择，因此最终选择的两个方向一定是正交的。</p>
<p>（<strong>补充</strong>：协方差为 0 时，两个变量只是线性不相关。完全独立是有问题的，才疏学浅，还望见谅。）</p>
<p><strong><font color="red"> 至此，我们得到了降维问题的优化目标：将一组 N 维向量降为 K 维，其目标是选择 K 个单位正交基，使得原始数据变换到这组基上后，各变量两两间协方差为 0，而变量方差则尽可能大（在正交的约束下，取最大的 K 个方差）。</font></strong></p>
<h4><span id="23-协方差矩阵">2.3 协方差矩阵</span></h4><p>针对我们给出的优化目标，接下来我们将从数学的角度来给出优化目标。我们看到，最终要达到的目的与<strong>变量内方差及变量间协方差</strong>有密切关系。因此我们希望能将两者统一表示，仔细观察发现，两者均可以表示为内积的形式，而内积又与矩阵相乘密切相关。于是我们有：</p>
<p>假设我们只有 a 和 b 两个变量，那么我们将它们按行组成矩阵 X：</p>
<p><img src="https://www.zhihu.com/equation?tex=X%3D%5Cbegin%7Bpmatrix%7D++a_1+%26+a_2+%26+%5Ccdots+%26+a_m+%5C%5C+b_1+%26+b_2+%26+%5Ccdots+%26+b_m++%5Cend%7Bpmatrix%7D+%5C%5C" alt="[公式]"></p>
<p>然后：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7Bm%7DXX%5E%5Cmathsf%7BT%7D%3D+%5Cbegin%7Bpmatrix%7D++%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Ba_i%5E2%7D+%26+%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Ba_ib_i%7D+%5C%5C+%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Ba_ib_i%7D+%26+%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Bb_i%5E2%7D++%5Cend%7Bpmatrix%7D+%3D+%5Cbegin%7Bpmatrix%7D++Cov%28a%2Ca%29+%26+Cov%28a%2Cb%29+%5C%5C++Cov%28b%2Ca%29+%26+Cov%28b%2Cb%29+%5Cend%7Bpmatrix%7D+%5C%5C" alt="[公式]"></p>
<p>我们可以看到这个矩阵对角线上的分别是两个变量的方差，而其它元素是 a 和 b 的协方差。两者被统一到了一个矩阵里。</p>
<p><strong>设我们有 m 个 n 维数据记录，将其排列成矩阵</strong> <img src="https://www.zhihu.com/equation?tex=X_%7Bn%2Cm%7D" alt="[公式]"> <strong>，设</strong> <img src="https://www.zhihu.com/equation?tex=C%3D%5Cfrac%7B1%7D%7Bm%7DXX%5ET" alt="[公式]"> <strong>，则 C 是一个对称矩阵，其对角线分别对应各个变量的方差，而第 i 行 j 列和 j 行 i 列元素相同，表示 i 和 j 两个变量的协方差</strong>。</p>
<h4><span id="24-矩阵对角化">2.4 矩阵对角化</span></h4><p>根据我们的优化条件，<strong>我们需要将除对角线外的其它元素化为 0，并且在对角线上将元素按大小从上到下排列（变量方差尽可能大）</strong>，这样我们就达到了优化目的。这样说可能还不是很明晰，我们进一步看下原矩阵与基变换后矩阵协方差矩阵的关系。</p>
<p>设原始数据矩阵 X 对应的协方差矩阵为 C，而 P 是一组基按行组成的矩阵，设 Y=PX，则 Y 为 X 对 P 做基变换后的数据。设 Y 的协方差矩阵为 D，我们推导一下 D 与 C 的关系：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D++D+%26+%3D++%5Cfrac%7B1%7D%7Bm%7DYY%5ET+%5C%5C++%26+%3D+%5Cfrac%7B1%7D%7Bm%7D%28PX%29%28PX%29%5ET+%5C%5C+%26+%3D+%5Cfrac%7B1%7D%7Bm%7DPXX%5ETP%5ET+%5C%5C++%26+%3D+P%28%5Cfrac%7B1%7D%7Bm%7DXX%5ET%29P%5ET+%5C%5C++%26+%3D+PCP%5ET++%5Cend%7Baligned%7D++%5C%5C" alt="[公式]"></p>
<p>这样我们就看清楚了，我们要找的 <strong>==P 是能让原始协方差矩阵对角化的 P==</strong>。换句话说，优化目标变成了<strong>寻找一个矩阵 P，满足</strong> <img src="https://www.zhihu.com/equation?tex=PCP%5ET" alt="[公式]"> <strong>是一个对角矩阵，并且对角元素按从大到小依次排列，那么 P 的前 K 行就是要寻找的基，用 P 的前 K 行组成的矩阵乘以 X 就使得 X 从 N 维降到了 K 维并满足上述优化条件</strong>。</p>
<p>至此，我们离 PCA 还有仅一步之遥，我们还需要完成对角化。</p>
<p><strong>由上文知道，协方差矩阵 C 是一个是对称矩阵，在线性代数中实对称矩阵有一系列非常好的性质：</strong></p>
<ol>
<li><strong>实对称矩阵不同特征值对应的特征向量必然正交</strong>。</li>
<li><strong>设特征向量 <img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="[公式]"> 重数为 r，则必然存在 r 个线性无关的特征向量对应于 <img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="[公式]"> ，因此可以将这 r 个特征向量单位正交化。</strong></li>
</ol>
<p><strong>由上面两条可知，一个 n 行 n 列的实对称矩阵一定可以找到 n 个单位正交特征向量，设这 n 个特征向量为 <img src="https://www.zhihu.com/equation?tex=e_1%2Ce_2%2C%5Ccdots%2Ce_n" alt="[公式]"> ，我们将其按列组成矩阵： <img src="https://www.zhihu.com/equation?tex=E%3D%28e_1+%2C+e_2+%2C+%5Ccdots+%2C+e_n+%29" alt="[公式]"> 。</strong></p>
<p>则对协方差矩阵 C 有如下结论：</p>
<p><img src="https://www.zhihu.com/equation?tex=E%5ETCE%3D%5CLambda%3D%5Cbegin%7Bpmatrix%7D+%5Clambda_1+%26+%26+%26+%5C%5C+%26+%5Clambda_2+%26+%26+%5C%5C+%26+%26+%5Cddots+%26+%5C%5C+%26+%26+%26+%5Clambda_n+%5Cend%7Bpmatrix%7D+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%5CLambda" alt="[公式]"> 为对角矩阵，其对角元素为各特征向量对应的特征值（可能有重复）。到这里，我们发现我们已经找到了需要的矩阵 P： <img src="https://www.zhihu.com/equation?tex=P%3DE%5E%5Cmathsf%7BT%7D" alt="[公式]"> 。</p>
<p><strong>P 是协方差矩阵的特征向量单位化后按行排列出的矩阵</strong>，其中每一行都是 C 的一个特征向量。如果设 P 按照 <img src="https://www.zhihu.com/equation?tex=%5CLambda" alt="[公式]"> 中特征值的从大到小，将特征向量从上到下排列，则用 P 的前 K 行组成的矩阵乘以原始数据矩阵 X，就得到了我们需要的降维后的数据矩阵 Y。</p>
<blockquote>
<p>  <strong>拉格朗日乘子法证明</strong>:<strong>方差就是协方差矩阵的特征值</strong></p>
</blockquote>
<h4><span id="25-最近重构性-思路">2.5 最近重构性-思路</span></h4><p>以上的证明思路主要是基于最大可分性的思想，<strong>通过一条直线使得样本点投影到该直线上的方差最大</strong>。除此之外，我们还可以<strong>将其转换为线型回归问题，其目标是求解一个线性函数使得对应直线能够更好地拟合样本点集合</strong>。这就<strong>使得我们的优化目标从方差最大转化为平方误差最小</strong>，因为映射距离越短，丢失的信息也会越小。区别于最大可分性，这是从最近重构性的角度进行论证。</p>
<h3><span id="3-求解步骤">==3. 求解步骤==</span></h3><h4><span id="总结一下-pca-的算法步骤设有-m-条-n-维数据">总结一下 PCA 的算法步骤：<strong>设有 m 条 n 维数据。</strong></span></h4><ol>
<li><strong>将原始数据按列组成 n 行 m 列矩阵 X；</strong></li>
<li><strong>将 X 的每一行进行==零均值化==，即减去这一行的均值</strong>；【<strong>零均值化</strong>】【<strong>方差、协方差好计算</strong>】</li>
<li><strong>==求出协方差矩阵==</strong> <img src="https://www.zhihu.com/equation?tex=C%3D%5Cfrac%7B1%7D%7Bm%7DXX%5E%5Cmathsf%7BT%7D" alt="[公式]"> ；</li>
<li><strong>求出协方差矩阵的特征值及对应的特征向量</strong>；</li>
<li><strong>将特征向量按对应特征值大小从上到下按行排列成矩阵，取前 k 行组成矩阵 P</strong>；</li>
<li><img src="https://www.zhihu.com/equation?tex=Y%3DPX" alt="[公式]"> <strong>即为降维到 k 维后的数据</strong>。</li>
</ol>
<h4><span id="4-性质维度灾难-降噪-过拟合-特征独立">4. 性质【维度灾难、降噪、过拟合、特征独立】</span></h4><ol>
<li><strong>==缓解维度灾难==</strong>：PCA 算法通过舍去一部分信息之后能使得样本的采样密度增大（因为维数降低了），这是缓解维度灾难的重要手段；</li>
<li><strong>==降噪==</strong>：当数据受到噪声影响时，最小特征值对应的特征向量往往与噪声有关，将它们舍弃能在一定程度上起到降噪的效果；</li>
<li><strong>==过拟合==</strong>：PCA 保留了主要信息，但这个主要信息只是针对训练集的，而且这个主要信息未必是重要信息。有可能舍弃了一些看似无用的信息，但是这些看似无用的信息恰好是重要信息，只是在训练集上没有很大的表现，所以 PCA 也可能加剧了过拟合；</li>
<li><strong>==特征独立==</strong>：PCA 不仅将数据压缩到低维，它也使得<strong>降维之后的数据各特征相互独立</strong>；</li>
</ol>
<h3><span id="5-细节">5. 细节</span></h3><h4><span id="51-零均值化">5.1 零均值化</span></h4><p>当对训练集进行 PCA 降维时，也需要对验证集、测试集执行同样的降维。==而<strong>对验证集、测试集执行零均值化操作时，均值必须从训练集计算而来</strong>，不能使用验证集或者测试集的中心向量。==</p>
<p>其原因也很简单，因为我们的训练集时可观测到的数据，测试集不可观测所以不会知道其均值，而验证集再大部分情况下是在处理完数据后再从训练集中分离出来，一般不会单独处理。如果真的是单独处理了，不能独自求均值的原因是和测试集一样。</p>
<p>另外我们也需要保证一致性，我们拿训练集训练出来的模型用来预测测试集的前提假设就是两者是独立同分布的，如果不能保证一致性的话，会出现 Variance Shift 的问题。</p>
<h4><span id="52-svd-的对比">==5.2 SVD 的对比==</span></h4><p>这是两个不同的数学定义。我们先给结论：<strong>特征值和特征向量是针对方阵</strong>才有的，而<strong>对任意形状的矩阵都可以做奇异值分解</strong>。</p>
<p><strong>PCA</strong>：<strong>方阵的特征值分解</strong>，对于一个方阵 A。其中，Q 是这个矩阵 A 的特征向量组成的矩阵， <img src="https://www.zhihu.com/equation?tex=%5CLambda" alt="[公式]"> 是一个对角矩阵，每一个对角线元素就是一个特征值，里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变化方向（从主要的变化到次要的变化排列)。也就是说矩阵 A 的信息可以由其特征值和特征向量表示。</p>
<p><strong>SVD</strong>：<strong>矩阵的奇异值分解其实就是对于矩阵 A 的协方差矩阵 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=AA%5ET" alt="[公式]"> 做特征值分解推导出来的</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=A_%7Bm%2Cn%7D%3DU_%7Bm%2Cm%7D%5CLambda_%7Bm%2Cn%7DV%5ET_%7Bn%2Cn%7D+%5Capprox+U_%7Bm%2Ck%7D%5CLambda_%7Bk%2Ck%7DV%5ET_%7Bk%2Cn%7D+%5C%5C" alt="[公式]"></p>
<p>其中：U V 都是正交矩阵，有 <img src="https://www.zhihu.com/equation?tex=U%5ETU%3DI_m%2C+V%5ETV%3DI_n" alt="[公式]"> 。这里的约等于是因为 <img src="https://www.zhihu.com/equation?tex=%5CLambda" alt="[公式]"> 中有 n 个奇异值，但是由于排在后面的很多接近 0，所以我们可以仅保留比较大的 k 个奇异值。</p>
<p><img src="https://www.zhihu.com/equation?tex=A%5ETA%3D%28U+%5CLambda+V%5ET%29%5ETU+%5CLambda+V%5ET+%3DV+%5CLambda%5ET+U%5ETU+%5CLambda+V%5ET++%3D+V%5CLambda%5E2+V%5ET+%5C%5C+AA%5ET%3DU+%5CLambda+V%5ET%28U+%5CLambda+V%5ET%29%5ET+%3DU+%5CLambda+V%5ETV+%5CLambda%5ET+U%5ET+%3D+U%5CLambda%5E2+U%5ET++%5C%5C" alt="[公式]"></p>
<p>所以，V U 两个矩阵分别是 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=AA%5ET" alt="[公式]"> 的特征向量，中间的矩阵对角线的元素是 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=AA%5ET" alt="[公式]"> 的特征值。我们也很容易看出 A 的奇异值和 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 的特征值之间的关系。</p>
<p>PCA 需要对协方差矩阵 <img src="https://www.zhihu.com/equation?tex=C%3D%5Cfrac%7B1%7D%7Bm%7DXX%5ET" alt="[公式]"> 。进行特征值分解； SVD 也是对 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 进行特征值分解。如果取 <img src="https://www.zhihu.com/equation?tex=A%3D%5Cfrac%7BX%5ET%7D%7B%5Csqrt%7Bm%7D%7D" alt="[公式]"> 则两者基本等价。所以 PCA 问题可以转换成 SVD 求解。</p>
<p><strong>==而实际上 Sklearn 的 PCA 就是用 SVD 进行求解的==</strong>，原因有以下几点：</p>
<ol>
<li>当样本维度很高时，协方差矩阵计算太慢；</li>
<li>方阵特征值分解计算效率不高；</li>
<li><strong>==SVD 除了特征值分解这种求解方式外，还有更高效更准确的迭代求解方式，避免了 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 的计算；==</strong></li>
<li><strong>其实 PCA 与 SVD 的右奇异向量的压缩效果相同</strong>。</li>
</ol>
<blockquote>
<ol>
<li>《机器学习》周志华</li>
<li><a href="https://link.zhihu.com/?target=https%3A//blog.codinglabs.org/articles/pca-tutorial.html">PCA 的数学原理</a></li>
<li><a href="https://link.zhihu.com/?target=http%3A//web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm">Singular Value Decomposition (SVD) tutorial</a></li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.cnblogs.com/LeftNotEasy/archive/2011/01/08/lda-and-pca-machine-learning.html">机器学习中的数学（4）——线性判别分析（LDA）, 主成分分析（PCA）</a></li>
<li><a href="https://link.zhihu.com/?target=https%3A//my.oschina.net/findbill/blog/535044">从SVD到PCA——奇妙的数学游戏</a></li>
<li>scikit-learn：降维算法PCA和SVD <a href="https://blog.csdn.net/HHG20171226/article/details/102981822">https://blog.csdn.net/HHG20171226/article/details/102981822</a></li>
</ol>
</blockquote>
<h2><span id="二-线性判别分析lda监督">二、线性判别分析（LDA）【监督】</span></h2><blockquote>
<p>  ==<strong>“投影后类内方差最小，类间方差最大”</strong>==</p>
<ul>
<li><a href="https://blog.csdn.net/liuweiyuxiang/article/details/78874106">https://blog.csdn.net/liuweiyuxiang/article/details/78874106</a></li>
</ul>
</blockquote>
<h3><span id="21-概念">2.1 概念</span></h3><p><strong>线性判别分析（Linear Discriminant Analysis，LDA）是一种经典的降维方法。和主成分分析PCA不考虑样本类别输出的无监督降维技术不同，LDA是一种监督学习的降维技术，数据集的每个样本有类别输出。</strong></p>
<p><strong>LDA分类思想简单总结如下：</strong></p>
<ol>
<li>多维空间中，数据处理分类问题较为复杂，LDA算法将多维空间中的数据投影到一条直线上，将d维数据转化成1维数据进行处理。</li>
<li>对于训练数据，设法将多维数据投影到一条直线上，<strong>同类数据的投影点尽可能接近，异类数据点尽可能远离</strong>。</li>
<li>对数据进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定样本的类别。</li>
</ol>
<p><strong><font color="red"> 如果用一句话概括LDA思想，即“投影后类内方差最小，类间方差最大”。</font></strong></p>
<p>假设有红、蓝两类数据，这些数据特征均为二维，如下图所示。我们的目标是将这些数据投影到一维，让每一类相近的数据的投影点尽可能接近，不同类别数据尽可能远，即图中红色和蓝色数据中心之间的距离尽可能大。</p>
<p><img src="image-20220526135646769.png" alt="image-20220526135646769"></p>
<p> 从上图直观看出，右图红色数据和蓝色数据在各自的区域来说相对集中，根据数据分布直方图也可看出，所以右图的投影效果好于左图，左图中间直方图部分有明显交集。 以上例子是基于数据是二维的，分类后的投影是一条直线。如果原始数据是多维的，则投影后的分类面是一低维的超平面。</p>
<h3><span id="22-原理">2.2 原理</span></h3><p> LDA的原理是，将带上标签的数据（点），通过投影的方法，投影到维度更低的空间中，使得投影后的点，会形成按类别区分，一簇一簇的情况，相同类别的点，将会在投影后的空间中更接近。要说明白LDA，首先得弄明白线性分类器(<a href="http://en.wikipedia.org/wiki/Linear_classifier">Linear Classifier</a>)：因为LDA是一种线性分类器。对于<strong>K-分类的一个分类问题，会有K个线性函数</strong>：</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455464493.png" alt="image"></p>
<p>当满足条件：对于所有的j，都有Yk &gt; Yj,的时候，我们就说x属于类别k。对于每一个分类，都有一个公式去算一个分值，在所有的公式得到的分值中，找一个最大的就是所属的分类了。</p>
<p>上式实际上就是一种投影，是将一个高维的点投影到一条高维的直线上，LDA最求的目标是，给出一个标注了类别的数据集，投影到了一条直线之后，能够使得点尽量的按类别区分开，当k=2即二分类问题的时候，如下图所示：</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455475507.gif" alt="clip_image002" style="zoom:67%;"></p>
<p>红色的方形的点为0类的原始点、蓝色的方形点为1类的原始点，经过原点的那条线就是投影的直线，从图上可以清楚的看到，红色的点和蓝色的点被<strong>原点</strong>明显的分开了，这个数据只是随便画的，如果在高维的情况下，看起来会更好一点。下面我来推导一下二分类LDA问题的公式：假设用来区分二分类的直线（投影函数)为：</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455471885.png" alt="image"></p>
<p> <strong>LDA分类的一个目标是使得==不同类别==之间的距离越远越好，==同一类别==之中的距离越近越好</strong>，所以我们需要定义几个关键的值。</p>
<ul>
<li><p><strong>==类别i的原始中心点为==</strong>：（Di表示属于类别i的点)</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455478264.png" alt="image"></p>
</li>
<li><p>类别i投影后的中心点为：</p>
</li>
</ul>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455488231.png" alt="image"></p>
<ul>
<li><strong>==衡量类别i投影后，类别点之间的分散程度（方差）为==</strong>：</li>
</ul>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455487326.png" alt="image"></p>
<ul>
<li><strong>==最终我们可以得到一个下面的公式，表示LDA投影到w后的损失函数==</strong>：</li>
</ul>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455484785.png" alt="image"></p>
<p>我们<strong>分类的目标是，使得类别内的点距离越近越好（集中），类别间的点越远越好。</strong>分母表示每一个类别内的方差之和，方差越大表示一个类别内的点越分散，分子为两个类别各自的中心点的距离的平方，我们最大化J(w)就可以求出最优的w了。想要求出最优的w，可以使用拉格朗日乘子法，但是现在我们得到的J(w)里面，w是不能被单独提出来的，我们就得想办法将w单独提出来。</p>
<p> 我们定义一个<strong>投影前的==各类别分散程度的矩阵==</strong>，这个矩阵看起来有一点麻烦，其实意思是，如果某一个分类的<strong>输入点集Di里面的点距离这个分类的中心店mi越近</strong>，则Si里面元素的值就越小，如果分类的点都紧紧地围绕着mi，则Si里面的元素值越更接近0.</p>
<script type="math/tex; mode=display">
S_{i}=\sum_{x \in D_{i}}\left(x-m_{i}\right)\left(x-m_{i}\right)^{T}</script><p>带入 $\mathrm{Si}$, 将 $\mathrm{J}(\mathrm{w})$ 分母化为:</p>
<p>$\tilde{s}_{i}=\sum_{x \in D_{i}}\left(w^{T} x-w^{T} m_{i}\right)^{2}=\sum_{x \in D_{i}} w^{T}\left(x-m_{i}\right)\left(x-m_{i}\right)^{T} w=w^{T} S_{i} w$</p>
<script type="math/tex; mode=display">{\tilde{S_{1}}}^{2}+{\tilde{S_{2}}}^{2}=w^{T}\left(S_{1}+S_{2}\right) w=w^{T} S_{w} w</script><p>同样的将 $\mathrm{J}(\mathrm{w})$ 分子化为:</p>
<script type="math/tex; mode=display">
\left|\widetilde{m_{1}}-\widetilde{m_{2}}\right|^{2}=w^{T}\left(m_{1}-m_{2}\right)\left(m_{1}-m_{2}\right)^{T} w=w^{T} S_{B} w</script><p>这样<strong>损失函数</strong>可以化成下面的形式:</p>
<script type="math/tex; mode=display">
J(w)=\frac{w^{T} S_{B} w}{w^{T} S_{w} w}</script><p>这样就可以用最喜欢的<strong>==拉格朗日乘子法==</strong>了, 但是还有一个问题, 如果分子、分母是都可以取任意值的, 那就会 使得有无穷解, 我们将分母限制为长度为 1, 并作为拉格朗日乘子法的限制条件, 带入得到:</p>
<script type="math/tex; mode=display">
\begin{aligned}
&c(w)=w^{T} S_{B} w-\lambda\left(w^{T} S_{w} w-1\right) \\
&\Rightarrow \frac{d c}{d w}=2 S_{B} w-2 \lambda S_{w} w=0 \\
&\Rightarrow S_{B} w=\lambda S_{w} w
\end{aligned}</script><p><strong>==这样的式子就是一个求特征值的问题了。==</strong><br>对于 $N(N&gt;2)$ 分类的问题, 我就直接写出下面的结论了:</p>
<script type="math/tex; mode=display">
\begin{aligned}
&S_{W}=\sum_{i=1}^{c} S_{i} \\
&S_{B}=\sum_{i=1}^{c} n_{i}\left(m_{i}-m\right)\left(m_{i}-m\right)^{T} \\
&S_{B} w_{i}=\lambda S_{w} w_{i}
\end{aligned}</script><p>这同样是一个求特征值的问题，我们求出的第i大的特征向量，就是对应的Wi了。</p>
<blockquote>
<p>  这里想多谈谈特征值，特征值在纯数学、量子力学、固体力学、计算机等等领域都有广泛的应用，特征值表示的是矩阵的性质，当我们取到矩阵的前N个最大的特征值的时候，我们可以说提取到的矩阵主要的成分（这个和之后的PCA相关，但是不是完全一样的概念）。在机器学习领域，不少的地方都要用到特征值的计算，比如说图像识别、pagerank、LDA、还有之后将会提到的PCA等等。</p>
</blockquote>
<p><strong>优缺点</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>优缺点</th>
<th>简要说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>优点</td>
<td>1. 可以使用类别的先验知识； 2. 以标签、类别衡量差异性的有监督降维方式，相对于PCA的模糊性，其目的更明确，更能反映样本间的差异；</td>
</tr>
<tr>
<td>缺点</td>
<td>1. LDA不适合对非高斯分布样本进行降维； 2. <strong>LDA降维最多降到分类数k-1维</strong>； 3. LDA在样本分类信息依赖方差而不是均值时，降维效果不好； 4. LDA可能过度拟合数据。</td>
</tr>
</tbody>
</table>
</div>
<h2><span id="三-t-sne-高维数据可视化">三、t-SNE 高维数据可视化</span></h2><blockquote>
<p>  高维数据可视化之t-SNE算法🌈:<a href="https://zhuanlan.zhihu.com/p/57937096">https://zhuanlan.zhihu.com/p/57937096</a></p>
</blockquote>
<p><strong>T-SNE算法是用于可视化的算法中效果最好的算法之一</strong>，相信大家也对T-SNE算法略有耳闻，本文参考T-SNE作者<strong>Laurens van der Maaten</strong>给出的源代码自己实现T-SNE算法代码，以此来加深对T-SNE的理解。先简单介绍一下T-SNE算法，T-SNE将数据点变换映射到概率分布上。</p>
<h4><span id="31-t-sne数据算法的目的">3.1 t-SNE数据算法的目的</span></h4><p><strong>主要是将数据从高维数据转到低维数据，并在低维空间里也保持其在高维空间里所携带的信息（比如高维空间里有的清晰的分布特征，转到低维度时也依然存在）。</strong></p>
<p><strong>==t-SNE将欧氏距离距离转换为条件概率，来表达点与点之间的相似度，再优化两个分布之间的距离-KL散度，从而保证点与点之间的分布概率不变。==</strong></p>
<h4><span id="32-sne原理">3.2 SNE原理</span></h4><p>$S N E$ 是<strong>通过仿射变换将数据点映射到相应概率分布上</strong>, 主要包括下面两个步骤:</p>
<ol>
<li>通过在高维空间中构建数据点之间的概率分布 $P$, 使得相似的数据点有更高的概率被选择, 而 不相似的数据点有较低的概率被选择;</li>
<li>然后在低维空间里重构这些点的概率分布 $Q$, 使得这两个概率分布尽可能相似。</li>
</ol>
<p>令输入空间是 $X \in \mathbb{R}^{n}$, 输出空间为 $Y \in \mathbb{R}^{t}(t \ll n)$ 。不妨假设含有 $m$ 个样本数据 $\left\{x^{(1)}, x^{(2)}, \cdots, x^{(m)}\right\}$, 其中 $x^{(i)} \in X$, 降维后的数据为 $\left\{y^{(1)}, y^{(2)}, \cdots, y^{(m)}\right\}, y^{(i)} \in Y$ 。 $S N E$ 是<strong>先将欧几里得距离转化为条件概率来表达点与点之间的相似度</strong>, 即首先是计算条件概 率 $p_{j \mid i}$, 其正比于 $x^{(i)}$ 和 $x^{(j)}$ 之间的相似度, $p_{j \mid i}$ 的计算公式为:</p>
<script type="math/tex; mode=display">
p_{j \mid i}=\frac{\exp \left(-\frac{\left\|x^{(i)}-x^{(j)}\right\|^{2}}{2 \sigma_{i}^{2}}\right)}{\sum_{k \neq i} \exp \left(-\frac{\left\|x^{(i)}-x^{(k)}\right\|^{2}}{2 \sigma_{i}^{2}}\right)}</script><p>在这里引入了一个参数 $\sigma_{i}$, 对于不同的数据点 $x^{(i)}$ 取值亦不相同, 因为我们关注的是不同数据 点两两之间的相似度, 故可设置 $p_{i \mid i}=0$ 。对于低维度下的数据点 $y^{(i)}$, 通过条件概率 $q_{j \mid i}$ 来 刻画 $y^{(i)}$ 与 $y^{(j)}$ 之间的相似度, $q_{j \mid i}$ 的计算公式为:</p>
<script type="math/tex; mode=display">
q_{j \mid i}=\frac{\exp \left(-\left\|y^{(i)}-y^{(j)}\right\|^{2}\right)}{\sum_{k \neq i} \exp \left(-\left\|y^{(i)}-y^{(k)}\right\|^{2}\right)}</script><p>同理, 设置 $q_{i \mid i}=0$ 。<br>如果降维的效果比较好, 局部特征保留完整, 那么有 $p_{i \mid j}=q_{i \mid j}$ 成立, 因此通过优化两个分布之 间的 <strong>$K L$ 散度构造出的损失函数为</strong>:</p>
<script type="math/tex; mode=display">
C\left(y^{(i)}\right)=\sum_{i} K L\left(P_{i} \| Q_{i}\right)=\sum_{i} \sum_{j} p_{j \mid i} \log \frac{p_{j \mid i}}{q_{j \mid i}}</script><p>这里的 $P_{i}$ 表示在给定高维数据点 $x^{(i)}$ 时, 其他所有数据点的条件概率分布; $Q_{i}$ 则表示在给定 低维数据点 $y^{(i)}$ 时, 其他所有数据点的条件概率分布。从损失函数可以看出, 当 $p_{j \mid i}$ 较大 $q_{j \mid i}$ 较小时, 惩罚较高; 而 $p_{j \mid i}$ 较小 $q_{j \mid i}$ 较大时, 惩罚较低。换句话说就是高维空间中两个数据点距 离较近时, 若映射到低维空间后距离较远, 那么将得到一个很高的惩罚; 反之, 高维空间中两个数 据点距离较远时, 若映射到低维空间距离较近, 将得到一个很低的惩罚值。也就是说, <strong>$S N E$ 的 损失函数更关注于局部特征, 而忽视了全局结构</strong>。</p>
<h4><span id="33-目标函数求解">3.3 目标函数求解</span></h4><h4><span id="34-对称性-sne">3.4 对称性-SNE</span></h4><p><strong>优化 <img src="https://www.zhihu.com/equation?tex=KL%28P%5CVert+Q%29" alt="[公式]"> 的一种替换思路是使用联合概率分布来替换条件概率分布</strong>，即 <img src="https://www.zhihu.com/equation?tex=P" alt="[公式]"> 是高维空间里数据点的联合概率分布， <img src="https://www.zhihu.com/equation?tex=Q" alt="[公式]"> 是低维空间里数据点的联合概率分布，此时的损失函数为：</p>
<p><img src="https://www.zhihu.com/equation?tex=C%28y%5E%7B%28i%29%7D%29%3DKL%28P%5CVert+Q%29%3D%5Csum%5Climits_i%5Csum%5Climits_jp_%7Bij%7D%5Clog%5Cdfrac%7Bp_%7Bij%7D%7D%7Bq_%7Bij%7D%7D%5C%5C" alt="[公式]"></p>
<p>同样的 <img src="https://www.zhihu.com/equation?tex=p_%7Bii%7D%3Dq_%7Bii%7D%3D0" alt="[公式]"> ，这种改进下的 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 称为对称 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> ，因为它的先验假设为对 <img src="https://www.zhihu.com/equation?tex=%5Cforall+i" alt="[公式]"> 有 <img src="https://www.zhihu.com/equation?tex=p_%7Bij%7D%3Dp_%7Bji%7D%2Cq_%7Bij%7D%3Dq_%7Bji%7D" alt="[公式]"> 成立，故概率分布可以改写成：</p>
<p><img src="https://www.zhihu.com/equation?tex=p_%7Bij%7D%3D%5Cdfrac%7Bexp%28-%5Cfrac%7B%5CVert+x%5E%7B%28i%29%7D-x%5E%7B%28j%29%7D%5CVert%5E2%7D%7B2%5Csigma%5E2%7D%29%7D%7B%5Csum%5Climits_%7Bk%5Cneq+l%7Dexp%28-%5Cfrac%7B%5CVert+x%5E%7B%28k%29%7D-x%5E%7B%28l%29%7D+%5CVert%5E2%7D%7B2%5Csigma%5E2%7D%29%7D%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+q_%7Bij%7D%3D%5Cdfrac%7Bexp%28-%5CVert+y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D+%5CVert%5E2%29%7D%7B%5Csum%5Climits_%7Bk%5Cneq+l%7Dexp%28-%5CVert+y%5E%7B%28k%29%7D-y%5E%7B%28l%29%7D+%5CVert%5E2%29%7D%5C%5C" alt="[公式]"></p>
<p>这种改进方法使得表达式简洁很多，但是容易受到异常点数据的影响，为了解决这个问题通过对联合概率分布定义修正为： <img src="https://www.zhihu.com/equation?tex=p_%7Bij%7D%3D%5Cfrac%7Bp_%7Bj%7Ci%7D%2Bp_%7Bi%7Cj%7D%7D%7B2%7D" alt="[公式]"> ，这保证了 <img src="https://www.zhihu.com/equation?tex=%5Csum%5Climits_jp_%7Bij%7D+%5Cgt+%5Cfrac%7B1%7D%7B2m%7D" alt="[公式]"> ，使得每个点对于损失函数都会有贡献。对称 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 最大的优点是简化了梯度计算，梯度公式改写为：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7B%5Cpartial+C%28y%5E%7B%28i%29%7D%29%7D%7B%5Cpartial+y%5E%7B%28i%29%7D%7D%3D4%5Csum%5Climits_j%28p_%7Bij%7D-q_%7Bij%7D%29%28y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D%29%5C%5C" alt="[公式]"></p>
<p>研究表明，对称 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 的效果差不多，有时甚至更好一点。</p>
<h4><span id="35-t-sne">3.5 t-SNE</span></h4><p><img src="https://www.zhihu.com/equation?tex=t%5Ctext%7B-%7DSNE" alt="[公式]"> 在对称 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 的改进是，首先<strong>通过在高维空间中使用高斯分布将距离转换为概率分布，然后在低维空间中，使用更加偏重长尾分布的方式来将距离转换为概率分布</strong>，使得高维度空间中的中低等距离在映射后能够有一个较大的距离。</p>
<p><img src="https://pic4.zhimg.com/80/v2-928a3ada308128f26b719d510a728fbb_1440w.jpg" alt="img"></p>
<p>从图中可以看到，在没有异常点时， <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 分布与高斯分布的拟合结果基本一致。而在第二张图中，出现了部分异常点，由于高斯分布的尾部较低，对异常点比较敏感，为了照顾这些异常点，高斯分布的拟合结果偏离了大多数样本所在位置，方差也较大。<strong>相比之下， <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 分布的尾部较高，对异常点不敏感，保证了其鲁棒性，因此拟合结果更为合理，较好的捕获了数据的全局特征。</strong></p>
<p>使用 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 分布替换高斯分布之后 <img src="https://www.zhihu.com/equation?tex=q_%7Bij+%7D" alt="[公式]"> 的变化如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=q_%7Bij%7D%3D%5Cdfrac%7B%281%2B%5CVert+y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D+%5CVert%5E2%29%5E%7B-1%7D%7D%7B%5Csum%5Climits_%7Bk%5Cneq+l%7D%281%2B%5CVert+y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D+%5CVert%5E2%29%5E%7B-1%7D%7D%5C%5C" alt="[公式]"></p>
<p>此外，随着自由度的逐渐增大， <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 分布的密度函数逐渐接近标准正态分布，因此在计算梯度方面会简单很多，优化后的梯度公式如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7B%5Cpartial+C%28y%5E%7B%28i%29%7D%29%7D%7B%5Cpartial+y%5E%7B%28i%29%7D%7D%3D4%5Csum%5Climits_%7Bj%7D%28p_%7Bij%7D-q_%7Bij%7D%29%28y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D%29%281%2B%5CVert+y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D+%5CVert%5E2%29%5E%7B-1%7D%5C%5C" alt="[公式]"></p>
<p>总的来说， <img src="https://www.zhihu.com/equation?tex=t%5Ctext%7B-%7DSNE" alt="[公式]"> 的梯度更新具有以下两个优势：</p>
<ul>
<li><strong>对于低维空间中不相似的数据点，用一个较小的距离会产生较大的梯度让这些数据点排斥开来</strong>；</li>
<li><strong>这种排斥又不会无限大，因此避免了不相似的数据点距离太远</strong>。</li>
</ul>
<h4><span id="总结">总结：</span></h4><p><img src="https://www.zhihu.com/equation?tex=t%5Ctext%7B-%7D+SNE" alt="[公式]"> 算法其实就是在 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 算法的基础上增加了两个改进：</p>
<ul>
<li>把 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 修正为对称 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> ，提高了计算效率，效果稍有提升；</li>
<li>在低维空间中采用了 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 分布替换原来的高斯分布，解决了高维空间映射到低维空间所产生的拥挤问题，优化了 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 过于关注局部特征而忽略全局特征的问题 。</li>
</ul>
<h2><span id="四-autoencoder">四、AutoEncoder</span></h2><blockquote>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/80377698">【全】一文带你了解自编码器（<em>AutoEncoder</em>）</a></li>
</ul>
</blockquote>
<p>理解为：（下图）高维数据（左测蓝色）通过某种网络变成低位数据（中间红色）后，又经过某种网络变回高维数据（右侧蓝色）。数据经过该模型前后没有变化，而中间的低维数据完全具有输入输出的高维数据的全部信息，所以可以用<a href="https://www.zhihu.com/search?q=低维数据&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;157482881&quot;}">低维数据</a>代表高维数据。</p>
<p>之所以叫AutoEncoder，而不叫AutoEncoderDecoder，是因为训练好之后只有encoder部分有用，<a href="https://www.zhihu.com/search?q=decoder&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;157482881&quot;}">decoder</a>部分就不用了。</p>
<p><img src="https://pic2.zhimg.com/v2-47f6429e5ffb379205ba0bcb0db399d1_b.jpg" alt="img"></p>
<p>进入深度学习的思路之后，编码的网络是开放的，可以自由设计的。一个思路是端到端，将网络的输出设为你任务要的结果（如类别、序列等），<strong>过程中的某层嵌入都可以作为降维的低维结果</strong>。当然，这种低维结果其实是模型的副产品，因为任务已经解决。比如bert模型得到（中文的）字嵌入。</p>
<h4><span id="优点">优点：</span></h4><ul>
<li>能够学习到非线性特性</li>
<li>降低数据维度</li>
</ul>
<h4><span id="缺点">缺点：</span></h4><ul>
<li>训练的<strong>计算成本高</strong></li>
<li><strong>可解释性较差</strong></li>
<li>背后的数学知识复杂</li>
<li>容易产生<strong>过度拟合</strong>的问题，尽管可以通过引入正则化策略缓解</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>降维与度量学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（11）CatBoost</title>
    <url>/posts/2ZWAT5R/</url>
    <content><![CDATA[<h2><span id="深入理解catboost">深入理解CatBoost</span></h2><blockquote>
<p>  深入理解CatBoost - Microstrong的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/102540344">https://zhuanlan.zhihu.com/p/102540344</a></p>
</blockquote>
<p><strong>本文主要内容概览：</strong></p>
<p><img src="https://pic1.zhimg.com/v2-f6a9520c6db0ba77ad620800cb36c054_b.jpg" alt="img"></p>
<h3><span id="一-catboost简介"><strong>一、CatBoost简介</strong></span></h3><p>CatBoost是俄罗斯的搜索巨头Yandex在2017年开源的机器学习库，是Boosting族算法的一种。CatBoost和XGBoost、LightGBM并称为GBDT的三大主流神器，都是在GBDT算法框架下的一种改进实现。XGBoost被广泛的应用于工业界，LightGBM有效的提升了GBDT的计算效率，而Yandex的CatBoost号称是比XGBoost和LightGBM在算法准确率等方面表现更为优秀的算法。</p>
<p>CatBoost是一种基于对称决策树（oblivious trees）为基学习器实现的参数较少、支持类别型变量和高准确性的GBDT框架，主要解决的痛点是高效合理地处理类别型特征，这一点从它的名字中可以看出来，<strong>CatBoost是由Categorical和Boosting组成。此外，CatBoost还解决了梯度偏差（Gradient Bias）以及预测偏移（Prediction shift）的问题，从而减少过拟合的发生，进而提高算法的准确性和泛化能力。</strong></p>
<p><strong>与XGBoost、LightGBM相比，CatBoost的创新点有：</strong></p>
<ul>
<li><strong>嵌入了自动将类别型特征处理为数值型特征的创新算法。首先对categorical features做一些统计，计算某个类别特征（category）出现的频率，之后加上超参数，生成新的数值型特征（numerical features）。</strong></li>
<li><strong>Catboost还使用了组合类别特征，可以利用到特征之间的联系，这极大的丰富了特征维度</strong>。</li>
<li>采用排序提升的方法对抗训练集中的噪声点，从而避免梯度估计的偏差，进而解决预测偏移的问题。</li>
<li>采用了<strong>完全对称树作为基模型</strong>。</li>
</ul>
<h3><span id="二-类别型特征">二、<strong>类别型特征</strong></span></h3><p><strong>所谓类别型特征，即这类特征不是数值型特征，而是离散的集合</strong>，比如省份名（山东、山西、河北等），城市名（北京、上海、深圳等），学历（本科、硕士、博士等）。在梯度提升算法中，最常用的是将这些类别型特征转为数值型来处理，一般类别型特征会转化为一个或多个数值型特征。</p>
<p><strong>类别型特征基数比较低（low-cardinality features）</strong>，即该特征的所有值去重后构成的集合元素个数比较少，一般利用One-hot编码方法将特征转为数值型。One-hot编码可以在数据预处理时完成，也可以在模型训练的时候完成，从训练时间的角度，后一种方法的实现更为高效，CatBoost对于基数较低的类别型特征也是采用后一种实现。</p>
<p><strong>高基数类别型特征（high cardinality features）</strong>当中，比如 <code>user ID</code>，这种编码方式会产生大量新的特征，造成维度灾难。一种折中的办法是可以将类别分组成有限个的群体再进行One-hot编码。<strong>一种常被使用的方法是根据目标变量统计（Target Statistics，以下简称TS）进行分组</strong>，目标变量统计用于估算每个类别的目标变量期望值。甚至有人直接用TS作为一个新的数值型变量来代替原来的类别型变量。<strong><font color="red"> 重要的是，可以通过对TS数值型特征的阈值设置，基于对数损失、基尼系数或者均方差，得到一个对于训练集而言将类别一分为二的所有可能划分当中最优的那个。</font></strong></p>
<p>在LightGBM当中，类别型特征用每一步梯度提升时的梯度统计（Gradient Statistics，以下简称GS）来表示。虽然为建树提供了重要的信息，但是这种方法有以下两个缺点：</p>
<ul>
<li>增加计算时间，因为需要对每一个类别型特征，在迭代的每一步，都需要对GS进行计算；</li>
<li>增加存储需求，对于一个类别型变量，需要存储每一次分离每个节点的类别；</li>
</ul>
<p><strong>为了克服这些缺点，LightGBM以损失部分信息为代价将所有的长尾类别归为一类</strong>，作者声称这样处理高基数类别型特征时比One-hot编码还是好不少。不过如果采用TS特征，那么对于每个类别只需要计算和存储一个数字。</p>
<p>因此，采用TS作为一个新的数值型特征是最有效、信息损失最小的处理类别型特征的方法。TS也被广泛应用在点击预测任务当中，这个场景当中的类别型特征有用户、地区、广告、广告发布者等。接下来我们着重讨论TS，暂时将One-hot编码和GS放一边。</p>
<h4><span id="21-目标变量统计target-statistics">2.1 <strong>目标变量统计（Target Statistics）</strong></span></h4><p><strong><font color="red"> CatBoost算法的设计初衷是为了更好的处理GBDT特征中的categorical features</font></strong>。在处理 GBDT特征中的categorical features的时候，最简单的方法是用 categorical feature 对应的标签的平均值来替换。在决策树中，标签平均值将作为节点分裂的标准。<strong>这种方法被称为 Greedy Target-based Statistics , 简称 Greedy TS</strong>，用公式来表达就是：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Chat%7Bx%7D_k%5Ei%3D%5Cfrac%7B%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%5Bx_%7Bj%2Ck%7D%3Dx_%7Bi%2Ck%7D%5D%5Ccdot+Y_i%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%5Bx_%7Bj%2Ck%7D%3Dx_%7Bi%2Ck%7D%5D%7D+%5C%5C" alt="[公式]"></p>
<p>这种方法有一个显而易见的缺陷，就是通常特征比标签包含更多的信息，<strong><font color="red"> 如果强行用标签的平均值来表示特征的话，当训练数据集和测试数据集数据结构和分布不一样的时候会出条件偏移问题。</font></strong></p>
<p>一个标准的改进 Greedy TS的方式是添加先验分布项，这样可以减少噪声和低频率类别型数据对于数据分布的影响：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Chat%7Bx%7D_k%5Ei%3D%5Cfrac%7B%5Csum_%7Bj%3D1%7D%5E%7Bp-1%7D%7B%5Bx_%7B%5Csigma_%7Bj%2Ck%7D%7D%3Dx_%7B%5Csigma_%7Bp%2Ck%7D%7D%5D%7DY_%7B%5Csigma_%7Bj%7D%7D%2Ba%5Ccdot+p%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bp-1%7D%7B%5Bx_%7B%5Csigma_%7Bj%2Ck%7D%7D%3Dx_%7B%5Csigma_%7Bp%2Ck%7D%7D%5D%7D%2Ba%7D+%5C%5C" alt="[公式]"></p>
<p> 其中$p$是添加的先验项， $a$通常是大于 <img src="https://www.zhihu.com/equation?tex=+0+" alt="[公式]"> 的权重系数。添加先验项是一个普遍做法，针对类别数较少的特征，它可以减少噪声数据。对于回归问题，一般情况下，先验项可取数据集label的均值。对于二分类，先验项是正例的先验概率。利用多个数据集排列也是有效的，但是，如果直接计算可能导致过拟合。CatBoost利用了一个比较新颖的计算叶子节点值的方法，这种方式(oblivious trees，对称树)可以避免多个数据集排列中直接计算会出现过拟合的问题。</p>
<p>当然，在论文《CatBoost: unbiased boosting with categorical features》中，还提到了其它几种改进Greedy TS的方法，分别有：Holdout TS、Leave-one-out TS、Ordered TS。我这里就不再翻译论文中的这些方法了，感兴趣的同学可以自己翻看一下原论文。</p>
<h4><span id="22-特征组合">2.2 <strong>特征组合</strong></span></h4><p>值得注意的是几个类别型特征的任意组合都可视为新的特征。例如，在音乐推荐应用中，我们有两个类别型特征：用户ID和音乐流派。如果有些用户更喜欢摇滚乐，将用户ID和音乐流派转换为数字特征时，根据上述这些信息就会丢失。结合这两个特征就可以解决这个问题，并且可以得到一个新的强大的特征。然而，组合的数量会随着数据集中类别型特征的数量成指数增长，因此不可能在算法中考虑所有组合。为当前树构造新的<a href="https://www.zhihu.com/search?q=分割点&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;102540344&quot;}">分割点</a>时，CatBoost会采用贪婪的策略考虑组合。对于树的第一次分割，不考虑任何组合。对于下一个分割，CatBoost将当前树的所有组合、类别型特征与数据集中的所有类别型特征相结合，并将新的组合类别型特征动态地转换为数值型特征。CatBoost还通过以下方式生成数值型特征和类别型特征的组合：树中选定的所有分割点都被视为具有两个值的类别型特征，并像类别型特征一样被进行组合考虑。</p>
<h4><span id="23-catboost处理categorical-features总结">2.3  <strong>CatBoost处理Categorical features总结</strong></span></h4><ul>
<li><strong>首先计算一些数据的statistics。计算某个category出现的频率，加上超参数，生成新的numerical features</strong>。这一策略要求同一标签数据不能排列在一起（即先全是0之后全是1这种方式），训练之前需要打乱数据集。</li>
<li>使用数据的不同排列（实际上是4个）。在每一轮建立树之前，先扔一轮骰子，决定使用哪个排列来生成树。</li>
<li>考虑使用categorical features的不同组合。例如颜色和种类组合起来，可以构成类似于blue dog这样的特征。当需要组合的categorical features变多时，CatBoost只考虑一部分<a href="https://www.zhihu.com/search?q=combinations&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;102540344&quot;}">combinations</a>。在选择第一个节点时，只考虑选择一个特征，例如A。在生成第二个节点时，考虑A和任意一个categorical feature的组合，选择其中最好的。就这样使用贪心算法生成combinations。</li>
<li><strong>除非向gender这种维数很小的情况，不建议自己生成One-hot编码向量，最好交给算法来处理。</strong></li>
</ul>
<h2><span id="三-catboostqampa">三、CatboostQ&amp;A</span></h2><h4><span id="31-catboost与xgboost-lightgbm的联系与区别">3.1 <strong>CatBoost与XGBoost、LightGBM的联系与区别？</strong></span></h4><p>（1）2014年3月XGBoost算法首次被<a href="https://www.zhihu.com/search?q=陈天奇&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;102540344&quot;}">陈天奇</a>提出，但是直到2016年才逐渐著名。2017年1月微软发布LightGBM第一个稳定版本。2017年4月Yandex开源CatBoost。自从XGBoost被提出之后，很多文章都在对其进行各种改进，CatBoost和LightGBM就是其中的两种。</p>
<p>（2）<strong>CatBoost处理类别型特征十分灵活，可直接传入类别型特征的列标识，模型会自动将其使用One-hot编码，还可通过设置 one_hot_max_size参数来限制One-hot特征向量的长度</strong>。如果不传入类别型特征的列标识，那么CatBoost会把所有列视为数值特征。对于One-hot编码超过设定的one_hot_max_size值的特征来说，CatBoost将会使用一种高效的encoding方法，与mean encoding类似，但是会降低过拟合。处理过程如下：</p>
<ul>
<li>将输入样本集随机排序，并生成多组随机排列的情况；</li>
<li>将浮点型或属性值标记转化为整数；</li>
<li>将所有的类别型特征值结果都根据以下公式，转化为数值结果；</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=avg%5C_target+%3D+%5Cfrac%7BcountInClass+%2B+prior%7D%7BtotalCount+%2B+1%7D+%5C%5C" alt="[公式]"> </p>
<p>其中 countInClass 表示在当前类别型特征值中有多少样本的标记值是1；prior 是分子的初始值，根据初始参数确定。totalCount 是在所有样本中（包含当前样本）和当前样本具有相同的类别型特征值的样本数量。</p>
<p>LighGBM 和 CatBoost 类似，也可以通过使用特征名称的输入来处理类别型特征数据，它没有对数据进行独热编码，因此速度比独热编码快得多。LighGBM 使用了一个特殊的算法来确定属性特征的分割值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_data = lgb.Dataset(data, label=label, feature_name=[<span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>], categorical_feature=[<span class="string">&#x27;c3&#x27;</span>])</span><br><span class="line"><span class="comment"># 注意，在建立适用于 LighGBM 的数据集之前，需要将类别型特征变量转化为整型变量，此算法不允许将字符串数据传给类别型变量参数。</span></span><br></pre></td></tr></table></figure>
<p>（3）XGBoost 和 CatBoost、 LighGBM 算法不同，XGBoost 本身无法处理类别型特征，而是像随机森林一样，只接受数值数据。因此在将类别型特征数据传入 XGBoost 之前，必须通过各种编码方式：例如序号编码、独热编码和二进制编码等对数据进行处理。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（10）集成学习*</title>
    <url>/posts/12GKN6G/</url>
    <content><![CDATA[<h2><span id="机器学习决策树中random-forest-adaboost-gbdt">【机器学习】决策树（中）——Random Forest、Adaboost、GBDT</span></h2><blockquote>
<p>  <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble">https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble</a></p>
<p>  机器学习算法中GBDT与Adaboost的区别与联系是什么？ - Frankenstein的回答 - 知乎 <a href="https://www.zhihu.com/question/54626685/answer/140610056">https://www.zhihu.com/question/54626685/answer/140610056</a></p>
<p>  GBDT学习笔记 - 许辙的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/169382376">https://zhuanlan.zhihu.com/p/169382376</a></p>
<p>  GBDT - 王多鱼的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/38057220">https://zhuanlan.zhihu.com/p/38057220</a></p>
</blockquote>
<p><img src="https://pic2.zhimg.com/v2-1ac553d300784e8d158bcc686e7cf66d_1440w.jpg?source=172ae18b" alt="【机器学习】决策树（中）——Random Forest、Adaboost、GBDT （非常详细）"></p>
<p>本文主要介绍基于集成学习的决策树，其主要通过不同学习框架生产基学习器，并综合所有基学习器的预测结果来改善单个基学习器的识别率和泛化性。</p>
<p>==模型的准确度可由偏差和方差共同决定：==</p>
<p>$\text { Error }=\text { bias }^{2}+\operatorname{var}+\xi$</p>
<p><strong>模型总体期望：</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
E(F) &=E\left(\sum_{i}^{m} r_{i} f_{i}\right) \\
&=\sum_{i}^{m} r_{i} E\left(f_{i}\right)
\end{aligned}</script><p><strong>模型总体方差</strong>:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\operatorname{Var}(F) &=\operatorname{Var}\left(\sum_{i}^{m} r_{i} f_{i}\right) \\
&=\sum_{i}^{m} \operatorname{Var}\left(r_{i} f_{i}\right)+\sum_{i \neq j}^{m} \operatorname{Cov}\left(r_{i} f_{i}, r_{j} f_{j}\right) \\
&=\sum_{i}^{m} r_{i}{ }^{2} \operatorname{Var}\left(f_{i}\right)+\sum_{i \neq j}^{m} \rho r_{i} r_{j} \sqrt{\operatorname{Var}\left(f_{i}\right)} \sqrt{\operatorname{Var}\left(f_{j}\right)} \\
&=m r^{2} \sigma^{2}+m(m-1) \rho r^{2} \sigma^{2} \\
&=m r^{2} \sigma^{2}(1-\rho)+m^{2} r^{2} \sigma^{2} \rho
\end{aligned}</script><div class="table-container">
<table>
<thead>
<tr>
<th>集成学习</th>
<th>Bagging</th>
<th>Boosting</th>
<th>Stacking</th>
</tr>
</thead>
<tbody>
<tr>
<td>思想</td>
<td>对训练集进行<strong>有放回抽样</strong>得到子训练集</td>
<td>基模型的训练是有<strong>顺序</strong>的，每个基模型都会在前一个基模型学习的基础上进行学习；基于贪心策略的前向加法</td>
<td><strong>预测值</strong>将作为训练样本的特征值，进行训练得到最终预测结果。</td>
</tr>
<tr>
<td>样本抽样</td>
<td>有放回地抽取数据集</td>
<td>训练集不变</td>
<td></td>
</tr>
<tr>
<td>样本权重</td>
<td>样本权重相等</td>
<td>不断调整样本的权重</td>
<td></td>
</tr>
<tr>
<td>优化目标</td>
<td>减小的是方差</td>
<td>减小的是偏差</td>
<td></td>
</tr>
<tr>
<td>基模型</td>
<td><strong>强模型（偏差低，方差高）</strong></td>
<td><strong>弱模型（偏差高，方差低）</strong>而整体模型的偏差由基模型累加而成，故基模型需要为弱模型。</td>
<td><strong>强模型（偏差低，方差高）</strong></td>
</tr>
<tr>
<td>相关性</td>
<td></td>
<td>对于 Boosting 来说，由于基模型共用同一套训练集，所以基模型间具有强相关性，故模型间的相关系数近似等于 1</td>
<td></td>
</tr>
<tr>
<td>模型偏差</td>
<td><strong>整体模型的偏差与基模型近似</strong>。(<script type="math/tex">\mu</script>)</td>
<td>基于贪心策略的前向加法，随着基模型数的增多，偏差减少。</td>
<td></td>
</tr>
<tr>
<td>模型方差</td>
<td>随着<strong>模型的增加可以降低整体模型的方差</strong>，故其基模型需要为强模型；(<script type="math/tex">\frac{\sigma^{2}(1-\rho)}{m}+\sigma^{2} \rho</script>)</td>
<td><strong>整体模型的方差与基模型近似</strong>（<script type="math/tex">\sigma^{2}</script>）</td>
</tr>
</tbody>
</table>
</div>
<h2><span id="1-集成学习">1. 集成学习</span></h2><p>常见的集成学习框架有三种：Bagging，Boosting 和 Stacking。三种集成学习框架在基学习器的产生和综合结果的方式上会有些区别，我们先做些简单的介绍。</p>
<h3><span id="11-bagging">1.1 Bagging</span></h3><p>Bagging 全称叫 <strong>Bootstrap aggregating</strong>，，==每个基学习器都会对训练集进行<strong>有放回抽样</strong>得到子训练集==，比较著名的采样法为 0.632 自助法（<strong>Bootstrap</strong>）。每个基学习器基于不同子训练集进行训练，并综合所有基学习器的预测值得到最终的预测结果。Bagging 常用的综合方法是<strong>投票法</strong>，票数最多的类别为预测类别。</p>
<p><img src="https://pic1.zhimg.com/80/v2-a0a3cb02f629f3db360fc68b4c2153c0_1440w.jpg" alt="img"></p>
<h3><span id="12-boosting">1.2 Boosting</span></h3><p><strong>Boosting 训练过程为阶梯状，基模型的训练是有顺序的，每个基模型都会在前一个基模型学习的基础上进行学习，最终综合所有基模型的预测值产生最终的预测结果</strong>，用的比较多的综合方式为加权法。</p>
<p><img src="https://pic3.zhimg.com/80/v2-3aab53d50ab65e11ad3c9e3decf895c2_1440w.jpg" alt="img"></p>
<h3><span id="13-stacking">1.3 Stacking</span></h3><p><strong>Stacking 是先用全部数据训练好基模型，然后每个基模型都对每个训练样本进行的预测，==其预测值将作为训练样本的特征值==，最终会得到新的训练样本，然后基于新的训练样本进行训练得到模型，然后得到最终预测结果。</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-f6787a16c23950d129a7927269d5352a_1440w.jpg" alt="img"></p>
<p>==那么，为什么集成学习会好于单个学习器呢？原因可能有三：==</p>
<ul>
<li><p>训练样本可能无法选择出最好的单个学习器，由于没法选择出最好的学习器，所以干脆结合起来一起用；</p>
</li>
<li><p>假设能找到最好的学习器，但由于算法运算的限制无法找到最优解，只能找到次优解，采用集成学习可以弥补算法的不足；</p>
</li>
<li><p>可能算法无法得到最优解，而集成学习能够得到近似解。比如说最优解是一条对角线，而单个决策树得到的结果只能是平行于坐标轴的，但是集成学习可以去拟合这条对角线。</p>
</li>
</ul>
<h3><span id="14-stacking-vs-神经网络">==<strong>1.4 Stacking</strong> vs <strong>神经网络</strong>==</span></h3><blockquote>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/32896968">https://zhuanlan.zhihu.com/p/32896968</a></p>
<p><strong>本文的核心观点是提供一种对于stacking的理解，即与神经网络对照来看。</strong>当然，在<a href="https://www.zhihu.com/question/59769987/answer/269367049">阿萨姆：为什么做stacking之后，准确率反而降低了？</a>中我已经说过stacking不是万能药，但往往很有效。通过与神经网络的对比，读者可以从另一个角度加深对stacking的理解。</p>
</li>
</ul>
</blockquote>
<h4><span id="141-stacking是一种表示学习representation-learning">1.4.1 Stacking是一种表示学习(representation learning)</span></h4><p><strong>表示学习指的是模型从原始数据中自动抽取有效特征的过程</strong>，比如深度学习就是一种表示学习的方法。关于表示学习的理解可以参考：<a href="https://www.zhihu.com/question/264417928/answer/283087276">阿萨姆：人工智能（AI）是如何处理数据的？</a></p>
<p>原始数据可能是杂乱无规律的。在stacking中，通过第一层的多个学习器后，有效的特征被学习出来了。从这个角度来看，stacking的第一层就是特征抽取的过程。在[1]的研究中，上排是未经stacking的数据，下排是经过stacking(多个无监督学习算法)处理后的数据，我们显著的发现红色和蓝色的数据在下排中分界更为明显。<strong>==数据经过了压缩处理。这个小例子说明了，有效的stacking可以对原始数据中的特征有效的抽取==</strong>。</p>
<p><img src="https://pic1.zhimg.com/80/v2-92ff83c7c6acc0dea6bc53ffe815e8bc_1440w.jpg" alt="img" style="zoom:80%;"></p>
<h4><span id="142-stacking和神经网络从某种角度看有异曲同工之妙神经网络也可以被看作是集成学习">1.4.2  <strong>Stacking和神经网络从某种角度看有异曲同工之妙，神经网络也可以被看作是集成学习</strong></span></h4><p>承接上一点，stacking的学习能力主要来自于对于特征的表示学习，这和神经网络的思路是一致的。这也是为什么我说“第一层”，“最后一层”。</p>
<p>而且神经网络也可以被看做是一种集成学习，主要取决于不同神经元、层对于不同特征的理解不同。从浅层到深层可以理解为一种从具体到抽象的过程。</p>
<p><strong>Stacking中的第一层可以等价于神经网络中的前 n-1层，而stacking中的最终分类层可以类比于神经网络中最后的输出层。</strong>不同点在于，<strong>stacking中不同的分类器通过异质来体现对于不同特征的表示</strong>，神经网络是从同质到异质的过程且有分布式表示的特点(distributed representation)。Stacking中应该也有分布式的特点，主要表现在多个分类器的结果并非完全不同，而有很大程度的相同之处。</p>
<p>但同时这也提出了一个挑战，多个分类器应该尽量在保证效果好的同时尽量不同，stacking集成学习框架的对于基分类器的两个要求：</p>
<ul>
<li>差异化(diversity)要大</li>
<li>准确性(accuracy)要高</li>
</ul>
<h4><span id="143-stacking-的输出层为什么用逻辑回归"><strong>1.4.3 Stacking 的输出层为什么用逻辑回归？</strong></span></h4><blockquote>
<p>  <strong>表示学习的过拟合问题</strong>：</p>
<ul>
<li>仅包含学习到的特征</li>
<li>交叉验证</li>
<li>简单模型：<strong>逻辑回归</strong></li>
</ul>
</blockquote>
<p>如果你看懂了上面的两点，你应该可以理解stacking的有效性主要来自于特征抽取。<strong>而表示学习中，如影随形的问题就是过拟合，试回想深度学习中的过拟合问题。</strong></p>
<p>在[3]中，周志华教授也重申了stacking在使用中的过拟合问题。因为第二层的特征来自于对于第一层数据的学习，那么第二层数据中的特征中不该包括原始特征，<strong>以降低过拟合的风险</strong>。举例：</p>
<ul>
<li>第二层数据特征：仅包含学习到的特征</li>
<li>第二层数据特征：包含学习到的特征 + 原始特征</li>
</ul>
<p>另一个例子是，stacking中一般都用交叉验证来避免过拟合，足可见这个问题的严重性。</p>
<p>为了降低过拟合的问题，第二层分类器应该是较为简单的分类器，广义线性如逻辑回归是一个不错的选择。<strong>在特征提取的过程中，我们已经使用了复杂的非线性变换，因此在输出层不需要复杂的分类器</strong>。这一点可以对比神经网络的激活函数或者输出层，都是很简单的函数，一点原因就是不需要复杂函数并能控制复杂度。</p>
<h4><span id="144-stacking是否需要多层第一层的分类器是否越多越好"><strong>1.4.4 Stacking是否需要多层？第一层的分类器是否越多越好？</strong></span></h4><p>通过以上分析，stacking的表示学习不是来自于多层堆叠的效果，而是<strong>来自于不同学习器对于不同特征的学习能力</strong>，并有效的结合起来。一般来看，2层对于stacking足够了。多层的stacking会面临更加复杂的过拟合问题，且收益有限。</p>
<p>第一层分类器的数量对于特征学习应该有所帮助，<strong>经验角度看越多的基分类器越好。即使有所重复和高依赖性，我们依然可以通过特征选择来处理</strong>，问题不大。</p>
<h2><span id="2-偏差与方差">2. 偏差与方差</span></h2><p>上节介绍了集成学习的基本概念，这节我们主要介绍下如何从偏差和方差的角度来理解集成学习。</p>
<h4><span id="21-集成学习的偏差与方差">2.1 集成学习的偏差与方差</span></h4><p><strong>==偏差（Bias）描述的是预测值和真实值之差==</strong>；<strong>==方差（Variance）描述的是预测值作为随机变量的离散程==度</strong>。放一场很经典的图：</p>
<p><img src="https://pic2.zhimg.com/80/v2-60c942f91d33d9dedf9dd2c7d482af5d_1440w.jpg" alt="img"></p>
<p><strong>模型</strong>的<strong>偏差</strong>与<strong>方差</strong></p>
<ul>
<li><strong>偏差：</strong>描述样本拟合出的模型的预测结果的期望与样本真实结果的差距，要想偏差表现的好，就需要复杂化模型，增加模型的参数，但这样容易过拟合，过拟合对应上图的 High Variance，点会很分散。低偏差对应的点都打在靶心附近，所以喵的很准，但不一定很稳；</li>
<li><strong>方差：</strong>描述样本上训练出来的模型在测试集上的表现，要想方差表现的好，需要简化模型，减少模型的复杂度，但这样容易欠拟合，欠拟合对应上图 High Bias，点偏离中心。低方差对应就是点都打的很集中，但不一定是靶心附近，手很稳，但不一定瞄的准。</li>
</ul>
<p>我们常说集成学习中的基模型是弱模型，通常来说弱模型是偏差高（在训练集上准确度低）方差小（防止过拟合能力强）的模型，<strong>但并不是所有集成学习框架中的基模型都是弱模型</strong>。<strong>Bagging 和 Stacking 中的基模型为强模型（偏差低，方差高），而Boosting 中的基模型为弱模型（偏差高，方差低）</strong>。</p>
<h4><span id="22-bagging-的偏差与方差">2.2 Bagging 的偏差与方差</span></h4><ul>
<li><strong>整体模型的期望等于基模型的期望，这也就意味着整体模型的偏差和基模型的偏差近似。</strong></li>
<li><strong>整体模型的方差小于等于基模型的方差，当且仅当相关性为 1 时取等号，随着基模型数量增多，整体模型的方差减少，从而防止过拟合的能力增强，模型的准确度得到提高。</strong>但是，模型的准确度一定会无限逼近于 1 吗？并不一定，当基模型数增加到一定程度时，方差公式第一项的改变对整体方差的作用很小，防止过拟合的能力达到极限，这便是准确度的极限了。</li>
</ul>
<h4><span id="23-boosting-的偏差与方差">2.3 Boosting 的偏差与方差</span></h4><ul>
<li>整体模型的方差等于基模型的方差，如果基模型不是弱模型，其方差相对较大，这将导致整体模型的方差很大，即无法达到防止过拟合的效果。因此，Boosting 框架中的基模型必须为弱模型。</li>
<li>此外 Boosting 框架中采用基于贪心策略的前向加法，整体模型的期望由基模型的期望累加而成，所以随着基模型数的增多，整体模型的期望值增加，整体模型的准确度提高。</li>
</ul>
<h4><span id="24-小结">2.4 小结</span></h4><ul>
<li>我们可以使用<strong>==模型的偏差和方差来近似描述模型的准确度==</strong>；</li>
<li>对于 Bagging 来说，整体模型的偏差与基模型近似，而随着模型的增加可以降低整体模型的方差，故其基模型需要为强模型；</li>
<li>对于 Boosting 来说，整体模型的方差近似等于基模型的方差，而整体模型的偏差由基模型累加而成，故基模型需要为弱模型。</li>
</ul>
<h2><span id="3-random-forestbagging">3. Random Forest（Bagging）</span></h2><blockquote>
<ol>
<li>随机森林具有<strong>防止过拟合能力</strong>，精度比大多数单个算法要好；<ol>
<li>随机森林分类器可以<strong>处理缺失值</strong>；</li>
</ol>
</li>
<li><strong>==于有袋外数据(OOB)==，可以在模型生成过程中取得真实误差的无偏估计，且不损失训练数据量在训练过程中，能够检测到feature间的互相影响，且可以得出feature的重要性，具有一定参考意义；</strong><ol>
<li>每棵树可以独立、同时生成，容易做成<strong>并行化方法</strong>；</li>
</ol>
</li>
<li>具有一定的特征选择能力。</li>
</ol>
</blockquote>
<p><strong>Random Forest（随机森林），用随机的方式建立一个森林。RF 算法由很多决策树组成，每一棵决策树之间没有关联。建立完森林后，当有新样本进入时，每棵决策树都会分别进行判断，然后基于投票法给出分类结果。</strong></p>
<p>对于分类问题，其输出的类别是由个别树输出的众数所决定的。在回归问题中，把每一棵决策树的输出进行平均得到最终的回归结果。</p>
<h3><span id="31-思想">3.1 思想</span></h3><p>Random Forest（随机森林）是 Bagging 的扩展变体，它在以决策树为基学习器构建 Bagging 集成的基础上，进一步在决策树的训练过程中引入了随机特征选择，因此可以概括 RF 包括四个部分：</p>
<ul>
<li><strong>样本随机：</strong>假设训练数据集共有 <img src="https://www.zhihu.com/equation?tex=M" alt="[公式]"> 个对象的数据，从样本数据中采取有放回（<strong>Boostrap</strong>）随机抽取 <img src="https://www.zhihu.com/equation?tex=N" alt="[公式]"> 个样本（因为是有放回抽取，有些数据可能被选中多次，有些数据可能不被选上)，每一次取出的样本不完全相同，这些样本组成了决策树的训练数据集；</li>
<li><strong>特征随机：</strong>假设每个样本数据都有 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 个特征，从所有特征中随机地选取 <img src="https://www.zhihu.com/equation?tex=k%28k%3C%3DK%29" alt="[公式]"> 个特征，选择最佳分割属性作为节点建立CART决策树，决策树成长期间 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 的大小始终不变（<strong>在Python中构造随机森林模型的时候，默认取特征的个数 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 是 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 的平方根，即 <img src="https://www.zhihu.com/equation?tex=%5Csqrt%7BK%7D" alt="[公式]"></strong> )；</li>
<li>重复前面的步骤，建立 <img src="https://www.zhihu.com/equation?tex=m" alt="[公式]"> 棵CART树，这些树都要完全的成长且不被修剪，这些树形成了森林；</li>
<li>根据这些树的预测结果进行投票，决定样本的最后预测类别。（针对回归模型，是根据这些决策树模型的平均值来获取最终的结果）</li>
</ul>
<p>随机选择样本和 Bagging 相同，采用的是 Bootstrap 自助采样法；<strong>==随机选择特征是指在每个节点在分裂过程中都是随机选择特征的==</strong>（区别与每棵树随机选择一批特征）。</p>
<blockquote>
<p>  这种随机性导致随机森林的==偏差会有稍微的增加==（相比于单棵不随机树），但是由于随机森林的“平均”特性，会使得它的==方差减小==，而且方差的减小补偿了偏差的增大，因此总体而言是更好的模型。</p>
</blockquote>
<p>随机采样由于引入了两种采样方法保证了随机性，所以每棵树都是最大可能的进行生长就算==不剪枝也不会出现过拟合==。</p>
<h3><span id="32-处理缺失值的方法">3.2 处理缺失值的方法</span></h3><ul>
<li>方法一（na.roughfix）简单粗暴，对于训练集,同一个class下的数据，如果是<strong>分类变量(categorical var)缺失，用众数补上</strong>，如果是<strong>连续型变量(numerical var)缺失，用中位数补</strong>。</li>
<li>方法二（rfImpute）这个方法计算量大，至于比方法一好坏？不好判断。先用na.roughfix补上缺失值，然后构建森林并计算proximity matrix，再回头看缺失值，如果是分类变量，则用没有缺失的观测实例的proximity中的权重进行投票。如果是连续型变量，则用<strong>proximity矩阵进行加权平均的方法补缺失值</strong>。然后迭代4-6次，这个补缺失值的思想和KNN有些类似。</li>
</ul>
<h3><span id="33-优缺点">3.3 优缺点</span></h3><h4><span id="优点"><strong>优点</strong>：</span></h4><ol>
<li><strong>模型准确率高</strong>：随机森林既可以处理分类问题，也可以处理回归问题，即使存在部分数据缺失的情况，随机森林也能保持很高的分类精度。</li>
<li><strong>能够处理数量庞大的高维度的特征</strong>，且不需要进行降维（因为特征子集是随机选择的）；</li>
<li><strong>易于并行化</strong>，在大数据集上有很大的优势；</li>
<li><p><strong>可解释性</strong>：可以生成树状结构，判断各个特征的重要性；</p>
<blockquote>
<p>  在sklearn中，随机森林<strong>基于每棵树分裂时的GINI指数下降量</strong>来判断各个特征的重要性。但是这种方法存在一个问题：当特征是连续的时候或者是类别很多的离散特征时，该方法会将这些特征的重要性增加。</p>
<p>  解决方法：对特征编码，使得特征的取值数量相近。</p>
</blockquote>
</li>
<li><strong>对异常值、缺失值不敏感；</strong></li>
<li><strong>随机森林有袋外数据（OOB），因此不需要单独划分交叉验证集</strong>。</li>
</ol>
<h4><span id="缺点">缺点：</span></h4><ul>
<li>随机森林解决回归问题的效果不如分类问题；（因为它的预测不是天生连续的，在解决回归问题时，随机森林并不能为训练数据以外的对象给出答案）</li>
<li><strong>树之间的相关性越大，错误率就越大</strong>；</li>
<li><strong>当训练数据噪声较大时，容易产生过拟合现象。</strong></li>
</ul>
<h3><span id="34-基学习期的选择">==3.4 基学习期的选择？==</span></h3><h4><span id="为什么集成学习的基分类器通常是决策树还有什么">为什么集成学习的基分类器通常是决策树？还有什么？</span></h4><p>基分类器通常是决策树：样本权重、方便调节、随机性；</p>
<ul>
<li><strong>==决策树可以较方便地将样本权重整合到训练过程中，而不需要通过过采样来调整样本权重。==</strong></li>
<li>树的表达能力和泛化能力，<strong>方便调节</strong>（可以通过树的层数来调节）</li>
<li>样本的扰动对决策树的影响较大，<strong><font color="red"> 因此不同子样本集合生成的决策树基分类器随机性较大。这样的不稳定的分类器更适合作为基分类器。</font></strong>此外树节点分类时随机选择一个特征子集，从中找出最优分裂属性，很好地引入了随机性。</li>
</ul>
<h4><span id="可以将随机森林的基分类器由决策树替换成线性分类器或k-nn吗">可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？</span></h4><p>Bagging主要好处是集成后的方差，比基分类器小。bagging采用的基分类，最好是本身对样本分布较为敏感。而线性分类器和K-NN都是较为稳定的分类器（参数模型？）甚至<strong>可能因为采样，而导致他们再训练中更难收敛，从而增大了集成分类器的偏差。</strong></p>
<h2><span id="4-adaboost-boosting-样本权重更新">4 Adaboost (Boosting) 样本权重更新?</span></h2><p>AdaBoost（Adaptive Boosting，自适应增强），其自适应在于：<strong>前一个基本分类器分错的样本会得到加强，加权后的全体样本再次被用来训练下一个基本分类器。同时，在每一轮中加入一个新的弱分类器，直到达到某个预定的==足够小的错误率或达到预先指定的最大迭代次数==。</strong></p>
<h3><span id="41-思想">4.1 思想</span></h3><p><strong>==Adaboost 迭代算法有三步：==</strong></p>
<ul>
<li>初始化训练样本的权值分布，每个样本具有相同权重；</li>
<li>训练弱分类器，如果样本分类正确，则在构造下一个训练集中，它的权值就会被降低；反之提高。用更新过的样本集去训练下一个分类器；</li>
<li>将所有弱分类组合成强分类器，各个弱分类器的训练过程结束后，<strong>加大分类误差率小的弱分类器的权重，降低分类误差率大的弱分类器的权重</strong>。</li>
</ul>
<h3><span id="42-细节">4.2 细节</span></h3><h5><span id="421-损失函数">==<strong>4.2.1 损失函数 ???</strong>==</span></h5><p>Adaboost 模型是<strong>加法模型</strong>，学习算法为<strong>前向分步学习算法</strong>，损失函数为<strong>指数函数的分类问题</strong>。</p>
<p><strong>加法模型</strong>：最终的强分类器是由若干个弱分类器<strong>加权平均</strong>得到的。</p>
<p><strong>前向分布学习算法</strong>：算法是通过一轮轮的弱学习器学习，<strong>利用前一个弱学习器的结果来更新后一个弱学习器的训练集权重</strong>。第 k 轮的强学习器为：</p>
<script type="math/tex; mode=display">
F_{k}(x)=\sum_{i=1}^{k} \alpha_{i} f_{i}(x)=F_{k-1}(x)+\alpha_{k} f_{k}(x)</script><p><strong>定义损失函数为 n 个样本的指数损失函数</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=L%28y%2CF%29+%3D+%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bn%7Dexp%28-y_iF_%7Bk%7D%28x_i%29%29++%5C%5C" alt="[公式]"></p>
<p>利用前向分布学习算法的关系可以得到：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D++L%28y%2C+F%29+%26%3D+%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bm%7Dexp%5B%28-y_i%29+%28F_%7Bk-1%7D%28x_i%29+%2B+%5Calpha_k+f_k%28x_i%29%29%5D++%5C%5C+%26%3D++%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bm%7Dexp%5B-y_i+F_%7Bk-1%7D%28x_i%29+-y_i++%5Calpha_k+f_k%28x_i%29%5D+%5C%5C+%26%3D++%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bm%7Dexp%5B-y_i+F_%7Bk-1%7D%28x_i%29+%5D+exp%5B-y_i++%5Calpha_k+f_k%28x_i%29%5D+++%5Cend%7Balign%7D++%5C%5C" alt="[公式]"></p>
<p><strong>因为 <img src="https://www.zhihu.com/equation?tex=F_%7Bk-1%7D%28x%29" alt="[公式]"> 已知==，所以令 <img src="https://www.zhihu.com/equation?tex=w_%7Bk%2Ci%7D+%3D+exp%28-y_iF_%7Bk-1%7D%28x_i%29%29" alt="[公式]"> ，==随着每一轮迭代而将这个式子带入损失函数，损失函数转化为：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=L%28y%2C+F%28x%29%29+%3D%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bm%7Dw_%7Bk%2Ci%7Dexp%5B-y_i%5Calpha_k+f_k%28x_i%29%5D+%5C%5C" alt="[公式]"></p>
<p>我们求 <img src="https://www.zhihu.com/equation?tex=f_k%28x%29" alt="[公式]"> ，可以得到：</p>
<p><img src="https://www.zhihu.com/equation?tex=f_k%28x%29+%3Dargmin%5C%3B+%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bm%7Dw_%7Bk%2Ci%7DI%28y_i+%5Cneq+f_k%28x_i%29%29+%5C%5C" alt="[公式]"></p>
<p>将 <img src="https://www.zhihu.com/equation?tex=f_k%28x%29" alt="[公式]"> 带入损失函数，并对 <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> 求导，使其等于 0，则就得到了：</p>
<p><img src="https://www.zhihu.com/equation?tex=+%5Calpha_k+%3D+%5Cfrac%7B1%7D%7B2%7Dlog%5Cfrac%7B1-e_k%7D%7Be_k%7D++%5C%5C" alt="[公式]"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=e_k" alt="[公式]"> 即为我们前面的<strong>分类误差率</strong>。</p>
<p><img src="https://www.zhihu.com/equation?tex=+e_k+%3D+%5Cfrac%7B%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dw_%7Bki%7D%5E%7B%E2%80%99%7DI%28y_i+%5Cneq+f_k%28x_i%29%29%7D%7B%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dw_%7Bki%7D%5E%7B%E2%80%99%7D%7D+%3D+%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dw_%7Bki%7DI%28y_i+%5Cneq+f_k%28x_i%29%29+%5C%5C" alt="[公式]"></p>
<p><strong>最后看样本权重的更新</strong>。利用 <img src="https://www.zhihu.com/equation?tex=F_%7Bk%7D%28x%29+%3D+F_%7Bk-1%7D%28x%29+%2B+%5Calpha_kf_k%28x%29" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=w_%7Bk%2B1%2Ci%7D%3Dw_%7Bk%2Ci%7Dexp%5B-y_i%5Calpha_kf_k%28x%2Ci%29%5D" alt="[公式]"> ，即可得：</p>
<p><img src="https://www.zhihu.com/equation?tex=w_%7Bk%2B1%2Ci%7D+%3D+w_%7Bki%7Dexp%5B-y_i%5Calpha_kf_k%28x_i%29%5D+%5C%5C" alt="[公式]"></p>
<p>这样就得到了样本权重更新公式。</p>
<h4><span id="422-正则化"><strong>4.2.2 正则化</strong></span></h4><p><strong>为了防止 Adaboost 过拟合，我们通常也会加入正则化项，这个正则化项我们通常称为步长</strong>（learning rate）。对于前面的弱学习器的迭代,加上正则化项 <img src="https://www.zhihu.com/equation?tex=%5Cmu+" alt="[公式]"> 我们有：</p>
<script type="math/tex; mode=display">
F_{k}(x)=F_{k-1}(x)+\mu \alpha_{k} f_{k}(x)</script><p><img src="https://www.zhihu.com/equation?tex=%5Cmu" alt="[公式]"> 的取值范围为 <img src="https://www.zhihu.com/equation?tex=0%3C%5Cmu%5Cleq1" alt="[公式]"> 。对于同样的训练集学习效果，较小的 <img src="https://www.zhihu.com/equation?tex=%5Cmu" alt="[公式]"> 意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。</p>
<h3><span id="43-优缺点">4.3 优缺点</span></h3><p><strong>4.3.1 优点</strong></p>
<ol>
<li>分类精度高；</li>
<li>可以<strong>用各种回归分类模型来构建弱学习器，非常灵活</strong>；</li>
<li>不容易发生过拟合。</li>
</ol>
<p><strong>4.3.2 缺点</strong></p>
<ol>
<li>对异常点敏感，异常点会获得较高权重。</li>
</ol>
<h2><span id="5-gbdt">5. GBDT</span></h2><blockquote>
<p>  <a href="https://www.cnblogs.com/modifyrong/p/7744987.html">https://www.cnblogs.com/modifyrong/p/7744987.html</a></p>
</blockquote>
<p><strong>GBDT（Gradient Boosting Decision Tree）是一种迭代的决策树算法，该算法由多棵决策树组成，从名字中我们可以看出来它是属于 Boosting 策略。GBDT 是被公认的泛化能力较强的算法。</strong></p>
<h3><span id="51-思想">5.1 思想</span></h3><p><strong>GBDT是boosting算法的一种，按照boosting的思想，在GBDT算法的每一步，用一棵决策树去拟合当前学习器的残差，获得一个新的弱学习器。将这每一步的决策树组合起来，就得到了一个强学习器</strong>。GBDT 由三个概念组成：Regression Decision Tree（即 DT）、Gradient Boosting（即 GB），和 Shrinkage（一个重要演变）</p>
<h4><span id="511-回归树regression-decision-tree"><strong>5.1.1 回归树（Regression Decision Tree）</strong></span></h4><p>如果认为 GBDT 由很多分类树那就大错特错了（虽然调整后也可以分类）。对于分类树而言，其值加减无意义（如性别），而对于回归树而言，其值加减才是有意义的（如说年龄）。GBDT 的核心在于累加所有树的结果作为最终结果，所以 GBDT 中的树都是<strong>回归树</strong>，不是分类树，这一点相当重要。</p>
<p><strong><font color="red"> 回归树在分枝时会穷举每一个特征的每个阈值以找到最好的分割点，衡量标准是最小化均方误差。</font></strong></p>
<h4><span id="512-梯度迭代gradient-boosting"><strong>5.1.2 梯度迭代（Gradient Boosting）</strong></span></h4><p>上面说到 GBDT 的核心在于累加所有树的结果作为最终结果，GBDT 的每一棵树都是以之前树得到的<strong>残差【负梯度】</strong>来更新目标值，这样每一棵树的<strong>值加起来</strong>即为 GBDT 的预测值。</p>
<p>模型的预测值可以表示为：</p>
<script type="math/tex; mode=display">
F_{k}(x)=\sum_{i=1}^{k} f_{i}(x)</script><p><img src="https://www.zhihu.com/equation?tex=f_%7Bi%7D%28x%29+" alt="[公式]"> 为<strong>基模型与其权重的乘积</strong>，模型的训练目标是使预测值 <img src="https://www.zhihu.com/equation?tex=F_k%28x%29" alt="[公式]"> 逼近真实值 y，也就是说要让每个基模型的预测值逼近各自要预测的部分真实值。<strong>==贪心==</strong>的解决手段：每次只训练一个基模型。那么，现在改写整体模型为迭代式：</p>
<script type="math/tex; mode=display">
F_{k}(x)=F_{k-1}(x)+f_{k}(x)</script><p>其实很简单，其<strong>==残差其实是最小均方损失函数关于预测值的反向梯度(划重点)==</strong>：<strong>用负梯度的解作为样本新的真实值</strong>。基于残差 GBDT 容易对异常值敏感。</p>
<script type="math/tex; mode=display">
-\frac{\partial\left(\frac{1}{2}\left(y-F_{k}(x)\right)^{2}\right)}{\partial F_{k}(x)}=y-F_{k}(x)</script><p>很明显后续的模型会对第 4 个值关注过多，这不是一种好的现象，所以一般回归类的损失函数会用<strong>绝对损失或者 Huber 损失函数</strong>来代替平方损失函数。</p>
<script type="math/tex; mode=display">
L(y, F)=|y-F|</script><script type="math/tex; mode=display">
L(y, F)= \begin{cases}\frac{1}{2}(y-F)^{2} & |y-F| \leq \delta \\ \delta(|y-F|-\delta / 2) & |y-F|>\delta\end{cases}</script><p>GBDT 的 Boosting 不同于 Adaboost 的 Boosting，<strong>==GBDT 的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于 0==</strong>，这样后面的树就能专注于那些被分错的样本。</p>
<blockquote>
<p>  <strong><font color="red"> 最后补充一点拟合残差的问题，无论损失函数是什么形式，每个决策树拟合的都是负梯度。只有当损失函数是均方损失时，负梯度刚好是残差</font></strong>，也就是说<strong>拟合残差只是针对均方损失的特例</strong>，并不能说GBDT的迭代的过程是拟合残差。</p>
</blockquote>
<h4><span id="513-缩减shrinkage添加权重-基数增大"><strong>5.1.3 缩减（Shrinkage）</strong>添加权重、基数增大</span></h4><blockquote>
<p>  <strong><font color="red"> gbdt中的步长和参数中的学习率作用是什么？详细讲一讲？</font></strong></p>
<ul>
<li>参数中的学习率用于梯度下降</li>
</ul>
</blockquote>
<p>Shrinkage 的思想认为，每走一小步逐渐逼近结果的效果要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它并不是完全信任每一棵残差树。</p>
<p>Shrinkage 不直接用残差修复误差，而是只修复一点点，把大步切成小步。<strong>本质上 Shrinkage 为每棵树设置了一个 weight，累加时要乘以这个 weight，当 weight 降低时，基模型数会配合增大</strong>。</p>
<h3><span id="52-优缺点">5.2 优缺点</span></h3><h4><span id="优点"><strong>优点</strong></span></h4><ol>
<li>可以自动进行特征组合，拟合非线性数据；在稠密数据集上泛化能力和表达能力很好。</li>
<li>可以灵活处理各种类型的数据，不需要对数据预处理和归一化。</li>
<li>预测可以并行，计算数据很快。</li>
</ol>
<h4><span id="缺点"><strong>缺点</strong></span></h4><ol>
<li>对异常点敏感。</li>
</ol>
<h3><span id="53-gbdt-与-adaboost-的对比">5.3 GBDT 与 Adaboost 的对比</span></h3><h4><span id="相同"><strong>相同：</strong></span></h4><ol>
<li>都是 Boosting 家族成员，使用弱分类器；</li>
<li>都使用前向分布算法；</li>
</ol>
<h4><span id="不同"><strong>不同：</strong></span></h4><ol>
<li><strong>迭代思路不同</strong>：Adaboost 是通过提升错分数据点的权重来弥补模型的不足（利用错分样本），而 GBDT 是通过算梯度来弥补模型的不足（利用残差）；</li>
<li><strong>损失函数不同</strong>：AdaBoost 采用的是<strong>指数损失</strong>，GBDT 使用的是<strong>绝对损失</strong>或者 <strong>Huber 损失函数</strong>；</li>
</ol>
<h3><span id="54-gbdt算法用于分类问题-二分类1维-多分类k维one-vs-all"><strong><font color="red"> 5.4 GBDT算法用于分类问题、二分类1维、多分类k维（one vs all）</font></strong></span></h3><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/46445201">https://zhuanlan.zhihu.com/p/46445201</a></p>
</blockquote>
<p>将GBDT应用于回归问题，相对来说比较容易理解。因为<strong>回归问题的损失函数一般为平方差损失函数</strong>，这时的残差，恰好等于预测值与实际值之间的差值。每次拿一棵决策树去拟合这个差值，使得残差越来越小，这个过程还是比较intuitive的。</p>
<p><strong><font color="red"> 将GBDT用于分类问题，类似于逻辑回归、FM模型用于分类问题，其实是在用一个线性模型或者包含交叉项的非线性模型，去拟合所谓的对数几率 <img src="https://www.zhihu.com/equation?tex=%5Cln+%5Cfrac%7Bp%7D%7B1-p%7D" alt="[公式]"> 。</font></strong>而GBDT也是一样，只是用一系列的梯度提升树去拟合这个对数几率，实际上最终得到的是一系列CART回归树。其分类模型可以表达为：</p>
<p><img src="https://www.zhihu.com/equation?tex=P%28y%3D1%7Cx%29+%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-+%5Csum_%7Bm%3D0%7D%5EM+h_m%28x%29%7D%7D%5C%5C" alt="[公式]"></p>
<p>其中<img src="https://www.zhihu.com/equation?tex=h_m%28x%29" alt="[公式]"> 就是学习到的决策树。清楚了这一点之后，我们便可以参考逻辑回归，单样本 <img src="https://www.zhihu.com/equation?tex=%28x_i%2C+y_i%29" alt="[公式]"> 的损失函数可以表达为<strong>交叉熵</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=loss%28x_i%2C+y_i%29+%3D+-y_i+%5Clog+%5Chat%7By_i%7D+-+%281-y_i%29+%5Clog%281-%5Chat%7By_i%7D%29%5C%5C" alt="[公式]"></p>
<p>假设第k步迭代之后当前学习器为 <img src="https://www.zhihu.com/equation?tex=F%28x%29+%3D+%5Csum_%7Bm%3D0%7D%5Ek+h_m%28x%29" alt="[公式]"> ，将 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D" alt="[公式]"> 的表达式带入之后， 可将损失函数写为：</p>
<p><img src="https://www.zhihu.com/equation?tex=loss%28x_i%2C+y_i%7CF%28x%29%29+%3D+y_i+%5Clog+%5Cleft%28+1%2Be%5E%7B-F%28x_i%29%7D+%5Cright%29+%2B+%281-y_i%29+%5Cleft%5B+F%28x_i%29+%2B+%5Clog+%5Cleft%28+1%2Be%5E%7B-F%28x_i%29%7D+%5Cright%29+%5Cright%5D%5C%5C" alt="[公式]"></p>
<p><strong>可以求得损失函数相对于当前学习器的负梯度为：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=-%5Cfrac%7B%5Cpartial+loss%7D%7B%5Cpartial+F%28x%29%7D%7C_%7Bx_i%2Cy_i%7D+%3D+y_i+-+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-F%28x_i%29%7D%7D%3D+y_i+-+%5Chat%7By_i%7D%5C%5C" alt="[公式]"></p>
<p>可以看到，同回归问题很类似，下一棵决策树的训练样本为： <img src="https://www.zhihu.com/equation?tex=%5C%7B+x_i%2C+y_i+-+%5Chat%7By_i%7D+%5C%7D_%7Bi%3D1%7D%5En" alt="[公式]"> ，其所需要拟合的残差为真实标签与预测概率之差。于是便有下面GBDT应用于二分类的算法：</p>
<ul>
<li><p><img src="https://www.zhihu.com/equation?tex=F_0%28x%29+%3D+h_0%28x%29+%3D+%5Clog+%5Cfrac%7Bp_1%7D%7B1-p_1%7D" alt="[公式]"> ，其中 <img src="https://www.zhihu.com/equation?tex=p_1" alt="[公式]"> 是训练样本中y=1的比例，利用先验信息来初始化学习器</p>
</li>
<li><p>For <img src="https://www.zhihu.com/equation?tex=m+%3D+1%2C2%2C...%2CM" alt="[公式]"> ：</p>
<ul>
<li>计算 <img src="https://www.zhihu.com/equation?tex=g_i+%3D+%5Chat%7By_i%7D+-+y_i" alt="[公式]"> ，并使用训练集 <img src="https://www.zhihu.com/equation?tex=%5C%7B%28x_i%2C+-g_i%29%5C%7D_%7Bi%3D1%7D%5En" alt="[公式]"> <strong>训练一棵回归树</strong> <img src="https://www.zhihu.com/equation?tex=t_m%28x%29" alt="[公式]"> ，其中 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D+%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-F_%7Bm-1%7D%28x%29%7D%7D" alt="[公式]"></li>
<li>通过一维最小化损失函数找到树的最优权重： <img src="https://www.zhihu.com/equation?tex=%5Crho_m+%3D+%5Cmathop%7B%5Cmathrm%7Bargmin%7D%7D%5Climits_%7B%5Crho%7D+%5Csum_i+loss%28x_i%2C+y_i%7CF_%7Bm-1%7D%28x%29%2B%5Crho+t_m%28x%29%29" alt="[公式]"></li>
<li><strong>考虑shrinkage</strong>，可得这一轮迭代之后的学习器 <img src="https://www.zhihu.com/equation?tex=F_m%28x%29+%3D+F_%7Bm-1%7D%28x%29+%2B+%5Calpha+%5Crho_m+t_m%28x%29" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> 为学习率</li>
</ul>
</li>
<li><p>得到最终学习器为： <img src="https://www.zhihu.com/equation?tex=F_M%28x%29" alt="[公式]"></p>
</li>
</ul>
<p>以上就是将GBDT应用于二分类问题的算法流程。类似地，对于多分类问题，则需要考虑以下softmax模型：</p>
<p><img src="https://www.zhihu.com/equation?tex=P%28y%3D1%7Cx%29+%3D+%5Cfrac%7Be%5E%7BF_1%28x%29%7D%7D%7B%5Csum_%7Bi%3D1%7D%5Ek+e%5E%7BF_i%28x%29%7D%7D%5C%5C" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=P%28y%3D2%7Cx%29+%3D+%5Cfrac%7Be%5E%7BF_2%28x%29%7D%7D%7B%5Csum_%7Bi%3D1%7D%5Ek+e%5E%7BF_i%28x%29%7D%7D%5C%5C" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=...+...%5C%5C" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=P%28y%3Dk%7Cx%29+%3D+%5Cfrac%7Be%5E%7BF_k%28x%29%7D%7D%7B%5Csum_%7Bi%3D1%7D%5Ek+e%5E%7BF_i%28x%29%7D%7D%5C%5C" alt="[公式]"></p>
<p><strong>其中 <img src="https://www.zhihu.com/equation?tex=F_1" alt="[公式]"> <img src="https://www.zhihu.com/equation?tex=F_k" alt="[公式]"> 是 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 个不同的tree ensemble。每一轮的训练实际上是训练了 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 棵树去拟合softmax的每一个分支模型的负梯度</strong>【one-hot中的一维】。softmax模型的单样本损失函数为：</p>
<p><img src="https://www.zhihu.com/equation?tex=loss+%3D+-%5Csum_%7Bi%3D1%7D%5Ek+y_i+%5Clog+P%28y_i%7Cx%29+%3D+-%5Csum_%7Bi%3D1%7D%5Ek+y_i+%5Clog+%5Cfrac%7Be%5E%7BF_i%28x%29%7D%7D%7B%5Csum_%7Bj%3D1%7D%5Ek+e%5E%7BF_j%28x%29%7D%7D%5C%5C" alt="[公式]"></p>
<p><strong>这里的 <img src="https://www.zhihu.com/equation?tex=y_i%5C+%28i%3D1...k%29" alt="[公式]"> 是样本label在k个类别上作one-hot编码之后的取值，只有一维为1，其余都是0。由以上表达式不难推导：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=-%5Cfrac%7B%5Cpartial+loss%7D%7B%5Cpartial+F_q%7D+%3D+y_q+-+%5Cfrac%7Be%5E%7BF_q%28x%29%7D%7D%7B%5Csum_%7Bj%3D1%7D%5Ek+e%5E%7BF_j%28x%29%7D%7D+%3D+y_q+-+%5Chat%7By_q%7D%5C%5C" alt="[公式]"></p>
<p>可见，这k棵树同样是拟合了样本的真实标签与预测概率之差，与二分类的过程非常类似。</p>
<h2><span id="6-集成学习qampa">6 集成学习Q&amp;A</span></h2><h4><span id="61-为什么gbdt和随机森林稍好点都不太适用直接用高维稀疏特征训练集"><strong><font color="red"> 6.1 为什么gbdt和随机森林(稍好点)都不太适用直接用高维稀疏特征训练集？</font></strong></span></h4><h5><span id="原因">原因：</span></h5><p>gbdt这类boosting或者rf这些bagging集成分类器模型的算法，是典型的贪心算法，在当前节点总是选择对当前数据集来说最好的选择</p>
<p>一个6层100树的模型，要迭代2^(5 4 3 2 1 0)<em>100次<em>*,每次都根据当前节点最大熵或者最小误差分割来选择变量</em></em></p>
<p><strong>那么，高维稀疏数据集里很多“小而美”的数据就被丢弃了</strong>，因为它对当前节点来说不是最佳分割方案(比如，关联分析里，支持度很低置信度很高的特征)</p>
<p>但是高维数据集里面，对特定的样本数据是有很强预测能力的，比如你买叶酸，买某些小的孕妇用品品类，对应这些人6个月后买奶粉概率高达40%，但叶酸和孕妇用品销量太小了，用户量全网万分之一都不到，这种特征肯定是被树算法舍弃的，哪怕这些特征很多很多。。它仍是被冷落的份。。。</p>
<h5><span id="方法lightgbm-互斥捆绑算法">方法：【LightGBM 互斥捆绑算法】</span></h5><h5><span id="选择svm和lr这种能提供最佳分割平面的算法可能会更好">选择svm和lr这种能提供最佳分割平面的算法可能会更好；</span></h5><p>但如果top.特征已经能够贡献很大的信息量了，比如刚才孕妇的案例，你用了一个孕妇用品一级类目的浏览次数购买金额购买次数这样的更大更强的特征包含了这些高维特征的信息量，那可能gbdt会更好</p>
<p>实际情况的数据集是，在数据仓库里的清洗阶段，你可以选择把它做成高维的特征，也可以选择用算法把它做成低维的特征，一般有</p>
<p>1-在数据清洗阶段，或用类目升级(三级类目升级到二三级类目)范围升级的方式来做特征，避免直接清洗出来高维特征</p>
<p>2-在特征生成后，<strong>利用数据分析结论简单直接的用多个高维特征合并</strong>(<a href="https://www.zhihu.com/search?q=加减乘除&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A574865175}">加减乘除</a>逻辑判断都行，随你合并打分)的方式来做特征，前提你hold得住工作量判断量，但这个如果业务洞察力强效果有可能特别好</p>
<p>3-在特征工程的特征处理阶段，我们可以用<strong>PCA因子构建等降维算法做特征整合</strong>，对应训练集，也这么搞，到时候回归或预测的时候，就用这个因子或者主成分的值来做特征</p>
<h4><span id="61-为什么集成学习的基分类器通常是决策树还有什么">6.1 为什么集成学习的基分类器通常是决策树？还有什么？</span></h4><p>基分类器通常是决策树：样本权重、方便调节、随机性；</p>
<ul>
<li><strong>==决策树可以较方便地将样本权重整合到训练过程中，而不需要通过过采样来调整样本权重。==</strong></li>
<li>树的表达能力和泛化能力，<strong>方便调节</strong>（可以通过树的层数来调节）</li>
<li>样本的扰动对决策树的影响较大，<strong><font color="red"> 因此不同子样本集合生成的决策树基分类器随机性较大。这样的不稳定的分类器更适合作为基分类器。</font></strong>此外树节点分类时随机选择一个特征子集，从中找出最优分裂属性，很好地引入了随机性。</li>
</ul>
<h4><span id="62-可以将随机森林的基分类器由决策树替换成线性分类器或k-nn吗">6.2 可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？</span></h4><p>Bagging主要好处是集成后的方差，比基分类器小。bagging采用的基分类，最好是本身对样本分布较为敏感。而线性分类器和K-NN都是较为稳定的分类器（参数模型？）甚至可能因为采样，而导致他们再训练中更难收敛，从而增大了集成分类器的偏差。</p>
<h4><span id="63-为什么可以利用gbdt算法实现特征组合和筛选gbdtlr"><strong><font color="red"> 6.3 为什么可以利用GBDT算法实现特征组合和筛选？【GBDT+LR】</font></strong></span></h4><p>GBDT模型是有一组有序的树模型组合起来的，前面的树是由对大多数样本有明显区分度的特征分裂构建而成，经过前面的树，仍然存在少数残差较大的样本，后面的树主要由能对这些少数样本有区分度的特征分裂构建。优先选择对整体有区分度的特征，然后再选择对少数样本有区分度的特征，这样才更加合理，所以<strong>GBDT子树节点分裂是一个特征选择的过程，而子树的多层结构则对特征组合的过程，最终实现特征的组合和筛选。</strong></p>
<p><strong>GBDT+LR融合方案：</strong></p>
<p>（1）利用GBDT模型训练数据，最终得到一系列弱分类器的cart树。</p>
<p>（2）<strong>生成新的训练数据。将原训练数据重新输入GBDT模型，对于每一个样本，都会经过模型的一系列树，对于每棵树，将样本落到的叶子节点置为1，其他叶子为0，然后将叶子节点的数字从左至右的拼接起来，形成该棵树的特征向量，最后将所有树的特征向量拼接起来，形成新的数据特征，之后保留原样本标签形成新的训练数据。</strong></p>
<p>（3）将上一步得到的训练数据作为输入数据输入到LR模型中进行训练</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（17）KNN</title>
    <url>/posts/171MAZN/</url>
    <content><![CDATA[<h2><span id="1-什么是knnkd树-siftbbf算法">1. 什么是KNN【KD树 + SIFT+BBF算法】</span></h2><blockquote>
<p>  KNN与KD树：<a href="https://www.joinquant.com/view/community/detail/dd60bd4e89761b916fe36dc4d14bb272">https://www.joinquant.com/view/community/detail/dd60bd4e89761b916fe36dc4d14bb272</a></p>
<p>  【数学】kd 树算法之详细篇 - 椰了的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/23966698">https://zhuanlan.zhihu.com/p/23966698</a></p>
<p>  <strong>KNN是生成式模型还是判别式的</strong>，为什么？ - 风控算法小白的回答 - 知乎 <a href="https://www.zhihu.com/question/475072467/answer/2027766449">https://www.zhihu.com/question/475072467/answer/2027766449</a></p>
</blockquote>
<h3><span id="11-knn的通俗解释">1.1 KNN的通俗解释</span></h3><p>何谓K近邻算法，即K-Nearest Neighbor algorithm，简称KNN算法，单从名字来猜想，可以简单粗暴的认为是：K个最近的邻居，当K=1时，算法便成了最近邻算法，即寻找最近的那个邻居。</p>
<p>用官方的话来说，所谓K近邻算法，即是给定一个训练数据集，对新的输入实例，<strong>在训练数据集中找到与该实例最邻近的K个实例（也就是上面所说的K个邻居），这K个实例的多数属于某个类，就把该输入实例分类到这个类中。</strong></p>
<p>​                                                                     <a href="https://camo.githubusercontent.com/f0eabe33161ae7f977f082590a3690be147319df428ad1695c79127ad406729d/68747470733a2f2f6a756c796564752d696d672e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f717565736261736536343135353238333936333437323839353636302e6a7067"><img src="https://camo.githubusercontent.com/f0eabe33161ae7f977f082590a3690be147319df428ad1695c79127ad406729d/68747470733a2f2f6a756c796564752d696d672e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f717565736261736536343135353238333936333437323839353636302e6a7067" alt="img"></a></p>
<p>​                                                                <a href="https://camo.githubusercontent.com/a8942eed547ab4f08494126b0d2e5480fdfc795252e4a34a956c2b959cb5c6b8/68747470733a2f2f6a756c796564752d696d672e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f717565736261736536343135353238333936363635343430333634362e706e67"><img src="https://camo.githubusercontent.com/a8942eed547ab4f08494126b0d2e5480fdfc795252e4a34a956c2b959cb5c6b8/68747470733a2f2f6a756c796564752d696d672e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f717565736261736536343135353238333936363635343430333634362e706e67" alt="img"></a></p>
<p>如上图所示，有两类不同的样本数据，分别用蓝色的小正方形和红色的小三角形表示，而图正中间的那个绿色的圆所标示的数据则是待分类的数据。也就是说，现在，我们不知道中间那个绿色的数据是从属于哪一类（蓝色小正方形or红色小三角形），KNN就是解决这个问题的。</p>
<p>如果<strong>K=3</strong>，绿色圆点的最近的3个邻居是2个红色小三角形和1个蓝色小正方形，少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于<strong>红色</strong>的三角形一类。</p>
<p>如果<strong>K=5</strong>，绿色圆点的最近的5个邻居是2个红色三角形和3个蓝色的正方形，还是少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于<strong>蓝色</strong>的正方形一类。</p>
<p><strong>于此我们看到，当无法判定当前待分类点是从属于已知分类中的哪一类时，我们可以依据统计学的理论看它所处的位置特征，衡量它周围邻居的权重，而把它归为(或分配)到权重更大的那一类。这就是K近邻算法的核心思想。</strong></p>
<h3><span id="12-近邻的距离度量">1.2 近邻的距离度量</span></h3><p>我们看到，K近邻算法的核心在于找到实例点的邻居，这个时候，问题就接踵而至了，如何找到邻居，邻居的判定标准是什么，用什么来度量。这一系列问题便是下面要讲的距离度量表示法。</p>
<p><strong>有哪些距离度量的表示法</strong>(普及知识点，可以跳过)：</p>
<ol>
<li><p><strong>==欧氏距离==</strong>，最常见的两点之间或多点之间的距离表示法，又称之为<strong>欧几里得度量</strong>，它定义于欧几里得空间中，如点 x = (x1,…,xn) 和 y = (y1,…,yn) 之间的距离为：</p>
<p><a href="https://camo.githubusercontent.com/0699ac91c0bb89297e4cf418ad7d46cac175652d1a1de30fccc66a16a0eef254/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f6428782c79293d2535437371727425374228785f312d795f3129253545322b28785f322d795f3229253545322b2e2e2e2b28785f6e2d795f6e29253545322537443d2535437371727425374225354373756d5f253742693d312537442535452537426e25374428785f692d795f692925354532253744"><img src="https://camo.githubusercontent.com/0699ac91c0bb89297e4cf418ad7d46cac175652d1a1de30fccc66a16a0eef254/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f6428782c79293d2535437371727425374228785f312d795f3129253545322b28785f322d795f3229253545322b2e2e2e2b28785f6e2d795f6e29253545322537443d2535437371727425374225354373756d5f253742693d312537442535452537426e25374428785f692d795f692925354532253744" alt="img"></a></p>
<ul>
<li><p>二维平面上两点a(x1,y1)与b(x2,y2)间的欧氏距离：</p>
<p><a href="https://camo.githubusercontent.com/b21b48fd9bce0b9f47d16d8e5505a6b600a02e1032632df73a77d5ba43012e2a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228785f312d785f3229253545322b28795f312d795f322925354532253744"><img src="https://camo.githubusercontent.com/b21b48fd9bce0b9f47d16d8e5505a6b600a02e1032632df73a77d5ba43012e2a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228785f312d785f3229253545322b28795f312d795f322925354532253744" alt="img"></a></p>
</li>
<li><p>三维空间两点a(x1,y1,z1)与b(x2,y2,z2)间的欧氏距离：</p>
<p><a href="https://camo.githubusercontent.com/ebf7fbc4dd6e6eb0d80576e7e5cd19d38ea7a8b9cd801680fc9b39f242367515/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228785f312d785f3229253545322b28795f312d795f3229253545322b287a5f312d7a5f322925354532253744"><img src="https://camo.githubusercontent.com/ebf7fbc4dd6e6eb0d80576e7e5cd19d38ea7a8b9cd801680fc9b39f242367515/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228785f312d785f3229253545322b28795f312d795f3229253545322b287a5f312d7a5f322925354532253744" alt="img"></a></p>
</li>
<li><p>两个n维向量a(x11,x12,…,x1n)与 b(x21,x22,…,x2n)间的欧氏距离：</p>
<p><a href="https://camo.githubusercontent.com/62f0123f5d52ed280b23c7972c60f635d52a02d0b4958bd5bf0a7c61328f3225/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374225354373756d5f2537426b3d312537442535452537426e25374428785f253742316b2537442d785f253742326b2537442925354532253744"><img src="https://camo.githubusercontent.com/62f0123f5d52ed280b23c7972c60f635d52a02d0b4958bd5bf0a7c61328f3225/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374225354373756d5f2537426b3d312537442535452537426e25374428785f253742316b2537442d785f253742326b2537442925354532253744" alt="img"></a></p>
<p>也可以用表示成向量运算的形式：</p>
<p><a href="https://camo.githubusercontent.com/8e7528374c22f456904f868c6619a94ba0e51180896315eb3b019f9d7b358742/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228612d622928612d622925354554253744"><img src="https://camo.githubusercontent.com/8e7528374c22f456904f868c6619a94ba0e51180896315eb3b019f9d7b358742/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228612d622928612d622925354554253744" alt="img"></a></p>
</li>
</ul>
</li>
<li><p><strong>曼哈顿距离</strong>，我们可以定义曼哈顿距离的正式意义为L1-距离或城市区块距离，也就是在<strong>==欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和==</strong>。例如在平面上，坐标（x1, y1）的点P1与坐标（x2, y2）的点P2的曼哈顿距离为： <a href="https://camo.githubusercontent.com/eeacd6c593ac3eadb18eebfdaf9e27626a54b8f8bdb9f53bc11a90713e8b0bf8/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f253743785f312d785f322537432b253743795f312d795f32253743"><img src="https://camo.githubusercontent.com/eeacd6c593ac3eadb18eebfdaf9e27626a54b8f8bdb9f53bc11a90713e8b0bf8/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f253743785f312d785f322537432b253743795f312d795f32253743" alt="img"></a>，要注意的是，曼哈顿距离依赖座标系统的转度，而非系统在座标轴上的平移或映射。</p>
<p>通俗来讲，想象你在曼哈顿要从一个十字路口开车到另外一个十字路口，驾驶距离是两点间的直线距离吗？显然不是，除非你能穿越大楼。而实际驾驶距离就是这个“曼哈顿距离”，此即曼哈顿距离名称的来源， 同时，曼哈顿距离也称为城市街区距离(City Block distance)。</p>
<ul>
<li><p>二维平面两点a(x1,y1)与b(x2,y2)间的曼哈顿距离</p>
<p><a href="https://camo.githubusercontent.com/c914feff78b9ccb3f920a67c8dba69b110d641abde5f2533f184a656780cb94d/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d253743785f312d785f322537432b253743795f312d795f32253743"><img src="https://camo.githubusercontent.com/c914feff78b9ccb3f920a67c8dba69b110d641abde5f2533f184a656780cb94d/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d253743785f312d785f322537432b253743795f312d795f32253743" alt="img"></a></p>
</li>
<li><p>两个n维向量a(x11,x12,…,x1n)与 b(x21,x22,…,x2n)间的曼哈顿距离</p>
<p><a href="https://camo.githubusercontent.com/eb4a219d2fbe50979339a7e1a83464ec27957562f106da7a3b08da8cc3394795/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d25354373756d5f2537426b3d312537442535452537426e253744253743785f253742316b2537442d785f253742326b253744253743"><img src="https://camo.githubusercontent.com/eb4a219d2fbe50979339a7e1a83464ec27957562f106da7a3b08da8cc3394795/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d25354373756d5f2537426b3d312537442535452537426e253744253743785f253742316b2537442d785f253742326b253744253743" alt="img"></a></p>
</li>
</ul>
</li>
<li><p><strong>切比雪夫距离</strong>，若二个向量或二个点p 、and q，其座标分别为Pi及qi，则两者之间的切比雪夫距离定义如下：</p>
<p><a href="https://camo.githubusercontent.com/3a305bb0cf8cdcd6a77f9e2e2cc1085542ae46f8c70c5b43c67be9728d3d99d6/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f445f25374243686562797368657625374428702c71293d6d61785f6928253743705f692d715f6925374329"><img src="https://camo.githubusercontent.com/3a305bb0cf8cdcd6a77f9e2e2cc1085542ae46f8c70c5b43c67be9728d3d99d6/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f445f25374243686562797368657625374428702c71293d6d61785f6928253743705f692d715f6925374329" alt="img"></a></p>
<p>这也等于以下Lp度量的极值： <a href="https://camo.githubusercontent.com/8fe6945bfb5795e12cfe28b72758c59a598e0c5a89b1ffb874f01cc8ff77a7ba/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d32345f32322d31392d34312e706e67"><img src="https://camo.githubusercontent.com/8fe6945bfb5795e12cfe28b72758c59a598e0c5a89b1ffb874f01cc8ff77a7ba/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d32345f32322d31392d34312e706e67" alt="img"></a>，因此切比雪夫距离也称为L∞度量。</p>
<p>以数学的观点来看，切比雪夫距离是由一致范数（uniform norm）（或称为上确界范数）所衍生的度量，也是超凸度量（injective metric space）的一种。</p>
<p>在平面几何中，若二点p及q的直角坐标系坐标为(x1,y1)及(x2,y2)，则切比雪夫距离为：</p>
<p><a href="https://camo.githubusercontent.com/2c68232279b3d8c857a5ebf5bcb91f6792abeb47daedeb22214391611680dd97/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f445f25374243686573732537443d6d617828253743785f322d785f312537432c253743795f322d795f3125374329"><img src="https://camo.githubusercontent.com/2c68232279b3d8c857a5ebf5bcb91f6792abeb47daedeb22214391611680dd97/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f445f25374243686573732537443d6d617828253743785f322d785f312537432c253743795f322d795f3125374329" alt="img"></a></p>
<p><strong>玩过国际象棋的朋友或许知道，国王走一步能够移动到相邻的8个方格中的任意一个。那么国王从格子(x1,y1)走到格子(x2,y2)最少需要多少步？。你会发现最少步数总是max( | x2-x1 | , | y2-y1 | ) 步 。有一种类似的一种距离度量方法叫切比雪夫距离。</strong></p>
<ul>
<li><p>二维平面两点a(x1,y1)与b(x2,y2)间的切比雪夫距离 ：</p>
<p><a href="https://camo.githubusercontent.com/9387d181258b2a722bcabf891beb2d616a2ec297f35bade87679099641f27f09/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d6d617828253743785f322d785f312537432c253743795f322d795f3125374329"><img src="https://camo.githubusercontent.com/9387d181258b2a722bcabf891beb2d616a2ec297f35bade87679099641f27f09/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d6d617828253743785f322d785f312537432c253743795f322d795f3125374329" alt="img"></a></p>
</li>
<li><p>两个n维向量a(x11,x12,…,x1n)与 b(x21,x22,…,x2n)间的切比雪夫距离：</p>
<p><a href="https://camo.githubusercontent.com/ea4a630eab19efb4c0270f3808dde70fec7bb5f21d37f76ab016316277fbb730/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d6d61785f6928253743785f25374231692537442d785f253742326925374425374329"><img src="https://camo.githubusercontent.com/ea4a630eab19efb4c0270f3808dde70fec7bb5f21d37f76ab016316277fbb730/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d6d61785f6928253743785f25374231692537442d785f253742326925374425374329" alt="img"></a></p>
</li>
</ul>
</li>
</ol>
<p><strong>==简单说来，各种“距离”的应用场景简单概括为：==</strong></p>
<ul>
<li><strong>空间：欧氏距离</strong>，</li>
<li><strong>路径：曼哈顿距离，国际象棋国王：切比雪夫距离</strong>，</li>
<li>以上三种的统一形式:闵可夫斯基距离，</li>
<li>加权：标准化欧氏距离，</li>
<li>排除量纲和依存：马氏距离，</li>
<li>向量差距：夹角余弦，</li>
<li><strong>编码差别：汉明距离</strong>，</li>
<li>集合近似度：杰卡德类似系数与距离，</li>
<li>相关：相关系数与相关距离。</li>
</ul>
<h3><span id="13-k值选择">1.3 K值选择</span></h3><ol>
<li>如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，<strong>K值的减小就意味着整体模型变得复杂，容易发生过拟合；</strong></li>
<li>如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且<strong>K值的增大就意味着整体的模型变得简单。</strong></li>
<li>K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的累，模型过于简单，忽略了训练实例中大量有用信息。</li>
</ol>
<p>在实际应用中，K值一般取一个比较小的数值，<strong>例如采用交叉验证法（简单来说，就是一部分样本做训练集，一部分做测试集）来选择最优的K值。</strong></p>
<h3><span id="14-knn最近邻分类算法的过程">1.4 KNN最近邻分类算法的过程</span></h3><ol>
<li>计算测试样本和训练样本中每个样本点的距离（常见的距离度量有欧式距离，马氏距离等）；</li>
<li>对上面所有的距离值进行排序；</li>
<li>选前 k 个最小距离的样本；</li>
<li>根据这 k 个样本的标签进行投票，得到最后的分类类别；</li>
</ol>
<h2><span id="关于knn的一些问题">关于KNN的一些问题</span></h2><ol>
<li><p>在k-means或kNN，我们是用欧氏距离来计算最近的邻居之间的距离。为什么不用<strong>曼哈顿距离</strong>？</p>
<p><strong>答：</strong>我们不用曼哈顿距离，因为它只计算水平或垂直距离，有维度的限制。另一方面，欧式距离可用于任何空间的距离计算问题。因为，数据点可以存在于任何空间，欧氏距离是更可行的选择。例如：想象一下国际象棋棋盘，象或车所做的移动是由曼哈顿距离计算的，因为它们是在各自的水平和垂直方向的运动。</p>
</li>
<li><p>KD-Tree相比KNN来进行快速图像特征比对的好处在哪里?</p>
<p>答：极大的节约了时间成本．点线距离如果 &gt;　最小点，无需回溯上一层，如果&lt;,则再上一层寻找。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（11）LGB*</title>
    <url>/posts/YFRZTY/</url>
    <content><![CDATA[<h2><span id="参考链接">参考链接</span></h2><ul>
<li><p><strong>XGBoost官方文档</strong>：<a href="https://xgboost.readthedocs.io/en/latest/index.html">https://xgboost.readthedocs.io/en/latest/index.html</a></p>
</li>
<li><p>LightGBM算法梳理：<a href="https://zhuanlan.zhihu.com/p/78293497">https://zhuanlan.zhihu.com/p/78293497</a></p>
</li>
<li><p>详解LightGBM两大利器：基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）：<a href="https://zhuanlan.zhihu.com/p/366234433">https://zhuanlan.zhihu.com/p/366234433</a></p>
</li>
<li><p>【机器学习】决策树（下）——XGBoost、LightGBM（非常详细）：<a href="https://zhuanlan.zhihu.com/p/87885678">https://zhuanlan.zhihu.com/p/87885678</a></p>
</li>
<li><p>xgboost面试题整理: <a href="https://xiaomindog.github.io/2021/06/22/xgb-qa/">https://xiaomindog.github.io/2021/06/22/xgb-qa/</a></p>
</li>
</ul>
<h2><span id="机器学习决策树下xgboost-lightgbm">【机器学习】决策树（下）——XGBoost、LightGBM</span></h2><p><img src="https://pic2.zhimg.com/80/v2-358e4bfce928d0460bd5e8b4cab8f715_1440w.jpg" alt="img"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Boosting 算法</th>
<th>GBDT</th>
<th>XGBoost</th>
<th>LightGBM</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>思想</strong><img src="image-20220315210756470.png" alt="image-20220315210756470" style="zoom:25%;"></td>
<td>回归树、梯度迭代、缩减（Shrinkage）;<strong>GBDT 的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于 0</strong></td>
<td><strong>二阶导数、线性分类器、正则化</strong>、缩减、<strong>列抽样、并行化</strong></td>
<td><strong>更快的训练速度和更低的内存使用</strong></td>
</tr>
<tr>
<td>目标函数</td>
<td><img src="image-20220315213233284.png" alt="image-20220315213233284" style="zoom: 25%;"></td>
<td><img src="image-20220315213503054.png" alt="image-20220315213503054" style="zoom: 67%;"><img src="image-20220315213608526.png" alt="image-20220315213608526" style="zoom: 33%;"></td>
<td>同上</td>
</tr>
<tr>
<td>损失函数</td>
<td>最小均方损失函数、<strong>绝对损失或者 Huber 损失函数</strong></td>
<td>【线性】最小均方损失函数、==sigmod和softmax==</td>
<td><strong>复杂度模型</strong>：<img src="image-20220315215849417.png" alt="image-20220315215849417" style="zoom: 25%;"></td>
</tr>
<tr>
<td>基模型</td>
<td>CART模型</td>
<td>CART模型/ ==回归模型==</td>
<td>CART模型/ ==回归模型==</td>
</tr>
<tr>
<td>抽样算法</td>
<td>无</td>
<td><strong>列抽样</strong>：借鉴了<strong>随机森林</strong>的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</td>
<td><strong>单边梯度抽样算法；</strong>根据样本梯度来对梯度小的这边样本进行采样，一部分大梯度和随机分布</td>
</tr>
<tr>
<td><strong>切分点算法</strong></td>
<td>CART模型</td>
<td><strong>预排序</strong>、<strong>贪心算法</strong>、<strong>近似算法（</strong>加权分位数缩略图<strong>）</strong></td>
<td><strong>直方图算法</strong>：内存消耗降低，计算代价减少；（不需要记录特征到样本的索引）</td>
</tr>
<tr>
<td><strong>缺失值算法</strong></td>
<td>CART模型</td>
<td><strong>稀疏感知算法</strong>：选择增益最大的枚举项即为最优<strong>缺省方向</strong>。【<strong><font color="red"> 稀疏数据优化不足</font></strong>】【<strong>gblinear 补0</strong>】</td>
<td><strong>互斥特征捆绑算法</strong>：<strong>互斥</strong>指的是一些特征很少同时出现非0值。<strong>稀疏感知算法</strong>；【<strong>gblinear 补0</strong>】</td>
</tr>
<tr>
<td><strong>建树策略</strong></td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Leaf-wise</strong>：每次分裂增益最大的叶子节点，直到达到停止条件。</td>
</tr>
<tr>
<td><strong>正则化</strong></td>
<td>无</td>
<td>L1 和 L2 正则化项</td>
<td>L1 和 L2 正则化项</td>
</tr>
<tr>
<td><strong>Shrinkage（缩减）</strong></td>
<td>有</td>
<td>有</td>
<td>有</td>
</tr>
<tr>
<td>类别特征优化</td>
<td>无</td>
<td>无</td>
<td><strong>类别特征最优分割</strong>：<strong>many-vs-many</strong></td>
</tr>
<tr>
<td>并行化设计</td>
<td>无</td>
<td><strong>块结构设计</strong>、</td>
<td><strong>特征并行</strong>、 <strong>数据并行</strong>、<strong>投票并行</strong></td>
</tr>
<tr>
<td>==缓存优化==</td>
<td>无</td>
<td>为每个线程分配一个连续的缓存区、<strong>“核外”块计算</strong></td>
<td>1、所有的特征都采用相同的方法获得梯度；2、其次，因为不需要存储特征到样本的索引，降低了存储消耗</td>
</tr>
<tr>
<td><strong>缺点</strong></td>
<td>对异常点敏感；</td>
<td><strong>预排序</strong>：仍需要遍历数据集；==不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引，相当于消耗了两倍的内存。==</td>
<td><strong>内存更小</strong>： 索引值、特征值边bin、互斥特征捆绑; <strong>速度更快</strong>：遍历直方图；单边梯度算法过滤掉梯度小的样本；基于 Leaf-wise 算法的增长策略构建树，减少了很多不必要的计算量；特征并行、数据并行方法加速计算</td>
</tr>
</tbody>
</table>
</div>
<h2><span id="一-lightgbm">一、LightGBM</span></h2><blockquote>
<ul>
<li>《<a href="https://www.zhihu.com/search?q=Lightgbm%3A+A+highly+efficient+gradient+boosting+decision+tree&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;165627712&quot;}">Lightgbm: A highly efficient gradient boosting decision tree</a>》</li>
<li>《A communication-efficient <a href="https://www.zhihu.com/search?q=parallel+algorithm+for+decision+tree&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;165627712&quot;}">parallel algorithm for decision tree</a>》</li>
</ul>
</blockquote>
<p>LightGBM 由微软提出，主要用于解决 GDBT 在海量数据中遇到的问题，以便其可以更好更快地用于工业实践中。从 LightGBM 名字我们可以看出其是轻量级（Light）的梯度提升机（GBM），其相对 XGBoost 具有<strong>训练速度快、内存占用低</strong>的特点。下图分别显示了 XGBoost、XGBoost_hist（利用梯度直方图的 XGBoost） 和 LightGBM 三者之间针对不同数据集情况下的内存和训练时间的对比：</p>
<p><img src="https://pic1.zhimg.com/80/v2-e015e3c4018f44787d74a47c9e0cd040_1440w.jpg" alt="img"></p>
<p>那么 LightGBM 到底如何做到<strong>更快的训练速度和更低的内存</strong>使用的呢？</p>
<h4><span id="lightgbm-为了解决这些问题提出了以下几点解决方案"><strong><font color="red"> LightGBM 为了解决这些问题提出了以下几点解决方案：</font></strong></span></h4><ol>
<li><p><strong>【减小内存、最优分类点】直方图算法</strong>；【特征离散化 + 内存占用 + 方差减少】</p>
</li>
<li><p><strong>【样本维度】 单边梯度抽样算法</strong>；【<strong>根据样本梯度来对梯度小的这边样本进行采样</strong>，一部分大梯度和随机分布】</p>
<blockquote>
<p>  <strong>一方面算法将更多的注意力放在训练不足的样本上，另一方面通过乘上权重来防止采样对原始数据分布造成太大的影响。</strong></p>
</blockquote>
</li>
<li><p><strong>【特征维度】互斥特征捆绑算法</strong>；【特征稀疏行优化 +分箱 】</p>
</li>
<li><p><strong>【分裂算法】基于最大深度的 Leaf-wise 的垂直生长算法</strong>；【深度限制的最大分裂收益的叶子】</p>
</li>
<li><p><strong>类别特征最优分割</strong>；</p>
</li>
<li><p><strong>特征并行和数据并行</strong>；</p>
</li>
<li><p><strong>缓存优化。</strong></p>
</li>
</ol>
<h3><span id="11-数学原理">1.1 数学原理</span></h3><h3><span id="111-直方图算法"><strong>1.1.1 直方图算法</strong></span></h3><h4><span id="1-直方图算法"><strong>(1) 直方图算法</strong></span></h4><p><strong><font color="red"> 直方图算法的基本思想是将连续的特征离散化为 k （默认256 1字节）个离散特征，同时构造一个宽度为 k 的直方图用于统计信息（含有 k 个 bin）。利用直方图算法我们无需遍历数据，只需要遍历 k 个 bin 即可找到最佳分裂点。</font></strong></p>
<p>我们知道特征离散化的具有很多优点，如存储方便、运算更快、鲁棒性强、模型更加稳定等等。对于直方图算法来说最直接的有以下两个优点（以 k=256 为例）：</p>
<ul>
<li><strong>内存占用更小：</strong>XGBoost 需要用 <strong>32 位的浮点数去存储特征值，并用 32 位的整形去存储排序索引</strong>，而 LightGBM 只需要用 8 位去存储直方图，<strong>相当于减少了 1/8</strong>；</li>
<li><strong>计算代价更小：</strong>计算特征分裂增益时，XGBoost 需要遍历一次数据找到最佳分裂点，而 LightGBM 只需要遍历一次 k 次，直接将时间复杂度从代价是O( feature <em> <strong>distinct_values_of_the_feature</strong>); 而 histogram 只需要计算 bins次, 代价是( feature </em> <strong>bins</strong>)。<strong>distinct_values_of_the_feature &gt;&gt; bins</strong></li>
</ul>
<p><img src="image-20220625171413733.png" alt="image-20220625171413733"></p>
<ol>
<li><strong>直方图优化算法需要在训练前预先把特征值转化为bin value</strong>，也就是对每个特征的取值做个分段函数，将所有样本在该特征上的取值划分到某一段（bin）中。最终把特征取值从连续值转化成了离散值。需要注意得是：feature value对应的bin value在整个训练过程中是不会改变的。</li>
<li><strong>最外面的 for 循环表示的意思是对当前模型下所有的叶子节点处理</strong>，需要遍历所有的特征，来找到增益最大的特征及其划分值，以此来分裂该叶子节点。</li>
<li>在某个叶子上，第二个 for 循环就开始遍历所有的特征了。<strong>对于每个特征，首先为其创建一个直方图 (new Histogram() )</strong>。这个直方图存储了两类信息，分别是<strong><font color="red"> 每个bin中样本的梯度之和 $H[ f.bins[i] ].g$ </font></strong>，还有就是<strong>每个bin中样本数量</strong>$（H[f.bins[i]].n）$</li>
<li>第三个 for 循环遍历所有样本，累积上述的两类统计值到样本所属的bin中。即直方图的每个 bin 中包含了一定的样本，在此计算每个 bin 中的样本的梯度之和并对 bin 中的样本记数。</li>
<li>最后一个for循环, 遍历所有bin, 分别以当前bin作为分割点, 累加其左边的bin至当前bin的梯度和（ $\left.S_{L}\right)$ 以及样本数量 $\left(n_{L}\right)$, 并与父节点上的总梯度和 $\left(S_{p}\right)$ 以及总样本数量 $\left(n_{p}\right)$ 相减, 得到右边 所有bin的梯度和 $\left(S_{R}\right)$ 以及样本数量 $\left(n_{R}\right)$, 带入公式, 计算出增益, 在遍历过程中取最大的增 益, 以此时的特征和bin的特征值作为分裂节点的特征和分裂特征取值。</li>
</ol>
<h4><span id="2-源码分析">(2) 源码分析</span></h4><blockquote>
<p>  <a href="https://blog.csdn.net/anshuai_aw1/article/details/83040541">https://blog.csdn.net/anshuai_aw1/article/details/83040541</a></p>
<p>  <strong><font color="red"> 『我爱机器学习』集成学习（四）LightGBM</font></strong>：<a href="https://www.hrwhisper.me/machine-learning-lightgbm/">https://www.hrwhisper.me/machine-learning-lightgbm/</a></p>
</blockquote>
<p>问题一：<strong>如何将特征映射到bin呢？即如何分桶？对于连续特征和类别特征分别怎么样处理？</strong></p>
<p>问题二：<strong>如何构建直方图？直方图算法累加的g是什么？难道没有二阶导数h吗？</strong></p>
<h4><span id="特征分桶">特征分桶：</span></h4><blockquote>
<p>  <strong>特征分桶的源码</strong>在<strong>bin.cpp</strong>文件和<strong>bin.h</strong>文件中。由于LGBM可以处理类别特征，因此对连续特征和类别特征的处理方式是不一样的。</p>
</blockquote>
<h4><span id="连续特征">连续特征:</span></h4><p>在<strong>bin.cpp</strong>中，我们可以看到<strong>GreedyFindBin</strong>函数和<strong>FindBinWithZeroAsOneBin</strong>函数，这两个函数得到了数值型特征取值（负数，0，正数）的各个bin的切分点，即bin_upper_bound。</p>
<h4><span id="greedyfindbin-数值型根据特征不同取值的个数划分类别型">GreedyFindBin: 数值型根据特征不同取值的个数划分，类别型？？</span></h4><ul>
<li><em>特征取值计数的数组</em>、<em>特征的不同的取值的数组</em>、<em>特征有多少个不同的取值</em></li>
<li><strong>bin_upper_bound就是记录桶分界的数组</strong></li>
<li>特征取值数比max_bin数量少，直接取distinct_values的中点放置</li>
<li>特征取值数比max_bin来得大，说明几个特征值要共用一个bin<ul>
<li>如果一个特征值的数目比mean_bin_size大，那么这些特征需要单独一个bin</li>
<li>剩下的特征取值的样本数平均每个剩下的bin：mean size for one bin</li>
</ul>
</li>
</ul>
<h4><span id="构建直方图">构建直方图：</span></h4><p>给定一个特征的值，我们现在已经可以转化为对应的bin了。现在我们就可以构建直方图了。</p>
<h4><span id="constructhistogram"><strong>ConstructHistogram</strong>：</span></h4><ul>
<li><strong>累加了一阶、二阶梯度和还有==个数==</strong></li>
<li>当然还有其它的版本，当is_constant_hessianis_constant_hessian为true的时候是不用二阶梯度的</li>
</ul>
<h4><span id="寻找最优切分点-缺失值处理-gain和xgb一样">寻找最优切分点 : 缺失值处理 + Gain和XGB一样</span></h4><h4><span id="3直方图算法优点"><strong><font color="red"> （3）直方图算法优点：</font></strong></span></h4><ul>
<li><p><strong>内存消耗降低</strong>。预排序算法需要的内存约是训练数据的两倍（2x样本数x维度x4Bytes），它需要用32位浮点来保存特征值，并且对每一列特征，都需要一个额外的排好序的索引，这也需要32位的存储空间。对于 直方图算法，则只需要(1x样本数x维 度x1Bytes)的内存消耗，仅为预排序算法的1/8。因为直方图算法仅需要存储特征的 bin 值(离散化后的数值)，不需要原始的特征值，也不用排序，而bin值用8位整型存储就足够了。</p>
</li>
<li><p><strong>算法时间复杂度大大降低</strong>。决策树算法在节点分裂时有两个主要操作组成，一个是“寻找分割点”，另一个是“数据分割”。从算法时间复杂度来看，在“寻找分割点”时，预排序算法对于深度为$k$的树的时间复杂度：对特征所有取值的排序为$O(NlogN)$，$N$为样本点数目，若有$D$维特征，则$O(kDNlogN)$，而直方图算法需要$O(kD \times bin)$ (bin是histogram 的横轴的数量，一般远小于样本数量$N$)。</p>
</li>
<li><p><strong>直方图算法还可以进一步加速</strong>【<strong>==两个维度==</strong>】。一个容易观察到的现象：<strong>一个叶子节点的直方图可以直接由父节点的直方图和兄弟节点的直方图做差得到（分裂时左右集合）</strong>。通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的$k$个bin。利用这个方法，LightGBM可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。</p>
<p><img src="https://pic1.zhimg.com/80/v2-86919e4fc187a11fe3fdb72780709c98_1440w.jpg" alt="img" style="zoom:67%;"></p>
</li>
<li><p><strong>缓存优化</strong>：上边说到 XGBoost 的预排序后的特征是通过索引给出的样本梯度的统计值，因其索引访问的结果并不连续，XGBoost 提出缓存访问优化算法进行改进。<strong><font color="red"> LightGBM 所使用直方图算法对 Cache 天生友好所有的特征都采用相同的方法获得梯度，构建直方图时bins字典同步记录一阶导、二阶导和个数，大大提高了缓存命中</font></strong>；因为<strong>不需要存储特征到样本的索引</strong>，降低了存储消耗，而且也不存在 Cache Miss的问题。</p>
</li>
<li><p><strong>数据并行优化</strong>，用 histgoram 可以大幅降低通信代价。用 pre-sorted 算法的话，通信代价是非常大的（几乎是没办法用的）。所以 xgoobst 在并行的时候也使用 histogram 进行通信。</p>
</li>
</ul>
<h4><span id="4直方图算法缺点">（4）直方图算法缺点：</span></h4><p><strong>当然，直方图算法并不是完美的。由于特征被离散化后，找到的并不是很精确的分割点，所以会对结果产生影响。</strong>但在不同的数据集上的结果表明，离散化的分割点对最终的精度影响并不是很大，甚至有时候会更好一点。原因是决策树本来就是弱模型，分割点是不是精确并不是太重要；<strong>较粗的分割点也有正则化的效果，可以有效地防止过拟合</strong>；即使单棵树的训练误差比精确分割的算法稍大，但在梯度提升（GradientBoosting）的框架下没有太大的影响。</p>
<h3><span id="112-单边梯度抽样算法"><strong>1.1.2 单边梯度抽样算法</strong></span></h3><font color="red"> **直方图算法仍有优化的空间**，建立直方图的复杂度为O(**feature × data**)，如果能**降低特征数**或者**降低样本数**，训练的时间会大大减少。</font>

<p><strong>GBDT 算法的梯度大小可以反应样本的权重，梯度越小说明模型拟合的越好，单边梯度抽样算法</strong>（Gradient-based One-Side Sampling, GOSS）利用这一信息对样本进行抽样，减少了大量梯度小的样本，在接下来的计算锅中只需关注梯度高的样本，极大的减少了计算量。</p>
<ol>
<li>根据<strong>梯度的绝对值</strong>将样本进行<strong>降序</strong>排序</li>
<li>选择前a×100%的样本，这些样本称为A</li>
<li>剩下的数据(1−a)×100的数据中，随机抽取b×100%的数据，这些样本称为B</li>
<li>在计算增益的时候，放大样本B中的梯度 (1−a)/b 倍</li>
<li>关于g，在具体的实现中是一阶梯度和二阶梯度的乘积，见Github的实现（LightGBM/src/boosting/goss.hpp）</li>
</ol>
<blockquote>
<p>  a%（大梯度）+ (1-a)/ b * b % 的大梯度</p>
</blockquote>
<p><strong>使用GOSS进行采样, 使得训练算法更加的关注没有充分训练(under-trained)的样本, 并且只会稍微的改变原有的数据分布</strong>。原有的在特征值为 $\mathrm{d}$ 处分数据带来的增益可以定义为：</p>
<script type="math/tex; mode=display">
V_{j \mid O}(d)=\frac{1}{n_{O}}\left(\frac{\left(\sum_{x_{i} \in O: x_{i j} \leq d} g_{i}\right)^{2}}{n_{l \mid O}^{j}(d)}+\frac{\left(\sum_{x_{i} \in O: x_{i j}>d} g_{i}\right)^{2}}{n_{r \mid O}^{j}(d)}\right)</script><p>其中:</p>
<ul>
<li>O为在决策树待分裂节点的训练集</li>
<li>$n_{o}=\sum I\left(x_{i} \in O\right)$</li>
<li>$n_{l \mid O}^{j}(d)=\sum I\left[x_{i} \in O: x_{i j} \leq d\right]$ and $n_{r \mid O}^{j}(d)=\sum I\left[x_{i} \in O: x_{i j}&gt;d\right]$</li>
</ul>
<p><strong>而使用GOSS后, 增益定义为：</strong></p>
<script type="math/tex; mode=display">
V_{j \mid O}(d)=\frac{1}{n_{O}}\left(\frac{\left(\sum_{x_{i} \in A_{l}} g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{l}} g_{i}\right)^{2}}{n_{l}^{j}(d)}+\frac{\left(\sum_{x_{i} \in A_{r}} g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{l}} g_{r}\right)^{2}}{n_{r}^{j}(d)}\right)</script><p>其中:</p>
<ul>
<li>$A_{l}=\left\{x_{i} \in A: x_{i j} \leq d\right\}, A_{r}=\left\{x_{i} \in A: x_{i j}&gt;d\right\}$</li>
<li>$B_{l}=\left\{x_{i} \in B: x_{i j} \leq d\right\}, B_{r}=\left\{x_{i} \in B: x_{i j}&gt;d\right\}$</li>
</ul>
<p>实验表明，该做法并没有降低模型性能，反而还有一定提升。究其原因，应该是采样也会增加弱学习器的多样性，从而潜在地提升了模型的泛化能力，稍微有点像深度学习的dropout。</p>
<h3><span id="113-互斥特征捆绑算法冲突小的特征可能与多个特征包组合特征集合"><strong>1.1.3 互斥特征捆绑算法</strong>【冲突小的特征可能与多个特征包组合】[特征集合]</span></h3><blockquote>
<p>  <strong>==互斥==指的是一些特征很少同时出现非0值</strong>【<strong>类似one-hot特征</strong>】</p>
<p>  <a href="https://zhuanlan.zhihu.com/p/366234433">详解LightGBM两大利器：基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）</a></p>
</blockquote>
<p><strong><font color="red"> 互斥特征捆绑算法（Exclusive Feature Bundling, EFB）指出如果将一些特征进行合并，则可以降低特征数量。</font></strong>高维特征往往是稀疏的，而且特征间可能是相互排斥的（如两个特征不同时取非零值），如果两个特征并不完全互斥（如只有一部分情况下是不同时取非零值），可以用互斥率表示互斥程度。</p>
<p><strong>1）首先介绍如何判定哪些特征应该捆绑在一起？</strong></p>
<p>EFB算法采用<strong>构图（build graph）</strong>的思想，将特征作为节点，不互斥的特征之间进行连边，然后从图中找出所有的捆绑特征集合。其实学过数据结构里的图算法就了解过，这个问题基本就是<a href="https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%9B%BE%E7%9D%80%E8%89%B2%E9%97%AE%E9%A2%98/8928655%3Ffr%3Daladdin">图着色问题</a>。但是图着色问题是一个<strong>NP-hard问题</strong>，不可能在多项式时间里找到最优解。</p>
<p>因此<strong>EFB采用了一种近似的贪心策略解决办法。它允许特征之间存在少数的样本点并不互斥</strong>（比如某些对应的样本点之间并不同时为非0），并设置一个最大冲突阈值 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 。我们选择合适的 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 值，可以在准确度和训练效率上获得很好的trade-off（均衡)。</p>
<p>==<strong>下面给出EFB的特征捆绑的贪心策略流程：</strong>==</p>
<blockquote>
<p>  （1）将特征作为图的顶点，对于<strong>不互斥的特征进行相连</strong>（存在同时不为0的样本），特征同时不为0的样本个数作为边的权重；<br>  （2）根据顶点的度对特征进行降序排序，度越大表明特征与其他特征的冲突越大（越不太可能与其他特征进行捆绑）；【<strong>入度排序，转化为非零值个数排序</strong>】<br>  （3）设置<strong>最大冲突阈值K</strong>，外层循环先对每一个上述排序好的特征，遍历已有的特征捆绑簇，如果发现该特征加入到该特征簇中的冲突数不会超过最大阈值K，则将该特征加入到该簇中。否则新建一个特征簇，将该特征加入到新建的簇中。</p>
</blockquote>
<p><img src="https://pic4.zhimg.com/80/v2-743681d9fd6cebee11f0dcc607f2f687_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p>上面时间的复杂度为 <img src="https://www.zhihu.com/equation?tex=O%28n%5E2%29" alt="[公式]"> ，n为特征的数量，时间其实主要花费在建图上面，两两特征计算互斥程度的时间较长（2层for循环）。对于百万级别的特征数量来说，该复杂度仍是<strong>不可行的</strong>。==为了提高效率，可以不再构建图，将特征直接按照非零值个数排序，将特征<strong>非零值个数</strong>类比为节点的度（即冲突程度)，因为更多的非零值更容易引起冲突。只是改进了排序策略，不再构建图，下面的for循环是一样的。==</p>
<p><strong>2）如何将特征捆绑簇里面的所有特征捆绑（合并）为一个特征？</strong>【<strong>直方图偏移</strong>】</p>
<p>如何进行合并，最关键的是如何能将原始特征从合并好的特征进行分离出来。EFB采用的是加入一个<strong>偏移常量</strong>（offset）来解决。</p>
<blockquote>
<p>  举个例子，我们绑定两个特征A和B，A取值范围为[0, 10)，B取值范围为[0, 20)。则我们可以加入一个偏移常量10，即将B的取值范围变为[10,30），然后合并后的特征范围就是[0, 30)，并且能很好的分离出原始特征~</p>
</blockquote>
<p>因为lgb中<strong>直方图算法</strong>对特征值进行了<strong>分桶</strong>（bin）操作，导致合并互斥特征变得更为简单。从上面伪码看到偏移常量offset直接对每个特征桶的数量累加就行，然后放入偏移常数数组（binRanges）中。</p>
<h3><span id="114-带深度限制的-leaf-wise-算法"><strong>1.1.4 带深度限制的 Leaf-wise 算法</strong></span></h3><h4><span id="level-wise">Level-wise</span></h4><p>大多数GBDT框架使用的按层生长 (level-wise) 的决策树生长策略，Level-wise遍历一次数据可以同时分裂同一层的叶子，容易进行<strong>多线程优化</strong>，也好<strong>控制模型复杂度，不容易过拟合</strong>。但实际上Level-wise是一种低效的算法，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销，因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。</p>
<h4><span id="leaf-wise">Leaf-wise</span></h4><p>Leaf-wise则是一种更为高效的策略，每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环。因此同Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度。Leaf-wise的缺点是可能会长出比较深的决策树，产生过拟合。因此LightGBM在Leaf-wise之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。</p>
<p><img src="https://pic2.zhimg.com/80/v2-76f2f27dd24fc452a9a65003e5cdd305_1440w.jpg" alt="img"></p>
<h3><span id="115-lightgbm类别特征最优分割">==<strong>1.1.5 LightGBM类别特征最优分割</strong>==</span></h3><blockquote>
<p>  LightGBM中只需要提前将类别映射到非负整数即可(<code>integer-encoded categorical features</code>)</p>
</blockquote>
<p><strong>我们知道，LightGBM可以直接处理类别特征，而不需要对类别特征做额外的one-hot encoding。那么LGB是如何实现的呢？</strong></p>
<p>类别特征的使用在实践中是很常见的。且为了解决one-hot编码处理类别特征的不足, LightGBM优化了对类别特征的支持，可以直接输入类别特征，不需要额外的0/1展开。<strong>LightGBM 采用 many-vs-many 的切分方式将类别特征分为两个子集，实现类别特征的最优切分</strong>。假设某维 特征有 k 个类别，则有 <img src="https://www.zhihu.com/equation?tex=2%5E%7B%28k-1%29%7D-1" alt="[公式]"> 种可能, 时间复杂度为 <img src="https://www.zhihu.com/equation?tex=O%5Cleft%282%5E%7Bk%7D%5Cright%29%2C" alt="[公式]"> LightGBM 基于 Fisher的 《<a href="https://www.zhihu.com/search?q=On+Grouping+For+Maximum+Homogeneity&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;165627712&quot;}">On Grouping For Maximum Homogeneity</a>》论文实现了 O(klogk) 的<a href="https://www.zhihu.com/search?q=时间复杂度&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;165627712&quot;}">时间复杂度</a>。</p>
<p><strong>算法流程如下图所示</strong>，在枚举分割点之前，先把直方图按照每个类别对应的label均值进行排序; 然后按照排序的结果依次枚举最优分割点。从下图可以看到, <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7BS+u+m%28y%29%7D%7B%5Coperatorname%7BCount%7D%28y%29%7D" alt="[公式]"> 为类别的均值。当然，这个方法很容易过拟合，所以LightGBM里面还增加了很多对于这个方法的约束和正则化。</p>
<p><img src="https://pic1.zhimg.com/v2-0f1b7024e9da8f09c75b7f8e436a5d24_b.jpg" alt="img" style="zoom:67%;"></p>
<p><strong>在Expo数据集上的实验结果表明，相比0/1展开的方法，使用LightGBM支持的类别特征可以使训练速度加速8倍，并且精度一致。</strong>更重要的是，LightGBM是第一个直接支持类别特征的GBDT工具。</p>
<h3><span id="12-工程实现-并行计算">1.2 工程实现 - 并行计算</span></h3><h3><span id="121-特征并行优化-最优划分点"><strong>1.2.1 特征并行</strong>【优化 最优划分点】</span></h3><p>传统的特征并行算法在于对数据进行垂直划分，然后使用<strong>不同机器找到不同特征的最优分裂点</strong>，<strong>基于通信整合得到最佳划分点</strong>，然后基于通信告知其他机器划分结果。==在本小节中，<strong>工作的节点称为worker</strong>==</p>
<h4><span id="传统">==<strong>传统：</strong>==</span></h4><ul>
<li>垂直划分数据<strong>（对特征划分）</strong>，<strong>不同的worker有不同的特征集</strong></li>
<li>每个workers找到局部最佳的切分点{feature, threshold}</li>
<li>workers使用点对点通信，找到全局最佳切分点</li>
<li><strong>具有全局最佳切分点的worker进行节点分裂，然后广播切分后的结果</strong>（<strong>左右子树的instance indices</strong>）</li>
<li>其它worker根据收到的instance indices也进行划分</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-b0d10c5cd832402e4503e2c1220f7376_r.jpg" alt="preview" style="zoom: 67%;"></p>
<p><strong>传统的特征并行方法有个很大的缺点</strong>：</p>
<ul>
<li><strong>需要告知每台机器最终划分结果，增加了额外的复杂度</strong>（因为对数据进行垂直划分，每台机器所含数据不同，划分结果需要通过通信告知）；</li>
<li>无法加速split的过程，该过程复杂度为O(#data)O(#data)，当数据量大的时候效率不高；</li>
</ul>
<h4><span id="lightgbm"><strong>==LightGBM==</strong></span></h4><p><strong>LightGBM 则不进行数据垂直划分，每台机器都有训练集完整数据</strong>，在得到最佳划分方案后可在本地执行划分而减少了不必要的通信。</p>
<ul>
<li>每个workers找到局部最佳的切分点{feature, threshold}</li>
<li>workers使用点对点通信，找到全局最佳切分点</li>
<li>每个worker根据全局最佳切分点进行节点分裂</li>
</ul>
<p>缺点：</p>
<ul>
<li>split过程的复杂度仍是O(#data)，当数据量大的时候效率不高</li>
<li><strong>每个worker保存所有数据，存储代价高</strong></li>
</ul>
<h3><span id="122-数据并行"><strong>1.2.2 数据并行</strong></span></h3><h4><span id="传统方法">传统方法：</span></h4><p>数据并行目标是并行化整个决策学习的过程：</p>
<ul>
<li>水平切分数据，<strong>不同的worker拥有部分数据</strong></li>
<li>每个worker根据本地数据构建局部直方图</li>
<li>合并所有的局部直方图得到全部直方图</li>
<li>根据全局直方图找到最优切分点并进行分裂</li>
</ul>
<p><img src="https://www.hrwhisper.me/images/machine-learning-lightgbm/LightGBM-data-parallelization.png" alt="LightGBM-data-parallelization"></p>
<p>在第3步中，有两种合并的方式：</p>
<ul>
<li>采用点对点方式(point-to-point communication algorithm)进行通讯，每个worker通讯量为O(#machine∗#feature∗#bin)</li>
<li>采用collective communication algorithm(如“<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-collective.html">All Reduce</a>”)进行通讯（相当于有一个中心节点，通讯后在返回结果），每个worker的通讯量为O(2∗#feature∗#bin)</li>
</ul>
<h4><span id="lightgbm中的数据并行">LightGBM中的数据并行</span></h4><ol>
<li><strong>使用“Reduce Scatter”将不同worker的不同特征的直方图合并，然后workers在局部合并的直方图中找到局部最优划分，最后同步全局最优划分。</strong></li>
<li>前面提到过，可以通过直方图作差法得到兄弟节点的直方图，因此只需要通信一个节点的直方图。</li>
</ol>
<p>传统的数据并行策略主要为水平划分数据，然后本地构建直方图并整合成全局直方图，最后在全局直方图中找出最佳划分点。这种数据划分有一个很大的缺点：通讯开销过大。如果使用点对点通信，一台机器的通讯开销大约为 <img src="https://www.zhihu.com/equation?tex=O%28%5C%23machine+%2A+%5C%23feature+%2A%5C%23bin+%29" alt="[公式]"> ；如果使用集成的通信，则通讯开销为 <img src="https://www.zhihu.com/equation?tex=O%282+%2A+%5C%23feature+%2A%5C%23bin+%29" alt="[公式]"> ，</p>
<p><strong>LightGBM 采用分散规约（Reduce scatter）的方式将直方图整合的任务分摊到不同机器上，从而降低通信代价，并通过直方图做差进一步降低不同机器间的通信。</strong></p>
<h3><span id="123-投票并行"><strong>1.2.3 投票并行</strong></span></h3><p>LightGBM采用一种称为<strong>PV-Tree</strong>的算法进行投票并行(Voting Parallel)，其实这本质上也是一种<strong>数据并行</strong>。PV-Tree和普通的决策树差不多，只是在寻找最优切分点上有所不同。</p>
<p>其算法伪代码描述如下：</p>
<p><img src="https://www.hrwhisper.me/images/machine-learning-lightgbm/LightGBM-pv-tree.png" alt="LightGBM-pv-tree"></p>
<ol>
<li>水平切分数据，不同的worker拥有部分数据。</li>
<li>Local voting: <strong>每个worker构建直方图，找到top-k个最优的本地划分特征</strong></li>
<li>Global voting: <strong>中心节点聚合得到最优的top-2k个全局划分特征（top-2k是看对各个worker选择特征的个数进行计数，取最多的2k个）</strong></li>
<li><strong>Best Attribute Identification</strong>： <strong>中心节点向worker收集这top-2k个特征的直方图，并进行合并，然后计算得到全局的最优划分</strong></li>
<li>中心节点将全局最优划分广播给所有的worker，worker进行本地划分。</li>
</ol>
<p><img src="https://www.hrwhisper.me/images/machine-learning-lightgbm/LightGBM-voting-parallelization.png" alt="LightGBM-voting-parallelization"></p>
<p><strong>可以看出，PV-tree将原本需要#feature×#bin#feature×#bin 变为了2k×#bin2k×#bin，通信开销得到降低。此外，可以证明，当每个worker的数据足够多的时候，top-2k个中包含全局最佳切分点的概率非常高。</strong></p>
<h3><span id="124-缓存优化"><strong>1.2.4 缓存优化</strong></span></h3><p>上边说到 XGBoost 的预排序后的特征是通过索引给出的样本梯度的统计值，因其索引访问的结果并不连续，XGBoost 提出缓存访问优化算法进行改进。</p>
<p>而 LightGBM 所使用直方图算法对 Cache 天生友好：</p>
<ol>
<li>首先，<strong>所有的特征都采用相同的方法获得梯度</strong>（区别于不同特征通过不同的索引获得梯度），只需要对梯度进行排序并可实现连续访问，大大提高了缓存命中；</li>
<li>其次，因为<strong>不需要存储特征到样本的索引</strong>，降低了存储消耗，而且也不存在 Cache Miss的问题。</li>
</ol>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（19）【TODO】FP-growth</title>
    <url>/posts/2406X25/</url>
    <content><![CDATA[<h2><span id="fp-growth">FP-growth</span></h2><blockquote>
<ul>
<li>数据挖掘随笔（一）频繁模式挖掘与关联规则挖掘以及Apriori算法（python实现）：<a href="https://zhuanlan.zhihu.com/p/410019734">https://zhuanlan.zhihu.com/p/410019734</a></li>
<li>数据挖掘随笔（二）FP-growth算法——一种用于频繁模式挖掘的模式增长方式(Python实现)：<a href="https://zhuanlan.zhihu.com/p/411594391">https://zhuanlan.zhihu.com/p/411594391</a></li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>频繁项挖掘</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（11）XGB*</title>
    <url>/posts/3HRFFWP/</url>
    <content><![CDATA[<h2><span id="参考链接">参考链接</span></h2><ul>
<li><p><strong>XGBoost官方文档</strong>：<a href="https://xgboost.readthedocs.io/en/latest/index.html">https://xgboost.readthedocs.io/en/latest/index.html</a></p>
</li>
<li><p>LightGBM算法梳理：<a href="https://zhuanlan.zhihu.com/p/78293497">https://zhuanlan.zhihu.com/p/78293497</a></p>
</li>
<li><p>详解LightGBM两大利器：基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）：<a href="https://zhuanlan.zhihu.com/p/366234433">https://zhuanlan.zhihu.com/p/366234433</a></p>
</li>
<li><p>【机器学习】决策树（下）——XGBoost、LightGBM（非常详细）：<a href="https://zhuanlan.zhihu.com/p/87885678">https://zhuanlan.zhihu.com/p/87885678</a></p>
</li>
<li><p>xgboost面试题整理: <a href="https://xiaomindog.github.io/2021/06/22/xgb-qa/">https://xiaomindog.github.io/2021/06/22/xgb-qa/</a></p>
</li>
</ul>
<h2><span id="机器学习决策树下xgboost-lightgbm">【机器学习】决策树（下）——XGBoost、LightGBM</span></h2><p><img src="https://pic2.zhimg.com/80/v2-358e4bfce928d0460bd5e8b4cab8f715_1440w.jpg" alt="img"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Boosting 算法</th>
<th>GBDT</th>
<th>XGBoost</th>
<th>LightGBM</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>思想</strong><img src="image-20220315210756470.png" alt="image-20220315210756470" style="zoom:25%;"></td>
<td>回归树、梯度迭代、缩减（Shrinkage）;<strong>GBDT 的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于 0</strong></td>
<td><strong>二阶导数、线性分类器、正则化</strong>、缩减、<strong>列抽样、并行化</strong></td>
<td><strong>更快的训练速度和更低的内存使用</strong></td>
</tr>
<tr>
<td>目标函数</td>
<td><img src="image-20220315213233284.png" alt="image-20220315213233284" style="zoom: 25%;"></td>
<td><img src="image-20220315213503054.png" alt="image-20220315213503054" style="zoom: 67%;"><img src="image-20220315213608526.png" alt="image-20220315213608526" style="zoom: 33%;"></td>
<td>同上</td>
</tr>
<tr>
<td>损失函数</td>
<td>最小均方损失函数、<strong>绝对损失或者 Huber 损失函数</strong></td>
<td>【线性】最小均方损失函数、==sigmod和softmax==</td>
<td><strong>复杂度模型</strong>：<img src="image-20220315215849417.png" alt="image-20220315215849417" style="zoom: 25%;"></td>
</tr>
<tr>
<td>基模型</td>
<td>CART模型</td>
<td>CART模型/ ==回归模型==</td>
<td>CART模型/ ==回归模型==</td>
</tr>
<tr>
<td>抽样算法</td>
<td>无</td>
<td><strong>列抽样</strong>：借鉴了<strong>随机森林</strong>的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</td>
<td><strong>单边梯度抽样算法；</strong>根据样本梯度来对梯度小的这边样本进行采样，一部分大梯度和随机分布</td>
</tr>
<tr>
<td><strong>切分点算法</strong></td>
<td>CART模型</td>
<td><strong>预排序</strong>、<strong>贪心算法</strong>、<strong>近似算法（</strong>加权分位数缩略图<strong>）</strong></td>
<td><strong>直方图算法</strong>：内存消耗降低，计算代价减少；（不需要记录特征到样本的索引）</td>
</tr>
<tr>
<td><strong>缺失值算法</strong></td>
<td>CART模型</td>
<td><strong>稀疏感知算法</strong>：选择增益最大的枚举项即为最优<strong>缺省方向</strong>。【<strong><font color="red"> 稀疏数据优化不足</font></strong>】【<strong>gblinear 补0</strong>】</td>
<td><strong>互斥特征捆绑算法</strong>：<strong>互斥</strong>指的是一些特征很少同时出现非0值。<strong>稀疏感知算法</strong>；【<strong>gblinear 补0</strong>】</td>
</tr>
<tr>
<td><strong>建树策略</strong></td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Leaf-wise</strong>：每次分裂增益最大的叶子节点，直到达到停止条件。</td>
</tr>
<tr>
<td><strong>正则化</strong></td>
<td>无</td>
<td>L1 和 L2 正则化项</td>
<td>L1 和 L2 正则化项</td>
</tr>
<tr>
<td><strong>Shrinkage（缩减）</strong></td>
<td>有</td>
<td>有</td>
<td>有</td>
</tr>
<tr>
<td>类别特征优化</td>
<td>无</td>
<td>无</td>
<td><strong>类别特征最优分割</strong>：<strong>many-vs-many</strong></td>
</tr>
<tr>
<td>并行化设计</td>
<td>无</td>
<td><strong>块结构设计</strong>、</td>
<td><strong>特征并行</strong>、 <strong>数据并行</strong>、<strong>投票并行</strong></td>
</tr>
<tr>
<td>==缓存优化==</td>
<td>无</td>
<td>为每个线程分配一个连续的缓存区、<strong>“核外”块计算</strong></td>
<td>1、所有的特征都采用相同的方法获得梯度；2、其次，因为不需要存储特征到样本的索引，降低了存储消耗</td>
</tr>
<tr>
<td><strong>缺点</strong></td>
<td>对异常点敏感；</td>
<td><strong>预排序</strong>：仍需要遍历数据集；==不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引，相当于消耗了两倍的内存。==</td>
<td><strong>内存更小</strong>： 索引值、特征值边bin、互斥特征捆绑; <strong>速度更快</strong>：遍历直方图；单边梯度算法过滤掉梯度小的样本；基于 Leaf-wise 算法的增长策略构建树，减少了很多不必要的计算量；特征并行、数据并行方法加速计算</td>
</tr>
</tbody>
</table>
</div>
<h2><span id="一-xgboost-线性模型多分类增量训练xgb_直方图分布式部署">一、XGBoost [线性模型？多分类？增量训练？XGB_直方图，分布式部署]</span></h2><blockquote>
<p>  <strong>增量学习</strong>：XGBoost提供两种增量训练的方式，一种是在当前迭代树的基础上增加新树，原树不变；另一种是当前迭代树结构不变，重新计算叶节点权重，同时也可增加新树。</p>
<p>  <strong>线性模型</strong>：xgboost通过泰勒公式的二阶展开迭代的残差是1导/2导，线性回归迭代的是标签，xgboost需要串行多个线性回归，预测结果为多个象形线性回归的累积值……，除了用到了线性回归的原理方程式，他们两的损失函数，下降梯度都不一样，几乎没有什么共同点</p>
<p>  <strong>XGBoost 用泰勒展开优势在哪？</strong>：<a href="https://www.zhihu.com/question/61374305">https://www.zhihu.com/question/61374305</a></p>
<ul>
<li><strong>xgboost是以mse为基础推导出来的</strong>，在mse的情况下，xgboost的目标函数展开就是一阶项+二阶项的形式，而其他类似logloss这样的目标函数不能表示成这种形式。为了后续推导的统一，所以将<strong>目标函数进行二阶泰勒展开，就可以直接自定义损失函数了，只要二阶可导即可，增强了模型的扩展性</strong>。</li>
<li><p><strong>二阶信息能够让梯度收敛的更快，类似牛顿法比SGD收敛更快</strong>。一阶信息描述梯度变化方向，二阶信息可以描述梯度变化方向是如何变化的。</p>
<p><strong>==深入理解XGBoost==</strong>：<a href="https://bailingnan.github.io/post/shen-ru-li-jie-xgboost/">https://bailingnan.github.io/post/shen-ru-li-jie-xgboost/</a></p>
</li>
</ul>
</blockquote>
<p>XGBoost 是大规模并行 boosting tree 的工具，它是目前最快最好的开源 boosting tree 工具包，比常见的工具包快 10 倍以上。Xgboost 和 GBDT 两者都是 boosting 方法，除了工程实现、解决问题上的一些差异外，最大的不同就是<strong>目标函数</strong>的定义。故本文将从数学原理和工程实现上进行介绍，并在最后介绍下 Xgboost 的优点。</p>
<h3><span id="11-数学原理">1.1 数学原理</span></h3><p><strong>1.1.1 目标函数</strong></p>
<p>我们知道 XGBoost 是由$k$个基模型组成的一个加法运算式：</p>
<script type="math/tex; mode=display">
\hat{y}_{i}=\sum_{t=1}^{k} f_{t}\left(x_{i}\right)</script><p><strong>损失函数：</strong></p>
<script type="math/tex; mode=display">
L=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}\right)</script><p>我们知道模型的预测精度由模型的<strong>偏差</strong>和<strong>方差</strong>共同决定，损失函数代表了模型的偏差，想要方差小则需要简单的模型，所以目标函数由模型的<strong>损失函数$L$</strong>与抑<strong>制模型复杂度的正则项 <script type="math/tex">\Omega</script></strong>组成。支持<strong>决策树</strong>也支持<strong>线性模型</strong>。</p>
<script type="math/tex; mode=display">
O b j=\sum_{i=1}^{n} l\left(\hat{y}_{i}, y_{i}\right)+\sum_{t=1}^{k} \Omega\left(f_{t}\right)</script><p><strong>Boosting模型是向前加法：</strong></p>
<script type="math/tex; mode=display">
\hat{y}_{i}^{t}=\hat{y}_{i}^{t-1}+f_{t}\left(x_{i}\right)</script><p>目标函数就可以写成：</p>
<script type="math/tex; mode=display">
\begin{aligned}
O b j^{(t)} &=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{t}\right)+\sum_{i=1}^{t} \Omega\left(f_{i}\right) \\
&=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{t-1}+f_{t}\left(x_{i}\right)\right)+\sum_{i=1}^{t} \Omega\left(f_{i}\right)
\end{aligned}</script><p>求此时最优化目标函数，就相当于求解 <script type="math/tex">f_{t}\left(x_{i}\right)</script>。根据泰勒展开式：</p>
<script type="math/tex; mode=display">
f(x+\Delta x) \approx f(x)+f^{\prime}(x) \Delta x+\frac{1}{2} f^{\prime \prime}(x) \Delta x^{2}</script><p><strong>我们==把<script type="math/tex">\hat{y}_{i}^{t-1}</script>,视为x， <script type="math/tex">f_{t}\left(x_{i}\right)</script>视为<script type="math/tex">\Delta x</script>==，故可以将目标函数写成</strong>：</p>
<script type="math/tex; mode=display">
O b j^{(t)}=\sum_{i=1}^{n}\left[l\left(y_{i}, \hat{y}_{i}^{t-1}\right)+g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\sum_{i=1}^{t} \Omega\left(f_{i}\right)</script><p>由于<strong>第一项为常数，对优化没有影响，所以我们只需要求出每一步损失函数的一阶导和二阶导的值</strong>【==前t-1的结果和标签求==】，然后最优化目标函数，就可以得到每一步的f(x),最后根据加法模型得到一个整体模型。</p>
<script type="math/tex; mode=display">
O b j^{(t)} \approx \sum_{i=1}^{n}\left[g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\sum_{i=1}^{t} \Omega\left(f_{i}\right)</script><blockquote>
<p>  以<strong>平方损失函数</strong>【绝对值、hubor损失】为例（GBDT 残差）：</p>
<p>  <img src="image-20220404141858337.png" alt="image-20220404141858337" style="zoom:50%;"></p>
<p>  其中 <img src="https://www.zhihu.com/equation?tex=g_%7Bi%7D" alt="[公式]"> 为损失函数的一阶导， <img src="https://www.zhihu.com/equation?tex=h_%7Bi%7D" alt="[公式]"> 为损失函数的二阶导，<strong>注意这里的导是对 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_i%5E%7Bt-1%7D" alt="[公式]"> 求导</strong>。</p>
<script type="math/tex; mode=display">
  \begin{aligned}
  &g_{i}=\frac{\partial\left(\hat{y}^{t-1}-y_{i}\right)^{2}}{\partial \hat{y}^{t-1}}=2\left(\hat{y}^{t-1}-y_{i}\right) \\
  &h_{i}=\frac{\partial^{2}\left(\hat{y}^{t-1}-y_{i}\right)^{2}}{\hat{y}^{t-1}}=2
  \end{aligned}</script></blockquote>
<h4><span id="112-基于决策树的目标函数"><strong>1.1.2 基于决策树的目标函数</strong></span></h4><p>我们知道 Xgboost 的基模型<strong>不仅支持决策树，还支持线性模型</strong>，这里我们主要介绍基于决策树的目标函数。</p>
<p>我们可以将决<strong>策树定义为<script type="math/tex">f_{t}(x)=w_{q(x)}</script></strong>，x为某一样本，这里的 <img src="https://www.zhihu.com/equation?tex=q%28x%29" alt="[公式]"> 代表了该样本在哪个叶子结点上，而 <img src="https://www.zhihu.com/equation?tex=w_q" alt="[公式]"> 则代表了叶子结点取值 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> ，所以 <img src="https://www.zhihu.com/equation?tex=w_%7Bq%28x%29%7D" alt="[公式]"> 就代表了每个样本的取值 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> （即预测值)。</p>
<p><strong>决策树的复杂度</strong>可由<strong>叶子数 <img src="https://www.zhihu.com/equation?tex=T" alt="[公式]"></strong> 组成，叶子节点越少模型越简单，此外<strong>叶子节点也不应该含有过高的权重</strong> <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> （类比 LR 的每个变量的权重)，所以目标函数的正则项可以定义为：</p>
<script type="math/tex; mode=display">
\Omega\left(f_{t}\right)=\gamma T+\frac{1}{2} \lambda \sum_{j=1}^{T} w_{j}^{2}</script><p>即<strong>决策树模型的复杂度</strong>由生成的所有<strong>决策树的叶子节点数量</strong>，和所有<strong>节点权重所组成的向量的 <img src="https://www.zhihu.com/equation?tex=L_2" alt="[公式]"> 范式</strong>共同决定。</p>
<p><img src="https://pic1.zhimg.com/80/v2-e0ab9287990a6098e4cdbc5a8cff4150_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>我们设 <img src="https://www.zhihu.com/equation?tex=I_j%3D+%5C%7B+i+%5Cvert+q%28x_i%29%3Dj+%5C%7D" alt="[公式]"> 为第 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]"> 个叶子节点的样本集合，故我们的目标函数可以写成：</p>
<script type="math/tex; mode=display">
\begin{aligned}
O b j^{(t)} & \approx \sum_{i=1}^{n}\left[g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right) \\
&=\sum_{i=1}^{n}\left[g_{i} w_{q\left(x_{i}\right)}+\frac{1}{2} h_{i} w_{q\left(x_{i}\right)}^{2}\right]+\gamma T+\frac{1}{2} \lambda \sum_{j=1}^{T} w_{j}^{2} \\
&=\sum_{j=1}^{T}\left[\left(\sum_{i \in I_{j}} g_{i}\right) w_{j}+\frac{1}{2}\left(\sum_{i \in I_{j}} h_{i}+\lambda\right) w_{j}^{2}\right]+\gamma T
\end{aligned}</script><p>第二步是遍历所有的样本后求每个样本的损失函数，但样本最终会落在叶子节点上，所以我们也可以遍历叶子节点，然后获取叶子节点上的样本集合，最后在求损失函数。即我们之前样本的集合，现在都改写成叶子结点的集合，由于一个叶子结点有多个样本存在，因此才有了 <img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi+%5Cin+I_j%7Dg_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi+%5Cin+I_j%7Dh_i" alt="[公式]"> 这两项， <img src="https://www.zhihu.com/equation?tex=w_j" alt="[公式]"> 为第 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]"> 个叶子节点取值。</p>
<p><img src="image-20220314162051124.png" alt="image-20220314162051124" style="zoom: 25%;"></p>
<p><strong><font color="red"> 这里我们要注意 <img src="https://www.zhihu.com/equation?tex=G_j" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=H_j" alt="[公式]"> 是前 <img src="https://www.zhihu.com/equation?tex=t-1" alt="[公式]"> 步得到的结果，其值已知可视为常数，只有最后一棵树的叶子节点 <img src="https://www.zhihu.com/equation?tex=w_j" alt="[公式]"> 不确定，那么将目标函数对 <img src="https://www.zhihu.com/equation?tex=w_j" alt="[公式]"> 求一阶导，并令其等于 <img src="https://www.zhihu.com/equation?tex=0" alt="[公式]"> ，则可以求得叶子结点 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]"> 对应的权值：</font></strong></p>
<p><img src="https://www.zhihu.com/equation?tex=w_j%5E%2A%3D-%5Cfrac%7BG_j%7D%7BH_j%2B%5Clambda%7D++%5C%5C" alt="[公式]"></p>
<p>所以<strong>目标函数可以化简为：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=Obj+%3D+-%5Cfrac12+%5Csum_%7Bj%3D1%7D%5ET+%5Cfrac%7BG_j%5E2%7D%7BH_j%2B%5Clambda%7D+%2B+%5Cgamma+T+%5C%5C" alt="[公式]"></p>
<p><img src="https://pic2.zhimg.com/80/v2-f6db7af6c1e683192cb0ccf48eafaf99_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>上图给出目标函数计算的例子，求每个节点每个样本的一阶导数 <img src="https://www.zhihu.com/equation?tex=g_i" alt="[公式]"> 和二阶导数 <img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]"> ，然后针对每个节点对所含样本求和得到的 <img src="https://www.zhihu.com/equation?tex=G_j" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=H_j" alt="[公式]"> ，最后遍历决策树的节点即可得到<strong>目标函数</strong>。</p>
<h4><span id="113-最优切分点划分算法"><strong>1.1.3 最优切分点划分算法</strong></span></h4><p><strong><font color="red"> 在决策树的生长过程中，一个非常关键的问题是如何找到叶子的节点的最优切分点，</font></strong>Xgboost 支持两种分裂节点的方法——<strong>贪心算法</strong>和<strong>近似算法</strong>。</p>
<p><strong>1）贪心算法</strong></p>
<ol>
<li><strong>从深度为 <img src="https://www.zhihu.com/equation?tex=0" alt="[公式]"> 的树开始，对每个叶节点枚举所有的可用特征</strong>；</li>
<li>针对每个特征，把属于该节点的训练样本根据该特征值进行<strong>升序排列</strong>，通过线性扫描的方式来决定该特征的最佳分裂点，并记录该特征的分裂收益；</li>
<li>选择收益最大的特征作为分裂特征，用该特征的最佳分裂点作为分裂位置，在该节点上分裂出左右两个新的叶节点，并为每个新节点<strong>关联对应的样本集</strong>？？</li>
<li>回到第 1 步，递归执行到满足特定条件为止。（树的深度、gamma）</li>
</ol>
<h5><span id="那么如何计算每个特征的分裂收益呢">那么如何计算每个特征的分裂收益呢？</span></h5><p>假设我们在某一节点完成特征分裂，则分列前的目标函数可以写为：</p>
<p><img src="https://www.zhihu.com/equation?tex=Obj_%7B1%7D+%3D-%5Cfrac12+%5B%5Cfrac%7B%28G_L%2BG_R%29%5E2%7D%7BH_L%2BH_R%2B%5Clambda%7D%5D+%2B+%5Cgamma++%5C%5C" alt="[公式]"></p>
<p>分裂后的目标函数为：</p>
<p><img src="https://www.zhihu.com/equation?tex=Obj_2+%3D++-%5Cfrac12+%5B+%5Cfrac%7BG_L%5E2%7D%7BH_L%2B%5Clambda%7D+%2B+%5Cfrac%7BG_R%5E2%7D%7BH_R%2B%5Clambda%7D%5D+%2B2%5Cgamma+%5C%5C" alt="[公式]"></p>
<p>则对于目标函数来说，分裂后的收益为：<strong>MAX</strong>【<strong>obj1 - obj2 （分裂后越小越好）</strong>】</p>
<p><img src="https://www.zhihu.com/equation?tex=Gain%3D%5Cfrac12+%5Cleft%5B+%5Cfrac%7BG_L%5E2%7D%7BH_L%2B%5Clambda%7D+%2B+%5Cfrac%7BG_R%5E2%7D%7BH_R%2B%5Clambda%7D+-+%5Cfrac%7B%28G_L%2BG_R%29%5E2%7D%7BH_L%2BH_R%2B%5Clambda%7D%5Cright%5D+-+%5Cgamma+%5C%5C" alt="[公式]"></p>
<p>注意<strong>该特征收益也可作为特征重要性输出的重要依据</strong>。</p>
<p>我们可以发现对于所有的分裂点 <img src="https://www.zhihu.com/equation?tex=a" alt="[公式]"> ，我们只要做一遍从左到右的扫描就可以枚举出所有分割的梯度和 <img src="https://www.zhihu.com/equation?tex=G_L" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=G_R" alt="[公式]"> 。然后用上面的公式计算每个分割方案的分数就可以了。<font color="red">观察分裂后的收益，我们会发现节点划分不一定会使得结果变好，因为我们有一个引入<strong>新叶子的惩罚项（gamma)</strong>，也就是说引入的分割带来的<strong>增益如果小于一个阀值</strong>的时候，我们可以剪掉这个分割。 </font></p>
<p><strong>2）近似算法</strong>【<strong>加权分位划分点</strong>】</p>
<p><strong>贪婪算法可以的到最优解，但当数据量太大时则无法读入内存进行计算</strong>，近似算法主要针对贪婪算法这一缺点给出了近似最优解。</p>
<p>对于每个特征，只考察分位点可以减少计算复杂度。该算法会首先根据<strong>特征分布的分位数提出候选划分点，然后将连续型特征映射到由这些候选点划分的桶中</strong>，然后聚合统计信息找到所有区间的最佳分裂点。在提出候选切分点时有两种策略：</p>
<ul>
<li><strong>Global</strong>：<strong>学习每棵树前就提出候选切分点，并在每次分裂时都采用这种分割</strong>；</li>
<li><strong>Local</strong>：每次分裂前将重新提出候选切分点。</li>
</ul>
<p><strong>下图给出近似算法的具体例子，以三分位为例：</strong></p>
<p><img src="https://pic2.zhimg.com/80/v2-5d1dd1673419599094bf44dd4b533ba9_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>根据样本特征进行排序，然后基于分位数进行划分，并统计三个桶内的 <img src="https://www.zhihu.com/equation?tex=G%2CH" alt="[公式]"> 值，最终求解节点划分的增益。</p>
<h4><span id="114-加权分位数缩略图xgboost-直方图算法"><strong>1.1.4 加权分位数缩略图</strong>[XGBoost 直方图算法]</span></h4><ul>
<li><strong>第一个 for 循环：</strong>对特征 k <strong>根据该特征分布的分位数找到切割点的候选集合【==直方图==】</strong> <img src="https://www.zhihu.com/equation?tex=S_k%3D%5C%7Bs_%7Bk1%7D%2Cs_%7Bk2%7D%2C...%2Cs_%7Bkl%7D+%5C%7D" alt="[公式]"> 。XGBoost 支持 Global 策略和 Local 策略。</li>
<li><strong>第二个 for 循环：</strong>针对每个特征的候选集合，将样本映射到由该特征对应的候选点集构成的分桶区间中，即 <img src="https://www.zhihu.com/equation?tex=%7Bs_%7Bk%2Cv%7D%E2%89%A5x_%7Bjk%7D%3Es_%7Bk%2Cv%E2%88%921%7D%7D" alt="[公式]"> ，对每个桶统计 <img src="https://www.zhihu.com/equation?tex=G%2CH+" alt="[公式]"> 值，最后在这些统计量上寻找最佳分裂点。</li>
</ul>
<p><img src="https://pic1.zhimg.com/80/v2-161382c979557b8bae1563a459cd1ed4_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>事实上， <strong>XGBoost 不是简单地按照样本个数进行分位，而是以二阶导数值 <img src="https://www.zhihu.com/equation?tex=h_i+" alt="[公式]"> 作为样本的权重进行划分</strong>，如下：</p>
<p><img src="https://pic4.zhimg.com/80/v2-5f16246289eaa2a3ae72f971db198457_1440w.jpg" alt="img"></p>
<h5><span id="那么问题来了为什么要用-进行样本加权">==那么问题来了：为什么要用 <img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]"> 进行样本加权？==</span></h5><p>我们知道模型的目标函数为：</p>
<p><img src="https://www.zhihu.com/equation?tex=+Obj%5E%7B%28t%29%7D+%5Capprox+%5Csum_%7Bi%3D1%7D%5En+%5Cleft%5B+g_if_t%28x_i%29+%2B+%5Cfrac12h_if_t%5E2%28x_i%29+%5Cright%5D+%2B+%5Csum_%7Bi%3D1%7D%5Et++%5COmega%28f_i%29+%5C%5C" alt="[公式]"></p>
<p>我们稍作整理，便可以看出 <img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]"> 有对 loss 加权的作用。</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D++Obj%5E%7B%28t%29%7D+%26+%5Capprox+%5Csum_%7Bi%3D1%7D%5En+%5Cleft%5B+g_if_t%28x_i%29+%2B+%5Cfrac12h_if_t%5E2%28x_i%29+%5Cright%5D+%2B+%5Csum_%7Bi%3D1%7D%5Et++%5COmega%28f_i%29+%5C%5C+%5C%5C++++%26%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5B+g_i+f_t%28x_i%29+%2B+%5Cfrac%7B1%7D%7B2%7Dh_i+f_t%5E2%28x_i%29+%5Ccolor%7Bred%7D%7B%2B+%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7Bg_i%5E2%7D%7Bh_i%7D%7D%5D%2B%5COmega%28f_t%29+%5Ccolor%7Bred%7D%7B%2B+C%7D+%5C%5C++++%26%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Ccolor%7Bred%7D%7B%5Cfrac%7B1%7D%7B2%7Dh_i%7D+%5Cleft%5B+f_t%28x_i%29+-+%5Cleft%28+-%5Cfrac%7Bg_i%7D%7Bh_i%7D+%5Cright%29+%5Cright%5D%5E2+%2B+%5COmega%28f_t%29+%2B+C+%5Cend%7Balign%7D+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7Bg_i%5E2%7D%7Bh_i%7D" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=C" alt="[公式]"> 皆为常数。我们可以看到 <img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]"> 就是平方损失函数中样本的权重。</p>
<p>对于样本权值相同的数据集来说，找到候选分位点已经有了解决方案（GK 算法），但是当样本权值不一样时，该如何找到候选分位点呢？（作者给出了一个 Weighted Quantile Sketch 算法，这里将不做介绍。）</p>
<h4><span id="xgboost的近似直方图算法也类似于lightgbm这里的直方图算法-为什么慢"><strong><font color="red"> xgboost的近似直方图算法也类似于lightgbm这里的直方图算法? 为什么慢？</font></strong></span></h4><ul>
<li><strong>xgboost在每一层都动态构建直方图</strong>， 因为<strong>xgboost的直方图算法不是针对某个特定的feature</strong>，而是所有feature共享一个直方图(每个样本的权重是二阶导),所以每一层都要重新构建直方图，而<strong>lightgbm中对每个特征都有一个直方图</strong>，所以构建一次直方图就够了。</li>
<li><strong>lightgbm有一些工程上的cache优化</strong></li>
</ul>
<h4><span id="115-稀疏感知算法缺失值的处理"><strong>1.1.5 稀疏感知算法</strong>【<strong>缺失值的处理</strong>】</span></h4><blockquote>
<ul>
<li><strong>特征值缺失的样本无需遍历只需直接分配到左右节点</strong></li>
<li><strong>如果训练中没有数据缺失，预测时出现了数据缺失，则默认被分类到右节点.</strong>？<ul>
<li>看c++源码是默认向左方向</li>
</ul>
</li>
</ul>
</blockquote>
<p>在决策树的第一篇文章中我们介绍 CART 树在应对数据缺失时的分裂策略【<strong>缺失代理</strong>】，XGBoost 也给出了其解决方案。XGBoost 在构建树的节点过程中只考虑非缺失值的数据遍历，而为每个节点增加了一个缺省方向，当样本相应的特征值缺失时，可以被归类到缺省方向上，最优的缺省方向可以从数据中学到。</p>
<p><strong>XGBoost提出的是在计算分割后的分数时，遇到缺失值，分别将缺失值带入左右两个分割节点，然后取最大值的方向为其默认方向。</strong>至于如何学到缺省值的分支，其实很简单，<strong>分别枚举特征缺省的样本归为左右分支后的增益，选择增益最大的枚举项即为最优缺省方向。</strong></p>
<p>在构建树的过程中需要枚举特征缺失的样本，乍一看该算法的计算量增加了一倍，但其实该算法在构建树的过程中只考虑了特征未缺失的样本遍历，而<strong>特征值缺失的样本无需遍历只需直接分配到左右节点</strong>，故算法所需遍历的样本量减少，下图可以看到稀疏感知算法比 basic 算法速度块了超过 50 倍。</p>
<p><img src="https://pic1.zhimg.com/80/v2-e065bea4b424ea2d13b25ed2e7004aa8_1440w.jpg" alt="img" style="zoom:67%;"></p>
<h4><span id="116-缩减与列采样"><strong>1.1.6 缩减与列采样</strong></span></h4><p>除了在目标函数中引入正则项，为了防止过拟合，XGBoost还引入了缩减(shrinkage)和列抽样（column subsampling），通过在每一步的boosting中引入缩减系数，降低每个树和叶子对结果的影响；列采样是借鉴随机森林中的思想，根据反馈，列采样有时甚至比行抽样效果更好，同时，通过列采样能加速计算。</p>
<h3><span id="12-工程实现">1.2 工程实现</span></h3><h4><span id="121-块结构设计"><strong>1.2.1 块结构设计</strong></span></h4><p>我们知道，决策树的学习<strong>最耗时的一个步骤就是在每次寻找最佳分裂点是都需要对特征的值进行排序</strong>。而 <strong><font color="red"> XGBoost 在训练之前对根据特征对数据进行了排序，然后保存到块结构中，并在每个块结构中都采用了稀疏矩阵存储格式（Compressed Sparse Columns Format，CSC）进行存储，后面的训练过程中会重复地使用块结构，可以大大减小计算量。</font></strong></p>
<blockquote>
<p>  预排序 + 块设计【独立】 + 稀疏矩阵存储 </p>
</blockquote>
<ul>
<li><strong>每一个块结构包括一个或多个已经排序好的特征</strong>；</li>
<li><strong>缺失特征值将不进行排序</strong>；</li>
<li>每个特征会存储指向<strong>样本梯度统计值</strong>的索引，方便计算一阶导和二阶导数值；</li>
</ul>
<p>这种块结构存储的特征之间相互独立，方便计算机进行并行计算。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个<strong>特征的增益计算可以同时进行</strong>，这也是 Xgboost 能够实现分布式或者多线程计算的原因。</p>
<h4><span id="122-缓存访问优化算法索引访问梯度统计-gt-缓存空间不连续"><strong>1.2.2 缓存访问优化算法</strong>【索引访问梯度统计 -&gt; 缓存空间不连续】</span></h4><p>块结构的设计可以减少节点分裂时的计算量，但<strong>特征值通过索引访问样本梯度统计值的设计会导致访问操作的内存空间不连续</strong>，这样会造成缓存命中率低，从而影响到算法的效率。</p>
<p>为了解决缓存命中率低的问题，XGBoost 提出了缓存访问优化算法：为每个线程分配一个连续的缓存区，将需要的梯度信息存放在缓冲区中，这样就是实现了非连续空间到连续空间的转换，提高了算法效率。此外适当调整块大小，也可以有助于缓存优化。</p>
<p>于exact greedy算法中, 使用<strong>缓存预取（cache-aware prefetching）</strong>。具体来说，<strong>对每个线程分配一个连续的buffer</strong>，读取梯度信息并存入Buffer中（这样就实现了非连续到连续的转化）</p>
<h4><span id="123-核外块计算"><strong>1.2.3 “核外”块计算</strong></span></h4><p>当数据量过大时无法将数据全部加载到内存中，只能先将无法加载到内存中的数据暂存到硬盘中，直到需要时再进行加载计算，而这种操作必然涉及到因内存与硬盘速度不同而造成的资源浪费和性能瓶颈。为了解决这个问题，<strong>XGBoost 独立一个线程专门用于从硬盘读入数据，以实现处理数据和读入数据同时进行</strong>。</p>
<p>此外，XGBoost 还用了两种方法来降低硬盘读写的开销：</p>
<ul>
<li><strong>块压缩：</strong>对 Block 进行按列压缩，并在读取时进行解压；</li>
<li><strong>块拆分：</strong>将每个块存储到不同的磁盘中，从多个磁盘读取可以增加吞吐量。</li>
</ul>
<h4><span id="124-xgboost损失函数">==1.2.4 <strong>XGBoost损失函数</strong>==</span></h4><blockquote>
<p>  <a href="https://blog.csdn.net/qq_32103261/article/details/106664227">不平衡处理：xgboost 中scale_pos_weight、给样本设置权重weight、 自定义损失函数 和 简单复制正样本的区别</a></p>
</blockquote>
<p><strong>损失函数</strong>：损失函数描述了预测值和真实标签的差异，通过对损失函数的优化来获得对学习任务的一个近似求解方法。boosting类算法的损失函数的作用： Boosting的框架, 无论是GBDT还是Adaboost, 其在每一轮迭代中, <strong>根本没有理会损失函数具体是什么, 仅仅用到了损失函数的一阶导数通过随机梯度下降来参数更新</strong>。XGBoost是用了牛顿法进行的梯度更新。通过对损失进行分解得到一阶导数和二阶导数并通过牛顿法来迭代更新梯度。</p>
<h5><span id="1自定义损失函数">（1）==<strong>自定义损失函数</strong>==</span></h5><p><strong>XGBOOST是一个非常灵活的模型</strong>，允许使用者根据实际使用场景调整<a href="https://so.csdn.net/so/search?q=损失函数&amp;spm=1001.2101.3001.7020">损失函数</a>，对于常见的二分类问题一般使用的binary：logistic损失函数，其形式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=J%28%5Ctheta%29%3D-%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cleft%28y%5E%7B%28i%29%7D+%5Clog+h_%7B%5Ctheta%7D%5Cleft%28x%5E%7B%28i%29%7D%5Cright%29%2B%5Cleft%281-y%5E%7B%28i%29%7D%5Cright%29+%5Clog+%5Cleft%281-h_%7B%5Ctheta%7D%5Cleft%28x%5E%7B%28i%29%7D%5Cright%29%5Cright%29%5Cright%29+%EF%BC%883%EF%BC%89%5C%5C" alt="[公式]"></p>
<p>这个损失函数对于正类错分和负类错分给予的惩罚时相同的，但是<strong>对于不平衡数据集，或者某些特殊情况（两类错分代价不一样）的时候这样的损失函数就不再合理了。</strong></p>
<p>基于XGBoost的损失函数的分解求导，可以知道XGBoost的除正则项以外的核心影响因子是损失函数的1阶导和2阶导，所以对于任意的学习任务的损失函数，可以对其求一阶导数和二阶导数带入到XGBoost的自定义损失函数范式里面进行处理。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">custom_obj</span>(<span class="params">pred, dtrain</span>):<span class="comment"># pred 和 dtrain 的顺序不能弄反</span></span><br><span class="line">    <span class="comment"># STEP1 获得label</span></span><br><span class="line">    label = dtrain.get_label()</span><br><span class="line">    <span class="comment"># STEP2 如果是二分类任务，需要让预测值通过sigmoid函数获得0～1之间的预测值</span></span><br><span class="line">    <span class="comment"># 如果是回归任务则下述任务不需要通过sigmoid</span></span><br><span class="line">    <span class="comment"># 分类任务sigmoid化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line">    sigmoid_pred = sigmoid(原始预测值)</span><br><span class="line">    <span class="comment">#回归任务</span></span><br><span class="line">    pred = 原始预测值</span><br><span class="line">    <span class="comment"># STEP3 一阶导和二阶导</span></span><br><span class="line">    grad = 一阶导</span><br><span class="line">    hess = 二阶导</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> grad, hess</span><br></pre></td></tr></table></figure></p>
<p>非平衡分类学习任务，例如首笔首期30+的风险建模任务，首期30+的逾期率比例相对ever30+的逾期率为1/3左右，<strong>通过修正占比少的正样本权重来对影响正样本对损失函数的贡献度，可以进一步提升模型的效果</strong>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">weighted_binary_cross_entropy</span>(<span class="params">pred, dtrain,imbalance_alpha=<span class="number">10</span></span>):</span><br><span class="line">    <span class="comment"># retrieve data from dtrain matrix</span></span><br><span class="line">    label = dtrain.get_label()</span><br><span class="line">    <span class="comment"># compute the prediction with sigmoid</span></span><br><span class="line">    sigmoid_pred = <span class="number">1.0</span> / (<span class="number">1.0</span> + np.exp(-pred))</span><br><span class="line">    <span class="comment"># gradient</span></span><br><span class="line">    grad = -(imbalance_alpha ** label) * (label - sigmoid_pred)</span><br><span class="line">    hess = (imbalance_alpha ** label) * sigmoid_pred * (<span class="number">1.0</span> - sigmoid_pred)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> grad, hess </span><br></pre></td></tr></table></figure>
<h5><span id="2focal-loss">（2）Focal Loss</span></h5><p><strong>Focal Loss for Dense Object Detection 是ICCV2017的Best student paper,文章思路很简单但非常具有开拓性意义，效果也非常令人称赞。</strong></p>
<ul>
<li>大家还可以看知乎的讨论：<a href="https://www.zhihu.com/question/63581984">如何评价 Kaiming 的 Focal Loss for Dense Object Detection？</a></li>
<li>[机器学习] XGBoost 自定义损失函数-FocalLoss：<a href="https://blog.csdn.net/zwqjoy/article/details/109311133">https://blog.csdn.net/zwqjoy/article/details/109311133</a></li>
</ul>
<p>Focal Loss的引入主要是为了解决难易样本数量不平衡（注意，有区别于正负样本数量不平衡）的问题，实际可以使用的范围非常广泛，为了方便解释，拿目标检测的应用场景来说明</p>
<p><strong>==Focal Loss的主要思想就是改变损失函数.Focal loss是在交叉熵损失函数基础上进行的修改==</strong></p>
<p>单阶段的目标检测器通常会产生高达100k的候选目标，只有极少数是正样本，正负样本数量非常不平衡。我们在计算分类的时候常用的损失——交叉熵。<img src="https://private.codecogs.com/gif.latex?y%7B%7D%27" alt="y{}&#39;">是经过激活函数的输出，所以在0-1之间。可见普通的交叉熵对于正样本而言，输出概率越大损失越小。对于负样本而言，输出概率越小则损失越小。此时的损失函数在大量简单样本的迭代过程中比较缓慢且可能无法优化至最优。</p>
<p>为了解决<strong>正负样本不平衡</strong>的问题，我们通常会在交叉熵损失的前面加上一个参数<strong>平衡因子alpha</strong>，用来平衡正负样本本身的比例不均. 文中alpha取0.25，即正样本要比负样本占比小，这是因为负例易分。</p>
<h3><span id="13-优缺点">1.3 优缺点</span></h3><h4><span id="131-优点"><strong>1.3.1 优点</strong></span></h4><ol>
<li><strong>精度更高：</strong>GBDT 只用到一阶<strong>泰勒展开</strong>，而 XGBoost 对损失函数进行了二阶泰勒展开。<strong>XGBoost 引入二阶导一方面是为了增加精度，另一方面也是为了能够自定义损失函数，二阶泰勒展开可以近似大量损失函数</strong>；</li>
<li><strong>灵活性更强：</strong>GBDT 以 CART 作为<strong>基分类器</strong>，XGBoost 不仅支持 CART 还支持线性分类器，（使用线性分类器的 <strong>XGBoost 相当于带 L1 和 L2 正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）</strong>）。此外，XGBoost 工具支持自定义损失函数，只需函数支持一阶和二阶求导；</li>
<li><strong>正则化：</strong>XGBoost 在目标函数中加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、叶子节点权重的 L2 范式。正则项降低了模型的方差，使学习出来的模型更加简单，有助于防止过拟合；</li>
<li><strong>Shrinkage（缩减）：</strong>相当于学习速率。XGBoost 在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间；</li>
<li><strong>列抽样：</strong>XGBoost 借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</li>
<li><strong>缺失值处理：</strong>XGBoost 采用的稀疏感知算法极大的加快了节点分裂的速度；</li>
<li><strong>可以并行化操作：</strong>块结构可以很好的支持并行计算。</li>
</ol>
<h4><span id="132-缺点"><strong>1.3.2 缺点</strong></span></h4><ol>
<li>虽然利用<strong>预排序</strong>和<strong>近似算法</strong>可以降低寻找最佳分裂点的计算量，但在节点分裂过程中仍需要<strong>==遍历数据集==</strong>；</li>
<li>预排序过程的空间复杂度过高，不仅需要存储特征值，还需要<strong>==存储特征对应样本的梯度统计值的索引==</strong>，相当于消耗了两倍的内存。</li>
</ol>
<h2><span id="二-xgboost常用参数">二、XGBoost常用参数</span></h2><h4><span id="xgboost的参数一共分为三类">XGBoost的参数一共分为三类：</span></h4><p><a href="https://xgboost.apachecn.org/#/">完整参数请戳官方文档</a></p>
<p>1、<strong>通用参数</strong>：宏观函数控制。</p>
<p>2、<strong>Booster参数</strong>：控制每一步的booster(tree/regression)。booster参数一般可以调控模型的效果和计算代价。我们所说的调参，很这是大程度上都是在调整booster参数。</p>
<p>3、<strong>学习目标参数</strong>：控制训练目标的表现。我们对于问题的划分主要体现在学习目标参数上。比如我们要做分类还是回归，做二分类还是多分类，这都是目标参数所提供的。</p>
<h4><span id="通用参数">通用参数</span></h4><ol>
<li><strong>booster</strong>：我们有两种参数选择，<code>gbtree</code>、<code>dart</code>和<code>gblinear</code>。gbtree、dart是采用树的结构来运行数据，而gblinear是基于线性模型。</li>
<li><strong>silent</strong>：静默模式，为<code>1</code>时模型运行不输出。</li>
<li><strong>nthread</strong>: 使用线程数，一般我们设置成<code>-1</code>,使用所有线程。如果有需要，我们设置成多少就是用多少线程。</li>
</ol>
<h4><span id="booster参数">Booster参数</span></h4><ol>
<li><p><strong>==n_estimator==</strong>: 也作<code>num_boosting_rounds</code>这是生成的<strong>最大树的数目</strong>，也是最大的迭代次数。</p>
</li>
<li><p><strong>==learning_rate==</strong>: 有时也叫作<code>eta</code>，系统默认值为<code>0.3</code>,。<strong>每一步迭代的步长</strong>，很重要。太大了运行准确率不高，太小了运行速度慢。我们一般使用比默认值小一点，<code>0.1</code>左右就很好。</p>
</li>
<li><p><strong>==gamma==</strong>：系统默认为<code>0</code>,我们也常用<code>0</code>。在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。<code>gamma</code>指定了节点分裂所需的<strong>最小损失函数下降值</strong>。 这个参数的值越大，算法越保守。因为<code>gamma</code>值越大的时候，损失函数下降更多才可以分裂节点。所以树生成的时候更不容易分裂节点。范围: <code>[0,∞]</code></p>
</li>
<li><p><strong>==subsample==</strong>：系统默认为<code>1</code>。这个参数控制对于每棵树，<strong>随机采样的比例</strong>。减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。 典型值：<code>0.5-1</code>，<code>0.5</code>代表平均采样，防止过拟合. 范围: <code>(0,1]</code>，<strong>注意不可取0</strong></p>
</li>
<li><p><strong>colsample_bytree</strong>：系统默认值为1。我们一般设置成0.8左右。用来控制每棵<strong>随机采样的列数的占比</strong>(每一列是一个特征)。 典型值：<code>0.5-1</code>范围: <code>(0,1]</code></p>
</li>
<li><p><strong>colsample_bylevel</strong>：默认为1,我们也设置为1.这个就相比于前一个更加细致了，它指的是每棵树每次节点分裂的时候列采样的比例</p>
</li>
<li><p><strong>max_depth</strong>： 系统默认值为<code>6</code>，我们常用<code>3-10</code>之间的数字。这个值为<strong>树的最大深度</strong>。这个值是用来控制过拟合的。<code>max_depth</code>越大，模型学习的更加具体。设置为<code>0</code>代表没有限制，范围: <code>[0,∞]</code></p>
</li>
<li><p><strong>==max_delta_step==</strong>：默认<code>0</code>,我们常用<code>0</code>.这个参数限制了<strong>每棵树权重改变的最大步长</strong>，如果这个参数的值为<code>0</code>,则意味着没有约束。如果他被赋予了某一个正值，则是这个算法更加保守。通常，这个参数我们不需要设置，但是<strong>==当个类别的样本极不平衡的时候，这个参数对逻辑回归优化器是很有帮助的。==</strong></p>
</li>
<li><p><strong>==lambda==</strong>:也称<code>reg_lambda</code>,默认值为<code>0</code>。<strong>权重的L2正则化项</strong>。(和Ridge regression类似)。这个参数是用来控制XGBoost的正则化部分的。这个参数在减少过拟合上很有帮助。</p>
</li>
<li><p><strong>alpha</strong>:也称<code>reg_alpha</code>默认为<code>0</code>,权重的L1正则化项。(和Lasso regression类似)。 可以应用在很高维度的情况下，使得算法的速度更快。</p>
</li>
<li><p><strong>==scale_pos_weight==</strong>：默认为<code>1</code>在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛。通常可以将其设置为<strong>负样本的数目与正样本数目的比值</strong>。<strong>xgboost中==scale_pos_weight、对样本进行weight设置和简单复制正样本==得到的结果是一样的，本质上都是改变了训练的损失函数。通过自定义设置损失函数可得到验证。实际上基本思想都是通过过采样的方法处理不平衡数据。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (label == <span class="number">1.0</span>f) &#123;</span><br><span class="line">    w *= scale_pos_weight;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 见源码 src/objective/regression_obj.cu</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>  在DMatrix里边设置每个样本的weight 是 怎样改变训练过程的呢，其实是改变训练的损失函数，源代码里的代码如下，可以看到对不同的样本赋予不同的权重实际上是影响了该样本在训练过程中贡献的损失，进而改变了一阶导和二阶导。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_out_gpair[_idx] = GradientPair(Loss::FirstOrderGradient(p, label) * w,</span><br><span class="line">                   Loss::SecondOrderGradient(p, label) * w);</span><br><span class="line"><span class="comment"># 见源码 src/objective/regression_obj.cu</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4><span id="学习目标参数">学习目标参数</span></h4><h5><span id="objective-缺省值reglinear">objective [缺省值=reg:linear]</span></h5><ul>
<li><code>reg:linear</code>– <strong>线性回归</strong></li>
<li><code>reg:logistic</code> – <strong>逻辑回归</strong></li>
<li><code>binary:logistic</code> – 二分类逻辑回归，输出为概率</li>
<li><code>binary:logitraw</code> – 二分类逻辑回归，输出的结果为wTx</li>
<li><code>count:poisson</code> – 计数问题的poisson回归，输出结果为poisson分布。在poisson回归中，max_delta_step的缺省值为0.7 (used to safeguard optimization)</li>
<li><code>multi:softmax</code> – 设置 XGBoost 使用softmax目标函数做多分类，需要设置参数num_class（类别个数）</li>
<li><code>multi:softprob</code> – 如同softmax，但是输出结果为ndata*nclass的向量，其中的值是每个数据分为每个类的概率。</li>
</ul>
<h5><span id="eval_metric-缺省值通过目标函数选择">eval_metric [缺省值=通过目标函数选择]</span></h5><ul>
<li><code>rmse</code>: <strong>均方根误差</strong></li>
<li><code>mae</code>: <strong>平均绝对值误差</strong></li>
<li><code>logloss</code>: negative log-likelihood</li>
<li><code>error</code>: 二分类错误率。其值通过错误分类数目与全部分类数目比值得到。对于预测，预测值大于0.5被认为是正类，其它归为负类。 error@t: 不同的划分阈值可以通过 ‘t’进行设置</li>
<li><code>merror</code>: 多分类错误率，计算公式为(wrong cases)/(all cases)</li>
<li><code>mlogloss</code>: ==多分类log损失==</li>
<li><code>auc</code>: 曲线下的面积</li>
<li><code>ndcg</code>: Normalized Discounted Cumulative Gain</li>
<li><code>map</code>: 平均正确率</li>
</ul>
<p>一般来说，我们都会使用<code>xgboost.train(params, dtrain)</code>函数来训练我们的模型。这里的<code>params</code>指的是<code>booster</code>参数。</p>
<h1><span id="xgboostqampa">XGBoostQ&amp;A</span></h1><ul>
<li>推荐收藏 | 又有10道XGBoost面试题送给你：<a href="https://cloud.tencent.com/developer/article/1518305">https://cloud.tencent.com/developer/article/1518305</a></li>
</ul>
<h3><span id="1-xgboost模型如果过拟合了怎么解决"><strong>1、XGBoost模型如果过拟合了怎么解决?</strong></span></h3><ul>
<li><strong>正则项</strong>：叶子结点的数目和叶子结点权重的L2模的平方</li>
<li><strong>列抽样</strong>：训练的时候只用一部分特征，不仅可以降低过拟合，还可以加速</li>
<li><strong>子采样</strong>：每轮计算可以不使用全部样本</li>
<li><strong>shrinkage</strong>: 步长(学习率)，消弱训练出的每棵树的影响，让后面的训练有更大的学习空间</li>
</ul>
<p>当出现过拟合时，有两类参数可以缓解：</p>
<p>第一类参数：用于<strong>直接控制模型的复杂度</strong>。包括<code>max_depth,min_child_weight,gamma</code> 等参数</p>
<p>第二类参数：用于<strong>增加随机性</strong>，从而使得模型在训练时对于噪音不敏感。包括<code>subsample,colsample_bytree</code></p>
<p>还有就是直接减小<code>learning rate</code>，但需要同时增加<code>estimator</code> 参数。</p>
<h3><span id="2-怎么理解决策树-xgboost能处理缺失值而有的模型svm对缺失值比较敏感呢">2、怎么理解决策树、xgboost能处理缺失值？而有的模型(svm)对缺失值比较敏感呢?</span></h3><blockquote>
<p>   微调的回答 - 知乎 <a href="https://www.zhihu.com/question/58230411/answer/242037063">https://www.zhihu.com/question/58230411/answer/242037063</a></p>
<p>  XGBoost是一种<strong>boosting</strong>的集成学习模型：支持的弱学习器（即单个的学习器，也称基学习器）有<strong>树模型</strong>和<strong>线性模型</strong>（<strong>gblinear</strong>），默认为<strong>gbtree</strong>。</p>
<ul>
<li><p><strong>gblinear</strong>，<strong>由于线性模型不支持缺失值，会将缺失值填充为0</strong>；</p>
</li>
<li><p><strong>gbtree</strong>或者<strong>dart</strong>，则支持缺失值；</p>
</li>
</ul>
</blockquote>
<ul>
<li>工具包自动处理数据缺失<strong>不代表</strong>具体的算法可以<strong>处理缺失项</strong></li>
<li>对于有缺失的数据：以<a href="https://www.zhihu.com/search?q=决策树&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A242037063}">决策树</a>为原型的模型<strong>优于</strong>依赖距离度量的模型</li>
</ul>
<h3><span id="3-histogram-vs-pre-sorted">3、 Histogram VS Pre-sorted</span></h3><h4><span id="pre-sorted">Pre-sorted</span></h4><p><strong>预排序还是有一定优点的，如果不用预排序的话，在分裂节点的时候，选中某一个特征后，需要对A按特征值大小进行排序，然后计算每个阈值的增益，这个过程需要花费很多时间</strong>。</p>
<p>预排序算法在计算最优分裂时，各个特征的增益可以并行计算，并且能精确地找到分割点。但是<strong>预排序后需要保存特征值及排序后的索引，因此需要消耗两倍于训练数据的内存，时间消耗大</strong>。另外预排序后，<strong>特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化，时间消耗也大</strong>。最后，在每一层，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样。</p>
<h4><span id="historgram">Historgram</span></h4><p>首先需要指出的是，XGBoost在寻找树的分裂节点的也是支持直方图算法的，就是论文中提到的近视搜索算法（Approximate Algorithm）。<strong>只是，无论特征值是否为0，直方图算法都需要对特征的分箱值进行索引，因此对于大部分实际应用场景当中的稀疏数据优化不足。</strong></p>
<p>回过头来，为了能够发挥直方图算法的优化威力，LightGBM提出了另外两个新技术：<strong>单边梯度采样（Gradient-based One-Side Sampling</strong>）和<strong>互斥特征合并（Exclusive Feature Bundling）</strong>，<strong><font color="red"> 在减少维度和下采样上面做了优化以后才能够将直方图算法发挥得淋漓尽致。</font></strong></p>
<h3><span id="4-xgboost中的树如何剪枝">4、<strong>Xgboost中的树如何剪枝？</strong></span></h3><p><strong>在loss中增加了正则项</strong>：使用叶子结点的数目和叶子结点权重的L2模的平方，控制树的复杂度在每次分裂时，如果分裂后增益小于设置的阈值，则不分裂，则对应于Gain需要大于0才会分裂。(预剪枝)</p>
<p>则对于目标函数来说，分裂后的收益为：<strong>MAX</strong>【<strong>obj1 - obj2 （分裂后越小越好）</strong>】</p>
<p><img src="https://www.zhihu.com/equation?tex=Gain%3D%5Cfrac12+%5Cleft%5B+%5Cfrac%7BG_L%5E2%7D%7BH_L%2B%5Clambda%7D+%2B+%5Cfrac%7BG_R%5E2%7D%7BH_R%2B%5Clambda%7D+-+%5Cfrac%7B%28G_L%2BG_R%29%5E2%7D%7BH_L%2BH_R%2B%5Clambda%7D%5Cright%5D+-+%5Cgamma+%5C%5C" alt="[公式]"></p>
<p>注意<strong>该特征收益也可作为特征重要性输出的重要依据</strong>。</p>
<p>我们可以发现对于所有的分裂点 <img src="https://www.zhihu.com/equation?tex=a" alt="[公式]"> ，我们只要做一遍从左到右的扫描就可以枚举出所有分割的梯度和 <img src="https://www.zhihu.com/equation?tex=G_L" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=G_R" alt="[公式]"> 。然后用上面的公式计算每个分割方案的分数就可以了。<font color="red">观察分裂后的收益，我们会发现节点划分不一定会使得结果变好，因为我们有一个引入<strong>新叶子的惩罚项（gamma)</strong>，也就是说引入的分割带来的<strong>增益如果小于一个阀值</strong>的时候，我们可以剪掉这个分割。 </font></p>
<ul>
<li>当一次分裂后，计算新生成的左、右叶子节点样本权重和。如果任一个叶子结点的样本权重低于某一个阈值（最小样本权重和），也会收回此次分裂。</li>
<li>完成完整一棵树的分裂之后，再从底到顶反向检查是否有不满足分裂条件的结点，进行回溯剪枝。</li>
</ul>
<h3><span id="5-xgboost采样是有放回还是无放回的">5、<strong>Xgboost采样是有放回还是无放回的？</strong></span></h3><p>xgboost时基于boosting的方法，样本是不放回的 ，每轮样本不重复。</p>
<h3><span id="6-xgboost在工程上有哪些优化为什么要做这些工程化优化">6、<strong>Xgboost在工程上有哪些优化？为什么要做这些工程化优化？</strong></span></h3><h4><span id="块结构设计"><strong>块结构设计</strong></span></h4><p>我们知道，决策树的学习<strong>最耗时的一个步骤就是在每次寻找最佳分裂点是都需要对特征的值进行排序</strong>。而 <strong><font color="red"> XGBoost 在训练之前对根据特征对数据进行了排序，然后保存到块结构中，并在每个块结构中都采用了稀疏矩阵存储格式（Compressed Sparse Columns Format，CSC）进行存储，后面的训练过程中会重复地使用块结构，可以大大减小计算量。</font></strong></p>
<blockquote>
<p>  预排序 + 块设计【独立】 + 稀疏矩阵存储 </p>
</blockquote>
<ul>
<li><strong>每一个块结构包括一个或多个已经排序好的特征</strong>；</li>
<li><strong>缺失特征值将不进行排序</strong>；</li>
<li>每个特征会存储指向<strong>样本梯度统计值</strong>的索引，方便计算一阶导和二阶导数值；</li>
</ul>
<p>这种块结构存储的特征之间相互独立，方便计算机进行并行计算。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个<strong>特征的增益计算可以同时进行</strong>，这也是 Xgboost 能够实现分布式或者多线程计算的原因。</p>
<h4><span id="缓存访问优化算法索引访问梯度统计-gt-缓存空间不连续"><strong>缓存访问优化算法</strong>【索引访问梯度统计 -&gt; 缓存空间不连续】</span></h4><p>块结构的设计可以减少节点分裂时的计算量，但<strong>特征值通过索引访问样本梯度统计值的设计会导致访问操作的内存空间不连续</strong>，这样会造成缓存命中率低，从而影响到算法的效率。</p>
<p>为了解决缓存命中率低的问题，XGBoost 提出了缓存访问优化算法：为每个线程分配一个连续的缓存区，将需要的梯度信息存放在缓冲区中，这样就是实现了非连续空间到连续空间的转换，提高了算法效率。此外适当调整块大小，也可以有助于缓存优化。</p>
<p>于exact greedy算法中, 使用<strong>缓存预取（cache-aware prefetching）</strong>。具体来说，<strong>对每个线程分配一个连续的buffer</strong>，读取梯度信息并存入Buffer中（这样就实现了非连续到连续的转化）</p>
<h4><span id="核外块计算"><strong>“核外”块计算</strong></span></h4><p>当数据量过大时无法将数据全部加载到内存中，只能先将无法加载到内存中的数据暂存到硬盘中，直到需要时再进行加载计算，而这种操作必然涉及到因内存与硬盘速度不同而造成的资源浪费和性能瓶颈。为了解决这个问题，<strong>XGBoost 独立一个线程专门用于从硬盘读入数据，以实现处理数据和读入数据同时进行</strong>。</p>
<p>此外，XGBoost 还用了两种方法来降低硬盘读写的开销：</p>
<ul>
<li><strong>块压缩：</strong>对 Block 进行按列压缩，并在读取时进行解压；</li>
<li><strong>块拆分：</strong>将每个块存储到不同的磁盘中，从多个磁盘读取可以增加吞吐量。</li>
</ul>
<h3><span id="7-xgboost与gbdt有什么联系和不同基模型-算法-工程设计">7、<strong>Xgboost与GBDT有什么联系和不同？</strong>【基模型、算法、工程设计】</span></h3><ol>
<li><strong>基分类器</strong>：GBDT 以 CART 作为基分类器，而Xgboost的基分类器不仅支持CART决策树，还支持线性分类器，此时Xgboost相当于带L1和L2正则化项的Logistic回归（分类问题）或者线性回归（回归问题）。</li>
<li><strong>导数信息</strong>：GBDT只用了一阶导数信息，Xgboost中对损失函数进行二阶泰勒展开，引入二阶导数信息，并且XGBoost还支持自定义损失函数，只要损失函数一阶和二阶可导即可。</li>
<li><strong>正则项</strong>：Xgboost的目标函数加入正则项(叶子结点的数目和叶子结点权重的L2模的平方)，相当于分裂预剪枝过程，降低过拟合。</li>
<li><strong>列抽样</strong>：Xgboost支持列采样，与随机森林类似，用于防止过拟合且加速。(列采样就是训练的时候随机使用一部分特征)，也同时支持子采样，即每轮迭代计算可以不使用全部样本，对样本数据进行采样。</li>
<li><strong>缺失值处理</strong>：Xgboost可以处理缺失值(具体，查看上方问答)</li>
<li><strong>并行化</strong>：Xgboost可以在特征维度进行并行化，在训练前预先将每个特征按照特征值大小进行预排序，按块的形式存储，后续可以重复使用这个结构，减小计算量，分裂时可以用多线程并行计算每个特征的增益，最终选增益最大的那个特征去做分裂，提高训练速度。</li>
</ol>
<h3><span id="8-xgboost特征重要性">8、<strong><font color="red"> XGBoost特征重要性</font></strong></span></h3><blockquote>
<p>  <strong>何时使用shap value分析特征重要性？</strong> -  知乎 <a href="https://www.zhihu.com/question/527570173/answer/2472253431">https://www.zhihu.com/question/527570173/answer/2472253431</a></p>
</blockquote>
<p>这一思路，通常被用来做<strong>特征筛选</strong>。剔除贡献度不高的尾部特征，增强模型的<a href="https://www.zhihu.com/search?q=鲁棒性&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;355884348&quot;}">鲁棒性</a>的同时，起到特征降维的作用。另一个方面，则是用来做<strong>模型的可解释性</strong>。我们期望的结果是：重要的特征是符合业务直觉的；符合业务直觉的特征排名靠前。</p>
<h4><span id="xgb内置的三种特征重要性计算方法">XGB内置的三种特征重要性计算方法</span></h4><ul>
<li><strong>weight</strong>：<code>xgb.plot_importance</code>,<strong>子树模型分裂时，用到的特征次数。这里计算的是所有的树。</strong></li>
<li><strong>gain</strong>:<code>model.feature_importances_</code>,信息增益的泛化概念。这里是指，<strong>节点分裂时，该特征带来信息增益（目标函数）优化的平均值。</strong></li>
<li><strong>cover</strong>:<code>model = XGBRFClassifier(importance_type = &#39;cover&#39;)</code> 这个计算方法，需要在定义模型时定义。之后再调用<code>model.feature_importances_</code> 得到的便是基于<code>cover</code>得到的贡献度。<strong>树模型在分裂时，特征下的叶子结点涵盖的样本数除以特征用来分裂的次数。分裂越靠近根部，cover 值越大。</strong></li>
</ul>
<h4><span id="其他重要性计算方法">其他重要性计算方法</span></h4><ul>
<li><strong>permutation</strong>:<strong>如果这个特征很重要，那么我们打散所有样本中的该特征，则最后的优化目标将折损。这里的折损程度，就是特征的重要程度。</strong></li>
<li><strong>shap</strong>:<strong>轮流去掉每一个特征，算出剩下特征的贡献情况，以此来推导出被去除特征的边际贡献。该方法是目前唯一的逻辑严密的特征解释方法</strong></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>集成学习</category>
      </categories>
  </entry>
</search>
