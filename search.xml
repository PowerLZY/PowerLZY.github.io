<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>机器学习模型评价指标</title>
    <url>/2023/04/16/hello-world/</url>
    <content><![CDATA[<blockquote>
<p>  一文看懂机器学习指标：准确率、精准率、召回率、F1、ROC曲线、AUC曲线:<a href="https://zhuanlan.zhihu.com/p/93107394">https://zhuanlan.zhihu.com/p/93107394</a></p>
<p>  <strong>机器学习-最全面的评价指标体系: <a href="https://zhuanlan.zhihu.com/p/359997979">https://zhuanlan.zhihu.com/p/359997979</a></strong></p>
<p>  <a href="https://github.com/HaoMood/homepage/blob/master/files/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8-03-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0.pdf">机器学习工程师面试宝典-03-模型评估</a></p>
<p>  <strong><a href="http://www.china-nb.cn/gongsidongtai/17-85.html">分类模型评估指标——准确率、精准率、召回率、F1、ROC曲线、AUC曲线</a></strong></p>
</blockquote>
<img src="/.io//image-20220421165422230.png" alt="image-20220421165422230" style="zoom:50%;">

<img src="/.io//image-20220421165436795.png" alt="image-20220421165436795" style="zoom:50%;">

<h3 id="一、二分类问题"><a href="#一、二分类问题" class="headerlink" title="一、二分类问题"></a>一、二分类问题</h3><blockquote>
<p>  <strong>阈值调节问题？</strong></p>
</blockquote>
<ul>
<li><strong>准确率 (Accuracy)<strong>：</strong>预测正确的概率</strong>  【**(TP+TN)&#x2F;(TP+TN+FP+FN)**】</li>
<li><strong>精确率（查准率 Precision )：&#x3D;&#x3D;预测为正的样本&#x3D;&#x3D;中实际为正的样本的概率</strong> 【**TP&#x2F;(TP+FP)**】</li>
<li>错误发现率（FDR）&#x3D; 1 - 精确率 &#x3D; &#x3D;&#x3D;预测为正的样本&#x3D;&#x3D;中实际为负的样本的概率 【**FP&#x2F;(TP+FP)**】</li>
<li><strong>召回率（查全率）- Recall</strong>：**&#x3D;&#x3D;实际为正的样本&#x3D;&#x3D;中被预测为正样本的概率<strong>【</strong>TP&#x2F;(TP+FN)**】</li>
<li><strong>真正率（TPR） &#x3D; 灵敏度（&#x3D;&#x3D;召回率&#x3D;&#x3D;） &#x3D;</strong> <strong>TP&#x2F;(TP+FN)</strong></li>
<li><strong>假正率（FPR） &#x3D; 1- 特异度 &#x3D;</strong> <strong>FP&#x2F;(FP+TN)</strong></li>
<li><strong>F1&#x3D;是准确率和召回率的&#x3D;&#x3D;调和平均值&#x3D;&#x3D; (2×Precision×Recall)&#x2F;（Precision+Recall）</strong></li>
<li><strong>G-mean（GM）&#x3D; 是准确率和召回率的&#x3D;&#x3D;几何平均值&#x3D;&#x3D;</strong> <img src="/.io//640-20230416162047009.svg" alt="img"></li>
</ul>
<h3 id="1-1-F1-x3D-2×Precision×Recall-x2F-（Precision-Recall）"><a href="#1-1-F1-x3D-2×Precision×Recall-x2F-（Precision-Recall）" class="headerlink" title="1.1 F1&#x3D;(2×Precision×Recall) &#x2F;（Precision+Recall）"></a>1.1 <strong>F1&#x3D;(2×Precision×Recall) &#x2F;（Precision+Recall）</strong></h3><p>精确率（Precision）和召回率（Recall）之间的关系用图来表达，就是下面的PR曲线。可以发现他们俩的关系是「两难全」的关系。为了综合两者的表现，在两者之间找一个平衡点，就出现了一个 F1分数。</p>
<h4 id="F1-x3D-2×Precision×Recall-x2F-（Precision-Recall）"><a href="#F1-x3D-2×Precision×Recall-x2F-（Precision-Recall）" class="headerlink" title="F1&#x3D;(2×Precision×Recall)  &#x2F;（Precision+Recall）"></a><strong>F1&#x3D;(2×Precision×Recall)  &#x2F;（Precision+Recall）</strong></h4><p>P意义类似于每通过准确预测得到TP个正例需要TP+FP个预测类别为正例的样本。</p>
<p>R意义类似于每通过成功召回得到TP个正例需要TP+FN个真实类别为正例的样本。</p>
<p>F1度量了给定一批样本，对这一批样本进行预测与召回，最终得到的正例的多少。<strong>其中一半的正例是通过预测得到的，一半的正例是通过召回得到的。</strong></p>
<p>有一种把预测所需的预测类别为正例的样本和召回所需的真实类别为正例的样本看作原料，而我们的目标正例样本看作产品的感觉。<strong>所以也能解释为什么P跟R其中一者比较低的时候，F1会偏低。因为跟算术平均数不一样，两者不能互相替代，两部分各负责一半。那么加权调和平均Fbeta也可以很好的理解了。</strong></p>
<p>$$<br>\frac{1}{F_\beta}&#x3D;\frac{1}{1+\beta^2} \cdot\left(\frac{1}{P}+\frac{\beta^2}{R}\right)<br>$$<br>各自负责的比例不一样了。因此beta越大，Fbeta越着重考虑召回能力。</p>
<h3 id="1-2-ROC-x2F-AUC的概念"><a href="#1-2-ROC-x2F-AUC的概念" class="headerlink" title="1.2 ROC&#x2F;AUC的概念"></a>1.2 ROC&#x2F;AUC的概念</h3><p><strong>1. 灵敏度，特异度，真正率，假正率</strong></p>
<p>在正式介绍ROC&#x2F;AUC之前，我们还要再介绍两个指标，<strong>这两个指标的选择也正是ROC和AUC可以无视样本不平衡的原因。</strong> 这两个指标分别是：<strong>灵敏度和（1-特异度），也叫做真正率（TPR）和假正率（FPR）</strong>。其实我们可以发现<strong>灵敏度和召回率是一模一样的，只是名字换了而已</strong>。由于我们比较关心正样本，所以需要查看有多少负样本被错误地预测为正样本，所以使用（1-特异度），而不是特异度。</p>
<p><strong>真正率（TPR） &#x3D; 灵敏度（&#x3D;&#x3D;召回率&#x3D;&#x3D;） &#x3D;</strong> <strong>TP&#x2F;(TP+FN)</strong></p>
<p><strong>假正率（FPR） &#x3D; 1- 特异度 &#x3D;</strong> <strong>FP&#x2F;(FP+TN)</strong></p>
<p>下面是真正率和假正率的示意，我们发现<strong>TPR和FPR分别是基于实际表现1和0出发的，也就是说它们分别在实际的正样本和负样本中来观察相关概率问题。</strong> </p>
<blockquote>
<p>  正因为如此，所以无论样本是否平衡，都不会被影响。还是拿之前的例子，总样本中，90%是正样本，10%是负样本。我们知道用准确率是有水分的，但是用TPR和FPR不一样。这里，TPR只关注90%正样本中有多少是被真正覆盖的，而与那10%毫无关系，同理，FPR只关注10%负样本中有多少是被错误覆盖的，也与那90%毫无关系，</p>
</blockquote>
<p><strong>如果我们从实际表现的各个结果角度出发，就可以避免样本不平衡的问题了，这也是为什么选用TPR和FPR作为ROC&#x2F;AUC的指标的原因。</strong></p>
<h4 id="2-ROC（接受者操作特征曲线）"><a href="#2-ROC（接受者操作特征曲线）" class="headerlink" title="2. ROC（接受者操作特征曲线）"></a><strong>2. ROC（接受者操作特征曲线）</strong></h4><blockquote>
<p>  ROC（Receiver Operating Characteristic）曲线，又称接受者操作特征曲线。该曲线最早应用于雷达信号检测领域，用于区分信号与噪声。后来人们将其用于评价模型的预测能力，ROC曲线是基于<strong>混淆矩阵</strong>得出的。</p>
</blockquote>
<p>ROC曲线中的主要两个指标就是<strong>真正率</strong>和<strong>假正率，</strong> 上面也解释了这么选择的好处所在。其中<strong>横坐标为假正率（FPR），纵坐标为真正率（TPR）</strong>，下面就是一个标准的ROC曲线图。</p>
<h4 id="AUC的缺陷？"><a href="#AUC的缺陷？" class="headerlink" title="AUC的缺陷？"></a>AUC的缺陷？</h4><p><strong>优点</strong>：目前普遍认为接收器工作特性曲线（ROC）曲线下的面积—AUC是评估分类模型准确性的标准方法。<strong>它避免了在阈值选择过程中假定的主观性</strong>，当连续的概率得到的分数被转换为二分类标签时，通过总结整体模型表现，其衡量模型区分正负样本的性能优于通过阈值来判断的其他方法（比如准确率、召回率等）。</p>
<ul>
<li><strong>忽略了预测的概率值和模型的拟合优度</strong></li>
<li><strong>AUC反应了太过笼统的信息。无法反应召回率、精确率等在实际业务中经常关心的指标</strong></li>
<li><font color="red"> <strong>对FPR和TPR两种错误的代价同等看待</strong></font></li>
<li>它没有给出模型误差的空间分布信息</li>
<li>最重要的一点，AUC的misleading的问题</li>
</ul>
<p><strong>&#x3D;&#x3D;auc仅反应模型的排序能力&#x3D;&#x3D;，无法反应模型的拟合优度；auc很多时候无法直接反应细粒度的和业务目标更相关的metric信息，例如 top k的准确率，召回率等等（例如同auc的模型在不同的区间的预测能力是存在差别的）；</strong></p>
<h3 id="1-3、K-S曲线"><a href="#1-3、K-S曲线" class="headerlink" title="1.3、K-S曲线"></a>1.3、K-S曲线</h3><blockquote>
<p>  <strong>K-S曲线</strong>，又称作洛伦兹曲线。实际上，K-S曲线的数据来源以及本质和ROC曲线是一致的，只是ROC曲线是把真正率（ <img src="/.io//equation-20230416162046966" alt="[公式]"> ）和假正率（ <img src="/.io//equation-20230416162046970" alt="[公式]"> ）当作横纵轴，<strong>而K-S曲线是把真正率（ <img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> ）和假正率（ <img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> )都当作是纵轴，横轴则由选定的阈值来充当。从 <strong>K-S 曲线</strong>就能衍生出 <img src="/.io//equation-20230416162046950" alt="[公式]"> 值， <img src="/.io//equation-20230416162046968" alt="[公式]"> ，即是两条曲线之间的最大间隔距离。</strong></p>
</blockquote>
<p><strong>K-S曲线的画法：</strong></p>
<ol>
<li><p><strong>排序：</strong>对于二元分类器来说，模型训练完成之后每个样本都会得到一个类概率值，把样本按这个类概率值从大到小进行排序；</p>
</li>
<li><p><strong>找阈值：</strong>取排序后前 <img src="/.io//equation?tex=10/%25/times+k(k%253D1%252C2%252C3%252C..-20230416162046951.%252C9)" alt="[公式]"> 处的值（概率值）作为阈值，分别计算出不同的 <img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> 和<img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> 值，以<img src="https://www.zhihu.com/equation?tex=10%5C%25%5Ctimes+k(k=1,2,3,...,9)" alt="[公式]">为横坐标，分别以<img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> 和<img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> 值为纵坐标，就可以画出两个曲线，这就是K-S曲线，类似于下图。</p>
</li>
<li><p><strong>KS值</strong>：</p>
<p>从 <strong>K-S 曲线</strong>就能衍生出 <img src="/.io//equation-20230416162046950" alt="[公式]"> 值， <img src="/.io//equation-20230416162046968" alt="[公式]"> ，即是两条曲线之间的最大间隔距离。KS值越大表示模型 的区分能力越强。</p>
</li>
</ol>
<img src="/.io//v2-f913b42cefcd32f9fdbfa027de2dfbc8_1440w.jpg" alt="img" style="zoom: 50%;">

<h3 id="1-4-Lift曲线"><a href="#1-4-Lift曲线" class="headerlink" title="1.4 Lift曲线"></a>1.4 Lift曲线</h3><p><strong>Lift曲线它衡量的是，与不利用模型相比，模型的预测能力“变好”了多少，lift(提升指数)越大，模型的运行效果越好。实质上它强调的是投入与产出比</strong>。</p>
<p><strong>tip:<strong>理解</strong>Lift</strong>可以先看一下Quora上的一篇文章：**<a href="https://link.zhihu.com/?target=https://www.quora.com/Whats-Lift-curve">What’s Lift curve?</a>**</p>
<p><strong>Lift计算公式：</strong>先介绍几个相关的指标，以免混淆：</p>
<ul>
<li><strong>准确率（accuracy，ACC）</strong>：</li>
</ul>
<p><img src="/.io//equation-20230416162047033" alt="[公式]"></p>
<ul>
<li><strong>正确率(Precision，PRE)，查准率</strong>：</li>
</ul>
<p><img src="/.io//equation-20230416162047062" alt="[公式]"></p>
<ul>
<li>**真阳性率(True Positive Rate，TPR)，灵敏度(Sensitivity)，召回率(Recall)**：</li>
</ul>
<p><img src="/.io//equation-20230416162047046" alt="[公式]"></p>
<ul>
<li>**假阳性率(False Positice Rate，FPR)，误诊率( &#x3D; 1 - 特异度)**：</li>
</ul>
<p><img src="/.io//equation-20230416162047333" alt="[公式]"></p>
<p><strong>Lift计算公式：</strong></p>
<p><img src="/.io//equation-20230416162047311" alt="[公式]"></p>
<p>根据以上公式可知，<strong>Lift指标可以这样理解：</strong>在不使用模型的情况下，我们用先验概率估计正例的比例，即上式子分母部分，以此作为正例的命中率；利用模型后，我们不需要从整个样本中来挑选正例，只需要从我们预测为正例的那个样本的子集 <img src="/.io//equation-20230416162047100" alt="[公式]"> 中挑选正例，这时正例的命中率为 <img src="/.io//equation-20230416162047320-1633247." alt="[公式]"> ，后者除以前者即可得提升值<strong>Lift。</strong></p>
<h4 id="Lift曲线："><a href="#Lift曲线：" class="headerlink" title="Lift曲线："></a><strong>Lift曲线：</strong></h4><p>为了作出<strong>LIft</strong>曲线，首先引入 <img src="/.io//equation-20230416162047320" alt="[公式]"> 的概念：</p>
<p><img src="/.io//equation-20230416162047327" alt="[公式]"></p>
<p><strong>从公式可以看出</strong>，<img src="/.io//equation-20230416162047320" alt="[公式]">代表的是预测为正例的样本占整个样本的比例。</p>
<p>当阈值为0时，所有的样本都被预测为正例，因此 <img src="/.io//equation-20230416162047329" alt="[公式]"> ，于是 <img src="/.io//equation-20230416162047403" alt="[公式]"> ，模型未起提升作用。随着阈值逐渐增大，被预测为正例的样本数逐渐减少，<img src="/.io//equation-20230416162047320" alt="[公式]">减小，而较少的预测正例样本中的真实正例比例逐渐增大。当阈值增大至1时，没有样本被预测为正例，此时 <img src="/.io//equation-20230416162047476" alt="[公式]"> ，而 <img src="/.io//equation-20230416162047459" alt="[公式]"> 。由此可见， <img src="/.io//equation-20230416162047460" alt="[公式]"> 与<img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]">存在相反方向变化的关系。在此基础上作出 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 图：</p>
<img src="/.io//v2-4cfa1e77335b91d9a47acb7238383c1e_1440w.jpg" alt="img" style="zoom: 50%;">

<p>一般要求，在尽量大的 <img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]"> 下得到尽量大的 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]">，所以 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 曲线的右半部分应该尽量陡峭。</p>
<h3 id="1-5-P-R曲线"><a href="#1-5-P-R曲线" class="headerlink" title="1.5 P-R曲线"></a>1.5 <strong>P-R曲线</strong></h3><ul>
<li><p><strong>精确率（查准率）- Precision ：&#x3D;&#x3D;预测为正的样本&#x3D;&#x3D;中实际为正的样本的概率</strong> 【**TP&#x2F;(TP+FP)**】</p>
</li>
<li><p><strong>召回率（查全率）- Recall</strong>：**&#x3D;&#x3D;实际为正的样本&#x3D;&#x3D;中被预测为正样本的概率<strong>【</strong>TP&#x2F;(TP+FN)**】</p>
</li>
</ul>
<p>P-R曲线刻画<strong>查准率</strong>和<strong>查全率（召回率）</strong>之间的关系，查准率指的是在所有预测为正例的数据中，真正例所占的比例，查全率是指预测为真正例的数据占所有正例数据的比例。查准率和查全率是一对矛盾的度量，一般来说，查准率高时，查全率往往偏低，查全率高时，查准率往往偏低。</p>
<p>在很多情况下，我们可以根据学习器的预测结果对样例进行排序，排在前面的是学习器认为最可能是正例的样本，排在后面的是学习器认为最不可能是正例的样本，按此顺序逐个把样本作为正例进行预测，则每次可计算当前的查全率和查准率，以查准率为y轴，以查全率为x轴，可以画出下面的P-R曲线。</p>
<img src="/.io//v2-dc6abbb24e2dfbfefe4777408d2a8e5c_1440w.jpg" alt="img" style="zoom:67%;">

<p>如果一个学习器的P-R曲线被另一个学习器的P-R曲线完全包住，则可断言后者的性能优于前者，当然我们可以根据曲线下方的面积大小来进行比较，但更常用的是<strong>平衡点</strong>或者是F1值。</p>
<ul>
<li><strong>平衡点（BEP）</strong>是查准率&#x3D;查全率时的取值，如果这个值较大，则说明学习器的性能较好。F1值越大，我们可以认为该学习器的性能较好。</li>
<li><font color="red"> <strong>F1度量</strong>：<strong>BEP过于简单，这个平衡点是建立在”查准率&#x3D;查全率“的前提下，无法满足实际不同场景的应用。</strong></font></li>
</ul>
<p>我们先来引入加权调和平均： <img src="/.io//equation-20230416162047533" alt="[公式]">：</p>
<p><img src="/.io//equation-20230416162047516" alt="[公式]"></p>
<p>加权调和平均与<strong>算术平均</strong> <img src="/.io//equation-20230416162047501" alt="[公式]"> 和<strong>几何平均</strong> <img src="/.io//equation-20230416162047744" alt="[公式]"> 相比，<strong>调和平均更重视较小值（这可以从倒数上看出来）</strong>。当 <img src="/.io//equation-20230416162047557" alt="[公式]"> ，即F1是基于查准率和查全率的调和平均定义的，F1的公式如下：</p>
<p><img src="/.io//equation-20230416162047728" alt="[公式]"></p>
<p>我们把公式求倒数，即可得：</p>
<p><img src="/.io//equation-20230416162047554" alt="[公式]"></p>
<p>在一些应用中，对查准率和查全率的重视程度不同。例如在商品推荐中，为了尽可能少打扰用户，更希望推荐的内容确实是用户感兴趣的，此时查准率更重要；而在罪犯信息检索或者病人检查系统中，更希望尽可能少的漏判，此时查全率更重要。F1度量的一般形式是 <img src="/.io//equation-20230416162047757" alt="[公式]"> ，能让我们自定义对查准率&#x2F;查全率的不同偏好：</p>
<p><img src="/.io//equation-20230416162047731" alt="[公式]"></p>
<p>其中， <img src="/.io//equation-20230416162047732" alt="[公式]"> 度量了查全率对查准率的相对重要性（不明白的同学可以回看公式1）， <img src="/.io//equation-20230416162047729" alt="[公式]"> 时退化为标准F1，<img src="/.io//equation-20230416162048546" alt="[公式]">&#x3D;&#x3D;时查全率有更大影响； <img src="/.io//equation-20230416162048521" alt="[公式]"> 时，查准率有更大影响。&#x3D;&#x3D;</p>
<h3 id="1-6-对数损失-Log-Loss"><a href="#1-6-对数损失-Log-Loss" class="headerlink" title="1.6 对数损失(Log Loss)"></a>1.6 <strong>对数损失(Log Loss)</strong></h3><p><strong>AUC ROC考虑用于确定模型性能的预测概率</strong>。然而，AUC ROC存在问题，它只考虑概率的顺序，因此<strong>没有考虑模型预测更可能为正样本的更高概率的能力(即考虑了大小，但没有考虑更高精度)<strong>。</strong>在这种情况下，我们可以使用对数损失，即每个实例的正例预测概率的对数的负平均值。</strong></p>
<p>对数损失（Logistic Loss，logloss）是对预测概率的似然估计，其标准形式为：</p>
<p><img src="/.io//equation-20230416162048834" alt="[公式]"></p>
<p>对数损失最小化本质是上利用样本中的已知分布，求解拟合这种分布的最佳模型参数，使这种分布出现概率最大。</p>
<p>对数损失对应的二分类的计算公式为：</p>
<p><img src="/.io//equation-20230416162048881" alt="[公式]"></p>
<p>其中N为样本数， <img src="/.io//equation-20230416162048799" alt="[公式]"> 为预测为1的概率。对数损失在多分类问题中也可以使用，其计算公式为：</p>
<p><img src="/.io//equation-20230416162048828" alt="[公式]"></p>
<p>其中，N为样本数，C为类别数，logloss衡量的是预测概率分布和真实概率分布的差异性，取值越小越好。</p>
<h3 id="1-7-多分类"><a href="#1-7-多分类" class="headerlink" title="1.7 多分类"></a>1.7 多分类</h3><p>很多时候我们有多个<strong>二分类混淆矩阵</strong>，例如进行多次训练&#x2F;测试，每次得到一个混淆矩阵；或是在多个数据集上进行训练&#x2F;测试，希望估计算法的全局性能；或者是执行分类任务，每两两类别的组合都对应一个混淆矩阵；总之是在<strong>n个二分类混淆矩阵上综合考察查准率和查全率</strong>。</p>
<ul>
<li><strong>宏观</strong>：在各个混淆军阵上分别计算出查准率和查全率，记为(P1,R1)，(P2,R2),…(Pn,Rn)，在<strong>计算平均值</strong>，这样就得到“宏观查准率”(macro-P)，“宏观查全率”(macro-R)、“宏观F1”(macro-F1)：</li>
</ul>
<p><img src="/.io//equation-20230416162048883" alt="[公式]"></p>
<p><img src="/.io//equation-20230416162048768" alt="[公式]"></p>
<p><img src="/.io//equation-20230416162048925" alt="[公式]"></p>
<ul>
<li><strong>微观</strong>：<strong>将个混淆矩阵对应的元素进行平均，得到TP、FP、TN、FN的平均值</strong>，分别记为 <img src="/.io//equation-20230416162048919" alt="[公式]"> 、 <img src="/.io//equation-20230416162048984" alt="[公式]"> 、 <img src="/.io//equation-20230416162049151" alt="[公式]"> 、 <img src="/.io//equation-20230416162048985" alt="[公式]"> ，再基于这些平均值计算出“微观查准率”(micro-P)，“微观查全率”(micro-R)、“微观F1”(micro-F1)：</li>
</ul>
<p><img src="/.io//equation-20230416162049034" alt="[公式]"></p>
<p><img src="/.io//equation-20230416162049017" alt="[公式]"></p>
<p><img src="/.io//equation-20230416162049062" alt="[公式]"></p>
<h2 id="二、回归问题评价指标"><a href="#二、回归问题评价指标" class="headerlink" title="二、回归问题评价指标"></a>二、回归问题评价指标</h2><blockquote>
<p>  <strong>均方差损失 Mean Squared Loss、平均绝对误差损失 Mean Absolute Error Loss、Huber Loss、分位数损失 Quantile Loss</strong></p>
</blockquote>
<p>机器学习中的监督学习本质上是给定一系列训练样本 <img src="/.io//equation-20230416162049473" alt="[公式]"> ，尝试学习 <img src="/.io//equation-20230416162049156" alt="[公式]"> 的映射关系，使得给定一个 <img src="/.io//equation-20230416162049168" alt="[公式]"> ，即便这个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 不在训练样本中，也能够得到尽量接近真实 <img src="/.io//equation-20230416162049157" alt="[公式]"> 的输出 <img src="/.io//equation-20230416162049217" alt="[公式]"> 。而损失函数（Loss Function）则是这个过程中关键的一个组成部分，用来<strong>衡量模型的输出</strong> <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D" alt="[公式]"> <strong>与真实的</strong> <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> <strong>之间的差距</strong>，给模型的优化指明方向。</p>
<h3 id="2-1-均方差损失-MSE、L2-loss"><a href="#2-1-均方差损失-MSE、L2-loss" class="headerlink" title="2.1 均方差损失 MSE、L2 loss"></a>2.1 均方差损失 MSE、L2 loss</h3><h5 id="基本形式与原理"><a href="#基本形式与原理" class="headerlink" title="基本形式与原理"></a><strong>基本形式与原理</strong></h5><p><strong>均方差Mean Squared Error (MSE)损失是机器学习、深度学习回归任务中最常用的一种损失函数</strong>，也称为 <strong>L2 Loss</strong>。其基本形式如下：</p>
<p><img src="/.io//equation-20230416162049999" alt="[公式]"></p>
<p>从直觉上理解均方差损失，这个损失函数的最小值为 0（当预测等于真实值时），最大值为无穷大。下图是对于真实值 <img src="/.io//equation-20230416162049932" alt="[公式]"> ，不同的预测值 <img src="/.io//equation?tex=%5B-1.5%252C+1-20230416162049423.5%5D" alt="[公式]"> 的均方差损失的变化图。横轴是不同的预测值，纵轴是均方差损失，可以看到随着预测与真实值绝对误差 <img src="/.io//equation-20230416162049408" alt="[公式]"> 的增加，均方差损失呈二次方地增加。</p>
<p><img src="/.io//v2-f13a4355c21d16cad8b3f30e8a24b5cc_1440w-20230416162046673.jpg" alt="img"></p>
<blockquote>
<h4 id="背后的假设"><a href="#背后的假设" class="headerlink" title="背后的假设"></a>背后的假设</h4><p>  <strong>【独立同分布-中心极限定理】</strong>：<br>  如果 <img src="/.io//equation-20230416162050043" alt="[公式]"> 独立同分布，且 <img src="/.io//equation-20230416162049991" alt="[公式]"> ，则n足够大时 <img src="/.io//equation-20230416162050213" alt="[公式]"> 近似服从正态分布 <img src="/.io//equation-20230416162049568" alt="[公式]"> ，即</p>
<p>  <img src="/.io//equation-20230416162049986" alt="[公式]"></p>
<p>  实际上在一定的假设下，我们可以使用最大化似然得到均方差损失的形式。假设<strong>模型预测与真实值之间的误差服从标准高斯分布</strong>（ <img src="/.io//equation-20230416162050188" alt="[公式]"> ），则给定一个 <img src="/.io//equation-20230416162050488" alt="[公式]"> 模型输出真实值 <img src="/.io//equation-20230416162050490" alt="[公式]"> 的概率为</p>
<p>  <img src="/.io//equation-20230416162050304" alt="[公式]"></p>
<p>  <strong>进一步我们假设数据集中 N 个样本点之间相互独立，则给定所有 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 输出所有真实值 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 的概率，即似然 Likelihood</strong>，为所有 <img src="/.io//equation-20230416162050196" alt="[公式]"> 的累乘</p>
<p>  <img src="/.io//equation-20230416162050500" alt="[公式]"></p>
<p>  通常为了计算方便，我们通常最大化对数似然 Log-Likelihood</p>
<p>  <img src="/.io//equation-20230416162050459" alt="[公式]"></p>
<p>  去掉与 <img src="/.io//equation-20230416162050494" alt="[公式]"> 无关的第一项，然后转化为最小化负对数似然 Negative Log-Likelihood</p>
<p>  <img src="/.io//equation-20230416162050548" alt="[公式]"></p>
<p>  可以看到这个实际上就是均方差损失的形式。也就是说<strong>在模型输出与真实值的误差服从高斯分布的假设下，最小化均方差损失函数与极大似然估计本质上是一致的</strong>，因此在这个假设能被满足的场景中（比如回归），均方差损失是一个很好的损失函数选择；当这个假设没能被满足的场景中（比如分类），均方差损失不是一个好的选择。</p>
</blockquote>
<h3 id="hulu-百面机器学习-——-平方根误差的”意外“"><a href="#hulu-百面机器学习-——-平方根误差的”意外“" class="headerlink" title=" hulu 百面机器学习 —— 平方根误差的”意外“"></a><strong><font color="red"> hulu 百面机器学习 —— 平方根误差的”意外“</font></strong></h3><h4 id="95-的时间区间效果很好，RMSE指标居高不下的原因？"><a href="#95-的时间区间效果很好，RMSE指标居高不下的原因？" class="headerlink" title="95%的时间区间效果很好，RMSE指标居高不下的原因？"></a>95%的时间区间效果很好，RMSE指标居高不下的原因？</h4><p><img src="/.io//equation-20230416162049999" alt="[公式]"></p>
<p>一般情况下RSME能反应预测值与真实值的偏离程度，但是<strong>易受离群点</strong>的影响；</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>数据预处理将噪音去掉</li>
<li>将离群点的产生机制建模进去</li>
<li>更鲁棒的模型评估指标：<strong>平均绝对百分比误差</strong>（MAPE），<strong>分位数损失</strong></li>
</ul>
<h4 id="2-2-平均绝对误差-MAE"><a href="#2-2-平均绝对误差-MAE" class="headerlink" title="2.2 平均绝对误差 MAE"></a>2.2 <strong>平均绝对误差 MAE</strong></h4><p><strong>平均绝对误差 Mean Absolute Error (MAE）</strong> 是另一类常用的损失函数，也称为 <strong>L1 Loss</strong>。其基本形式如下</p>
<p><img src="/.io//equation-20230416162050595" alt="[公式]"></p>
<p>同样的我们可以对这个损失函数进行可视化如下图，MAE 损失的最小值为 0（当预测等于真实值时），最大值为无穷大。可以看到随着预测与真实值绝对误差 <img src="/.io//equation-20230416162049408" alt="[公式]"> 的增加，MAE 损失呈线性增长。</p>
<p><img src="/.io//v2-fd248542b6b5aa9fadcab44340045dee_1440w-20230416162047379.jpg" alt="img"></p>
<blockquote>
<h4 id="背后的假设-1"><a href="#背后的假设-1" class="headerlink" title="背后的假设"></a>背后的假设</h4><p>  同样的我们可以在一定的假设下通过最大化似然得到 MAE 损失的形式，假设<strong>模型预测与真实值之间的误差服从拉普拉斯分布 Laplace distribution</strong>（ <img src="/.io//equation-20230416162050627" alt="[公式]"> ），则给定一个 <img src="/.io//equation-20230416162050488" alt="[公式]"> 模型输出真实值 <img src="/.io//equation-20230416162050490" alt="[公式]"> 的概率为</p>
<p>  <img src="/.io//equation-20230416162050629" alt="[公式]"></p>
<p>  与上面推导 MSE 时类似，我们可以得到的负对数似然实际上就是 MAE 损失的形式</p>
<p>  <img src="/.io//equation-20230416162050623" alt="[公式]"></p>
</blockquote>
<h3 id="2-3-MAE-与-MSE-区别"><a href="#2-3-MAE-与-MSE-区别" class="headerlink" title="2.3 MAE 与 MSE 区别"></a>2.3 MAE 与 MSE 区别</h3><p>MAE 和 MSE 作为损失函数的主要区别是：<strong>MSE 损失相比 MAE 通常可以更快地收敛，但 MAE 损失对于 outlier 更加健壮</strong>，即更加不易受到 outlier 影响。</p>
<ul>
<li><p><strong>MSE 通常比 MAE 可以更快地收敛</strong>。当使用梯度下降算法时，MSE 损失的梯度为 <img src="/.io//equation-20230416162050592" alt="[公式]"> ，而 MAE 损失的梯度为 <img src="/.io//equation-20230416162050635" alt="[公式]"> ，即 MSE 的梯度的 scale 会随误差大小变化，而 MAE 的梯度的 scale 则一直保持为 1，即便在绝对误差 <img src="/.io//equation-20230416162050892" alt="[公式]"> 很小的时候 MAE 的梯度 scale 也同样为 1，这实际上是非常不利于模型的训练的。当然你可以通过在训练过程中动态调整学习率缓解这个问题，但是总的来说，损失函数梯度之间的差异导致了 MSE 在大部分时候比 MAE 收敛地更快。这个也是 MSE 更为流行的原因。</p>
</li>
<li><p><strong>MAE 对于异常值（outlier） 更加 robust</strong>。我们可以从两个角度来理解这一点：</p>
<ul>
<li>第一个角度是直观地理解，下图是 MAE 和 MSE 损失画到同一张图里面，由于MAE 损失与绝对误差之间是线性关系，MSE 损失与误差是平方关系，当误差非常大的时候，MSE 损失会远远大于 MAE 损失。<strong>因此当数据中出现一个误差非常大的 outlier 时，MSE 会产生一个非常大的损失，对模型的训练会产生较大的影响</strong>。<img src="/.io//v2-c8edffe0406dafae41a042e412cd3251_1440w-20230416162047585.jpg" alt="img"></li>
<li>第二个角度是从两个损失函数的假设出发，MSE 假设了误差服从高斯分布，MAE 假设了误差服从拉普拉斯分布。拉普拉斯分布本身对于 outlier 更加 robust。参考下图（来源：<a href="https://link.zhihu.com/?target=https://www.cs.ubc.ca/~murphyk/MLbook/">Machine Learning: A Probabilistic Perspective</a> 2.4.3 The Laplace distribution Figure 2.8），当右图右侧出现了 outliers 时，拉普拉斯分布相比高斯分布受到的影响要小很多。因此以拉普拉斯分布为假设的 MAE 对 outlier 比高斯分布为假设的 MSE 更加 robust。<img src="/.io//v2-93ad65845f5b0dc0327fde4ded661804_1440w-20230416162047378.jpg" alt="img" style="zoom: 67%;"></li>
</ul>
</li>
</ul>
<h3 id="2-4-Huber-Loss"><a href="#2-4-Huber-Loss" class="headerlink" title="2.4 Huber Loss"></a>2.4 Huber Loss</h3><blockquote>
<ul>
<li>在误差接近 0 时使用 MSE，使损失函数可导并且梯度更加稳定</li>
<li>在误差较大时使用 MAE 可以降低 outlier 的影响，使训练对 outlier 更加健壮。</li>
</ul>
</blockquote>
<p>上文我们分别介绍了 MSE 和 MAE 损失以及各自的优缺点，MSE 损失收敛快但容易受 outlier 影响，MAE 对 outlier 更加健壮但是收敛慢，<a href="https://link.zhihu.com/?target=https://en.wikipedia.org/wiki/Huber_loss">Huber Loss</a> 则是一种将 MSE 与 MAE 结合起来，取两者优点的损失函数，也被称作 Smooth Mean Absolute Error Loss 。其原理很简单，就是在误差接近 0 时使用 MSE，误差较大时使用 MAE，公式为</p>
<p><img src="/.io//equation-20230416162050848" alt="[公式]"></p>
<p>上式中 <img src="/.io//equation-20230416162050875" alt="[公式]"> 是 Huber Loss 的一个超参数，<img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="[公式]"> 的值是 MSE 和 MAE 两个损失连接的位置。上式等号右边第一项是 MSE 的部分，第二项是 MAE 部分，在 MAE 的部分公式为 <img src="/.io//equation-20230416162050955" alt="[公式]"> 是为了保证误差 <img src="/.io//equation-20230416162050914" alt="[公式]"> 时 MAE 和 MSE 的取值一致，进而保证 Huber Loss 损失连续可导。</p>
<p>下图是 <img src="/.io//equation?tex=/delta%253D1-20230416162050876.0" alt="[公式]"> 时的 Huber Loss，可以看到在 <img src="/.io//equation-20230416162051143" alt="[公式]"> 的区间内实际上就是 MSE 损失，在 <img src="/.io//equation-20230416162050970" alt="[公式]"> 和 <img src="/.io//equation-20230416162050962" alt="[公式]"> 区间内为 MAE损失。</p>
<p><img src="/.io//v2-b4260d38f70dd920fa46b8717596bda7_1440w-20230416162047797.jpg" alt="img"></p>
<h3 id="2-5-分位数损失-Quantile-Loss"><a href="#2-5-分位数损失-Quantile-Loss" class="headerlink" title="2.5 分位数损失 Quantile Loss"></a>2.5 分位数损失 Quantile Loss</h3><blockquote>
<p>  <strong>MAE 中分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong></p>
</blockquote>
<p><strong>分位数回归 Quantile Regression 是一类在实际应用中非常有用的回归算法</strong>，通常的回归算法是拟合目标值的期望或者中位数，而分位数回归可以通过给定不同的分位点，<strong>拟合目标值的不同分位数</strong>。</p>
<p><img src="/.io//v2-8eb8ecfcdd8031a16a471905217934a0_1440w-20230416162047585.jpg" alt="img"></p>
<p>分位数回归是通过使用分位数损失 Quantile Loss 来实现这一点的，分位数损失形式如下，式中的 r 分位数系数。</p>
<p><img src="/.io//equation-20230416162050991" alt="[公式]"></p>
<p>我们如何理解这个损失函数呢？这个损失函数是一个分段的函数 ，将 <img src="/.io//equation-20230416162051027" alt="[公式]"> （高估） 和 <img src="/.io//equation-20230416162051092" alt="[公式]"> （低估） 两种情况分开来，并分别给予不同的系数。当 <img src="/.io//equation?tex=r%3E0-20230416162051067.5" alt="[公式]"> 时，低估的损失要比高估的损失更大，反过来当 <img src="/.io//equation?tex=r+%3C+0-20230416162051140.5" alt="[公式]"> 时，高估的损失比低估的损失大；分位数损失实现了<strong>分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong>。特别地，当 <img src="/.io//equation?tex=r%253D0-20230416162051084.5" alt="[公式]"> 时，分位数损失退化为 MAE 损失，从这里可以看出 MAE 损失实际上是分位数损失的一个特例 — 中位数回归。</p>
<p>下图是取不同的分位点 0.2、0.5、0.6 得到的三个不同的分位损失函数的可视化，可以看到 0.2 和 0.6 在高估和低估两种情况下损失是不同的，而 0.5 实际上就是 MAE。</p>
<p><img src="/.io//v2-f8ed385f32a517c784bce841e6da1daf_1440w-20230416162047923.jpg" alt="img"></p>
<h3 id="2-6-平均绝对百分误差-MAPE"><a href="#2-6-平均绝对百分误差-MAPE" class="headerlink" title="2.6  平均绝对百分误差 MAPE"></a>2.6  平均绝对百分误差 MAPE</h3><p>虽然平均绝对误差能够获得一个评价值，但是你并不知道这个值代表模型拟合是优还是劣，只有通过对比才能达到效果。当需要以相对的观点来衡量误差时，则使用MAPE。</p>
<p><strong>平均绝对百分误差</strong>（<strong>Mean Absolute Percentage Error，MAPE</strong>）是对 MAE 的一种改进，考虑了绝对误差相对真实值的比例。</p>
<ul>
<li><strong>优点</strong>：考虑了预测值与真实值的误差。考虑了误差与真实值之间的比例。</li>
</ul>
<p><img src="/.io//equation-20230416162051160" alt="公式"></p>
<blockquote>
<p>  在某些场景下，如房价从 <img src="/.io//equation-20230416162051155" alt="公式"> 到 <img src="/.io//equation-20230416162051238" alt="公式"> 之间，<img src="https://www.zhihu.com/equation?tex=5K" alt="公式"> 预测成 <img src="/.io//equation-20230416162051191" alt="公式"> 与 <img src="https://www.zhihu.com/equation?tex=50K" alt="公式"> 预测成 <img src="/.io//equation-20230416162051244" alt="公式"> 的差别是非常大的，而平均绝对百分误差考虑到了这点。</p>
</blockquote>
<h2 id="三、相似性度量指标"><a href="#三、相似性度量指标" class="headerlink" title="三、相似性度量指标"></a>三、相似性度量指标</h2><blockquote>
<p>  机器学习中的相似性度量方法 - 天下客的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/411876558">https://zhuanlan.zhihu.com/p/411876558</a></p>
</blockquote>
<p>描述样本之间相似度的方法有很多种，一般来说常用的有相关系数和欧式距离。本文对机器学习中常用的相似性度量方法进行了总结。<strong>在做分类时，常常需要估算不同样本之间的相似性度量（Similarity Measurement），</strong>这时通常采用的方法就是计算样本间的“距离”（distance）。采用什么样的方法计算距离是很讲究的，甚至关系到分类的正确与否。</p>
<ul>
<li><strong>欧式距离</strong>：k-means</li>
<li><strong>曼哈顿距离</strong>：</li>
<li><strong>切比雪夫距离</strong>：</li>
<li>闵可夫斯基距离</li>
<li>标准化欧氏距离</li>
<li>马氏距离</li>
<li><a href="https://www.zhihu.com/search?q=%E5%A4%B9%E8%A7%92%E4%BD%99%E5%BC%A6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%2255493039%22%7D">夹角余弦</a></li>
<li><strong>汉明距离</strong>：simhash</li>
<li><strong>杰卡德距离&amp;杰卡德相似系数</strong>: <strong>杰卡德相似系数是衡量两个集合的相似度一种指标。</strong></li>
<li>相关系数&amp;相关距离</li>
<li>信息熵</li>
</ul>
<h2 id="四、推荐算法评价指标"><a href="#四、推荐算法评价指标" class="headerlink" title="四、推荐算法评价指标"></a>四、推荐算法评价指标</h2><ul>
<li>推荐算法评价指标 - 一干正事就犯困的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/359528909">https://zhuanlan.zhihu.com/p/359528909</a></li>
</ul>
<h4 id="4-1-AP"><a href="#4-1-AP" class="headerlink" title="4.1 AP"></a>4.1 AP</h4><p><code>AP</code> 衡量的是训练好的模型在每个类别上的好坏；</p>
<img src="/.io//v2-e8656365e7eee25065d6bdfec33368e5_1440w-20230416162048752.jpg" alt="img" style="zoom: 67%;">

<p><strong>AP总结了一个精确召回曲线，作为在每个阈值处获得的精度的加权平均值，并且与以前的阈值相比，召回率的增加用作权重</strong>：</p>
<img src="/.io//image-20220711160205051.png" alt="image-20220711160205051" style="zoom:50%;">

<p>其中和分别是第n个阈值[1]时的精度和召回率。此实现未进行插值，并且与使用梯形规则计算精确调用曲线下的面积有所不同，后者使用线性插值并且可能过于乐观。</p>
<h4 id="4-2-MAP"><a href="#4-2-MAP" class="headerlink" title="4.2 MAP"></a>4.2 MAP</h4><p><strong>MAP（Mean Average Precision）常用于排序任务，MAP的计算涉及另外两个指标：Precision和Recall</strong></p>
<ul>
<li><strong>Precision和Precision@k</strong></li>
</ul>
<p>推荐算法中的精度precision计算如下： </p>
<p><img src="/.io//equation-20230416162051242" alt="[公式]"></p>
<p>可以看出Precision的计算没有考虑结果列表中item的顺序，Precision@k则通过切片的方式将顺序隐含在结果中。Precision@k表示列表前k项的Precision，随着k的变化，可以得到一系列precision值，用 <img src="/.io//equation-20230416162051298" alt="[公式]"> 表示。</p>
<ul>
<li><strong>Recall和Recall@k</strong></li>
</ul>
<p>推荐算法中的召回率recall计算如下：</p>
<p><img src="/.io//equation-20230416162051263" alt="[公式]"></p>
<p>与Precision@k相似，recall@k表示结果列表前k项的recall，随着k的变化，可以得到一系列的recall值，用 <img src="/.io//equation-20230416162051297" alt="[公式]"> 表示。</p>
<ul>
<li><h5 id="AP-N"><a href="#AP-N" class="headerlink" title="AP@N"></a>AP@N</h5></li>
</ul>
<p>AP（Average Precision）平均精度的计算以Precision@k为基础，可以体现出结果列表中item顺序的重要性，其计算过程如下： </p>
<p><img src="/.io//equation-20230416162051331" alt="[公式]"></p>
<p>其中，N表示要求推荐的N个item，m表示所有相关的item总数， <img src="/.io//equation-20230416162051506" alt="[公式]"> 表示第k个item是否相关，相关为1，反之为0</p>
<p><strong>AP@N的值越大，表示推荐列表中相关的item数量越多以及相关item的排名越靠前</strong></p>
<ul>
<li><h5 id="MAP-N"><a href="#MAP-N" class="headerlink" title="MAP@N"></a>MAP@N</h5></li>
</ul>
<p><strong>AP@N评价了算法对单个用户的性能，MAP@N则是算法对多个用户的平均值，是平均数的平均，其计算过程如下</strong>：</p>
<p><img src="/.io//equation-20230416162051575" alt="[公式]"></p>
<h2 id="五、聚类算法评价指标"><a href="#五、聚类算法评价指标" class="headerlink" title="五、聚类算法评价指标"></a>五、聚类算法评价指标</h2><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/343667804">https://zhuanlan.zhihu.com/p/343667804</a></p>
<p>  十分钟掌握聚类算法的评估指标：<a href="https://juejin.cn/post/6997913127572471821">https://juejin.cn/post/6997913127572471821</a></p>
</blockquote>
<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>如同之前介绍的其它算法模型一样，对于聚类来讲我们同样会通过一些评价指标来衡量聚类算法的优与劣。在聚类任务中，常见的评价指标有：<strong>纯度（Purity）</strong>、<strong>兰德系数（Rand Index, RI）</strong>、<strong>F值（F-score）</strong>和<strong>调整兰德系数（Adjusted Rand Index,ARI）</strong>。同时，这四种评价指标也是聚类相关论文中出现得最多的评价方法。下面，我们就来对这些算法一一进行介绍。</p>
<img src="/.io//v2-e62c8b4b793c89b1cd70f2aaebf690c6_1440w-20230416162048995.jpg" alt="img" style="zoom: 67%;">

<p>好的聚类算法，一般要求类簇具有：</p>
<ul>
<li><strong>簇内 (intra-cluster) 相似度高</strong></li>
<li><strong>簇间 (inter-cluster) 相似度底</strong></li>
</ul>
<p>一般来说，评估聚类质量有两个标准，内部评估评价指标和外部评估指标。</p>
<h3 id="【外部评估】"><a href="#【外部评估】" class="headerlink" title="【外部评估】"></a>【外部评估】</h3><h3 id="5-1聚类纯度-聚类的准确率"><a href="#5-1聚类纯度-聚类的准确率" class="headerlink" title="5.1聚类纯度 - 聚类的准确率"></a><strong>5.1聚类纯度</strong> - 聚类的准确率</h3><p>在聚类结果的评估标准中，一种最简单最直观的方法就是计算它的<strong>聚类纯度</strong>（purity），别看纯度听起来很陌生，但实际上和<strong>分类问题中的准确率有着异曲同工之妙</strong>。因为聚类纯度的总体思想也<strong>用聚类正确的样本数除以总的样本数，因此它也经常被称为聚类的准确率</strong>。只是对于聚类后的结果我们并不知道每个簇所对应的真实类别，因此需要取每种情况下的最大值。具体的，纯度的计算公式定义如下：</p>
<p><img src="/.io//equation-20230416162051527" alt="[公式]"></p>
<p>其中<img src="/.io//equation-20230416162051524" alt="[公式]">表示总的样本数；<img src="/.io//equation?tex=/Omega%253D/%7B/omega_1%252C/omega_2%252C..-20230416162051525.%252C/omega_K/%7D" alt="[公式]">表示一个个聚类后的簇，而<img src="/.io//equation?tex=/mathbb%7BC%7D%253D/%7Bc_1%252C_2%252C..-20230416162051543.c_J/%7D" alt="[公式]">表示正确的类别；<img src="/.io//equation-20230416162051815" alt="[公式]">表示聚类后第<img src="/.io//equation-20230416162051616" alt="[公式]">个簇中的所有样本，<img src="/.io//equation-20230416162051619" alt="[公式]">表示第<img src="/.io//equation-20230416162051612" alt="[公式]">个类别中真实的样本。在这里<img src="/.io//equation-20230416162051679" alt="[公式]">的取值范围为<img src="/.io//equation-20230416162051779" alt="[公式]">，越大表示聚类效果越好。</p>
<h3 id="5-2-兰德系数与F值-同簇混淆矩阵"><a href="#5-2-兰德系数与F值-同簇混淆矩阵" class="headerlink" title="5.2 兰德系数与F值  [同簇混淆矩阵]"></a><strong>5.2 兰德系数与F值</strong>  [同簇混淆矩阵]</h3><p>在介绍完了纯度这一评价指标后，我们再来看看兰德系数（Rand Index）和F值。虽然兰德系数听起来是一个陌生的名词，但它的计算过程却也与准确率的计算过程类似。同时，虽然这里也有一个叫做F值的指标，并且它的计算过程也和分类指标中的F值类似，但是两者却有着本质的差别。说了这么多，那这两个指标到底该怎么算呢？同分类问题中的混淆矩阵类似，这里我们也要先定义四种情况进行计数，然后再进行指标的计算。</p>
<p><strong>为了说明兰德系数背后的思想，我们还是以图1中的聚类结果为例进行说明（为了方便观察，我们再放一张图在这里）:</strong></p>
<img src="/.io//v2-e62c8b4b793c89b1cd70f2aaebf690c6_1440w-20230416162048995.jpg" alt="img" style="zoom: 67%;">

<ul>
<li><img src="/.io//equation-20230416162051924" alt="[公式]">：表示两个<strong>同类样本点</strong>在<strong>同一个簇</strong>（布袋）中的情况数量；</li>
<li><img src="/.io//equation-20230416162051734" alt="[公式]">：表示两个<strong>非同类样本点</strong>在<strong>同一个簇</strong>中的情况数量；</li>
<li><img src="/.io//equation-20230416162051915" alt="[公式]">：表示两个<strong>非同类样本点</strong>分别在<strong>两个簇</strong>中的情况数量；</li>
<li><img src="/.io//equation-20230416162051935" alt="[公式]">：表示两个同类样本点分别在<strong>两个簇</strong>中的情况数量；</li>
</ul>
<p>由此，我们便能得到如下所示的对<strong>混淆矩阵（Pair Confusion Matrix）</strong>：</p>
<img src="/.io//v2-a9e709a995b006be04d026aebc721c4e_1440w-20230416162049533.png" alt="img" style="zoom:75%;">

<p>有了上面各种情况的统计值，我们就可以定义出兰德系数和F值的计算公式：</p>
<p><img src="/.io//equation-20230416162051911" alt="[公式]"><img src="/.io//equation-20230416162051996" alt="[公式]"></p>
<p>从上面的计算公式来看，<img src="/.io//equation-20230416162051993" alt="[公式]">从形式上看都非常像分类问题中的准确率与F值，但是有着本质的却别。同时，在这里<img src="/.io//equation-20230416162052007" alt="[公式]">和<img src="/.io//equation-20230416162047757" alt="[公式]">的取值范围均为<img src="/.io//equation-20230416162051779" alt="[公式]">，越大表示聚类效果越好。</p>
<h4 id="5-3-调整兰德系数（Adjusted-Rand-index）【归一化】"><a href="#5-3-调整兰德系数（Adjusted-Rand-index）【归一化】" class="headerlink" title="5.3 调整兰德系数（Adjusted Rand index）【归一化】"></a>5.3 调整兰德系数（Adjusted Rand index）【归一化】</h4><p>对于随机结果，RI并不能保证分数接近零。<strong>为了实现“在聚类结果随机产生的情况下，指标应该接近零”</strong>，调整兰德系数（Adjusted rand index）被提出，它具有更高的区分度。</p>
<p>其公式为：<br>$$<br>\mathrm{ARI}&#x3D;\frac{\mathrm{RI}-E[\mathrm{RI}]}{\max (\mathrm{RI})-E[\mathrm{RI}]}<br>$$<br>$A R$ 取值范围为 $[-1,1]$, 值越大意味着聚类结果与真实情况越吻合。从广义的角度来讲, ARI衡量的是两个数据分布的吻合程度。</p>
<p>优点:</p>
<ul>
<li>对任意数量的聚类中心和样本数, 随机聚类的ARI都非常接近于 0 。</li>
<li>取值在 $[-1,1]$ 之间, 负数代表结果不好, 越接近于1越好。</li>
<li>对簇的结构不需作出任何假设：可以用于比较聚类算法。</li>
</ul>
<p>缺点:</p>
<ul>
<li>ARI 需要 ground truth classes 的相关知识, ARI需要真实标签, 而在实践中几乎不可用, 或者需要人工 标注者手动分配（如在监督学习环境中）。</li>
</ul>
<h3 id="5-4-标准化互信息（NMI-Normalized-Mutual-Information）"><a href="#5-4-标准化互信息（NMI-Normalized-Mutual-Information）" class="headerlink" title="5.4  标准化互信息（NMI, Normalized Mutual Information）"></a>5.4 <strong><font color="red"> 标准化互信息（NMI, Normalized Mutual Information）</font></strong></h3><p>互信息是用来衡量两个数据分布的吻合程度。它也是一有用的信息度量，它是指两个事件集合之间的相关性。互信息越大，词条和类别的相关程度也越大。</p>
<h3 id="【内部指标】"><a href="#【内部指标】" class="headerlink" title="【内部指标】"></a>【内部指标】</h3><p>内部评估指标主要基于数据集的集合结构信息从紧致性、分离性、连通性和重叠度等方面对聚类划分进行评价。即基于数据聚类自身进行评估的。</p>
<h3 id="5-5-轮廓系数（Silhouette-Coefficient）"><a href="#5-5-轮廓系数（Silhouette-Coefficient）" class="headerlink" title="5.5  轮廓系数（Silhouette Coefficient）"></a>5.5 <strong><font color="red"> 轮廓系数（Silhouette Coefficient）</font></strong></h3><p>轮廓系数适用于实际类别信息未知的情况。</p>
<p>对于单个样本，设<strong>a是与它同类别中其他样本的平均距离</strong>，<strong>b是与它距离最近不同类别中样本的平均距离</strong>，其轮廓系数为：</p>
<p>$s &#x3D; \frac {b-a} {max(a, b)}$</p>
<p>对于一个样本集合，它的轮廓系数是所有样本轮廓系数的平均值。轮廓系数的取值范围是[-1,1]，同类别样本距离越相近，不同类别样本距离越远，值越大。当值为负数时，说明聚类效果很差。</p>
<h3 id="5-6-Calinski-Harabaz指数（Calinski-Harabaz-Index）"><a href="#5-6-Calinski-Harabaz指数（Calinski-Harabaz-Index）" class="headerlink" title="5.6 Calinski-Harabaz指数（Calinski-Harabaz Index）"></a>5.6 Calinski-Harabaz指数（Calinski-Harabaz Index）</h3><p>在真实的分群label不知道的情况下，Calinski-Harabasz可以作为评估模型的一个指标。</p>
<p>Calinski-Harabasz指数通过<strong>计算类中各点与类中心的距离平方和来度量类内的紧密度</strong>，通过**&#x3D;&#x3D;计算各类中心点与数据集中心点距离平方和来度量数据集的分离度&#x3D;&#x3D;<strong>，CH指标</strong>由分离度与紧密度的比值得到**。从而，CH越大代表着类自身越紧密，类与类之间越分散，即更优的聚类结果。</p>
<p><strong>优点</strong></p>
<ul>
<li>当簇的密集且分离较好时，分数更高。</li>
<li>得分计算很快，与轮廓系数的对比，最大的优势：快！相差几百倍！毫秒级。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>凸的簇的CH指数通常高于其他类型的簇。例如，通过 DBSCAN 获得基于密度的簇；所以，不适合基于密度的聚类算法（DBSCAN）。</li>
</ul>
<h3 id="5-7-戴维森堡丁指数（DBI-Davies-Bouldin-Index）"><a href="#5-7-戴维森堡丁指数（DBI-Davies-Bouldin-Index）" class="headerlink" title="5.7 戴维森堡丁指数（DBI, Davies-Bouldin Index）"></a>5.7 戴维森堡丁指数（DBI, Davies-Bouldin Index）</h3><p><strong>DB指数是计算任意两类别的类内距离平均距离之和除以两聚类中心距离求最大值</strong>。DB越小，意味着类内距 离越小同时类间距离越大。<strong>零是可能的最低值, 接近零的值表示更好的分区</strong>。<br>$$<br>\begin{gathered}<br>R_{i j}&#x3D;\frac{s_{i}+s_{j}}{d_{i j}} \<br>D B&#x3D;\frac{1}{k} \sum_{i&#x3D;1}^{k} \max <em>{i \neq j} R</em>{i j}<br>\end{gathered}<br>$$<br>其中, $s_{i}$ 表示簇的每个点与该簇的质心之间的平均距离, 也称为簇直径。 $d_{i j}$ 表示聚类和的质心之间的距 离。<br>算法生成的聚类结果越是朝着簇内距离最小（类内相似性最大）和笶间距离最大（类间相似性最小）变化， 那么Davies-Bouldin指数就会越小。<br><strong>缺点</strong>:</p>
<ul>
<li>因使用欧式距离, 所以对于环状分布聚类评测很差。</li>
</ul>
<h2 id="六、评分总结（sklearn）"><a href="#六、评分总结（sklearn）" class="headerlink" title="六、评分总结（sklearn）"></a>六、评分总结（sklearn）</h2><blockquote>
<p>  sklearn.metrics - 回归&#x2F;分类模型的评估方法:<a href="https://zhuanlan.zhihu.com/p/408078074">https://zhuanlan.zhihu.com/p/408078074</a></p>
</blockquote>
<h3 id="6-1-分类模型"><a href="#6-1-分类模型" class="headerlink" title="6.1 分类模型"></a>6.1 分类模型</h3><h4 id="accuracy-score"><a href="#accuracy-score" class="headerlink" title="accuracy_score"></a><strong>accuracy_score</strong></h4><p><strong>分类准确率分数是指所有分类正确的百分比</strong>。分类准确率这一衡量分类器的标准比较容易理解，但是它不能告诉你响应值的潜在分布，并且它也不能告诉你分类器犯错的类型。所以在使用的时候，一般需要搭配matplotlib等数据可视化工具来观察预测的分类情况，与实际的结果做更加直观的比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score  </span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>]  </span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]  </span><br><span class="line">accuracy_score(y_true, y_pred)  <span class="comment"># 默认normalization = True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.5</span></span><br><span class="line">accuracy_score(y_true, y_pred, normalize=<span class="literal">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">2</span></span><br></pre></td></tr></table></figure>

<h4 id="recall-score"><a href="#recall-score" class="headerlink" title="recall_score"></a><strong>recall_score</strong></h4><p>召回率 &#x3D;<strong>提取出的正确信息条数 &#x2F;样本中的信息条数</strong>。通俗地说，就是所有准确的条目有多少被检索出来了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">recall_score(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>,average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">参数average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br></pre></td></tr></table></figure>

<p>将一个二分类matrics拓展到多分类或多标签问题时，我们可以将数据看成多个二分类问题的集合，每个类都是一个二分类。接着，我们可以通过跨多个分类计算每个二分类metrics得分的均值，这在一些情况下很有用。你可以使用<strong>average参数</strong>来指定。 </p>
<ul>
<li>macro：计算二分类metrics的均值，为每个类给出相同权重的分值。</li>
<li>weighted:对于不均衡数量的类来说，计算二分类metrics的平均，通过在每个类的score上进行加权实现。 </li>
<li>micro：给出了每个样本类以及它对整个metrics的贡献的pair（sample-weight），而非对整个类的metrics求和，它会每个类的metrics上的权重及因子进行求和，来计算整个份额。</li>
<li>samples：应用在multilabel问题上。它不会计算每个类，相反，它会在评估数据中，通过计算真实类和预测类的差异的metrics，来求平均（sample_weight-weighted） </li>
<li>average：average&#x3D;None将返回一个数组，它包含了每个类的得分.</li>
</ul>
<h4 id="roc-curve"><a href="#roc-curve" class="headerlink" title="roc_curve"></a><strong>roc_curve</strong></h4><p>ROC曲线指受试者工作特征曲线&#x2F;接收器操作特性(receiver operating characteristic，ROC)曲线,是<strong>反映灵敏性和特效性连续变量的综合指标</strong>,是用构图法揭示敏感性和特异性的相互关系，它通过将连续变量设定出多个不同的临界值，从而计算出一系列敏感性和特异性。ROC曲线是根据一系列不同的二分类方式（分界值或决定阈），<strong>以真正例率（也就是灵敏度）（True Positive Rate,TPR）为纵坐标，假正例率（1-特效性）（False Positive Rate,FPR）为横坐标</strong>绘制的曲线。</p>
<p>通过ROC我们可以观察到模型正确识别的正例的比例与模型错误地把负例数据识别成正例的比例之间的权衡。TPR的增加以FPR的增加为代价。ROC曲线下的面积是模型准确率的度量，<strong>AUC</strong>（Area under roc curve）。</p>
<p><strong>TPR</strong> &#x3D; TP &#x2F;（TP + FN） （正样本<strong>预测数</strong> &#x2F; 正样本<strong>实际数</strong>）</p>
<p><strong>FPR</strong> &#x3D; FP &#x2F;（FP + TN） （负样本<strong>预测数</strong> &#x2F;负样本<strong>实际数</strong>）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics  </span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>])  </span><br><span class="line">scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=<span class="number">2</span>)  </span><br><span class="line">fpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.</span> ,  <span class="number">0.5</span>,  <span class="number">0.5</span>, <span class="number">1.</span> ])  </span><br><span class="line">tpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.5</span>,  <span class="number">0.5</span>,  <span class="number">1.</span> , <span class="number">1.</span> ])  </span><br><span class="line">thresholds  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.8</span> ,  <span class="number">0.4</span> ,  <span class="number">0.35</span>, <span class="number">0.1</span> ])  </span><br><span class="line"></span><br><span class="line"><span class="comment"># check auc score</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> auc   </span><br><span class="line">metrics.auc(fpr, tpr)   </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以直接根据预测值+真实值来计算出auc值，略过roc的计算过程</span></span><br><span class="line">‘’‘</span><br><span class="line">sklearn.metrics.roc_auc_score(y_true, y_score, average=<span class="string">&#x27;macro&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br><span class="line">’‘’</span><br><span class="line"><span class="comment"># 真实值（必须是二值）、预测值（可以是0/1,也可以是proba值）</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score  </span><br><span class="line">y_true = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])  </span><br><span class="line">y_scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">roc_auc_score(y_true, y_scores)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>  </span><br></pre></td></tr></table></figure>

<h4 id="confusion-metric"><a href="#confusion-metric" class="headerlink" title="confusion metric"></a><strong>confusion metric</strong></h4><p>混淆矩阵（confusion matrix），又称为可能性表格或是错误矩阵。它是一种特定的矩阵用来呈现算法性能的可视化效果。其每一列代表预测值，每一行代表的是实际的类别。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">confusion_matric(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>, average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<h4 id="precision-score"><a href="#precision-score" class="headerlink" title="precision_score"></a><strong>precision_score</strong></h4><p>计算精确度——precision <img src="/.io//equation-20230416162052015" alt="[公式]"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">precision_score(y_true, y_pred, labels=None, pos_label=1, average=&#x27;binary&#x27;)</span><br></pre></td></tr></table></figure>

<p><img src="/.io//v2-a3b6092e30d2eab7d2372007aec15105_r-20230416162050205.jpg" alt="preview"></p>
<h2 id="评价指标Q-amp-A"><a href="#评价指标Q-amp-A" class="headerlink" title="评价指标Q&amp;A"></a>评价指标Q&amp;A</h2><h4 id="精度指标存在的问题？"><a href="#精度指标存在的问题？" class="headerlink" title="精度指标存在的问题？"></a><strong>精度指标存在的问题</strong>？</h4><ul>
<li>有倾向性的问题。比如，判断空中的飞行物是导弹还是其他飞行物，很显然为了减少损失，我们更倾向于相信是导弹而采用相应的防护措施。此时判断为导弹实际上是其他飞行物与判断为其他飞行物实际上是导弹这两种情况的重要性是不一样的；</li>
<li>样本类别数量严重不均衡的情况。比如银行客户样本中好客户990个，坏客户10个。如果一个模型直接把所有客户都判断为好客户，得到精度为99%，但这显然是没有意义的。</li>
</ul>
<h4 id="为什么-ROC-和-AUC-都能应用于非均衡的分类问题？"><a href="#为什么-ROC-和-AUC-都能应用于非均衡的分类问题？" class="headerlink" title="为什么 ROC 和 AUC 都能应用于非均衡的分类问题？"></a><strong>为什么 ROC 和 AUC 都能应用于非均衡的分类问题？</strong></h4><p><strong>ROC曲线只与横坐标 (FPR) 和 纵坐标 (TPR) 有关系</strong> 。我们可以发现TPR只是正样本中预测正确的概率，而FPR只是负样本中预测错误的概率，和正负样本的比例没有关系。因此 ROC 的值与实际的正负样本比例无关，因此既可以用于均衡问题，也可以用于非均衡问题。而 AUC 的几何意义为ROC曲线下的面积，因此也和实际的正负样本比例无关。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习理论</title>
    <url>/2023/04/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/</url>
    <content><![CDATA[<h1 id="机器学习理论"><a href="#机器学习理论" class="headerlink" title="机器学习理论"></a>机器学习理论</h1><h3 id="一、-机器学习中参数模型和非参数模型理解"><a href="#一、-机器学习中参数模型和非参数模型理解" class="headerlink" title="一、 机器学习中参数模型和非参数模型理解"></a><strong>一、 <a href="https://blog.csdn.net/FrankieHello/article/details/94022594">机器学习中参数模型和非参数模型理解</a></strong></h3><p><strong>参数模型通常假设总体服从某个分布，这个分布可以由一些参数确定，如正态分布由均值和标准差确定，在此基础上构建的模型称为参数模型</strong>；非参数模型对于总体的分布不做任何假设或者说是数据分布假设自由，只知道其分布是存在的，所以就无法得到其分布的相关参数，只能通过非参数统计的方法进行推断。</p>
<p><strong>参数模型</strong>：线性回归、逻辑回归、感知机、基本型的SVM</p>
<p><strong>非参数模型</strong>：决策树、对偶型的SVM、朴素贝叶斯、神经网络</p>
<h3 id="二、-判别模型-VS-生成模型"><a href="#二、-判别模型-VS-生成模型" class="headerlink" title="二、 判别模型 VS 生成模型"></a>二、 判别模型 VS 生成模型</h3><blockquote>
<p>  判别模型与生成模型，概率模型与非概率模型、参数模型与非参数模型总结 - Eureka的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/37821985">https://zhuanlan.zhihu.com/p/37821985</a></p>
<p>  <strong>机器学习中的判别式模型和生成式模型</strong> - Microstrong的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/74586507">https://zhuanlan.zhihu.com/p/74586507</a></p>
</blockquote>
<img src="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-9b345d3e93a81dc4e7a88fccff3720b3_b-1633296.png" alt="img" style="zoom: 67%;" />



<h5 id="判别模型：感知机、逻辑斯特回归、支持向量机、神经网络、k近邻都属于判别学习模型。"><a href="#判别模型：感知机、逻辑斯特回归、支持向量机、神经网络、k近邻都属于判别学习模型。" class="headerlink" title="判别模型：感知机、逻辑斯特回归、支持向量机、神经网络、k近邻都属于判别学习模型。"></a>判别模型：感知机、逻辑斯特回归、支持向量机、神经网络、k近邻都属于判别学习模型。</h5><p><strong>判别模型分为两种:</strong></p>
<ul>
<li>直接对输入空间到输出空间的映射进行建模, 也就是学习函数 $h$ :</li>
</ul>
<p>$$<br>h: X \rightarrow Y, s . t . y&#x3D;h(x)<br>$$</p>
<ul>
<li>对条件概率 $P(y \mid x)$ 进行建模, 然后根据贝叶斯风险最小化的准则进行分类: 【</li>
</ul>
<p>$$<br>y&#x3D;\arg \max _{y \in{-1,1}} P(y \mid x)<br>$$</p>
<h5 id="生成模型："><a href="#生成模型：" class="headerlink" title="生成模型："></a>生成模型：</h5><p>生成模型是间接地, 先对 $P(x, y)$ 进行建模, 再根据贝叶斯公式:<br>$$<br>P(y \mid x)&#x3D;\frac{P(x \mid y) P(y)}{P(x)}<br>$$<br>算出 $P(y \mid x)$, 最后根据 $\arg \max _{y \in{-1,1}} P(y \mid x)$ 来做分类 (由此可知, 判别模型实际上不需要对 $P(x, y)$ 进行建模)。</p>
<h3 id="三、-非概率模型-VS-概率模型"><a href="#三、-非概率模型-VS-概率模型" class="headerlink" title="三、 非概率模型 VS 概率模型"></a>三、 非概率模型 VS 概率模型</h3><p>两者的本质区别在于是否涉及到概率分布。</p>
<h4 id="概率模型"><a href="#概率模型" class="headerlink" title="概率模型"></a><strong>概率模型</strong></h4><blockquote>
<p>  <strong>线性回归（高斯分布）、LR（伯努利分布）、高斯判别分析、朴素贝叶斯</strong></p>
</blockquote>
<p><strong>概率模型指出了学习的目的是学出 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137110" alt="[公式]"> 或 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137088" alt="[公式]">，但最后都是根据 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137141" alt="[公式]"> 来做判别归类</strong>。对于 <img src="https://www.zhihu.com/equation?tex=P(x,y)" alt="[公式]"> 的估计，一般是根据乘法公式 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137082" alt="[公式]"> 将其拆解成 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137078" alt="[公式]"> 分别进行估计。无论是对 <img src="https://www.zhihu.com/equation?tex=P(x%7Cy),P(y)" alt="[公式]"> 还是 <img src="https://www.zhihu.com/equation?tex=P(y%7Cx)" alt="[公式]"> 的估计，都是会先假设分布的形式，例如逻辑斯特回归就假设了 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137091" alt="[公式]"> 服从伯努利分布。分布形式固定以后，剩下的就是分布参数的估计问题。<strong>常用的估计有极大似然估计(MLE)和极大后验概率估计(MAP)等</strong>。其中，极大后验概率估计涉及到分布参数的先验概率，这为我们注入先验知识提供了途径。逻辑斯特回归、高斯判别分析、朴素贝叶斯都属于概率模型。</p>
<p>在一定的条件下，非概率模型与概率模型有以下对应关系:</p>
<img src="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-70105273742bb35eba11ec79151573cc_1440w-1633296.jpg" alt="img" style="zoom:50%;" />

<h4 id="非概率模型"><a href="#非概率模型" class="headerlink" title="非概率模型"></a>非概率模型</h4><blockquote>
<p>  <strong>感知机、支持向量机、神经网络、k近邻都属于非概率模型</strong>。线性支持向量机可以显式地写出损失函数——hinge损失。神经网络也可以显式地写出损失函数——平方损失。</p>
</blockquote>
<p><strong>非概率模型指的是直接学习输入空间到输出空间的映射 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137167" alt="[公式]"> ，学习的过程中基本不涉及概率密度的估计，概率密度的积分等操作，问题的关键在于最优化问题的求解</strong>。通常，为了学习假设 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137214" alt="[公式]"> ，我们会先根据一些先验知识(prior knowledge) 来选择一个特定的假设空间 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137277" alt="[公式]"> (函数空间)，例如一个由所有线性函数构成的空间，然后在这个空间中找出泛化误差最小的假设出来，</p>
<p><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137231" alt="[公式]"></p>
<p>其中 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137222" alt="[公式]"> 是我们选取的损失函数，选择不同的损失函数，得到假设的泛化误差就会不一样。由于我们并不知道 <img src="https://www.zhihu.com/equation?tex=P(x,y)" alt="[公式]"> ，所以即使我们选好了损失函数，也无法计算出假设的泛化误差，更别提找到那个给出最小泛化误差的假设。于是，我们转而去找那个使得经验误差最小的假设，</p>
<p>$$<br>g&#x3D;\arg \min _{h \in H} \hat{\varepsilon}(h)&#x3D;\arg \min <em>{h \in H} \frac{1}{m} \sum</em>{i&#x3D;1}^{m} l\left(h\left(x^{(i)}\right), y^{(i)}\right)<br>$$<br><font color = red> 这种学习的策略叫经验误差最小化(ERM)，理论依据是大数定律：当训练样例无穷多的时候，假设的经验误差会依概率收敛到假设的泛化误差。</font>要想成功地学习一个问题，必须在学习的过程中注入先验知识。前面，我们根据先验知识来选择假设空间，其实，在选定了假设空间后，先验知识还可以继续发挥作用，这一点体现在为我们的优化问题加上正则化项上，例如常用的 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137249" alt="[公式]"> 正则化， <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137321" alt="[公式]"> 正则化等。<br>$$<br>g&#x3D;\arg \min _{h \in H} \hat{\varepsilon}(h)&#x3D;\arg \min <em>{h \in H} \frac{1}{m} \sum</em>{i&#x3D;1}^{m} l\left(h\left(x^{(i)}\right), y^{(i)}\right)+\lambda \Omega(h)<br>$$</p>
<h2 id="四、-过拟合和欠拟合"><a href="#四、-过拟合和欠拟合" class="headerlink" title="四、 过拟合和欠拟合"></a>四、 过拟合和欠拟合</h2><blockquote>
<p>  欠拟合、过拟合及如何防止过拟合 - G-kdom的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/72038532">https://zhuanlan.zhihu.com/p/72038532</a></p>
</blockquote>
<h3 id="4-1-欠拟合"><a href="#4-1-欠拟合" class="headerlink" title="4.1 欠拟合"></a>4.1 欠拟合</h3><p><strong>欠拟合是指模型不能在训练集上获得足够低的误差</strong>。换句换说，就是模型复杂度低，模型在训练集上就表现很差，没法学习到数据背后的规律。</p>
<h3 id="4-2-欠拟合解决方法"><a href="#4-2-欠拟合解决方法" class="headerlink" title="4.2 欠拟合解决方法"></a>4.2 欠拟合解决方法</h3><p>欠拟合基本上都会发生在训练刚开始的时候，经过不断训练之后欠拟合应该不怎么考虑了。但是如果真的还是存在的话，可以通过<strong>增加网络复杂度</strong>或者在模型中<strong>增加特征</strong>，这些都是很好解决欠拟合的方法。</p>
<h3 id="4-3-过拟合"><a href="#4-3-过拟合" class="headerlink" title="4.3 过拟合"></a>4.3 过拟合</h3><p>过拟合是指训练误差和测试误差之间的差距太大。换句换说，就是模型复杂度高于实际问题，<strong>模型在训练集上表现很好，但在测试集上却表现很差</strong>。模型对训练集”死记硬背”（记住了不适用于测试集的训练集性质或特点），没有理解数据背后的规律，<strong>泛化能力差</strong>。</p>
<p>造成原因主要有以下几种：<br>1、<strong>训练数据集样本单一，样本不足</strong>。如果训练样本只有负样本，然后那生成的模型去预测正样本，这肯定预测不准。所以训练样本要尽可能的全面，覆盖所有的数据类型。<br>2、<strong>训练数据中噪声干扰过大</strong>。噪声指训练数据中的干扰数据。过多的干扰会导致记录了很多噪声特征，忽略了真实输入和输出之间的关系。<br>3、<strong>模型过于复杂。</strong>模型太复杂，已经能够“死记硬背”记下了训练数据的信息，但是遇到没有见过的数据的时候不能够变通，泛化能力太差。我们希望模型对不同的模型都有稳定的输出。模型太复杂是过拟合的重要因素。</p>
<h3 id="4-4-如何防止过拟合"><a href="#4-4-如何防止过拟合" class="headerlink" title="4.4 如何防止过拟合"></a>4.4 如何防止过拟合</h3><p>要想解决过拟合问题，就要显著减少测试误差而不过度增加训练误差，从而提高模型的泛化能力。</p>
<h4 id="1、使用正则化（Regularization）方法。"><a href="#1、使用正则化（Regularization）方法。" class="headerlink" title="1、使用正则化（Regularization）方法。"></a>1、<strong>使用正则化（Regularization）方法。</strong></h4><p>那什么是<a href="https://www.zhihu.com/search?q=%E6%AD%A3%E5%88%99%E5%8C%96&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%2272038532%22%7D">正则化</a>呢？<strong>正则化是指修改学习算法，使其降低泛化误差而非训练误差</strong>。</p>
<p>常用的正则化方法根据具体的使用策略不同可分为：（1）直接提供正则化约束的参数正则化方法，如L1&#x2F;L2正则化；（2）通过工程上的技巧来实现更低泛化误差的方法，如提前终止(Early stopping)和Dropout；（3）不直接提供约束的隐式正则化方法，如数据增强等。</p>
<p><strong>L2正则化起到使得权重参数 <img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/equation-20230416162137359" alt="[公式]"> 变小的效果，为什么能防止过拟合呢？</strong>因为更小的权重参数 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> 意味着模型的复杂度更低，对训练数据的拟合刚刚好，不会过分拟合训练数据，从而提高模型的泛化能力。</p>
<h4 id="2、获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法"><a href="#2、获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法" class="headerlink" title="2、获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法"></a>2、<strong>获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法</strong></h4><p>让机器学习或深度学习模型泛化能力更好的办法就是使用更多的数据进行训练。但是，在实践中，我们拥有的数据量是有限的。解决这个问题的一种方法就是<strong>创建“假数据”并添加到训练集中——数据集增强</strong>。通过增加训练集的额外副本来增加训练集的大小，进而改进模型的泛化能力。</p>
<p>我们以图像数据集举例，能够做：旋转图像、缩放图像、随机裁剪、加入随机噪声、平移、镜像等方式来增加数据量。另外补充一句，在物体分类问题里，<strong>CNN在图像识别的过程中有强大的“不变性”规则，即待辨识的物体在图像中的形状、姿势、位置、图像整体明暗度都不会影响分类结果</strong>。我们就可以通过图像平移、翻转、缩放、切割等手段将数据库成倍扩充。</p>
<h4 id="3-采用合适的模型（控制模型的复杂度）"><a href="#3-采用合适的模型（控制模型的复杂度）" class="headerlink" title="3. 采用合适的模型（控制模型的复杂度）"></a><strong>3. 采用合适的模型（控制模型的复杂度）</strong></h4><p>过于复杂的模型会带来过拟合问题。对于模型的设计，目前公认的一个深度学习规律”deeper is better”。国内外各种大牛通过实验和竞赛发现，对于CNN来说，层数越多效果越好，但是也更容易产生过拟合，并且计算所耗费的时间也越长。</p>
<p>根据<strong>奥卡姆剃刀法则</strong>：在同样能够解释已知观测现象的假设中，我们应该挑选“最简单”的那一个。对于模型的设计而言，我们应该<strong>选择简单、合适的模型解决复杂的问题</strong>。</p>
<h4 id="4-降低特征的数量"><a href="#4-降低特征的数量" class="headerlink" title="4. 降低特征的数量"></a><strong>4. 降低特征的数量</strong></h4><p>对于一些特征工程而言，可以降低特征的数量——删除冗余特征，人工选择保留哪些特征。这种方法也可以解决过拟合问题。</p>
<h4 id="5-Dropout"><a href="#5-Dropout" class="headerlink" title="5. Dropout"></a><strong>5. Dropout</strong></h4><p>Dropout是在训练网络时用的一种技巧（trike），相当于在隐藏单元增加了噪声。<strong>Dropout 指的是在训练过程中每次按一定的概率（比如50%）随机地“删除”一部分隐藏单元（神经元）。</strong>所谓的“删除”不是真正意义上的删除，其实就是将该部分神经元的激活函数设为0（激活函数的输出为0），让这些神经元不计算而已。</p>
<p><strong>Dropout为什么有助于防止过拟合呢？</strong></p>
<p>（a）在训练过程中会产生不同的训练模型，不同的训练模型也会产生不同的的计算结果。随着训练的不断进行，计算结果会在一个范围内波动，但是均值却不会有很大变化，因此可以把最终的训练结果看作是不同模型的平均输出。</p>
<p>（b）它消除或者减弱了神经元节点间的联合，降低了网络对单个神经元的依赖，从而增强了泛化能力。</p>
<h4 id="6-Early-stopping（提前终止）"><a href="#6-Early-stopping（提前终止）" class="headerlink" title="6. Early stopping（提前终止）"></a><strong>6. Early stopping（提前终止）</strong></h4><p>对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如<a href="https://www.zhihu.com/search?q=%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%2272038532%22%7D">梯度下降</a>（Gradient descent）。<strong>Early stopping是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合</strong>。</p>
<p>为了获得性能良好的神经网络，训练过程中可能会经过很多次<a href="https://www.zhihu.com/search?q=epoch&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%2272038532%22%7D">epoch</a>（遍历整个数据集的次数，一次为一个epoch）。如果epoch数量太少，网络有可能发生欠拟合；如果epoch数量太多，则有可能发生过拟合。Early <a href="https://www.zhihu.com/search?q=stopping&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%2272038532%22%7D">stopping</a>旨在解决epoch数量需要手动设置的问题。具体做法：<strong>每个epoch（或每N个epoch）结束后，在验证集上获取测试结果，随着epoch的增加，如果在验证集上发现测试误差上升，则停止训练，将停止之后的权重作为网络的最终参数。</strong></p>
<p><strong>为什么能防止过拟合？</strong>当还未在神经网络运行太多迭代过程的时候，w参数接近于0，因为随机初始化<a href="https://www.zhihu.com/search?q=w%E5%80%BC&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%2272038532%22%7D">w值</a>的时候，它的值是较小的随机值。当你开始迭代过程，w的值会变得越来越大。到后面时，w的值已经变得十分大了。所以early stopping要做的就是在中间点停止迭代过程。我们将会得到一个中等大小的w参数，会得到与L2正则化相似的结果，选择了w参数较小的神经网络。</p>
<p><strong>Early Stopping缺点：没有采取不同的方式来解决优化损失函数和过拟合这两个问题</strong>，而是用一种方法同时解决两个问题 ，结果就是要考虑的东西变得更复杂。之所以不能独立地处理，因为如果你停止了优化损失函数，你可能会发现损失函数的值不够小，同时你又不希望过拟合。</p>
<h2 id="五、损失函数-loss-与评价指标-metric-的区别？"><a href="#五、损失函数-loss-与评价指标-metric-的区别？" class="headerlink" title="五、损失函数(loss)与评价指标(metric)的区别？"></a>五、损失函数(loss)与评价指标(metric)的区别？</h2><p><strong>当建立一个学习算法时，我们希望最大化一个给定的评价指标matric（比如说准确度），但算法在学习过程中会尝试优化一个不同的损失函数loss（比如说MSE&#x2F;Cross-entropy）。</strong></p>
<h4 id="那为什么不把评价指标matric作为学习算法的损失函数loss呢？"><a href="#那为什么不把评价指标matric作为学习算法的损失函数loss呢？" class="headerlink" title="那为什么不把评价指标matric作为学习算法的损失函数loss呢？"></a>那为什么不把评价指标matric作为学习算法的损失函数loss呢？</h4><ul>
<li><p>一般来说，我认为你应该尝试优化一个与你最关心的评价指标相对应的损失函数。例如，在做分类时，我认为你需要给我一个很好的理由，让我不要优化交叉熵。也就是说，交叉熵并不是一个非常直观的指标，所以一旦你完成了训练，你可能还想知道你的分类准确率有多高，以了解你的模型是否真的能在现实世界中发挥作用，总之，在每个epoch训练完后，你都会有多个评估指标。这样作的主要原因是为了了解你的模型在做什么。这意味着你想要最大化指标A，以便得到一个接近最大化指标B的解决方案。</p>
</li>
<li><p>通常情况下，MSE&#x2F;交叉熵比精度更容易优化，因为它们对模型参数是可微的，在某些情况下甚至是凸的，这使得它更容易。</p>
</li>
</ul>
<h2 id="六、标准化和归一化"><a href="#六、标准化和归一化" class="headerlink" title="六、标准化和归一化"></a>六、标准化和归一化</h2><blockquote>
<p>  PCA、k-means、SVM、回归模型、<strong>神经网络</strong></p>
</blockquote>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p><strong>归一化和标准化</strong>都是对<strong>数据做变换</strong>的方式，将原始的一列数据转换到某个范围，或者某种形态，具体的：</p>
<blockquote>
<p>  **归一化(Normalization)**：将一列数据变化到某个固定区间(范围)中，通常，这个区间是[0, 1]，广义的讲，可以是各种区间，比如映射到[0，1]一样可以继续映射到其他范围，图像中可能会映射到[0,255]，其他情况可能映射到[-1,1]；</p>
<p>  <strong>标准化(Standardization)<strong>：将数据变换为均值为0，标准差为1的分布切记，</strong>&#x3D;&#x3D;并非一定是正态的；&#x3D;&#x3D;</strong></p>
<p>  <strong>中心化</strong>：另外，还有一种处理叫做中心化，也叫零均值处理，就是将每个原始数据减去这些数据的均值。</p>
</blockquote>
<h4 id="差异"><a href="#差异" class="headerlink" title="差异"></a>差异</h4><blockquote>
<p>  <strong>归一化：对处理后的数据范围有严格要求;</strong></p>
<p>  <strong>标准化:  数据不为稳定，存在极端的最大最小值;  涉及距离度量、协方差计算的时候;</strong></p>
</blockquote>
<ul>
<li><strong>归一化会严格的限定变换后数据的范围</strong>，比如按之前最大最小值处理的，它的范围严格在[ 0 , 1 ]之间；而<strong>标准化</strong>就没有严格的区间，变换后的数据没有范围，只是其均值是0，标准差为1。</li>
<li><strong>归一化的缩放比例仅仅与极值有关</strong>，容易受到异常值的影响。</li>
</ul>
<h4 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h4><ul>
<li>回归模型，自变量X的量纲不一致导致了**&#x3D;&#x3D;回归系数无法直接解读&#x3D;&#x3D;**或者错误解读；需要将X都处理到统一量纲下，这样才可比；</li>
<li>机器学习任务和统计学任务中有很多地方要用到**&#x3D;&#x3D;“距离”的计算&#x3D;&#x3D;**，比如PCA，比如KNN，比如kmeans等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果；</li>
<li>参数估计时使用**&#x3D;&#x3D;梯度下降&#x3D;&#x3D;<strong>，在使用梯度下降的方法求解最优化问题时， 归一化&#x2F;标准化后可以加快梯度下降的求解速度，即</strong>&#x3D;&#x3D;提升模型的收敛速度&#x3D;&#x3D;**。</li>
</ul>
<h4 id="其他：log、sigmod、softmax-变换"><a href="#其他：log、sigmod、softmax-变换" class="headerlink" title="其他：log、sigmod、softmax 变换"></a>其他：log、sigmod、softmax 变换</h4><h2 id="七、回归-vs-分类"><a href="#七、回归-vs-分类" class="headerlink" title="七、回归 vs 分类"></a>七、回归 vs 分类</h2><p>回归问题可以理解为是定量输出的问题，是一个连续变量预测；分类问题可以理解为是定性输出的问题，是一个离散变量预测。</p>
<h1 id="数据基础"><a href="#数据基础" class="headerlink" title="数据基础"></a>数据基础</h1><p><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20220721233129072-1633296.png" alt="image-20220721233129072"></p>
<h4 id="sigmod-交叉熵求导"><a href="#sigmod-交叉熵求导" class="headerlink" title="sigmod 交叉熵求导"></a>sigmod 交叉熵求导</h4><p>交叉熵损失函数为：</p>
<img src="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20220330212904952-1633296.png" alt="image-20220330212904952" style="zoom:50%;" />

<p>其中：</p>
<p><img src="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20220721232846261-1633296.png" alt="image-20220721232846261"></p>
<p>由此，得到：</p>
<img src="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20220330212956623-1633296.png" alt="image-20220330212956623" style="zoom:50%;" />

<p><strong>求导：</strong></p>
<img src="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20220330213027011.png" alt="image-20220330213027011" style="zoom:50%;" />

<p>这就是交叉熵对参数的导数：</p>
<img src="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20220330213041006-1633296.png" alt="image-20220330213041006" style="zoom:50%;" />

<h4 id="平方损失函数【绝对值、hubor损失】为例（GBDT-残差）："><a href="#平方损失函数【绝对值、hubor损失】为例（GBDT-残差）：" class="headerlink" title="平方损失函数【绝对值、hubor损失】为例（GBDT 残差）："></a><strong>平方损失函数</strong>【绝对值、hubor损失】为例（GBDT 残差）：</h4><blockquote>
<p>  $$<br>  \begin{aligned}<br>  &amp;g_{i}&#x3D;\frac{\partial\left(\hat{y}^{t-1}-y_{i}\right)^{2}}{\partial \hat{y}^{t-1}}&#x3D;2\left(\hat{y}^{t-1}-y_{i}\right) \<br>  &amp;h_{i}&#x3D;\frac{\partial^{2}\left(\hat{y}^{t-1}-y_{i}\right)^{2}}{\hat{y}^{t-1}}&#x3D;2<br>  \end{aligned}<br>  $$</p>
</blockquote>
<h4 id="softmax-函数求导"><a href="#softmax-函数求导" class="headerlink" title="softmax 函数求导"></a>softmax 函数求导</h4><p>softmax 回归的参数矩阵 $\theta$ 可以记为<br>$$<br>\theta&#x3D;\left[\begin{array}{c}<br>\theta_{1}^{T} \<br>\theta_{2}^{T} \<br>\vdots \<br>\theta_{k}^{T}<br>\end{array}\right]<br>$$<br>定义 softmax 回归的代价函数<br>$$<br>L(\theta)&#x3D;-\frac{1}{m}\left[\sum_{i&#x3D;1}^{m} \sum_{j&#x3D;1}^{k} 1\left{y_{i}&#x3D;j\right} \log \frac{e^{\theta_{j}^{T} x_{i}}}{\sum_{l&#x3D;1}^{k} e^{\theta_{l}^{T} x_{i}}}\right]<br>$$<br>其中, 1{:}是示性函数, 即 $1{$ 值为真的表达式 $}&#x3D;1 ， 1{$ 值为假的表达式 $}&#x3D;0$ 。跟 logistic 函数一样, 利用梯度下降法最小化代价函数, 下面 求解 $\theta$ 的梯度。 $L(\theta)$ 关于 $\theta_{j}$ 的梯度求解为</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>test</title>
    <url>/2023/04/16/test/</url>
    <content><![CDATA[<blockquote>
<p>  一文看懂机器学习指标：准确率、精准率、召回率、F1、ROC曲线、AUC曲线:<a href="https://zhuanlan.zhihu.com/p/93107394">https://zhuanlan.zhihu.com/p/93107394</a></p>
<p>  <strong>机器学习-最全面的评价指标体系: <a href="https://zhuanlan.zhihu.com/p/359997979">https://zhuanlan.zhihu.com/p/359997979</a></strong></p>
<p>  <a href="https://github.com/HaoMood/homepage/blob/master/files/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8-03-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0.pdf">机器学习工程师面试宝典-03-模型评估</a></p>
<p>  <strong><a href="http://www.china-nb.cn/gongsidongtai/17-85.html">分类模型评估指标——准确率、精准率、召回率、F1、ROC曲线、AUC曲线</a></strong></p>
</blockquote>
<img src="/.io//image-20220421165422230.png" alt="image-20220421165422230" style="zoom:50%;">

<img src="/.io//image-20220421165436795.png" alt="image-20220421165436795" style="zoom:50%;">

<h3 id="一、二分类问题"><a href="#一、二分类问题" class="headerlink" title="一、二分类问题"></a>一、二分类问题</h3><blockquote>
<p>  <strong>阈值调节问题？</strong></p>
</blockquote>
<ul>
<li><strong>准确率 (Accuracy)<strong>：</strong>预测正确的概率</strong>  【**(TP+TN)&#x2F;(TP+TN+FP+FN)**】</li>
<li><strong>精确率（查准率 Precision )：&#x3D;&#x3D;预测为正的样本&#x3D;&#x3D;中实际为正的样本的概率</strong> 【**TP&#x2F;(TP+FP)**】</li>
<li>错误发现率（FDR）&#x3D; 1 - 精确率 &#x3D; &#x3D;&#x3D;预测为正的样本&#x3D;&#x3D;中实际为负的样本的概率 【**FP&#x2F;(TP+FP)**】</li>
<li><strong>召回率（查全率）- Recall</strong>：**&#x3D;&#x3D;实际为正的样本&#x3D;&#x3D;中被预测为正样本的概率<strong>【</strong>TP&#x2F;(TP+FN)**】</li>
<li><strong>真正率（TPR） &#x3D; 灵敏度（&#x3D;&#x3D;召回率&#x3D;&#x3D;） &#x3D;</strong> <strong>TP&#x2F;(TP+FN)</strong></li>
<li><strong>假正率（FPR） &#x3D; 1- 特异度 &#x3D;</strong> <strong>FP&#x2F;(FP+TN)</strong></li>
<li><strong>F1&#x3D;是准确率和召回率的&#x3D;&#x3D;调和平均值&#x3D;&#x3D; (2×Precision×Recall)&#x2F;（Precision+Recall）</strong></li>
<li><strong>G-mean（GM）&#x3D; 是准确率和召回率的&#x3D;&#x3D;几何平均值&#x3D;&#x3D;</strong> <img src="/.io//640-20230416162047009.svg" alt="img"></li>
</ul>
<h3 id="1-1-F1-x3D-2×Precision×Recall-x2F-（Precision-Recall）"><a href="#1-1-F1-x3D-2×Precision×Recall-x2F-（Precision-Recall）" class="headerlink" title="1.1 F1&#x3D;(2×Precision×Recall) &#x2F;（Precision+Recall）"></a>1.1 <strong>F1&#x3D;(2×Precision×Recall) &#x2F;（Precision+Recall）</strong></h3><p>精确率（Precision）和召回率（Recall）之间的关系用图来表达，就是下面的PR曲线。可以发现他们俩的关系是「两难全」的关系。为了综合两者的表现，在两者之间找一个平衡点，就出现了一个 F1分数。</p>
<h4 id="F1-x3D-2×Precision×Recall-x2F-（Precision-Recall）"><a href="#F1-x3D-2×Precision×Recall-x2F-（Precision-Recall）" class="headerlink" title="F1&#x3D;(2×Precision×Recall)  &#x2F;（Precision+Recall）"></a><strong>F1&#x3D;(2×Precision×Recall)  &#x2F;（Precision+Recall）</strong></h4><p>P意义类似于每通过准确预测得到TP个正例需要TP+FP个预测类别为正例的样本。</p>
<p>R意义类似于每通过成功召回得到TP个正例需要TP+FN个真实类别为正例的样本。</p>
<p>F1度量了给定一批样本，对这一批样本进行预测与召回，最终得到的正例的多少。<strong>其中一半的正例是通过预测得到的，一半的正例是通过召回得到的。</strong></p>
<p>有一种把预测所需的预测类别为正例的样本和召回所需的真实类别为正例的样本看作原料，而我们的目标正例样本看作产品的感觉。<strong>所以也能解释为什么P跟R其中一者比较低的时候，F1会偏低。因为跟算术平均数不一样，两者不能互相替代，两部分各负责一半。那么加权调和平均Fbeta也可以很好的理解了。</strong></p>
<p>$$<br>\frac{1}{F_\beta}&#x3D;\frac{1}{1+\beta^2} \cdot\left(\frac{1}{P}+\frac{\beta^2}{R}\right)<br>$$<br>各自负责的比例不一样了。因此beta越大，Fbeta越着重考虑召回能力。</p>
<h3 id="1-2-ROC-x2F-AUC的概念"><a href="#1-2-ROC-x2F-AUC的概念" class="headerlink" title="1.2 ROC&#x2F;AUC的概念"></a>1.2 ROC&#x2F;AUC的概念</h3><p><strong>1. 灵敏度，特异度，真正率，假正率</strong></p>
<p>在正式介绍ROC&#x2F;AUC之前，我们还要再介绍两个指标，<strong>这两个指标的选择也正是ROC和AUC可以无视样本不平衡的原因。</strong> 这两个指标分别是：<strong>灵敏度和（1-特异度），也叫做真正率（TPR）和假正率（FPR）</strong>。其实我们可以发现<strong>灵敏度和召回率是一模一样的，只是名字换了而已</strong>。由于我们比较关心正样本，所以需要查看有多少负样本被错误地预测为正样本，所以使用（1-特异度），而不是特异度。</p>
<p><strong>真正率（TPR） &#x3D; 灵敏度（&#x3D;&#x3D;召回率&#x3D;&#x3D;） &#x3D;</strong> <strong>TP&#x2F;(TP+FN)</strong></p>
<p><strong>假正率（FPR） &#x3D; 1- 特异度 &#x3D;</strong> <strong>FP&#x2F;(FP+TN)</strong></p>
<p>下面是真正率和假正率的示意，我们发现<strong>TPR和FPR分别是基于实际表现1和0出发的，也就是说它们分别在实际的正样本和负样本中来观察相关概率问题。</strong> </p>
<blockquote>
<p>  正因为如此，所以无论样本是否平衡，都不会被影响。还是拿之前的例子，总样本中，90%是正样本，10%是负样本。我们知道用准确率是有水分的，但是用TPR和FPR不一样。这里，TPR只关注90%正样本中有多少是被真正覆盖的，而与那10%毫无关系，同理，FPR只关注10%负样本中有多少是被错误覆盖的，也与那90%毫无关系，</p>
</blockquote>
<p><strong>如果我们从实际表现的各个结果角度出发，就可以避免样本不平衡的问题了，这也是为什么选用TPR和FPR作为ROC&#x2F;AUC的指标的原因。</strong></p>
<h4 id="2-ROC（接受者操作特征曲线）"><a href="#2-ROC（接受者操作特征曲线）" class="headerlink" title="2. ROC（接受者操作特征曲线）"></a><strong>2. ROC（接受者操作特征曲线）</strong></h4><blockquote>
<p>  ROC（Receiver Operating Characteristic）曲线，又称接受者操作特征曲线。该曲线最早应用于雷达信号检测领域，用于区分信号与噪声。后来人们将其用于评价模型的预测能力，ROC曲线是基于<strong>混淆矩阵</strong>得出的。</p>
</blockquote>
<p>ROC曲线中的主要两个指标就是<strong>真正率</strong>和<strong>假正率，</strong> 上面也解释了这么选择的好处所在。其中<strong>横坐标为假正率（FPR），纵坐标为真正率（TPR）</strong>，下面就是一个标准的ROC曲线图。</p>
<h4 id="AUC的缺陷？"><a href="#AUC的缺陷？" class="headerlink" title="AUC的缺陷？"></a>AUC的缺陷？</h4><p><strong>优点</strong>：目前普遍认为接收器工作特性曲线（ROC）曲线下的面积—AUC是评估分类模型准确性的标准方法。<strong>它避免了在阈值选择过程中假定的主观性</strong>，当连续的概率得到的分数被转换为二分类标签时，通过总结整体模型表现，其衡量模型区分正负样本的性能优于通过阈值来判断的其他方法（比如准确率、召回率等）。</p>
<ul>
<li><strong>忽略了预测的概率值和模型的拟合优度</strong></li>
<li><strong>AUC反应了太过笼统的信息。无法反应召回率、精确率等在实际业务中经常关心的指标</strong></li>
<li><font color="red"> <strong>对FPR和TPR两种错误的代价同等看待</strong></font></li>
<li>它没有给出模型误差的空间分布信息</li>
<li>最重要的一点，AUC的misleading的问题</li>
</ul>
<p><strong>&#x3D;&#x3D;auc仅反应模型的排序能力&#x3D;&#x3D;，无法反应模型的拟合优度；auc很多时候无法直接反应细粒度的和业务目标更相关的metric信息，例如 top k的准确率，召回率等等（例如同auc的模型在不同的区间的预测能力是存在差别的）；</strong></p>
<h3 id="1-3、K-S曲线"><a href="#1-3、K-S曲线" class="headerlink" title="1.3、K-S曲线"></a>1.3、K-S曲线</h3><blockquote>
<p>  <strong>K-S曲线</strong>，又称作洛伦兹曲线。实际上，K-S曲线的数据来源以及本质和ROC曲线是一致的，只是ROC曲线是把真正率（ <img src="/.io//equation-20230416162046966" alt="[公式]"> ）和假正率（ <img src="/.io//equation-20230416162046970" alt="[公式]"> ）当作横纵轴，<strong>而K-S曲线是把真正率（ <img src="/.io//equation-20230416170932127" alt="[公式]"> ）和假正率（ <img src="/.io//equation-20230416170932165" alt="[公式]"> )都当作是纵轴，横轴则由选定的阈值来充当。从 <strong>K-S 曲线</strong>就能衍生出 <img src="/.io//equation-20230416162046950" alt="[公式]"> 值， <img src="/.io//equation-20230416162046968" alt="[公式]"> ，即是两条曲线之间的最大间隔距离。</strong></p>
</blockquote>
<p><strong>K-S曲线的画法：</strong></p>
<ol>
<li><p><strong>排序：</strong>对于二元分类器来说，模型训练完成之后每个样本都会得到一个类概率值，把样本按这个类概率值从大到小进行排序；</p>
</li>
<li><p><strong>找阈值：</strong>取排序后前 <img src="/.io//equation?tex=10/%25/times+k(k%253D1%252C2%252C3%252C..-20230416162046951.%252C9)" alt="[公式]"> 处的值（概率值）作为阈值，分别计算出不同的 <img src="/.io//equation-20230416170932127" alt="[公式]"> 和<img src="/.io//equation-20230416170932165" alt="[公式]"> 值，以<img src="/.io//equation?tex=10/%25/times+k(k%253D1%252C2%252C3%252C..-20230416170932128.%252C9)" alt="[公式]">为横坐标，分别以<img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> 和<img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> 值为纵坐标，就可以画出两个曲线，这就是K-S曲线，类似于下图。</p>
</li>
<li><p><strong>KS值</strong>：</p>
<p>从 <strong>K-S 曲线</strong>就能衍生出 <img src="/.io//equation-20230416162046950" alt="[公式]"> 值， <img src="/.io//equation-20230416162046968" alt="[公式]"> ，即是两条曲线之间的最大间隔距离。KS值越大表示模型 的区分能力越强。</p>
</li>
</ol>
<img src="/.io//v2-f913b42cefcd32f9fdbfa027de2dfbc8_1440w.jpg" alt="img" style="zoom: 50%;">

<h3 id="1-4-Lift曲线"><a href="#1-4-Lift曲线" class="headerlink" title="1.4 Lift曲线"></a>1.4 Lift曲线</h3><p><strong>Lift曲线它衡量的是，与不利用模型相比，模型的预测能力“变好”了多少，lift(提升指数)越大，模型的运行效果越好。实质上它强调的是投入与产出比</strong>。</p>
<p><strong>tip:<strong>理解</strong>Lift</strong>可以先看一下Quora上的一篇文章：**<a href="https://link.zhihu.com/?target=https://www.quora.com/Whats-Lift-curve">What’s Lift curve?</a>**</p>
<p><strong>Lift计算公式：</strong>先介绍几个相关的指标，以免混淆：</p>
<ul>
<li><strong>准确率（accuracy，ACC）</strong>：</li>
</ul>
<p><img src="/.io//equation-20230416162047033" alt="[公式]"></p>
<ul>
<li><strong>正确率(Precision，PRE)，查准率</strong>：</li>
</ul>
<p><img src="/.io//equation-20230416162047062" alt="[公式]"></p>
<ul>
<li>**真阳性率(True Positive Rate，TPR)，灵敏度(Sensitivity)，召回率(Recall)**：</li>
</ul>
<p><img src="/.io//equation-20230416162047046" alt="[公式]"></p>
<ul>
<li>**假阳性率(False Positice Rate，FPR)，误诊率( &#x3D; 1 - 特异度)**：</li>
</ul>
<p><img src="/.io//equation-20230416162047333" alt="[公式]"></p>
<p><strong>Lift计算公式：</strong></p>
<p><img src="/.io//equation-20230416162047311" alt="[公式]"></p>
<p>根据以上公式可知，<strong>Lift指标可以这样理解：</strong>在不使用模型的情况下，我们用先验概率估计正例的比例，即上式子分母部分，以此作为正例的命中率；利用模型后，我们不需要从整个样本中来挑选正例，只需要从我们预测为正例的那个样本的子集 <img src="/.io//equation-20230416162047100" alt="[公式]"> 中挑选正例，这时正例的命中率为 <img src="/.io//equation-20230416162047320-1633247." alt="[公式]"> ，后者除以前者即可得提升值<strong>Lift。</strong></p>
<h4 id="Lift曲线："><a href="#Lift曲线：" class="headerlink" title="Lift曲线："></a><strong>Lift曲线：</strong></h4><p>为了作出<strong>LIft</strong>曲线，首先引入 <img src="/.io//equation-20230416162047320" alt="[公式]"> 的概念：</p>
<p><img src="/.io//equation-20230416162047327" alt="[公式]"></p>
<p><strong>从公式可以看出</strong>，<img src="/.io//equation-20230416162047320" alt="[公式]">代表的是预测为正例的样本占整个样本的比例。</p>
<p>当阈值为0时，所有的样本都被预测为正例，因此 <img src="/.io//equation-20230416162047329" alt="[公式]"> ，于是 <img src="/.io//equation-20230416162047403" alt="[公式]"> ，模型未起提升作用。随着阈值逐渐增大，被预测为正例的样本数逐渐减少，<img src="/.io//equation-20230416162047320" alt="[公式]">减小，而较少的预测正例样本中的真实正例比例逐渐增大。当阈值增大至1时，没有样本被预测为正例，此时 <img src="/.io//equation-20230416162047476" alt="[公式]"> ，而 <img src="/.io//equation-20230416162047459" alt="[公式]"> 。由此可见， <img src="/.io//equation-20230416162047460" alt="[公式]"> 与<img src="/.io//equation-20230416170932031-1636172." alt="[公式]">存在相反方向变化的关系。在此基础上作出 <img src="/.io//equation-20230416170932031" alt="[公式]"> 图：</p>
<img src="/.io//v2-4cfa1e77335b91d9a47acb7238383c1e_1440w.jpg" alt="img" style="zoom: 50%;">

<p>一般要求，在尽量大的 <img src="/.io//equation-20230416170932031-1636172." alt="[公式]"> 下得到尽量大的 <img src="/.io//equation-20230416170932031" alt="[公式]">，所以 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 曲线的右半部分应该尽量陡峭。</p>
<h3 id="1-5-P-R曲线"><a href="#1-5-P-R曲线" class="headerlink" title="1.5 P-R曲线"></a>1.5 <strong>P-R曲线</strong></h3><ul>
<li><p><strong>精确率（查准率）- Precision ：&#x3D;&#x3D;预测为正的样本&#x3D;&#x3D;中实际为正的样本的概率</strong> 【**TP&#x2F;(TP+FP)**】</p>
</li>
<li><p><strong>召回率（查全率）- Recall</strong>：**&#x3D;&#x3D;实际为正的样本&#x3D;&#x3D;中被预测为正样本的概率<strong>【</strong>TP&#x2F;(TP+FN)**】</p>
</li>
</ul>
<p>P-R曲线刻画<strong>查准率</strong>和<strong>查全率（召回率）</strong>之间的关系，查准率指的是在所有预测为正例的数据中，真正例所占的比例，查全率是指预测为真正例的数据占所有正例数据的比例。查准率和查全率是一对矛盾的度量，一般来说，查准率高时，查全率往往偏低，查全率高时，查准率往往偏低。</p>
<p>在很多情况下，我们可以根据学习器的预测结果对样例进行排序，排在前面的是学习器认为最可能是正例的样本，排在后面的是学习器认为最不可能是正例的样本，按此顺序逐个把样本作为正例进行预测，则每次可计算当前的查全率和查准率，以查准率为y轴，以查全率为x轴，可以画出下面的P-R曲线。</p>
<img src="/.io//v2-dc6abbb24e2dfbfefe4777408d2a8e5c_1440w.jpg" alt="img" style="zoom:67%;">

<p>如果一个学习器的P-R曲线被另一个学习器的P-R曲线完全包住，则可断言后者的性能优于前者，当然我们可以根据曲线下方的面积大小来进行比较，但更常用的是<strong>平衡点</strong>或者是F1值。</p>
<ul>
<li><strong>平衡点（BEP）</strong>是查准率&#x3D;查全率时的取值，如果这个值较大，则说明学习器的性能较好。F1值越大，我们可以认为该学习器的性能较好。</li>
<li><font color="red"> <strong>F1度量</strong>：<strong>BEP过于简单，这个平衡点是建立在”查准率&#x3D;查全率“的前提下，无法满足实际不同场景的应用。</strong></font></li>
</ul>
<p>我们先来引入加权调和平均： <img src="/.io//equation-20230416162047533" alt="[公式]">：</p>
<p><img src="/.io//equation-20230416162047516" alt="[公式]"></p>
<p>加权调和平均与<strong>算术平均</strong> <img src="/.io//equation-20230416162047501" alt="[公式]"> 和<strong>几何平均</strong> <img src="/.io//equation-20230416162047744" alt="[公式]"> 相比，<strong>调和平均更重视较小值（这可以从倒数上看出来）</strong>。当 <img src="/.io//equation-20230416162047557" alt="[公式]"> ，即F1是基于查准率和查全率的调和平均定义的，F1的公式如下：</p>
<p><img src="/.io//equation-20230416162047728" alt="[公式]"></p>
<p>我们把公式求倒数，即可得：</p>
<p><img src="/.io//equation-20230416162047554" alt="[公式]"></p>
<p>在一些应用中，对查准率和查全率的重视程度不同。例如在商品推荐中，为了尽可能少打扰用户，更希望推荐的内容确实是用户感兴趣的，此时查准率更重要；而在罪犯信息检索或者病人检查系统中，更希望尽可能少的漏判，此时查全率更重要。F1度量的一般形式是 <img src="/.io//equation-20230416162047757" alt="[公式]"> ，能让我们自定义对查准率&#x2F;查全率的不同偏好：</p>
<p><img src="/.io//equation-20230416162047731" alt="[公式]"></p>
<p>其中， <img src="/.io//equation-20230416162047732" alt="[公式]"> 度量了查全率对查准率的相对重要性（不明白的同学可以回看公式1）， <img src="/.io//equation-20230416162047729" alt="[公式]"> 时退化为标准F1，<img src="/.io//equation-20230416162048546" alt="[公式]">&#x3D;&#x3D;时查全率有更大影响； <img src="/.io//equation-20230416162048521" alt="[公式]"> 时，查准率有更大影响。&#x3D;&#x3D;</p>
<h3 id="1-6-对数损失-Log-Loss"><a href="#1-6-对数损失-Log-Loss" class="headerlink" title="1.6 对数损失(Log Loss)"></a>1.6 <strong>对数损失(Log Loss)</strong></h3><p><strong>AUC ROC考虑用于确定模型性能的预测概率</strong>。然而，AUC ROC存在问题，它只考虑概率的顺序，因此<strong>没有考虑模型预测更可能为正样本的更高概率的能力(即考虑了大小，但没有考虑更高精度)<strong>。</strong>在这种情况下，我们可以使用对数损失，即每个实例的正例预测概率的对数的负平均值。</strong></p>
<p>对数损失（Logistic Loss，logloss）是对预测概率的似然估计，其标准形式为：</p>
<p><img src="/.io//equation-20230416162048834" alt="[公式]"></p>
<p>对数损失最小化本质是上利用样本中的已知分布，求解拟合这种分布的最佳模型参数，使这种分布出现概率最大。</p>
<p>对数损失对应的二分类的计算公式为：</p>
<p><img src="/.io//equation-20230416162048881" alt="[公式]"></p>
<p>其中N为样本数， <img src="/.io//equation-20230416162048799" alt="[公式]"> 为预测为1的概率。对数损失在多分类问题中也可以使用，其计算公式为：</p>
<p><img src="/.io//equation-20230416162048828" alt="[公式]"></p>
<p>其中，N为样本数，C为类别数，logloss衡量的是预测概率分布和真实概率分布的差异性，取值越小越好。</p>
<h3 id="1-7-多分类"><a href="#1-7-多分类" class="headerlink" title="1.7 多分类"></a>1.7 多分类</h3><p>很多时候我们有多个<strong>二分类混淆矩阵</strong>，例如进行多次训练&#x2F;测试，每次得到一个混淆矩阵；或是在多个数据集上进行训练&#x2F;测试，希望估计算法的全局性能；或者是执行分类任务，每两两类别的组合都对应一个混淆矩阵；总之是在<strong>n个二分类混淆矩阵上综合考察查准率和查全率</strong>。</p>
<ul>
<li><strong>宏观</strong>：在各个混淆军阵上分别计算出查准率和查全率，记为(P1,R1)，(P2,R2),…(Pn,Rn)，在<strong>计算平均值</strong>，这样就得到“宏观查准率”(macro-P)，“宏观查全率”(macro-R)、“宏观F1”(macro-F1)：</li>
</ul>
<p><img src="/.io//equation-20230416162048883" alt="[公式]"></p>
<p><img src="/.io//equation-20230416162048768" alt="[公式]"></p>
<p><img src="/.io//equation-20230416162048925" alt="[公式]"></p>
<ul>
<li><strong>微观</strong>：<strong>将个混淆矩阵对应的元素进行平均，得到TP、FP、TN、FN的平均值</strong>，分别记为 <img src="/.io//equation-20230416162048919" alt="[公式]"> 、 <img src="/.io//equation-20230416162048984" alt="[公式]"> 、 <img src="/.io//equation-20230416162049151" alt="[公式]"> 、 <img src="/.io//equation-20230416162048985" alt="[公式]"> ，再基于这些平均值计算出“微观查准率”(micro-P)，“微观查全率”(micro-R)、“微观F1”(micro-F1)：</li>
</ul>
<p><img src="/.io//equation-20230416162049034" alt="[公式]"></p>
<p><img src="/.io//equation-20230416162049017" alt="[公式]"></p>
<p><img src="/.io//equation-20230416162049062" alt="[公式]"></p>
<h2 id="二、回归问题评价指标"><a href="#二、回归问题评价指标" class="headerlink" title="二、回归问题评价指标"></a>二、回归问题评价指标</h2><blockquote>
<p>  <strong>均方差损失 Mean Squared Loss、平均绝对误差损失 Mean Absolute Error Loss、Huber Loss、分位数损失 Quantile Loss</strong></p>
</blockquote>
<p>机器学习中的监督学习本质上是给定一系列训练样本 <img src="/.io//equation-20230416162049473" alt="[公式]"> ，尝试学习 <img src="/.io//equation-20230416162049156" alt="[公式]"> 的映射关系，使得给定一个 <img src="/.io//equation-20230416162049168" alt="[公式]"> ，即便这个 <img src="/.io//equation-20230416170932058" alt="[公式]"> 不在训练样本中，也能够得到尽量接近真实 <img src="/.io//equation-20230416162049157" alt="[公式]"> 的输出 <img src="/.io//equation-20230416162049217" alt="[公式]"> 。而损失函数（Loss Function）则是这个过程中关键的一个组成部分，用来<strong>衡量模型的输出</strong> <img src="/.io//equation-20230416170932222" alt="[公式]"> <strong>与真实的</strong> <img src="/.io//equation-20230416170932218" alt="[公式]"> <strong>之间的差距</strong>，给模型的优化指明方向。</p>
<h3 id="2-1-均方差损失-MSE、L2-loss"><a href="#2-1-均方差损失-MSE、L2-loss" class="headerlink" title="2.1 均方差损失 MSE、L2 loss"></a>2.1 均方差损失 MSE、L2 loss</h3><h5 id="基本形式与原理"><a href="#基本形式与原理" class="headerlink" title="基本形式与原理"></a><strong>基本形式与原理</strong></h5><p><strong>均方差Mean Squared Error (MSE)损失是机器学习、深度学习回归任务中最常用的一种损失函数</strong>，也称为 <strong>L2 Loss</strong>。其基本形式如下：</p>
<p><img src="/.io//equation-20230416162049999" alt="[公式]"></p>
<p>从直觉上理解均方差损失，这个损失函数的最小值为 0（当预测等于真实值时），最大值为无穷大。下图是对于真实值 <img src="/.io//equation-20230416162049932" alt="[公式]"> ，不同的预测值 <img src="/.io//equation?tex=%5B-1.5%252C+1-20230416162049423.5%5D" alt="[公式]"> 的均方差损失的变化图。横轴是不同的预测值，纵轴是均方差损失，可以看到随着预测与真实值绝对误差 <img src="/.io//equation-20230416162049408" alt="[公式]"> 的增加，均方差损失呈二次方地增加。</p>
<p><img src="/.io//v2-f13a4355c21d16cad8b3f30e8a24b5cc_1440w-20230416162046673.jpg" alt="img"></p>
<blockquote>
<h4 id="背后的假设"><a href="#背后的假设" class="headerlink" title="背后的假设"></a>背后的假设</h4><p>  <strong>【独立同分布-中心极限定理】</strong>：<br>  如果 <img src="/.io//equation-20230416162050043" alt="[公式]"> 独立同分布，且 <img src="/.io//equation-20230416162049991" alt="[公式]"> ，则n足够大时 <img src="/.io//equation-20230416162050213" alt="[公式]"> 近似服从正态分布 <img src="/.io//equation-20230416162049568" alt="[公式]"> ，即</p>
<p>  <img src="/.io//equation-20230416162049986" alt="[公式]"></p>
<p>  实际上在一定的假设下，我们可以使用最大化似然得到均方差损失的形式。假设<strong>模型预测与真实值之间的误差服从标准高斯分布</strong>（ <img src="/.io//equation-20230416162050188" alt="[公式]"> ），则给定一个 <img src="/.io//equation-20230416162050488" alt="[公式]"> 模型输出真实值 <img src="/.io//equation-20230416162050490" alt="[公式]"> 的概率为</p>
<p>  <img src="/.io//equation-20230416162050304" alt="[公式]"></p>
<p>  <strong>进一步我们假设数据集中 N 个样本点之间相互独立，则给定所有 <img src="/.io//equation-20230416170932058" alt="[公式]"> 输出所有真实值 <img src="/.io//equation-20230416170932218" alt="[公式]"> 的概率，即似然 Likelihood</strong>，为所有 <img src="/.io//equation-20230416162050196" alt="[公式]"> 的累乘</p>
<p>  <img src="/.io//equation-20230416162050500" alt="[公式]"></p>
<p>  通常为了计算方便，我们通常最大化对数似然 Log-Likelihood</p>
<p>  <img src="/.io//equation-20230416162050459" alt="[公式]"></p>
<p>  去掉与 <img src="/.io//equation-20230416162050494" alt="[公式]"> 无关的第一项，然后转化为最小化负对数似然 Negative Log-Likelihood</p>
<p>  <img src="/.io//equation-20230416162050548" alt="[公式]"></p>
<p>  可以看到这个实际上就是均方差损失的形式。也就是说<strong>在模型输出与真实值的误差服从高斯分布的假设下，最小化均方差损失函数与极大似然估计本质上是一致的</strong>，因此在这个假设能被满足的场景中（比如回归），均方差损失是一个很好的损失函数选择；当这个假设没能被满足的场景中（比如分类），均方差损失不是一个好的选择。</p>
</blockquote>
<h3 id="hulu-百面机器学习-——-平方根误差的”意外“"><a href="#hulu-百面机器学习-——-平方根误差的”意外“" class="headerlink" title=" hulu 百面机器学习 —— 平方根误差的”意外“"></a><strong><font color="red"> hulu 百面机器学习 —— 平方根误差的”意外“</font></strong></h3><h4 id="95-的时间区间效果很好，RMSE指标居高不下的原因？"><a href="#95-的时间区间效果很好，RMSE指标居高不下的原因？" class="headerlink" title="95%的时间区间效果很好，RMSE指标居高不下的原因？"></a>95%的时间区间效果很好，RMSE指标居高不下的原因？</h4><p><img src="/.io//equation-20230416162049999" alt="[公式]"></p>
<p>一般情况下RSME能反应预测值与真实值的偏离程度，但是<strong>易受离群点</strong>的影响；</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>数据预处理将噪音去掉</li>
<li>将离群点的产生机制建模进去</li>
<li>更鲁棒的模型评估指标：<strong>平均绝对百分比误差</strong>（MAPE），<strong>分位数损失</strong></li>
</ul>
<h4 id="2-2-平均绝对误差-MAE"><a href="#2-2-平均绝对误差-MAE" class="headerlink" title="2.2 平均绝对误差 MAE"></a>2.2 <strong>平均绝对误差 MAE</strong></h4><p><strong>平均绝对误差 Mean Absolute Error (MAE）</strong> 是另一类常用的损失函数，也称为 <strong>L1 Loss</strong>。其基本形式如下</p>
<p><img src="/.io//equation-20230416162050595" alt="[公式]"></p>
<p>同样的我们可以对这个损失函数进行可视化如下图，MAE 损失的最小值为 0（当预测等于真实值时），最大值为无穷大。可以看到随着预测与真实值绝对误差 <img src="/.io//equation-20230416162049408" alt="[公式]"> 的增加，MAE 损失呈线性增长。</p>
<p><img src="/.io//v2-fd248542b6b5aa9fadcab44340045dee_1440w-20230416162047379.jpg" alt="img"></p>
<blockquote>
<h4 id="背后的假设-1"><a href="#背后的假设-1" class="headerlink" title="背后的假设"></a>背后的假设</h4><p>  同样的我们可以在一定的假设下通过最大化似然得到 MAE 损失的形式，假设<strong>模型预测与真实值之间的误差服从拉普拉斯分布 Laplace distribution</strong>（ <img src="/.io//equation-20230416162050627" alt="[公式]"> ），则给定一个 <img src="/.io//equation-20230416162050488" alt="[公式]"> 模型输出真实值 <img src="/.io//equation-20230416162050490" alt="[公式]"> 的概率为</p>
<p>  <img src="/.io//equation-20230416162050629" alt="[公式]"></p>
<p>  与上面推导 MSE 时类似，我们可以得到的负对数似然实际上就是 MAE 损失的形式</p>
<p>  <img src="/.io//equation-20230416162050623" alt="[公式]"></p>
</blockquote>
<h3 id="2-3-MAE-与-MSE-区别"><a href="#2-3-MAE-与-MSE-区别" class="headerlink" title="2.3 MAE 与 MSE 区别"></a>2.3 MAE 与 MSE 区别</h3><p>MAE 和 MSE 作为损失函数的主要区别是：<strong>MSE 损失相比 MAE 通常可以更快地收敛，但 MAE 损失对于 outlier 更加健壮</strong>，即更加不易受到 outlier 影响。</p>
<ul>
<li><p><strong>MSE 通常比 MAE 可以更快地收敛</strong>。当使用梯度下降算法时，MSE 损失的梯度为 <img src="/.io//equation-20230416162050592" alt="[公式]"> ，而 MAE 损失的梯度为 <img src="/.io//equation-20230416162050635" alt="[公式]"> ，即 MSE 的梯度的 scale 会随误差大小变化，而 MAE 的梯度的 scale 则一直保持为 1，即便在绝对误差 <img src="/.io//equation-20230416162050892" alt="[公式]"> 很小的时候 MAE 的梯度 scale 也同样为 1，这实际上是非常不利于模型的训练的。当然你可以通过在训练过程中动态调整学习率缓解这个问题，但是总的来说，损失函数梯度之间的差异导致了 MSE 在大部分时候比 MAE 收敛地更快。这个也是 MSE 更为流行的原因。</p>
</li>
<li><p><strong>MAE 对于异常值（outlier） 更加 robust</strong>。我们可以从两个角度来理解这一点：</p>
<ul>
<li>第一个角度是直观地理解，下图是 MAE 和 MSE 损失画到同一张图里面，由于MAE 损失与绝对误差之间是线性关系，MSE 损失与误差是平方关系，当误差非常大的时候，MSE 损失会远远大于 MAE 损失。<strong>因此当数据中出现一个误差非常大的 outlier 时，MSE 会产生一个非常大的损失，对模型的训练会产生较大的影响</strong>。<img src="/.io//v2-c8edffe0406dafae41a042e412cd3251_1440w-20230416162047585.jpg" alt="img"></li>
<li>第二个角度是从两个损失函数的假设出发，MSE 假设了误差服从高斯分布，MAE 假设了误差服从拉普拉斯分布。拉普拉斯分布本身对于 outlier 更加 robust。参考下图（来源：<a href="https://link.zhihu.com/?target=https://www.cs.ubc.ca/~murphyk/MLbook/">Machine Learning: A Probabilistic Perspective</a> 2.4.3 The Laplace distribution Figure 2.8），当右图右侧出现了 outliers 时，拉普拉斯分布相比高斯分布受到的影响要小很多。因此以拉普拉斯分布为假设的 MAE 对 outlier 比高斯分布为假设的 MSE 更加 robust。<img src="/.io//v2-93ad65845f5b0dc0327fde4ded661804_1440w-20230416162047378.jpg" alt="img" style="zoom: 67%;"></li>
</ul>
</li>
</ul>
<h3 id="2-4-Huber-Loss"><a href="#2-4-Huber-Loss" class="headerlink" title="2.4 Huber Loss"></a>2.4 Huber Loss</h3><blockquote>
<ul>
<li>在误差接近 0 时使用 MSE，使损失函数可导并且梯度更加稳定</li>
<li>在误差较大时使用 MAE 可以降低 outlier 的影响，使训练对 outlier 更加健壮。</li>
</ul>
</blockquote>
<p>上文我们分别介绍了 MSE 和 MAE 损失以及各自的优缺点，MSE 损失收敛快但容易受 outlier 影响，MAE 对 outlier 更加健壮但是收敛慢，<a href="https://link.zhihu.com/?target=https://en.wikipedia.org/wiki/Huber_loss">Huber Loss</a> 则是一种将 MSE 与 MAE 结合起来，取两者优点的损失函数，也被称作 Smooth Mean Absolute Error Loss 。其原理很简单，就是在误差接近 0 时使用 MSE，误差较大时使用 MAE，公式为</p>
<p><img src="/.io//equation-20230416162050848" alt="[公式]"></p>
<p>上式中 <img src="/.io//equation-20230416162050875" alt="[公式]"> 是 Huber Loss 的一个超参数，<img src="/.io//equation-20230416170932136" alt="[公式]"> 的值是 MSE 和 MAE 两个损失连接的位置。上式等号右边第一项是 MSE 的部分，第二项是 MAE 部分，在 MAE 的部分公式为 <img src="/.io//equation-20230416162050955" alt="[公式]"> 是为了保证误差 <img src="/.io//equation-20230416162050914" alt="[公式]"> 时 MAE 和 MSE 的取值一致，进而保证 Huber Loss 损失连续可导。</p>
<p>下图是 <img src="/.io//equation?tex=/delta%253D1-20230416162050876.0" alt="[公式]"> 时的 Huber Loss，可以看到在 <img src="/.io//equation-20230416162051143" alt="[公式]"> 的区间内实际上就是 MSE 损失，在 <img src="/.io//equation-20230416162050970" alt="[公式]"> 和 <img src="/.io//equation-20230416162050962" alt="[公式]"> 区间内为 MAE损失。</p>
<p><img src="/.io//v2-b4260d38f70dd920fa46b8717596bda7_1440w-20230416162047797.jpg" alt="img"></p>
<h3 id="2-5-分位数损失-Quantile-Loss"><a href="#2-5-分位数损失-Quantile-Loss" class="headerlink" title="2.5 分位数损失 Quantile Loss"></a>2.5 分位数损失 Quantile Loss</h3><blockquote>
<p>  <strong>MAE 中分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong></p>
</blockquote>
<p><strong>分位数回归 Quantile Regression 是一类在实际应用中非常有用的回归算法</strong>，通常的回归算法是拟合目标值的期望或者中位数，而分位数回归可以通过给定不同的分位点，<strong>拟合目标值的不同分位数</strong>。</p>
<p><img src="/.io//v2-8eb8ecfcdd8031a16a471905217934a0_1440w-20230416162047585.jpg" alt="img"></p>
<p>分位数回归是通过使用分位数损失 Quantile Loss 来实现这一点的，分位数损失形式如下，式中的 r 分位数系数。</p>
<p><img src="/.io//equation-20230416162050991" alt="[公式]"></p>
<p>我们如何理解这个损失函数呢？这个损失函数是一个分段的函数 ，将 <img src="/.io//equation-20230416162051027" alt="[公式]"> （高估） 和 <img src="/.io//equation-20230416162051092" alt="[公式]"> （低估） 两种情况分开来，并分别给予不同的系数。当 <img src="/.io//equation?tex=r%3E0-20230416162051067.5" alt="[公式]"> 时，低估的损失要比高估的损失更大，反过来当 <img src="/.io//equation?tex=r+%3C+0-20230416162051140.5" alt="[公式]"> 时，高估的损失比低估的损失大；分位数损失实现了<strong>分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong>。特别地，当 <img src="/.io//equation?tex=r%253D0-20230416162051084.5" alt="[公式]"> 时，分位数损失退化为 MAE 损失，从这里可以看出 MAE 损失实际上是分位数损失的一个特例 — 中位数回归。</p>
<p>下图是取不同的分位点 0.2、0.5、0.6 得到的三个不同的分位损失函数的可视化，可以看到 0.2 和 0.6 在高估和低估两种情况下损失是不同的，而 0.5 实际上就是 MAE。</p>
<p><img src="/.io//v2-f8ed385f32a517c784bce841e6da1daf_1440w-20230416162047923.jpg" alt="img"></p>
<h3 id="2-6-平均绝对百分误差-MAPE"><a href="#2-6-平均绝对百分误差-MAPE" class="headerlink" title="2.6  平均绝对百分误差 MAPE"></a>2.6  平均绝对百分误差 MAPE</h3><p>虽然平均绝对误差能够获得一个评价值，但是你并不知道这个值代表模型拟合是优还是劣，只有通过对比才能达到效果。当需要以相对的观点来衡量误差时，则使用MAPE。</p>
<p><strong>平均绝对百分误差</strong>（<strong>Mean Absolute Percentage Error，MAPE</strong>）是对 MAE 的一种改进，考虑了绝对误差相对真实值的比例。</p>
<ul>
<li><strong>优点</strong>：考虑了预测值与真实值的误差。考虑了误差与真实值之间的比例。</li>
</ul>
<p><img src="/.io//equation-20230416162051160" alt="公式"></p>
<blockquote>
<p>  在某些场景下，如房价从 <img src="/.io//equation-20230416162051155" alt="公式"> 到 <img src="/.io//equation-20230416162051238" alt="公式"> 之间，<img src="/.io//equation-20230416170932269" alt="公式"> 预测成 <img src="/.io//equation-20230416162051191" alt="公式"> 与 <img src="/.io//equation-20230416170932224" alt="公式"> 预测成 <img src="/.io//equation-20230416162051244" alt="公式"> 的差别是非常大的，而平均绝对百分误差考虑到了这点。</p>
</blockquote>
<h2 id="三、相似性度量指标"><a href="#三、相似性度量指标" class="headerlink" title="三、相似性度量指标"></a>三、相似性度量指标</h2><blockquote>
<p>  机器学习中的相似性度量方法 - 天下客的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/411876558">https://zhuanlan.zhihu.com/p/411876558</a></p>
</blockquote>
<p>描述样本之间相似度的方法有很多种，一般来说常用的有相关系数和欧式距离。本文对机器学习中常用的相似性度量方法进行了总结。<strong>在做分类时，常常需要估算不同样本之间的相似性度量（Similarity Measurement），</strong>这时通常采用的方法就是计算样本间的“距离”（distance）。采用什么样的方法计算距离是很讲究的，甚至关系到分类的正确与否。</p>
<ul>
<li><strong>欧式距离</strong>：k-means</li>
<li><strong>曼哈顿距离</strong>：</li>
<li><strong>切比雪夫距离</strong>：</li>
<li>闵可夫斯基距离</li>
<li>标准化欧氏距离</li>
<li>马氏距离</li>
<li><a href="https://www.zhihu.com/search?q=%E5%A4%B9%E8%A7%92%E4%BD%99%E5%BC%A6&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%2255493039%22%7D">夹角余弦</a></li>
<li><strong>汉明距离</strong>：simhash</li>
<li><strong>杰卡德距离&amp;杰卡德相似系数</strong>: <strong>杰卡德相似系数是衡量两个集合的相似度一种指标。</strong></li>
<li>相关系数&amp;相关距离</li>
<li>信息熵</li>
</ul>
<h2 id="四、推荐算法评价指标"><a href="#四、推荐算法评价指标" class="headerlink" title="四、推荐算法评价指标"></a>四、推荐算法评价指标</h2><ul>
<li>推荐算法评价指标 - 一干正事就犯困的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/359528909">https://zhuanlan.zhihu.com/p/359528909</a></li>
</ul>
<h4 id="4-1-AP"><a href="#4-1-AP" class="headerlink" title="4.1 AP"></a>4.1 AP</h4><p><code>AP</code> 衡量的是训练好的模型在每个类别上的好坏；</p>
<img src="/.io//v2-e8656365e7eee25065d6bdfec33368e5_1440w-20230416162048752.jpg" alt="img" style="zoom: 67%;">

<p><strong>AP总结了一个精确召回曲线，作为在每个阈值处获得的精度的加权平均值，并且与以前的阈值相比，召回率的增加用作权重</strong>：</p>
<img src="/.io//image-20220711160205051.png" alt="image-20220711160205051" style="zoom:50%;">

<p>其中和分别是第n个阈值[1]时的精度和召回率。此实现未进行插值，并且与使用梯形规则计算精确调用曲线下的面积有所不同，后者使用线性插值并且可能过于乐观。</p>
<h4 id="4-2-MAP"><a href="#4-2-MAP" class="headerlink" title="4.2 MAP"></a>4.2 MAP</h4><p><strong>MAP（Mean Average Precision）常用于排序任务，MAP的计算涉及另外两个指标：Precision和Recall</strong></p>
<ul>
<li><strong>Precision和Precision@k</strong></li>
</ul>
<p>推荐算法中的精度precision计算如下： </p>
<p><img src="/.io//equation-20230416162051242" alt="[公式]"></p>
<p>可以看出Precision的计算没有考虑结果列表中item的顺序，Precision@k则通过切片的方式将顺序隐含在结果中。Precision@k表示列表前k项的Precision，随着k的变化，可以得到一系列precision值，用 <img src="/.io//equation-20230416162051298" alt="[公式]"> 表示。</p>
<ul>
<li><strong>Recall和Recall@k</strong></li>
</ul>
<p>推荐算法中的召回率recall计算如下：</p>
<p><img src="/.io//equation-20230416162051263" alt="[公式]"></p>
<p>与Precision@k相似，recall@k表示结果列表前k项的recall，随着k的变化，可以得到一系列的recall值，用 <img src="/.io//equation-20230416162051297" alt="[公式]"> 表示。</p>
<ul>
<li><h5 id="AP-N"><a href="#AP-N" class="headerlink" title="AP@N"></a>AP@N</h5></li>
</ul>
<p>AP（Average Precision）平均精度的计算以Precision@k为基础，可以体现出结果列表中item顺序的重要性，其计算过程如下： </p>
<p><img src="/.io//equation-20230416162051331" alt="[公式]"></p>
<p>其中，N表示要求推荐的N个item，m表示所有相关的item总数， <img src="/.io//equation-20230416162051506" alt="[公式]"> 表示第k个item是否相关，相关为1，反之为0</p>
<p><strong>AP@N的值越大，表示推荐列表中相关的item数量越多以及相关item的排名越靠前</strong></p>
<ul>
<li><h5 id="MAP-N"><a href="#MAP-N" class="headerlink" title="MAP@N"></a>MAP@N</h5></li>
</ul>
<p><strong>AP@N评价了算法对单个用户的性能，MAP@N则是算法对多个用户的平均值，是平均数的平均，其计算过程如下</strong>：</p>
<p><img src="/.io//equation-20230416162051575" alt="[公式]"></p>
<h2 id="五、聚类算法评价指标"><a href="#五、聚类算法评价指标" class="headerlink" title="五、聚类算法评价指标"></a>五、聚类算法评价指标</h2><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/343667804">https://zhuanlan.zhihu.com/p/343667804</a></p>
<p>  十分钟掌握聚类算法的评估指标：<a href="https://juejin.cn/post/6997913127572471821">https://juejin.cn/post/6997913127572471821</a></p>
</blockquote>
<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>如同之前介绍的其它算法模型一样，对于聚类来讲我们同样会通过一些评价指标来衡量聚类算法的优与劣。在聚类任务中，常见的评价指标有：<strong>纯度（Purity）</strong>、<strong>兰德系数（Rand Index, RI）</strong>、<strong>F值（F-score）</strong>和<strong>调整兰德系数（Adjusted Rand Index,ARI）</strong>。同时，这四种评价指标也是聚类相关论文中出现得最多的评价方法。下面，我们就来对这些算法一一进行介绍。</p>
<img src="/.io//v2-e62c8b4b793c89b1cd70f2aaebf690c6_1440w-20230416162048995.jpg" alt="img" style="zoom: 67%;">

<p>好的聚类算法，一般要求类簇具有：</p>
<ul>
<li><strong>簇内 (intra-cluster) 相似度高</strong></li>
<li><strong>簇间 (inter-cluster) 相似度底</strong></li>
</ul>
<p>一般来说，评估聚类质量有两个标准，内部评估评价指标和外部评估指标。</p>
<h3 id="【外部评估】"><a href="#【外部评估】" class="headerlink" title="【外部评估】"></a>【外部评估】</h3><h3 id="5-1聚类纯度-聚类的准确率"><a href="#5-1聚类纯度-聚类的准确率" class="headerlink" title="5.1聚类纯度 - 聚类的准确率"></a><strong>5.1聚类纯度</strong> - 聚类的准确率</h3><p>在聚类结果的评估标准中，一种最简单最直观的方法就是计算它的<strong>聚类纯度</strong>（purity），别看纯度听起来很陌生，但实际上和<strong>分类问题中的准确率有着异曲同工之妙</strong>。因为聚类纯度的总体思想也<strong>用聚类正确的样本数除以总的样本数，因此它也经常被称为聚类的准确率</strong>。只是对于聚类后的结果我们并不知道每个簇所对应的真实类别，因此需要取每种情况下的最大值。具体的，纯度的计算公式定义如下：</p>
<p><img src="/.io//equation-20230416162051527" alt="[公式]"></p>
<p>其中<img src="/.io//equation-20230416162051524" alt="[公式]">表示总的样本数；<img src="/.io//equation?tex=/Omega%253D/%7B/omega_1%252C/omega_2%252C..-20230416162051525.%252C/omega_K/%7D" alt="[公式]">表示一个个聚类后的簇，而<img src="/.io//equation?tex=/mathbb%7BC%7D%253D/%7Bc_1%252C_2%252C..-20230416162051543.c_J/%7D" alt="[公式]">表示正确的类别；<img src="/.io//equation-20230416162051815" alt="[公式]">表示聚类后第<img src="/.io//equation-20230416162051616" alt="[公式]">个簇中的所有样本，<img src="/.io//equation-20230416162051619" alt="[公式]">表示第<img src="/.io//equation-20230416162051612" alt="[公式]">个类别中真实的样本。在这里<img src="/.io//equation-20230416162051679" alt="[公式]">的取值范围为<img src="/.io//equation-20230416162051779" alt="[公式]">，越大表示聚类效果越好。</p>
<h3 id="5-2-兰德系数与F值-同簇混淆矩阵"><a href="#5-2-兰德系数与F值-同簇混淆矩阵" class="headerlink" title="5.2 兰德系数与F值  [同簇混淆矩阵]"></a><strong>5.2 兰德系数与F值</strong>  [同簇混淆矩阵]</h3><p>在介绍完了纯度这一评价指标后，我们再来看看兰德系数（Rand Index）和F值。虽然兰德系数听起来是一个陌生的名词，但它的计算过程却也与准确率的计算过程类似。同时，虽然这里也有一个叫做F值的指标，并且它的计算过程也和分类指标中的F值类似，但是两者却有着本质的差别。说了这么多，那这两个指标到底该怎么算呢？同分类问题中的混淆矩阵类似，这里我们也要先定义四种情况进行计数，然后再进行指标的计算。</p>
<p><strong>为了说明兰德系数背后的思想，我们还是以图1中的聚类结果为例进行说明（为了方便观察，我们再放一张图在这里）:</strong></p>
<img src="/.io//v2-e62c8b4b793c89b1cd70f2aaebf690c6_1440w-20230416162048995.jpg" alt="img" style="zoom: 67%;">

<ul>
<li><img src="/.io//equation-20230416162051924" alt="[公式]">：表示两个<strong>同类样本点</strong>在<strong>同一个簇</strong>（布袋）中的情况数量；</li>
<li><img src="/.io//equation-20230416162051734" alt="[公式]">：表示两个<strong>非同类样本点</strong>在<strong>同一个簇</strong>中的情况数量；</li>
<li><img src="/.io//equation-20230416162051915" alt="[公式]">：表示两个<strong>非同类样本点</strong>分别在<strong>两个簇</strong>中的情况数量；</li>
<li><img src="/.io//equation-20230416162051935" alt="[公式]">：表示两个同类样本点分别在<strong>两个簇</strong>中的情况数量；</li>
</ul>
<p>由此，我们便能得到如下所示的对<strong>混淆矩阵（Pair Confusion Matrix）</strong>：</p>
<img src="/.io//v2-a9e709a995b006be04d026aebc721c4e_1440w-20230416162049533.png" alt="img" style="zoom:75%;">

<p>有了上面各种情况的统计值，我们就可以定义出兰德系数和F值的计算公式：</p>
<p><img src="/.io//equation-20230416162051911" alt="[公式]"><img src="/.io//equation-20230416162051996" alt="[公式]"></p>
<p>从上面的计算公式来看，<img src="/.io//equation-20230416162051993" alt="[公式]">从形式上看都非常像分类问题中的准确率与F值，但是有着本质的却别。同时，在这里<img src="/.io//equation-20230416162052007" alt="[公式]">和<img src="/.io//equation-20230416162047757" alt="[公式]">的取值范围均为<img src="/.io//equation-20230416162051779" alt="[公式]">，越大表示聚类效果越好。</p>
<h4 id="5-3-调整兰德系数（Adjusted-Rand-index）【归一化】"><a href="#5-3-调整兰德系数（Adjusted-Rand-index）【归一化】" class="headerlink" title="5.3 调整兰德系数（Adjusted Rand index）【归一化】"></a>5.3 调整兰德系数（Adjusted Rand index）【归一化】</h4><p>对于随机结果，RI并不能保证分数接近零。<strong>为了实现“在聚类结果随机产生的情况下，指标应该接近零”</strong>，调整兰德系数（Adjusted rand index）被提出，它具有更高的区分度。</p>
<p>其公式为：<br>$$<br>\mathrm{ARI}&#x3D;\frac{\mathrm{RI}-E[\mathrm{RI}]}{\max (\mathrm{RI})-E[\mathrm{RI}]}<br>$$<br>$A R$ 取值范围为 $[-1,1]$, 值越大意味着聚类结果与真实情况越吻合。从广义的角度来讲, ARI衡量的是两个数据分布的吻合程度。</p>
<p>优点:</p>
<ul>
<li>对任意数量的聚类中心和样本数, 随机聚类的ARI都非常接近于 0 。</li>
<li>取值在 $[-1,1]$ 之间, 负数代表结果不好, 越接近于1越好。</li>
<li>对簇的结构不需作出任何假设：可以用于比较聚类算法。</li>
</ul>
<p>缺点:</p>
<ul>
<li>ARI 需要 ground truth classes 的相关知识, ARI需要真实标签, 而在实践中几乎不可用, 或者需要人工 标注者手动分配（如在监督学习环境中）。</li>
</ul>
<h3 id="5-4-标准化互信息（NMI-Normalized-Mutual-Information）"><a href="#5-4-标准化互信息（NMI-Normalized-Mutual-Information）" class="headerlink" title="5.4  标准化互信息（NMI, Normalized Mutual Information）"></a>5.4 <strong><font color="red"> 标准化互信息（NMI, Normalized Mutual Information）</font></strong></h3><p>互信息是用来衡量两个数据分布的吻合程度。它也是一有用的信息度量，它是指两个事件集合之间的相关性。互信息越大，词条和类别的相关程度也越大。</p>
<h3 id="【内部指标】"><a href="#【内部指标】" class="headerlink" title="【内部指标】"></a>【内部指标】</h3><p>内部评估指标主要基于数据集的集合结构信息从紧致性、分离性、连通性和重叠度等方面对聚类划分进行评价。即基于数据聚类自身进行评估的。</p>
<h3 id="5-5-轮廓系数（Silhouette-Coefficient）"><a href="#5-5-轮廓系数（Silhouette-Coefficient）" class="headerlink" title="5.5  轮廓系数（Silhouette Coefficient）"></a>5.5 <strong><font color="red"> 轮廓系数（Silhouette Coefficient）</font></strong></h3><p>轮廓系数适用于实际类别信息未知的情况。</p>
<p>对于单个样本，设<strong>a是与它同类别中其他样本的平均距离</strong>，<strong>b是与它距离最近不同类别中样本的平均距离</strong>，其轮廓系数为：</p>
<p>$s &#x3D; \frac {b-a} {max(a, b)}$</p>
<p>对于一个样本集合，它的轮廓系数是所有样本轮廓系数的平均值。轮廓系数的取值范围是[-1,1]，同类别样本距离越相近，不同类别样本距离越远，值越大。当值为负数时，说明聚类效果很差。</p>
<h3 id="5-6-Calinski-Harabaz指数（Calinski-Harabaz-Index）"><a href="#5-6-Calinski-Harabaz指数（Calinski-Harabaz-Index）" class="headerlink" title="5.6 Calinski-Harabaz指数（Calinski-Harabaz Index）"></a>5.6 Calinski-Harabaz指数（Calinski-Harabaz Index）</h3><p>在真实的分群label不知道的情况下，Calinski-Harabasz可以作为评估模型的一个指标。</p>
<p>Calinski-Harabasz指数通过<strong>计算类中各点与类中心的距离平方和来度量类内的紧密度</strong>，通过**&#x3D;&#x3D;计算各类中心点与数据集中心点距离平方和来度量数据集的分离度&#x3D;&#x3D;<strong>，CH指标</strong>由分离度与紧密度的比值得到**。从而，CH越大代表着类自身越紧密，类与类之间越分散，即更优的聚类结果。</p>
<p><strong>优点</strong></p>
<ul>
<li>当簇的密集且分离较好时，分数更高。</li>
<li>得分计算很快，与轮廓系数的对比，最大的优势：快！相差几百倍！毫秒级。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>凸的簇的CH指数通常高于其他类型的簇。例如，通过 DBSCAN 获得基于密度的簇；所以，不适合基于密度的聚类算法（DBSCAN）。</li>
</ul>
<h3 id="5-7-戴维森堡丁指数（DBI-Davies-Bouldin-Index）"><a href="#5-7-戴维森堡丁指数（DBI-Davies-Bouldin-Index）" class="headerlink" title="5.7 戴维森堡丁指数（DBI, Davies-Bouldin Index）"></a>5.7 戴维森堡丁指数（DBI, Davies-Bouldin Index）</h3><p><strong>DB指数是计算任意两类别的类内距离平均距离之和除以两聚类中心距离求最大值</strong>。DB越小，意味着类内距 离越小同时类间距离越大。<strong>零是可能的最低值, 接近零的值表示更好的分区</strong>。<br>$$<br>\begin{gathered}<br>R_{i j}&#x3D;\frac{s_{i}+s_{j}}{d_{i j}} \<br>D B&#x3D;\frac{1}{k} \sum_{i&#x3D;1}^{k} \max <em>{i \neq j} R</em>{i j}<br>\end{gathered}<br>$$<br>其中, $s_{i}$ 表示簇的每个点与该簇的质心之间的平均距离, 也称为簇直径。 $d_{i j}$ 表示聚类和的质心之间的距 离。<br>算法生成的聚类结果越是朝着簇内距离最小（类内相似性最大）和笶间距离最大（类间相似性最小）变化， 那么Davies-Bouldin指数就会越小。<br><strong>缺点</strong>:</p>
<ul>
<li>因使用欧式距离, 所以对于环状分布聚类评测很差。</li>
</ul>
<h2 id="六、评分总结（sklearn）"><a href="#六、评分总结（sklearn）" class="headerlink" title="六、评分总结（sklearn）"></a>六、评分总结（sklearn）</h2><blockquote>
<p>  sklearn.metrics - 回归&#x2F;分类模型的评估方法:<a href="https://zhuanlan.zhihu.com/p/408078074">https://zhuanlan.zhihu.com/p/408078074</a></p>
</blockquote>
<h3 id="6-1-分类模型"><a href="#6-1-分类模型" class="headerlink" title="6.1 分类模型"></a>6.1 分类模型</h3><h4 id="accuracy-score"><a href="#accuracy-score" class="headerlink" title="accuracy_score"></a><strong>accuracy_score</strong></h4><p><strong>分类准确率分数是指所有分类正确的百分比</strong>。分类准确率这一衡量分类器的标准比较容易理解，但是它不能告诉你响应值的潜在分布，并且它也不能告诉你分类器犯错的类型。所以在使用的时候，一般需要搭配matplotlib等数据可视化工具来观察预测的分类情况，与实际的结果做更加直观的比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score  </span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>]  </span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]  </span><br><span class="line">accuracy_score(y_true, y_pred)  <span class="comment"># 默认normalization = True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.5</span></span><br><span class="line">accuracy_score(y_true, y_pred, normalize=<span class="literal">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">2</span></span><br></pre></td></tr></table></figure>

<h4 id="recall-score"><a href="#recall-score" class="headerlink" title="recall_score"></a><strong>recall_score</strong></h4><p>召回率 &#x3D;<strong>提取出的正确信息条数 &#x2F;样本中的信息条数</strong>。通俗地说，就是所有准确的条目有多少被检索出来了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">recall_score(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>,average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">参数average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br></pre></td></tr></table></figure>

<p>将一个二分类matrics拓展到多分类或多标签问题时，我们可以将数据看成多个二分类问题的集合，每个类都是一个二分类。接着，我们可以通过跨多个分类计算每个二分类metrics得分的均值，这在一些情况下很有用。你可以使用<strong>average参数</strong>来指定。 </p>
<ul>
<li>macro：计算二分类metrics的均值，为每个类给出相同权重的分值。</li>
<li>weighted:对于不均衡数量的类来说，计算二分类metrics的平均，通过在每个类的score上进行加权实现。 </li>
<li>micro：给出了每个样本类以及它对整个metrics的贡献的pair（sample-weight），而非对整个类的metrics求和，它会每个类的metrics上的权重及因子进行求和，来计算整个份额。</li>
<li>samples：应用在multilabel问题上。它不会计算每个类，相反，它会在评估数据中，通过计算真实类和预测类的差异的metrics，来求平均（sample_weight-weighted） </li>
<li>average：average&#x3D;None将返回一个数组，它包含了每个类的得分.</li>
</ul>
<h4 id="roc-curve"><a href="#roc-curve" class="headerlink" title="roc_curve"></a><strong>roc_curve</strong></h4><p>ROC曲线指受试者工作特征曲线&#x2F;接收器操作特性(receiver operating characteristic，ROC)曲线,是<strong>反映灵敏性和特效性连续变量的综合指标</strong>,是用构图法揭示敏感性和特异性的相互关系，它通过将连续变量设定出多个不同的临界值，从而计算出一系列敏感性和特异性。ROC曲线是根据一系列不同的二分类方式（分界值或决定阈），<strong>以真正例率（也就是灵敏度）（True Positive Rate,TPR）为纵坐标，假正例率（1-特效性）（False Positive Rate,FPR）为横坐标</strong>绘制的曲线。</p>
<p>通过ROC我们可以观察到模型正确识别的正例的比例与模型错误地把负例数据识别成正例的比例之间的权衡。TPR的增加以FPR的增加为代价。ROC曲线下的面积是模型准确率的度量，<strong>AUC</strong>（Area under roc curve）。</p>
<p><strong>TPR</strong> &#x3D; TP &#x2F;（TP + FN） （正样本<strong>预测数</strong> &#x2F; 正样本<strong>实际数</strong>）</p>
<p><strong>FPR</strong> &#x3D; FP &#x2F;（FP + TN） （负样本<strong>预测数</strong> &#x2F;负样本<strong>实际数</strong>）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics  </span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>])  </span><br><span class="line">scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=<span class="number">2</span>)  </span><br><span class="line">fpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.</span> ,  <span class="number">0.5</span>,  <span class="number">0.5</span>, <span class="number">1.</span> ])  </span><br><span class="line">tpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.5</span>,  <span class="number">0.5</span>,  <span class="number">1.</span> , <span class="number">1.</span> ])  </span><br><span class="line">thresholds  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.8</span> ,  <span class="number">0.4</span> ,  <span class="number">0.35</span>, <span class="number">0.1</span> ])  </span><br><span class="line"></span><br><span class="line"><span class="comment"># check auc score</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> auc   </span><br><span class="line">metrics.auc(fpr, tpr)   </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以直接根据预测值+真实值来计算出auc值，略过roc的计算过程</span></span><br><span class="line">‘’‘</span><br><span class="line">sklearn.metrics.roc_auc_score(y_true, y_score, average=<span class="string">&#x27;macro&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br><span class="line">’‘’</span><br><span class="line"><span class="comment"># 真实值（必须是二值）、预测值（可以是0/1,也可以是proba值）</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score  </span><br><span class="line">y_true = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])  </span><br><span class="line">y_scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">roc_auc_score(y_true, y_scores)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>  </span><br></pre></td></tr></table></figure>

<h4 id="confusion-metric"><a href="#confusion-metric" class="headerlink" title="confusion metric"></a><strong>confusion metric</strong></h4><p>混淆矩阵（confusion matrix），又称为可能性表格或是错误矩阵。它是一种特定的矩阵用来呈现算法性能的可视化效果。其每一列代表预测值，每一行代表的是实际的类别。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">confusion_matric(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>, average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<h4 id="precision-score"><a href="#precision-score" class="headerlink" title="precision_score"></a><strong>precision_score</strong></h4><p>计算精确度——precision <img src="/.io//equation-20230416162052015" alt="[公式]"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">precision_score(y_true, y_pred, labels=None, pos_label=1, average=&#x27;binary&#x27;)</span><br></pre></td></tr></table></figure>

<p><img src="/.io//v2-a3b6092e30d2eab7d2372007aec15105_r-20230416162050205.jpg" alt="preview"></p>
<h2 id="评价指标Q-amp-A"><a href="#评价指标Q-amp-A" class="headerlink" title="评价指标Q&amp;A"></a>评价指标Q&amp;A</h2><h4 id="精度指标存在的问题？"><a href="#精度指标存在的问题？" class="headerlink" title="精度指标存在的问题？"></a><strong>精度指标存在的问题</strong>？</h4><ul>
<li>有倾向性的问题。比如，判断空中的飞行物是导弹还是其他飞行物，很显然为了减少损失，我们更倾向于相信是导弹而采用相应的防护措施。此时判断为导弹实际上是其他飞行物与判断为其他飞行物实际上是导弹这两种情况的重要性是不一样的；</li>
<li>样本类别数量严重不均衡的情况。比如银行客户样本中好客户990个，坏客户10个。如果一个模型直接把所有客户都判断为好客户，得到精度为99%，但这显然是没有意义的。</li>
</ul>
<h4 id="为什么-ROC-和-AUC-都能应用于非均衡的分类问题？"><a href="#为什么-ROC-和-AUC-都能应用于非均衡的分类问题？" class="headerlink" title="为什么 ROC 和 AUC 都能应用于非均衡的分类问题？"></a><strong>为什么 ROC 和 AUC 都能应用于非均衡的分类问题？</strong></h4><p><strong>ROC曲线只与横坐标 (FPR) 和 纵坐标 (TPR) 有关系</strong> 。我们可以发现TPR只是正样本中预测正确的概率，而FPR只是负样本中预测错误的概率，和正负样本的比例没有关系。因此 ROC 的值与实际的正负样本比例无关，因此既可以用于均衡问题，也可以用于非均衡问题。而 AUC 的几何意义为ROC曲线下的面积，因此也和实际的正负样本比例无关。</p>
]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
</search>
