<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>机器学习（0）理论基础</title>
    <url>/posts/52716/</url>
    <content><![CDATA[<h3><span id="一-机器学习中参数模型和非参数模型理解">一、 机器学习中参数模型和非参数模型理解</span></h3><blockquote>
<p>  参考：<a href="https://blog.csdn.net/FrankieHello/article/details/94022594">https://blog.csdn.net/FrankieHello/article/details/94022594</a></p>
</blockquote>
<p><strong>参数模型通常假设总体服从某个分布，这个分布可以由一些参数确定，如正态分布由均值和标准差确定，在此基础上构建的模型称为参数模型</strong>；非参数模型对于总体的分布不做任何假设或者说是数据分布假设自由，只知道其分布是存在的，所以就无法得到其分布的相关参数，只能通过非参数统计的方法进行推断。</p>
<p><strong>参数模型</strong>：线性回归、逻辑回归、感知机、基本型的SVM</p>
<p><strong>非参数模型</strong>：决策树、对偶型的SVM、朴素贝叶斯、神经网络</p>
<span id="more"></span>
<h3><span id="二-判别模型-vs-生成模型">二、 判别模型 VS 生成模型</span></h3><blockquote>
<p>  判别模型与生成模型，概率模型与非概率模型、参数模型与非参数模型总结 - Eureka的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/37821985">https://zhuanlan.zhihu.com/p/37821985</a></p>
<p>  <strong>机器学习中的判别式模型和生成式模型</strong> - Microstrong的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/74586507">https://zhuanlan.zhihu.com/p/74586507</a></p>
</blockquote>
<p><img src="https://s2.loli.net/2023/04/17/AYyZUiraIdN5Dn1.png" alt="image-20230417171758407" style="zoom:50%;"></p>
<p><strong>判别模型：感知机、逻辑斯特回归、支持向量机、神经网络、k近邻都属于判别学习模型。判别模型分为两种:</strong></p>
<ul>
<li>直接对输入空间到输出空间的映射进行建模, 也就是学习函数 $h$ : </li>
</ul>
<script type="math/tex; mode=display">
h: X \rightarrow Y, s . t . y=h(x)</script><ul>
<li>对条件概率 $P(y \mid x)$ 进行建模, 然后根据贝叶斯风险最小化的准则进行分类: </li>
</ul>
<script type="math/tex; mode=display">
y=\arg \max _{y \in\{-1,1\}} P(y \mid x)</script><p><strong>生成模型：</strong></p>
<p>生成模型是间接地, 先对 $P(x, y)$ 进行建模, 再根据贝叶斯公式:$P(y \mid x)=\frac{P(x \mid y) P(y)}{P(x)}$</p>
<script type="math/tex; mode=display">
P(y \mid x)=\frac{P(x \mid y) P(y)}{P(x)}</script><p>算出 $P(y \mid x)$, 最后根据 $\arg \max _{y \in\{-1,1\}} P(y \mid x)$ 来做分类 (由此可知, 判别模型实际上不需要对 $P(x, y)$ 进行建模)。</p>
<h3><span id="三-概率模型-vs-非概率模型">三、概率模型 vs 非概率模型</span></h3><h4><span id="31-概率模型">3.1 概率模型</span></h4><blockquote>
<p>  <strong>线性回归（高斯分布）、LR（伯努利分布）、高斯判别分析、朴素贝叶斯</strong></p>
</blockquote>
<p><strong>概率模型指出了学习的目的是学出 $P(x, y)$ 或 $P(y \mid x)$, 但最后都是根据 $\arg \max _{y \in\{-1,1\}} P(y \mid x)$ 来做判别归类</strong>。对于 $P(x, y)$ 的估计, 一般是根据乘法公式 $P(x, y)=P(x \mid y) P(y)$ 将其拆解成 $P(x \mid y), P(y)$ 分别进行估计。无论是对 $P(x \mid y), P(y)$ 还是 $P(y \mid x)$ 的估计, 都是会先假设分布的形式, 例如逻辑斯特回归就假设了 $Y \mid X$ 服从伯努利分 布。分布形式固定以后, 剩下的就是分布参数的估计问题。<strong>常用的估计有极大似然估计(MLE)和极大后验概率估计 (MAP)等</strong>。其中, 极大后验概率估计涉及到分布参数的先验概率, 这为我们注入先验知识提供了途径。逻辑斯特回 归、高斯判别分析、朴素贝叶斯都属于概率模型。</p>
<p>在一定的条件下，非概率模型与概率模型有以下对应关系:</p>
<p><img src="https://s2.loli.net/2023/04/17/AYyZUiraIdN5Dn1.png" alt="image-20230417171758407" style="zoom:50%;"></p>
<h4><span id="32-非概率模型">3.2 非概率模型</span></h4><blockquote>
<p>  <strong>感知机、支持向量机、神经网络、k近邻都属于非概率模型</strong>。线性支持向量机可以显式地写出损失函数——hinge损失。神经网络也可以显式地写出损失函数——平方损失。</p>
</blockquote>
<p>非概率模型指的是直接学习输入空间到输出空间的映射 $h$, 学习的过程中基本不涉及概率密度的估计, 概率密度 的积分等操作, 问题的关键在于最优化问题的求解。通常, 为了学习假设 $h(x)$, 我们会先根据一些先验知识 (prior knowledge) 来选择一个特定的假设空间 $H(x)$ (函数空间), 例如一个由所有线性函数构成的空间, 然后在 这个空间中找出泛化误差最小的假设出来, |</p>
<script type="math/tex; mode=display">
h^*=\arg \min _{h \in H} \varepsilon(h)=\arg \min _{h \in H} \sum_{x, y} l(h(x), y) P(x, y)</script><p>其中 $l(h(x), y)$ 是我们选取的损失函数, 选择不同的损失函数, 得到假设的泛化误差就会不一样。由于我们并不知 道 $P(x, y)$, 所以即使我们选好了损失函数, 也无法计算出假设的泛化误差, 更别提找到那个给出最小泛化误差的 假设。于是，我们转而去找那个使得经验误差最小的假设</p>
<script type="math/tex; mode=display">
g=\arg \min _{h \in H} \hat{\varepsilon}(h)=\arg \min _{h \in H} \frac{1}{m} \sum_{i=1}^{m} l\left(h\left(x^{(i)}\right), y^{(i)}\right)</script><p><font color="red"> 这种学习的策略叫经验误差最小化(ERM)，理论依据是大数定律：当训练样例无穷多的时候，假设的经验误差会依概率收敛到假设的泛化误差。</font>要想成功地学习一个问题，必须在学习的过程中注入先验知识。前面，我们根据先验知识来选择假设空间，其实，在选定了假设空间后，先验知识还可以继续发挥作用，这一点体现在为我们的优化问题加上正则化项上，例如常用的$L1$正则化， $L2$正则化等。</p>
<script type="math/tex; mode=display">
g=\arg \min _{h \in H} \hat{\varepsilon}(h)=\arg \min _{h \in H} \frac{1}{m} \sum_{i=1}^{m} l\left(h\left(x^{(i)}\right), y^{(i)}\right)+\lambda \Omega(h)</script><h3><span id="四-过拟合和欠拟合">四、 过拟合和欠拟合</span></h3><blockquote>
<p>  欠拟合、过拟合及如何防止过拟合 - G-kdom的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/72038532">https://zhuanlan.zhihu.com/p/72038532</a></p>
</blockquote>
<h4><span id="41-欠拟合">4.1 欠拟合</span></h4><p><strong>欠拟合是指模型不能在训练集上获得足够低的误差</strong>。换句换说，就是模型复杂度低，模型在训练集上就表现很差，没法学习到数据背后的规律。</p>
<h4><span id="42-欠拟合解决方法">4.2 欠拟合解决方法</span></h4><p>欠拟合基本上都会发生在训练刚开始的时候，经过不断训练之后欠拟合应该不怎么考虑了。但是如果真的还是存在的话，可以通过<strong>增加网络复杂度</strong>或者在模型中<strong>增加特征</strong>，这些都是很好解决欠拟合的方法。</p>
<h4><span id="43-过拟合">4.3 过拟合</span></h4><p>过拟合是指训练误差和测试误差之间的差距太大。换句换说，就是模型复杂度高于实际问题，<strong>模型在训练集上表现很好，但在测试集上却表现很差</strong>。模型对训练集”死记硬背”（记住了不适用于测试集的训练集性质或特点），没有理解数据背后的规律，<strong>泛化能力差</strong>。</p>
<p>造成原因主要有以下几种：<br>1、<strong>训练数据集样本单一，样本不足</strong>。如果训练样本只有负样本，然后那生成的模型去预测正样本，这肯定预测不准。所以训练样本要尽可能的全面，覆盖所有的数据类型。<br>2、<strong>训练数据中噪声干扰过大</strong>。噪声指训练数据中的干扰数据。过多的干扰会导致记录了很多噪声特征，忽略了真实输入和输出之间的关系。<br>3、<strong>模型过于复杂。</strong>模型太复杂，已经能够“死记硬背”记下了训练数据的信息，但是遇到没有见过的数据的时候不能够变通，泛化能力太差。我们希望模型对不同的模型都有稳定的输出。模型太复杂是过拟合的重要因素。</p>
<h4><span id="44-如何防止过拟合">4.4 如何防止过拟合</span></h4><p>要想解决过拟合问题，就要显著减少测试误差而不过度增加训练误差，从而提高模型的泛化能力。</p>
<h5><span id="1-使用正则化regularization方法">1、使用正则化（Regularization）方法。</span></h5><p>那什么是<a href="https://www.zhihu.com/search?q=正则化&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">正则化</a>呢？<strong>正则化是指修改学习算法，使其降低泛化误差而非训练误差</strong>。</p>
<p>常用的正则化方法根据具体的使用策略不同可分为：（1）直接提供正则化约束的参数正则化方法，如L1/L2正则化；（2）通过工程上的技巧来实现更低泛化误差的方法，如提前终止(Early stopping)和Dropout；（3）不直接提供约束的隐式正则化方法，如数据增强等。</p>
<p><strong>L2正则化起到使得权重参数 $w$变小的效果，为什么能防止过拟合呢？</strong>因为更小的权重参数$w$意味着模型的复杂度更低，对训练数据的拟合刚刚好，不会过分拟合训练数据，从而提高模型的泛化能力。</p>
<h5><span id="2-获取和使用更多的数据数据集增强解决过拟合的根本性方法">2、获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法</span></h5><p>让机器学习或深度学习模型泛化能力更好的办法就是使用更多的数据进行训练。但是，在实践中，我们拥有的数据量是有限的。解决这个问题的一种方法就是<strong>创建“假数据”并添加到训练集中——数据集增强</strong>。通过增加训练集的额外副本来增加训练集的大小，进而改进模型的泛化能力。</p>
<p>我们以图像数据集举例，能够做：旋转图像、缩放图像、随机裁剪、加入随机噪声、平移、镜像等方式来增加数据量。另外补充一句，在物体分类问题里，<strong>CNN在图像识别的过程中有强大的“不变性”规则，即待辨识的物体在图像中的形状、姿势、位置、图像整体明暗度都不会影响分类结果</strong>。我们就可以通过图像平移、翻转、缩放、切割等手段将数据库成倍扩充。</p>
<h5><span id="3-采用合适的模型控制模型的复杂度">3. 采用合适的模型（控制模型的复杂度）</span></h5><p>过于复杂的模型会带来过拟合问题。对于模型的设计，目前公认的一个深度学习规律”deeper is better”。国内外各种大牛通过实验和竞赛发现，对于CNN来说，层数越多效果越好，但是也更容易产生过拟合，并且计算所耗费的时间也越长。</p>
<p>根据<strong>奥卡姆剃刀法则</strong>：在同样能够解释已知观测现象的假设中，我们应该挑选“最简单”的那一个。对于模型的设计而言，我们应该<strong>选择简单、合适的模型解决复杂的问题</strong>。</p>
<h5><span id="4-降低特征的数量">4. 降低特征的数量</span></h5><p>对于一些特征工程而言，可以降低特征的数量——删除冗余特征，人工选择保留哪些特征。这种方法也可以解决过拟合问题。</p>
<h5><span id="5-dropout">5. Dropout</span></h5><p>Dropout是在训练网络时用的一种技巧（trike），相当于在隐藏单元增加了噪声。<strong>Dropout 指的是在训练过程中每次按一定的概率（比如50%）随机地“删除”一部分隐藏单元（神经元）。</strong>所谓的“删除”不是真正意义上的删除，其实就是将该部分神经元的激活函数设为0（激活函数的输出为0），让这些神经元不计算而已。</p>
<p><strong>Dropout为什么有助于防止过拟合呢？</strong></p>
<p>（a）在训练过程中会产生不同的训练模型，不同的训练模型也会产生不同的的计算结果。随着训练的不断进行，计算结果会在一个范围内波动，但是均值却不会有很大变化，因此可以把最终的训练结果看作是不同模型的平均输出。</p>
<p>（b）它消除或者减弱了神经元节点间的联合，降低了网络对单个神经元的依赖，从而增强了泛化能力。</p>
<h5><span id="6-early-stopping提前终止">6. Early stopping（提前终止）</span></h5><p>对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如<a href="https://www.zhihu.com/search?q=梯度下降&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">梯度下降</a>（Gradient descent）。<strong>Early stopping是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合</strong>。</p>
<p>为了获得性能良好的神经网络，训练过程中可能会经过很多次<a href="https://www.zhihu.com/search?q=epoch&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">epoch</a>（遍历整个数据集的次数，一次为一个epoch）。如果epoch数量太少，网络有可能发生欠拟合；如果epoch数量太多，则有可能发生过拟合。Early <a href="https://www.zhihu.com/search?q=stopping&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">stopping</a>旨在解决epoch数量需要手动设置的问题。具体做法：<strong>每个epoch（或每N个epoch）结束后，在验证集上获取测试结果，随着epoch的增加，如果在验证集上发现测试误差上升，则停止训练，将停止之后的权重作为网络的最终参数。</strong></p>
<p><strong>为什么能防止过拟合？</strong>当还未在神经网络运行太多迭代过程的时候，w参数接近于0，因为随机初始化<a href="https://www.zhihu.com/search?q=w值&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">w值</a>的时候，它的值是较小的随机值。当你开始迭代过程，w的值会变得越来越大。到后面时，w的值已经变得十分大了。所以early stopping要做的就是在中间点停止迭代过程。我们将会得到一个中等大小的w参数，会得到与L2正则化相似的结果，选择了w参数较小的神经网络。</p>
<p><strong>Early Stopping缺点：没有采取不同的方式来解决优化损失函数和过拟合这两个问题</strong>，而是用一种方法同时解决两个问题 ，结果就是要考虑的东西变得更复杂。之所以不能独立地处理，因为如果你停止了优化损失函数，你可能会发现损失函数的值不够小，同时你又不希望过拟合。</p>
<h3><span id="五-损失函数loss与评价指标metric的区别">五、损失函数(loss)与评价指标(metric)的区别？</span></h3><p><strong>当建立一个学习算法时，我们希望最大化一个给定的评价指标matric（比如说准确度），但算法在学习过程中会尝试优化一个不同的损失函数loss（比如说MSE/Cross-entropy）。</strong></p>
<p><strong><font color="red"> 那为什么不把评价指标matric作为学习算法的损失函数loss呢？</font></strong></p>
<ul>
<li><p>一般来说，我认为你应该尝试优化一个与你最关心的评价指标相对应的损失函数。例如，在做分类时，我认为你需要给我一个很好的理由，让我不要优化交叉熵。也就是说，交叉熵并不是一个非常直观的指标，所以一旦你完成了训练，你可能还想知道你的分类准确率有多高，以了解你的模型是否真的能在现实世界中发挥作用，总之，在每个epoch训练完后，你都会有多个评估指标。这样作的主要原因是为了了解你的模型在做什么。这意味着你想要最大化指标A，以便得到一个接近最大化指标B的解决方案。</p>
</li>
<li><p>通常情况下，MSE/交叉熵比精度更容易优化，因为它们对模型参数是可微的，在某些情况下甚至是凸的，这使得它更容易。</p>
</li>
</ul>
<h3><span id="六-标准化和归一化">六、标准化和归一化</span></h3><blockquote>
<p>  PCA、k-means、SVM、回归模型、<strong>神经网络</strong></p>
</blockquote>
<h4><span id="61-定义">6.1 定义</span></h4><p><strong>归一化和标准化</strong>都是对<strong>数据做变换</strong>的方式，将原始的一列数据转换到某个范围，或者某种形态，具体的：</p>
<blockquote>
<p>  <strong>归一化(Normalization)</strong>：将一列数据变化到某个固定区间(范围)中，通常，这个区间是[0, 1]，广义的讲，可以是各种区间，比如映射到[0，1]一样可以继续映射到其他范围，图像中可能会映射到[0,255]，其他情况可能映射到[-1,1]；</p>
<p>  <strong>标准化(Standardization)</strong>：将数据变换为均值为0，标准差为1的分布切记，<strong>并非一定是正态的；</strong></p>
<p>  <strong>中心化</strong>：另外，还有一种处理叫做中心化，也叫零均值处理，就是将每个原始数据减去这些数据的均值。</p>
</blockquote>
<h4><span id="62-差异">6.2 差异</span></h4><blockquote>
<p>  <strong>归一化：对处理后的数据范围有严格要求;</strong></p>
<p>  <strong>标准化:  数据不为稳定，存在极端的最大最小值;  涉及距离度量、协方差计算的时候;</strong></p>
</blockquote>
<ul>
<li><strong>归一化会严格的限定变换后数据的范围</strong>，比如按之前最大最小值处理的，它的范围严格在[ 0 , 1 ]之间；而<strong>标准化</strong>就没有严格的区间，变换后的数据没有范围，只是其均值是0，标准差为1。</li>
<li><strong>归一化的缩放比例仅仅与极值有关</strong>，容易受到异常值的影响。</li>
</ul>
<h4><span id="63-用处">6.3 用处</span></h4><ul>
<li>回归模型，自变量X的量纲不一致导致了<strong>回归系数无法直接解读</strong>或者错误解读；需要将X都处理到统一量纲下，这样才可比；</li>
<li>机器学习任务和统计学任务中有很多地方要用到<strong>“距离”的计算</strong>，比如PCA，比如KNN，比如kmeans等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果；</li>
<li>参数估计时使用<strong>梯度下降</strong>，在使用梯度下降的方法求解最优化问题时， 归一化/标准化后可以加快梯度下降的求解速度，即<strong>提升模型的收敛速度</strong>。</li>
</ul>
<p><strong>其他：log、sigmod、softmax 变换</strong></p>
<h3><span id="七-回归-vs-分类">七、回归 vs 分类</span></h3><p>回归问题可以理解为是定量输出的问题，是一个连续变量预测；分类问题可以理解为是定性输出的问题，是一个离散变量预测。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>理论基础</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习（2）模型评估</title>
    <url>/posts/274TK9B/</url>
    <content><![CDATA[<h2><span id="六-ab-测试">六、A/B 测试</span></h2><blockquote>
<p>  【AB测试最全干货】史上最全知识点及常见面试题（上篇） - 数据分析狗一枚的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/375902281">https://zhuanlan.zhihu.com/p/375902281</a></p>
</blockquote>
<h4><span id="引言">引言</span></h4><p>科学家门捷列夫说「没有测量，就没有科学」，在AI场景下我们同样需要定量的数值化指标来指导我们更好地应用模型对数据进行学习和建模。</p>
<p>事实上，在机器学习领域，对模型的测量和评估至关重要。选择与问题相匹配的评估方法，能帮助我们快速准确地发现在模型选择和训练过程中出现的问题，进而对模型进行优化和迭代。本文我们系统地讲解一下机器学习模型评估相关知识。</p>
<span id="more"></span>
<h4><span id="61-模型评估的目标">6.1 模型评估的目标</span></h4><p><strong>模型评估的目标是选出泛化能力强的模型完成机器学习任务</strong>。实际的机器学习任务往往需要进行大量的实验，经过反复调参、使用多种模型算法（甚至多模型融合策略）来完成自己的机器学习问题，并观察哪种模型算法在什么样的参数下能够最好地完成任务。</p>
<p>但是我们无法提前获取「未知的样本」，因此我们会基于已有的数据进行切分来完成模型训练和评估，借助于切分出的数据进行评估，可以很好地判定模型状态（过拟合 or 欠拟合），进而迭代优化。</p>
<p>在建模过程中，为了获得泛化能力强的模型，我们需要一整套方法及评价指标。</p>
<ul>
<li><strong>评估方法</strong>：为保证客观地评估模型，对数据集进行的有效划分实验方法。</li>
<li><strong>性能指标</strong>：量化地度量模型效果的指标。</li>
</ul>
<h4><span id="62-离线与在线实验方法">6.2 离线与在线实验方法</span></h4><p>进行评估的实验方法可以分为「离线」和「在线」两种。</p>
<h4><span id="离线实验方法">离线实验方法：</span></h4><blockquote>
<p>  在<strong>离线评估</strong>中，经常使用<strong>准确率（Accuracy）、查准率（Precision）、召回率（Recall）、ROC、AUC、PRC</strong>等指标来评估模型。</p>
</blockquote>
<p><strong>模型评估通常指离线试验</strong>。原型设计（Prototyping）阶段及离线试验方法，包含以下几个过程：</p>
<ul>
<li>使用历史数据训练一个适合解决目标任务的一个或多个机器学习模型。</li>
<li>对模型进行验证（Validation）与离线评估（Offline Evaluation）。</li>
<li>通过评估指标选择一个较好的模型。</li>
</ul>
<h4><span id="在线实验方法">在线实验方法：</span></h4><blockquote>
<p>  <strong>在线评估</strong>与离线评估所用的评价指标不同，一般使用一些商业评价指标，如<strong>用户生命周期值（Customer Lifetime value）、广告点击率（Click Through Rate）、用户流失率</strong>（Customer Churn Rate）等标。</p>
</blockquote>
<p>除了离线评估之外，其实还有一种在线评估的实验方法。由于模型是在老的模型产生的数据上学习和验证的，而线上的数据与之前是不同的，因此离线评估并不完全代表线上的模型结果。因此我们需要在线评估，来验证模型的有效性。</p>
<p><img src="https://www.zhihu.com/equation?tex=A%2FB%20%5Cquad%20Test" alt="公式"> <strong>是目前在线测试中最主要的方法</strong>。<img src="https://www.zhihu.com/equation?tex=A%2FB%20%5Cquad%20Test" alt="公式"> 是为同一个目标制定两个方案让一部分用户使用 <img src="https://www.zhihu.com/equation?tex=A" alt="公式"> 方案，另一部分用户使用 <img src="https://www.zhihu.com/equation?tex=B" alt="公式"> 方案，记录下用户的使用情况，看哪个方案更符合设计目标。如果不做AB实验直接上线新方案，新方案甚至可能会毁掉你的产品。</p>
<h4><span id="63-模型离线评估后为什么要进行ab测试"><strong><font color="red"> 6.3 模型离线评估后，为什么要进行ab测试？</font></strong></span></h4><ul>
<li><strong>离线评估无法消除过拟合的影响</strong>，因此离线评估结果无法代替线上的评估效果</li>
<li><strong>离线评估过程中无法模拟线上的真实环境，例如数据丢失、样本反馈延迟</strong></li>
<li>线上的<strong>某些商业指标例如收益、留存等无法通过离线计算</strong></li>
</ul>
<h4><span id="64-如何进行线上ab测试">6.4 <strong>如何进行线上ab测试？</strong></span></h4><p>进行ab测试的主要手段时对用户进行分桶，即将<strong>用户分成实验组和对照组</strong>。实验组使用新模型，对照组使用base模型。<strong>分桶过程中需要保证样本的独立性和采样的无偏性</strong>，确保每个用户只划分到一个桶中，分桶过程中需要保证user id是一个<a href="https://www.zhihu.com/search?q=随机数&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;440144351&quot;}">随机数</a>，才能保证数据无偏的。</p>
<h2><span id="七-模型评估">七、模型评估</span></h2><h4><span id="71-holdout">7.1 holdout</span></h4><p><strong>留出法是机器学习中最常见的评估方法之一，它会从训练数据中保留出验证样本集，这部分数据不用于训练，而用于模型评估</strong>。</p>
<h4><span id="72-交叉验证">7.2 交叉验证</span></h4><p><strong>留出法的数据划分，可能会带来偏差</strong>。在机器学习中，另外一种比较常见的评估方法是交叉验证法—— <img src="https://www.zhihu.com/equation?tex=K" alt="公式"> <strong>折交叉验证对 <img src="https://www.zhihu.com/equation?tex=K" alt="公式"> 个不同分组训练的结果进行平均来减少方差</strong>。</p>
<h4><span id="73-自助法">7.3 自助法</span></h4><p>Bootstrap 是一种用小样本估计总体值的一种非参数方法，在进化和生态学研究中应用十分广泛。<strong>Bootstrap通过有放回抽样生成大量的伪样本，通过对伪样本进行计算，获得统计量的分布，从而估计数据的整体分布</strong>。</p>
<h2><span id="八-超参数调优">八、超参数调优</span></h2><p>神经网咯是有许多超参数决定的，例如网络深度，学习率，正则等等。如何寻找最好的超参数组合，是一个老人靠经验，新人靠运气的任务。</p>
<h4><span id="81-网格搜索">8.1 网格搜索</span></h4><h4><span id="82-随机搜索">8.2 随机搜索</span></h4><h4><span id="83-贝叶斯优化">==8.3 贝叶斯优化==</span></h4><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/390373572"><em>贝叶斯优化</em>(原理+代码解读)</a></p>
<p>  <a href="https://zhuanlan.zhihu.com/p/27916208">LightGBM调参指南(带贝叶斯优化代码)</a></p>
<ul>
<li>贝叶斯调参采用高斯过程，考虑之前的参数信息，不断地更新先验；网格搜索未考虑之前的参数信息</li>
<li>贝叶斯调参迭代次数少，速度快；网格搜索速度慢,参数多时易导致维度爆炸</li>
<li><p>贝叶斯调参针对非凸问题依然稳健；网格搜索针对非凸问题易得到局部最优</p>
<h4><span id="可用的贝叶斯优化框架">可用的贝叶斯优化框架</span></h4></li>
</ul>
<ol>
<li>BayesianOptimization：<a href="https://link.zhihu.com/?target=https%3A//github.com/fmfn/BayesianOptimization">https://github.com/fmfn/BayesianOptimization</a></li>
<li>清华开源的openbox：<a href="https://link.zhihu.com/?target=https%3A//open-box.readthedocs.io/zh_CN/latest/index.html">https://open-box.readthedocs.io/zh_CN/latest/index.html</a></li>
<li>华为开源的HEBO：<a href="https://link.zhihu.com/?target=https%3A//github.com/huawei-noah/HEBO">https://github.com/huawei-noah/HEBO</a></li>
<li><strong>Hyperopt</strong>：<a href="https://link.zhihu.com/?target=http%3A//hyperopt.github.io/hyperopt/">http://hyperopt.github.io/hype</a></li>
</ol>
</blockquote>
<h4><span id="贝叶斯优化什么黑盒优化">贝叶斯优化什么?【黑盒优化】</span></h4><p>求助 gradient-free 的优化算法了，这类算法也很多了，<strong>贝叶斯优化就属于无梯度优化算法</strong>中的一种，它希望在尽可能少的试验情况下去尽可能获得优化命题的全局最优解。</p>
<p><img src="https://pic1.zhimg.com/v2-75933a225ab1875a27188013ce0d8740_b.jpg" alt="img" style="zoom: 33%;"></p>
<ul>
<li>目标函数 <img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]"> 及其导数未知，否则就可以用梯度下降等方法求解。</li>
<li>计算目标函数时间成本大，意味着像蚁群算法、遗传算法这种方法也失效了，因为计算一次要花费很多时间。</li>
</ul>
<h4><span id="概述">概述</span></h4><p>贝叶斯优化，是一种使用<strong>贝叶斯定理来指导搜索以找到目标函数的最小值或最大值的方法</strong>，就是在每次迭代的时候，利用之前观测到的历史信息（先验知识）来进行下一次优化，通俗点讲，<strong>就是在进行一次迭代的时候，先回顾下之前的迭代结果，结果太差的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 附近就不去找了，尽量往结果好一点的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 附近去找最优解，</strong>这样一来搜索的效率就大大提高了，这其实和人的思维方式也有点像，每次在学习中试错，并且在下次的时候根据这些经验来找到最优的策略。</p>
<h4><span id="贝叶斯优化过程">贝叶斯优化过程</span></h4><p>首先，假设有一个这样的函数 <img src="https://www.zhihu.com/equation?tex=c%28x%29" alt="[公式]"> ，我们需要找到他的最小值，如下图所示，这也是我们所需要优化的目标函数，但是我们并不能够知道他的具体形状以及表达形式是怎么样的。</p>
<p><img src="https://pic3.zhimg.com/v2-ddb9527a36ddcdb539d573fa5124d576_b.jpg" alt="img"></p>
<p>贝叶斯优化是通过一种叫做代理优化的方式来进行的，就是不知道真实的目标函数长什么样，我们就用一个<strong>代理函数（surrogate function）来代替目标函数</strong>，<strong>而这个代理函数就可以通过先采样几个点，再通过这几个点来给他拟合出来</strong>，如下图虚线所示：</p>
<p><img src="https://pic2.zhimg.com/v2-53769125b87835a74445a472415c22a1_b.jpg" alt="img"></p>
<p>基于构造的代理函数，<strong>我们就可以在可能是最小值的点附近采集更多的点</strong>，或者在还没有采样过的区域来采集更多的点，有了更多点，就可以<strong>更新代理函数</strong>，使之更逼近真实的目标函数的形状，这样的话也更容易找到目标函数的最小值，这个采样的过程同样可以通过构建一个采集函数来表示，也就是知道了当前代理函数的形状，如何选择下一个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 使得收益最大。</p>
<p><strong>然后重复以上过程，最终就可以找到函数的最小值点了，这大致就是贝叶斯优化的一个过程：</strong></p>
<ol>
<li><strong>初始化一个代理函数的先验分布</strong></li>
<li><strong>选择数据点 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> ，使得采集函数 <img src="https://www.zhihu.com/equation?tex=a%28x%29" alt="[公式]"> 取最大值</strong></li>
<li><strong>在目标函数 <img src="https://www.zhihu.com/equation?tex=+c%28x%29" alt="[公式]"> 中评估数据点 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 并获取其结果 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"></strong> </li>
<li><strong>使用新数据 <img src="https://www.zhihu.com/equation?tex=%28x%2Cy%29" alt="[公式]"> 更新代理函数，得到一个后验分布（作为下一步的先验分布)</strong></li>
<li>重复2-4步，直到达到最大迭代次数</li>
</ol>
<p>举个例子，如图所示，一开始只有两个点（t=2），代理函数的分布是紫色的区域那块，然后根据代理函数算出一个采集函数（绿色线），取采集函数的最大值所在的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> （红色三角处），算出 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> ，然后根据新的点 <img src="https://www.zhihu.com/equation?tex=%28x%2Cy%29" alt="[公式]"> 更新代理函数和采集函数（t=3），继续重复上面步骤，选择新的采集函数最大值所在的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> ，算出 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> ，再更新代理函数和采集函数，然后继续迭代。</p>
<p><img src="https://pic1.zhimg.com/v2-82ed7dc24fca93f3c2c5820ab519a5f8_b.jpg" alt="img" style="zoom: 67%;"></p>
<p>问题的核心就在于代理函数和采集函数如何构建，常用的代理函数有：</p>
<ol>
<li><strong>高斯过程（Gaussian processes）</strong></li>
<li><strong>Tree Parzer Estimator</strong></li>
<li><strong>概率随机森林：针对类别型变量</strong></li>
</ol>
<p>采集函数则需要兼顾两方面的性质：</p>
<ol>
<li>利用当前已开发的区域（Exploitation）：即在当前最小值附近继续搜索</li>
<li>探索尚未开发的区域（Exploration）：即在还没有搜索过的区域里面搜索，可能那里才是全局最优解</li>
</ol>
<p><strong>常用的采集函数有：</strong></p>
<ol>
<li>Probability of improvement（PI）</li>
<li>Expected improvement（EI）</li>
<li>Confidence bound criteria，包括LCB和UCB</li>
</ol>
<h4><span id="84-hyperopt">8.4 Hyperopt</span></h4><p>Hyperopt 是一个强大的 Python 库，用于超参数优化，由 jamesbergstra 开发。Hyperopt 使用贝叶斯优化的形式进行参数调整，允许你为给定模型获得最佳参数。它可以在大范围内优化具有数百个参数的模型。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（3）模型融合</title>
    <url>/posts/38SVER1/</url>
    <content><![CDATA[<h2><span id="融合机器学习模型一种提升预测能力的方法"></span></h2><p>没有哪个机器学习模型可以常胜，如何找到当前问题的最优解是一个永恒的问题。</p>
<p>幸运的是，<strong>结合/融合/整合 (integration/ combination/ fusion)多个机器学习模型往往可以提高整体的预测能力。</strong>这是一种非常有效的提升手段，在多分类器系统(multi-classifier system)和集成学习(ensemble learning)中，融合都是最重要的一个步骤。</p>
<p>一般来说，<strong>模型融合或多或少都能提高的最终的预测能力，且一般不会比最优子模型差</strong>。举个实用的例子，Kaggle比赛中常用的stacking方法就是模型融合，通过结合多个各有所长的子学习器，我们实现了更好的预测结果。基本的理论假设是：<strong>不同的子模型在不同的数据上有不同的表达能力，我们可以结合他们擅长的部分，得到一个在各个方面都很“准确”的模型</strong>。当然，最基本的假设是子模型的误差是互相独立的，这个一般是不现实的。但即使子模型间的误差有相关性，适当的结合方法依然可以各取其长，从而达到提升效果。</p>
<p>我们今天介绍几种简单、有效的模型结合方法。</p>
<span id="more"></span>
<h3><span id="1-案例分析"><strong>1. 案例分析</strong></span></h3><p>让我们给出一个简单的分析。假设我们有天气数据X和对应的标签y，现在希望实现一个可以预测明天天气的模型 <img src="https://www.zhihu.com/equation?tex=%5Cpsi" alt="[公式]"> 。但我们并不知道用什么算法效果最好，于是尝试了十种算法，包括</p>
<ul>
<li>算法1: 逻辑回归 - <img src="https://www.zhihu.com/equation?tex=C_%7B1%7D" alt="[公式]"></li>
<li>算法2：支持向量机（SVM）-  <img src="https://www.zhihu.com/equation?tex=C_%7B2%7D" alt="[公式]"> </li>
<li>…</li>
<li>算法10：随机森林 -  <img src="https://www.zhihu.com/equation?tex=C_%7B10%7D" alt="[公式]"> </li>
</ul>
<p>结果发现他们表现都一般，在验证集上的误分率比较高。我们现在期待找到一种方法，可以有效提高最终预测结果。</p>
<h3><span id="2-平均法投票法"><strong>2. 平均法/投票法</strong></span></h3><p>一种比较直白的方法就是对让10个算法模型同时对需要预测的数据进行预测，并对结果取平均数/众数。假设10个分类器对于测试数据 <img src="https://www.zhihu.com/equation?tex=X_%7Bt%7D" alt="[公式]"> 的预测结果是<img src="https://www.zhihu.com/equation?tex=%5BC_%7B1%7D%28X_t%29%2CC_%7B2%7D%28X_t%29%2C...%2CC_%7B10%7D%28X_t%29%5D%3D%5B0%2C1%2C1%2C1%2C1%2C1%2C0%2C1%2C1%2C0%5D" alt="[公式]"> ，那很显然少数服从多数，我们应该选择1作为 <img src="https://www.zhihu.com/equation?tex=X_%7Bt%7D" alt="[公式]"> 的预测结果。如果取平均值的话也可以那么会得到0.7，高于阈值0.5，因此是等价的。</p>
<p>但这个时候需要有几个注意的地方：</p>
<p><strong>首先，不同分类器的输出结果取值范围不同</strong>，不一定是[0,1]，而可以是无限定范围的值。举例，逻辑回归的输出范围是0-1（概率），而k-近邻的输出结果可以是大于0的任意实数，其他算法的输出范围可能是负数。<strong>因此整合多个分类器时，需要注意不同分类器的输出范围，并统一这个取值范围</strong>。</p>
<ul>
<li>比如可以先转化为如<strong>二分类结果</strong>，把输出的范围统一后再进行整合。但这种方法的问题在于我们丢失了很多信息，0.5和0.99都会被转化为1，但明显其可靠程度差别很大。</li>
<li>也可以转化为排序（ranking），再对不同的ranking进行求平均。</li>
<li>更加稳妥的方法是对每个分类器的输出结果做标准化，也就是调整到正态分布上去。之后就可以对多个调整后的结果进行整合。同理，用归一化也可以有类似的效果。</li>
</ul>
<p><strong>其次，就是整合稳定性的问题</strong>。采用平均法的另一个风险在于可能被极值所影响。正态分布的取值是 <img src="https://www.zhihu.com/equation?tex=%5B-%5Cinfty%2C%2B%5Cinfty%5D" alt="[公式]"> ，在少数情况下平均值会受到少数极值的影响。一个常见的解决方法是，用中位数（median)来代替平均数进行整合。</p>
<p><strong>同时，模型整合面临的另一个问题是子模型良莠不齐</strong>。如果10个模型中有1个表现非常差，那么会拖累最终的效果，适得其反。==因此，简单、粗暴的把所有子模型通过平均法整合起来效果往往一般。==</p>
<h3><span id="3-寻找优秀的子模型准而不同">3. 寻找优秀的子模型准而不同</span></h3><p>不难看出，一个较差的子模型会拖累整体的集成表现，那么这就涉及到另一个问题？什么样的子模型是优秀的。</p>
<p>一般来说，我们希望子模型：<strong>准而不同 -&gt; accurate but diversified</strong>。好的子模型应该首先是准确的，这样才会有所帮助。其次不同子模型间应该有差别，比如独立的误差，这样作为一个整体才能起到<strong>互补作用</strong>。</p>
<p>因此，如果想实现良好的结合效果，就必须对子模型进行筛选，去粗取精。在这里我们需要做出一点解释，我们今天说的融合方法和bagging还有boosting中的思路不大相同。==bagging和boosting中的子模型都是<strong>很简单的且基数庞大</strong>，而我们今天的模型融合是<strong>结合少量但较为复杂的模型</strong>。==</p>
<h3><span id="4-筛选方法赋予不同子模型不同的权重"><strong>4. 筛选方法：赋予不同子模型不同的权重</strong></span></h3><p>因此我们不能再简单的取平均了，而应该给优秀的子模型更大的权重。在这种前提下，一个比较直白的方法就是根据子<strong>模型的准确率给出一个参考权重</strong> <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> ，子模型越准确那么它的权重就更大，对于最终预测的影响就更强： <img src="https://www.zhihu.com/equation?tex=w_%7Bi%7D%3D%5Cfrac%7BAcc%28C_%7Bi%7D%29%7D%7B%5Csum_%7B1%7D%5E%7B10%7D%7BAcc%28C_%7Bj%7D%29%7D%7D" alt="[公式]"> 。简单取平均是这个方法的一个特例，即假设子模型准确率一致。</p>
<h3><span id="5-更进一步学习分类器权重"><strong>5. 更进一步：学习分类器权重</strong></span></h3><p>在4中提到的方法在一定程度上可以缓解问题，但效果有限。那么另一个思路是，我们是否可以学习每个分类器的权重呢？</p>
<p>答案是肯定，这也就是Stacking的核心思路。通过增加一层来学习子模型的权重。</p>
<p><img src="https://pic3.zhimg.com/v2-13396e65c2bcc1c270ca536310686d07_720w.jpg?source=d16d100b" alt="img"></p>
<p><strong>图片来源</strong>：<a href="https://www.quora.com/What-is-stacking-in-machine-learning">https://www.quora.com/What-is-stacking-in-machine-learning</a></p>
<p>更多有关于stacking的讨论可以参考我最近的文章：<a href="https://zhuanlan.zhihu.com/p/32896968">「Stacking」与「神经网络」</a>。简单来说，就是加一层逻辑回归或者SVM，把子模型的输出结果当做训练数据，来自动赋予不同子模型不同的权重。</p>
<p>==<strong>一般来看，这种方法只要使用得当，效果应该比简单取平均值、或者根据准确度计算权重的效果会更好。</strong>==</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（4）损失函数</title>
    <url>/posts/31ZV2YD/</url>
    <content><![CDATA[<p>机器学习中的监督学习本质上是给定一系列训练样本 $\left(x_i, y_i\right)$, 尝试学习 $x \rightarrow y$ 的映射关系, 使得给定一个 $x$ , 即便这个 $x$ 不在训练样本中, 也能够得到尽量接近真实 $y$ 的输出 $\hat{y}$ 。<strong>损失函数 (Loss Function) 则是这个过程中关键的一个组成部分, 用来衡量模型的输出 $\hat{y}$ 与真实的 $y$ 之间的差距, 给模型的优化指明方向。</strong></p>
<p>本文将介绍机器学习、深度学习中分类与回归常用的几种损失函数, 包括<strong>均方差损失 Mean Squared Loss、平 均绝对误差损失 Mean Absolute Error Loss、Huber Loss、分位数损失 Quantile Loss、交叉樀损失函数 Cross Entropy Loss、Hinge 损失 Hinge Loss</strong>。主要介绍各种损失函数的基本形式、原理、特点等方面。</p>
<span id="more"></span>
<h3><span id="前言">前言</span></h3><p>在正文开始之前, 先说下关于 Loss Function、Cost Function 和 Objective Function 的区别和联系。在机器学习 的语境下这三个术语经常被交叉使用。</p>
<ul>
<li><strong>损失函数</strong> Loss Function 通常是<strong>针对单个训练样本而言,</strong> 给定一个模型输出 $\hat{y}$ 和一个真实 $y$, 损失函数输 出一个实值损失 $L=f\left(y_i, \hat{y_i}\right)$</li>
<li><strong>代价函数</strong> Cost Function 通常是<strong>针对整个训练集</strong>（或者在使用 mini-batch gradient descent 时一个 minibatch）的总损失 $J=\sum_{i=1}^N f\left(y_i, \hat{y}_i\right)$</li>
<li><strong>目标函数</strong> Objective Function 是一个更通用的术语, 表示任意希望被优化的函数, 用于机器学习领域和非机 器学习领域 (比如运筹优化)</li>
</ul>
<p>一句话总结三者的关系就是：<font color="red"> <strong>A loss function is a part of a cost function which is a type of an objective function.</strong></font></p>
<p><img src="https://s2.loli.net/2023/04/17/BRyjpDGtWUXcJ2S.png" alt="img" style="zoom: 67%;"></p>
<p>由于损失函数和代价函数只是在针对样本集上有区别，因此在本文中统一使用了损失函数这个术语，但下文的相关公式实际上采用的是代价函数 Cost Function 的形式，请读者自行留意。</p>
<h3><span id="结构风险函数">结构风险函数</span></h3><p>损失函数（loss function）是用来估量模型的预测值f(x)与真实值$Y$不一致的程度，它是一个非负实数值函数，通常使用$L(Y,f(x))$来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数的重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下的式子：</p>
<p><img src="https://s2.loli.net/2023/04/17/TaUDLMBO5upXZEA.png" alt="image-20220821223950768" style="zoom:50%;"></p>
<p>前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的Φ是正则化项（regularizer）或者叫惩罚项（penalty term）,它可以是L1，也可以是L2等其他的正则函数。整个式子表示的意思是找到使目标函数最小时的θ值。下面列出集中常见的损失函数。</p>
<h3><span id="一-对数损失函数逻辑回归mle-交叉熵损失函数">一、 对数损失函数（逻辑回归）MLE  【交叉熵损失函数】</span></h3><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/52100927">https://zhuanlan.zhihu.com/p/52100927</a></p>
<p>  <a href="https://blog.csdn.net/tsyccnh/article/details/79163834">一文搞懂交叉熵在机器学习中的使用，透彻理解交叉熵背后的直觉</a></p>
<p>  <a href="https://zhuanlan.zhihu.com/p/35709485">损失函数｜交叉熵损失函数</a></p>
</blockquote>
<p>有些人可能觉得逻辑回归的损失函数就是平方损失，其实并不是。<strong>平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到</strong>，而逻辑回归得到的并不是平方损失。在逻辑回归的推导中，<strong>它假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数</strong>，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：</p>
<p><strong>最小化负的似然函数</strong>（即$maxF(y,f(x))—&gt;min−F(y,f(x))$)。从损失函数的视角来看，它就成了<strong>log损失函数了。</strong></p>
<h4><span id="原理解释1条件概率下方便计算极大似然估计">原理解释1：<strong>条件概率下方便计算极大似然估计</strong></span></h4><p>Log损失函数的标准形式：</p>
<p>$L(Y,P(Y|X))=−logP(Y|X)$</p>
<p>刚刚说到，<strong>取对数是为了方便计算极大似然估计</strong>，因为在MLE中，直接求导比较困难，所以通常都是先取对数再求导找极值点。损失函数$L(Y.P(Y|X))$表达的是样本在分类$Y$的情况下，使概率$P(Y|X)$达到最大值（换言之，就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者什么样的参数才能使我们观测到目前这组数据的概率最大）。因为log函数是单调递增的，所以$logP(Y|X)$也会达到最大值，因此在前面加上负号之后，最大化$P(Y|X)$就等价于最小化$L$了。</p>
<p><strong>logistic回归</strong>的$P(y|x)$表达式如下（为了将类别标签y统一为1和0，下面将表达式分开表示）：</p>
<p><img src="https://s2.loli.net/2023/04/17/kYQmSNU389DaEgW.png" alt="image-20220322202521355" style="zoom:50%;"></p>
<p>将上面的公式合并在一起，可得到第i个样本正确预测的概率：</p>
<p><img src="https://s2.loli.net/2023/04/17/H9K4sYIapf7lZqC.png" alt="image-20220322202548296" style="zoom:50%;"></p>
<p>上式是对一个样本进行建模的数据表达。对于所有的样本，假设每条样本生成过程独立，在整个样本空间中（N个样本）的概率分布为：</p>
<p><img src="https://s2.loli.net/2023/04/17/9juth32ZNkznoC6.png" alt="image-20220322202618734" style="zoom:50%;"></p>
<p>将上式代入到对数损失函数中，得到最终的损失函数为：</p>
<p><img src="https://s2.loli.net/2023/04/17/Xzdpa6StP4KgNkJ.png" alt="image-20220322202653661" style="zoom:50%;"></p>
<h4><span id="原理解释2相对熵kl散度推理">原理解释2：相对熵（KL散度）推理</span></h4><blockquote>
<p>  相对熵又称KL散度,如果我们对于同一个随机变量 x 有两个单独的概率分布 P(x) 和 Q(x)，我们可以使用 KL 散度（Kullback-Leibler (KL) divergence）来衡量这两个分布的差异.$DKL$的值越小，表示q分布和p分布越接近.</p>
</blockquote>
<h5><span id="相对熵">相对熵:</span></h5><p><img src="https://s2.loli.net/2023/04/17/Hs19MdiWOfokNuP.png" alt="image-20220330133351613" style="zoom:50%;"></p>
<h5><span id="相对熵-信息熵-交叉熵">相对熵 = 信息熵 + 交叉熵 ：</span></h5><p><img src="https://s2.loli.net/2023/04/17/WBZsoc9JwQjkG27.png" alt="image-20220330134202064" style="zoom:50%;"></p>
<p><strong>【对数损失函数（Log loss function）】和【交叉熵损失函数（Cross-entroy loss funtion）】在很多文献内是一致的，因为他们的表示式的本质是一样的。</strong></p>
<h3><span id="二-平方损失函数线性回归gbdt最小二乘法ordinary-least-squaresmse">二、 平方损失函数（线性回归，GBDT，最小二乘法，Ordinary Least Squares）MSE</span></h3><p>最小二乘法是线性回归的一种，OLS 将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（为什么假设成高斯分布呢？其实这里隐藏了一个小知识点，就是中心极限定理，可以参考【central limit theorem】），最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。换言之，OLS是基于<strong>距离</strong>的，而这个距离就是我们用的最多的欧几里得距离。为什么它会选择使用欧式距离作为误差度量呢（即Mean squared error， MSE），主要有以下几个原因：</p>
<ul>
<li>简单，计算方便；</li>
<li>欧氏距离是一种很好的相似性度量标准；</li>
<li>在不同的表示域变换后特征性质不变。</li>
</ul>
<p>平方损失（Square loss）的标准形式如下：$L(Y,f(X))=(Y−f(x))^2$当样本个数为n时，此时的损失函数变为：</p>
<p><img src="https://s2.loli.net/2023/04/17/XuAymnSOw6RhQ9a.png" alt="image-20220322202912962" style="zoom:50%;"></p>
<p>$Y−f(X)$ 表示的是<strong>残差</strong>，整个式子表示的是残差的平方和，而我们的目的就是最小化这个目标函数值（注：该式子未加入正则项），也就是最小化残差的平方和（residual sum of squares，RSS）。</p>
<p>而在实际应用中，通常会使用<strong>均方差</strong>（MSE）作为一项衡量指标，公式如下：</p>
<p><img src="https://s2.loli.net/2023/04/17/dye1NVAtOUw2BoY.png" alt="image-20220322202957484" style="zoom:50%;"></p>
<h3><span id="三-指数损失函数adaboost">三、 指数损失函数（Adaboost）</span></h3><blockquote>
<p>  Adaboost训练误差以指数下降。所以说，指数损失本身并没有带来优化上的特殊，优点在于计算和表达简单。</p>
</blockquote>
<p>学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。在Adaboost中，经过m此迭代之后，可以得到$fm(x)$:</p>
<p><img src="https://s2.loli.net/2023/04/17/fZ8APgDerkSjBIu.png" alt="image-20220322203050695" style="zoom:50%;"></p>
<p><strong>Adaboost</strong>每次迭代时的目的是为了找到最小化下列式子时的参数 $a$ 和 $G$：</p>
<p><img src="https://s2.loli.net/2023/04/17/iphlobfSa5m1cXI.png" alt="image-20220322203141435" style="zoom:50%;"></p>
<p>而指数损失函数(exp-loss）的标准形式如下:</p>
<p><img src="https://s2.loli.net/2023/04/17/hq6iCpQVFeGHnOA.png" alt="image-20220322203221432" style="zoom:50%;"></p>
<p>可以看出，Adaboost的目标式子就是指数损失，在给定N个样本的情况下，Adaboost的损失函数为：</p>
<p><img src="https://s2.loli.net/2023/04/17/ECdNvKtrjZM6o2h.png" alt="image-20220322203238853" style="zoom:50%;"></p>
<h3><span id="四-hinge-合页损失函数svmadvgan">四、 Hinge 合页损失函数（SVM，advGAN）</span></h3><p><img src="https://s2.loli.net/2023/04/17/7x8WAuHyCcMs6I5.png" alt="image-20220401165315551" style="zoom:50%;"></p>
<p>线性支持向量机学习除了原始最优化问题，还有另外一种解释，就是最优化以下目标函数：</p>
<p><img src="https://s2.loli.net/2023/04/17/UXvLs7pH9rj2qoi.png" alt="image-20220322205741804" style="zoom:50%;"></p>
<p>目标函数的第一项是经验损失或经验风险函数：</p>
<p><img src="https://s2.loli.net/2023/04/17/G4hjnsLVavBS9YR.png" alt="image-20220322205801232" style="zoom:50%;"></p>
<p>称为<strong>合页损失函数</strong>（hinge loss function）。下标”+”表示以下取正值的函数：</p>
<p><img src="https://s2.loli.net/2023/04/17/YLEMueb3kBpWxvA.png" alt="image-20220322205844003" style="zoom:50%;"></p>
<p>这就是说，当样本点$(xi,yi)$被正确分类且函数间隔（确信度）$yi(w·xi+b)$大于1时，损失是0，否则损失是$1−yi(w·xi+b)$。目标函数的第二项是系数为 $λ$ 的 $w$ 的 $L2$ 范数，是正则化项。</p>
<p>接下来证明线性支持向量机原始最优化问题：</p>
<p><img src="https://s2.loli.net/2023/04/17/B8nxPKcVfCsGJ92.png" alt="image-20220322210000477" style="zoom:50%;"></p>
<p><img src="https://s2.loli.net/2023/04/17/w1SQdeAEi6qb7c2.png" alt="image-20220322210121285" style="zoom:50%;"></p>
<p>先令$[1−yi(w·xi+b)]+=ξi$，则$ξi≥0$，第二个约束条件成立；由$[1−yi(w·xi+b)]+=ξi$，当$1−yi(w·xi+b)&gt;0$时，有$yi(w·xi+b)=1−ξi$;当$1−yi(w·xi+b)≤0$时，$ξi=0$，有$yi(w·xi+b)≥1−ξi$，所以第一个约束条件成立。所以两个约束条件都满足，最优化问题可以写作</p>
<p><img src="https://s2.loli.net/2023/04/17/Sb7qPknjhDrmAvI.png" alt="image-20220322210943775" style="zoom:50%;"></p>
<p>若取 $λ=1/2C$ 则:</p>
<p><img src="https://s2.loli.net/2023/04/17/VpbFxCN62ArYZyJ.png" alt="image-20220322211012150" style="zoom:50%;"></p>
<h3><span id="五-softmax函数和sigmoid函数的区别与联系">五、Softmax函数和Sigmoid函数的区别与联系</span></h3><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/356976844">https://zhuanlan.zhihu.com/p/356976844</a></p>
</blockquote>
<h4><span id="51-分类任务">5.1 分类任务</span></h4><h5><span id="sigmoid">sigmoid</span></h5><blockquote>
<p>  Sigmoid =<strong>多标签分类问题</strong>=多个正确答案=非独占输出（例如胸部X光检查、住院）。构建分类器，解决有多个正确答案的问题时，用Sigmoid函数分别处理各个原始输出值。</p>
<p>  Softmax =<strong>多类别分类问题</strong>=只有一个正确答案=互斥输出（例如手写数字，鸢尾花）。构建分类器，解决只有唯一正确答案的问题时，用Softmax函数处理各个原始输出值。Softmax函数的分母综合了原始输出值的所有因素，这意味着，Softmax函数得到的不同概率之间相互关联。</p>
</blockquote>
<p><strong>Sigmoid函数</strong>是一种logistic函数，它将任意的值转换到 [0, 1] 之间，如图1所示，函数表达式为:$Sigmoid(x) = \frac{1}{1-e^{-x}}$ 。它的导函数为：$Sigmoid^{‘}(x)=Sigmoid(x)\cdot(1-Sigmoid(x))$。</p>
<p><img src="https://s2.loli.net/2023/04/17/vqpA79snRahWw1F.png" alt="img" style="zoom:50%;"></p>
<p><strong>优点</strong>：</p>
<ol>
<li>Sigmoid函数的输出在(0,1)之间，输出范围有限，优化稳定，可以用作<strong>输出层</strong>。</li>
<li>连续函数，便于<strong>求导</strong>。</li>
</ol>
<p><strong>缺点</strong>：</p>
<ol>
<li><p>最明显的就是<strong>饱和性</strong>，从上图也不难看出其两侧导数逐渐趋近于0，容易造成<strong>梯度消失</strong>。</p>
<p>2.激活函数的偏移现象。Sigmoid函数的输出值均大于0，使得输出不是0的均值，这会导致后一层的神经元将得到上一层非0均值的信号作为输入，这会对梯度产生影响。</p>
</li>
<li><p>计算复杂度高，因为Sigmoid函数是指数形式。</p>
</li>
</ol>
<h5><span id="softmax">Softmax</span></h5><p><strong>Softmax函数</strong>，又称<strong>归一化指数函数</strong>，函数表达式为： $\operatorname{Softmax}(x)=\frac{e^{x_i}}{\sum_{j=1}^n e^{x_j}}$ 。</p>
<p><img src="https://s2.loli.net/2023/04/17/QVYJzvwPZtnpoBE.jpg" alt="img" style="zoom: 67%;"></p>
<p><strong>Softmax函数是二分类函数Sigmoid在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。</strong>如图2所示，Softmax直白来说就是将原来输出是3,1,-3通过Softmax函数一作用，就映射成为(0,1)的值，而这些值的累和为1（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标。</p>
<p>由于Softmax函数先拉大了输入向量元素之间的差异（通过指数函数），然后才归一化为一个概率分布，在应用到分类问题时，它使得各个类别的概率差异比较显著，最大值产生的概率更接近1，这样输出分布的形式更接近真实分布。</p>
<p><strong>Softmax可以由三个不同的角度来解释。从不同角度来看softmax函数，可以对其应用场景有更深刻的理解：</strong></p>
<ol>
<li><strong>softmax可以当作argmax的一种平滑近似</strong>，与arg max操作中暴力地选出一个最大值（产生一个one-hot向量）不同，softmax将这种输出作了一定的平滑，即将one-hot输出中最大值对应的1按输入元素值的大小分配给其他位置。</li>
<li><strong>softmax将输入向量归一化映射到一个类别概率分布</strong>，即 n 个类别上的概率分布（前文也有提到）。这也是为什么在深度学习中常常将softmax作为MLP的最后一层，并配合以交叉熵损失函数（对分布间差异的一种度量)。</li>
<li>从<strong>概率图模型</strong>的角度来看，softmax的这种形式可以理解为一个概率无向图上的联合概率。因此你会发现，条件最大熵模型与softmax回归模型实际上是一致的，诸如这样的例子还有很多。由于概率图模型很大程度上借用了一些热力学系统的理论，因此也可以从物理系统的角度赋予softmax一定的内涵。</li>
</ol>
<h4><span id="52-总结">5.2 总结</span></h4><ol>
<li>如果模型输出为非互斥类别，且可以同时选择多个类别，则采用Sigmoid函数计算该网络的原始输出值。</li>
<li>如果模型输出为<strong>互斥类别</strong>，且只能选择一个类别，则采用Softmax函数计算该网络的原始输出值。</li>
<li><strong>Sigmoid函数</strong>可以用来解决<strong>多标签问题</strong>，<strong>Softmax</strong>函数用来解决<strong>单标签问题</strong>。</li>
<li>对于某个分类场景，当Softmax函数能用时，Sigmoid函数一定可以用。</li>
</ol>
<h3><span id="六-损失函数qampa">六、损失函数Q&amp;A</span></h3><h4><span id="平方误差损失函数和交叉熵损失函数分别适合什么场景">平方误差损失函数和交叉熵损失函数分别适合什么场景？</span></h4><p>一般还说，平方损失函数更适合输出为连续，并且最后一层不含sigmod或softmax激活函数的神经网络；交叉熵损失函数更适合二分类或多分类的场景。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习（1）评价指标</title>
    <url>/posts/27302/</url>
    <content><![CDATA[<blockquote>
<p>  一文看懂机器学习指标：准确率、精准率、召回率、F1、ROC曲线、AUC曲线:<a href="https://zhuanlan.zhihu.com/p/93107394">https://zhuanlan.zhihu.com/p/93107394</a></p>
<p>  <strong>机器学习-最全面的评价指标体系: <a href="https://zhuanlan.zhihu.com/p/359997979">https://zhuanlan.zhihu.com/p/359997979</a></strong></p>
<p>  <a href="https://github.com/HaoMood/homepage/blob/master/files/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8-03-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0.pdf">机器学习工程师面试宝典-03-模型评估</a></p>
<p>  <strong><a href="http://www.china-nb.cn/gongsidongtai/17-85.html">分类模型评估指标——准确率、精准率、召回率、F1、ROC曲线、AUC曲线</a></strong></p>
</blockquote>
<span id="more"></span>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/image-20220421165422230.png" alt="image-20220421165422230" style="zoom:50%;"></p>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/image-20220421165436795.png" alt="image-20220421165436795" style="zoom:50%;"></p>
<h3><span id="一-二分类问题">一、二分类问题</span></h3><blockquote>
<p>  <strong>阈值调节问题？</strong></p>
</blockquote>
<ul>
<li><strong>准确率 (Accuracy)</strong>：<strong>预测正确的概率</strong>  【<strong>(TP+TN)/(TP+TN+FP+FN)</strong>】</li>
<li><strong>精确率（查准率 Precision )：==预测为正的样本==中实际为正的样本的概率</strong> 【<strong>TP/(TP+FP)</strong>】</li>
<li>错误发现率（FDR）= 1 - 精确率 = ==预测为正的样本==中实际为负的样本的概率 【<strong>FP/(TP+FP)</strong>】</li>
<li><strong>召回率（查全率）- Recall</strong>：<strong>==实际为正的样本==中被预测为正样本的概率</strong>【<strong>TP/(TP+FN)</strong>】</li>
<li><strong>真正率（TPR） = 灵敏度（==召回率==） =</strong> <strong>TP/(TP+FN)</strong></li>
<li><strong>假正率（FPR） = 1- 特异度 =</strong> <strong>FP/(FP+TN)</strong></li>
<li><strong>F1=是准确率和召回率的==调和平均值== (2×Precision×Recall)/（Precision+Recall）</strong></li>
<li><strong>G-mean（GM）= 是准确率和召回率的==几何平均值==</strong> <img src="https://image.jiqizhixin.com/uploads/editor/c9841ee6-28df-4eb9-aace-8902a6e525a5/640.svg" alt="img"></li>
</ul>
<h3><span id="11-f12precisionrecall-precisionrecall">1.1 <strong>F1=(2×Precision×Recall) /（Precision+Recall）</strong></span></h3><p>精确率（Precision）和召回率（Recall）之间的关系用图来表达，就是下面的PR曲线。可以发现他们俩的关系是「两难全」的关系。为了综合两者的表现，在两者之间找一个平衡点，就出现了一个 F1分数。</p>
<h4><span id="f12precisionrecall-precisionrecall"><strong>F1=(2×Precision×Recall)  /（Precision+Recall）</strong></span></h4><p>P意义类似于每通过准确预测得到TP个正例需要TP+FP个预测类别为正例的样本。</p>
<p>R意义类似于每通过成功召回得到TP个正例需要TP+FN个真实类别为正例的样本。</p>
<p>F1度量了给定一批样本，对这一批样本进行预测与召回，最终得到的正例的多少。<strong>其中一半的正例是通过预测得到的，一半的正例是通过召回得到的。</strong></p>
<p>有一种把预测所需的预测类别为正例的样本和召回所需的真实类别为正例的样本看作原料，而我们的目标正例样本看作产品的感觉。<strong>所以也能解释为什么P跟R其中一者比较低的时候，F1会偏低。因为跟算术平均数不一样，两者不能互相替代，两部分各负责一半。那么加权调和平均Fbeta也可以很好的理解了。</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7BF_%7B%5Cbeta%7D%7D%3D%5Cfrac%7B1%7D%7B1%2B%5Cbeta%5E%7B2%7D%7D%5Ccdot%5Cleft%28+%5Cfrac%7B1%7D%7BP%7D%2B+%5Cfrac%7B%5Cbeta%5E%7B2%7D%7D%7BR%7D%5Cright%29" alt="[公式]"></p>
<p>各自负责的比例不一样了。因此beta越大，Fbeta越着重考虑召回能力。</p>
<h3><span id="12-rocauc的概念">1.2 ROC/AUC的概念</span></h3><p><strong>1. 灵敏度，特异度，真正率，假正率</strong></p>
<p>在正式介绍ROC/AUC之前，我们还要再介绍两个指标，<strong>这两个指标的选择也正是ROC和AUC可以无视样本不平衡的原因。</strong> 这两个指标分别是：<strong>灵敏度和（1-特异度），也叫做真正率（TPR）和假正率（FPR）</strong>。其实我们可以发现<strong>灵敏度和召回率是一模一样的，只是名字换了而已</strong>。由于我们比较关心正样本，所以需要查看有多少负样本被错误地预测为正样本，所以使用（1-特异度），而不是特异度。</p>
<p><strong>真正率（TPR） = 灵敏度（==召回率==） =</strong> <strong>TP/(TP+FN)</strong></p>
<p><strong>假正率（FPR） = 1- 特异度 =</strong> <strong>FP/(FP+TN)</strong></p>
<p>下面是真正率和假正率的示意，我们发现<strong>TPR和FPR分别是基于实际表现1和0出发的，也就是说它们分别在实际的正样本和负样本中来观察相关概率问题。</strong> </p>
<blockquote>
<p>  正因为如此，所以无论样本是否平衡，都不会被影响。还是拿之前的例子，总样本中，90%是正样本，10%是负样本。我们知道用准确率是有水分的，但是用TPR和FPR不一样。这里，TPR只关注90%正样本中有多少是被真正覆盖的，而与那10%毫无关系，同理，FPR只关注10%负样本中有多少是被错误覆盖的，也与那90%毫无关系，</p>
</blockquote>
<p><strong>如果我们从实际表现的各个结果角度出发，就可以避免样本不平衡的问题了，这也是为什么选用TPR和FPR作为ROC/AUC的指标的原因。</strong></p>
<h4><span id="2-roc接受者操作特征曲线"><strong>2. ROC（接受者操作特征曲线）</strong></span></h4><blockquote>
<p>  ROC（Receiver Operating Characteristic）曲线，又称接受者操作特征曲线。该曲线最早应用于雷达信号检测领域，用于区分信号与噪声。后来人们将其用于评价模型的预测能力，ROC曲线是基于<strong>混淆矩阵</strong>得出的。</p>
</blockquote>
<p>ROC曲线中的主要两个指标就是<strong>真正率</strong>和<strong>假正率，</strong> 上面也解释了这么选择的好处所在。其中<strong>横坐标为假正率（FPR），纵坐标为真正率（TPR）</strong>，下面就是一个标准的ROC曲线图。</p>
<h4><span id="auc的缺陷">AUC的缺陷？</span></h4><p><strong>优点</strong>：目前普遍认为接收器工作特性曲线（ROC）曲线下的面积—AUC是评估分类模型准确性的标准方法。<strong>它避免了在阈值选择过程中假定的主观性</strong>，当连续的概率得到的分数被转换为二分类标签时，通过总结整体模型表现，其衡量模型区分正负样本的性能优于通过阈值来判断的其他方法（比如准确率、召回率等）。</p>
<ul>
<li><strong>忽略了预测的概率值和模型的拟合优度</strong></li>
<li><strong>AUC反应了太过笼统的信息。无法反应召回率、精确率等在实际业务中经常关心的指标</strong></li>
<li><font color="red"> **对FPR和TPR两种错误的代价同等看待**</font></li>
<li>它没有给出模型误差的空间分布信息</li>
<li>最重要的一点，AUC的misleading的问题</li>
</ul>
<p><strong>==auc仅反应模型的排序能力==，无法反应模型的拟合优度；auc很多时候无法直接反应细粒度的和业务目标更相关的metric信息，例如 top k的准确率，召回率等等（例如同auc的模型在不同的区间的预测能力是存在差别的）；</strong></p>
<h3><span id="13-k-s曲线">1.3、K-S曲线</span></h3><blockquote>
<p>  <strong>K-S曲线</strong>，又称作洛伦兹曲线。实际上，K-S曲线的数据来源以及本质和ROC曲线是一致的，只是ROC曲线是把真正率（ <img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> ）和假正率（ <img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> ）当作横纵轴，<strong>而K-S曲线是把真正率（ <img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> ）和假正率（ <img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> )都当作是纵轴，横轴则由选定的阈值来充当。从 </strong>K-S 曲线<strong>就能衍生出 <img src="https://www.zhihu.com/equation?tex=KS" alt="[公式]"> 值， <img src="https://www.zhihu.com/equation?tex=KS+%3D+max%28TPR+-+FPR%29" alt="[公式]"> ，即是两条曲线之间的最大间隔距离。</strong></p>
</blockquote>
<p><strong>K-S曲线的画法：</strong></p>
<ol>
<li><p><strong>排序：</strong>对于二元分类器来说，模型训练完成之后每个样本都会得到一个类概率值，把样本按这个类概率值从大到小进行排序；</p>
</li>
<li><p><strong>找阈值：</strong>取排序后前 <img src="https://www.zhihu.com/equation?tex=10%5C%25%5Ctimes+k%28k%3D1%2C2%2C3%2C...%2C9%29" alt="[公式]"> 处的值（概率值）作为阈值，分别计算出不同的 <img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> 和<img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> 值，以<img src="https://www.zhihu.com/equation?tex=10%5C%25%5Ctimes+k%28k%3D1%2C2%2C3%2C...%2C9%29" alt="[公式]">为横坐标，分别以<img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> 和<img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> 值为纵坐标，就可以画出两个曲线，这就是K-S曲线，类似于下图。</p>
</li>
<li><p><strong>KS值</strong>：</p>
<p>从 <strong>K-S 曲线</strong>就能衍生出 <img src="https://www.zhihu.com/equation?tex=KS" alt="[公式]"> 值， <img src="https://www.zhihu.com/equation?tex=KS+%3D+max%28TPR+-+FPR%29" alt="[公式]"> ，即是两条曲线之间的最大间隔距离。KS值越大表示模型 的区分能力越强。</p>
</li>
</ol>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/v2-f913b42cefcd32f9fdbfa027de2dfbc8_1440w.jpg" alt="img" style="zoom: 50%;"></p>
<h3><span id="14-lift曲线">1.4 Lift曲线</span></h3><p><strong>Lift曲线它衡量的是，与不利用模型相比，模型的预测能力“变好”了多少，lift(提升指数)越大，模型的运行效果越好。实质上它强调的是投入与产出比</strong>。</p>
<p><strong>tip:</strong>理解<strong>Lift</strong>可以先看一下Quora上的一篇文章：<strong><a href="https://link.zhihu.com/?target=https%3A//www.quora.com/Whats-Lift-curve">What’s Lift curve?</a></strong></p>
<p><strong>Lift计算公式：</strong>先介绍几个相关的指标，以免混淆：</p>
<ul>
<li><strong>准确率（accuracy，ACC）</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=ACC%3D%5Cfrac%7BTP%2BTN%7D%7BFP%2BFN%2BTP%2BTN%7D%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>正确率(Precision，PRE)，查准率</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=PRE+%3D+%5Cfrac%7BTP%7D%7BTP%2BFP%7D+%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>真阳性率(True Positive Rate，TPR)，灵敏度(Sensitivity)，召回率(Recall)</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=TPR%3D%5Cfrac%7BTP%7D%7BTP%2BFN%7D+%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>假阳性率(False Positice Rate，FPR)，误诊率( = 1 - 特异度)</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=FPR%3D%5Cfrac%7BFP%7D%7BFP%2BTN%7D%5C%5C" alt="[公式]"></p>
<p><strong>Lift计算公式：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=Lift%3D%5Cfrac%7B%5Cfrac%7BTP%7D%7BTP%2BFP%7D%7D%7B%5Cfrac%7BTP%2BFN%7D%7BTP%2BFP%2BTN%2BFN%7D%7D%3D%5Cfrac%7BPRE%7D%7B%E6%AD%A3%E4%BE%8B%E5%8D%A0%E6%AF%94%7D%5C%5C" alt="[公式]"></p>
<p>根据以上公式可知，<strong>Lift指标可以这样理解：</strong>在不使用模型的情况下，我们用先验概率估计正例的比例，即上式子分母部分，以此作为正例的命中率；利用模型后，我们不需要从整个样本中来挑选正例，只需要从我们预测为正例的那个样本的子集 <img src="https://www.zhihu.com/equation?tex=TP%2BFP" alt="[公式]"> 中挑选正例，这时正例的命中率为 <img src="https://www.zhihu.com/equation?tex=PRE" alt="[公式]"> ，后者除以前者即可得提升值<strong>Lift。</strong></p>
<h4><span id="lift曲线"><strong>Lift曲线：</strong></span></h4><p>为了作出<strong>LIft</strong>曲线，首先引入 <img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]"> 的概念：</p>
<p><img src="https://www.zhihu.com/equation?tex=depth%3D%5Cfrac%7BTP%2BFP%7D%7BTP%2BFP%2BTN%2BFN%7D%5C%5C" alt="[公式]"></p>
<p><strong>从公式可以看出</strong>，<img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]">代表的是预测为正例的样本占整个样本的比例。</p>
<p>当阈值为0时，所有的样本都被预测为正例，因此 <img src="https://www.zhihu.com/equation?tex=depth%3D1" alt="[公式]"> ，于是 <img src="https://www.zhihu.com/equation?tex=Lift%3D1" alt="[公式]"> ，模型未起提升作用。随着阈值逐渐增大，被预测为正例的样本数逐渐减少，<img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]">减小，而较少的预测正例样本中的真实正例比例逐渐增大。当阈值增大至1时，没有样本被预测为正例，此时 <img src="https://www.zhihu.com/equation?tex=depth%3D0" alt="[公式]"> ，而 <img src="https://www.zhihu.com/equation?tex=Lift%3D0" alt="[公式]"> 。由此可见， <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 与<img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]">存在相反方向变化的关系。在此基础上作出 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 图：</p>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/v2-4cfa1e77335b91d9a47acb7238383c1e_1440w.jpg" alt="img" style="zoom: 50%;"></p>
<p>一般要求，在尽量大的 <img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]"> 下得到尽量大的 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]">，所以 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 曲线的右半部分应该尽量陡峭。</p>
<h3><span id="15-p-r曲线">1.5 <strong>P-R曲线</strong></span></h3><ul>
<li><p><strong>精确率（查准率）- Precision ：==预测为正的样本==中实际为正的样本的概率</strong> 【<strong>TP/(TP+FP)</strong>】</p>
</li>
<li><p><strong>召回率（查全率）- Recall</strong>：<strong>==实际为正的样本==中被预测为正样本的概率</strong>【<strong>TP/(TP+FN)</strong>】</p>
</li>
</ul>
<p>P-R曲线刻画<strong>查准率</strong>和<strong>查全率（召回率）</strong>之间的关系，查准率指的是在所有预测为正例的数据中，真正例所占的比例，查全率是指预测为真正例的数据占所有正例数据的比例。查准率和查全率是一对矛盾的度量，一般来说，查准率高时，查全率往往偏低，查全率高时，查准率往往偏低。</p>
<p>在很多情况下，我们可以根据学习器的预测结果对样例进行排序，排在前面的是学习器认为最可能是正例的样本，排在后面的是学习器认为最不可能是正例的样本，按此顺序逐个把样本作为正例进行预测，则每次可计算当前的查全率和查准率，以查准率为y轴，以查全率为x轴，可以画出下面的P-R曲线。</p>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/v2-dc6abbb24e2dfbfefe4777408d2a8e5c_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>如果一个学习器的P-R曲线被另一个学习器的P-R曲线完全包住，则可断言后者的性能优于前者，当然我们可以根据曲线下方的面积大小来进行比较，但更常用的是<strong>平衡点</strong>或者是F1值。</p>
<ul>
<li><strong>平衡点（BEP）</strong>是查准率=查全率时的取值，如果这个值较大，则说明学习器的性能较好。F1值越大，我们可以认为该学习器的性能较好。</li>
<li><font color="red"> **F1度量**：**BEP过于简单，这个平衡点是建立在”查准率=查全率“的前提下，无法满足实际不同场景的应用。**</font>

</li>
</ul>
<p>我们先来引入加权调和平均： <img src="https://www.zhihu.com/equation?tex=F_%5Cbeta" alt="[公式]">：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+%5Cfrac+%7B1%7D%7BF_%7B%5Cbeta%7D%7D%3D%5Cfrac+%7B1%7D%7B1%2B%7B%5Cbeta%7D%5E2%7D%28%5Cfrac%7B1%7D%7BP%7D%2B%5Cfrac%7B%5Cbeta%5E2%7D%7BR%7D%29++++%5Cquad+%E5%85%AC%E5%BC%8F%281%29" alt="[公式]"></p>
<p>加权调和平均与<strong>算术平均</strong> <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7BP%2BR%7D%7B2%7D" alt="[公式]"> 和<strong>几何平均</strong> <img src="https://www.zhihu.com/equation?tex=%5Csqrt%7BP%2BR%7D" alt="[公式]"> 相比，<strong>调和平均更重视较小值（这可以从倒数上看出来）</strong>。当 <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3D1+" alt="[公式]"> ，即F1是基于查准率和查全率的调和平均定义的，F1的公式如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+%5Cfrac+%7B1%7D%7BF_%7B1%7D%7D%3D%5Cfrac+%7B1%7D%7B2%7D%28%5Cfrac%7B1%7D%7BP%7D%2B%5Cfrac%7B1%7D%7BR%7D%29" alt="[公式]"></p>
<p>我们把公式求倒数，即可得：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+F1%3D%5Cfrac%7B2%2AP%2AR%7D%7BP%2BR%7D" alt="[公式]"></p>
<p>在一些应用中，对查准率和查全率的重视程度不同。例如在商品推荐中，为了尽可能少打扰用户，更希望推荐的内容确实是用户感兴趣的，此时查准率更重要；而在罪犯信息检索或者病人检查系统中，更希望尽可能少的漏判，此时查全率更重要。F1度量的一般形式是 <img src="https://www.zhihu.com/equation?tex=F_%7B%5Cbeta%7D" alt="[公式]"> ，能让我们自定义对查准率/查全率的不同偏好：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+F_%7B%5Cbeta%7D%3D%5Cfrac%7B%281%2B%5Cbeta%5E2%29%2AP%2AR%7D%7B%28%5Cbeta%5E2%2AP%29%2BR%7D" alt="[公式]"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3E0+" alt="[公式]"> 度量了查全率对查准率的相对重要性（不明白的同学可以回看公式1）， <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3D1" alt="[公式]"> 时退化为标准F1，<img src="https://www.zhihu.com/equation?tex=%5Cbeta%3E1+" alt="[公式]">==时查全率有更大影响； <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3C1" alt="[公式]"> 时，查准率有更大影响。==</p>
<h3><span id="16-对数损失log-loss">1.6 <strong>对数损失(Log Loss)</strong></span></h3><p><strong>AUC ROC考虑用于确定模型性能的预测概率</strong>。然而，AUC ROC存在问题，它只考虑概率的顺序，因此<strong>没有考虑模型预测更可能为正样本的更高概率的能力(即考虑了大小，但没有考虑更高精度)</strong>。<strong>在这种情况下，我们可以使用对数损失，即每个实例的正例预测概率的对数的负平均值。</strong></p>
<p>对数损失（Logistic Loss，logloss）是对预测概率的似然估计，其标准形式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+logloss%3DlogP%28Y%7CX%29" alt="[公式]"></p>
<p>对数损失最小化本质是上利用样本中的已知分布，求解拟合这种分布的最佳模型参数，使这种分布出现概率最大。</p>
<p>对数损失对应的二分类的计算公式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=logloss%3D-%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_ilog%5Chat%7By_i%7D%2B%281-y_i%29log%281-%5Chat%7By_i%7D%29%29+%2C%5Cquad%5Cquad%5Cquad+y%5Cin%5B0%2C1%5D" alt="[公式]"></p>
<p>其中N为样本数， <img src="https://www.zhihu.com/equation?tex=%5Chat+y_i" alt="[公式]"> 为预测为1的概率。对数损失在多分类问题中也可以使用，其计算公式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=logloss%3D-%5Cfrac%7B1%7D%7BN%7D%5Cfrac%7B1%7D%7BC%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%5Csum_%7Bj%3D1%7D%5E%7BC%7D%28y_%7Bij%7Dlog%5Chat%7By_%7Bij%7D%7D%29+%2C%5Cquad%5Cquad%5Cquad+y%5Cin%5B0%2C1%5D" alt="[公式]"></p>
<p>其中，N为样本数，C为类别数，logloss衡量的是预测概率分布和真实概率分布的差异性，取值越小越好。</p>
<h3><span id="17-多分类">1.7 多分类</span></h3><p>很多时候我们有多个<strong>二分类混淆矩阵</strong>，例如进行多次训练/测试，每次得到一个混淆矩阵；或是在多个数据集上进行训练/测试，希望估计算法的全局性能；或者是执行分类任务，每两两类别的组合都对应一个混淆矩阵；总之是在<strong>n个二分类混淆矩阵上综合考察查准率和查全率</strong>。</p>
<ul>
<li><strong>宏观</strong>：在各个混淆军阵上分别计算出查准率和查全率，记为(P1,R1)，(P2,R2),…(Pn,Rn)，在<strong>计算平均值</strong>，这样就得到“宏观查准率”(macro-P)，“宏观查全率”(macro-R)、“宏观F1”(macro-F1)：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+macro-P+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7DP_i" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+macro-R+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7DR_i" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+macro-F1%3D%5Cfrac%7B2%2Amacro-P%2Amacro-R%7D%7Bmacro-P%2Bmacro-R%7D" alt="[公式]"></p>
<ul>
<li><strong>微观</strong>：<strong>将个混淆矩阵对应的元素进行平均，得到TP、FP、TN、FN的平均值</strong>，分别记为 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BTP%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BFP%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BFN%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BTN%7D" alt="[公式]"> ，再基于这些平均值计算出“微观查准率”(micro-P)，“微观查全率”(micro-R)、“微观F1”(micro-F1)：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+micro-P%3D%5Cfrac%7B%5Coverline%7BTP%7D%7D%7B%5Coverline%7BTP%7D%2B%5Coverline%7BFP%7D%7D" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+micro-R%3D%5Cfrac%7B%5Coverline%7BTP%7D%7D%7B%5Coverline%7BTP%7D%2B%5Coverline%7BFN%7D%7D" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+micro-F1%3D%5Cfrac%7B2%2Amicro-P%2Amicro-R%7D%7Bmicro-P%2Bmicro-R%7D" alt="[公式]"></p>
<h2><span id="二-回归问题评价指标">二、回归问题评价指标</span></h2><blockquote>
<p>  <strong>均方差损失 Mean Squared Loss、平均绝对误差损失 Mean Absolute Error Loss、Huber Loss、分位数损失 Quantile Loss</strong></p>
</blockquote>
<p>机器学习中的监督学习本质上是给定一系列训练样本 <img src="https://www.zhihu.com/equation?tex=%28x_i%2C+y_i%29" alt="[公式]"> ，尝试学习 <img src="https://www.zhihu.com/equation?tex=x%5Crightarrow+y" alt="[公式]"> 的映射关系，使得给定一个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> ，即便这个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 不在训练样本中，也能够得到尽量接近真实 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 的输出 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D" alt="[公式]"> 。而损失函数（Loss Function）则是这个过程中关键的一个组成部分，用来<strong>衡量模型的输出</strong> <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D" alt="[公式]"> <strong>与真实的</strong> <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> <strong>之间的差距</strong>，给模型的优化指明方向。</p>
<h3><span id="21-均方差损失-mse-l2-loss">2.1 均方差损失 MSE、L2 loss</span></h3><h5><span id="基本形式与原理"><strong>基本形式与原理</strong></span></h5><p><strong>均方差Mean Squared Error (MSE)损失是机器学习、深度学习回归任务中最常用的一种损失函数</strong>，也称为 <strong>L2 Loss</strong>。其基本形式如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=J_%7BMSE%7D+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_i+-+%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>从直觉上理解均方差损失，这个损失函数的最小值为 0（当预测等于真实值时），最大值为无穷大。下图是对于真实值 <img src="https://www.zhihu.com/equation?tex=y%3D0" alt="[公式]"> ，不同的预测值 <img src="https://www.zhihu.com/equation?tex=%5B-1.5%2C+1.5%5D" alt="[公式]"> 的均方差损失的变化图。横轴是不同的预测值，纵轴是均方差损失，可以看到随着预测与真实值绝对误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y-+%5Chat%7By%7D%5Crvert" alt="[公式]"> 的增加，均方差损失呈二次方地增加。</p>
<p><img src="https://pic1.zhimg.com/80/v2-f13a4355c21d16cad8b3f30e8a24b5cc_1440w.jpg" alt="img"></p>
<blockquote>
<h4><span id="背后的假设">背后的假设</span></h4><p>  <strong>【独立同分布-中心极限定理】</strong>：<br>  如果 <img src="https://www.zhihu.com/equation?tex=%5C%7BX_n%5C%7D" alt="[公式]"> 独立同分布，且 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb+EX%3D%5Cmu%2C%5Cquad+%5Cmathbb+D+X%3D%5Csigma%5E2%3E0" alt="[公式]"> ，则n足够大时 <img src="https://www.zhihu.com/equation?tex=%5Coverline+X_n" alt="[公式]"> 近似服从正态分布 <img src="https://www.zhihu.com/equation?tex=N%5Cleft%28%5Cmu%2C%5Cfrac%7B%5Csigma%5E2%7Dn%5Cright%29" alt="[公式]"> ，即</p>
<p>  <img src="https://www.zhihu.com/equation?tex=%5Clim_%7Bn%5Cto%5Cinfty%7DP%5Cleft%28%5Cfrac%7B%5Coverline+X_n-%5Cmu%7D%7B%5Csigma%2F%5Csqrt+n%7D%3Ca%5Cright%29%3D%5CPhi%28a%29%3D%5Cint_%7B-%5Cinfty%7D%5Ea%5Cfrac1%7B%5Csqrt%7B2%5Cpi%7D%7De%5E%7B-t%5E2%2F2%7Ddt%5C%5C" alt="[公式]"></p>
<p>  实际上在一定的假设下，我们可以使用最大化似然得到均方差损失的形式。假设<strong>模型预测与真实值之间的误差服从标准高斯分布</strong>（ <img src="https://www.zhihu.com/equation?tex=%5Cmu%3D0%2C+%5Csigma%3D1" alt="[公式]"> ），则给定一个 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 模型输出真实值 <img src="https://www.zhihu.com/equation?tex=y_i" alt="[公式]"> 的概率为</p>
<p>  <img src="https://www.zhihu.com/equation?tex=p%28y_i%7Cx_i%29+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%7D%5Cmathbb%7Bexp%7D%5Cleft+%28-%5Cfrac%7B%28y_i-%5Chat%7By_i%7D%29%5E2%7D%7B2%7D%5Cright+%29+%5C%5C" alt="[公式]"></p>
<p>  <strong>进一步我们假设数据集中 N 个样本点之间相互独立，则给定所有 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 输出所有真实值 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 的概率，即似然 Likelihood</strong>，为所有 <img src="https://www.zhihu.com/equation?tex=p%28y_i+%5Cvert+x_i%29" alt="[公式]"> 的累乘</p>
<p>  <img src="https://www.zhihu.com/equation?tex=L%28x%2C+y%29+%3D+%5Cprod_%7Bi%3D1%7D%5E%7BN%7D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%7D%5Cmathbb%7Bexp%7D%5Cleft+%28-%5Cfrac%7B%28y_i-%5Chat%7By_i%7D%29%5E2%7D%7B2%7D%5Cright%29+%5C%5C" alt="[公式]"></p>
<p>  通常为了计算方便，我们通常最大化对数似然 Log-Likelihood</p>
<p>  <img src="https://www.zhihu.com/equation?tex=LL%28x%2C+y%29%3D%5Cmathbb%7Blog%7D%28L%28x%2C+y%29%29%3D-%5Cfrac%7BN%7D%7B2%7D%5Cmathbb%7Blog%7D2%5Cpi+-+%5Cfrac%7B1%7D%7B2%7D+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%28y_i-%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>  去掉与 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D" alt="[公式]"> 无关的第一项，然后转化为最小化负对数似然 Negative Log-Likelihood</p>
<p>  <img src="https://www.zhihu.com/equation?tex=NLL%28x%2C+y%29+%3D+%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_i+-+%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>  可以看到这个实际上就是均方差损失的形式。也就是说<strong>在模型输出与真实值的误差服从高斯分布的假设下，最小化均方差损失函数与极大似然估计本质上是一致的</strong>，因此在这个假设能被满足的场景中（比如回归），均方差损失是一个很好的损失函数选择；当这个假设没能被满足的场景中（比如分类），均方差损失不是一个好的选择。</p>
</blockquote>
<h3><span id="hulu-百面机器学习-平方根误差的意外"><strong><font color="red"> hulu 百面机器学习 —— 平方根误差的”意外“</font></strong></span></h3><h4><span id="95的时间区间效果很好rmse指标居高不下的原因">95%的时间区间效果很好，RMSE指标居高不下的原因？</span></h4><p><img src="https://www.zhihu.com/equation?tex=J_%7BMSE%7D+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_i+-+%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>一般情况下RSME能反应预测值与真实值的偏离程度，但是<strong>易受离群点</strong>的影响；</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>数据预处理将噪音去掉</li>
<li>将离群点的产生机制建模进去</li>
<li>更鲁棒的模型评估指标：<strong>平均绝对百分比误差</strong>（MAPE），<strong>分位数损失</strong></li>
</ul>
<h4><span id="22-平均绝对误差-mae">2.2 <strong>平均绝对误差 MAE</strong></span></h4><p><strong>平均绝对误差 Mean Absolute Error (MAE）</strong> 是另一类常用的损失函数，也称为 <strong>L1 Loss</strong>。其基本形式如下</p>
<p><img src="https://www.zhihu.com/equation?tex=+J_%7BMAE%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%5Cleft+%7C+y_i+-+%5Chat%7By_i%7D+%5Cright+%7C+%5C%5C" alt="[公式]"></p>
<p>同样的我们可以对这个损失函数进行可视化如下图，MAE 损失的最小值为 0（当预测等于真实值时），最大值为无穷大。可以看到随着预测与真实值绝对误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y-+%5Chat%7By%7D%5Crvert" alt="[公式]"> 的增加，MAE 损失呈线性增长。</p>
<p><img src="https://pic3.zhimg.com/80/v2-fd248542b6b5aa9fadcab44340045dee_1440w.jpg" alt="img"></p>
<blockquote>
<h4><span id="背后的假设">背后的假设</span></h4><p>  同样的我们可以在一定的假设下通过最大化似然得到 MAE 损失的形式，假设<strong>模型预测与真实值之间的误差服从拉普拉斯分布 Laplace distribution</strong>（ <img src="https://www.zhihu.com/equation?tex=%5Cmu%3D0%2C+b%3D1" alt="[公式]"> ），则给定一个 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 模型输出真实值 <img src="https://www.zhihu.com/equation?tex=y_i" alt="[公式]"> 的概率为</p>
<p>  <img src="https://www.zhihu.com/equation?tex=p%28y_i%7Cx_i%29+%3D+%5Cfrac%7B1%7D%7B2%7D%5Cmathbb%7Bexp%7D%28-%5Cleft+%7Cy_i-%5Chat%7By_i%7D%5Cright%7C%29+%5C%5C" alt="[公式]"></p>
<p>  与上面推导 MSE 时类似，我们可以得到的负对数似然实际上就是 MAE 损失的形式</p>
<p>  <img src="https://www.zhihu.com/equation?tex=L%28x%2C+y%29+%3D+%5Cprod_%7Bi%3D1%7D%5E%7BN%7D%5Cfrac%7B1%7D%7B2%7D%5Cmathbb%7Bexp%7D%28-%7Cy_i-%5Chat%7By_i%7D%7C%29%5C%5C+++LL%28x%2C+y%29+%3D+N%5Cln%7B%5Cfrac%7B1%7D%7B2%7D%7D+-+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%7Cy_i-%5Chat%7By_i%7D%7C+%5C%5C+++NLL%28x%2C+y%29+%3D+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%7Cy_i-%5Chat%7By_i%7D%7C++%5C%5C" alt="[公式]"></p>
</blockquote>
<h3><span id="23-mae-与-mse-区别">2.3 MAE 与 MSE 区别</span></h3><p>MAE 和 MSE 作为损失函数的主要区别是：<strong>MSE 损失相比 MAE 通常可以更快地收敛，但 MAE 损失对于 outlier 更加健壮</strong>，即更加不易受到 outlier 影响。</p>
<ul>
<li><p><strong>MSE 通常比 MAE 可以更快地收敛</strong>。当使用梯度下降算法时，MSE 损失的梯度为 <img src="https://www.zhihu.com/equation?tex=-%5Chat%7By_i%7D" alt="[公式]"> ，而 MAE 损失的梯度为 <img src="https://www.zhihu.com/equation?tex=%5Cpm1" alt="[公式]"> ，即 MSE 的梯度的 scale 会随误差大小变化，而 MAE 的梯度的 scale 则一直保持为 1，即便在绝对误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y_i-%5Chat%7By_i%7D+%5Crvert" alt="[公式]"> 很小的时候 MAE 的梯度 scale 也同样为 1，这实际上是非常不利于模型的训练的。当然你可以通过在训练过程中动态调整学习率缓解这个问题，但是总的来说，损失函数梯度之间的差异导致了 MSE 在大部分时候比 MAE 收敛地更快。这个也是 MSE 更为流行的原因。</p>
</li>
<li><p><strong>MAE 对于异常值（outlier） 更加 robust</strong>。我们可以从两个角度来理解这一点：</p>
<ul>
<li>第一个角度是直观地理解，下图是 MAE 和 MSE 损失画到同一张图里面，由于MAE 损失与绝对误差之间是线性关系，MSE 损失与误差是平方关系，当误差非常大的时候，MSE 损失会远远大于 MAE 损失。<strong>因此当数据中出现一个误差非常大的 outlier 时，MSE 会产生一个非常大的损失，对模型的训练会产生较大的影响</strong>。<img src="https://pic2.zhimg.com/80/v2-c8edffe0406dafae41a042e412cd3251_1440w.jpg" alt="img"></li>
<li>第二个角度是从两个损失函数的假设出发，MSE 假设了误差服从高斯分布，MAE 假设了误差服从拉普拉斯分布。拉普拉斯分布本身对于 outlier 更加 robust。参考下图（来源：<a href="https://link.zhihu.com/?target=https%3A//www.cs.ubc.ca/~murphyk/MLbook/">Machine Learning: A Probabilistic Perspective</a> 2.4.3 The Laplace distribution Figure 2.8），当右图右侧出现了 outliers 时，拉普拉斯分布相比高斯分布受到的影响要小很多。因此以拉普拉斯分布为假设的 MAE 对 outlier 比高斯分布为假设的 MSE 更加 robust。<img src="https://pic1.zhimg.com/80/v2-93ad65845f5b0dc0327fde4ded661804_1440w.jpg" alt="img" style="zoom: 67%;"></li>
</ul>
</li>
</ul>
<h3><span id="24-huber-loss">2.4 Huber Loss</span></h3><blockquote>
<ul>
<li>在误差接近 0 时使用 MSE，使损失函数可导并且梯度更加稳定</li>
<li>在误差较大时使用 MAE 可以降低 outlier 的影响，使训练对 outlier 更加健壮。</li>
</ul>
</blockquote>
<p>上文我们分别介绍了 MSE 和 MAE 损失以及各自的优缺点，MSE 损失收敛快但容易受 outlier 影响，MAE 对 outlier 更加健壮但是收敛慢，<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Huber_loss">Huber Loss</a> 则是一种将 MSE 与 MAE 结合起来，取两者优点的损失函数，也被称作 Smooth Mean Absolute Error Loss 。其原理很简单，就是在误差接近 0 时使用 MSE，误差较大时使用 MAE，公式为</p>
<p><img src="https://www.zhihu.com/equation?tex=J_%7Bhuber%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN%5Cmathbb%7BI%7D_%7B%7C+y_i+-+%5Chat%7By_i%7D%7C+%5Cleq+%5Cdelta%7D+%5Cfrac%7B%28y_i+-+%5Chat%7By_i%7D%29%5E2%7D%7B2%7D%2B+%5Cmathbb%7BI%7D_%7B%7C+y_i+-+%5Chat%7By_i%7D%7C+%3E+%5Cdelta%7D+%28%5Cdelta+%7Cy_i+-+%5Chat%7By_i%7D%7C+-+%5Cfrac%7B1%7D%7B2%7D%5Cdelta%5E2%29+%5C%5C" alt="[公式]"></p>
<p>上式中 <img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="[公式]"> 是 Huber Loss 的一个超参数，<img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="[公式]"> 的值是 MSE 和 MAE 两个损失连接的位置。上式等号右边第一项是 MSE 的部分，第二项是 MAE 部分，在 MAE 的部分公式为 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+%5Clvert+y_i+-+%5Chat%7By_i%7D%5Crvert+-+%5Cfrac%7B1%7D%7B2%7D%5Cdelta%5E2" alt="[公式]"> 是为了保证误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y+-+%5Chat%7By%7D%5Crvert%3D%5Cpm+%5Cdelta" alt="[公式]"> 时 MAE 和 MSE 的取值一致，进而保证 Huber Loss 损失连续可导。</p>
<p>下图是 <img src="https://www.zhihu.com/equation?tex=%5Cdelta%3D1.0" alt="[公式]"> 时的 Huber Loss，可以看到在 <img src="https://www.zhihu.com/equation?tex=%5B-%5Cdelta%2C+%5Cdelta%5D" alt="[公式]"> 的区间内实际上就是 MSE 损失，在 <img src="https://www.zhihu.com/equation?tex=%28-%5Cinfty%2C+%5Cdelta%29" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%28%5Cdelta%2C+%5Cinfty%29" alt="[公式]"> 区间内为 MAE损失。</p>
<p><img src="https://pic4.zhimg.com/80/v2-b4260d38f70dd920fa46b8717596bda7_1440w.jpg" alt="img"></p>
<h3><span id="25-分位数损失-quantile-loss">2.5 分位数损失 Quantile Loss</span></h3><blockquote>
<p>  <strong>MAE 中分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong></p>
</blockquote>
<p><strong>分位数回归 Quantile Regression 是一类在实际应用中非常有用的回归算法</strong>，通常的回归算法是拟合目标值的期望或者中位数，而分位数回归可以通过给定不同的分位点，<strong>拟合目标值的不同分位数</strong>。</p>
<p><img src="https://pic1.zhimg.com/80/v2-8eb8ecfcdd8031a16a471905217934a0_1440w.jpg" alt="img"></p>
<p>分位数回归是通过使用分位数损失 Quantile Loss 来实现这一点的，分位数损失形式如下，式中的 r 分位数系数。</p>
<p><img src="https://www.zhihu.com/equation?tex=J_%7Bquant%7D+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%5Cmathbb%7BI%7D_%7B%5Chat%7By_i%7D%5Cgeq+y_i%7D%281-r%29%7Cy_i+-+%5Chat%7By_i%7D%7C+%2B+%5Cmathbb%7BI%7D_%7B%5Chat%7By_i%7D%3C+y_i%7Dr%7Cy_i-%5Chat%7By_i%7D%7C+%5C%5C" alt="[公式]"></p>
<p>我们如何理解这个损失函数呢？这个损失函数是一个分段的函数 ，将 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D+%5Cgeq+y_i" alt="[公式]"> （高估） 和 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D+%3C+y_i" alt="[公式]"> （低估） 两种情况分开来，并分别给予不同的系数。当 <img src="https://www.zhihu.com/equation?tex=r%3E0.5" alt="[公式]"> 时，低估的损失要比高估的损失更大，反过来当 <img src="https://www.zhihu.com/equation?tex=r+%3C+0.5" alt="[公式]"> 时，高估的损失比低估的损失大；分位数损失实现了<strong>分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong>。特别地，当 <img src="https://www.zhihu.com/equation?tex=r%3D0.5" alt="[公式]"> 时，分位数损失退化为 MAE 损失，从这里可以看出 MAE 损失实际上是分位数损失的一个特例 — 中位数回归。</p>
<p>下图是取不同的分位点 0.2、0.5、0.6 得到的三个不同的分位损失函数的可视化，可以看到 0.2 和 0.6 在高估和低估两种情况下损失是不同的，而 0.5 实际上就是 MAE。</p>
<p><img src="https://pic4.zhimg.com/80/v2-f8ed385f32a517c784bce841e6da1daf_1440w.jpg" alt="img"></p>
<h3><span id="26-平均绝对百分误差-mape">2.6  平均绝对百分误差 MAPE</span></h3><p>虽然平均绝对误差能够获得一个评价值，但是你并不知道这个值代表模型拟合是优还是劣，只有通过对比才能达到效果。当需要以相对的观点来衡量误差时，则使用MAPE。</p>
<p><strong>平均绝对百分误差</strong>（<strong>Mean Absolute Percentage Error，MAPE</strong>）是对 MAE 的一种改进，考虑了绝对误差相对真实值的比例。</p>
<ul>
<li><strong>优点</strong>：考虑了预测值与真实值的误差。考虑了误差与真实值之间的比例。</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=MAPE%3D%5Cfrac%7B100%7D%7Bm%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20%5Cleft%20%7C%20%20%5Cfrac%7By_%7Bi%7D-f%5Cleft%28x_%7Bi%7D%5Cright%29%7D%7By_%7Bi%7D%7D%20%5Cright%20%7C" alt="公式"></p>
<blockquote>
<p>  在某些场景下，如房价从 <img src="https://www.zhihu.com/equation?tex=5K" alt="公式"> 到 <img src="https://www.zhihu.com/equation?tex=50K" alt="公式"> 之间，<img src="https://www.zhihu.com/equation?tex=5K" alt="公式"> 预测成 <img src="https://www.zhihu.com/equation?tex=10K" alt="公式"> 与 <img src="https://www.zhihu.com/equation?tex=50K" alt="公式"> 预测成 <img src="https://www.zhihu.com/equation?tex=45K" alt="公式"> 的差别是非常大的，而平均绝对百分误差考虑到了这点。</p>
</blockquote>
<h2><span id="三-相似性度量指标">三、相似性度量指标</span></h2><blockquote>
<p>  机器学习中的相似性度量方法 - 天下客的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/411876558">https://zhuanlan.zhihu.com/p/411876558</a></p>
</blockquote>
<p>描述样本之间相似度的方法有很多种，一般来说常用的有相关系数和欧式距离。本文对机器学习中常用的相似性度量方法进行了总结。<strong>在做分类时，常常需要估算不同样本之间的相似性度量（Similarity Measurement），</strong>这时通常采用的方法就是计算样本间的“距离”（distance）。采用什么样的方法计算距离是很讲究的，甚至关系到分类的正确与否。</p>
<ul>
<li><strong>欧式距离</strong>：k-means</li>
<li><strong>曼哈顿距离</strong>：</li>
<li><strong>切比雪夫距离</strong>：</li>
<li>闵可夫斯基距离</li>
<li>标准化欧氏距离</li>
<li>马氏距离</li>
<li><a href="https://www.zhihu.com/search?q=夹角余弦&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;55493039&quot;}">夹角余弦</a></li>
<li><strong>汉明距离</strong>：simhash</li>
<li><strong>杰卡德距离&amp;杰卡德相似系数</strong>: <strong>杰卡德相似系数是衡量两个集合的相似度一种指标。</strong></li>
<li>相关系数&amp;相关距离</li>
<li>信息熵</li>
</ul>
<h2><span id="四-推荐算法评价指标">四、推荐算法评价指标</span></h2><ul>
<li>推荐算法评价指标 - 一干正事就犯困的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/359528909">https://zhuanlan.zhihu.com/p/359528909</a></li>
</ul>
<h4><span id="41-ap">4.1 AP</span></h4><p><code>AP</code> 衡量的是训练好的模型在每个类别上的好坏；</p>
<p><img src="https://pic2.zhimg.com/80/v2-e8656365e7eee25065d6bdfec33368e5_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p><strong>AP总结了一个精确召回曲线，作为在每个阈值处获得的精度的加权平均值，并且与以前的阈值相比，召回率的增加用作权重</strong>：</p>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20220711160205051.png" alt="image-20220711160205051" style="zoom:50%;"></p>
<p>其中和分别是第n个阈值[1]时的精度和召回率。此实现未进行插值，并且与使用梯形规则计算精确调用曲线下的面积有所不同，后者使用线性插值并且可能过于乐观。</p>
<h4><span id="42-map">4.2 MAP</span></h4><p><strong>MAP（Mean Average Precision）常用于排序任务，MAP的计算涉及另外两个指标：Precision和Recall</strong></p>
<ul>
<li><strong>Precision和Precision@k</strong></li>
</ul>
<p>推荐算法中的精度precision计算如下： </p>
<p><img src="https://www.zhihu.com/equation?tex=precision%3D%5Cfrac%7B%E7%AE%97%E6%B3%95%E7%BB%93%E6%9E%9C%E4%B8%AD%E7%9B%B8%E5%85%B3%E7%9A%84item%E6%95%B0%E9%87%8F%7D%7B%E6%8E%A8%E8%8D%90%E7%9A%84item%E6%80%BB%E6%95%B0%E9%87%8F%7D+%5C%5C" alt="[公式]"></p>
<p>可以看出Precision的计算没有考虑结果列表中item的顺序，Precision@k则通过切片的方式将顺序隐含在结果中。Precision@k表示列表前k项的Precision，随着k的变化，可以得到一系列precision值，用 <img src="https://www.zhihu.com/equation?tex=P%28k%29" alt="[公式]"> 表示。</p>
<ul>
<li><strong>Recall和Recall@k</strong></li>
</ul>
<p>推荐算法中的召回率recall计算如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=+recall%3D%5Cfrac%7B%E7%AE%97%E6%B3%95%E7%BB%93%E6%9E%9C%E4%B8%AD%E7%9B%B8%E5%85%B3%E7%9A%84item%E6%95%B0%E9%87%8F%7D%7B%E6%89%80%E6%9C%89%E7%9B%B8%E5%85%B3%E7%9A%84item%E6%95%B0%E9%87%8F%7D%5C%5C" alt="[公式]"></p>
<p>与Precision@k相似，recall@k表示结果列表前k项的recall，随着k的变化，可以得到一系列的recall值，用 <img src="https://www.zhihu.com/equation?tex=r%28k%29" alt="[公式]"> 表示。</p>
<ul>
<li><h5><span id="apn">AP@N</span></h5></li>
</ul>
<p>AP（Average Precision）平均精度的计算以Precision@k为基础，可以体现出结果列表中item顺序的重要性，其计算过程如下： </p>
<p><img src="https://www.zhihu.com/equation?tex=AP%40N%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum%5EN_%7Bk%3D1%7D%28P%28k%29%5Cquad+if%5C%2C+kth%5C%2C+item%5C%2C+is%5C%2C+relevant%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum%5EN_%7Bk%3D1%7DP%28k%29%5Ccdot+rel%28k%29+%5C%5C" alt="[公式]"></p>
<p>其中，N表示要求推荐的N个item，m表示所有相关的item总数， <img src="https://www.zhihu.com/equation?tex=rel%28k%29" alt="[公式]"> 表示第k个item是否相关，相关为1，反之为0</p>
<p><strong>AP@N的值越大，表示推荐列表中相关的item数量越多以及相关item的排名越靠前</strong></p>
<ul>
<li><h5><span id="mapn">MAP@N</span></h5></li>
</ul>
<p><strong>AP@N评价了算法对单个用户的性能，MAP@N则是算法对多个用户的平均值，是平均数的平均，其计算过程如下</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=MAP%40N%3D%5Cfrac%7B1%7D%7B%7CU%7C%7D%5Csum_%7Bu%3D1%7D%5E%7B%7CU%7C%7D%28AP%40N%29u%3D%5Cfrac%7B1%7D%7B%7CU%7C%7D%5Csum%7Bu%3D1%7D%5E%7B%7CU%7C%7D%28%5Cfrac%7B1%7D%7Bm%7D%5Csum%5EN_%7Bk%3D1%7DP_u%28k%29%5Ccdot+rel_u%28k%29%29+%5C%5C" alt="[公式]"></p>
<h2><span id="五-聚类算法评价指标">五、聚类算法评价指标</span></h2><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/343667804">https://zhuanlan.zhihu.com/p/343667804</a></p>
<p>  十分钟掌握聚类算法的评估指标：<a href="https://juejin.cn/post/6997913127572471821">https://juejin.cn/post/6997913127572471821</a></p>
</blockquote>
<h4><span id="前言">前言</span></h4><p>如同之前介绍的其它算法模型一样，对于聚类来讲我们同样会通过一些评价指标来衡量聚类算法的优与劣。在聚类任务中，常见的评价指标有：<strong>纯度（Purity）</strong>、<strong>兰德系数（Rand Index, RI）</strong>、<strong>F值（F-score）</strong>和<strong>调整兰德系数（Adjusted Rand Index,ARI）</strong>。同时，这四种评价指标也是聚类相关论文中出现得最多的评价方法。下面，我们就来对这些算法一一进行介绍。</p>
<p><img src="https://pic3.zhimg.com/80/v2-e62c8b4b793c89b1cd70f2aaebf690c6_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>好的聚类算法，一般要求类簇具有：</p>
<ul>
<li><strong>簇内 (intra-cluster) 相似度高</strong></li>
<li><strong>簇间 (inter-cluster) 相似度底</strong></li>
</ul>
<p>一般来说，评估聚类质量有两个标准，内部评估评价指标和外部评估指标。</p>
<h3><span id="外部评估">【外部评估】</span></h3><h3><span id="51聚类纯度-聚类的准确率"><strong>5.1聚类纯度</strong> - 聚类的准确率</span></h3><p>在聚类结果的评估标准中，一种最简单最直观的方法就是计算它的<strong>聚类纯度</strong>（purity），别看纯度听起来很陌生，但实际上和<strong>分类问题中的准确率有着异曲同工之妙</strong>。因为聚类纯度的总体思想也<strong>用聚类正确的样本数除以总的样本数，因此它也经常被称为聚类的准确率</strong>。只是对于聚类后的结果我们并不知道每个簇所对应的真实类别，因此需要取每种情况下的最大值。具体的，纯度的计算公式定义如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+P%3D%28%5COmega%2C%5Cmathbb%7BC%7D%29%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bk%7D%5Cmax_%7Bj%7D%7C%5Comega_k%5Ccap+c_j%7C+%5Cend%7Baligned%7D%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%281%29+%5C%5C" alt="[公式]"></p>
<p>其中<img src="https://www.zhihu.com/equation?tex=N" alt="[公式]">表示总的样本数；<img src="https://www.zhihu.com/equation?tex=%5COmega%3D%5C%7B%5Comega_1%2C%5Comega_2%2C...%2C%5Comega_K%5C%7D" alt="[公式]">表示一个个聚类后的簇，而<img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BC%7D%3D%5C%7Bc_1%2C_2%2C...c_J%5C%7D" alt="[公式]">表示正确的类别；<img src="https://www.zhihu.com/equation?tex=%5Comega_k" alt="[公式]">表示聚类后第<img src="https://www.zhihu.com/equation?tex=k" alt="[公式]">个簇中的所有样本，<img src="https://www.zhihu.com/equation?tex=c_j" alt="[公式]">表示第<img src="https://www.zhihu.com/equation?tex=j" alt="[公式]">个类别中真实的样本。在这里<img src="https://www.zhihu.com/equation?tex=P" alt="[公式]">的取值范围为<img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[公式]">，越大表示聚类效果越好。</p>
<h3><span id="52-兰德系数与f值-同簇混淆矩阵"><strong>5.2 兰德系数与F值</strong>  [同簇混淆矩阵]</span></h3><p>在介绍完了纯度这一评价指标后，我们再来看看兰德系数（Rand Index）和F值。虽然兰德系数听起来是一个陌生的名词，但它的计算过程却也与准确率的计算过程类似。同时，虽然这里也有一个叫做F值的指标，并且它的计算过程也和分类指标中的F值类似，但是两者却有着本质的差别。说了这么多，那这两个指标到底该怎么算呢？同分类问题中的混淆矩阵类似，这里我们也要先定义四种情况进行计数，然后再进行指标的计算。</p>
<p><strong>为了说明兰德系数背后的思想，我们还是以图1中的聚类结果为例进行说明（为了方便观察，我们再放一张图在这里）:</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-e62c8b4b793c89b1cd70f2aaebf690c6_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=TP" alt="[公式]">：表示两个<strong>同类样本点</strong>在<strong>同一个簇</strong>（布袋）中的情况数量；</li>
<li><img src="https://www.zhihu.com/equation?tex=FP" alt="[公式]">：表示两个<strong>非同类样本点</strong>在<strong>同一个簇</strong>中的情况数量；</li>
<li><img src="https://www.zhihu.com/equation?tex=TN" alt="[公式]">：表示两个<strong>非同类样本点</strong>分别在<strong>两个簇</strong>中的情况数量；</li>
<li><img src="https://www.zhihu.com/equation?tex=FN" alt="[公式]">：表示两个同类样本点分别在<strong>两个簇</strong>中的情况数量；</li>
</ul>
<p>由此，我们便能得到如下所示的对<strong>混淆矩阵（Pair Confusion Matrix）</strong>：</p>
<p><img src="https://pic3.zhimg.com/80/v2-a9e709a995b006be04d026aebc721c4e_1440w.png" alt="img" style="zoom:75%;"></p>
<p>有了上面各种情况的统计值，我们就可以定义出兰德系数和F值的计算公式：</p>
<p><img src="https://www.zhihu.com/equation?tex=RI%3D%5Cfrac%7BTP%2BTN%7D%7BTP%2BFP%2BFN%2BTN%7D%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%283%29+%5C%5C" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+Precision%26%3D%5Cfrac%7BTP%7D%7BTP%2BFP%7D%5C%5C%5B2ex%5D+Recall%26%3D%5Cfrac%7BTP%7D%7BTP%2BFN%7D%5C%5C%5B2ex%5D+F_%7B%5Cbeta%7D%26%3D%281%2B%5Cbeta%5E2%29%5Cfrac%7BPrecision%5Ccdot+Recall%7D%7B%5Cbeta%5E2%5Ccdot+Precision%2BRecall%7D+%5Cend%7Baligned%7D%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%284%29+%5C%5C" alt="[公式]"></p>
<p>从上面的计算公式来看，<img src="https://www.zhihu.com/equation?tex=%283%29%284%29" alt="[公式]">从形式上看都非常像分类问题中的准确率与F值，但是有着本质的却别。同时，在这里<img src="https://www.zhihu.com/equation?tex=RI" alt="[公式]">和<img src="https://www.zhihu.com/equation?tex=F_%7B%5Cbeta%7D" alt="[公式]">的取值范围均为<img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[公式]">，越大表示聚类效果越好。</p>
<h4><span id="53-调整兰德系数adjusted-rand-index归一化">5.3 调整兰德系数（Adjusted Rand index）【归一化】</span></h4><p>对于随机结果，RI并不能保证分数接近零。<strong>为了实现“在聚类结果随机产生的情况下，指标应该接近零”</strong>，调整兰德系数（Adjusted rand index）被提出，它具有更高的区分度。</p>
<p>其公式为：</p>
<script type="math/tex; mode=display">
\mathrm{ARI}=\frac{\mathrm{RI}-E[\mathrm{RI}]}{\max (\mathrm{RI})-E[\mathrm{RI}]}</script><p>$A R$ 取值范围为 $[-1,1]$, 值越大意味着聚类结果与真实情况越吻合。从广义的角度来讲, ARI衡量的是两个数据分布的吻合程度。</p>
<p>优点:</p>
<ul>
<li>对任意数量的聚类中心和样本数, 随机聚类的ARI都非常接近于 0 。</li>
<li>取值在 $[-1,1]$ 之间, 负数代表结果不好, 越接近于1越好。</li>
<li>对簇的结构不需作出任何假设：可以用于比较聚类算法。</li>
</ul>
<p>缺点:</p>
<ul>
<li>ARI 需要 ground truth classes 的相关知识, ARI需要真实标签, 而在实践中几乎不可用, 或者需要人工 标注者手动分配（如在监督学习环境中）。</li>
</ul>
<h3><span id="54-标准化互信息nmi-normalized-mutual-information">5.4 <strong><font color="red"> 标准化互信息（NMI, Normalized Mutual Information）</font></strong></span></h3><p>互信息是用来衡量两个数据分布的吻合程度。它也是一有用的信息度量，它是指两个事件集合之间的相关性。互信息越大，词条和类别的相关程度也越大。</p>
<h3><span id="内部指标">【内部指标】</span></h3><p>内部评估指标主要基于数据集的集合结构信息从紧致性、分离性、连通性和重叠度等方面对聚类划分进行评价。即基于数据聚类自身进行评估的。</p>
<h3><span id="55-轮廓系数silhouette-coefficient">5.5 <strong><font color="red"> 轮廓系数（Silhouette Coefficient）</font></strong></span></h3><p>轮廓系数适用于实际类别信息未知的情况。</p>
<p>对于单个样本，设<strong>a是与它同类别中其他样本的平均距离</strong>，<strong>b是与它距离最近不同类别中样本的平均距离</strong>，其轮廓系数为：</p>
<p>$s = \frac {b-a} {max(a, b)}$</p>
<p>对于一个样本集合，它的轮廓系数是所有样本轮廓系数的平均值。轮廓系数的取值范围是[-1,1]，同类别样本距离越相近，不同类别样本距离越远，值越大。当值为负数时，说明聚类效果很差。</p>
<h3><span id="56-calinski-harabaz指数calinski-harabaz-index">5.6 Calinski-Harabaz指数（Calinski-Harabaz Index）</span></h3><p>在真实的分群label不知道的情况下，Calinski-Harabasz可以作为评估模型的一个指标。</p>
<p>Calinski-Harabasz指数通过<strong>计算类中各点与类中心的距离平方和来度量类内的紧密度</strong>，通过<strong>==计算各类中心点与数据集中心点距离平方和来度量数据集的分离度==</strong>，CH指标<strong>由分离度与紧密度的比值得到</strong>。从而，CH越大代表着类自身越紧密，类与类之间越分散，即更优的聚类结果。</p>
<p><strong>优点</strong></p>
<ul>
<li>当簇的密集且分离较好时，分数更高。</li>
<li>得分计算很快，与轮廓系数的对比，最大的优势：快！相差几百倍！毫秒级。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>凸的簇的CH指数通常高于其他类型的簇。例如，通过 DBSCAN 获得基于密度的簇；所以，不适合基于密度的聚类算法（DBSCAN）。</li>
</ul>
<h3><span id="57-戴维森堡丁指数dbi-davies-bouldin-index">5.7 戴维森堡丁指数（DBI, Davies-Bouldin Index）</span></h3><p><strong>DB指数是计算任意两类别的类内距离平均距离之和除以两聚类中心距离求最大值</strong>。DB越小，意味着类内距 离越小同时类间距离越大。<strong>零是可能的最低值, 接近零的值表示更好的分区</strong>。</p>
<script type="math/tex; mode=display">
\begin{gathered}
R_{i j}=\frac{s_{i}+s_{j}}{d_{i j}} \\
D B=\frac{1}{k} \sum_{i=1}^{k} \max _{i \neq j} R_{i j}
\end{gathered}</script><p>其中, $s_{i}$ 表示簇的每个点与该簇的质心之间的平均距离, 也称为簇直径。 $d_{i j}$ 表示聚类和的质心之间的距 离。<br>算法生成的聚类结果越是朝着簇内距离最小（类内相似性最大）和笶间距离最大（类间相似性最小）变化， 那么Davies-Bouldin指数就会越小。<br><strong>缺点</strong>:</p>
<ul>
<li>因使用欧式距离, 所以对于环状分布聚类评测很差。</li>
</ul>
<h2><span id="六-评分总结sklearn">六、评分总结（sklearn）</span></h2><blockquote>
<p>  sklearn.metrics - 回归/分类模型的评估方法:<a href="https://zhuanlan.zhihu.com/p/408078074">https://zhuanlan.zhihu.com/p/408078074</a></p>
</blockquote>
<h3><span id="61-分类模型">6.1 分类模型</span></h3><h4><span id="accuracy_score"><strong>accuracy_score</strong></span></h4><p><strong>分类准确率分数是指所有分类正确的百分比</strong>。分类准确率这一衡量分类器的标准比较容易理解，但是它不能告诉你响应值的潜在分布，并且它也不能告诉你分类器犯错的类型。所以在使用的时候，一般需要搭配matplotlib等数据可视化工具来观察预测的分类情况，与实际的结果做更加直观的比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score  </span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>]  </span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]  </span><br><span class="line">accuracy_score(y_true, y_pred)  <span class="comment"># 默认normalization = True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.5</span></span><br><span class="line">accuracy_score(y_true, y_pred, normalize=<span class="literal">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">2</span></span><br></pre></td></tr></table></figure>
<h4><span id="recall_score"><strong>recall_score</strong></span></h4><p>召回率 =<strong>提取出的正确信息条数 /样本中的信息条数</strong>。通俗地说，就是所有准确的条目有多少被检索出来了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">recall_score(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>,average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">参数average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br></pre></td></tr></table></figure>
<p>将一个二分类matrics拓展到多分类或多标签问题时，我们可以将数据看成多个二分类问题的集合，每个类都是一个二分类。接着，我们可以通过跨多个分类计算每个二分类metrics得分的均值，这在一些情况下很有用。你可以使用<strong>average参数</strong>来指定。 </p>
<ul>
<li>macro：计算二分类metrics的均值，为每个类给出相同权重的分值。</li>
<li>weighted:对于不均衡数量的类来说，计算二分类metrics的平均，通过在每个类的score上进行加权实现。 </li>
<li>micro：给出了每个样本类以及它对整个metrics的贡献的pair（sample-weight），而非对整个类的metrics求和，它会每个类的metrics上的权重及因子进行求和，来计算整个份额。</li>
<li>samples：应用在multilabel问题上。它不会计算每个类，相反，它会在评估数据中，通过计算真实类和预测类的差异的metrics，来求平均（sample_weight-weighted） </li>
<li>average：average=None将返回一个数组，它包含了每个类的得分.</li>
</ul>
<h4><span id="roc_curve"><strong>roc_curve</strong></span></h4><p>ROC曲线指受试者工作特征曲线/接收器操作特性(receiver operating characteristic，ROC)曲线,是<strong>反映灵敏性和特效性连续变量的综合指标</strong>,是用构图法揭示敏感性和特异性的相互关系，它通过将连续变量设定出多个不同的临界值，从而计算出一系列敏感性和特异性。ROC曲线是根据一系列不同的二分类方式（分界值或决定阈），<strong>以真正例率（也就是灵敏度）（True Positive Rate,TPR）为纵坐标，假正例率（1-特效性）（False Positive Rate,FPR）为横坐标</strong>绘制的曲线。</p>
<p>通过ROC我们可以观察到模型正确识别的正例的比例与模型错误地把负例数据识别成正例的比例之间的权衡。TPR的增加以FPR的增加为代价。ROC曲线下的面积是模型准确率的度量，<strong>AUC</strong>（Area under roc curve）。</p>
<p><strong>TPR</strong> = TP /（TP + FN） （正样本<strong>预测数</strong> / 正样本<strong>实际数</strong>）</p>
<p><strong>FPR</strong> = FP /（FP + TN） （负样本<strong>预测数</strong> /负样本<strong>实际数</strong>）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics  </span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>])  </span><br><span class="line">scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=<span class="number">2</span>)  </span><br><span class="line">fpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.</span> ,  <span class="number">0.5</span>,  <span class="number">0.5</span>, <span class="number">1.</span> ])  </span><br><span class="line">tpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.5</span>,  <span class="number">0.5</span>,  <span class="number">1.</span> , <span class="number">1.</span> ])  </span><br><span class="line">thresholds  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.8</span> ,  <span class="number">0.4</span> ,  <span class="number">0.35</span>, <span class="number">0.1</span> ])  </span><br><span class="line"></span><br><span class="line"><span class="comment"># check auc score</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> auc   </span><br><span class="line">metrics.auc(fpr, tpr)   </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以直接根据预测值+真实值来计算出auc值，略过roc的计算过程</span></span><br><span class="line">‘’‘</span><br><span class="line">sklearn.metrics.roc_auc_score(y_true, y_score, average=<span class="string">&#x27;macro&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br><span class="line">’‘’</span><br><span class="line"><span class="comment"># 真实值（必须是二值）、预测值（可以是0/1,也可以是proba值）</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score  </span><br><span class="line">y_true = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])  </span><br><span class="line">y_scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">roc_auc_score(y_true, y_scores)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>  </span><br></pre></td></tr></table></figure>
<h4><span id="confusion-metric"><strong>confusion metric</strong></span></h4><p>混淆矩阵（confusion matrix），又称为可能性表格或是错误矩阵。它是一种特定的矩阵用来呈现算法性能的可视化效果。其每一列代表预测值，每一行代表的是实际的类别。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">confusion_matric(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>, average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="precision_score"><strong>precision_score</strong></span></h4><p>计算精确度——precision <img src="https://www.zhihu.com/equation?tex=%3DTP%2F%28TP%2FFP%29" alt="[公式]"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">precision_score(y_true, y_pred, labels=None, pos_label=1, average=&#x27;binary&#x27;)</span><br></pre></td></tr></table></figure>
<p><img src="https://pic2.zhimg.com/v2-a3b6092e30d2eab7d2372007aec15105_r.jpg" alt="preview"></p>
<h2><span id="评价指标qampa">评价指标Q&amp;A</span></h2><h4><span id="精度指标存在的问题"><strong>精度指标存在的问题</strong>？</span></h4><ul>
<li>有倾向性的问题。比如，判断空中的飞行物是导弹还是其他飞行物，很显然为了减少损失，我们更倾向于相信是导弹而采用相应的防护措施。此时判断为导弹实际上是其他飞行物与判断为其他飞行物实际上是导弹这两种情况的重要性是不一样的；</li>
<li>样本类别数量严重不均衡的情况。比如银行客户样本中好客户990个，坏客户10个。如果一个模型直接把所有客户都判断为好客户，得到精度为99%，但这显然是没有意义的。</li>
</ul>
<h4><span id="为什么-roc-和-auc-都能应用于非均衡的分类问题"><strong>为什么 ROC 和 AUC 都能应用于非均衡的分类问题？</strong></span></h4><p><strong>ROC曲线只与横坐标 (FPR) 和 纵坐标 (TPR) 有关系</strong> 。我们可以发现TPR只是正样本中预测正确的概率，而FPR只是负样本中预测错误的概率，和正负样本的比例没有关系。因此 ROC 的值与实际的正负样本比例无关，因此既可以用于均衡问题，也可以用于非均衡问题。而 AUC 的几何意义为ROC曲线下的面积，因此也和实际的正负样本比例无关。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>评价指标</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习（5）SVM*</title>
    <url>/posts/26M5EPY/</url>
    <content><![CDATA[<h2><span id="支持向量机-svm">支持向量机 SVM</span></h2><p><strong>以几何的角度，在丰富的数据理论的基础上，简化了通常的分类和回归问题。</strong></p>
<h2><span id><img src="https://s2.loli.net/2023/04/17/mxOqbNtTMPoSyRz.jpg" alt="【机器学习】支持向量机 SVM（非常详细）" style="zoom:51%;"></span></h2><p>SVM 是一个非常优雅的算法，具有完善的数学理论，虽然如今工业界用到的不多，但还是决定花点时间去写篇文章整理一下。</p>
<span id="more"></span>
<h2><span id="1-支持向量">1. 支持向量</span></h2><blockquote>
<p>  <strong>本质：SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</strong>为了对数据中的噪声有一定的容忍能力。</p>
<p>  <strong>几何意义</strong>：找到一个超平面将特征空间的正负样本分开，最大分隔（对噪音有一定的容忍能力）</p>
<p>  <strong>间隔表示</strong>：划分超平面到属于不同标记的最近样本的距离之和</p>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/52168498">https://zhuanlan.zhihu.com/p/52168498</a></p>
<p><strong>KKT条件</strong>：<strong>判断不等式约束问题是否为最优解的必要条件</strong></p>
</li>
</ul>
</blockquote>
<h3><span id="11-线性可分">1.1 线性可分</span></h3><p>首先我们先来了解下什么是线性可分。</p>
<p><img src="https://s2.loli.net/2023/04/17/ycmF6werxUvYLh5.jpg" alt="img" style="zoom:50%;"></p>
<p>在二维空间上，两类点被一条直线完全分开叫做线性可分。</p>
<p>严格的数学定义是：</p>
<p><img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 是 n 维欧氏空间中的两个点集。如果存在 n 维向量 w 和实数 b，使得所有属于 <img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 的点 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 都有 <img src="https://www.zhihu.com/equation?tex=wx_i+%2B+b+%3E+0" alt="[公式]"> ，而对于所有属于 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 的点 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 则有 <img src="https://www.zhihu.com/equation?tex=wx_j+%2B+b+%3C+0" alt="[公式]"> ，则我们称 <img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 线性可分。</p>
<h3><span id="12-最大间隔超平面">1.2 最大间隔超平面</span></h3><p>从二维扩展到多维空间中时，将 <img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 完全正确地划分开的 <img src="https://www.zhihu.com/equation?tex=wx%2Bb%3D0" alt="[公式]"> 就成了一个超平面。</p>
<p>为了使这个超平面更具鲁棒性，我们会去找最佳超平面，以最大间隔把两类样本分开的超平面，也称之为最大间隔超平面。</p>
<ul>
<li>两类样本分别分割在该超平面的两侧；</li>
<li><strong>两侧距离超平面最近的样本点到超平面的距离被最大化了。</strong>【附近点】</li>
</ul>
<h3><span id="13-支持向量-距离超平面最近的点">1.3 支持向量 【距离超平面最近的点】</span></h3><p><img src="https://s2.loli.net/2023/04/17/HDlAed2wZf8cXi1.jpg" alt="img" style="zoom:50%;"></p>
<p>样本中距离超平面最近的一些点，这些点叫做支持向量。</p>
<h3><span id="14-svm-最优化问题">1.4 SVM 最优化问题</span></h3><p><strong>==SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面==</strong>。任意超平面可以用下面这个线性方程来描述：</p>
<p>​                                 <img src="https://www.zhihu.com/equation?tex=w%5ETx%2Bb%3D0+%5C%5C" alt="[公式]"></p>
<p>二维空间点 <img src="https://www.zhihu.com/equation?tex=%28x%2Cy%29" alt="[公式]"> 到直线 <img src="https://www.zhihu.com/equation?tex=Ax%2BBy%2BC%3D0" alt="[公式]"> 的距离公式是：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7CAx%2BBy%2BC%7C%7D%7B%5Csqrt%7BA%5E2%2BB%5E2%7D%7D+%5C%5C" alt="[公式]"></p>
<p><strong>扩展到 n 维空间后，点 <img src="https://www.zhihu.com/equation?tex=x%3D%28x_1%2Cx_2%E2%80%A6x_n%29" alt="[公式]"> 到直线 <img src="https://www.zhihu.com/equation?tex=w%5ETx%2Bb%3D0" alt="[公式]"> 的距离为</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7Cw%5ETx%2Bb%7C%7D%7B%7C%7Cw%7C%7C%7D+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%7C%7Cw%7C%7C%3D%5Csqrt%7Bw_1%5E2%2B%E2%80%A6w_n%5E2%7D" alt="[公式]"> 。</p>
<p>如图所示，根据支持向量的定义我们知道，支持向量到超平面的距离为 d，其他点到超平面的距离大于 d。</p>
<p><img src="https://s2.loli.net/2023/04/17/2yZRMfWemFcoX75.jpg" alt="img" style="zoom:50%;"></p>
<p>于是我们有这样的一个公式：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+%5Cbegin%7Baligned%7D+%5Cfrac%7Bw%5ETx%2Bb%7D%7B%7C%7Cw%7C%7C%7D+%26%5Cgeq+d+%5Cquad++y%3D1+%5C%5C+%5Cfrac%7Bw%5ETx%2Bb%7D%7B%7C%7Cw%7C%7C%7D+%26%5Cleq+-d++%5Cquad+y%3D-1++%5Cend%7Baligned%7D+%5Cright.+%5C%5C" alt="[公式]"></p>
<p>将两个方程合并，我们可以简写为：</p>
<p><img src="https://www.zhihu.com/equation?tex=y%28w%5ETx%2Bb%29+%5Cgeq+1+%5C%5C" alt="[公式]"></p>
<p>至此我们就可以得到最大间隔超平面的上下两个超平面：</p>
<p><img src="https://s2.loli.net/2023/04/17/aZbmfK4zWsSjyo2.png" alt="image-20220409203050568" style="zoom:50%;"></p>
<p><strong>间隔</strong>：<strong>训练集中离划分超平面最近的样本到划分超平面距离的两倍</strong>。有了间隔的定义，划分超平面“离正负样本都比较远”这一目标可以等价描述为正负样本里划分超平面的距离尽可能远。即<strong>让离划分超平面最近的样本到划分超平面距离尽可能远</strong>。==优化目标==：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\max _{\boldsymbol{w}, b} \gamma &=\max _{\boldsymbol{w}, b}\left(2 \min _{i} \frac{1}{\|\boldsymbol{w}\|}\left|\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right|\right) \\
&=\max _{\boldsymbol{w}, b} \min _{i} \frac{2}{\|\boldsymbol{w}\|}\left|\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right|
\end{aligned}</script><p><strong>简化过程</strong>：</p>
<ul>
<li><p><strong>缩放</strong>：为了简化优化问题, 我们可以通过调整 $(\boldsymbol{w}, b)$ 使得：</p>
<script type="math/tex; mode=display">
\min _{i}\left|\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right|=1 .</script></li>
<li><p><strong>标签替换绝对值</strong>：</p>
<script type="math/tex; mode=display">
s.t. \min _{i} y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)=1</script></li>
<li><p><strong>简化约束条件</strong>【<strong>反正法</strong>】</p>
</li>
</ul>
<h4><span id="硬间隔线性svm的基本型"><strong><font color="red"> 硬间隔线性SVM的基本型：</font></strong></span></h4><script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w} \\
\text { s.t. } & y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right) \geq 1, \quad i=1,2, \ldots, m
\end{array}</script><p><img src="https://s2.loli.net/2023/04/17/l4WjzV7smKBoe8f.png" alt="image-20220423163130805" style="zoom:50%;"></p>
<p><strong>二次规划是指目标函数是==二次函数==，约束是==线性不等式约束==的一类优化问题</strong> + 凸函数</p>
<h2><span id="2-硬间隔线性svm对偶型">2. 硬间隔线性SVM对偶型</span></h2><blockquote>
<p>  本科高等数学学的<strong>拉格朗日程数法</strong>是<strong>等式约束优化问题</strong>：</p>
<p>  <img src="https://www.zhihu.com/equation?tex=%5Cmin+f%28x_%7B1%7D+%2Cx_%7B2%7D+%2C...%2Cx_%7Bn%7D+%29+%5C%5C+s.t.+%5Cquad+h_%7Bk%7D+%28x_%7B1%7D+%2Cx_%7B2%7D+%2C...%2Cx_%7Bn%7D+%29%3D0+%5Cquad+k+%3D1%2C2%2C...%2Cl%5C%5C" alt="[公式]"></p>
<p>  我们令 <img src="https://www.zhihu.com/equation?tex=L%28x%2C%5Clambda+%29+%3D+f%28x%29+%2B+%5Csum%5Climits_%7Bk+%3D+1%7D%5El+%5Clambda+_k+h_k+%28x%29" alt="[公式]"> ，函数 <img src="https://www.zhihu.com/equation?tex=L%28x%2Cy%29" alt="[公式]"> 称为 Lagrange 函数，参数 <img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="[公式]"> 称为 Lagrange 乘子<strong>==没有非负要求。==</strong></p>
<p>  利用必要条件找到可能的极值点：</p>
<p>  <img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+%5Cbegin%7Baligned%7D++%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+x_i%7D+%3D+0+%5Cquad+i%3D1%2C2%2C...%2Cn+%5C%5C+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+%5Clambda_k%7D+%3D+0+%5Cquad+k%3D1%2C2%2C...%2Cl++%5Cend%7Baligned%7D+%5Cright.+%5C%5C" alt="[公式]"></p>
<p>  具体是否为极值点需根据问题本身的具体情况检验。这个方程组称为等式约束的极值必要条件。</p>
<p>  等式约束下的 Lagrange 乘数法引入了 <img src="https://www.zhihu.com/equation?tex=l" alt="[公式]"> 个 Lagrange 乘子，我们将 <img src="https://www.zhihu.com/equation?tex=x_%7Bi%7D" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bk%7D" alt="[公式]"> 一视同仁，把 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bk%7D+" alt="[公式]"> 也看作优化变量，共有 <img src="https://www.zhihu.com/equation?tex=%28n%2Bl%29" alt="[公式]"> 个优化变量。</p>
</blockquote>
<h5><span id="1写成约束优化问题的基本型">（1）写成约束优化问题的基本型</span></h5><script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w} \\
\text { s.t. } & 1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right) \leq 0, \quad i=1,2, \ldots, m
\end{array}</script><h5><span id="2-构建基本型的拉格朗日函数">（2） 构建基本型的拉格朗日函数</span></h5><script type="math/tex; mode=display">
\mathcal{L}(\boldsymbol{w}, b, \boldsymbol{\alpha}):=\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right)</script><h5><span id="3交换min-max顺序">（3）交换min, max顺序</span></h5><blockquote>
<p>  ==<strong>解得最优解 $\boldsymbol{u}^{\star}$ 。这样两层优化问题将变为一层最大化（max）问题, 问题难度大大降低, 称为对偶问题 (Dual Problem) :</strong>==【<strong>对偶问题是原问题的下界</strong>】</p>
<ul>
<li><script type="math/tex; mode=display">
\max _{\boldsymbol{\alpha}, \boldsymbol{\beta}} \min _{\boldsymbol{u}} \mathcal{L}(\boldsymbol{u}, \boldsymbol{\alpha}, \boldsymbol{\beta}) \leq \min _{\boldsymbol{u}} \max _{\boldsymbol{\alpha}, \boldsymbol{\beta}} \mathcal{L}(\boldsymbol{u}, \boldsymbol{\alpha}, \boldsymbol{\beta})</script></li>
<li><p>硬间隔线性SVM满足<strong>Slater条件</strong>， <strong>因此原问题和对偶问题等价</strong></p>
</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">
\begin{array}{cl}
\max _{\boldsymbol{\alpha}} \min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right) \\
\text { s.t. } & \alpha_{i} \geq 0, \quad i=1,2, \ldots, m .
\end{array}</script><p>首先计算 $\boldsymbol{w}$ 的最优值, 令 $\frac{\partial \mathcal{L}}{\partial \boldsymbol{w}}=\mathbf{0}$</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial \boldsymbol{w}} &=\frac{\partial}{\partial \boldsymbol{w}}\left(\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right)\right) \\
&=\boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(-y_{i} \boldsymbol{x}_{i}\right) \\
&=\boldsymbol{w}-\sum_{i=1}^{m} \alpha_{i} y_{i} \boldsymbol{x}_{i} \\
&=\mathbf{0}
\end{aligned}</script><p>==可以解得最优值==$\boldsymbol{w}$</p>
<script type="math/tex; mode=display">
\boldsymbol{w}^{\star}=\sum_{i=1}^{m} \alpha_{i} y_{i} \boldsymbol{x}_{i}</script><p>然后计算 $b$ 的最优值, 令 $\frac{\partial \mathcal{L}}{\partial b}=0$</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial b} &=\frac{\partial}{\partial b}\left(\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right)\right) \\
&=\sum_{i=1}^{m} \alpha_{i}\left(-y_{i}\right) \\
&=-\sum_{i=1}^{m} \alpha_{i} y_{i} \\
&=0
\end{aligned}</script><p>==可以得到一个等式== $b^{\star}$ </p>
<script type="math/tex; mode=display">
\sum_{i=1}^{m} \alpha_{i} y_{i}=0</script><p>注意到这里并没有给出最优值 $b^{\star}$ 应该是多少, 而是一个等式, 该等式是一个约束项, 而最优值通过后面的 <strong>KKT 条件</strong>的互补松弛可以计算得到。</p>
<h4><span id="硬性间隔线性svm的对偶型"><strong><font color="red"> 硬性间隔线性SVM的对偶型：</font></strong></span></h4><script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{\alpha}} & \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j} \boldsymbol{x}_{i}^{\top} \boldsymbol{x}_{j}-\sum_{i=1}^{m} \alpha_{i} \\
\text { s.t. } & \alpha_{i} \geq 0, \quad i=1,2, \ldots, m \\
& \sum_{i=1}^{m} \alpha_{i} y_{i}=0
\end{array}</script><h5><span id="4利用kkt条件得到主问题的最优解">==（4）利用KKT条件得到主问题的最优解==</span></h5><p><strong>KKT 条件是指优化问题在最优处（包括基本型的最优值，对偶问题的最优值）必须满足的条件</strong>。</p>
<p>线性支持向量机的 <strong>KKT 条件</strong>:</p>
<ul>
<li><strong>主问题可行</strong>: $g_{i}\left(\boldsymbol{u}^{\star}\right)=1-y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right) \leq 0$ ；</li>
<li><strong>对偶问题可行</strong>: $\alpha_{i}^{\star} \geq 0$;</li>
<li><strong>主变量最优</strong>: $\boldsymbol{w}^{\star}=\sum_{i=1}^{m} \alpha_{i} y_{i} \boldsymbol{x}_{i}, \sum_{i=1}^{m} \alpha_{i} y_{i}=0$;</li>
<li><strong><font color="red"> 互补松弛: $\alpha_{i}^{\star} g_{i}\left(\boldsymbol{u}^{\star}\right)=\alpha_{i}^{\star}\left(1-y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right)\right)=0$ ；</font></strong></li>
</ul>
<p><strong>根据 KKT 条件中的 $\alpha_{i}^{\star} \geq 0$, 我们可以根据 $\alpha_{i}^{\star}$ 的取值将训练集 $D$ 中所有的样本分成两类</strong>, 如 图 17 所示。</p>
<ul>
<li>如果 $\alpha_{i}^{\star}&gt;0$, <strong>对应的样本称为支持向量 (Support Vector)</strong>, 根据 $\alpha_{i}^{\star}\left(1-y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right)\right)=0$ , 那么一定有 $y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right)=1$, 该样本是距离划分超平面最近的样本, 位于最大间隔边界 （见第 $2.3$ 节）;</li>
<li>如果 $\alpha_{i}^{\star}=0$, 对应的样本不是非支持向量, 那么有 $y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right) \geq 1$, 该样本不一定是距离 划分超平面最近的样本, <strong>位于最大间隔边界或之外</strong>。</li>
</ul>
<p><img src="https://s2.loli.net/2023/04/17/Gkx9AygPfvXmheq.png" alt="image-20220409212350705" style="zoom:50%;"></p>
<p><strong>结论</strong>：</p>
<ul>
<li><strong><font color="red"> 参数 w， b 仅由支持向量决定，与训练集的其他样本无关；</font></strong></li>
<li><strong><font color="red"> 对偶性是非参数模型，预测阶段不仅需要$\alpha_{i}$参数，还支持向量；</font></strong></li>
</ul>
<script type="math/tex; mode=display">
\begin{aligned}
&h(\boldsymbol{x}):=\operatorname{sign}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}+b^{\star}\right) \quad \text { （硬间隔线性 SVM 的基本型的假设函数） }\\
&=\operatorname{sign}\left(\sum_{i \in S V} \alpha_{i}^{\star} y_{i} \boldsymbol{x}_{i}^{\top} \boldsymbol{x}+b^{\star}\right) \text {.(硬间隔线性 SVM 的对偶型的假设函数） }
\end{aligned}</script><h3><span id="3-svm优化方法">3、SVM优化方法</span></h3><h5><span id="smo算法求解">==SMO算法求解==</span></h5><p>我们可以看出来这是一个<strong>二次规划问题</strong>，问题规模正比于训练样本数，我们常用 SMO(Sequential Minimal Optimization) 算法求解。</p>
<p><strong>==SMO(Sequential Minimal Optimization)，序列最小优化算法【基于坐标下降算法】，其核心思想非常简单：每次只优化一个参数，其他参数先固定住，仅求当前这个优化参数的极值。我们来看一下 SMO 算法在 SVM 中的应用。==</strong></p>
<p>我们刚说了 SMO 算法每次只优化一个参数，但我们的优化目标有约束条件： <img src="https://www.zhihu.com/equation?tex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bn%7D%5Clambda_iy_i+%3D+0" alt="[公式]"> ，没法一次只变动一个参数。所以我们选择了一次选择两个参数。具体步骤为：</p>
<ol>
<li>选择两个需要更新的参数 <img src="https://www.zhihu.com/equation?tex=%5Clambda_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Clambda_j" alt="[公式]"> ，固定其他参数。于是我们有以下约束：</li>
</ol>
<p>这样约束就变成了：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Clambda_i+y_i%2B%5Clambda_j+y_j+%3D+c+%5Cquad+%5Clambda_i+%5Cgeq+0%2C%5Clambda_j+%5Cgeq+0+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=c%3D-%5Csum%5Climits_%7Bk+%5Cne+i%2Cj%7D%5Clambda_ky_k" alt="[公式]"> ，由此可以得出 <img src="https://www.zhihu.com/equation?tex=%5Clambda_j%3D%5Cfrac%7Bc-%5Clambda_iy_i%7D%7By_j%7D" alt="[公式]"> ，也就是说我们可以用 <img src="https://www.zhihu.com/equation?tex=%5Clambda_i" alt="[公式]"> 的表达式代替 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bj%7D" alt="[公式]"> 。这样就相当于把目标问题转化成了仅有一个约束条件的最优化问题，仅有的约束是 <img src="https://www.zhihu.com/equation?tex=%5Clambda_i+%5Cgeq+0" alt="[公式]"> 。</p>
<ol>
<li><p>对于仅有一个约束条件的最优化问题，我们完全可以在 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi%7D" alt="[公式]"> 上对优化目标求偏导，令导数为零，从而求出变量值 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi_%7Bnew%7D%7D" alt="[公式]"> ，然后根据 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi_%7Bnew%7D%7D" alt="[公式]"> 求出 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bj_%7Bnew%7D%7D" alt="[公式]"> 。</p>
</li>
<li><p>多次迭代直至收敛。</p>
</li>
</ol>
<p>通过 SMO 求得最优解 <img src="https://www.zhihu.com/equation?tex=%5Clambda%5E%2A" alt="[公式]"> 。</p>
<h3><span id="4-软间隔线性svm">4. 软间隔线性SVM</span></h3><p>在实际应用中，完全线性可分的样本是很少的，如果遇到了不能够完全线性可分的样本，我们应该怎么办？比如下面这个：</p>
<p><img src="https://s2.loli.net/2023/04/17/zDNf9QWoTs2JxVp.jpg" alt="img" style="zoom: 33%;"></p>
<p>于是我们就有了软间隔，相比于硬间隔的苛刻条件，我们允许个别样本点出现在间隔带里面，比如：</p>
<p><img src="https://s2.loli.net/2023/04/17/ha4zMrmIS9Z7jnW.jpg" alt="img" style="zoom: 33%;"></p>
<p>我们允许部分样本点不满足约束条件：</p>
<p><img src="https://www.zhihu.com/equation?tex=1-y_i%28w%5ETx_i+%2B+b%29+%5Cleq+0+%5C%5C" alt="[公式]"></p>
<p>为了度量这个间隔软到何种程度，我们为每个样本引入一个松弛变量 <img src="https://www.zhihu.com/equation?tex=%5Cxi_%7Bi%7D" alt="[公式]"> ，令 <img src="https://www.zhihu.com/equation?tex=%5Cxi_%7Bi%7D+%5Cgeq+0" alt="[公式]"> ，且 <img src="https://www.zhihu.com/equation?tex=1+-+y_i%28w%5ETx_i+%2B+b%29-%5Cxi_i+%5Cleq+0" alt="[公式]"> 。对应如下图所示：</p>
<p><img src="https://s2.loli.net/2023/04/17/GlPvqnUM7FDeTyX.jpg" alt="img" style="zoom: 33%;"></p>
<p><strong>这边要注意一个问题，在间隔内的那部分样本点是不是支持向量？</strong></p>
<p>我们可以由求参数 w 的那个式子可看出，只要 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi%7D+%3E+0" alt="[公式]"> 的点都能够影响我们的超平面，因此都是支持向量。</p>
<p><strong>==硬间隔线性SVM的基本型：==</strong>【凸二次规划问题， 具有全局最小值】</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w} \\
\text { s.t. } & y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right) \geq 1, \quad i=1,2, \ldots, m
\end{array}</script><p>约束中要求所有的样本都满足 $y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1$, 也就是让所有的样本都满足 $y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right)&gt;0$。<br>现在我们想对<strong>该约束进行一点放松</strong>, 我们希望在优化间隔的同时, 允许分类错误的样本出现, 但这类样本应尽可能少:</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+C \sum_{i=1}^{m} \mathbb{I}\left(y_{i} \neq \operatorname{sign}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right)\right) \\
\text { s.t. } & y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1, \quad \text { 若 } y_{i}=\operatorname{sign}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) .
\end{array}</script><p>其中, 优化目标的第一项 $\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}$ 源自硬间隔核化 SVM 的基本型, 即优化间隔。优化目标的第二项 中的 $\mathbb{I}(\cdot)$ 是指示函数, 函数的参数通常是一个条件, 如果条件为真（True）, 则指示函数值为 1 ; 如果条件为假 (False), 则指示函数值为 0 。<br>$\sum_{i=1}^{m} \mathbb{I}\left(y_{i} \neq \operatorname{sign}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right)\right)$ 的含义是统计训练集 $D$ 中所有<strong>预测错误的样本总数</strong>。因此, 公式 162 的目标函数是同时优化间隔和最小化训练集预测错误的样本总数, <strong>==$C$ 是个可调节的超参数, 用于权衡优化间隔和出现少量分类错误的样本这两个目标。==</strong></p>
<p>但是, 由于<strong>==指示函数 $I(\cdot)$ 不是连续函数, 更不是凸函数, 使得优化问题不再是二次规划问题==</strong>, 求解起来十分困难, 所以我们需要对其进行简化。另外<strong>==指示函数没有区分预测错误的不同程度==</strong>,因此, 我们<strong>引入松他变量</strong> (Slack Variable) $\xi_{i} \in \mathbb{R}$, 用于<strong>度量训练集 $D$ 中第 $i$ 个样本违背约束的程度</strong>。当第 $i$ 个样本<strong>==违背约束的程度==</strong>越大, 松弛变量 $\xi_{i}$ 的值越大</p>
<script type="math/tex; mode=display">
\xi_{i}:= \begin{cases}0 & \text { 若 } y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1 ; \\ 1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) & \text { 否则. }\end{cases}</script><p>基于以上定义, 松弛变量 $\xi_{i}$ 的取值有以下四种情况, 如图 27 所示, 注意图 27 只是示意图, 用于理 解概念, 不表示用图中数据训练得到的分类边界一定是这样:</p>
<ul>
<li>当 $\xi_{i}=0$ 时, 训练集 $D$ 中第 $i$ 个样本分类正确 $h\left(\boldsymbol{x}_{i}\right)=y_{i}$, 且满足大间隔约束 $y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1$;</li>
<li>当 $0&lt;\xi_{i}&lt;1$ 时, 训练集 $D$ 中第 $i$ 个样本分类正确 $h\left(\boldsymbol{x}_{i}\right)=y_{i}$, 但是不满足大间隔约束;</li>
<li>当 $\xi_{i}=1$ 时, 训练集 $D$ 中第 $i$ 个样本恰好位于划分超平面 $\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b=0$ 上, 且不满足大间 隔约束;</li>
<li>当 $\xi&gt;0$ 时, 训练集 $D$ 中第 $i$ 个样本分类错误 $h\left(\boldsymbol{x}_{i}\right) \neq y_{i}$, 且不满足大间隔约束。</li>
</ul>
<p><img src="https://s2.loli.net/2023/04/17/LPukQfqKiBNToV5.png" alt="image-20220409230106609" style="zoom:50%;"></p>
<h4><span id="软间隔核化svm基本型合页损失函数"><strong>==软间隔核化SVM基本型==：</strong>（<strong>==合页损失函数==</strong>）</span></h4><p><img src="https://s2.loli.net/2023/04/17/ROQk4xowVb7Fu39.png" alt="image-20220401163522598" style="zoom:50%;"></p>
<p><img src="https://s2.loli.net/2023/04/17/CvTiDaHNeWm3q6E.png" alt="image-20220401164527480" style="zoom:50%;"></p>
<p><strong>变为：</strong></p>
<p><img src="https://s2.loli.net/2023/04/17/bsWvAUQaM29RzNP.png" alt="image-20220401164354384" style="zoom:50%;"></p>
<p>令<img src="https://s2.loli.net/2023/04/17/3j4TyoqNfcnBrLW.png" alt="image-20220401164559373" style="zoom:50%;">：<strong>==合页损失==</strong></p>
<p><img src="https://s2.loli.net/2023/04/17/XIRKolZvQGECYAw.png" alt="image-20220401164608500" style="zoom:50%;"></p>
<blockquote>
<h5><span id="回顾对数几率回归">回顾：对数几率回归：</span></h5><p>  <img src="https://s2.loli.net/2023/04/17/ZtVDeIKydQsNhTM.png" alt="image-20220401164913393" style="zoom:50%;"></p>
</blockquote>
<p>==<strong>软间隔核化SVM对偶性：</strong>== <strong>软间隔的对偶性是在硬间隔的对偶性对拉格朗日参数添加一个上界</strong>。</p>
<p><img src="https://s2.loli.net/2023/04/17/hMnsiJqL59xYduO.png" alt="image-20220401161707141" style="zoom:50%;"></p>
<h3><span id="5-核函数对偶性">5. 核函数【对偶性】</span></h3><h4><span id="51-线性不可分">5.1 线性不可分</span></h4><blockquote>
<p>  <strong>==对于在有限维度向量空间中线性不可分的样本，我们将其映射到更高维度的向量空间里，再通过间隔最大化的方式，学习得到支持向量机，就是非线性 SVM。==</strong></p>
</blockquote>
<p>我们刚刚讨论的<strong>硬间隔</strong>和<strong>软间隔</strong>都是在说样本的完全线性可分或者大部分样本点的线性可分。</p>
<p>但我们可能会碰到的一种情况是样本点不是线性可分的，比如：</p>
<p><img src="https://s2.loli.net/2023/04/17/BpDe2wT9zZQrJVn.jpg" alt="img" style="zoom:50%;"></p>
<p>这种情况的解决方法就是：将<strong>==二维线性不可分样本映射到高维空间中，让样本点在高维空间线性可分==</strong>，比如：</p>
<p><img src="https://s2.loli.net/2023/04/17/JhEDzmfuGyPK7A6.jpg" alt="img" style="zoom:50%;"></p>
<p>对于在有限维度向量空间中线性不可分的样本，我们将其映射到更高维度的向量空间里，再通过间隔最大化的方式，学习得到支持向量机，就是非线性 SVM。</p>
<p>我们用 x 表示原来的样本点，用 <img src="https://www.zhihu.com/equation?tex=%5Cphi%28x%29" alt="[公式]"> 表示 x 映射到特征新的特征空间后到新向量。那么分割超平面可以表示为： <img src="https://www.zhihu.com/equation?tex=f%28x%29%3Dw+%5Cphi%28x%29%2Bb" alt="[公式]"> 。</p>
<p>对于非线性 SVM 的对偶问题就变成了：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cmin%5Climits_%7B%5Clambda%7D+%5B%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%5Clambda_i+%5Clambda_j+y_i+y_j+%28%5Cphi%28x_i%29+%5Ccdot+%5Cphi%28x_j%29%29-%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%5Clambda_i%5D+%5C%5C+s.t.++%5Cquad+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Clambda_iy_i+%3D+0%2C+%5Cquad+%5Clambda_i+%5Cgeq+0%2C+%5Cquad+C-%5Clambda_i-%5Cmu_i%3D0+%5C%5C" alt="[公式]"></p>
<p>可以看到与线性 SVM 唯一的不同就是：之前的 <img src="https://www.zhihu.com/equation?tex=%28x_i+%5Ccdot+x_j%29" alt="[公式]"> 变成了 <img src="https://www.zhihu.com/equation?tex=%28%5Cphi%28x_i%29+%5Ccdot+%5Cphi%28x_j%29%29" alt="[公式]"> 。</p>
<h3><span id="52-核函数的作用">5.2 核函数的作用</span></h3><p>我们不禁有个疑问：只是做个内积运算，为什么要有核函数的呢？</p>
<p>这是因为<strong>低维空间映射到高维空间后维度可能会很大，如果将全部样本的点乘全部计算好，这样的计算量太大</strong>了。</p>
<p>但如果我们有这样的一==核函数== <img src="https://www.zhihu.com/equation?tex=k%28x%2Cy%29+%3D+%28%5Cphi%28x%29%2C%5Cphi%28y%29%29" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 在特征空间的内积等于它们在原始样本空间中通过函数 <img src="https://www.zhihu.com/equation?tex=k%28+x%2C+y%29" alt="[公式]"> 计算的结果，我们就不需要计算高维甚至无穷维空间的内积了。</p>
<p>举个例子：假设我们有一个<strong>==多项式核函数==</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x%2Cy%29%3D%28x+%5Ccdot+y+%2B+1%29%5E2+%5C%5C" alt="[公式]"></p>
<p>带进样本点的后：</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x%2Cy%29+%3D+%28%5Csum_%7Bi%3D1%7D%5En%28x_i+%5Ccdot+y_i%29+%2B+1%29%5E2+%5C%5C" alt="[公式]"></p>
<p>而它的展开项是：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi%3D1%7D%5Enx_i%5E2y_i%5E2%2B%5Csum_%7Bi%3D2%7D%5En%5Csum_%7Bj%3D1%7D%5E%7Bi-1%7D%28%5Csqrt2x_ix_j%29%28%5Csqrt2y_iy_j%29%2B%5Csum_%7Bi%3D1%7D%7Bn%7D%28%5Csqrt2x_i%29%28%5Csqrt2y_i%29%2B1+%5C%5C" alt="[公式]"></p>
<p>如果没有核函数，我们则需要把向量映射成：</p>
<p><img src="https://www.zhihu.com/equation?tex=x%5E%7B%27%7D+%3D+%28x_1%5E2%2C...%2Cx_n%5E2%2C...%5Csqrt2x_1%2C...%2C%5Csqrt2x_n%2C1%29+%5C%5C" alt="[公式]"></p>
<p>然后在进行内积计算，才能与多项式核函数达到相同的效果。</p>
<p>可见核函数的引入一方面减少了我们计算量，另一方面也减少了我们存储数据的内存使用量。</p>
<h3><span id="53-常见核函数">5.3 常见核函数</span></h3><p>我们常用核函数有：</p>
<p><strong>线性核函数</strong>【无映射】</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x_i%2Cx_j%29+%3D+x_i%5ETx_j+%5C%5C" alt="[公式]"></p>
<ul>
<li>优点：有加速算法库、没有特征映射、过拟合风险低</li>
<li>缺点：只能处理线性</li>
</ul>
<p><strong>多项式核函数</strong>【映射，超参数】</p>
<p><img src="https://www.zhihu.com/equation?tex=+k%28x_i%2Cx_j%29+%3D+%28x_i%5ETx_j%29%5Ed%5C%5C" alt="[公式]"></p>
<p><strong>高斯核函数</strong>【映射，超参数】</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x_i%2Cx_j%29+%3D+exp%28-%5Cfrac%7B%7C%7Cx_i-x_j%7C%7C%7D%7B2%5Cdelta%5E2%7D%29+%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>表示能力强，但容易过拟合</strong></li>
<li><strong>高斯核没有多项核不稳定的问题</strong></li>
<li><strong>只有一个超参数</strong></li>
</ul>
<h3><span id="54-如何选择核函数">==5.4 <strong>如何选择核函数？</strong>==</span></h3><blockquote>
<p>  <strong>其他核函数：拉普拉斯、sigmod、卡方、直方图交叉</strong></p>
<p>  可自定义和组合核函数</p>
</blockquote>
<ul>
<li>如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM；</li>
<li>如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数；</li>
<li>如果特征的数量小，而样本的数量很大，则需要手工添加一些特征从而变成第一种情况。</li>
</ul>
<p><img src="https://s2.loli.net/2023/04/17/uFims1jZcWSPBRx.png" alt="image-20220331203905843" style="zoom:50%;"></p>
<h3><span id="55-核方法">5.5 核方法</span></h3><h4><span id="核化lr-非线性">核化LR [非线性]</span></h4><p>正类: y = +1 负类 y= -1</p>
<p><img src="https://s2.loli.net/2023/04/17/mvX4dbSUTuzYKAq.png" alt="image-20220331205845613" style="zoom:50%;"></p>
<p><img src="https://s2.loli.net/2023/04/17/UGMhET5quOZiVLn.png" alt="image-20220331211740625" style="zoom:50%;"></p>
<p><img src="https://s2.loli.net/2023/04/17/6HjbuOyVkhNDmAL.png" alt="image-20220331211757367" style="zoom:50%;"></p>
<p><strong>梯度下降求解：</strong></p>
<p>核化LR的参数通常都非0，并且几乎用到所有训练的样本，预测效率比较低。</p>
<p><img src="https://s2.loli.net/2023/04/17/8d9UGWZyzBoAhjJ.png" alt="image-20220331212433609" style="zoom:50%;"></p>
<h3><span id="56-支持向量回归-svr-核化岭回归">5.6 支持向量回归 SVR = ？核化岭回归？</span></h3><blockquote>
<p>  <a href="https://blog.csdn.net/ch18328071580/article/details/94168411">https://blog.csdn.net/ch18328071580/article/details/94168411</a></p>
<p>  <strong>支持向量在隔代之外</strong></p>
</blockquote>
<h4><span id="svr与一般线性回归的区别">SVR与一般线性回归的区别</span></h4><div class="table-container">
<table>
<thead>
<tr>
<th>SVR</th>
<th>线性回归</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据在间隔带内则不计算损失，<strong>当且仅当f(x)与y之间的差距的绝对值大于ϵ才计算损失</strong></td>
<td>只要f(x)与y不相等时，就计算损失</td>
</tr>
<tr>
<td><strong>通过最大化间隔带的宽度与最小化总损失</strong>来优化模型</td>
<td>通过梯度下降之后求均值来优化模型</td>
</tr>
</tbody>
</table>
</div>
<p><strong>岭回归：</strong><img src="https://s2.loli.net/2023/04/17/tHg4BJuNZzcX7Yd.png" alt="image-20220401144206172" style="zoom:50%;"></p>
<h5><span id="支持向量回归我们假设fx与y之间最多有一定的偏差大于偏差才计数损失">支持向量回归：==我们假设f(x)与y之间最多有一定的偏差，大于偏差才计数损失==</span></h5><script type="math/tex; mode=display">
\min _{w, b} \frac{1}{2}\|w\|^{2}+C \sum_{i=1}^{m} l_{\epsilon}\left(f\left(x_{i}\right), y_{i}\right)</script><p>其中C为正则化常数, $l_{\epsilon}$ 是图中所示的 $\epsilon$-不敏感损失 ( $\epsilon$-insensitive loss)函数:</p>
<script type="math/tex; mode=display">
l_{\epsilon}(\mathrm{z})= \begin{cases}0, & \text { if }|z| \leq \epsilon \\ |z|-\epsilon, & \text { otherwise }\end{cases}</script><p>引入松弛变量 $\xi_{i}$ 和 $\left(\xi_{i}\right)$, 可将式重写为:</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\min _{w, b, \xi_{i}, \xi_{i}} & \frac{1}{2}\|w\|^{2}+C \sum_{i=1}^{m}\left(\xi_{i}, \widehat{\xi}_{i}\right) \\
\text { s.t. } & f\left(x_{i}\right)-y_{i} \leq \epsilon+\xi_{i} \\
& y_{i}-f\left(x_{i}\right) \leq \epsilon+\widehat{\xi}_{i} \\
& \xi_{i} \geq 0, \hat{\xi}_{i} \geq 0, i=1,2, \ldots m
\end{array}</script><p>引入拉格朗日乘子 $\mu_{i}$,</p>
<p>$L(w, b, \alpha, \hat{\alpha}, \xi, \hat{\xi}, \mu, \hat{\mu})$<br>$=\frac{1}{2}|w|^{2}+C \sum_{i=1}^{m}\left(\xi_{i}+\widehat{\xi}_{i}\right)-\sum_{i=1}^{m} \xi_{i} \mu_{i}-\sum_{i=1}^{m} \widehat{\xi}_{i} \widehat{\mu_{i}}$<br>$+\sum_{i=1}^{m} \alpha_{i}\left(f\left(x_{i}\right)-y_{i}-\epsilon-\xi_{i}\right)+\sum_{i=1}^{m} \widehat{\alpha_{i}}\left(y_{i}-f\left(x_{i}\right)-\epsilon-\widehat{\xi}_{i}\right)$</p>
<p>再令 $L(w, b, a, \hat{a}, \xi, \hat{\xi}, \mu, \mu)$ 对 $w, b, \xi_{i}, \hat{\xi}_{i}$ 的偏导为零可得:</p>
<script type="math/tex; mode=display">
w=\sum_{i=1}^{m}\left(\widehat{\alpha_{i}}-\alpha_{i}\right) x_{i}</script><p>上述过程中需满足KKT条件, 即要求:</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{c}
\alpha_{i}\left(f\left(x_{i}\right)-y_{i}-\epsilon-\xi_{i}\right)=0 \\
\widehat{\alpha_{i}}\left(y_{i}-f\left(x_{i}\right)-\epsilon-\widehat{\xi}_{i}\right)=0 \\
\alpha_{i} \widehat{\alpha_{i}}=0, \xi_{i} \widehat{\xi}_{i}=0 \\
\left(C-\alpha_{i}\right) \xi_{i}=0,\left(C-\widehat{\alpha_{i}}\right) \widehat{\xi}_{i}=0 .
\end{array}\right.</script><h3><span id="57-多分类-svm">5.7 多分类 SVM</span></h3><h4><span id="571-多分类问题">5.7.1 多分类问题</span></h4><ul>
<li>多分类问题拆解成若干个二分类问题，对于每个二分类训练一个分类器。<ul>
<li><strong>one vs one 拆解</strong>：K(K-1)/2 个分类器。</li>
<li><strong>one vs Rest 拆解</strong>：K个分类器</li>
</ul>
</li>
</ul>
<p><img src="https://s2.loli.net/2023/04/17/OJqX539ByWxSDVN.png" alt="image-20220401192909167" style="zoom:50%;"></p>
<ul>
<li><p><strong>根据模型特点设计：多分类线性SVM</strong></p>
<ul>
<li><p><strong>层次支持向量机</strong></p>
</li>
<li><p><strong>回顾二分类</strong>；</p>
<p><img src="https://s2.loli.net/2023/04/17/YJLzqnSQGTyXFc3.png" alt="image-20220401193645250" style="zoom:50%;"></p>
</li>
<li><p><strong>多分类线性SVM</strong>：</p>
<p><img src="https://s2.loli.net/2023/04/17/kZ19DcBfzWuMAaG.png" alt="image-20220401194059380" style="zoom:50%;"></p>
</li>
</ul>
</li>
</ul>
<h2><span id="6-优缺点">6. 优缺点</span></h2><h3><span id="61-优点">6.1 优点</span></h3><ul>
<li>有严格的<strong>==数学理论支持==</strong>，<strong>==可解释性强==</strong>，<strong>==不依靠统计方法==</strong>，从而<strong>简化了通常的分类和回归问题</strong>；</li>
<li>能找出对任务至关重要的<strong>==关键样本==</strong>（即：<strong>支持向量</strong>）；</li>
<li>采用<strong>==核技巧==</strong>之后，<strong>==可以处理非线性分类/回归任务==</strong>；</li>
<li><strong>==最终决策函数只由少数的支持向量所确定，计算的复杂性取决于支持向量的数目，而不是样本空间的维数，这在某种意义上避免了“维数灾难”。==</strong></li>
</ul>
<h3><span id="62-缺点">6.2 缺点</span></h3><ul>
<li><strong>训练时间长</strong>：当采用 SMO 算法时，由于每次都需要挑选一对参数，因此时间复杂度为 <img src="https://www.zhihu.com/equation?tex=O%28N%5E2%29" alt="[公式]"> ，其中 N 为训练样本的数量；</li>
<li><strong>存储空间大</strong>：当采用核技巧时，如果需要存储核矩阵，则空间复杂度为 <img src="https://www.zhihu.com/equation?tex=O%28N%5E2%29" alt="[公式]"> ；</li>
<li><strong>预测时间长</strong>：模型预测时，预测时间与支持向量的个数成正比。当支持向量的数量较大时，预测计算复杂度较高。</li>
</ul>
<p><strong>==因此支持向量机目前只适合小批量样本的任务，无法适应百万甚至上亿样本的任务。==</strong></p>
<h2><span id="svm-qampa">SVM Q&amp;A</span></h2><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/93715996">https://zhuanlan.zhihu.com/p/93715996</a></p>
</blockquote>
<h3><span id="1-原理">1、原理：</span></h3><ul>
<li>简单介绍SVM（详细原理）：从分类平面，到求两类间的最大间隔，到转化为求间隔分之一，等优化问题，然后就是优化问题的解决办法，首先是用拉格拉日乘子把约束优化转化为无约束优化，对各个变量求导令其为零，得到的式子带入拉格朗日式子从而转化为对偶问题， 最后再利用SMO（序列最小优化）来解决这个对偶问题。<strong>svm里面的超参数c有啥用：软间隔SVM去权衡优化目标和少量分错样本的目标。</strong></li>
<li><p>SVM的推导，解释原问题和对偶问题，<strong>SVM原问题和对偶问题的关系</strong>，<strong>KKT限制条件</strong>，<strong>KKT条件用哪些</strong>，完整描述；软间隔问题，解释支持向量、核函数（哪个地方引入、画图解释高维映射，高斯核可以升到多少维，如何选择核函数），引入拉格朗日的优化方法的原因，最大的特点，损失函数解释</p>
<ul>
<li><strong>KKT限制</strong>：主问题可行、对偶问题可行、主变量最优、<strong>互补松弛</strong></li>
</ul>
</li>
<li><p><strong>为什么要把原问题转换为对偶问题？</strong></p>
<ul>
<li>因为原问题是凸二次规划问题，转换为对偶问题更加高效。为什么求解对偶问题更加高效？因为只用求解alpha系数，而alpha系数只有支持向量才非0，其他全部为0.alpha系数有多少个？样本点的个数</li>
</ul>
</li>
</ul>
<h3><span id="2-svm与lr最大区别lr和svm对于outlier的敏感程度分析逻辑回归与svm的区别">2、SVM与LR最大区别，LR和SVM对于outlier的敏感程度分析，逻辑回归与SVM的区别？</span></h3><h3><span id="3-svm如何解决多分类问题-可以做回归吗怎么做">3、SVM如何解决==多分类问题==、可以做==回归==吗，怎么做？</span></h3><h3><span id="4-机器学习有很多关于核函数的说法核函数的定义和作用是什么">4、机器学习有很多关于核函数的说法，核函数的定义和作用是什么？</span></h3><p><a href="https://www.zhihu.com/question/24627666">https://www.zhihu.com/question/24627666</a></p>
<h3><span id="5-linear-svm-和-lr-有什么异同">5、Linear SVM 和 LR 有什么异同？</span></h3><h4><span id="svm和lr相同点">SVM和LR相同点：</span></h4><ul>
<li>SVM和LR都属于机器学习的监督学习中的<strong>判别式模型</strong>（判别式模型对$p(y|x)$进行建模或直接基于x预测y，生成模型：$p(x|y)$和$p(y)$进行建模,预测后验概率）。</li>
<li>SVM和LR都是线性二分类模型，<strong>分类边界为一个超平面</strong>。</li>
<li>线性SVM和对数几率回归都可以基于表示定理和<strong>核技巧处理非线性可分问题</strong>。</li>
<li><strong>SVM的基本型和对数几率函数都属于参数模型。SVM的对偶性和核化对数几率回归都属于非参数模型</strong>。</li>
<li>SVM和LR优化目标都表示成：经验风险+结构风险（正则项）的形式；均是0，1损失的替代函数。风险结构都是L2正则化。</li>
<li><strong>SVM和LR都是凸优化问题，都能收敛到全局最优解。</strong></li>
<li>SVM和对数几率函数的优化目标相似，性能相当。</li>
<li><strong>SVM多分类：多分类SVM；LR多分类：Softmax回归。</strong></li>
</ul>
<h3><span id="svm和lr的区别"><strong><font color="red"> SVM和LR的区别：</font></strong></span></h3><blockquote>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>SVM</th>
<th>LR</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>思想</strong></td>
<td><strong>SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面</strong>。</td>
<td><strong>逻辑回归</strong>是使用线性回归模型的预测值逼近分类任务真实标记的对数几率。</td>
</tr>
<tr>
<td><strong>输出</strong></td>
<td><strong>非概率方法</strong>；</td>
<td><strong>概率方法</strong>；需要对$p(y</td>
<td>x)$进行假设，具有概率意义。</td>
</tr>
<tr>
<td><strong>经验损失函数</strong></td>
<td><strong>合页损失函数</strong>；有一段平的零区域、使得SVM的对偶性有稀疏性。</td>
<td><strong>交叉熵损失函数</strong></td>
</tr>
<tr>
<td><strong>训练样本</strong></td>
<td>支持向量（少数样本），SVM的参数和假设函数只和支持向量有关。</td>
<td>全样本</td>
</tr>
<tr>
<td><strong>优化方法</strong></td>
<td>次梯度下降和坐标梯度下降 【<strong>SMO算法</strong>】</td>
<td><strong>梯度下降</strong></td>
</tr>
<tr>
<td>多分类</td>
<td><strong>多分类SVM</strong></td>
<td><strong>Softmax回归</strong></td>
</tr>
<tr>
<td><strong>敏感程度</strong></td>
<td>SVM考虑分类边界线附近的样本（决定分类超平面的样本）。在支持向量外添加或减少任何样本点对分类决策面没有任何影响；</td>
<td>LR受所有数据点的影响。直接依赖数据分布，每个样本点都会影响决策面的结果。如果训练数据不同类别严重不平衡。</td>
</tr>
</tbody>
</table>
</div>
<p><a href="https://www.zhihu.com/question/26768865">https://www.zhihu.com/question/26768865</a></p>
<h3><span id="6-支持向量机svm是否适合大规模数据速度">6、支持向量机(SVM)是否适合大规模数据？【速度】</span></h3><p><a href="https://www.zhihu.com/question/19591450">https://www.zhihu.com/question/19591450</a></p>
<h3><span id="7-svm和逻辑斯特回归对同一样本a进行训练如果某类中增加一些数据点那么原来的决策边界分别会怎么变化">7、SVM和逻辑斯特回归对同一样本A进行训练，如果某类中增加一些数据点，那么原来的决策边界分别会怎么变化？</span></h3><p><a href="https://www.zhihu.com/question/30123068">https://www.zhihu.com/question/30123068</a></p>
<h3><span id="8-各种机器学习的应用场景分别是什么例如k近邻贝叶斯决策树svm逻辑斯蒂回归和最大熵模型">8、各种机器学习的应用场景分别是什么？例如，k近邻,贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。</span></h3><p><a href="https://www.zhihu.com/question/26726794">https://www.zhihu.com/question/26726794</a></p>
<h3><span id="9-svm与感知器的联系和优缺点比较">==9、SVM与感知器的联系和优缺点比较==</span></h3><p><strong>感知机用误分类样本点的几何距离之和</strong>来表示模型的损失函数，用梯度下降算法优化，直至没有误分类点。</p>
<script type="math/tex; mode=display">
L(w, b)=-\sum_{x^{(i)} \in M} y^{(i)}\left(w^{T} x^{(i)}+b\right)</script><h4><span id="感知机与svm区别">==感知机与SVM区别：==</span></h4><p><strong>SVM可以视为对感知器的二阶改进</strong>：第一阶改进是加入了 <img src="https://www.zhihu.com/equation?tex=%5Cgamma" alt="[公式]"> 获得hinge loss，从而具备了产生大间隔的潜质；第二阶改进是加入了权向量的L2正则化项，从而避免产生无意义的大函数间隔，而是产生大的几何间隔。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>感知机</th>
<th>SVM</th>
</tr>
</thead>
<tbody>
<tr>
<td>思想</td>
<td>分离超平面基于误分类的损失函数<img src="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5En+max%280%2C+-y_i%28w%5ETx_i%2Bb%29%29%5C%5C" alt="[公式]"></td>
<td><img src="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5En+max%280%2C+1-y_i%28w%5ETx_i%2Bb%29%29+%2B+%5Calpha+%7C%7Cw%7C%7C_2%5E2+%5C%5C" alt="[公式]" style="zoom:150%;"></td>
</tr>
<tr>
<td>超平面</td>
<td>因采用的初值不同而得到不同的超平面</td>
<td>让离划分超平面最近的样本到划分超平面距离尽可能远</td>
</tr>
<tr>
<td>关键样本</td>
<td>每步的分错样本</td>
<td><strong>支持向量</strong></td>
</tr>
<tr>
<td>非线性问题</td>
<td>无</td>
<td>核化</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
</search>
