<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>/2023/04/16/Untitled/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>机器学习理论</title>
    <url>/2023/04/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%880%EF%BC%89%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h2 id="机器学习理论"><a href="#机器学习理论" class="headerlink" title="机器学习理论"></a>机器学习理论</h2><h3 id="一、-机器学习中参数模型和非参数模型理解"><a href="#一、-机器学习中参数模型和非参数模型理解" class="headerlink" title="一、 机器学习中参数模型和非参数模型理解"></a><strong>一、 机器学习中参数模型和非参数模型理解</strong></h3><blockquote>
<p>  参考：<a href="https://blog.csdn.net/FrankieHello/article/details/94022594">https://blog.csdn.net/FrankieHello/article/details/94022594</a></p>
</blockquote>
<p><strong>参数模型通常假设总体服从某个分布，这个分布可以由一些参数确定，如正态分布由均值和标准差确定，在此基础上构建的模型称为参数模型</strong>；非参数模型对于总体的分布不做任何假设或者说是数据分布假设自由，只知道其分布是存在的，所以就无法得到其分布的相关参数，只能通过非参数统计的方法进行推断。</p>
<p><strong>参数模型</strong>：线性回归、逻辑回归、感知机、基本型的SVM</p>
<p><strong>非参数模型</strong>：决策树、对偶型的SVM、朴素贝叶斯、神经网络</p>
<span id="more"></span>
<h3 id="二、-判别模型-VS-生成模型"><a href="#二、-判别模型-VS-生成模型" class="headerlink" title="二、 判别模型 VS 生成模型"></a>二、 判别模型 VS 生成模型</h3><blockquote>
<p>  判别模型与生成模型，概率模型与非概率模型、参数模型与非参数模型总结 - Eureka的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/37821985">https://zhuanlan.zhihu.com/p/37821985</a></p>
<p>  <strong>机器学习中的判别式模型和生成式模型</strong> - Microstrong的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/74586507">https://zhuanlan.zhihu.com/p/74586507</a></p>
</blockquote>

<p><img src="v2-9b345d3e93a81dc4e7a88fccff3720b3_b-1633296.png" alt="img" style="zoom: 67%;"></p>
<h5 id="判别模型：感知机、逻辑斯特回归、支持向量机、神经网络、k近邻都属于判别学习模型。"><a href="#判别模型：感知机、逻辑斯特回归、支持向量机、神经网络、k近邻都属于判别学习模型。" class="headerlink" title="判别模型：感知机、逻辑斯特回归、支持向量机、神经网络、k近邻都属于判别学习模型。"></a>判别模型：感知机、逻辑斯特回归、支持向量机、神经网络、k近邻都属于判别学习模型。</h5><p><strong>判别模型分为两种:</strong></p>
<ul>
<li>直接对输入空间到输出空间的映射进行建模, 也就是学习函数 $h$ : </li>
</ul>
<script type="math/tex; mode=display">
h: X \rightarrow Y, s . t . y=h(x)</script><ul>
<li>对条件概率 $P(y \mid x)$ 进行建模, 然后根据贝叶斯风险最小化的准则进行分类: 【</li>
</ul>
<script type="math/tex; mode=display">
y=\arg \max _{y \in\{-1,1\}} P(y \mid x)</script><h5 id="生成模型："><a href="#生成模型：" class="headerlink" title="生成模型："></a>生成模型：</h5><p>生成模型是间接地, 先对 $P(x, y)$ 进行建模, 再根据贝叶斯公式:</p>
<script type="math/tex; mode=display">
P(y \mid x)=\frac{P(x \mid y) P(y)}{P(x)}</script><p>算出 $P(y \mid x)$, 最后根据 $\arg \max _{y \in\{-1,1\}} P(y \mid x)$ 来做分类 (由此可知, 判别模型实际上不需要对 $P(x, y)$ 进行建模)。</p>
<h3 id="三、-非概率模型-VS-概率模型"><a href="#三、-非概率模型-VS-概率模型" class="headerlink" title="三、 非概率模型 VS 概率模型"></a>三、 非概率模型 VS 概率模型</h3><p>两者的本质区别在于是否涉及到概率分布。</p>
<h4 id="3-1-概率模型"><a href="#3-1-概率模型" class="headerlink" title="3.1 概率模型"></a>3.1 <strong>概率模型</strong></h4><blockquote>
<p>  <strong>线性回归（高斯分布）、LR（伯努利分布）、高斯判别分析、朴素贝叶斯</strong></p>
</blockquote>
<p><strong>概率模型指出了学习的目的是学出 $P(x, y)$ 或 $P(y \mid x)$, 但最后都是根据 $\arg \max _{y \in\{-1,1\}} P(y \mid x)$ 来做判别归类</strong>。对于 $P(x, y)$ 的估计, 一般是根据乘法公式 $P(x, y)=P(x \mid y) P(y)$ 将其拆解成 $P(x \mid y), P(y)$ 分别进行估计。无论是对 $P(x \mid y), P(y)$ 还是 $P(y \mid x)$ 的估计, 都是会先假设分布的形式, 例如逻辑斯特回归就假设了 $Y \mid X$ 服从伯努利分 布。分布形式固定以后, 剩下的就是分布参数的估计问题。<strong>常用的估计有极大似然估计(MLE)和极大后验概率估计 (MAP)等</strong>。其中, 极大后验概率估计涉及到分布参数的先验概率, 这为我们注入先验知识提供了途径。逻辑斯特回 归、高斯判别分析、朴素贝叶斯都属于概率模型。</p>
<p>在一定的条件下，非概率模型与概率模型有以下对应关系:</p>
<p><img src="v2-70105273742bb35eba11ec79151573cc_1440w-1633296.jpg" alt="img" style="zoom:50%;"></p>
<h4 id="3-2-非概率模型"><a href="#3-2-非概率模型" class="headerlink" title="3.2 非概率模型"></a>3.2 非概率模型</h4><blockquote>
<p>  <strong>感知机、支持向量机、神经网络、k近邻都属于非概率模型</strong>。线性支持向量机可以显式地写出损失函数——hinge损失。神经网络也可以显式地写出损失函数——平方损失。</p>
</blockquote>
<p>非概率模型指的是直接学习输入空间到输出空间的映射 $h$, 学习的过程中基本不涉及概率密度的估计, 概率密度 的积分等操作, 问题的关键在于最优化问题的求解。通常, 为了学习假设 $h(x)$, 我们会先根据一些先验知识 (prior knowledge) 来选择一个特定的假设空间 $H(x)$ (函数空间), 例如一个由所有线性函数构成的空间, 然后在 这个空间中找出泛化误差最小的假设出来, |</p>
<script type="math/tex; mode=display">
h^*=\arg \min _{h \in H} \varepsilon(h)=\arg \min _{h \in H} \sum_{x, y} l(h(x), y) P(x, y)</script><p>其中 $l(h(x), y)$ 是我们选取的损失函数, 选择不同的损失函数, 得到假设的泛化误差就会不一样。由于我们并不知 道 $P(x, y)$, 所以即使我们选好了损失函数, 也无法计算出假设的泛化误差, 更别提找到那个给出最小泛化误差的 假设。于是，我们转而去找那个使得经验误差最小的假设</p>
<script type="math/tex; mode=display">
g=\arg \min _{h \in H} \hat{\varepsilon}(h)=\arg \min _{h \in H} \frac{1}{m} \sum_{i=1}^{m} l\left(h\left(x^{(i)}\right), y^{(i)}\right)</script><p><font color="red"> 这种学习的策略叫经验误差最小化(ERM)，理论依据是大数定律：当训练样例无穷多的时候，假设的经验误差会依概率收敛到假设的泛化误差。</font>要想成功地学习一个问题，必须在学习的过程中注入先验知识。前面，我们根据先验知识来选择假设空间，其实，在选定了假设空间后，先验知识还可以继续发挥作用，这一点体现在为我们的优化问题加上正则化项上，例如常用的$L1$正则化， $L2$正则化等。</p>
<script type="math/tex; mode=display">
g=\arg \min _{h \in H} \hat{\varepsilon}(h)=\arg \min _{h \in H} \frac{1}{m} \sum_{i=1}^{m} l\left(h\left(x^{(i)}\right), y^{(i)}\right)+\lambda \Omega(h)</script><h2 id="四、-过拟合和欠拟合"><a href="#四、-过拟合和欠拟合" class="headerlink" title="四、 过拟合和欠拟合"></a>四、 过拟合和欠拟合</h2><blockquote>
<p>  欠拟合、过拟合及如何防止过拟合 - G-kdom的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/72038532">https://zhuanlan.zhihu.com/p/72038532</a></p>
</blockquote>
<h3 id="4-1-欠拟合"><a href="#4-1-欠拟合" class="headerlink" title="4.1 欠拟合"></a>4.1 欠拟合</h3><p><strong>欠拟合是指模型不能在训练集上获得足够低的误差</strong>。换句换说，就是模型复杂度低，模型在训练集上就表现很差，没法学习到数据背后的规律。</p>
<h3 id="4-2-欠拟合解决方法"><a href="#4-2-欠拟合解决方法" class="headerlink" title="4.2 欠拟合解决方法"></a>4.2 欠拟合解决方法</h3><p>欠拟合基本上都会发生在训练刚开始的时候，经过不断训练之后欠拟合应该不怎么考虑了。但是如果真的还是存在的话，可以通过<strong>增加网络复杂度</strong>或者在模型中<strong>增加特征</strong>，这些都是很好解决欠拟合的方法。</p>
<h3 id="4-3-过拟合"><a href="#4-3-过拟合" class="headerlink" title="4.3 过拟合"></a>4.3 过拟合</h3><p>过拟合是指训练误差和测试误差之间的差距太大。换句换说，就是模型复杂度高于实际问题，<strong>模型在训练集上表现很好，但在测试集上却表现很差</strong>。模型对训练集”死记硬背”（记住了不适用于测试集的训练集性质或特点），没有理解数据背后的规律，<strong>泛化能力差</strong>。</p>
<p>造成原因主要有以下几种：<br>1、<strong>训练数据集样本单一，样本不足</strong>。如果训练样本只有负样本，然后那生成的模型去预测正样本，这肯定预测不准。所以训练样本要尽可能的全面，覆盖所有的数据类型。<br>2、<strong>训练数据中噪声干扰过大</strong>。噪声指训练数据中的干扰数据。过多的干扰会导致记录了很多噪声特征，忽略了真实输入和输出之间的关系。<br>3、<strong>模型过于复杂。</strong>模型太复杂，已经能够“死记硬背”记下了训练数据的信息，但是遇到没有见过的数据的时候不能够变通，泛化能力太差。我们希望模型对不同的模型都有稳定的输出。模型太复杂是过拟合的重要因素。</p>
<h3 id="4-4-如何防止过拟合"><a href="#4-4-如何防止过拟合" class="headerlink" title="4.4 如何防止过拟合"></a>4.4 如何防止过拟合</h3><p>要想解决过拟合问题，就要显著减少测试误差而不过度增加训练误差，从而提高模型的泛化能力。</p>
<h4 id="1、使用正则化（Regularization）方法。"><a href="#1、使用正则化（Regularization）方法。" class="headerlink" title="1、使用正则化（Regularization）方法。"></a>1、<strong>使用正则化（Regularization）方法。</strong></h4><p>那什么是<a href="https://www.zhihu.com/search?q=正则化&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">正则化</a>呢？<strong>正则化是指修改学习算法，使其降低泛化误差而非训练误差</strong>。</p>
<p>常用的正则化方法根据具体的使用策略不同可分为：（1）直接提供正则化约束的参数正则化方法，如L1/L2正则化；（2）通过工程上的技巧来实现更低泛化误差的方法，如提前终止(Early stopping)和Dropout；（3）不直接提供约束的隐式正则化方法，如数据增强等。</p>
<p><strong>L2正则化起到使得权重参数 $w$变小的效果，为什么能防止过拟合呢？</strong>因为更小的权重参数$w$意味着模型的复杂度更低，对训练数据的拟合刚刚好，不会过分拟合训练数据，从而提高模型的泛化能力。</p>
<h4 id="2、获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法"><a href="#2、获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法" class="headerlink" title="2、获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法"></a>2、<strong>获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法</strong></h4><p>让机器学习或深度学习模型泛化能力更好的办法就是使用更多的数据进行训练。但是，在实践中，我们拥有的数据量是有限的。解决这个问题的一种方法就是<strong>创建“假数据”并添加到训练集中——数据集增强</strong>。通过增加训练集的额外副本来增加训练集的大小，进而改进模型的泛化能力。</p>
<p>我们以图像数据集举例，能够做：旋转图像、缩放图像、随机裁剪、加入随机噪声、平移、镜像等方式来增加数据量。另外补充一句，在物体分类问题里，<strong>CNN在图像识别的过程中有强大的“不变性”规则，即待辨识的物体在图像中的形状、姿势、位置、图像整体明暗度都不会影响分类结果</strong>。我们就可以通过图像平移、翻转、缩放、切割等手段将数据库成倍扩充。</p>
<h4 id="3-采用合适的模型（控制模型的复杂度）"><a href="#3-采用合适的模型（控制模型的复杂度）" class="headerlink" title="3. 采用合适的模型（控制模型的复杂度）"></a><strong>3. 采用合适的模型（控制模型的复杂度）</strong></h4><p>过于复杂的模型会带来过拟合问题。对于模型的设计，目前公认的一个深度学习规律”deeper is better”。国内外各种大牛通过实验和竞赛发现，对于CNN来说，层数越多效果越好，但是也更容易产生过拟合，并且计算所耗费的时间也越长。</p>
<p>根据<strong>奥卡姆剃刀法则</strong>：在同样能够解释已知观测现象的假设中，我们应该挑选“最简单”的那一个。对于模型的设计而言，我们应该<strong>选择简单、合适的模型解决复杂的问题</strong>。</p>
<h4 id="4-降低特征的数量"><a href="#4-降低特征的数量" class="headerlink" title="4. 降低特征的数量"></a><strong>4. 降低特征的数量</strong></h4><p>对于一些特征工程而言，可以降低特征的数量——删除冗余特征，人工选择保留哪些特征。这种方法也可以解决过拟合问题。</p>
<h4 id="5-Dropout"><a href="#5-Dropout" class="headerlink" title="5. Dropout"></a><strong>5. Dropout</strong></h4><p>Dropout是在训练网络时用的一种技巧（trike），相当于在隐藏单元增加了噪声。<strong>Dropout 指的是在训练过程中每次按一定的概率（比如50%）随机地“删除”一部分隐藏单元（神经元）。</strong>所谓的“删除”不是真正意义上的删除，其实就是将该部分神经元的激活函数设为0（激活函数的输出为0），让这些神经元不计算而已。</p>
<p><strong>Dropout为什么有助于防止过拟合呢？</strong></p>
<p>（a）在训练过程中会产生不同的训练模型，不同的训练模型也会产生不同的的计算结果。随着训练的不断进行，计算结果会在一个范围内波动，但是均值却不会有很大变化，因此可以把最终的训练结果看作是不同模型的平均输出。</p>
<p>（b）它消除或者减弱了神经元节点间的联合，降低了网络对单个神经元的依赖，从而增强了泛化能力。</p>
<h4 id="6-Early-stopping（提前终止）"><a href="#6-Early-stopping（提前终止）" class="headerlink" title="6. Early stopping（提前终止）"></a><strong>6. Early stopping（提前终止）</strong></h4><p>对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如<a href="https://www.zhihu.com/search?q=梯度下降&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">梯度下降</a>（Gradient descent）。<strong>Early stopping是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合</strong>。</p>
<p>为了获得性能良好的神经网络，训练过程中可能会经过很多次<a href="https://www.zhihu.com/search?q=epoch&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">epoch</a>（遍历整个数据集的次数，一次为一个epoch）。如果epoch数量太少，网络有可能发生欠拟合；如果epoch数量太多，则有可能发生过拟合。Early <a href="https://www.zhihu.com/search?q=stopping&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">stopping</a>旨在解决epoch数量需要手动设置的问题。具体做法：<strong>每个epoch（或每N个epoch）结束后，在验证集上获取测试结果，随着epoch的增加，如果在验证集上发现测试误差上升，则停止训练，将停止之后的权重作为网络的最终参数。</strong></p>
<p><strong>为什么能防止过拟合？</strong>当还未在神经网络运行太多迭代过程的时候，w参数接近于0，因为随机初始化<a href="https://www.zhihu.com/search?q=w值&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;72038532&quot;}">w值</a>的时候，它的值是较小的随机值。当你开始迭代过程，w的值会变得越来越大。到后面时，w的值已经变得十分大了。所以early stopping要做的就是在中间点停止迭代过程。我们将会得到一个中等大小的w参数，会得到与L2正则化相似的结果，选择了w参数较小的神经网络。</p>
<p><strong>Early Stopping缺点：没有采取不同的方式来解决优化损失函数和过拟合这两个问题</strong>，而是用一种方法同时解决两个问题 ，结果就是要考虑的东西变得更复杂。之所以不能独立地处理，因为如果你停止了优化损失函数，你可能会发现损失函数的值不够小，同时你又不希望过拟合。</p>
<h2 id="五、损失函数-loss-与评价指标-metric-的区别？"><a href="#五、损失函数-loss-与评价指标-metric-的区别？" class="headerlink" title="五、损失函数(loss)与评价指标(metric)的区别？"></a>五、损失函数(loss)与评价指标(metric)的区别？</h2><p><strong>当建立一个学习算法时，我们希望最大化一个给定的评价指标matric（比如说准确度），但算法在学习过程中会尝试优化一个不同的损失函数loss（比如说MSE/Cross-entropy）。</strong></p>
<h4 id="那为什么不把评价指标matric作为学习算法的损失函数loss呢？"><a href="#那为什么不把评价指标matric作为学习算法的损失函数loss呢？" class="headerlink" title="那为什么不把评价指标matric作为学习算法的损失函数loss呢？"></a>那为什么不把评价指标matric作为学习算法的损失函数loss呢？</h4><ul>
<li><p>一般来说，我认为你应该尝试优化一个与你最关心的评价指标相对应的损失函数。例如，在做分类时，我认为你需要给我一个很好的理由，让我不要优化交叉熵。也就是说，交叉熵并不是一个非常直观的指标，所以一旦你完成了训练，你可能还想知道你的分类准确率有多高，以了解你的模型是否真的能在现实世界中发挥作用，总之，在每个epoch训练完后，你都会有多个评估指标。这样作的主要原因是为了了解你的模型在做什么。这意味着你想要最大化指标A，以便得到一个接近最大化指标B的解决方案。</p>
</li>
<li><p>通常情况下，MSE/交叉熵比精度更容易优化，因为它们对模型参数是可微的，在某些情况下甚至是凸的，这使得它更容易。</p>
</li>
</ul>
<h2 id="六、标准化和归一化"><a href="#六、标准化和归一化" class="headerlink" title="六、标准化和归一化"></a>六、标准化和归一化</h2><blockquote>
<p>  PCA、k-means、SVM、回归模型、<strong>神经网络</strong></p>
</blockquote>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p><strong>归一化和标准化</strong>都是对<strong>数据做变换</strong>的方式，将原始的一列数据转换到某个范围，或者某种形态，具体的：</p>
<blockquote>
<p>  <strong>归一化(Normalization)</strong>：将一列数据变化到某个固定区间(范围)中，通常，这个区间是[0, 1]，广义的讲，可以是各种区间，比如映射到[0，1]一样可以继续映射到其他范围，图像中可能会映射到[0,255]，其他情况可能映射到[-1,1]；</p>
<p>  <strong>标准化(Standardization)</strong>：将数据变换为均值为0，标准差为1的分布切记，<strong>并非一定是正态的；</strong></p>
<p>  <strong>中心化</strong>：另外，还有一种处理叫做中心化，也叫零均值处理，就是将每个原始数据减去这些数据的均值。</p>
</blockquote>
<h4 id="差异"><a href="#差异" class="headerlink" title="差异"></a>差异</h4><blockquote>
<p>  <strong>归一化：对处理后的数据范围有严格要求;</strong></p>
<p>  <strong>标准化:  数据不为稳定，存在极端的最大最小值;  涉及距离度量、协方差计算的时候;</strong></p>
</blockquote>
<ul>
<li><strong>归一化会严格的限定变换后数据的范围</strong>，比如按之前最大最小值处理的，它的范围严格在[ 0 , 1 ]之间；而<strong>标准化</strong>就没有严格的区间，变换后的数据没有范围，只是其均值是0，标准差为1。</li>
<li><strong>归一化的缩放比例仅仅与极值有关</strong>，容易受到异常值的影响。</li>
</ul>
<h4 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h4><ul>
<li>回归模型，自变量X的量纲不一致导致了<strong>回归系数无法直接解读</strong>或者错误解读；需要将X都处理到统一量纲下，这样才可比；</li>
<li>机器学习任务和统计学任务中有很多地方要用到<strong>“距离”的计算</strong>，比如PCA，比如KNN，比如kmeans等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果；</li>
<li>参数估计时使用<strong>梯度下降</strong>，在使用梯度下降的方法求解最优化问题时， 归一化/标准化后可以加快梯度下降的求解速度，即<strong>提升模型的收敛速度</strong>。</li>
</ul>
<h4 id="其他：log、sigmod、softmax-变换"><a href="#其他：log、sigmod、softmax-变换" class="headerlink" title="其他：log、sigmod、softmax 变换"></a>其他：log、sigmod、softmax 变换</h4><h2 id="七、回归-vs-分类"><a href="#七、回归-vs-分类" class="headerlink" title="七、回归 vs 分类"></a>七、回归 vs 分类</h2><p>回归问题可以理解为是定量输出的问题，是一个连续变量预测；分类问题可以理解为是定性输出的问题，是一个离散变量预测。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title></title>
    <url>/2022/07/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8811%EF%BC%89CatBoost/</url>
    <content><![CDATA[<h2 id="深入理解CatBoost"><a href="#深入理解CatBoost" class="headerlink" title="深入理解CatBoost"></a>深入理解CatBoost</h2><blockquote>
<p>  深入理解CatBoost - Microstrong的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/102540344">https://zhuanlan.zhihu.com/p/102540344</a></p>
</blockquote>
<p><strong>本文主要内容概览：</strong></p>
<p><img src="https://pic1.zhimg.com/v2-f6a9520c6db0ba77ad620800cb36c054_b.jpg" alt="img"></p>
<h3 id="一、CatBoost简介"><a href="#一、CatBoost简介" class="headerlink" title="一、CatBoost简介"></a><strong>一、CatBoost简介</strong></h3><p>CatBoost是俄罗斯的搜索巨头Yandex在2017年开源的机器学习库，是Boosting族算法的一种。CatBoost和XGBoost、LightGBM并称为GBDT的三大主流神器，都是在GBDT算法框架下的一种改进实现。XGBoost被广泛的应用于工业界，LightGBM有效的提升了GBDT的计算效率，而Yandex的CatBoost号称是比XGBoost和LightGBM在算法准确率等方面表现更为优秀的算法。</p>
<p>CatBoost是一种基于对称决策树（oblivious trees）为基学习器实现的参数较少、支持类别型变量和高准确性的GBDT框架，主要解决的痛点是高效合理地处理类别型特征，这一点从它的名字中可以看出来，<strong>CatBoost是由Categorical和Boosting组成。此外，CatBoost还解决了梯度偏差（Gradient Bias）以及预测偏移（Prediction shift）的问题，从而减少过拟合的发生，进而提高算法的准确性和泛化能力。</strong></p>
<p><strong>与XGBoost、LightGBM相比，CatBoost的创新点有：</strong></p>
<ul>
<li><strong>嵌入了自动将类别型特征处理为数值型特征的创新算法。首先对categorical features做一些统计，计算某个类别特征（category）出现的频率，之后加上超参数，生成新的数值型特征（numerical features）。</strong></li>
<li><strong>Catboost还使用了组合类别特征，可以利用到特征之间的联系，这极大的丰富了特征维度</strong>。</li>
<li>采用排序提升的方法对抗训练集中的噪声点，从而避免梯度估计的偏差，进而解决预测偏移的问题。</li>
<li>采用了<strong>完全对称树作为基模型</strong>。</li>
</ul>
<h3 id="二、类别型特征"><a href="#二、类别型特征" class="headerlink" title="二、类别型特征"></a>二、<strong>类别型特征</strong></h3><p><strong>所谓类别型特征，即这类特征不是数值型特征，而是离散的集合</strong>，比如省份名（山东、山西、河北等），城市名（北京、上海、深圳等），学历（本科、硕士、博士等）。在梯度提升算法中，最常用的是将这些类别型特征转为数值型来处理，一般类别型特征会转化为一个或多个数值型特征。</p>
<p><strong>类别型特征基数比较低（low-cardinality features）</strong>，即该特征的所有值去重后构成的集合元素个数比较少，一般利用One-hot编码方法将特征转为数值型。One-hot编码可以在数据预处理时完成，也可以在模型训练的时候完成，从训练时间的角度，后一种方法的实现更为高效，CatBoost对于基数较低的类别型特征也是采用后一种实现。</p>
<p><strong>高基数类别型特征（high cardinality features）</strong>当中，比如 <code>user ID</code>，这种编码方式会产生大量新的特征，造成维度灾难。一种折中的办法是可以将类别分组成有限个的群体再进行One-hot编码。<strong>一种常被使用的方法是根据目标变量统计（Target Statistics，以下简称TS）进行分组</strong>，目标变量统计用于估算每个类别的目标变量期望值。甚至有人直接用TS作为一个新的数值型变量来代替原来的类别型变量。<strong><font color="red"> 重要的是，可以通过对TS数值型特征的阈值设置，基于对数损失、基尼系数或者均方差，得到一个对于训练集而言将类别一分为二的所有可能划分当中最优的那个。</font></strong></p>
<p>在LightGBM当中，类别型特征用每一步梯度提升时的梯度统计（Gradient Statistics，以下简称GS）来表示。虽然为建树提供了重要的信息，但是这种方法有以下两个缺点：</p>
<ul>
<li>增加计算时间，因为需要对每一个类别型特征，在迭代的每一步，都需要对GS进行计算；</li>
<li>增加存储需求，对于一个类别型变量，需要存储每一次分离每个节点的类别；</li>
</ul>
<p><strong>为了克服这些缺点，LightGBM以损失部分信息为代价将所有的长尾类别归为一类</strong>，作者声称这样处理高基数类别型特征时比One-hot编码还是好不少。不过如果采用TS特征，那么对于每个类别只需要计算和存储一个数字。</p>
<p>因此，采用TS作为一个新的数值型特征是最有效、信息损失最小的处理类别型特征的方法。TS也被广泛应用在点击预测任务当中，这个场景当中的类别型特征有用户、地区、广告、广告发布者等。接下来我们着重讨论TS，暂时将One-hot编码和GS放一边。</p>
<h4 id="2-1-目标变量统计（Target-Statistics）"><a href="#2-1-目标变量统计（Target-Statistics）" class="headerlink" title="2.1 目标变量统计（Target Statistics）"></a>2.1 <strong>目标变量统计（Target Statistics）</strong></h4><p><strong><font color="red"> CatBoost算法的设计初衷是为了更好的处理GBDT特征中的categorical features</font></strong>。在处理 GBDT特征中的categorical features的时候，最简单的方法是用 categorical feature 对应的标签的平均值来替换。在决策树中，标签平均值将作为节点分裂的标准。<strong>这种方法被称为 Greedy Target-based Statistics , 简称 Greedy TS</strong>，用公式来表达就是：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Chat%7Bx%7D_k%5Ei%3D%5Cfrac%7B%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%5Bx_%7Bj%2Ck%7D%3Dx_%7Bi%2Ck%7D%5D%5Ccdot+Y_i%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%5Bx_%7Bj%2Ck%7D%3Dx_%7Bi%2Ck%7D%5D%7D+%5C%5C" alt="[公式]"></p>
<p>这种方法有一个显而易见的缺陷，就是通常特征比标签包含更多的信息，<strong><font color="red"> 如果强行用标签的平均值来表示特征的话，当训练数据集和测试数据集数据结构和分布不一样的时候会出条件偏移问题。</font></strong></p>
<p>一个标准的改进 Greedy TS的方式是添加先验分布项，这样可以减少噪声和低频率类别型数据对于数据分布的影响：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Chat%7Bx%7D_k%5Ei%3D%5Cfrac%7B%5Csum_%7Bj%3D1%7D%5E%7Bp-1%7D%7B%5Bx_%7B%5Csigma_%7Bj%2Ck%7D%7D%3Dx_%7B%5Csigma_%7Bp%2Ck%7D%7D%5D%7DY_%7B%5Csigma_%7Bj%7D%7D%2Ba%5Ccdot+p%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bp-1%7D%7B%5Bx_%7B%5Csigma_%7Bj%2Ck%7D%7D%3Dx_%7B%5Csigma_%7Bp%2Ck%7D%7D%5D%7D%2Ba%7D+%5C%5C" alt="[公式]"></p>
<p> 其中 <img src="https://www.zhihu.com/equation?tex=p" alt="[公式]"> 是添加的先验项， <img src="https://www.zhihu.com/equation?tex=a+" alt="[公式]"> 通常是大于 <img src="https://www.zhihu.com/equation?tex=+0+" alt="[公式]"> 的权重系数。添加先验项是一个普遍做法，针对类别数较少的特征，它可以减少噪声数据。对于回归问题，一般情况下，先验项可取数据集label的均值。对于二分类，先验项是正例的先验概率。利用多个数据集排列也是有效的，但是，如果直接计算可能导致过拟合。CatBoost利用了一个比较新颖的计算叶子节点值的方法，这种方式(oblivious trees，对称树)可以避免多个数据集排列中直接计算会出现过拟合的问题。</p>
<p>当然，在论文《CatBoost: unbiased boosting with categorical features》中，还提到了其它几种改进Greedy TS的方法，分别有：Holdout TS、Leave-one-out TS、Ordered TS。我这里就不再翻译论文中的这些方法了，感兴趣的同学可以自己翻看一下原论文。</p>
<h4 id="2-2-特征组合"><a href="#2-2-特征组合" class="headerlink" title="2.2 特征组合"></a>2.2 <strong>特征组合</strong></h4><p>值得注意的是几个类别型特征的任意组合都可视为新的特征。例如，在音乐推荐应用中，我们有两个类别型特征：用户ID和音乐流派。如果有些用户更喜欢摇滚乐，将用户ID和音乐流派转换为数字特征时，根据上述这些信息就会丢失。结合这两个特征就可以解决这个问题，并且可以得到一个新的强大的特征。然而，组合的数量会随着数据集中类别型特征的数量成指数增长，因此不可能在算法中考虑所有组合。为当前树构造新的<a href="https://www.zhihu.com/search?q=分割点&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;102540344&quot;}">分割点</a>时，CatBoost会采用贪婪的策略考虑组合。对于树的第一次分割，不考虑任何组合。对于下一个分割，CatBoost将当前树的所有组合、类别型特征与数据集中的所有类别型特征相结合，并将新的组合类别型特征动态地转换为数值型特征。CatBoost还通过以下方式生成数值型特征和类别型特征的组合：树中选定的所有分割点都被视为具有两个值的类别型特征，并像类别型特征一样被进行组合考虑。</p>
<h4 id="2-3-CatBoost处理Categorical-features总结"><a href="#2-3-CatBoost处理Categorical-features总结" class="headerlink" title="2.3  CatBoost处理Categorical features总结"></a>2.3  <strong>CatBoost处理Categorical features总结</strong></h4><ul>
<li><strong>首先计算一些数据的statistics。计算某个category出现的频率，加上超参数，生成新的numerical features</strong>。这一策略要求同一标签数据不能排列在一起（即先全是0之后全是1这种方式），训练之前需要打乱数据集。</li>
<li>使用数据的不同排列（实际上是4个）。在每一轮建立树之前，先扔一轮骰子，决定使用哪个排列来生成树。</li>
<li>考虑使用categorical features的不同组合。例如颜色和种类组合起来，可以构成类似于blue dog这样的特征。当需要组合的categorical features变多时，CatBoost只考虑一部分<a href="https://www.zhihu.com/search?q=combinations&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;102540344&quot;}">combinations</a>。在选择第一个节点时，只考虑选择一个特征，例如A。在生成第二个节点时，考虑A和任意一个categorical feature的组合，选择其中最好的。就这样使用贪心算法生成combinations。</li>
<li><strong>除非向gender这种维数很小的情况，不建议自己生成One-hot编码向量，最好交给算法来处理。</strong></li>
</ul>
<h2 id="三、CatboostQ-amp-A"><a href="#三、CatboostQ-amp-A" class="headerlink" title="三、CatboostQ&amp;A"></a>三、CatboostQ&amp;A</h2><h4 id="3-1-CatBoost与XGBoost、LightGBM的联系与区别？"><a href="#3-1-CatBoost与XGBoost、LightGBM的联系与区别？" class="headerlink" title="3.1 CatBoost与XGBoost、LightGBM的联系与区别？"></a>3.1 <strong>CatBoost与XGBoost、LightGBM的联系与区别？</strong></h4><p>（1）2014年3月XGBoost算法首次被<a href="https://www.zhihu.com/search?q=陈天奇&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;102540344&quot;}">陈天奇</a>提出，但是直到2016年才逐渐著名。2017年1月微软发布LightGBM第一个稳定版本。2017年4月Yandex开源CatBoost。自从XGBoost被提出之后，很多文章都在对其进行各种改进，CatBoost和LightGBM就是其中的两种。</p>
<p>（2）<strong>CatBoost处理类别型特征十分灵活，可直接传入类别型特征的列标识，模型会自动将其使用One-hot编码，还可通过设置 one_hot_max_size参数来限制One-hot特征向量的长度</strong>。如果不传入类别型特征的列标识，那么CatBoost会把所有列视为数值特征。对于One-hot编码超过设定的one_hot_max_size值的特征来说，CatBoost将会使用一种高效的encoding方法，与mean encoding类似，但是会降低过拟合。处理过程如下：</p>
<ul>
<li>将输入样本集随机排序，并生成多组随机排列的情况；</li>
<li>将浮点型或属性值标记转化为整数；</li>
<li>将所有的类别型特征值结果都根据以下公式，转化为数值结果；</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=avg%5C_target+%3D+%5Cfrac%7BcountInClass+%2B+prior%7D%7BtotalCount+%2B+1%7D+%5C%5C" alt="[公式]"> </p>
<p>其中 countInClass 表示在当前类别型特征值中有多少样本的标记值是1；prior 是分子的初始值，根据初始参数确定。totalCount 是在所有样本中（包含当前样本）和当前样本具有相同的类别型特征值的样本数量。</p>
<p>LighGBM 和 CatBoost 类似，也可以通过使用特征名称的输入来处理类别型特征数据，它没有对数据进行独热编码，因此速度比独热编码快得多。LighGBM 使用了一个特殊的算法来确定属性特征的分割值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_data = lgb.Dataset(data, label=label, feature_name=[<span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>], categorical_feature=[<span class="string">&#x27;c3&#x27;</span>])</span><br><span class="line"><span class="comment"># 注意，在建立适用于 LighGBM 的数据集之前，需要将类别型特征变量转化为整型变量，此算法不允许将字符串数据传给类别型变量参数。</span></span><br></pre></td></tr></table></figure>
<p>（3）XGBoost 和 CatBoost、 LighGBM 算法不同，XGBoost 本身无法处理类别型特征，而是像随机森林一样，只接受数值数据。因此在将类别型特征数据传入 XGBoost 之前，必须通过各种编码方式：例如序号编码、独热编码和二进制编码等对数据进行处理。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8810%EF%BC%89%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0*/</url>
    <content><![CDATA[<h2 id="【机器学习】决策树（中）——Random-Forest、Adaboost、GBDT"><a href="#【机器学习】决策树（中）——Random-Forest、Adaboost、GBDT" class="headerlink" title="【机器学习】决策树（中）——Random Forest、Adaboost、GBDT"></a>【机器学习】决策树（中）——Random Forest、Adaboost、GBDT</h2><blockquote>
<p>  <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble">https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble</a></p>
<p>  机器学习算法中GBDT与Adaboost的区别与联系是什么？ - Frankenstein的回答 - 知乎 <a href="https://www.zhihu.com/question/54626685/answer/140610056">https://www.zhihu.com/question/54626685/answer/140610056</a></p>
<p>  GBDT学习笔记 - 许辙的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/169382376">https://zhuanlan.zhihu.com/p/169382376</a></p>
<p>  GBDT - 王多鱼的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/38057220">https://zhuanlan.zhihu.com/p/38057220</a></p>
</blockquote>
<p><img src="https://pic2.zhimg.com/v2-1ac553d300784e8d158bcc686e7cf66d_1440w.jpg?source=172ae18b" alt="【机器学习】决策树（中）——Random Forest、Adaboost、GBDT （非常详细）"></p>
<p>本文主要介绍基于集成学习的决策树，其主要通过不同学习框架生产基学习器，并综合所有基学习器的预测结果来改善单个基学习器的识别率和泛化性。</p>
<p>==模型的准确度可由偏差和方差共同决定：==</p>
<p>$\text { Error }=\text { bias }^{2}+\operatorname{var}+\xi$</p>
<p><strong>模型总体期望：</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
E(F) &=E\left(\sum_{i}^{m} r_{i} f_{i}\right) \\
&=\sum_{i}^{m} r_{i} E\left(f_{i}\right)
\end{aligned}</script><p><strong>模型总体方差</strong>:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\operatorname{Var}(F) &=\operatorname{Var}\left(\sum_{i}^{m} r_{i} f_{i}\right) \\
&=\sum_{i}^{m} \operatorname{Var}\left(r_{i} f_{i}\right)+\sum_{i \neq j}^{m} \operatorname{Cov}\left(r_{i} f_{i}, r_{j} f_{j}\right) \\
&=\sum_{i}^{m} r_{i}{ }^{2} \operatorname{Var}\left(f_{i}\right)+\sum_{i \neq j}^{m} \rho r_{i} r_{j} \sqrt{\operatorname{Var}\left(f_{i}\right)} \sqrt{\operatorname{Var}\left(f_{j}\right)} \\
&=m r^{2} \sigma^{2}+m(m-1) \rho r^{2} \sigma^{2} \\
&=m r^{2} \sigma^{2}(1-\rho)+m^{2} r^{2} \sigma^{2} \rho
\end{aligned}</script><div class="table-container">
<table>
<thead>
<tr>
<th>集成学习</th>
<th>Bagging</th>
<th>Boosting</th>
<th>Stacking</th>
</tr>
</thead>
<tbody>
<tr>
<td>思想</td>
<td>对训练集进行<strong>有放回抽样</strong>得到子训练集</td>
<td>基模型的训练是有<strong>顺序</strong>的，每个基模型都会在前一个基模型学习的基础上进行学习；基于贪心策略的前向加法</td>
<td><strong>预测值</strong>将作为训练样本的特征值，进行训练得到最终预测结果。</td>
</tr>
<tr>
<td>样本抽样</td>
<td>有放回地抽取数据集</td>
<td>训练集不变</td>
<td></td>
</tr>
<tr>
<td>样本权重</td>
<td>样本权重相等</td>
<td>不断调整样本的权重</td>
<td></td>
</tr>
<tr>
<td>优化目标</td>
<td>减小的是方差</td>
<td>减小的是偏差</td>
<td></td>
</tr>
<tr>
<td>基模型</td>
<td><strong>强模型（偏差低，方差高）</strong></td>
<td><strong>弱模型（偏差高，方差低）</strong>而整体模型的偏差由基模型累加而成，故基模型需要为弱模型。</td>
<td><strong>强模型（偏差低，方差高）</strong></td>
</tr>
<tr>
<td>相关性</td>
<td></td>
<td>对于 Boosting 来说，由于基模型共用同一套训练集，所以基模型间具有强相关性，故模型间的相关系数近似等于 1</td>
<td></td>
</tr>
<tr>
<td>模型偏差</td>
<td><strong>整体模型的偏差与基模型近似</strong>。(<script type="math/tex">\mu</script>)</td>
<td>基于贪心策略的前向加法，随着基模型数的增多，偏差减少。</td>
<td></td>
</tr>
<tr>
<td>模型方差</td>
<td>随着<strong>模型的增加可以降低整体模型的方差</strong>，故其基模型需要为强模型；(<script type="math/tex">\frac{\sigma^{2}(1-\rho)}{m}+\sigma^{2} \rho</script>)</td>
<td><strong>整体模型的方差与基模型近似</strong>（<script type="math/tex">\sigma^{2}</script>）</td>
</tr>
</tbody>
</table>
</div>
<h2 id="1-集成学习"><a href="#1-集成学习" class="headerlink" title="1. 集成学习"></a>1. 集成学习</h2><p>常见的集成学习框架有三种：Bagging，Boosting 和 Stacking。三种集成学习框架在基学习器的产生和综合结果的方式上会有些区别，我们先做些简单的介绍。</p>
<h3 id="1-1-Bagging"><a href="#1-1-Bagging" class="headerlink" title="1.1 Bagging"></a>1.1 Bagging</h3><p>Bagging 全称叫 <strong>Bootstrap aggregating</strong>，，==每个基学习器都会对训练集进行<strong>有放回抽样</strong>得到子训练集==，比较著名的采样法为 0.632 自助法（<strong>Bootstrap</strong>）。每个基学习器基于不同子训练集进行训练，并综合所有基学习器的预测值得到最终的预测结果。Bagging 常用的综合方法是<strong>投票法</strong>，票数最多的类别为预测类别。</p>
<p><img src="https://pic1.zhimg.com/80/v2-a0a3cb02f629f3db360fc68b4c2153c0_1440w.jpg" alt="img"></p>
<h3 id="1-2-Boosting"><a href="#1-2-Boosting" class="headerlink" title="1.2 Boosting"></a>1.2 Boosting</h3><p><strong>Boosting 训练过程为阶梯状，基模型的训练是有顺序的，每个基模型都会在前一个基模型学习的基础上进行学习，最终综合所有基模型的预测值产生最终的预测结果</strong>，用的比较多的综合方式为加权法。</p>
<p><img src="https://pic3.zhimg.com/80/v2-3aab53d50ab65e11ad3c9e3decf895c2_1440w.jpg" alt="img"></p>
<h3 id="1-3-Stacking"><a href="#1-3-Stacking" class="headerlink" title="1.3 Stacking"></a>1.3 Stacking</h3><p><strong>Stacking 是先用全部数据训练好基模型，然后每个基模型都对每个训练样本进行的预测，==其预测值将作为训练样本的特征值==，最终会得到新的训练样本，然后基于新的训练样本进行训练得到模型，然后得到最终预测结果。</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-f6787a16c23950d129a7927269d5352a_1440w.jpg" alt="img"></p>
<p>==那么，为什么集成学习会好于单个学习器呢？原因可能有三：==</p>
<ul>
<li><p>训练样本可能无法选择出最好的单个学习器，由于没法选择出最好的学习器，所以干脆结合起来一起用；</p>
</li>
<li><p>假设能找到最好的学习器，但由于算法运算的限制无法找到最优解，只能找到次优解，采用集成学习可以弥补算法的不足；</p>
</li>
<li><p>可能算法无法得到最优解，而集成学习能够得到近似解。比如说最优解是一条对角线，而单个决策树得到的结果只能是平行于坐标轴的，但是集成学习可以去拟合这条对角线。</p>
</li>
</ul>
<h3 id="1-4-Stacking-vs-神经网络"><a href="#1-4-Stacking-vs-神经网络" class="headerlink" title="==1.4 Stacking vs 神经网络=="></a>==<strong>1.4 Stacking</strong> vs <strong>神经网络</strong>==</h3><blockquote>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/32896968">https://zhuanlan.zhihu.com/p/32896968</a></p>
<p><strong>本文的核心观点是提供一种对于stacking的理解，即与神经网络对照来看。</strong>当然，在<a href="https://www.zhihu.com/question/59769987/answer/269367049">阿萨姆：为什么做stacking之后，准确率反而降低了？</a>中我已经说过stacking不是万能药，但往往很有效。通过与神经网络的对比，读者可以从另一个角度加深对stacking的理解。</p>
</li>
</ul>
</blockquote>
<h4 id="1-4-1-Stacking是一种表示学习-representation-learning"><a href="#1-4-1-Stacking是一种表示学习-representation-learning" class="headerlink" title="1.4.1 Stacking是一种表示学习(representation learning)"></a>1.4.1 Stacking是一种表示学习(representation learning)</h4><p><strong>表示学习指的是模型从原始数据中自动抽取有效特征的过程</strong>，比如深度学习就是一种表示学习的方法。关于表示学习的理解可以参考：<a href="https://www.zhihu.com/question/264417928/answer/283087276">阿萨姆：人工智能（AI）是如何处理数据的？</a></p>
<p>原始数据可能是杂乱无规律的。在stacking中，通过第一层的多个学习器后，有效的特征被学习出来了。从这个角度来看，stacking的第一层就是特征抽取的过程。在[1]的研究中，上排是未经stacking的数据，下排是经过stacking(多个无监督学习算法)处理后的数据，我们显著的发现红色和蓝色的数据在下排中分界更为明显。<strong>==数据经过了压缩处理。这个小例子说明了，有效的stacking可以对原始数据中的特征有效的抽取==</strong>。</p>
<p><img src="https://pic1.zhimg.com/80/v2-92ff83c7c6acc0dea6bc53ffe815e8bc_1440w.jpg" alt="img" style="zoom:80%;"></p>
<h4 id="1-4-2-Stacking和神经网络从某种角度看有异曲同工之妙，神经网络也可以被看作是集成学习"><a href="#1-4-2-Stacking和神经网络从某种角度看有异曲同工之妙，神经网络也可以被看作是集成学习" class="headerlink" title="1.4.2  Stacking和神经网络从某种角度看有异曲同工之妙，神经网络也可以被看作是集成学习"></a>1.4.2  <strong>Stacking和神经网络从某种角度看有异曲同工之妙，神经网络也可以被看作是集成学习</strong></h4><p>承接上一点，stacking的学习能力主要来自于对于特征的表示学习，这和神经网络的思路是一致的。这也是为什么我说“第一层”，“最后一层”。</p>
<p>而且神经网络也可以被看做是一种集成学习，主要取决于不同神经元、层对于不同特征的理解不同。从浅层到深层可以理解为一种从具体到抽象的过程。</p>
<p><strong>Stacking中的第一层可以等价于神经网络中的前 n-1层，而stacking中的最终分类层可以类比于神经网络中最后的输出层。</strong>不同点在于，<strong>stacking中不同的分类器通过异质来体现对于不同特征的表示</strong>，神经网络是从同质到异质的过程且有分布式表示的特点(distributed representation)。Stacking中应该也有分布式的特点，主要表现在多个分类器的结果并非完全不同，而有很大程度的相同之处。</p>
<p>但同时这也提出了一个挑战，多个分类器应该尽量在保证效果好的同时尽量不同，stacking集成学习框架的对于基分类器的两个要求：</p>
<ul>
<li>差异化(diversity)要大</li>
<li>准确性(accuracy)要高</li>
</ul>
<h4 id="1-4-3-Stacking-的输出层为什么用逻辑回归？"><a href="#1-4-3-Stacking-的输出层为什么用逻辑回归？" class="headerlink" title="1.4.3 Stacking 的输出层为什么用逻辑回归？"></a><strong>1.4.3 Stacking 的输出层为什么用逻辑回归？</strong></h4><blockquote>
<p>  <strong>表示学习的过拟合问题</strong>：</p>
<ul>
<li>仅包含学习到的特征</li>
<li>交叉验证</li>
<li>简单模型：<strong>逻辑回归</strong></li>
</ul>
</blockquote>
<p>如果你看懂了上面的两点，你应该可以理解stacking的有效性主要来自于特征抽取。<strong>而表示学习中，如影随形的问题就是过拟合，试回想深度学习中的过拟合问题。</strong></p>
<p>在[3]中，周志华教授也重申了stacking在使用中的过拟合问题。因为第二层的特征来自于对于第一层数据的学习，那么第二层数据中的特征中不该包括原始特征，<strong>以降低过拟合的风险</strong>。举例：</p>
<ul>
<li>第二层数据特征：仅包含学习到的特征</li>
<li>第二层数据特征：包含学习到的特征 + 原始特征</li>
</ul>
<p>另一个例子是，stacking中一般都用交叉验证来避免过拟合，足可见这个问题的严重性。</p>
<p>为了降低过拟合的问题，第二层分类器应该是较为简单的分类器，广义线性如逻辑回归是一个不错的选择。<strong>在特征提取的过程中，我们已经使用了复杂的非线性变换，因此在输出层不需要复杂的分类器</strong>。这一点可以对比神经网络的激活函数或者输出层，都是很简单的函数，一点原因就是不需要复杂函数并能控制复杂度。</p>
<h4 id="1-4-4-Stacking是否需要多层？第一层的分类器是否越多越好？"><a href="#1-4-4-Stacking是否需要多层？第一层的分类器是否越多越好？" class="headerlink" title="1.4.4 Stacking是否需要多层？第一层的分类器是否越多越好？"></a><strong>1.4.4 Stacking是否需要多层？第一层的分类器是否越多越好？</strong></h4><p>通过以上分析，stacking的表示学习不是来自于多层堆叠的效果，而是<strong>来自于不同学习器对于不同特征的学习能力</strong>，并有效的结合起来。一般来看，2层对于stacking足够了。多层的stacking会面临更加复杂的过拟合问题，且收益有限。</p>
<p>第一层分类器的数量对于特征学习应该有所帮助，<strong>经验角度看越多的基分类器越好。即使有所重复和高依赖性，我们依然可以通过特征选择来处理</strong>，问题不大。</p>
<h2 id="2-偏差与方差"><a href="#2-偏差与方差" class="headerlink" title="2. 偏差与方差"></a>2. 偏差与方差</h2><p>上节介绍了集成学习的基本概念，这节我们主要介绍下如何从偏差和方差的角度来理解集成学习。</p>
<h4 id="2-1-集成学习的偏差与方差"><a href="#2-1-集成学习的偏差与方差" class="headerlink" title="2.1 集成学习的偏差与方差"></a>2.1 集成学习的偏差与方差</h4><p><strong>==偏差（Bias）描述的是预测值和真实值之差==</strong>；<strong>==方差（Variance）描述的是预测值作为随机变量的离散程==度</strong>。放一场很经典的图：</p>
<p><img src="https://pic2.zhimg.com/80/v2-60c942f91d33d9dedf9dd2c7d482af5d_1440w.jpg" alt="img"></p>
<p><strong>模型</strong>的<strong>偏差</strong>与<strong>方差</strong></p>
<ul>
<li><strong>偏差：</strong>描述样本拟合出的模型的预测结果的期望与样本真实结果的差距，要想偏差表现的好，就需要复杂化模型，增加模型的参数，但这样容易过拟合，过拟合对应上图的 High Variance，点会很分散。低偏差对应的点都打在靶心附近，所以喵的很准，但不一定很稳；</li>
<li><strong>方差：</strong>描述样本上训练出来的模型在测试集上的表现，要想方差表现的好，需要简化模型，减少模型的复杂度，但这样容易欠拟合，欠拟合对应上图 High Bias，点偏离中心。低方差对应就是点都打的很集中，但不一定是靶心附近，手很稳，但不一定瞄的准。</li>
</ul>
<p>我们常说集成学习中的基模型是弱模型，通常来说弱模型是偏差高（在训练集上准确度低）方差小（防止过拟合能力强）的模型，<strong>但并不是所有集成学习框架中的基模型都是弱模型</strong>。<strong>Bagging 和 Stacking 中的基模型为强模型（偏差低，方差高），而Boosting 中的基模型为弱模型（偏差高，方差低）</strong>。</p>
<h4 id="2-2-Bagging-的偏差与方差"><a href="#2-2-Bagging-的偏差与方差" class="headerlink" title="2.2 Bagging 的偏差与方差"></a>2.2 Bagging 的偏差与方差</h4><ul>
<li><strong>整体模型的期望等于基模型的期望，这也就意味着整体模型的偏差和基模型的偏差近似。</strong></li>
<li><strong>整体模型的方差小于等于基模型的方差，当且仅当相关性为 1 时取等号，随着基模型数量增多，整体模型的方差减少，从而防止过拟合的能力增强，模型的准确度得到提高。</strong>但是，模型的准确度一定会无限逼近于 1 吗？并不一定，当基模型数增加到一定程度时，方差公式第一项的改变对整体方差的作用很小，防止过拟合的能力达到极限，这便是准确度的极限了。</li>
</ul>
<h4 id="2-3-Boosting-的偏差与方差"><a href="#2-3-Boosting-的偏差与方差" class="headerlink" title="2.3 Boosting 的偏差与方差"></a>2.3 Boosting 的偏差与方差</h4><ul>
<li>整体模型的方差等于基模型的方差，如果基模型不是弱模型，其方差相对较大，这将导致整体模型的方差很大，即无法达到防止过拟合的效果。因此，Boosting 框架中的基模型必须为弱模型。</li>
<li>此外 Boosting 框架中采用基于贪心策略的前向加法，整体模型的期望由基模型的期望累加而成，所以随着基模型数的增多，整体模型的期望值增加，整体模型的准确度提高。</li>
</ul>
<h4 id="2-4-小结"><a href="#2-4-小结" class="headerlink" title="2.4 小结"></a>2.4 小结</h4><ul>
<li>我们可以使用<strong>==模型的偏差和方差来近似描述模型的准确度==</strong>；</li>
<li>对于 Bagging 来说，整体模型的偏差与基模型近似，而随着模型的增加可以降低整体模型的方差，故其基模型需要为强模型；</li>
<li>对于 Boosting 来说，整体模型的方差近似等于基模型的方差，而整体模型的偏差由基模型累加而成，故基模型需要为弱模型。</li>
</ul>
<h2 id="3-Random-Forest（Bagging）"><a href="#3-Random-Forest（Bagging）" class="headerlink" title="3. Random Forest（Bagging）"></a>3. Random Forest（Bagging）</h2><blockquote>
<ol>
<li>随机森林具有<strong>防止过拟合能力</strong>，精度比大多数单个算法要好；<ol>
<li>随机森林分类器可以<strong>处理缺失值</strong>；</li>
</ol>
</li>
<li><strong>==于有袋外数据(OOB)==，可以在模型生成过程中取得真实误差的无偏估计，且不损失训练数据量在训练过程中，能够检测到feature间的互相影响，且可以得出feature的重要性，具有一定参考意义；</strong><ol>
<li>每棵树可以独立、同时生成，容易做成<strong>并行化方法</strong>；</li>
</ol>
</li>
<li>具有一定的特征选择能力。</li>
</ol>
</blockquote>
<p><strong>Random Forest（随机森林），用随机的方式建立一个森林。RF 算法由很多决策树组成，每一棵决策树之间没有关联。建立完森林后，当有新样本进入时，每棵决策树都会分别进行判断，然后基于投票法给出分类结果。</strong></p>
<p>对于分类问题，其输出的类别是由个别树输出的众数所决定的。在回归问题中，把每一棵决策树的输出进行平均得到最终的回归结果。</p>
<h3 id="3-1-思想"><a href="#3-1-思想" class="headerlink" title="3.1 思想"></a>3.1 思想</h3><p>Random Forest（随机森林）是 Bagging 的扩展变体，它在以决策树为基学习器构建 Bagging 集成的基础上，进一步在决策树的训练过程中引入了随机特征选择，因此可以概括 RF 包括四个部分：</p>
<ul>
<li><strong>样本随机：</strong>假设训练数据集共有 <img src="https://www.zhihu.com/equation?tex=M" alt="[公式]"> 个对象的数据，从样本数据中采取有放回（<strong>Boostrap</strong>）随机抽取 <img src="https://www.zhihu.com/equation?tex=N" alt="[公式]"> 个样本（因为是有放回抽取，有些数据可能被选中多次，有些数据可能不被选上)，每一次取出的样本不完全相同，这些样本组成了决策树的训练数据集；</li>
<li><strong>特征随机：</strong>假设每个样本数据都有 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 个特征，从所有特征中随机地选取 <img src="https://www.zhihu.com/equation?tex=k%28k%3C%3DK%29" alt="[公式]"> 个特征，选择最佳分割属性作为节点建立CART决策树，决策树成长期间 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 的大小始终不变（<strong>在Python中构造随机森林模型的时候，默认取特征的个数 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 是 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 的平方根，即 <img src="https://www.zhihu.com/equation?tex=%5Csqrt%7BK%7D" alt="[公式]"></strong> )；</li>
<li>重复前面的步骤，建立 <img src="https://www.zhihu.com/equation?tex=m" alt="[公式]"> 棵CART树，这些树都要完全的成长且不被修剪，这些树形成了森林；</li>
<li>根据这些树的预测结果进行投票，决定样本的最后预测类别。（针对回归模型，是根据这些决策树模型的平均值来获取最终的结果）</li>
</ul>
<p>随机选择样本和 Bagging 相同，采用的是 Bootstrap 自助采样法；<strong>==随机选择特征是指在每个节点在分裂过程中都是随机选择特征的==</strong>（区别与每棵树随机选择一批特征）。</p>
<blockquote>
<p>  这种随机性导致随机森林的==偏差会有稍微的增加==（相比于单棵不随机树），但是由于随机森林的“平均”特性，会使得它的==方差减小==，而且方差的减小补偿了偏差的增大，因此总体而言是更好的模型。</p>
</blockquote>
<p>随机采样由于引入了两种采样方法保证了随机性，所以每棵树都是最大可能的进行生长就算==不剪枝也不会出现过拟合==。</p>
<h3 id="3-2-处理缺失值的方法"><a href="#3-2-处理缺失值的方法" class="headerlink" title="3.2 处理缺失值的方法"></a>3.2 处理缺失值的方法</h3><ul>
<li>方法一（na.roughfix）简单粗暴，对于训练集,同一个class下的数据，如果是<strong>分类变量(categorical var)缺失，用众数补上</strong>，如果是<strong>连续型变量(numerical var)缺失，用中位数补</strong>。</li>
<li>方法二（rfImpute）这个方法计算量大，至于比方法一好坏？不好判断。先用na.roughfix补上缺失值，然后构建森林并计算proximity matrix，再回头看缺失值，如果是分类变量，则用没有缺失的观测实例的proximity中的权重进行投票。如果是连续型变量，则用<strong>proximity矩阵进行加权平均的方法补缺失值</strong>。然后迭代4-6次，这个补缺失值的思想和KNN有些类似。</li>
</ul>
<h3 id="3-3-优缺点"><a href="#3-3-优缺点" class="headerlink" title="3.3 优缺点"></a>3.3 优缺点</h3><h4 id="优点："><a href="#优点：" class="headerlink" title="优点："></a><strong>优点</strong>：</h4><ol>
<li><strong>模型准确率高</strong>：随机森林既可以处理分类问题，也可以处理回归问题，即使存在部分数据缺失的情况，随机森林也能保持很高的分类精度。</li>
<li><strong>能够处理数量庞大的高维度的特征</strong>，且不需要进行降维（因为特征子集是随机选择的）；</li>
<li><strong>易于并行化</strong>，在大数据集上有很大的优势；</li>
<li><p><strong>可解释性</strong>：可以生成树状结构，判断各个特征的重要性；</p>
<blockquote>
<p>  在sklearn中，随机森林<strong>基于每棵树分裂时的GINI指数下降量</strong>来判断各个特征的重要性。但是这种方法存在一个问题：当特征是连续的时候或者是类别很多的离散特征时，该方法会将这些特征的重要性增加。</p>
<p>  解决方法：对特征编码，使得特征的取值数量相近。</p>
</blockquote>
</li>
<li><strong>对异常值、缺失值不敏感；</strong></li>
<li><strong>随机森林有袋外数据（OOB），因此不需要单独划分交叉验证集</strong>。</li>
</ol>
<h4 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h4><ul>
<li>随机森林解决回归问题的效果不如分类问题；（因为它的预测不是天生连续的，在解决回归问题时，随机森林并不能为训练数据以外的对象给出答案）</li>
<li><strong>树之间的相关性越大，错误率就越大</strong>；</li>
<li><strong>当训练数据噪声较大时，容易产生过拟合现象。</strong></li>
</ul>
<h3 id="3-4-基学习期的选择？"><a href="#3-4-基学习期的选择？" class="headerlink" title="==3.4 基学习期的选择？=="></a>==3.4 基学习期的选择？==</h3><h4 id="为什么集成学习的基分类器通常是决策树？还有什么？"><a href="#为什么集成学习的基分类器通常是决策树？还有什么？" class="headerlink" title="为什么集成学习的基分类器通常是决策树？还有什么？"></a>为什么集成学习的基分类器通常是决策树？还有什么？</h4><p>基分类器通常是决策树：样本权重、方便调节、随机性；</p>
<ul>
<li><strong>==决策树可以较方便地将样本权重整合到训练过程中，而不需要通过过采样来调整样本权重。==</strong></li>
<li>树的表达能力和泛化能力，<strong>方便调节</strong>（可以通过树的层数来调节）</li>
<li>样本的扰动对决策树的影响较大，<strong><font color="red"> 因此不同子样本集合生成的决策树基分类器随机性较大。这样的不稳定的分类器更适合作为基分类器。</font></strong>此外树节点分类时随机选择一个特征子集，从中找出最优分裂属性，很好地引入了随机性。</li>
</ul>
<h4 id="可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？"><a href="#可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？" class="headerlink" title="可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？"></a>可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？</h4><p>Bagging主要好处是集成后的方差，比基分类器小。bagging采用的基分类，最好是本身对样本分布较为敏感。而线性分类器和K-NN都是较为稳定的分类器（参数模型？）甚至<strong>可能因为采样，而导致他们再训练中更难收敛，从而增大了集成分类器的偏差。</strong></p>
<h2 id="4-Adaboost-Boosting-样本权重更新"><a href="#4-Adaboost-Boosting-样本权重更新" class="headerlink" title="4 Adaboost (Boosting) 样本权重更新?"></a>4 Adaboost (Boosting) 样本权重更新?</h2><p>AdaBoost（Adaptive Boosting，自适应增强），其自适应在于：<strong>前一个基本分类器分错的样本会得到加强，加权后的全体样本再次被用来训练下一个基本分类器。同时，在每一轮中加入一个新的弱分类器，直到达到某个预定的==足够小的错误率或达到预先指定的最大迭代次数==。</strong></p>
<h3 id="4-1-思想"><a href="#4-1-思想" class="headerlink" title="4.1 思想"></a>4.1 思想</h3><p><strong>==Adaboost 迭代算法有三步：==</strong></p>
<ul>
<li>初始化训练样本的权值分布，每个样本具有相同权重；</li>
<li>训练弱分类器，如果样本分类正确，则在构造下一个训练集中，它的权值就会被降低；反之提高。用更新过的样本集去训练下一个分类器；</li>
<li>将所有弱分类组合成强分类器，各个弱分类器的训练过程结束后，<strong>加大分类误差率小的弱分类器的权重，降低分类误差率大的弱分类器的权重</strong>。</li>
</ul>
<h3 id="4-2-细节"><a href="#4-2-细节" class="headerlink" title="4.2 细节"></a>4.2 细节</h3><h5 id="4-2-1-损失函数"><a href="#4-2-1-损失函数" class="headerlink" title="==4.2.1 损失函数 ???=="></a>==<strong>4.2.1 损失函数 ???</strong>==</h5><p>Adaboost 模型是<strong>加法模型</strong>，学习算法为<strong>前向分步学习算法</strong>，损失函数为<strong>指数函数的分类问题</strong>。</p>
<p><strong>加法模型</strong>：最终的强分类器是由若干个弱分类器<strong>加权平均</strong>得到的。</p>
<p><strong>前向分布学习算法</strong>：算法是通过一轮轮的弱学习器学习，<strong>利用前一个弱学习器的结果来更新后一个弱学习器的训练集权重</strong>。第 k 轮的强学习器为：</p>
<script type="math/tex; mode=display">
F_{k}(x)=\sum_{i=1}^{k} \alpha_{i} f_{i}(x)=F_{k-1}(x)+\alpha_{k} f_{k}(x)</script><p><strong>定义损失函数为 n 个样本的指数损失函数</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=L%28y%2CF%29+%3D+%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bn%7Dexp%28-y_iF_%7Bk%7D%28x_i%29%29++%5C%5C" alt="[公式]"></p>
<p>利用前向分布学习算法的关系可以得到：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D++L%28y%2C+F%29+%26%3D+%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bm%7Dexp%5B%28-y_i%29+%28F_%7Bk-1%7D%28x_i%29+%2B+%5Calpha_k+f_k%28x_i%29%29%5D++%5C%5C+%26%3D++%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bm%7Dexp%5B-y_i+F_%7Bk-1%7D%28x_i%29+-y_i++%5Calpha_k+f_k%28x_i%29%5D+%5C%5C+%26%3D++%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bm%7Dexp%5B-y_i+F_%7Bk-1%7D%28x_i%29+%5D+exp%5B-y_i++%5Calpha_k+f_k%28x_i%29%5D+++%5Cend%7Balign%7D++%5C%5C" alt="[公式]"></p>
<p><strong>因为 <img src="https://www.zhihu.com/equation?tex=F_%7Bk-1%7D%28x%29" alt="[公式]"> 已知==，所以令 <img src="https://www.zhihu.com/equation?tex=w_%7Bk%2Ci%7D+%3D+exp%28-y_iF_%7Bk-1%7D%28x_i%29%29" alt="[公式]"> ，==随着每一轮迭代而将这个式子带入损失函数，损失函数转化为：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=L%28y%2C+F%28x%29%29+%3D%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bm%7Dw_%7Bk%2Ci%7Dexp%5B-y_i%5Calpha_k+f_k%28x_i%29%5D+%5C%5C" alt="[公式]"></p>
<p>我们求 <img src="https://www.zhihu.com/equation?tex=f_k%28x%29" alt="[公式]"> ，可以得到：</p>
<p><img src="https://www.zhihu.com/equation?tex=f_k%28x%29+%3Dargmin%5C%3B+%5Csum_%5Climits%7Bi%3D1%7D%5E%7Bm%7Dw_%7Bk%2Ci%7DI%28y_i+%5Cneq+f_k%28x_i%29%29+%5C%5C" alt="[公式]"></p>
<p>将 <img src="https://www.zhihu.com/equation?tex=f_k%28x%29" alt="[公式]"> 带入损失函数，并对 <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> 求导，使其等于 0，则就得到了：</p>
<p><img src="https://www.zhihu.com/equation?tex=+%5Calpha_k+%3D+%5Cfrac%7B1%7D%7B2%7Dlog%5Cfrac%7B1-e_k%7D%7Be_k%7D++%5C%5C" alt="[公式]"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=e_k" alt="[公式]"> 即为我们前面的<strong>分类误差率</strong>。</p>
<p><img src="https://www.zhihu.com/equation?tex=+e_k+%3D+%5Cfrac%7B%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dw_%7Bki%7D%5E%7B%E2%80%99%7DI%28y_i+%5Cneq+f_k%28x_i%29%29%7D%7B%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dw_%7Bki%7D%5E%7B%E2%80%99%7D%7D+%3D+%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dw_%7Bki%7DI%28y_i+%5Cneq+f_k%28x_i%29%29+%5C%5C" alt="[公式]"></p>
<p><strong>最后看样本权重的更新</strong>。利用 <img src="https://www.zhihu.com/equation?tex=F_%7Bk%7D%28x%29+%3D+F_%7Bk-1%7D%28x%29+%2B+%5Calpha_kf_k%28x%29" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=w_%7Bk%2B1%2Ci%7D%3Dw_%7Bk%2Ci%7Dexp%5B-y_i%5Calpha_kf_k%28x%2Ci%29%5D" alt="[公式]"> ，即可得：</p>
<p><img src="https://www.zhihu.com/equation?tex=w_%7Bk%2B1%2Ci%7D+%3D+w_%7Bki%7Dexp%5B-y_i%5Calpha_kf_k%28x_i%29%5D+%5C%5C" alt="[公式]"></p>
<p>这样就得到了样本权重更新公式。</p>
<h4 id="4-2-2-正则化"><a href="#4-2-2-正则化" class="headerlink" title="4.2.2 正则化"></a><strong>4.2.2 正则化</strong></h4><p><strong>为了防止 Adaboost 过拟合，我们通常也会加入正则化项，这个正则化项我们通常称为步长</strong>（learning rate）。对于前面的弱学习器的迭代,加上正则化项 <img src="https://www.zhihu.com/equation?tex=%5Cmu+" alt="[公式]"> 我们有：</p>
<script type="math/tex; mode=display">
F_{k}(x)=F_{k-1}(x)+\mu \alpha_{k} f_{k}(x)</script><p><img src="https://www.zhihu.com/equation?tex=%5Cmu" alt="[公式]"> 的取值范围为 <img src="https://www.zhihu.com/equation?tex=0%3C%5Cmu%5Cleq1" alt="[公式]"> 。对于同样的训练集学习效果，较小的 <img src="https://www.zhihu.com/equation?tex=%5Cmu" alt="[公式]"> 意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。</p>
<h3 id="4-3-优缺点"><a href="#4-3-优缺点" class="headerlink" title="4.3 优缺点"></a>4.3 优缺点</h3><p><strong>4.3.1 优点</strong></p>
<ol>
<li>分类精度高；</li>
<li>可以<strong>用各种回归分类模型来构建弱学习器，非常灵活</strong>；</li>
<li>不容易发生过拟合。</li>
</ol>
<p><strong>4.3.2 缺点</strong></p>
<ol>
<li>对异常点敏感，异常点会获得较高权重。</li>
</ol>
<h2 id="5-GBDT"><a href="#5-GBDT" class="headerlink" title="5. GBDT"></a>5. GBDT</h2><blockquote>
<p>  <a href="https://www.cnblogs.com/modifyrong/p/7744987.html">https://www.cnblogs.com/modifyrong/p/7744987.html</a></p>
</blockquote>
<p><strong>GBDT（Gradient Boosting Decision Tree）是一种迭代的决策树算法，该算法由多棵决策树组成，从名字中我们可以看出来它是属于 Boosting 策略。GBDT 是被公认的泛化能力较强的算法。</strong></p>
<h3 id="5-1-思想"><a href="#5-1-思想" class="headerlink" title="5.1 思想"></a>5.1 思想</h3><p><strong>GBDT是boosting算法的一种，按照boosting的思想，在GBDT算法的每一步，用一棵决策树去拟合当前学习器的残差，获得一个新的弱学习器。将这每一步的决策树组合起来，就得到了一个强学习器</strong>。GBDT 由三个概念组成：Regression Decision Tree（即 DT）、Gradient Boosting（即 GB），和 Shrinkage（一个重要演变）</p>
<h4 id="5-1-1-回归树（Regression-Decision-Tree）"><a href="#5-1-1-回归树（Regression-Decision-Tree）" class="headerlink" title="5.1.1 回归树（Regression Decision Tree）"></a><strong>5.1.1 回归树（Regression Decision Tree）</strong></h4><p>如果认为 GBDT 由很多分类树那就大错特错了（虽然调整后也可以分类）。对于分类树而言，其值加减无意义（如性别），而对于回归树而言，其值加减才是有意义的（如说年龄）。GBDT 的核心在于累加所有树的结果作为最终结果，所以 GBDT 中的树都是<strong>回归树</strong>，不是分类树，这一点相当重要。</p>
<p><strong><font color="red"> 回归树在分枝时会穷举每一个特征的每个阈值以找到最好的分割点，衡量标准是最小化均方误差。</font></strong></p>
<h4 id="5-1-2-梯度迭代（Gradient-Boosting）"><a href="#5-1-2-梯度迭代（Gradient-Boosting）" class="headerlink" title="5.1.2 梯度迭代（Gradient Boosting）"></a><strong>5.1.2 梯度迭代（Gradient Boosting）</strong></h4><p>上面说到 GBDT 的核心在于累加所有树的结果作为最终结果，GBDT 的每一棵树都是以之前树得到的<strong>残差【负梯度】</strong>来更新目标值，这样每一棵树的<strong>值加起来</strong>即为 GBDT 的预测值。</p>
<p>模型的预测值可以表示为：</p>
<script type="math/tex; mode=display">
F_{k}(x)=\sum_{i=1}^{k} f_{i}(x)</script><p><img src="https://www.zhihu.com/equation?tex=f_%7Bi%7D%28x%29+" alt="[公式]"> 为<strong>基模型与其权重的乘积</strong>，模型的训练目标是使预测值 <img src="https://www.zhihu.com/equation?tex=F_k%28x%29" alt="[公式]"> 逼近真实值 y，也就是说要让每个基模型的预测值逼近各自要预测的部分真实值。<strong>==贪心==</strong>的解决手段：每次只训练一个基模型。那么，现在改写整体模型为迭代式：</p>
<script type="math/tex; mode=display">
F_{k}(x)=F_{k-1}(x)+f_{k}(x)</script><p>其实很简单，其<strong>==残差其实是最小均方损失函数关于预测值的反向梯度(划重点)==</strong>：<strong>用负梯度的解作为样本新的真实值</strong>。基于残差 GBDT 容易对异常值敏感。</p>
<script type="math/tex; mode=display">
-\frac{\partial\left(\frac{1}{2}\left(y-F_{k}(x)\right)^{2}\right)}{\partial F_{k}(x)}=y-F_{k}(x)</script><p>很明显后续的模型会对第 4 个值关注过多，这不是一种好的现象，所以一般回归类的损失函数会用<strong>绝对损失或者 Huber 损失函数</strong>来代替平方损失函数。</p>
<script type="math/tex; mode=display">
L(y, F)=|y-F|</script><script type="math/tex; mode=display">
L(y, F)= \begin{cases}\frac{1}{2}(y-F)^{2} & |y-F| \leq \delta \\ \delta(|y-F|-\delta / 2) & |y-F|>\delta\end{cases}</script><p>GBDT 的 Boosting 不同于 Adaboost 的 Boosting，<strong>==GBDT 的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于 0==</strong>，这样后面的树就能专注于那些被分错的样本。</p>
<blockquote>
<p>  <strong><font color="red"> 最后补充一点拟合残差的问题，无论损失函数是什么形式，每个决策树拟合的都是负梯度。只有当损失函数是均方损失时，负梯度刚好是残差</font></strong>，也就是说<strong>拟合残差只是针对均方损失的特例</strong>，并不能说GBDT的迭代的过程是拟合残差。</p>
</blockquote>
<h4 id="5-1-3-缩减（Shrinkage）添加权重、基数增大"><a href="#5-1-3-缩减（Shrinkage）添加权重、基数增大" class="headerlink" title="5.1.3 缩减（Shrinkage）添加权重、基数增大"></a><strong>5.1.3 缩减（Shrinkage）</strong>添加权重、基数增大</h4><blockquote>
<p>  <strong><font color="red"> gbdt中的步长和参数中的学习率作用是什么？详细讲一讲？</font></strong></p>
<ul>
<li>参数中的学习率用于梯度下降</li>
</ul>
</blockquote>
<p>Shrinkage 的思想认为，每走一小步逐渐逼近结果的效果要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它并不是完全信任每一棵残差树。</p>
<p>Shrinkage 不直接用残差修复误差，而是只修复一点点，把大步切成小步。<strong>本质上 Shrinkage 为每棵树设置了一个 weight，累加时要乘以这个 weight，当 weight 降低时，基模型数会配合增大</strong>。</p>
<h3 id="5-2-优缺点"><a href="#5-2-优缺点" class="headerlink" title="5.2 优缺点"></a>5.2 优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a><strong>优点</strong></h4><ol>
<li>可以自动进行特征组合，拟合非线性数据；在稠密数据集上泛化能力和表达能力很好。</li>
<li>可以灵活处理各种类型的数据，不需要对数据预处理和归一化。</li>
<li>预测可以并行，计算数据很快。</li>
</ol>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a><strong>缺点</strong></h4><ol>
<li>对异常点敏感。</li>
</ol>
<h3 id="5-3-GBDT-与-Adaboost-的对比"><a href="#5-3-GBDT-与-Adaboost-的对比" class="headerlink" title="5.3 GBDT 与 Adaboost 的对比"></a>5.3 GBDT 与 Adaboost 的对比</h3><h4 id="相同："><a href="#相同：" class="headerlink" title="相同："></a><strong>相同：</strong></h4><ol>
<li>都是 Boosting 家族成员，使用弱分类器；</li>
<li>都使用前向分布算法；</li>
</ol>
<h4 id="不同："><a href="#不同：" class="headerlink" title="不同："></a><strong>不同：</strong></h4><ol>
<li><strong>迭代思路不同</strong>：Adaboost 是通过提升错分数据点的权重来弥补模型的不足（利用错分样本），而 GBDT 是通过算梯度来弥补模型的不足（利用残差）；</li>
<li><strong>损失函数不同</strong>：AdaBoost 采用的是<strong>指数损失</strong>，GBDT 使用的是<strong>绝对损失</strong>或者 <strong>Huber 损失函数</strong>；</li>
</ol>
<h3 id="5-4-GBDT算法用于分类问题、二分类1维、多分类k维（one-vs-all）"><a href="#5-4-GBDT算法用于分类问题、二分类1维、多分类k维（one-vs-all）" class="headerlink" title=" 5.4 GBDT算法用于分类问题、二分类1维、多分类k维（one vs all）"></a><strong><font color="red"> 5.4 GBDT算法用于分类问题、二分类1维、多分类k维（one vs all）</font></strong></h3><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/46445201">https://zhuanlan.zhihu.com/p/46445201</a></p>
</blockquote>
<p>将GBDT应用于回归问题，相对来说比较容易理解。因为<strong>回归问题的损失函数一般为平方差损失函数</strong>，这时的残差，恰好等于预测值与实际值之间的差值。每次拿一棵决策树去拟合这个差值，使得残差越来越小，这个过程还是比较intuitive的。</p>
<p><strong><font color="red"> 将GBDT用于分类问题，类似于逻辑回归、FM模型用于分类问题，其实是在用一个线性模型或者包含交叉项的非线性模型，去拟合所谓的对数几率 <img src="https://www.zhihu.com/equation?tex=%5Cln+%5Cfrac%7Bp%7D%7B1-p%7D" alt="[公式]"> 。</font></strong>而GBDT也是一样，只是用一系列的梯度提升树去拟合这个对数几率，实际上最终得到的是一系列CART回归树。其分类模型可以表达为：</p>
<p><img src="https://www.zhihu.com/equation?tex=P%28y%3D1%7Cx%29+%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-+%5Csum_%7Bm%3D0%7D%5EM+h_m%28x%29%7D%7D%5C%5C" alt="[公式]"></p>
<p>其中<img src="https://www.zhihu.com/equation?tex=h_m%28x%29" alt="[公式]"> 就是学习到的决策树。清楚了这一点之后，我们便可以参考逻辑回归，单样本 <img src="https://www.zhihu.com/equation?tex=%28x_i%2C+y_i%29" alt="[公式]"> 的损失函数可以表达为<strong>交叉熵</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=loss%28x_i%2C+y_i%29+%3D+-y_i+%5Clog+%5Chat%7By_i%7D+-+%281-y_i%29+%5Clog%281-%5Chat%7By_i%7D%29%5C%5C" alt="[公式]"></p>
<p>假设第k步迭代之后当前学习器为 <img src="https://www.zhihu.com/equation?tex=F%28x%29+%3D+%5Csum_%7Bm%3D0%7D%5Ek+h_m%28x%29" alt="[公式]"> ，将 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D" alt="[公式]"> 的表达式带入之后， 可将损失函数写为：</p>
<p><img src="https://www.zhihu.com/equation?tex=loss%28x_i%2C+y_i%7CF%28x%29%29+%3D+y_i+%5Clog+%5Cleft%28+1%2Be%5E%7B-F%28x_i%29%7D+%5Cright%29+%2B+%281-y_i%29+%5Cleft%5B+F%28x_i%29+%2B+%5Clog+%5Cleft%28+1%2Be%5E%7B-F%28x_i%29%7D+%5Cright%29+%5Cright%5D%5C%5C" alt="[公式]"></p>
<p><strong>可以求得损失函数相对于当前学习器的负梯度为：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=-%5Cfrac%7B%5Cpartial+loss%7D%7B%5Cpartial+F%28x%29%7D%7C_%7Bx_i%2Cy_i%7D+%3D+y_i+-+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-F%28x_i%29%7D%7D%3D+y_i+-+%5Chat%7By_i%7D%5C%5C" alt="[公式]"></p>
<p>可以看到，同回归问题很类似，下一棵决策树的训练样本为： <img src="https://www.zhihu.com/equation?tex=%5C%7B+x_i%2C+y_i+-+%5Chat%7By_i%7D+%5C%7D_%7Bi%3D1%7D%5En" alt="[公式]"> ，其所需要拟合的残差为真实标签与预测概率之差。于是便有下面GBDT应用于二分类的算法：</p>
<ul>
<li><p><img src="https://www.zhihu.com/equation?tex=F_0%28x%29+%3D+h_0%28x%29+%3D+%5Clog+%5Cfrac%7Bp_1%7D%7B1-p_1%7D" alt="[公式]"> ，其中 <img src="https://www.zhihu.com/equation?tex=p_1" alt="[公式]"> 是训练样本中y=1的比例，利用先验信息来初始化学习器</p>
</li>
<li><p>For <img src="https://www.zhihu.com/equation?tex=m+%3D+1%2C2%2C...%2CM" alt="[公式]"> ：</p>
<ul>
<li>计算 <img src="https://www.zhihu.com/equation?tex=g_i+%3D+%5Chat%7By_i%7D+-+y_i" alt="[公式]"> ，并使用训练集 <img src="https://www.zhihu.com/equation?tex=%5C%7B%28x_i%2C+-g_i%29%5C%7D_%7Bi%3D1%7D%5En" alt="[公式]"> <strong>训练一棵回归树</strong> <img src="https://www.zhihu.com/equation?tex=t_m%28x%29" alt="[公式]"> ，其中 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D+%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-F_%7Bm-1%7D%28x%29%7D%7D" alt="[公式]"></li>
<li>通过一维最小化损失函数找到树的最优权重： <img src="https://www.zhihu.com/equation?tex=%5Crho_m+%3D+%5Cmathop%7B%5Cmathrm%7Bargmin%7D%7D%5Climits_%7B%5Crho%7D+%5Csum_i+loss%28x_i%2C+y_i%7CF_%7Bm-1%7D%28x%29%2B%5Crho+t_m%28x%29%29" alt="[公式]"></li>
<li><strong>考虑shrinkage</strong>，可得这一轮迭代之后的学习器 <img src="https://www.zhihu.com/equation?tex=F_m%28x%29+%3D+F_%7Bm-1%7D%28x%29+%2B+%5Calpha+%5Crho_m+t_m%28x%29" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> 为学习率</li>
</ul>
</li>
<li><p>得到最终学习器为： <img src="https://www.zhihu.com/equation?tex=F_M%28x%29" alt="[公式]"></p>
</li>
</ul>
<p>以上就是将GBDT应用于二分类问题的算法流程。类似地，对于多分类问题，则需要考虑以下softmax模型：</p>
<p><img src="https://www.zhihu.com/equation?tex=P%28y%3D1%7Cx%29+%3D+%5Cfrac%7Be%5E%7BF_1%28x%29%7D%7D%7B%5Csum_%7Bi%3D1%7D%5Ek+e%5E%7BF_i%28x%29%7D%7D%5C%5C" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=P%28y%3D2%7Cx%29+%3D+%5Cfrac%7Be%5E%7BF_2%28x%29%7D%7D%7B%5Csum_%7Bi%3D1%7D%5Ek+e%5E%7BF_i%28x%29%7D%7D%5C%5C" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=...+...%5C%5C" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=P%28y%3Dk%7Cx%29+%3D+%5Cfrac%7Be%5E%7BF_k%28x%29%7D%7D%7B%5Csum_%7Bi%3D1%7D%5Ek+e%5E%7BF_i%28x%29%7D%7D%5C%5C" alt="[公式]"></p>
<p><strong>其中 <img src="https://www.zhihu.com/equation?tex=F_1" alt="[公式]"> <img src="https://www.zhihu.com/equation?tex=F_k" alt="[公式]"> 是 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 个不同的tree ensemble。每一轮的训练实际上是训练了 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 棵树去拟合softmax的每一个分支模型的负梯度</strong>【one-hot中的一维】。softmax模型的单样本损失函数为：</p>
<p><img src="https://www.zhihu.com/equation?tex=loss+%3D+-%5Csum_%7Bi%3D1%7D%5Ek+y_i+%5Clog+P%28y_i%7Cx%29+%3D+-%5Csum_%7Bi%3D1%7D%5Ek+y_i+%5Clog+%5Cfrac%7Be%5E%7BF_i%28x%29%7D%7D%7B%5Csum_%7Bj%3D1%7D%5Ek+e%5E%7BF_j%28x%29%7D%7D%5C%5C" alt="[公式]"></p>
<p><strong>这里的 <img src="https://www.zhihu.com/equation?tex=y_i%5C+%28i%3D1...k%29" alt="[公式]"> 是样本label在k个类别上作one-hot编码之后的取值，只有一维为1，其余都是0。由以上表达式不难推导：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=-%5Cfrac%7B%5Cpartial+loss%7D%7B%5Cpartial+F_q%7D+%3D+y_q+-+%5Cfrac%7Be%5E%7BF_q%28x%29%7D%7D%7B%5Csum_%7Bj%3D1%7D%5Ek+e%5E%7BF_j%28x%29%7D%7D+%3D+y_q+-+%5Chat%7By_q%7D%5C%5C" alt="[公式]"></p>
<p>可见，这k棵树同样是拟合了样本的真实标签与预测概率之差，与二分类的过程非常类似。</p>
<h2 id="6-集成学习Q-amp-A"><a href="#6-集成学习Q-amp-A" class="headerlink" title="6 集成学习Q&amp;A"></a>6 集成学习Q&amp;A</h2><h4 id="6-1-为什么gbdt和随机森林-稍好点-都不太适用直接用高维稀疏特征训练集？"><a href="#6-1-为什么gbdt和随机森林-稍好点-都不太适用直接用高维稀疏特征训练集？" class="headerlink" title=" 6.1 为什么gbdt和随机森林(稍好点)都不太适用直接用高维稀疏特征训练集？"></a><strong><font color="red"> 6.1 为什么gbdt和随机森林(稍好点)都不太适用直接用高维稀疏特征训练集？</font></strong></h4><h5 id="原因："><a href="#原因：" class="headerlink" title="原因："></a>原因：</h5><p>gbdt这类boosting或者rf这些bagging集成分类器模型的算法，是典型的贪心算法，在当前节点总是选择对当前数据集来说最好的选择</p>
<p>一个6层100树的模型，要迭代2^(5 4 3 2 1 0)<em>100次<em>*,每次都根据当前节点最大熵或者最小误差分割来选择变量</em></em></p>
<p><strong>那么，高维稀疏数据集里很多“小而美”的数据就被丢弃了</strong>，因为它对当前节点来说不是最佳分割方案(比如，关联分析里，支持度很低置信度很高的特征)</p>
<p>但是高维数据集里面，对特定的样本数据是有很强预测能力的，比如你买叶酸，买某些小的孕妇用品品类，对应这些人6个月后买奶粉概率高达40%，但叶酸和孕妇用品销量太小了，用户量全网万分之一都不到，这种特征肯定是被树算法舍弃的，哪怕这些特征很多很多。。它仍是被冷落的份。。。</p>
<h5 id="方法：【LightGBM-互斥捆绑算法】"><a href="#方法：【LightGBM-互斥捆绑算法】" class="headerlink" title="方法：【LightGBM 互斥捆绑算法】"></a>方法：【LightGBM 互斥捆绑算法】</h5><h5 id="选择svm和lr这种能提供最佳分割平面的算法可能会更好；"><a href="#选择svm和lr这种能提供最佳分割平面的算法可能会更好；" class="headerlink" title="选择svm和lr这种能提供最佳分割平面的算法可能会更好；"></a>选择svm和lr这种能提供最佳分割平面的算法可能会更好；</h5><p>但如果top.特征已经能够贡献很大的信息量了，比如刚才孕妇的案例，你用了一个孕妇用品一级类目的浏览次数购买金额购买次数这样的更大更强的特征包含了这些高维特征的信息量，那可能gbdt会更好</p>
<p>实际情况的数据集是，在数据仓库里的清洗阶段，你可以选择把它做成高维的特征，也可以选择用算法把它做成低维的特征，一般有</p>
<p>1-在数据清洗阶段，或用类目升级(三级类目升级到二三级类目)范围升级的方式来做特征，避免直接清洗出来高维特征</p>
<p>2-在特征生成后，<strong>利用数据分析结论简单直接的用多个高维特征合并</strong>(<a href="https://www.zhihu.com/search?q=加减乘除&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A574865175}">加减乘除</a>逻辑判断都行，随你合并打分)的方式来做特征，前提你hold得住工作量判断量，但这个如果业务洞察力强效果有可能特别好</p>
<p>3-在特征工程的特征处理阶段，我们可以用<strong>PCA因子构建等降维算法做特征整合</strong>，对应训练集，也这么搞，到时候回归或预测的时候，就用这个因子或者主成分的值来做特征</p>
<h4 id="6-1-为什么集成学习的基分类器通常是决策树？还有什么？"><a href="#6-1-为什么集成学习的基分类器通常是决策树？还有什么？" class="headerlink" title="6.1 为什么集成学习的基分类器通常是决策树？还有什么？"></a>6.1 为什么集成学习的基分类器通常是决策树？还有什么？</h4><p>基分类器通常是决策树：样本权重、方便调节、随机性；</p>
<ul>
<li><strong>==决策树可以较方便地将样本权重整合到训练过程中，而不需要通过过采样来调整样本权重。==</strong></li>
<li>树的表达能力和泛化能力，<strong>方便调节</strong>（可以通过树的层数来调节）</li>
<li>样本的扰动对决策树的影响较大，<strong><font color="red"> 因此不同子样本集合生成的决策树基分类器随机性较大。这样的不稳定的分类器更适合作为基分类器。</font></strong>此外树节点分类时随机选择一个特征子集，从中找出最优分裂属性，很好地引入了随机性。</li>
</ul>
<h4 id="6-2-可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？"><a href="#6-2-可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？" class="headerlink" title="6.2 可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？"></a>6.2 可以将随机森林的基分类器，由决策树替换成线性分类器或K-NN吗？</h4><p>Bagging主要好处是集成后的方差，比基分类器小。bagging采用的基分类，最好是本身对样本分布较为敏感。而线性分类器和K-NN都是较为稳定的分类器（参数模型？）甚至可能因为采样，而导致他们再训练中更难收敛，从而增大了集成分类器的偏差。</p>
<h4 id="6-3-为什么可以利用GBDT算法实现特征组合和筛选？【GBDT-LR】"><a href="#6-3-为什么可以利用GBDT算法实现特征组合和筛选？【GBDT-LR】" class="headerlink" title=" 6.3 为什么可以利用GBDT算法实现特征组合和筛选？【GBDT+LR】"></a><strong><font color="red"> 6.3 为什么可以利用GBDT算法实现特征组合和筛选？【GBDT+LR】</font></strong></h4><p>GBDT模型是有一组有序的树模型组合起来的，前面的树是由对大多数样本有明显区分度的特征分裂构建而成，经过前面的树，仍然存在少数残差较大的样本，后面的树主要由能对这些少数样本有区分度的特征分裂构建。优先选择对整体有区分度的特征，然后再选择对少数样本有区分度的特征，这样才更加合理，所以<strong>GBDT子树节点分裂是一个特征选择的过程，而子树的多层结构则对特征组合的过程，最终实现特征的组合和筛选。</strong></p>
<p><strong>GBDT+LR融合方案：</strong></p>
<p>（1）利用GBDT模型训练数据，最终得到一系列弱分类器的cart树。</p>
<p>（2）<strong>生成新的训练数据。将原训练数据重新输入GBDT模型，对于每一个样本，都会经过模型的一系列树，对于每棵树，将样本落到的叶子节点置为1，其他叶子为0，然后将叶子节点的数字从左至右的拼接起来，形成该棵树的特征向量，最后将所有树的特征向量拼接起来，形成新的数据特征，之后保留原样本标签形成新的训练数据。</strong></p>
<p>（3）将上一步得到的训练数据作为输入数据输入到LR模型中进行训练</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8811%EF%BC%89LGB*/</url>
    <content><![CDATA[<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><p><strong>XGBoost官方文档</strong>：<a href="https://xgboost.readthedocs.io/en/latest/index.html">https://xgboost.readthedocs.io/en/latest/index.html</a></p>
</li>
<li><p>LightGBM算法梳理：<a href="https://zhuanlan.zhihu.com/p/78293497">https://zhuanlan.zhihu.com/p/78293497</a></p>
</li>
<li><p>详解LightGBM两大利器：基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）：<a href="https://zhuanlan.zhihu.com/p/366234433">https://zhuanlan.zhihu.com/p/366234433</a></p>
</li>
<li><p>【机器学习】决策树（下）——XGBoost、LightGBM（非常详细）：<a href="https://zhuanlan.zhihu.com/p/87885678">https://zhuanlan.zhihu.com/p/87885678</a></p>
</li>
<li><p>xgboost面试题整理: <a href="https://xiaomindog.github.io/2021/06/22/xgb-qa/">https://xiaomindog.github.io/2021/06/22/xgb-qa/</a></p>
</li>
</ul>
<h2 id="【机器学习】决策树（下）——XGBoost、LightGBM"><a href="#【机器学习】决策树（下）——XGBoost、LightGBM" class="headerlink" title="【机器学习】决策树（下）——XGBoost、LightGBM"></a>【机器学习】决策树（下）——XGBoost、LightGBM</h2><p><img src="https://pic2.zhimg.com/80/v2-358e4bfce928d0460bd5e8b4cab8f715_1440w.jpg" alt="img"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Boosting 算法</th>
<th>GBDT</th>
<th>XGBoost</th>
<th>LightGBM</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>思想</strong><img src="image-20220315210756470.png" alt="image-20220315210756470" style="zoom:25%;"></td>
<td>回归树、梯度迭代、缩减（Shrinkage）;<strong>GBDT 的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于 0</strong></td>
<td><strong>二阶导数、线性分类器、正则化</strong>、缩减、<strong>列抽样、并行化</strong></td>
<td><strong>更快的训练速度和更低的内存使用</strong></td>
</tr>
<tr>
<td>目标函数</td>
<td><img src="image-20220315213233284.png" alt="image-20220315213233284" style="zoom: 25%;"></td>
<td><img src="image-20220315213503054.png" alt="image-20220315213503054" style="zoom: 67%;"><img src="image-20220315213608526.png" alt="image-20220315213608526" style="zoom: 33%;"></td>
<td>同上</td>
</tr>
<tr>
<td>损失函数</td>
<td>最小均方损失函数、<strong>绝对损失或者 Huber 损失函数</strong></td>
<td>【线性】最小均方损失函数、==sigmod和softmax==</td>
<td><strong>复杂度模型</strong>：<img src="image-20220315215849417.png" alt="image-20220315215849417" style="zoom: 25%;"></td>
</tr>
<tr>
<td>基模型</td>
<td>CART模型</td>
<td>CART模型/ ==回归模型==</td>
<td>CART模型/ ==回归模型==</td>
</tr>
<tr>
<td>抽样算法</td>
<td>无</td>
<td><strong>列抽样</strong>：借鉴了<strong>随机森林</strong>的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</td>
<td><strong>单边梯度抽样算法；</strong>根据样本梯度来对梯度小的这边样本进行采样，一部分大梯度和随机分布</td>
</tr>
<tr>
<td><strong>切分点算法</strong></td>
<td>CART模型</td>
<td><strong>预排序</strong>、<strong>贪心算法</strong>、<strong>近似算法（</strong>加权分位数缩略图<strong>）</strong></td>
<td><strong>直方图算法</strong>：内存消耗降低，计算代价减少；（不需要记录特征到样本的索引）</td>
</tr>
<tr>
<td><strong>缺失值算法</strong></td>
<td>CART模型</td>
<td><strong>稀疏感知算法</strong>：选择增益最大的枚举项即为最优<strong>缺省方向</strong>。【<strong><font color="red"> 稀疏数据优化不足</font></strong>】【<strong>gblinear 补0</strong>】</td>
<td><strong>互斥特征捆绑算法</strong>：<strong>互斥</strong>指的是一些特征很少同时出现非0值。<strong>稀疏感知算法</strong>；【<strong>gblinear 补0</strong>】</td>
</tr>
<tr>
<td><strong>建树策略</strong></td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Leaf-wise</strong>：每次分裂增益最大的叶子节点，直到达到停止条件。</td>
</tr>
<tr>
<td><strong>正则化</strong></td>
<td>无</td>
<td>L1 和 L2 正则化项</td>
<td>L1 和 L2 正则化项</td>
</tr>
<tr>
<td><strong>Shrinkage（缩减）</strong></td>
<td>有</td>
<td>有</td>
<td>有</td>
</tr>
<tr>
<td>类别特征优化</td>
<td>无</td>
<td>无</td>
<td><strong>类别特征最优分割</strong>：<strong>many-vs-many</strong></td>
</tr>
<tr>
<td>并行化设计</td>
<td>无</td>
<td><strong>块结构设计</strong>、</td>
<td><strong>特征并行</strong>、 <strong>数据并行</strong>、<strong>投票并行</strong></td>
</tr>
<tr>
<td>==缓存优化==</td>
<td>无</td>
<td>为每个线程分配一个连续的缓存区、<strong>“核外”块计算</strong></td>
<td>1、所有的特征都采用相同的方法获得梯度；2、其次，因为不需要存储特征到样本的索引，降低了存储消耗</td>
</tr>
<tr>
<td><strong>缺点</strong></td>
<td>对异常点敏感；</td>
<td><strong>预排序</strong>：仍需要遍历数据集；==不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引，相当于消耗了两倍的内存。==</td>
<td><strong>内存更小</strong>： 索引值、特征值边bin、互斥特征捆绑; <strong>速度更快</strong>：遍历直方图；单边梯度算法过滤掉梯度小的样本；基于 Leaf-wise 算法的增长策略构建树，减少了很多不必要的计算量；特征并行、数据并行方法加速计算</td>
</tr>
</tbody>
</table>
</div>
<h2 id="一、LightGBM"><a href="#一、LightGBM" class="headerlink" title="一、LightGBM"></a>一、LightGBM</h2><blockquote>
<ul>
<li>《<a href="https://www.zhihu.com/search?q=Lightgbm%3A+A+highly+efficient+gradient+boosting+decision+tree&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;165627712&quot;}">Lightgbm: A highly efficient gradient boosting decision tree</a>》</li>
<li>《A communication-efficient <a href="https://www.zhihu.com/search?q=parallel+algorithm+for+decision+tree&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;165627712&quot;}">parallel algorithm for decision tree</a>》</li>
</ul>
</blockquote>
<p>LightGBM 由微软提出，主要用于解决 GDBT 在海量数据中遇到的问题，以便其可以更好更快地用于工业实践中。从 LightGBM 名字我们可以看出其是轻量级（Light）的梯度提升机（GBM），其相对 XGBoost 具有<strong>训练速度快、内存占用低</strong>的特点。下图分别显示了 XGBoost、XGBoost_hist（利用梯度直方图的 XGBoost） 和 LightGBM 三者之间针对不同数据集情况下的内存和训练时间的对比：</p>
<p><img src="https://pic1.zhimg.com/80/v2-e015e3c4018f44787d74a47c9e0cd040_1440w.jpg" alt="img"></p>
<p>那么 LightGBM 到底如何做到<strong>更快的训练速度和更低的内存</strong>使用的呢？</p>
<h4 id="LightGBM-为了解决这些问题提出了以下几点解决方案："><a href="#LightGBM-为了解决这些问题提出了以下几点解决方案：" class="headerlink" title=" LightGBM 为了解决这些问题提出了以下几点解决方案："></a><strong><font color="red"> LightGBM 为了解决这些问题提出了以下几点解决方案：</font></strong></h4><ol>
<li><p><strong>【减小内存、最优分类点】直方图算法</strong>；【特征离散化 + 内存占用 + 方差减少】</p>
</li>
<li><p><strong>【样本维度】 单边梯度抽样算法</strong>；【<strong>根据样本梯度来对梯度小的这边样本进行采样</strong>，一部分大梯度和随机分布】</p>
<blockquote>
<p>  <strong>一方面算法将更多的注意力放在训练不足的样本上，另一方面通过乘上权重来防止采样对原始数据分布造成太大的影响。</strong></p>
</blockquote>
</li>
<li><p><strong>【特征维度】互斥特征捆绑算法</strong>；【特征稀疏行优化 +分箱 】</p>
</li>
<li><p><strong>【分裂算法】基于最大深度的 Leaf-wise 的垂直生长算法</strong>；【深度限制的最大分裂收益的叶子】</p>
</li>
<li><p><strong>类别特征最优分割</strong>；</p>
</li>
<li><p><strong>特征并行和数据并行</strong>；</p>
</li>
<li><p><strong>缓存优化。</strong></p>
</li>
</ol>
<h3 id="1-1-数学原理"><a href="#1-1-数学原理" class="headerlink" title="1.1 数学原理"></a>1.1 数学原理</h3><h3 id="1-1-1-直方图算法"><a href="#1-1-1-直方图算法" class="headerlink" title="1.1.1 直方图算法"></a><strong>1.1.1 直方图算法</strong></h3><h4 id="1-直方图算法"><a href="#1-直方图算法" class="headerlink" title="(1) 直方图算法"></a><strong>(1) 直方图算法</strong></h4><p><strong><font color="red"> 直方图算法的基本思想是将连续的特征离散化为 k （默认256 1字节）个离散特征，同时构造一个宽度为 k 的直方图用于统计信息（含有 k 个 bin）。利用直方图算法我们无需遍历数据，只需要遍历 k 个 bin 即可找到最佳分裂点。</font></strong></p>
<p>我们知道特征离散化的具有很多优点，如存储方便、运算更快、鲁棒性强、模型更加稳定等等。对于直方图算法来说最直接的有以下两个优点（以 k=256 为例）：</p>
<ul>
<li><strong>内存占用更小：</strong>XGBoost 需要用 <strong>32 位的浮点数去存储特征值，并用 32 位的整形去存储排序索引</strong>，而 LightGBM 只需要用 8 位去存储直方图，<strong>相当于减少了 1/8</strong>；</li>
<li><strong>计算代价更小：</strong>计算特征分裂增益时，XGBoost 需要遍历一次数据找到最佳分裂点，而 LightGBM 只需要遍历一次 k 次，直接将时间复杂度从代价是O( feature <em> <strong>distinct_values_of_the_feature</strong>); 而 histogram 只需要计算 bins次, 代价是( feature </em> <strong>bins</strong>)。<strong>distinct_values_of_the_feature &gt;&gt; bins</strong></li>
</ul>
<p><img src="image-20220625171413733.png" alt="image-20220625171413733"></p>
<ol>
<li><strong>直方图优化算法需要在训练前预先把特征值转化为bin value</strong>，也就是对每个特征的取值做个分段函数，将所有样本在该特征上的取值划分到某一段（bin）中。最终把特征取值从连续值转化成了离散值。需要注意得是：feature value对应的bin value在整个训练过程中是不会改变的。</li>
<li><strong>最外面的 for 循环表示的意思是对当前模型下所有的叶子节点处理</strong>，需要遍历所有的特征，来找到增益最大的特征及其划分值，以此来分裂该叶子节点。</li>
<li>在某个叶子上，第二个 for 循环就开始遍历所有的特征了。<strong>对于每个特征，首先为其创建一个直方图 (new Histogram() )</strong>。这个直方图存储了两类信息，分别是<strong><font color="red"> 每个bin中样本的梯度之和 $H[ f.bins[i] ].g$ </font></strong>，还有就是<strong>每个bin中样本数量</strong>$（H[f.bins[i]].n）$</li>
<li>第三个 for 循环遍历所有样本，累积上述的两类统计值到样本所属的bin中。即直方图的每个 bin 中包含了一定的样本，在此计算每个 bin 中的样本的梯度之和并对 bin 中的样本记数。</li>
<li>最后一个for循环, 遍历所有bin, 分别以当前bin作为分割点, 累加其左边的bin至当前bin的梯度和（ $\left.S_{L}\right)$ 以及样本数量 $\left(n_{L}\right)$, 并与父节点上的总梯度和 $\left(S_{p}\right)$ 以及总样本数量 $\left(n_{p}\right)$ 相减, 得到右边 所有bin的梯度和 $\left(S_{R}\right)$ 以及样本数量 $\left(n_{R}\right)$, 带入公式, 计算出增益, 在遍历过程中取最大的增 益, 以此时的特征和bin的特征值作为分裂节点的特征和分裂特征取值。</li>
</ol>
<h4 id="2-源码分析"><a href="#2-源码分析" class="headerlink" title="(2) 源码分析"></a>(2) 源码分析</h4><blockquote>
<p>  <a href="https://blog.csdn.net/anshuai_aw1/article/details/83040541">https://blog.csdn.net/anshuai_aw1/article/details/83040541</a></p>
<p>  <strong><font color="red"> 『我爱机器学习』集成学习（四）LightGBM</font></strong>：<a href="https://www.hrwhisper.me/machine-learning-lightgbm/">https://www.hrwhisper.me/machine-learning-lightgbm/</a></p>
</blockquote>
<p>问题一：<strong>如何将特征映射到bin呢？即如何分桶？对于连续特征和类别特征分别怎么样处理？</strong></p>
<p>问题二：<strong>如何构建直方图？直方图算法累加的g是什么？难道没有二阶导数h吗？</strong></p>
<h4 id="特征分桶："><a href="#特征分桶：" class="headerlink" title="特征分桶："></a>特征分桶：</h4><blockquote>
<p>  <strong>特征分桶的源码</strong>在<strong>bin.cpp</strong>文件和<strong>bin.h</strong>文件中。由于LGBM可以处理类别特征，因此对连续特征和类别特征的处理方式是不一样的。</p>
</blockquote>
<h4 id="连续特征"><a href="#连续特征" class="headerlink" title="连续特征:"></a>连续特征:</h4><p>在<strong>bin.cpp</strong>中，我们可以看到<strong>GreedyFindBin</strong>函数和<strong>FindBinWithZeroAsOneBin</strong>函数，这两个函数得到了数值型特征取值（负数，0，正数）的各个bin的切分点，即bin_upper_bound。</p>
<h4 id="GreedyFindBin-数值型根据特征不同取值的个数划分，类别型？？"><a href="#GreedyFindBin-数值型根据特征不同取值的个数划分，类别型？？" class="headerlink" title="GreedyFindBin: 数值型根据特征不同取值的个数划分，类别型？？"></a>GreedyFindBin: 数值型根据特征不同取值的个数划分，类别型？？</h4><ul>
<li><em>特征取值计数的数组</em>、<em>特征的不同的取值的数组</em>、<em>特征有多少个不同的取值</em></li>
<li><strong>bin_upper_bound就是记录桶分界的数组</strong></li>
<li>特征取值数比max_bin数量少，直接取distinct_values的中点放置</li>
<li>特征取值数比max_bin来得大，说明几个特征值要共用一个bin<ul>
<li>如果一个特征值的数目比mean_bin_size大，那么这些特征需要单独一个bin</li>
<li>剩下的特征取值的样本数平均每个剩下的bin：mean size for one bin</li>
</ul>
</li>
</ul>
<h4 id="构建直方图："><a href="#构建直方图：" class="headerlink" title="构建直方图："></a>构建直方图：</h4><p>给定一个特征的值，我们现在已经可以转化为对应的bin了。现在我们就可以构建直方图了。</p>
<h4 id="ConstructHistogram："><a href="#ConstructHistogram：" class="headerlink" title="ConstructHistogram："></a><strong>ConstructHistogram</strong>：</h4><ul>
<li><strong>累加了一阶、二阶梯度和还有==个数==</strong></li>
<li>当然还有其它的版本，当is_constant_hessianis_constant_hessian为true的时候是不用二阶梯度的</li>
</ul>
<h4 id="寻找最优切分点-缺失值处理-Gain和XGB一样"><a href="#寻找最优切分点-缺失值处理-Gain和XGB一样" class="headerlink" title="寻找最优切分点 : 缺失值处理 + Gain和XGB一样"></a>寻找最优切分点 : 缺失值处理 + Gain和XGB一样</h4><h4 id="（3）直方图算法优点："><a href="#（3）直方图算法优点：" class="headerlink" title=" （3）直方图算法优点："></a><strong><font color="red"> （3）直方图算法优点：</font></strong></h4><ul>
<li><p><strong>内存消耗降低</strong>。预排序算法需要的内存约是训练数据的两倍（2x样本数x维度x4Bytes），它需要用32位浮点来保存特征值，并且对每一列特征，都需要一个额外的排好序的索引，这也需要32位的存储空间。对于 直方图算法，则只需要(1x样本数x维 度x1Bytes)的内存消耗，仅为预排序算法的1/8。因为直方图算法仅需要存储特征的 bin 值(离散化后的数值)，不需要原始的特征值，也不用排序，而bin值用8位整型存储就足够了。</p>
</li>
<li><p><strong>算法时间复杂度大大降低</strong>。决策树算法在节点分裂时有两个主要操作组成，一个是“寻找分割点”，另一个是“数据分割”。从算法时间复杂度来看，在“寻找分割点”时，预排序算法对于深度为$k$的树的时间复杂度：对特征所有取值的排序为$O(NlogN)$，$N$为样本点数目，若有$D$维特征，则$O(kDNlogN)$，而直方图算法需要$O(kD \times bin)$ (bin是histogram 的横轴的数量，一般远小于样本数量$N$)。</p>
</li>
<li><p><strong>直方图算法还可以进一步加速</strong>【<strong>==两个维度==</strong>】。一个容易观察到的现象：<strong>一个叶子节点的直方图可以直接由父节点的直方图和兄弟节点的直方图做差得到（分裂时左右集合）</strong>。通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的$k$个bin。利用这个方法，LightGBM可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。</p>
<p><img src="https://pic1.zhimg.com/80/v2-86919e4fc187a11fe3fdb72780709c98_1440w.jpg" alt="img" style="zoom:67%;"></p>
</li>
<li><p><strong>缓存优化</strong>：上边说到 XGBoost 的预排序后的特征是通过索引给出的样本梯度的统计值，因其索引访问的结果并不连续，XGBoost 提出缓存访问优化算法进行改进。<strong><font color="red"> LightGBM 所使用直方图算法对 Cache 天生友好所有的特征都采用相同的方法获得梯度，构建直方图时bins字典同步记录一阶导、二阶导和个数，大大提高了缓存命中</font></strong>；因为<strong>不需要存储特征到样本的索引</strong>，降低了存储消耗，而且也不存在 Cache Miss的问题。</p>
</li>
<li><p><strong>数据并行优化</strong>，用 histgoram 可以大幅降低通信代价。用 pre-sorted 算法的话，通信代价是非常大的（几乎是没办法用的）。所以 xgoobst 在并行的时候也使用 histogram 进行通信。</p>
</li>
</ul>
<h4 id="（4）直方图算法缺点："><a href="#（4）直方图算法缺点：" class="headerlink" title="（4）直方图算法缺点："></a>（4）直方图算法缺点：</h4><p><strong>当然，直方图算法并不是完美的。由于特征被离散化后，找到的并不是很精确的分割点，所以会对结果产生影响。</strong>但在不同的数据集上的结果表明，离散化的分割点对最终的精度影响并不是很大，甚至有时候会更好一点。原因是决策树本来就是弱模型，分割点是不是精确并不是太重要；<strong>较粗的分割点也有正则化的效果，可以有效地防止过拟合</strong>；即使单棵树的训练误差比精确分割的算法稍大，但在梯度提升（GradientBoosting）的框架下没有太大的影响。</p>
<h3 id="1-1-2-单边梯度抽样算法"><a href="#1-1-2-单边梯度抽样算法" class="headerlink" title="1.1.2 单边梯度抽样算法"></a><strong>1.1.2 单边梯度抽样算法</strong></h3><font color="red"> **直方图算法仍有优化的空间**，建立直方图的复杂度为O(**feature × data**)，如果能**降低特征数**或者**降低样本数**，训练的时间会大大减少。</font>

<p><strong>GBDT 算法的梯度大小可以反应样本的权重，梯度越小说明模型拟合的越好，单边梯度抽样算法</strong>（Gradient-based One-Side Sampling, GOSS）利用这一信息对样本进行抽样，减少了大量梯度小的样本，在接下来的计算锅中只需关注梯度高的样本，极大的减少了计算量。</p>
<ol>
<li>根据<strong>梯度的绝对值</strong>将样本进行<strong>降序</strong>排序</li>
<li>选择前a×100%的样本，这些样本称为A</li>
<li>剩下的数据(1−a)×100的数据中，随机抽取b×100%的数据，这些样本称为B</li>
<li>在计算增益的时候，放大样本B中的梯度 (1−a)/b 倍</li>
<li>关于g，在具体的实现中是一阶梯度和二阶梯度的乘积，见Github的实现（LightGBM/src/boosting/goss.hpp）</li>
</ol>
<blockquote>
<p>  a%（大梯度）+ (1-a)/ b * b % 的大梯度</p>
</blockquote>
<p><strong>使用GOSS进行采样, 使得训练算法更加的关注没有充分训练(under-trained)的样本, 并且只会稍微的改变原有的数据分布</strong>。原有的在特征值为 $\mathrm{d}$ 处分数据带来的增益可以定义为：</p>
<script type="math/tex; mode=display">
V_{j \mid O}(d)=\frac{1}{n_{O}}\left(\frac{\left(\sum_{x_{i} \in O: x_{i j} \leq d} g_{i}\right)^{2}}{n_{l \mid O}^{j}(d)}+\frac{\left(\sum_{x_{i} \in O: x_{i j}>d} g_{i}\right)^{2}}{n_{r \mid O}^{j}(d)}\right)</script><p>其中:</p>
<ul>
<li>O为在决策树待分裂节点的训练集</li>
<li>$n_{o}=\sum I\left(x_{i} \in O\right)$</li>
<li>$n_{l \mid O}^{j}(d)=\sum I\left[x_{i} \in O: x_{i j} \leq d\right]$ and $n_{r \mid O}^{j}(d)=\sum I\left[x_{i} \in O: x_{i j}&gt;d\right]$</li>
</ul>
<p><strong>而使用GOSS后, 增益定义为：</strong></p>
<script type="math/tex; mode=display">
V_{j \mid O}(d)=\frac{1}{n_{O}}\left(\frac{\left(\sum_{x_{i} \in A_{l}} g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{l}} g_{i}\right)^{2}}{n_{l}^{j}(d)}+\frac{\left(\sum_{x_{i} \in A_{r}} g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{l}} g_{r}\right)^{2}}{n_{r}^{j}(d)}\right)</script><p>其中:</p>
<ul>
<li>$A_{l}=\left\{x_{i} \in A: x_{i j} \leq d\right\}, A_{r}=\left\{x_{i} \in A: x_{i j}&gt;d\right\}$</li>
<li>$B_{l}=\left\{x_{i} \in B: x_{i j} \leq d\right\}, B_{r}=\left\{x_{i} \in B: x_{i j}&gt;d\right\}$</li>
</ul>
<p>实验表明，该做法并没有降低模型性能，反而还有一定提升。究其原因，应该是采样也会增加弱学习器的多样性，从而潜在地提升了模型的泛化能力，稍微有点像深度学习的dropout。</p>
<h3 id="1-1-3-互斥特征捆绑算法【冲突小的特征可能与多个特征包组合】-特征集合"><a href="#1-1-3-互斥特征捆绑算法【冲突小的特征可能与多个特征包组合】-特征集合" class="headerlink" title="1.1.3 互斥特征捆绑算法【冲突小的特征可能与多个特征包组合】[特征集合]"></a><strong>1.1.3 互斥特征捆绑算法</strong>【冲突小的特征可能与多个特征包组合】[特征集合]</h3><blockquote>
<p>  <strong>==互斥==指的是一些特征很少同时出现非0值</strong>【<strong>类似one-hot特征</strong>】</p>
<p>  <a href="https://zhuanlan.zhihu.com/p/366234433">详解LightGBM两大利器：基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）</a></p>
</blockquote>
<p><strong><font color="red"> 互斥特征捆绑算法（Exclusive Feature Bundling, EFB）指出如果将一些特征进行合并，则可以降低特征数量。</font></strong>高维特征往往是稀疏的，而且特征间可能是相互排斥的（如两个特征不同时取非零值），如果两个特征并不完全互斥（如只有一部分情况下是不同时取非零值），可以用互斥率表示互斥程度。</p>
<p><strong>1）首先介绍如何判定哪些特征应该捆绑在一起？</strong></p>
<p>EFB算法采用<strong>构图（build graph）</strong>的思想，将特征作为节点，不互斥的特征之间进行连边，然后从图中找出所有的捆绑特征集合。其实学过数据结构里的图算法就了解过，这个问题基本就是<a href="https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%9B%BE%E7%9D%80%E8%89%B2%E9%97%AE%E9%A2%98/8928655%3Ffr%3Daladdin">图着色问题</a>。但是图着色问题是一个<strong>NP-hard问题</strong>，不可能在多项式时间里找到最优解。</p>
<p>因此<strong>EFB采用了一种近似的贪心策略解决办法。它允许特征之间存在少数的样本点并不互斥</strong>（比如某些对应的样本点之间并不同时为非0），并设置一个最大冲突阈值 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 。我们选择合适的 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]"> 值，可以在准确度和训练效率上获得很好的trade-off（均衡)。</p>
<p>==<strong>下面给出EFB的特征捆绑的贪心策略流程：</strong>==</p>
<blockquote>
<p>  （1）将特征作为图的顶点，对于<strong>不互斥的特征进行相连</strong>（存在同时不为0的样本），特征同时不为0的样本个数作为边的权重；<br>  （2）根据顶点的度对特征进行降序排序，度越大表明特征与其他特征的冲突越大（越不太可能与其他特征进行捆绑）；【<strong>入度排序，转化为非零值个数排序</strong>】<br>  （3）设置<strong>最大冲突阈值K</strong>，外层循环先对每一个上述排序好的特征，遍历已有的特征捆绑簇，如果发现该特征加入到该特征簇中的冲突数不会超过最大阈值K，则将该特征加入到该簇中。否则新建一个特征簇，将该特征加入到新建的簇中。</p>
</blockquote>
<p><img src="https://pic4.zhimg.com/80/v2-743681d9fd6cebee11f0dcc607f2f687_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p>上面时间的复杂度为 <img src="https://www.zhihu.com/equation?tex=O%28n%5E2%29" alt="[公式]"> ，n为特征的数量，时间其实主要花费在建图上面，两两特征计算互斥程度的时间较长（2层for循环）。对于百万级别的特征数量来说，该复杂度仍是<strong>不可行的</strong>。==为了提高效率，可以不再构建图，将特征直接按照非零值个数排序，将特征<strong>非零值个数</strong>类比为节点的度（即冲突程度)，因为更多的非零值更容易引起冲突。只是改进了排序策略，不再构建图，下面的for循环是一样的。==</p>
<p><strong>2）如何将特征捆绑簇里面的所有特征捆绑（合并）为一个特征？</strong>【<strong>直方图偏移</strong>】</p>
<p>如何进行合并，最关键的是如何能将原始特征从合并好的特征进行分离出来。EFB采用的是加入一个<strong>偏移常量</strong>（offset）来解决。</p>
<blockquote>
<p>  举个例子，我们绑定两个特征A和B，A取值范围为[0, 10)，B取值范围为[0, 20)。则我们可以加入一个偏移常量10，即将B的取值范围变为[10,30），然后合并后的特征范围就是[0, 30)，并且能很好的分离出原始特征~</p>
</blockquote>
<p>因为lgb中<strong>直方图算法</strong>对特征值进行了<strong>分桶</strong>（bin）操作，导致合并互斥特征变得更为简单。从上面伪码看到偏移常量offset直接对每个特征桶的数量累加就行，然后放入偏移常数数组（binRanges）中。</p>
<h3 id="1-1-4-带深度限制的-Leaf-wise-算法"><a href="#1-1-4-带深度限制的-Leaf-wise-算法" class="headerlink" title="1.1.4 带深度限制的 Leaf-wise 算法"></a><strong>1.1.4 带深度限制的 Leaf-wise 算法</strong></h3><h4 id="Level-wise"><a href="#Level-wise" class="headerlink" title="Level-wise"></a>Level-wise</h4><p>大多数GBDT框架使用的按层生长 (level-wise) 的决策树生长策略，Level-wise遍历一次数据可以同时分裂同一层的叶子，容易进行<strong>多线程优化</strong>，也好<strong>控制模型复杂度，不容易过拟合</strong>。但实际上Level-wise是一种低效的算法，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销，因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。</p>
<h4 id="Leaf-wise"><a href="#Leaf-wise" class="headerlink" title="Leaf-wise"></a>Leaf-wise</h4><p>Leaf-wise则是一种更为高效的策略，每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环。因此同Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度。Leaf-wise的缺点是可能会长出比较深的决策树，产生过拟合。因此LightGBM在Leaf-wise之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。</p>
<p><img src="https://pic2.zhimg.com/80/v2-76f2f27dd24fc452a9a65003e5cdd305_1440w.jpg" alt="img"></p>
<h3 id="1-1-5-LightGBM类别特征最优分割"><a href="#1-1-5-LightGBM类别特征最优分割" class="headerlink" title="==1.1.5 LightGBM类别特征最优分割=="></a>==<strong>1.1.5 LightGBM类别特征最优分割</strong>==</h3><blockquote>
<p>  LightGBM中只需要提前将类别映射到非负整数即可(<code>integer-encoded categorical features</code>)</p>
</blockquote>
<p><strong>我们知道，LightGBM可以直接处理类别特征，而不需要对类别特征做额外的one-hot encoding。那么LGB是如何实现的呢？</strong></p>
<p>类别特征的使用在实践中是很常见的。且为了解决one-hot编码处理类别特征的不足, LightGBM优化了对类别特征的支持，可以直接输入类别特征，不需要额外的0/1展开。<strong>LightGBM 采用 many-vs-many 的切分方式将类别特征分为两个子集，实现类别特征的最优切分</strong>。假设某维 特征有 k 个类别，则有 <img src="https://www.zhihu.com/equation?tex=2%5E%7B%28k-1%29%7D-1" alt="[公式]"> 种可能, 时间复杂度为 <img src="https://www.zhihu.com/equation?tex=O%5Cleft%282%5E%7Bk%7D%5Cright%29%2C" alt="[公式]"> LightGBM 基于 Fisher的 《<a href="https://www.zhihu.com/search?q=On+Grouping+For+Maximum+Homogeneity&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;165627712&quot;}">On Grouping For Maximum Homogeneity</a>》论文实现了 O(klogk) 的<a href="https://www.zhihu.com/search?q=时间复杂度&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;165627712&quot;}">时间复杂度</a>。</p>
<p><strong>算法流程如下图所示</strong>，在枚举分割点之前，先把直方图按照每个类别对应的label均值进行排序; 然后按照排序的结果依次枚举最优分割点。从下图可以看到, <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7BS+u+m%28y%29%7D%7B%5Coperatorname%7BCount%7D%28y%29%7D" alt="[公式]"> 为类别的均值。当然，这个方法很容易过拟合，所以LightGBM里面还增加了很多对于这个方法的约束和正则化。</p>
<p><img src="https://pic1.zhimg.com/v2-0f1b7024e9da8f09c75b7f8e436a5d24_b.jpg" alt="img" style="zoom:67%;"></p>
<p><strong>在Expo数据集上的实验结果表明，相比0/1展开的方法，使用LightGBM支持的类别特征可以使训练速度加速8倍，并且精度一致。</strong>更重要的是，LightGBM是第一个直接支持类别特征的GBDT工具。</p>
<h3 id="1-2-工程实现-并行计算"><a href="#1-2-工程实现-并行计算" class="headerlink" title="1.2 工程实现 - 并行计算"></a>1.2 工程实现 - 并行计算</h3><h3 id="1-2-1-特征并行【优化-最优划分点】"><a href="#1-2-1-特征并行【优化-最优划分点】" class="headerlink" title="1.2.1 特征并行【优化 最优划分点】"></a><strong>1.2.1 特征并行</strong>【优化 最优划分点】</h3><p>传统的特征并行算法在于对数据进行垂直划分，然后使用<strong>不同机器找到不同特征的最优分裂点</strong>，<strong>基于通信整合得到最佳划分点</strong>，然后基于通信告知其他机器划分结果。==在本小节中，<strong>工作的节点称为worker</strong>==</p>
<h4 id="传统："><a href="#传统：" class="headerlink" title="==传统：=="></a>==<strong>传统：</strong>==</h4><ul>
<li>垂直划分数据<strong>（对特征划分）</strong>，<strong>不同的worker有不同的特征集</strong></li>
<li>每个workers找到局部最佳的切分点{feature, threshold}</li>
<li>workers使用点对点通信，找到全局最佳切分点</li>
<li><strong>具有全局最佳切分点的worker进行节点分裂，然后广播切分后的结果</strong>（<strong>左右子树的instance indices</strong>）</li>
<li>其它worker根据收到的instance indices也进行划分</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-b0d10c5cd832402e4503e2c1220f7376_r.jpg" alt="preview" style="zoom: 67%;"></p>
<p><strong>传统的特征并行方法有个很大的缺点</strong>：</p>
<ul>
<li><strong>需要告知每台机器最终划分结果，增加了额外的复杂度</strong>（因为对数据进行垂直划分，每台机器所含数据不同，划分结果需要通过通信告知）；</li>
<li>无法加速split的过程，该过程复杂度为O(#data)O(#data)，当数据量大的时候效率不高；</li>
</ul>
<h4 id="LightGBM"><a href="#LightGBM" class="headerlink" title="==LightGBM=="></a><strong>==LightGBM==</strong></h4><p><strong>LightGBM 则不进行数据垂直划分，每台机器都有训练集完整数据</strong>，在得到最佳划分方案后可在本地执行划分而减少了不必要的通信。</p>
<ul>
<li>每个workers找到局部最佳的切分点{feature, threshold}</li>
<li>workers使用点对点通信，找到全局最佳切分点</li>
<li>每个worker根据全局最佳切分点进行节点分裂</li>
</ul>
<p>缺点：</p>
<ul>
<li>split过程的复杂度仍是O(#data)，当数据量大的时候效率不高</li>
<li><strong>每个worker保存所有数据，存储代价高</strong></li>
</ul>
<h3 id="1-2-2-数据并行"><a href="#1-2-2-数据并行" class="headerlink" title="1.2.2 数据并行"></a><strong>1.2.2 数据并行</strong></h3><h4 id="传统方法："><a href="#传统方法：" class="headerlink" title="传统方法："></a>传统方法：</h4><p>数据并行目标是并行化整个决策学习的过程：</p>
<ul>
<li>水平切分数据，<strong>不同的worker拥有部分数据</strong></li>
<li>每个worker根据本地数据构建局部直方图</li>
<li>合并所有的局部直方图得到全部直方图</li>
<li>根据全局直方图找到最优切分点并进行分裂</li>
</ul>
<p><img src="https://www.hrwhisper.me/images/machine-learning-lightgbm/LightGBM-data-parallelization.png" alt="LightGBM-data-parallelization"></p>
<p>在第3步中，有两种合并的方式：</p>
<ul>
<li>采用点对点方式(point-to-point communication algorithm)进行通讯，每个worker通讯量为O(#machine∗#feature∗#bin)</li>
<li>采用collective communication algorithm(如“<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-collective.html">All Reduce</a>”)进行通讯（相当于有一个中心节点，通讯后在返回结果），每个worker的通讯量为O(2∗#feature∗#bin)</li>
</ul>
<h4 id="LightGBM中的数据并行"><a href="#LightGBM中的数据并行" class="headerlink" title="LightGBM中的数据并行"></a>LightGBM中的数据并行</h4><ol>
<li><strong>使用“Reduce Scatter”将不同worker的不同特征的直方图合并，然后workers在局部合并的直方图中找到局部最优划分，最后同步全局最优划分。</strong></li>
<li>前面提到过，可以通过直方图作差法得到兄弟节点的直方图，因此只需要通信一个节点的直方图。</li>
</ol>
<p>传统的数据并行策略主要为水平划分数据，然后本地构建直方图并整合成全局直方图，最后在全局直方图中找出最佳划分点。这种数据划分有一个很大的缺点：通讯开销过大。如果使用点对点通信，一台机器的通讯开销大约为 <img src="https://www.zhihu.com/equation?tex=O%28%5C%23machine+%2A+%5C%23feature+%2A%5C%23bin+%29" alt="[公式]"> ；如果使用集成的通信，则通讯开销为 <img src="https://www.zhihu.com/equation?tex=O%282+%2A+%5C%23feature+%2A%5C%23bin+%29" alt="[公式]"> ，</p>
<p><strong>LightGBM 采用分散规约（Reduce scatter）的方式将直方图整合的任务分摊到不同机器上，从而降低通信代价，并通过直方图做差进一步降低不同机器间的通信。</strong></p>
<h3 id="1-2-3-投票并行"><a href="#1-2-3-投票并行" class="headerlink" title="1.2.3 投票并行"></a><strong>1.2.3 投票并行</strong></h3><p>LightGBM采用一种称为<strong>PV-Tree</strong>的算法进行投票并行(Voting Parallel)，其实这本质上也是一种<strong>数据并行</strong>。PV-Tree和普通的决策树差不多，只是在寻找最优切分点上有所不同。</p>
<p>其算法伪代码描述如下：</p>
<p><img src="https://www.hrwhisper.me/images/machine-learning-lightgbm/LightGBM-pv-tree.png" alt="LightGBM-pv-tree"></p>
<ol>
<li>水平切分数据，不同的worker拥有部分数据。</li>
<li>Local voting: <strong>每个worker构建直方图，找到top-k个最优的本地划分特征</strong></li>
<li>Global voting: <strong>中心节点聚合得到最优的top-2k个全局划分特征（top-2k是看对各个worker选择特征的个数进行计数，取最多的2k个）</strong></li>
<li><strong>Best Attribute Identification</strong>： <strong>中心节点向worker收集这top-2k个特征的直方图，并进行合并，然后计算得到全局的最优划分</strong></li>
<li>中心节点将全局最优划分广播给所有的worker，worker进行本地划分。</li>
</ol>
<p><img src="https://www.hrwhisper.me/images/machine-learning-lightgbm/LightGBM-voting-parallelization.png" alt="LightGBM-voting-parallelization"></p>
<p><strong>可以看出，PV-tree将原本需要#feature×#bin#feature×#bin 变为了2k×#bin2k×#bin，通信开销得到降低。此外，可以证明，当每个worker的数据足够多的时候，top-2k个中包含全局最佳切分点的概率非常高。</strong></p>
<h3 id="1-2-4-缓存优化"><a href="#1-2-4-缓存优化" class="headerlink" title="1.2.4 缓存优化"></a><strong>1.2.4 缓存优化</strong></h3><p>上边说到 XGBoost 的预排序后的特征是通过索引给出的样本梯度的统计值，因其索引访问的结果并不连续，XGBoost 提出缓存访问优化算法进行改进。</p>
<p>而 LightGBM 所使用直方图算法对 Cache 天生友好：</p>
<ol>
<li>首先，<strong>所有的特征都采用相同的方法获得梯度</strong>（区别于不同特征通过不同的索引获得梯度），只需要对梯度进行排序并可实现连续访问，大大提高了缓存命中；</li>
<li>其次，因为<strong>不需要存储特征到样本的索引</strong>，降低了存储消耗，而且也不存在 Cache Miss的问题。</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8813%EF%BC%89EM%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="EM——期望最大-概率模型"><a href="#EM——期望最大-概率模型" class="headerlink" title="EM——期望最大 [概率模型]"></a>EM——期望最大 [概率模型]</h1><blockquote>
<p>  <strong>EM 算法通过引入隐含变量，使用 MLE（极大似然估计）进行迭代求解参数。通常引入隐含变量后会有两个参数，EM 算法首先会固定其中的第一个参数，然后使用 MLE 计算第二个变量值；接着通过固定第二个变量，再使用 MLE 估测第一个变量值，依次迭代，直至收敛到局部最优解。</strong></p>
<ol>
<li><a href="https://www.zhihu.com/question/27976634">怎么通俗易懂地解释 EM 算法并且举个例子?</a></li>
<li><a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/zouxy09/article/details/8537620">从最大似然到 EM 算法浅解</a></li>
<li><h5 id="EM算法"><a href="#EM算法" class="headerlink" title="EM算法"></a><a href="https://zhuanlan.zhihu.com/p/39490840">EM算法</a></h5></li>
</ol>
</blockquote>
<p><strong><font color="red"> EM 算法，全称 Expectation Maximization Algorithm。期望最大算法是一种迭代算法，用于含有隐变量（Hidden Variable）的概率参数模型的最大似然估计或极大后验概率估计。</font></strong></p>
<p>本文思路大致如下：先简要介绍其思想，然后举两个例子帮助大家理解，有了感性的认识后再进行严格的数学公式推导。</p>
<h2 id="1-思想"><a href="#1-思想" class="headerlink" title="1. 思想"></a>1. 思想</h2><p>EM 算法的核心思想非常简单，分为两步：<strong>Expection-Step</strong> 和 <strong>Maximization-Step</strong>。<strong>E-Step 主要通过观察数据和现有模型来估计参数</strong>，然后用这个估计的参数值来计算似然函数的期望值；而 M-Step 是寻找似然函数最大化时对应的参数。由于算法会保证在每次迭代之后<strong>似然函数都会增加</strong>，所以函数最终会收敛。</p>
<p><img src="https://www.zhihu.com/equation?tex=EM" alt="[公式]"> <strong>算法一句话总结就是</strong>： <img src="https://www.zhihu.com/equation?tex=E" alt="[公式]"> 步固定 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 优化 <img src="https://www.zhihu.com/equation?tex=Q" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=M" alt="[公式]"> 步固定 <img src="https://www.zhihu.com/equation?tex=Q" alt="[公式]"> 优化 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 。</p>
<h3 id="2-例子"><a href="#2-例子" class="headerlink" title="2 例子"></a>2 例子</h3><h4 id="2-1-例子-A"><a href="#2-1-例子-A" class="headerlink" title="2.1 例子 A"></a>2.1 例子 A</h4><p>假设有两枚硬币 A 和 B，他们的随机抛掷的结果如下图所示：</p>
<p><img src="https://pic4.zhimg.com/80/v2-4e19d89b47e21cf284644b0576e9af0f_1440w.jpg" alt="img"></p>
<p>我们很容易估计出两枚硬币抛出正面的概率：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctheta_A+%3D+24%2F30+%3D0.8+%5C%5C%5Ctheta_B+%3D+9%2F20+%3D0.45++%5C%5C" alt="[公式]"></p>
<p>现在我们加入<strong>隐变量</strong>，抹去每轮投掷的硬币标记：</p>
<p><img src="https://pic1.zhimg.com/80/v2-caa896173185a8f527c037c122122258_1440w.jpg" alt="img"></p>
<p>碰到这种情况，我们该如何估计 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"> 的值？</p>
<p>我们多了一个隐变量 <img src="https://www.zhihu.com/equation?tex=Z%3D%28z_1%2C+z_2%2C+z_3%2C+z_4%2C+z_5%29" alt="[公式]"> ，代表每一轮所使用的硬币，我们需要知道每一轮抛掷所使用的硬币这样才能估计 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"> 的值，但是估计隐变量 Z 我们又需要知道 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"> 的值，才能用极大似然估计法去估计出 Z。这就陷入了一个鸡生蛋和蛋生鸡的问题。</p>
<p>其解决方法就是先<strong>随机初始化 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"></strong> ，然后用去估计 Z， 然后基于 Z 按照最大似然概率去估计新的 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"> ，循环至收敛。</p>
<h4 id="2-1-2-计算"><a href="#2-1-2-计算" class="headerlink" title="2.1.2 计算"></a><strong>2.1.2 计算</strong></h4><p>随机初始化 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A%3D0.6" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B%3D0.5" alt="[公式]"></p>
<p>对于第一轮来说，如果是硬币 A，得出的 5 正 5 反的概率为： <img src="https://www.zhihu.com/equation?tex=0.6%5E5%2A0.4%5E5" alt="[公式]"> ；如果是硬币 B，得出的 5 正 5 反的概率为： <img src="https://www.zhihu.com/equation?tex=0.5%5E5%2A0.5%5E5" alt="[公式]"> 。我们可以算出使用是硬币 A 和硬币 B 的概率分别为：</p>
<p><img src="https://www.zhihu.com/equation?tex=P_A%3D%5Cfrac%7B0.6%5E5+%2A+0.4%5E5%7D%7B%280.6%5E5+%2A+0.4%5E5%29+%2B+%280.5%5E5+%2A+0.5%5E5%29%7D+%3D+0.45%5C%5C+P_B%3D%5Cfrac%7B0.5%5E5+%2A+0.5%5E5%7D%7B%280.6%5E5+%2A+0.4%5E5%29+%2B+%280.5%5E5+%2A+0.5%5E5%29%7D+%3D+0.55+%5C%5C" alt="[公式]"></p>
<p><img src="https://pic4.zhimg.com/80/v2-b325de65a5bcac196fc0939f346410d7_1440w.jpg" alt="img"></p>
<p>从期望的角度来看，对于第一轮抛掷，使用硬币 A 的概率是 0.45，使用硬币 B 的概率是 0.55。同理其他轮。这一步我们实际上是<strong>估计出了 Z 的概率分布</strong>，这部就是 <strong>E-Step</strong>。</p>
<p>结合硬币 A 的概率和上一张投掷结果，我们利用期望可以求出硬币 A 和硬币 B 的贡献。以第二轮硬币 A 为例子，计算方式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=H%3A+0.80%2A9+%3D7.2+%5C%5C+T%3A+0.80%2A1%3D0.8+%5C%5C" alt="[公式]"></p>
<p>于是我们可以得到：</p>
<p><img src="https://pic1.zhimg.com/80/v2-9b6e8c50c0761c6ac19909c26e0a71d4_1440w.jpg" alt="img"></p>
<p>然后用极大似然估计来估计新的 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_A" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta_B" alt="[公式]"> 。</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctheta_A+%3D+%5Cfrac%7B21.3%7D%7B21.3%2B8.6%7D+%3D+0.71+%5C%5C+%5Ctheta_B+%3D+%5Cfrac%7B11.7%7D%7B11.7+%2B+8.4%7D+%3D+0.58+%5C%5C" alt="[公式]"></p>
<p>这步就对应了 M-Step，重新估计出了参数值。如此反复迭代，我们就可以算出最终的参数值。</p>
<p>上述讲解对应下图：</p>
<p><img src="https://pic3.zhimg.com/v2-6cac968d6500cbca58fc90347c288466_r.jpg" alt="preview" style="zoom:50%;"></p>
<h4 id="2-2-例子-B"><a href="#2-2-例子-B" class="headerlink" title="2.2 例子 B"></a>2.2 例子 B</h4><p>如果说例子 A 需要计算你可能没那么直观，那就举更一个简单的例子：</p>
<p>现在一个班里有 50 个男生和 50 个女生，且男女生分开。我们假定男生的身高服从正态分布： <img src="https://www.zhihu.com/equation?tex=N%28%5Cmu_1%2C+%5Csigma%5E2_1+%29" alt="[公式]"> ，女生的身高则服从另一个正态分布： <img src="https://www.zhihu.com/equation?tex=N%28%5Cmu_2%2C+%5Csigma%5E2_2+%29" alt="[公式]"> 。这时候我们可以用极大似然法（MLE），分别通过这 50 个男生和 50 个女生的样本来估计这两个正态分布的参数。</p>
<p>但现在我们让情况复杂一点，就是这 50 个男生和 50 个女生混在一起了。我们拥有 100 个人的身高数据，却不知道这 100 个人每一个是男生还是女生。</p>
<p>这时候情况就有点尴尬，因为通常来说，我们只有知道了精确的男女身高的正态分布参数我们才能知道每一个人更有可能是男生还是女生。但从另一方面去考量，我们只有知道了每个人是男生还是女生才能尽可能准确地估计男女各自身高的正态分布的参数。</p>
<p>这个时候有人就想到我们必须从某一点开始，并用迭代的办法去解决这个问题：<strong>==我们先设定男生身高和女生身高分布的几个参数（初始值），然后根据这些参数去判断每一个样本（人）是男生还是女生，之后根据标注后的样本再反过来重新估计参数。之后再多次重复这个过程，直至稳定。这个算法也就是 EM 算法。==</strong></p>
<h3 id="3-推导"><a href="#3-推导" class="headerlink" title="3. 推导"></a>3. 推导</h3><p>给定数据集，假设样本间相互独立，我们想要拟合模型 <img src="https://www.zhihu.com/equation?tex=p%28x%3B%5Ctheta%29" alt="[公式]"> 到数据的参数。根据分布我们可以得到如下<strong>似然函数</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+L%28%5Ctheta%29+%26%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7Dlog+p%28x_i%3B%5Ctheta%29++%5C%5C+%26%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7Dlog+%5Csum_%7Bz%7Dp%28x_i%2C+z%3B%5Ctheta%29+%5Cend%7Baligned%7D+%5C%5C" alt="[公式]"></p>
<p>第一步是<strong>对极大似然函数取对数</strong>，第二步是对每个样本的每个可能的类别 z 求<strong>联合概率分布之和</strong>。如果这个 z 是已知的数，那么使用极大似然法会很容易。但如果 z 是隐变量，我们就需要用 EM 算法来求。<strong>事实上，隐变量估计问题也可以通过梯度下降等优化算法，但事实由于求和项将随着隐变量的数目以指数级上升，会给梯度计算带来麻烦；而 EM 算法则可看作一种非梯度优化方法。</strong></p>
<h4 id="3-1-求解含有隐变量的概率模型"><a href="#3-1-求解含有隐变量的概率模型" class="headerlink" title="3.1 求解含有隐变量的概率模型"></a>3.1 求解含有隐变量的概率模型</h4><p><strong>为了求解含有隐变量 <img src="https://www.zhihu.com/equation?tex=z" alt="[公式]"> 的概率模型</strong> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D%5Chat%7B%5Ctheta%7D%3D%5Cmathop%7B%5Carg%5Cmax%7D_%7B%5Ctheta%7D+%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Clog+%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7Dp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%5Cend%7Baligned%7D" alt="[公式]"> <strong>需要一些特殊的技巧</strong>，通过引入隐变量 <img src="https://www.zhihu.com/equation?tex=z%5E%7B%28i%29%7D" alt="[公式]"> 的概率分布为 <img src="https://www.zhihu.com/equation?tex=Q_i%28z%5E%7B%28i%29%7D%29" alt="[公式]"> ，<strong>==因为 <img src="https://www.zhihu.com/equation?tex=%5Clog+%28x%29" alt="[公式]"> 是凹函数故结合凹函数形式下的詹森不等式进行放缩处理==</strong><br> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Clog+%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7Dp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%26%3D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Clog+%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7D+Q_i%28z%5E%7B%28i%29%7D%29%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%5C%5C+%26%3D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Clog+%5Cmathbb%7BE%7D%28%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%29%5C%5C+%26%5Cge%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Cmathbb%7BE%7D%5B%5Clog%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%29%5D%5C%5C+%26%3D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%5Clog%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"><br>其中由概率分布的充要条件 <img src="https://www.zhihu.com/equation?tex=%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%3D1%E3%80%81Q_i%28z%5E%7B%28i%29%7D%29%5Cge0" alt="[公式]"> 可看成下述关于 <img src="https://www.zhihu.com/equation?tex=z" alt="[公式]"> 函数分布列的形式：</p>
<p><img src="https://pic2.zhimg.com/v2-cb7ddb5cdc34761ec70d63c97189b102_720w.jpg?source=d16d100b" alt="img" style="zoom:50%;"></p>
<p><strong>这个过程可以看作是对 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> 求了下界</strong>，假设 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 已经给定那么 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> 的值就取决于 <img src="https://www.zhihu.com/equation?tex=Q_i%28z%5E%7B%28i%29%7D%29" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=p%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%29" alt="[公式]"> 了，因此可以通过调整这两个概率使下界不断上升，以逼近 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> 的真实值，当不等式变成等式时说明调整后的概率能够等价于 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> ，所以必须找到使得等式成立的条件，即寻找<br> <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BE%7D%5B%5Clog%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%29%5D%3D%5Clog+%5Cmathbb%7BE%7D%5B%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%5D%5C%5C" alt="[公式]"><br>由期望得性质可知当<br> <img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%3DC%2C%5C+%5C+%5C+%5C+%5C+C%5Cin%5Cmathbb%7BR%7D+%5C+%5C+%5C+%5C+%5C+%28%2A%29%5C%5C" alt="[公式]"><br>等式成立，对上述等式进行变形处理可得<br> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%26p%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%3DCQ_i%28z%5E%7B%28i%29%7D%29%5C%5C+%26%5CLeftrightarrow+%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7Dp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%3DC%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%3DC%5C%5C+%26%5CLeftrightarrow+%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7Dp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%3DC+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%28%2A%2A%29+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"><br>把 <img src="https://www.zhihu.com/equation?tex=%28%2A%2A%29" alt="[公式]"> 式带入 <img src="https://www.zhihu.com/equation?tex=%28%2A%29" alt="[公式]"> 化简可知<br> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+Q_i%28z%5E%7B%28i%29%7D%29%26%3D%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7B%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7Dp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%5C%5C+%26%3D%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7Bp%28x%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%5C%5C+%26%3Dp%28z%5E%7B%28i%29%7D%7Cx%5E%7B%28i%29%7D%3B%5Ctheta%29+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"><br>至此，可以推出<strong>在固定参数 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 后</strong>， <img src="https://www.zhihu.com/equation?tex=Q_i%28z%5E%7B%28i%29%7D%29" alt="[公式]"> 的<strong>计算公式就是后验概率</strong>，解决了 <img src="https://www.zhihu.com/equation?tex=Q_i%28z%5E%7B%28i%29%7D%29" alt="[公式]"> 如何选择得问题。这一步称为 <img src="https://www.zhihu.com/equation?tex=E" alt="[公式]"> 步，建立 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> 得下界；接下来得 <img src="https://www.zhihu.com/equation?tex=M" alt="[公式]"> 步，就是在给定 <img src="https://www.zhihu.com/equation?tex=Q_i%28z%5E%7B%28i%29%7D%29" alt="[公式]"> 后，调整 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 去极大化 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%29" alt="[公式]"> 的下界即<br> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%26%5Cmathop%7B%5Carg%5Cmax%7D_%7B%5Ctheta%7D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Clog+p%28x%5E%7B%28i%29%7D%3B%5Ctheta%29%5C%5C+%26%5CLeftrightarrow+%5Cmathop%7B%5Carg%5Cmax%7D_%7B%5Ctheta%7D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%5Clog%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%5C%5C+%26%5CLeftrightarrow+%5Cmathop%7B%5Carg%5Cmax%7D_%7B%5Ctheta%7D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%5Cleft%5B%5Clog+p%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29-%5Clog+Q_i%28z%5E%7B%28i%29%7D%29%5Cright%5D%5C%5C+%26%5CLeftrightarrow+%5Cmathop%7B%5Carg%5Cmax%7D_%7B%5Ctheta%7D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%28z%5E%7B%28i%29%7D%29%5Clog+p%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%29+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"><br>因此EM算法的迭代形式为：</p>
<p><img src="https://pic2.zhimg.com/80/v2-8a4f41596e78bfeb1b4044212b259524_1440w.jpg?source=d16d100b" alt="img" style="zoom:50%;"></p>
<p><img src="https://pic3.zhimg.com/80/v2-2f7fc5ca144d2f85f14d46e88055dd86_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>这张图的意思就是：<strong>首先我们固定</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> <strong>，调整</strong> <img src="https://www.zhihu.com/equation?tex=Q%28z%29" alt="[公式]"> <strong>使下界</strong> <img src="https://www.zhihu.com/equation?tex=J%28z%2CQ%29" alt="[公式]"> <strong>上升至与</strong> <img src="https://www.zhihu.com/equation?tex=L%28%5Ctheta%29" alt="[公式]"> <strong>在此点</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> <strong>处相等（绿色曲线到蓝色曲线），然后固定</strong> <img src="https://www.zhihu.com/equation?tex=Q%28z%29" alt="[公式]"> <strong>，调整</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> <strong>使下界</strong> <img src="https://www.zhihu.com/equation?tex=J%28z%2CQ%29" alt="[公式]"> <strong>达到最大值（</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta_t" alt="[公式]"> <strong>到</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D" alt="[公式]"> <strong>），然后再固定</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> <strong>，调整</strong> <img src="https://www.zhihu.com/equation?tex=Q%28z%29" alt="[公式]"> <strong>，一直到收敛到似然函数</strong> <img src="https://www.zhihu.com/equation?tex=L%28%5Ctheta%29" alt="[公式]"> <strong>的最大值处的</strong> <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 。</p>
<p><strong><font color="red"> EM 算法通过引入隐含变量，使用 MLE（极大似然估计）进行迭代求解参数。通常引入隐含变量后会有两个参数，EM 算法首先会固定其中的第一个参数，然后使用 MLE 计算第二个变量值；接着通过固定第二个变量，再使用 MLE 估测第一个变量值，依次迭代，直至收敛到局部最优解。</font></strong></p>
<h4 id="3-2-EM算法的收敛性"><a href="#3-2-EM算法的收敛性" class="headerlink" title="3.2 EM算法的收敛性"></a>3.2 EM算法的收敛性</h4><p>不妨假设 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%29%7D" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%2B1%29%7D" alt="[公式]"> 是EM算法第 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> 次迭代和第 <img src="https://www.zhihu.com/equation?tex=k%2B1" alt="[公式]"> 次迭代的结果，要确保 <img src="https://www.zhihu.com/equation?tex=EM" alt="[公式]"> 算法收敛那么等价于证明 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%29%7D%29%5Cle%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%2B1%29%7D%29" alt="[公式]"> 也就是说极大似然估计单调增加，那么算法最终会迭代到极大似然估计的最大值。在选定 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%29%7D" alt="[公式]"> 后可以得到 <img src="https://www.zhihu.com/equation?tex=E" alt="[公式]"> 步 <img src="https://www.zhihu.com/equation?tex=Q_i%5E%7B%28k%29%7D%28z%5E%7B%28i%29%7D%29%3Dp%28z%5E%7B%28i%29%7D%7Cx%5E%7B%28i%29%7D%3B%5Ctheta%5E%7B%28k%29%7D%29" alt="[公式]"> ，这一步保证了在给定 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%29%7D" alt="[公式]"> 时，詹森不等式中的等式成立即<br> <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%29%7D%29%3D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%5E%7B%28k%29%7D%28z%5E%7B%28i%29%7D%29%5Clog+%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%5E%7B%28k%29%7D%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%5C%5C" alt="[公式]"><br>然后再进行 <img src="https://www.zhihu.com/equation?tex=M" alt="[公式]"> 步，固定 <img src="https://www.zhihu.com/equation?tex=Q_i%5E%7B%28k%29%7D%28z%5E%7B%28i%29%7D%29" alt="[公式]"> 并将 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%29%7D" alt="[公式]"> 视作变量，对上式 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%29%7D%29" alt="[公式]"> 求导后得到 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%2B1%29%7D" alt="[公式]"> 因此有如下式子成立<br> <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%29%7D%29%26%3D%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%5E%7B%28k%29%7D%28z%5E%7B%28i%29%7D%29%5Clog+%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%5E%7B%28k%29%7D%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%28a%29%5C%5C+%26%5Cle+%5Csum%5Climits_%7Bi%3D1%7D%5Em%5Csum%5Climits_%7Bz%5E%7B%28i%29%7D%7DQ_i%5E%7B%28k%29%7D%28z%5E%7B%28i%29%7D%29%5Clog+%5Cdfrac%7Bp%28x%5E%7B%28i%29%7D%2Cz%5E%7B%28i%29%7D%3B%5Ctheta%5E%7B%28k%29%7D%29%7D%7BQ_i%28z%5E%7B%28i%29%7D%29%7D%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%28b%29%5C%5C+%26%5Cle%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%2B1%29%7D%29%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%28c%29+%5Cend%7Baligned%7D%5C%5C" alt="[公式]"><br>首先 <img src="https://www.zhihu.com/equation?tex=%28a%29" alt="[公式]"> 式是前面 <img src="https://www.zhihu.com/equation?tex=E" alt="[公式]"> 步所保证詹森不等式中的等式成立的条件， <img src="https://www.zhihu.com/equation?tex=%28a%29" alt="[公式]"> 到 <img src="https://www.zhihu.com/equation?tex=%28b%29" alt="[公式]"> 是 <img src="https://www.zhihu.com/equation?tex=M" alt="[公式]"> 步的定义，<img src="https://www.zhihu.com/equation?tex=%28b%29" alt="[公式]"> 到 <img src="https://www.zhihu.com/equation?tex=%28c%29" alt="[公式]">对任意参数都成立，而其等式的条件是固定 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> 并调整好 <img src="https://www.zhihu.com/equation?tex=Q" alt="[公式]"> 时成立，<img src="https://www.zhihu.com/equation?tex=%28b%29" alt="[公式]"> 到 <img src="https://www.zhihu.com/equation?tex=%28c%29" alt="[公式]">只是固定 <img src="https://www.zhihu.com/equation?tex=Q" alt="[公式]"> 调整 <img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]"> ，在得到 <img src="https://www.zhihu.com/equation?tex=%5Ctheta%5E%7B%28k%2B1%29%7D" alt="[公式]"> 时，只是最大化 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%29%7D%29" alt="[公式]"> ，也就是 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D%28%5Ctheta%5E%7B%28k%2B1%29%7D%29" alt="[公式]"> 的一个下界而没有使等式成立。</p>
<h3 id="4-另一种理解"><a href="#4-另一种理解" class="headerlink" title="4. 另一种理解"></a>4. 另一种理解</h3><p>坐标上升法（Coordinate ascent）：</p>
<p><img src="https://pic4.zhimg.com/80/v2-b28bfe68513ff86d9643fec10786b827_1440w.jpg" alt="img"></p>
<p>途中直线为迭代优化路径，因为每次只优化一个变量，所以可以看到它没走一步都是平行与坐标轴的。</p>
<p>EM 算法类似于坐标上升法，E 步：固定参数，优化 Q；M 步：固定 Q，优化参数。交替将极值推向最大。</p>
<h4 id="5-应用"><a href="#5-应用" class="headerlink" title="5. 应用"></a>5. 应用</h4><p>EM 的应用有很多，比如、混合高斯模型、聚类、HMM 等等。其中 <strong>EM 在 K-means 中的用处</strong>，我将在介绍 K-means 中的给出。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8811%EF%BC%89XGB*/</url>
    <content><![CDATA[<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><p><strong>XGBoost官方文档</strong>：<a href="https://xgboost.readthedocs.io/en/latest/index.html">https://xgboost.readthedocs.io/en/latest/index.html</a></p>
</li>
<li><p>LightGBM算法梳理：<a href="https://zhuanlan.zhihu.com/p/78293497">https://zhuanlan.zhihu.com/p/78293497</a></p>
</li>
<li><p>详解LightGBM两大利器：基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）：<a href="https://zhuanlan.zhihu.com/p/366234433">https://zhuanlan.zhihu.com/p/366234433</a></p>
</li>
<li><p>【机器学习】决策树（下）——XGBoost、LightGBM（非常详细）：<a href="https://zhuanlan.zhihu.com/p/87885678">https://zhuanlan.zhihu.com/p/87885678</a></p>
</li>
<li><p>xgboost面试题整理: <a href="https://xiaomindog.github.io/2021/06/22/xgb-qa/">https://xiaomindog.github.io/2021/06/22/xgb-qa/</a></p>
</li>
</ul>
<h2 id="【机器学习】决策树（下）——XGBoost、LightGBM"><a href="#【机器学习】决策树（下）——XGBoost、LightGBM" class="headerlink" title="【机器学习】决策树（下）——XGBoost、LightGBM"></a>【机器学习】决策树（下）——XGBoost、LightGBM</h2><p><img src="https://pic2.zhimg.com/80/v2-358e4bfce928d0460bd5e8b4cab8f715_1440w.jpg" alt="img"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Boosting 算法</th>
<th>GBDT</th>
<th>XGBoost</th>
<th>LightGBM</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>思想</strong><img src="image-20220315210756470.png" alt="image-20220315210756470" style="zoom:25%;"></td>
<td>回归树、梯度迭代、缩减（Shrinkage）;<strong>GBDT 的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于 0</strong></td>
<td><strong>二阶导数、线性分类器、正则化</strong>、缩减、<strong>列抽样、并行化</strong></td>
<td><strong>更快的训练速度和更低的内存使用</strong></td>
</tr>
<tr>
<td>目标函数</td>
<td><img src="image-20220315213233284.png" alt="image-20220315213233284" style="zoom: 25%;"></td>
<td><img src="image-20220315213503054.png" alt="image-20220315213503054" style="zoom: 67%;"><img src="image-20220315213608526.png" alt="image-20220315213608526" style="zoom: 33%;"></td>
<td>同上</td>
</tr>
<tr>
<td>损失函数</td>
<td>最小均方损失函数、<strong>绝对损失或者 Huber 损失函数</strong></td>
<td>【线性】最小均方损失函数、==sigmod和softmax==</td>
<td><strong>复杂度模型</strong>：<img src="image-20220315215849417.png" alt="image-20220315215849417" style="zoom: 25%;"></td>
</tr>
<tr>
<td>基模型</td>
<td>CART模型</td>
<td>CART模型/ ==回归模型==</td>
<td>CART模型/ ==回归模型==</td>
</tr>
<tr>
<td>抽样算法</td>
<td>无</td>
<td><strong>列抽样</strong>：借鉴了<strong>随机森林</strong>的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</td>
<td><strong>单边梯度抽样算法；</strong>根据样本梯度来对梯度小的这边样本进行采样，一部分大梯度和随机分布</td>
</tr>
<tr>
<td><strong>切分点算法</strong></td>
<td>CART模型</td>
<td><strong>预排序</strong>、<strong>贪心算法</strong>、<strong>近似算法（</strong>加权分位数缩略图<strong>）</strong></td>
<td><strong>直方图算法</strong>：内存消耗降低，计算代价减少；（不需要记录特征到样本的索引）</td>
</tr>
<tr>
<td><strong>缺失值算法</strong></td>
<td>CART模型</td>
<td><strong>稀疏感知算法</strong>：选择增益最大的枚举项即为最优<strong>缺省方向</strong>。【<strong><font color="red"> 稀疏数据优化不足</font></strong>】【<strong>gblinear 补0</strong>】</td>
<td><strong>互斥特征捆绑算法</strong>：<strong>互斥</strong>指的是一些特征很少同时出现非0值。<strong>稀疏感知算法</strong>；【<strong>gblinear 补0</strong>】</td>
</tr>
<tr>
<td><strong>建树策略</strong></td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Leaf-wise</strong>：每次分裂增益最大的叶子节点，直到达到停止条件。</td>
</tr>
<tr>
<td><strong>正则化</strong></td>
<td>无</td>
<td>L1 和 L2 正则化项</td>
<td>L1 和 L2 正则化项</td>
</tr>
<tr>
<td><strong>Shrinkage（缩减）</strong></td>
<td>有</td>
<td>有</td>
<td>有</td>
</tr>
<tr>
<td>类别特征优化</td>
<td>无</td>
<td>无</td>
<td><strong>类别特征最优分割</strong>：<strong>many-vs-many</strong></td>
</tr>
<tr>
<td>并行化设计</td>
<td>无</td>
<td><strong>块结构设计</strong>、</td>
<td><strong>特征并行</strong>、 <strong>数据并行</strong>、<strong>投票并行</strong></td>
</tr>
<tr>
<td>==缓存优化==</td>
<td>无</td>
<td>为每个线程分配一个连续的缓存区、<strong>“核外”块计算</strong></td>
<td>1、所有的特征都采用相同的方法获得梯度；2、其次，因为不需要存储特征到样本的索引，降低了存储消耗</td>
</tr>
<tr>
<td><strong>缺点</strong></td>
<td>对异常点敏感；</td>
<td><strong>预排序</strong>：仍需要遍历数据集；==不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引，相当于消耗了两倍的内存。==</td>
<td><strong>内存更小</strong>： 索引值、特征值边bin、互斥特征捆绑; <strong>速度更快</strong>：遍历直方图；单边梯度算法过滤掉梯度小的样本；基于 Leaf-wise 算法的增长策略构建树，减少了很多不必要的计算量；特征并行、数据并行方法加速计算</td>
</tr>
</tbody>
</table>
</div>
<h2 id="一、XGBoost-线性模型？多分类？增量训练？XGB-直方图，分布式部署"><a href="#一、XGBoost-线性模型？多分类？增量训练？XGB-直方图，分布式部署" class="headerlink" title="一、XGBoost [线性模型？多分类？增量训练？XGB_直方图，分布式部署]"></a>一、XGBoost [线性模型？多分类？增量训练？XGB_直方图，分布式部署]</h2><blockquote>
<p>  <strong>增量学习</strong>：XGBoost提供两种增量训练的方式，一种是在当前迭代树的基础上增加新树，原树不变；另一种是当前迭代树结构不变，重新计算叶节点权重，同时也可增加新树。</p>
<p>  <strong>线性模型</strong>：xgboost通过泰勒公式的二阶展开迭代的残差是1导/2导，线性回归迭代的是标签，xgboost需要串行多个线性回归，预测结果为多个象形线性回归的累积值……，除了用到了线性回归的原理方程式，他们两的损失函数，下降梯度都不一样，几乎没有什么共同点</p>
<p>  <strong>XGBoost 用泰勒展开优势在哪？</strong>：<a href="https://www.zhihu.com/question/61374305">https://www.zhihu.com/question/61374305</a></p>
<ul>
<li><strong>xgboost是以mse为基础推导出来的</strong>，在mse的情况下，xgboost的目标函数展开就是一阶项+二阶项的形式，而其他类似logloss这样的目标函数不能表示成这种形式。为了后续推导的统一，所以将<strong>目标函数进行二阶泰勒展开，就可以直接自定义损失函数了，只要二阶可导即可，增强了模型的扩展性</strong>。</li>
<li><p><strong>二阶信息能够让梯度收敛的更快，类似牛顿法比SGD收敛更快</strong>。一阶信息描述梯度变化方向，二阶信息可以描述梯度变化方向是如何变化的。</p>
<p><strong>==深入理解XGBoost==</strong>：<a href="https://bailingnan.github.io/post/shen-ru-li-jie-xgboost/">https://bailingnan.github.io/post/shen-ru-li-jie-xgboost/</a></p>
</li>
</ul>
</blockquote>
<p>XGBoost 是大规模并行 boosting tree 的工具，它是目前最快最好的开源 boosting tree 工具包，比常见的工具包快 10 倍以上。Xgboost 和 GBDT 两者都是 boosting 方法，除了工程实现、解决问题上的一些差异外，最大的不同就是<strong>目标函数</strong>的定义。故本文将从数学原理和工程实现上进行介绍，并在最后介绍下 Xgboost 的优点。</p>
<h3 id="1-1-数学原理"><a href="#1-1-数学原理" class="headerlink" title="1.1 数学原理"></a>1.1 数学原理</h3><p><strong>1.1.1 目标函数</strong></p>
<p>我们知道 XGBoost 是由$k$个基模型组成的一个加法运算式：</p>
<script type="math/tex; mode=display">
\hat{y}_{i}=\sum_{t=1}^{k} f_{t}\left(x_{i}\right)</script><p><strong>损失函数：</strong></p>
<script type="math/tex; mode=display">
L=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}\right)</script><p>我们知道模型的预测精度由模型的<strong>偏差</strong>和<strong>方差</strong>共同决定，损失函数代表了模型的偏差，想要方差小则需要简单的模型，所以目标函数由模型的<strong>损失函数$L$</strong>与抑<strong>制模型复杂度的正则项 <script type="math/tex">\Omega</script></strong>组成。支持<strong>决策树</strong>也支持<strong>线性模型</strong>。</p>
<script type="math/tex; mode=display">
O b j=\sum_{i=1}^{n} l\left(\hat{y}_{i}, y_{i}\right)+\sum_{t=1}^{k} \Omega\left(f_{t}\right)</script><p><strong>Boosting模型是向前加法：</strong></p>
<script type="math/tex; mode=display">
\hat{y}_{i}^{t}=\hat{y}_{i}^{t-1}+f_{t}\left(x_{i}\right)</script><p>目标函数就可以写成：</p>
<script type="math/tex; mode=display">
\begin{aligned}
O b j^{(t)} &=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{t}\right)+\sum_{i=1}^{t} \Omega\left(f_{i}\right) \\
&=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{t-1}+f_{t}\left(x_{i}\right)\right)+\sum_{i=1}^{t} \Omega\left(f_{i}\right)
\end{aligned}</script><p>求此时最优化目标函数，就相当于求解 <script type="math/tex">f_{t}\left(x_{i}\right)</script>。根据泰勒展开式：</p>
<script type="math/tex; mode=display">
f(x+\Delta x) \approx f(x)+f^{\prime}(x) \Delta x+\frac{1}{2} f^{\prime \prime}(x) \Delta x^{2}</script><p><strong>我们==把<script type="math/tex">\hat{y}_{i}^{t-1}</script>,视为x， <script type="math/tex">f_{t}\left(x_{i}\right)</script>视为<script type="math/tex">\Delta x</script>==，故可以将目标函数写成</strong>：</p>
<script type="math/tex; mode=display">
O b j^{(t)}=\sum_{i=1}^{n}\left[l\left(y_{i}, \hat{y}_{i}^{t-1}\right)+g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\sum_{i=1}^{t} \Omega\left(f_{i}\right)</script><p>由于<strong>第一项为常数，对优化没有影响，所以我们只需要求出每一步损失函数的一阶导和二阶导的值</strong>【==前t-1的结果和标签求==】，然后最优化目标函数，就可以得到每一步的f(x),最后根据加法模型得到一个整体模型。</p>
<script type="math/tex; mode=display">
O b j^{(t)} \approx \sum_{i=1}^{n}\left[g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\sum_{i=1}^{t} \Omega\left(f_{i}\right)</script><blockquote>
<p>  以<strong>平方损失函数</strong>【绝对值、hubor损失】为例（GBDT 残差）：</p>
<p>  <img src="image-20220404141858337.png" alt="image-20220404141858337" style="zoom:50%;"></p>
<p>  其中 <img src="https://www.zhihu.com/equation?tex=g_%7Bi%7D" alt="[公式]"> 为损失函数的一阶导， <img src="https://www.zhihu.com/equation?tex=h_%7Bi%7D" alt="[公式]"> 为损失函数的二阶导，<strong>注意这里的导是对 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_i%5E%7Bt-1%7D" alt="[公式]"> 求导</strong>。</p>
<script type="math/tex; mode=display">
  \begin{aligned}
  &g_{i}=\frac{\partial\left(\hat{y}^{t-1}-y_{i}\right)^{2}}{\partial \hat{y}^{t-1}}=2\left(\hat{y}^{t-1}-y_{i}\right) \\
  &h_{i}=\frac{\partial^{2}\left(\hat{y}^{t-1}-y_{i}\right)^{2}}{\hat{y}^{t-1}}=2
  \end{aligned}</script></blockquote>
<h4 id="1-1-2-基于决策树的目标函数"><a href="#1-1-2-基于决策树的目标函数" class="headerlink" title="1.1.2 基于决策树的目标函数"></a><strong>1.1.2 基于决策树的目标函数</strong></h4><p>我们知道 Xgboost 的基模型<strong>不仅支持决策树，还支持线性模型</strong>，这里我们主要介绍基于决策树的目标函数。</p>
<p>我们可以将决<strong>策树定义为<script type="math/tex">f_{t}(x)=w_{q(x)}</script></strong>，x为某一样本，这里的 <img src="https://www.zhihu.com/equation?tex=q%28x%29" alt="[公式]"> 代表了该样本在哪个叶子结点上，而 <img src="https://www.zhihu.com/equation?tex=w_q" alt="[公式]"> 则代表了叶子结点取值 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> ，所以 <img src="https://www.zhihu.com/equation?tex=w_%7Bq%28x%29%7D" alt="[公式]"> 就代表了每个样本的取值 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> （即预测值)。</p>
<p><strong>决策树的复杂度</strong>可由<strong>叶子数 <img src="https://www.zhihu.com/equation?tex=T" alt="[公式]"></strong> 组成，叶子节点越少模型越简单，此外<strong>叶子节点也不应该含有过高的权重</strong> <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> （类比 LR 的每个变量的权重)，所以目标函数的正则项可以定义为：</p>
<script type="math/tex; mode=display">
\Omega\left(f_{t}\right)=\gamma T+\frac{1}{2} \lambda \sum_{j=1}^{T} w_{j}^{2}</script><p>即<strong>决策树模型的复杂度</strong>由生成的所有<strong>决策树的叶子节点数量</strong>，和所有<strong>节点权重所组成的向量的 <img src="https://www.zhihu.com/equation?tex=L_2" alt="[公式]"> 范式</strong>共同决定。</p>
<p><img src="https://pic1.zhimg.com/80/v2-e0ab9287990a6098e4cdbc5a8cff4150_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>我们设 <img src="https://www.zhihu.com/equation?tex=I_j%3D+%5C%7B+i+%5Cvert+q%28x_i%29%3Dj+%5C%7D" alt="[公式]"> 为第 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]"> 个叶子节点的样本集合，故我们的目标函数可以写成：</p>
<script type="math/tex; mode=display">
\begin{aligned}
O b j^{(t)} & \approx \sum_{i=1}^{n}\left[g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right) \\
&=\sum_{i=1}^{n}\left[g_{i} w_{q\left(x_{i}\right)}+\frac{1}{2} h_{i} w_{q\left(x_{i}\right)}^{2}\right]+\gamma T+\frac{1}{2} \lambda \sum_{j=1}^{T} w_{j}^{2} \\
&=\sum_{j=1}^{T}\left[\left(\sum_{i \in I_{j}} g_{i}\right) w_{j}+\frac{1}{2}\left(\sum_{i \in I_{j}} h_{i}+\lambda\right) w_{j}^{2}\right]+\gamma T
\end{aligned}</script><p>第二步是遍历所有的样本后求每个样本的损失函数，但样本最终会落在叶子节点上，所以我们也可以遍历叶子节点，然后获取叶子节点上的样本集合，最后在求损失函数。即我们之前样本的集合，现在都改写成叶子结点的集合，由于一个叶子结点有多个样本存在，因此才有了 <img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi+%5Cin+I_j%7Dg_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi+%5Cin+I_j%7Dh_i" alt="[公式]"> 这两项， <img src="https://www.zhihu.com/equation?tex=w_j" alt="[公式]"> 为第 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]"> 个叶子节点取值。</p>
<p><img src="image-20220314162051124.png" alt="image-20220314162051124" style="zoom: 25%;"></p>
<p><strong><font color="red"> 这里我们要注意 <img src="https://www.zhihu.com/equation?tex=G_j" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=H_j" alt="[公式]"> 是前 <img src="https://www.zhihu.com/equation?tex=t-1" alt="[公式]"> 步得到的结果，其值已知可视为常数，只有最后一棵树的叶子节点 <img src="https://www.zhihu.com/equation?tex=w_j" alt="[公式]"> 不确定，那么将目标函数对 <img src="https://www.zhihu.com/equation?tex=w_j" alt="[公式]"> 求一阶导，并令其等于 <img src="https://www.zhihu.com/equation?tex=0" alt="[公式]"> ，则可以求得叶子结点 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]"> 对应的权值：</font></strong></p>
<p><img src="https://www.zhihu.com/equation?tex=w_j%5E%2A%3D-%5Cfrac%7BG_j%7D%7BH_j%2B%5Clambda%7D++%5C%5C" alt="[公式]"></p>
<p>所以<strong>目标函数可以化简为：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=Obj+%3D+-%5Cfrac12+%5Csum_%7Bj%3D1%7D%5ET+%5Cfrac%7BG_j%5E2%7D%7BH_j%2B%5Clambda%7D+%2B+%5Cgamma+T+%5C%5C" alt="[公式]"></p>
<p><img src="https://pic2.zhimg.com/80/v2-f6db7af6c1e683192cb0ccf48eafaf99_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>上图给出目标函数计算的例子，求每个节点每个样本的一阶导数 <img src="https://www.zhihu.com/equation?tex=g_i" alt="[公式]"> 和二阶导数 <img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]"> ，然后针对每个节点对所含样本求和得到的 <img src="https://www.zhihu.com/equation?tex=G_j" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=H_j" alt="[公式]"> ，最后遍历决策树的节点即可得到<strong>目标函数</strong>。</p>
<h4 id="1-1-3-最优切分点划分算法"><a href="#1-1-3-最优切分点划分算法" class="headerlink" title="1.1.3 最优切分点划分算法"></a><strong>1.1.3 最优切分点划分算法</strong></h4><p><strong><font color="red"> 在决策树的生长过程中，一个非常关键的问题是如何找到叶子的节点的最优切分点，</font></strong>Xgboost 支持两种分裂节点的方法——<strong>贪心算法</strong>和<strong>近似算法</strong>。</p>
<p><strong>1）贪心算法</strong></p>
<ol>
<li><strong>从深度为 <img src="https://www.zhihu.com/equation?tex=0" alt="[公式]"> 的树开始，对每个叶节点枚举所有的可用特征</strong>；</li>
<li>针对每个特征，把属于该节点的训练样本根据该特征值进行<strong>升序排列</strong>，通过线性扫描的方式来决定该特征的最佳分裂点，并记录该特征的分裂收益；</li>
<li>选择收益最大的特征作为分裂特征，用该特征的最佳分裂点作为分裂位置，在该节点上分裂出左右两个新的叶节点，并为每个新节点<strong>关联对应的样本集</strong>？？</li>
<li>回到第 1 步，递归执行到满足特定条件为止。（树的深度、gamma）</li>
</ol>
<h5 id="那么如何计算每个特征的分裂收益呢？"><a href="#那么如何计算每个特征的分裂收益呢？" class="headerlink" title="那么如何计算每个特征的分裂收益呢？"></a>那么如何计算每个特征的分裂收益呢？</h5><p>假设我们在某一节点完成特征分裂，则分列前的目标函数可以写为：</p>
<p><img src="https://www.zhihu.com/equation?tex=Obj_%7B1%7D+%3D-%5Cfrac12+%5B%5Cfrac%7B%28G_L%2BG_R%29%5E2%7D%7BH_L%2BH_R%2B%5Clambda%7D%5D+%2B+%5Cgamma++%5C%5C" alt="[公式]"></p>
<p>分裂后的目标函数为：</p>
<p><img src="https://www.zhihu.com/equation?tex=Obj_2+%3D++-%5Cfrac12+%5B+%5Cfrac%7BG_L%5E2%7D%7BH_L%2B%5Clambda%7D+%2B+%5Cfrac%7BG_R%5E2%7D%7BH_R%2B%5Clambda%7D%5D+%2B2%5Cgamma+%5C%5C" alt="[公式]"></p>
<p>则对于目标函数来说，分裂后的收益为：<strong>MAX</strong>【<strong>obj1 - obj2 （分裂后越小越好）</strong>】</p>
<p><img src="https://www.zhihu.com/equation?tex=Gain%3D%5Cfrac12+%5Cleft%5B+%5Cfrac%7BG_L%5E2%7D%7BH_L%2B%5Clambda%7D+%2B+%5Cfrac%7BG_R%5E2%7D%7BH_R%2B%5Clambda%7D+-+%5Cfrac%7B%28G_L%2BG_R%29%5E2%7D%7BH_L%2BH_R%2B%5Clambda%7D%5Cright%5D+-+%5Cgamma+%5C%5C" alt="[公式]"></p>
<p>注意<strong>该特征收益也可作为特征重要性输出的重要依据</strong>。</p>
<p>我们可以发现对于所有的分裂点 <img src="https://www.zhihu.com/equation?tex=a" alt="[公式]"> ，我们只要做一遍从左到右的扫描就可以枚举出所有分割的梯度和 <img src="https://www.zhihu.com/equation?tex=G_L" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=G_R" alt="[公式]"> 。然后用上面的公式计算每个分割方案的分数就可以了。<font color="red">观察分裂后的收益，我们会发现节点划分不一定会使得结果变好，因为我们有一个引入<strong>新叶子的惩罚项（gamma)</strong>，也就是说引入的分割带来的<strong>增益如果小于一个阀值</strong>的时候，我们可以剪掉这个分割。 </font></p>
<p><strong>2）近似算法</strong>【<strong>加权分位划分点</strong>】</p>
<p><strong>贪婪算法可以的到最优解，但当数据量太大时则无法读入内存进行计算</strong>，近似算法主要针对贪婪算法这一缺点给出了近似最优解。</p>
<p>对于每个特征，只考察分位点可以减少计算复杂度。该算法会首先根据<strong>特征分布的分位数提出候选划分点，然后将连续型特征映射到由这些候选点划分的桶中</strong>，然后聚合统计信息找到所有区间的最佳分裂点。在提出候选切分点时有两种策略：</p>
<ul>
<li><strong>Global</strong>：<strong>学习每棵树前就提出候选切分点，并在每次分裂时都采用这种分割</strong>；</li>
<li><strong>Local</strong>：每次分裂前将重新提出候选切分点。</li>
</ul>
<p><strong>下图给出近似算法的具体例子，以三分位为例：</strong></p>
<p><img src="https://pic2.zhimg.com/80/v2-5d1dd1673419599094bf44dd4b533ba9_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>根据样本特征进行排序，然后基于分位数进行划分，并统计三个桶内的 <img src="https://www.zhihu.com/equation?tex=G%2CH" alt="[公式]"> 值，最终求解节点划分的增益。</p>
<h4 id="1-1-4-加权分位数缩略图-XGBoost-直方图算法"><a href="#1-1-4-加权分位数缩略图-XGBoost-直方图算法" class="headerlink" title="1.1.4 加权分位数缩略图[XGBoost 直方图算法]"></a><strong>1.1.4 加权分位数缩略图</strong>[XGBoost 直方图算法]</h4><ul>
<li><strong>第一个 for 循环：</strong>对特征 k <strong>根据该特征分布的分位数找到切割点的候选集合【==直方图==】</strong> <img src="https://www.zhihu.com/equation?tex=S_k%3D%5C%7Bs_%7Bk1%7D%2Cs_%7Bk2%7D%2C...%2Cs_%7Bkl%7D+%5C%7D" alt="[公式]"> 。XGBoost 支持 Global 策略和 Local 策略。</li>
<li><strong>第二个 for 循环：</strong>针对每个特征的候选集合，将样本映射到由该特征对应的候选点集构成的分桶区间中，即 <img src="https://www.zhihu.com/equation?tex=%7Bs_%7Bk%2Cv%7D%E2%89%A5x_%7Bjk%7D%3Es_%7Bk%2Cv%E2%88%921%7D%7D" alt="[公式]"> ，对每个桶统计 <img src="https://www.zhihu.com/equation?tex=G%2CH+" alt="[公式]"> 值，最后在这些统计量上寻找最佳分裂点。</li>
</ul>
<p><img src="https://pic1.zhimg.com/80/v2-161382c979557b8bae1563a459cd1ed4_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>事实上， <strong>XGBoost 不是简单地按照样本个数进行分位，而是以二阶导数值 <img src="https://www.zhihu.com/equation?tex=h_i+" alt="[公式]"> 作为样本的权重进行划分</strong>，如下：</p>
<p><img src="https://pic4.zhimg.com/80/v2-5f16246289eaa2a3ae72f971db198457_1440w.jpg" alt="img"></p>
<h5 id="那么问题来了：为什么要用-进行样本加权？"><a href="#那么问题来了：为什么要用-进行样本加权？" class="headerlink" title="==那么问题来了：为什么要用  进行样本加权？=="></a>==那么问题来了：为什么要用 <img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]"> 进行样本加权？==</h5><p>我们知道模型的目标函数为：</p>
<p><img src="https://www.zhihu.com/equation?tex=+Obj%5E%7B%28t%29%7D+%5Capprox+%5Csum_%7Bi%3D1%7D%5En+%5Cleft%5B+g_if_t%28x_i%29+%2B+%5Cfrac12h_if_t%5E2%28x_i%29+%5Cright%5D+%2B+%5Csum_%7Bi%3D1%7D%5Et++%5COmega%28f_i%29+%5C%5C" alt="[公式]"></p>
<p>我们稍作整理，便可以看出 <img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]"> 有对 loss 加权的作用。</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D++Obj%5E%7B%28t%29%7D+%26+%5Capprox+%5Csum_%7Bi%3D1%7D%5En+%5Cleft%5B+g_if_t%28x_i%29+%2B+%5Cfrac12h_if_t%5E2%28x_i%29+%5Cright%5D+%2B+%5Csum_%7Bi%3D1%7D%5Et++%5COmega%28f_i%29+%5C%5C+%5C%5C++++%26%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5B+g_i+f_t%28x_i%29+%2B+%5Cfrac%7B1%7D%7B2%7Dh_i+f_t%5E2%28x_i%29+%5Ccolor%7Bred%7D%7B%2B+%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7Bg_i%5E2%7D%7Bh_i%7D%7D%5D%2B%5COmega%28f_t%29+%5Ccolor%7Bred%7D%7B%2B+C%7D+%5C%5C++++%26%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Ccolor%7Bred%7D%7B%5Cfrac%7B1%7D%7B2%7Dh_i%7D+%5Cleft%5B+f_t%28x_i%29+-+%5Cleft%28+-%5Cfrac%7Bg_i%7D%7Bh_i%7D+%5Cright%29+%5Cright%5D%5E2+%2B+%5COmega%28f_t%29+%2B+C+%5Cend%7Balign%7D+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7Bg_i%5E2%7D%7Bh_i%7D" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=C" alt="[公式]"> 皆为常数。我们可以看到 <img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]"> 就是平方损失函数中样本的权重。</p>
<p>对于样本权值相同的数据集来说，找到候选分位点已经有了解决方案（GK 算法），但是当样本权值不一样时，该如何找到候选分位点呢？（作者给出了一个 Weighted Quantile Sketch 算法，这里将不做介绍。）</p>
<h4 id="xgboost的近似直方图算法也类似于lightgbm这里的直方图算法-为什么慢？"><a href="#xgboost的近似直方图算法也类似于lightgbm这里的直方图算法-为什么慢？" class="headerlink" title=" xgboost的近似直方图算法也类似于lightgbm这里的直方图算法? 为什么慢？"></a><strong><font color="red"> xgboost的近似直方图算法也类似于lightgbm这里的直方图算法? 为什么慢？</font></strong></h4><ul>
<li><strong>xgboost在每一层都动态构建直方图</strong>， 因为<strong>xgboost的直方图算法不是针对某个特定的feature</strong>，而是所有feature共享一个直方图(每个样本的权重是二阶导),所以每一层都要重新构建直方图，而<strong>lightgbm中对每个特征都有一个直方图</strong>，所以构建一次直方图就够了。</li>
<li><strong>lightgbm有一些工程上的cache优化</strong></li>
</ul>
<h4 id="1-1-5-稀疏感知算法【缺失值的处理】"><a href="#1-1-5-稀疏感知算法【缺失值的处理】" class="headerlink" title="1.1.5 稀疏感知算法【缺失值的处理】"></a><strong>1.1.5 稀疏感知算法</strong>【<strong>缺失值的处理</strong>】</h4><blockquote>
<ul>
<li><strong>特征值缺失的样本无需遍历只需直接分配到左右节点</strong></li>
<li><strong>如果训练中没有数据缺失，预测时出现了数据缺失，则默认被分类到右节点.</strong>？<ul>
<li>看c++源码是默认向左方向</li>
</ul>
</li>
</ul>
</blockquote>
<p>在决策树的第一篇文章中我们介绍 CART 树在应对数据缺失时的分裂策略【<strong>缺失代理</strong>】，XGBoost 也给出了其解决方案。XGBoost 在构建树的节点过程中只考虑非缺失值的数据遍历，而为每个节点增加了一个缺省方向，当样本相应的特征值缺失时，可以被归类到缺省方向上，最优的缺省方向可以从数据中学到。</p>
<p><strong>XGBoost提出的是在计算分割后的分数时，遇到缺失值，分别将缺失值带入左右两个分割节点，然后取最大值的方向为其默认方向。</strong>至于如何学到缺省值的分支，其实很简单，<strong>分别枚举特征缺省的样本归为左右分支后的增益，选择增益最大的枚举项即为最优缺省方向。</strong></p>
<p>在构建树的过程中需要枚举特征缺失的样本，乍一看该算法的计算量增加了一倍，但其实该算法在构建树的过程中只考虑了特征未缺失的样本遍历，而<strong>特征值缺失的样本无需遍历只需直接分配到左右节点</strong>，故算法所需遍历的样本量减少，下图可以看到稀疏感知算法比 basic 算法速度块了超过 50 倍。</p>
<p><img src="https://pic1.zhimg.com/80/v2-e065bea4b424ea2d13b25ed2e7004aa8_1440w.jpg" alt="img" style="zoom:67%;"></p>
<h4 id="1-1-6-缩减与列采样"><a href="#1-1-6-缩减与列采样" class="headerlink" title="1.1.6 缩减与列采样"></a><strong>1.1.6 缩减与列采样</strong></h4><p>除了在目标函数中引入正则项，为了防止过拟合，XGBoost还引入了缩减(shrinkage)和列抽样（column subsampling），通过在每一步的boosting中引入缩减系数，降低每个树和叶子对结果的影响；列采样是借鉴随机森林中的思想，根据反馈，列采样有时甚至比行抽样效果更好，同时，通过列采样能加速计算。</p>
<h3 id="1-2-工程实现"><a href="#1-2-工程实现" class="headerlink" title="1.2 工程实现"></a>1.2 工程实现</h3><h4 id="1-2-1-块结构设计"><a href="#1-2-1-块结构设计" class="headerlink" title="1.2.1 块结构设计"></a><strong>1.2.1 块结构设计</strong></h4><p>我们知道，决策树的学习<strong>最耗时的一个步骤就是在每次寻找最佳分裂点是都需要对特征的值进行排序</strong>。而 <strong><font color="red"> XGBoost 在训练之前对根据特征对数据进行了排序，然后保存到块结构中，并在每个块结构中都采用了稀疏矩阵存储格式（Compressed Sparse Columns Format，CSC）进行存储，后面的训练过程中会重复地使用块结构，可以大大减小计算量。</font></strong></p>
<blockquote>
<p>  预排序 + 块设计【独立】 + 稀疏矩阵存储 </p>
</blockquote>
<ul>
<li><strong>每一个块结构包括一个或多个已经排序好的特征</strong>；</li>
<li><strong>缺失特征值将不进行排序</strong>；</li>
<li>每个特征会存储指向<strong>样本梯度统计值</strong>的索引，方便计算一阶导和二阶导数值；</li>
</ul>
<p>这种块结构存储的特征之间相互独立，方便计算机进行并行计算。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个<strong>特征的增益计算可以同时进行</strong>，这也是 Xgboost 能够实现分布式或者多线程计算的原因。</p>
<h4 id="1-2-2-缓存访问优化算法【索引访问梯度统计-gt-缓存空间不连续】"><a href="#1-2-2-缓存访问优化算法【索引访问梯度统计-gt-缓存空间不连续】" class="headerlink" title="1.2.2 缓存访问优化算法【索引访问梯度统计 -&gt; 缓存空间不连续】"></a><strong>1.2.2 缓存访问优化算法</strong>【索引访问梯度统计 -&gt; 缓存空间不连续】</h4><p>块结构的设计可以减少节点分裂时的计算量，但<strong>特征值通过索引访问样本梯度统计值的设计会导致访问操作的内存空间不连续</strong>，这样会造成缓存命中率低，从而影响到算法的效率。</p>
<p>为了解决缓存命中率低的问题，XGBoost 提出了缓存访问优化算法：为每个线程分配一个连续的缓存区，将需要的梯度信息存放在缓冲区中，这样就是实现了非连续空间到连续空间的转换，提高了算法效率。此外适当调整块大小，也可以有助于缓存优化。</p>
<p>于exact greedy算法中, 使用<strong>缓存预取（cache-aware prefetching）</strong>。具体来说，<strong>对每个线程分配一个连续的buffer</strong>，读取梯度信息并存入Buffer中（这样就实现了非连续到连续的转化）</p>
<h4 id="1-2-3-“核外”块计算"><a href="#1-2-3-“核外”块计算" class="headerlink" title="1.2.3 “核外”块计算"></a><strong>1.2.3 “核外”块计算</strong></h4><p>当数据量过大时无法将数据全部加载到内存中，只能先将无法加载到内存中的数据暂存到硬盘中，直到需要时再进行加载计算，而这种操作必然涉及到因内存与硬盘速度不同而造成的资源浪费和性能瓶颈。为了解决这个问题，<strong>XGBoost 独立一个线程专门用于从硬盘读入数据，以实现处理数据和读入数据同时进行</strong>。</p>
<p>此外，XGBoost 还用了两种方法来降低硬盘读写的开销：</p>
<ul>
<li><strong>块压缩：</strong>对 Block 进行按列压缩，并在读取时进行解压；</li>
<li><strong>块拆分：</strong>将每个块存储到不同的磁盘中，从多个磁盘读取可以增加吞吐量。</li>
</ul>
<h4 id="1-2-4-XGBoost损失函数"><a href="#1-2-4-XGBoost损失函数" class="headerlink" title="==1.2.4 XGBoost损失函数=="></a>==1.2.4 <strong>XGBoost损失函数</strong>==</h4><blockquote>
<p>  <a href="https://blog.csdn.net/qq_32103261/article/details/106664227">不平衡处理：xgboost 中scale_pos_weight、给样本设置权重weight、 自定义损失函数 和 简单复制正样本的区别</a></p>
</blockquote>
<p><strong>损失函数</strong>：损失函数描述了预测值和真实标签的差异，通过对损失函数的优化来获得对学习任务的一个近似求解方法。boosting类算法的损失函数的作用： Boosting的框架, 无论是GBDT还是Adaboost, 其在每一轮迭代中, <strong>根本没有理会损失函数具体是什么, 仅仅用到了损失函数的一阶导数通过随机梯度下降来参数更新</strong>。XGBoost是用了牛顿法进行的梯度更新。通过对损失进行分解得到一阶导数和二阶导数并通过牛顿法来迭代更新梯度。</p>
<h5 id="（1）-自定义损失函数"><a href="#（1）-自定义损失函数" class="headerlink" title="（1）==自定义损失函数=="></a>（1）==<strong>自定义损失函数</strong>==</h5><p><strong>XGBOOST是一个非常灵活的模型</strong>，允许使用者根据实际使用场景调整<a href="https://so.csdn.net/so/search?q=损失函数&amp;spm=1001.2101.3001.7020">损失函数</a>，对于常见的二分类问题一般使用的binary：logistic损失函数，其形式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=J%28%5Ctheta%29%3D-%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cleft%28y%5E%7B%28i%29%7D+%5Clog+h_%7B%5Ctheta%7D%5Cleft%28x%5E%7B%28i%29%7D%5Cright%29%2B%5Cleft%281-y%5E%7B%28i%29%7D%5Cright%29+%5Clog+%5Cleft%281-h_%7B%5Ctheta%7D%5Cleft%28x%5E%7B%28i%29%7D%5Cright%29%5Cright%29%5Cright%29+%EF%BC%883%EF%BC%89%5C%5C" alt="[公式]"></p>
<p>这个损失函数对于正类错分和负类错分给予的惩罚时相同的，但是<strong>对于不平衡数据集，或者某些特殊情况（两类错分代价不一样）的时候这样的损失函数就不再合理了。</strong></p>
<p>基于XGBoost的损失函数的分解求导，可以知道XGBoost的除正则项以外的核心影响因子是损失函数的1阶导和2阶导，所以对于任意的学习任务的损失函数，可以对其求一阶导数和二阶导数带入到XGBoost的自定义损失函数范式里面进行处理。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">custom_obj</span>(<span class="params">pred, dtrain</span>):<span class="comment"># pred 和 dtrain 的顺序不能弄反</span></span><br><span class="line">    <span class="comment"># STEP1 获得label</span></span><br><span class="line">    label = dtrain.get_label()</span><br><span class="line">    <span class="comment"># STEP2 如果是二分类任务，需要让预测值通过sigmoid函数获得0～1之间的预测值</span></span><br><span class="line">    <span class="comment"># 如果是回归任务则下述任务不需要通过sigmoid</span></span><br><span class="line">    <span class="comment"># 分类任务sigmoid化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line">    sigmoid_pred = sigmoid(原始预测值)</span><br><span class="line">    <span class="comment">#回归任务</span></span><br><span class="line">    pred = 原始预测值</span><br><span class="line">    <span class="comment"># STEP3 一阶导和二阶导</span></span><br><span class="line">    grad = 一阶导</span><br><span class="line">    hess = 二阶导</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> grad, hess</span><br></pre></td></tr></table></figure></p>
<p>非平衡分类学习任务，例如首笔首期30+的风险建模任务，首期30+的逾期率比例相对ever30+的逾期率为1/3左右，<strong>通过修正占比少的正样本权重来对影响正样本对损失函数的贡献度，可以进一步提升模型的效果</strong>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">weighted_binary_cross_entropy</span>(<span class="params">pred, dtrain,imbalance_alpha=<span class="number">10</span></span>):</span><br><span class="line">    <span class="comment"># retrieve data from dtrain matrix</span></span><br><span class="line">    label = dtrain.get_label()</span><br><span class="line">    <span class="comment"># compute the prediction with sigmoid</span></span><br><span class="line">    sigmoid_pred = <span class="number">1.0</span> / (<span class="number">1.0</span> + np.exp(-pred))</span><br><span class="line">    <span class="comment"># gradient</span></span><br><span class="line">    grad = -(imbalance_alpha ** label) * (label - sigmoid_pred)</span><br><span class="line">    hess = (imbalance_alpha ** label) * sigmoid_pred * (<span class="number">1.0</span> - sigmoid_pred)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> grad, hess </span><br></pre></td></tr></table></figure>
<h5 id="（2）Focal-Loss"><a href="#（2）Focal-Loss" class="headerlink" title="（2）Focal Loss"></a>（2）Focal Loss</h5><p><strong>Focal Loss for Dense Object Detection 是ICCV2017的Best student paper,文章思路很简单但非常具有开拓性意义，效果也非常令人称赞。</strong></p>
<ul>
<li>大家还可以看知乎的讨论：<a href="https://www.zhihu.com/question/63581984">如何评价 Kaiming 的 Focal Loss for Dense Object Detection？</a></li>
<li>[机器学习] XGBoost 自定义损失函数-FocalLoss：<a href="https://blog.csdn.net/zwqjoy/article/details/109311133">https://blog.csdn.net/zwqjoy/article/details/109311133</a></li>
</ul>
<p>Focal Loss的引入主要是为了解决难易样本数量不平衡（注意，有区别于正负样本数量不平衡）的问题，实际可以使用的范围非常广泛，为了方便解释，拿目标检测的应用场景来说明</p>
<p><strong>==Focal Loss的主要思想就是改变损失函数.Focal loss是在交叉熵损失函数基础上进行的修改==</strong></p>
<p>单阶段的目标检测器通常会产生高达100k的候选目标，只有极少数是正样本，正负样本数量非常不平衡。我们在计算分类的时候常用的损失——交叉熵。<img src="https://private.codecogs.com/gif.latex?y%7B%7D%27" alt="y{}&#39;">是经过激活函数的输出，所以在0-1之间。可见普通的交叉熵对于正样本而言，输出概率越大损失越小。对于负样本而言，输出概率越小则损失越小。此时的损失函数在大量简单样本的迭代过程中比较缓慢且可能无法优化至最优。</p>
<p>为了解决<strong>正负样本不平衡</strong>的问题，我们通常会在交叉熵损失的前面加上一个参数<strong>平衡因子alpha</strong>，用来平衡正负样本本身的比例不均. 文中alpha取0.25，即正样本要比负样本占比小，这是因为负例易分。</p>
<h3 id="1-3-优缺点"><a href="#1-3-优缺点" class="headerlink" title="1.3 优缺点"></a>1.3 优缺点</h3><h4 id="1-3-1-优点"><a href="#1-3-1-优点" class="headerlink" title="1.3.1 优点"></a><strong>1.3.1 优点</strong></h4><ol>
<li><strong>精度更高：</strong>GBDT 只用到一阶<strong>泰勒展开</strong>，而 XGBoost 对损失函数进行了二阶泰勒展开。<strong>XGBoost 引入二阶导一方面是为了增加精度，另一方面也是为了能够自定义损失函数，二阶泰勒展开可以近似大量损失函数</strong>；</li>
<li><strong>灵活性更强：</strong>GBDT 以 CART 作为<strong>基分类器</strong>，XGBoost 不仅支持 CART 还支持线性分类器，（使用线性分类器的 <strong>XGBoost 相当于带 L1 和 L2 正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）</strong>）。此外，XGBoost 工具支持自定义损失函数，只需函数支持一阶和二阶求导；</li>
<li><strong>正则化：</strong>XGBoost 在目标函数中加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、叶子节点权重的 L2 范式。正则项降低了模型的方差，使学习出来的模型更加简单，有助于防止过拟合；</li>
<li><strong>Shrinkage（缩减）：</strong>相当于学习速率。XGBoost 在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间；</li>
<li><strong>列抽样：</strong>XGBoost 借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</li>
<li><strong>缺失值处理：</strong>XGBoost 采用的稀疏感知算法极大的加快了节点分裂的速度；</li>
<li><strong>可以并行化操作：</strong>块结构可以很好的支持并行计算。</li>
</ol>
<h4 id="1-3-2-缺点"><a href="#1-3-2-缺点" class="headerlink" title="1.3.2 缺点"></a><strong>1.3.2 缺点</strong></h4><ol>
<li>虽然利用<strong>预排序</strong>和<strong>近似算法</strong>可以降低寻找最佳分裂点的计算量，但在节点分裂过程中仍需要<strong>==遍历数据集==</strong>；</li>
<li>预排序过程的空间复杂度过高，不仅需要存储特征值，还需要<strong>==存储特征对应样本的梯度统计值的索引==</strong>，相当于消耗了两倍的内存。</li>
</ol>
<h2 id="二、XGBoost常用参数"><a href="#二、XGBoost常用参数" class="headerlink" title="二、XGBoost常用参数"></a>二、XGBoost常用参数</h2><h4 id="XGBoost的参数一共分为三类："><a href="#XGBoost的参数一共分为三类：" class="headerlink" title="XGBoost的参数一共分为三类："></a>XGBoost的参数一共分为三类：</h4><p><a href="https://xgboost.apachecn.org/#/">完整参数请戳官方文档</a></p>
<p>1、<strong>通用参数</strong>：宏观函数控制。</p>
<p>2、<strong>Booster参数</strong>：控制每一步的booster(tree/regression)。booster参数一般可以调控模型的效果和计算代价。我们所说的调参，很这是大程度上都是在调整booster参数。</p>
<p>3、<strong>学习目标参数</strong>：控制训练目标的表现。我们对于问题的划分主要体现在学习目标参数上。比如我们要做分类还是回归，做二分类还是多分类，这都是目标参数所提供的。</p>
<h4 id="通用参数"><a href="#通用参数" class="headerlink" title="通用参数"></a>通用参数</h4><ol>
<li><strong>booster</strong>：我们有两种参数选择，<code>gbtree</code>、<code>dart</code>和<code>gblinear</code>。gbtree、dart是采用树的结构来运行数据，而gblinear是基于线性模型。</li>
<li><strong>silent</strong>：静默模式，为<code>1</code>时模型运行不输出。</li>
<li><strong>nthread</strong>: 使用线程数，一般我们设置成<code>-1</code>,使用所有线程。如果有需要，我们设置成多少就是用多少线程。</li>
</ol>
<h4 id="Booster参数"><a href="#Booster参数" class="headerlink" title="Booster参数"></a>Booster参数</h4><ol>
<li><p><strong>==n_estimator==</strong>: 也作<code>num_boosting_rounds</code>这是生成的<strong>最大树的数目</strong>，也是最大的迭代次数。</p>
</li>
<li><p><strong>==learning_rate==</strong>: 有时也叫作<code>eta</code>，系统默认值为<code>0.3</code>,。<strong>每一步迭代的步长</strong>，很重要。太大了运行准确率不高，太小了运行速度慢。我们一般使用比默认值小一点，<code>0.1</code>左右就很好。</p>
</li>
<li><p><strong>==gamma==</strong>：系统默认为<code>0</code>,我们也常用<code>0</code>。在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。<code>gamma</code>指定了节点分裂所需的<strong>最小损失函数下降值</strong>。 这个参数的值越大，算法越保守。因为<code>gamma</code>值越大的时候，损失函数下降更多才可以分裂节点。所以树生成的时候更不容易分裂节点。范围: <code>[0,∞]</code></p>
</li>
<li><p><strong>==subsample==</strong>：系统默认为<code>1</code>。这个参数控制对于每棵树，<strong>随机采样的比例</strong>。减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。 典型值：<code>0.5-1</code>，<code>0.5</code>代表平均采样，防止过拟合. 范围: <code>(0,1]</code>，<strong>注意不可取0</strong></p>
</li>
<li><p><strong>colsample_bytree</strong>：系统默认值为1。我们一般设置成0.8左右。用来控制每棵<strong>随机采样的列数的占比</strong>(每一列是一个特征)。 典型值：<code>0.5-1</code>范围: <code>(0,1]</code></p>
</li>
<li><p><strong>colsample_bylevel</strong>：默认为1,我们也设置为1.这个就相比于前一个更加细致了，它指的是每棵树每次节点分裂的时候列采样的比例</p>
</li>
<li><p><strong>max_depth</strong>： 系统默认值为<code>6</code>，我们常用<code>3-10</code>之间的数字。这个值为<strong>树的最大深度</strong>。这个值是用来控制过拟合的。<code>max_depth</code>越大，模型学习的更加具体。设置为<code>0</code>代表没有限制，范围: <code>[0,∞]</code></p>
</li>
<li><p><strong>==max_delta_step==</strong>：默认<code>0</code>,我们常用<code>0</code>.这个参数限制了<strong>每棵树权重改变的最大步长</strong>，如果这个参数的值为<code>0</code>,则意味着没有约束。如果他被赋予了某一个正值，则是这个算法更加保守。通常，这个参数我们不需要设置，但是<strong>==当个类别的样本极不平衡的时候，这个参数对逻辑回归优化器是很有帮助的。==</strong></p>
</li>
<li><p><strong>==lambda==</strong>:也称<code>reg_lambda</code>,默认值为<code>0</code>。<strong>权重的L2正则化项</strong>。(和Ridge regression类似)。这个参数是用来控制XGBoost的正则化部分的。这个参数在减少过拟合上很有帮助。</p>
</li>
<li><p><strong>alpha</strong>:也称<code>reg_alpha</code>默认为<code>0</code>,权重的L1正则化项。(和Lasso regression类似)。 可以应用在很高维度的情况下，使得算法的速度更快。</p>
</li>
<li><p><strong>==scale_pos_weight==</strong>：默认为<code>1</code>在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛。通常可以将其设置为<strong>负样本的数目与正样本数目的比值</strong>。<strong>xgboost中==scale_pos_weight、对样本进行weight设置和简单复制正样本==得到的结果是一样的，本质上都是改变了训练的损失函数。通过自定义设置损失函数可得到验证。实际上基本思想都是通过过采样的方法处理不平衡数据。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (label == <span class="number">1.0</span>f) &#123;</span><br><span class="line">    w *= scale_pos_weight;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 见源码 src/objective/regression_obj.cu</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>  在DMatrix里边设置每个样本的weight 是 怎样改变训练过程的呢，其实是改变训练的损失函数，源代码里的代码如下，可以看到对不同的样本赋予不同的权重实际上是影响了该样本在训练过程中贡献的损失，进而改变了一阶导和二阶导。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_out_gpair[_idx] = GradientPair(Loss::FirstOrderGradient(p, label) * w,</span><br><span class="line">                   Loss::SecondOrderGradient(p, label) * w);</span><br><span class="line"><span class="comment"># 见源码 src/objective/regression_obj.cu</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="学习目标参数"><a href="#学习目标参数" class="headerlink" title="学习目标参数"></a>学习目标参数</h4><h5 id="objective-缺省值-reg-linear"><a href="#objective-缺省值-reg-linear" class="headerlink" title="objective [缺省值=reg:linear]"></a>objective [缺省值=reg:linear]</h5><ul>
<li><code>reg:linear</code>– <strong>线性回归</strong></li>
<li><code>reg:logistic</code> – <strong>逻辑回归</strong></li>
<li><code>binary:logistic</code> – 二分类逻辑回归，输出为概率</li>
<li><code>binary:logitraw</code> – 二分类逻辑回归，输出的结果为wTx</li>
<li><code>count:poisson</code> – 计数问题的poisson回归，输出结果为poisson分布。在poisson回归中，max_delta_step的缺省值为0.7 (used to safeguard optimization)</li>
<li><code>multi:softmax</code> – 设置 XGBoost 使用softmax目标函数做多分类，需要设置参数num_class（类别个数）</li>
<li><code>multi:softprob</code> – 如同softmax，但是输出结果为ndata*nclass的向量，其中的值是每个数据分为每个类的概率。</li>
</ul>
<h5 id="eval-metric-缺省值-通过目标函数选择"><a href="#eval-metric-缺省值-通过目标函数选择" class="headerlink" title="eval_metric [缺省值=通过目标函数选择]"></a>eval_metric [缺省值=通过目标函数选择]</h5><ul>
<li><code>rmse</code>: <strong>均方根误差</strong></li>
<li><code>mae</code>: <strong>平均绝对值误差</strong></li>
<li><code>logloss</code>: negative log-likelihood</li>
<li><code>error</code>: 二分类错误率。其值通过错误分类数目与全部分类数目比值得到。对于预测，预测值大于0.5被认为是正类，其它归为负类。 error@t: 不同的划分阈值可以通过 ‘t’进行设置</li>
<li><code>merror</code>: 多分类错误率，计算公式为(wrong cases)/(all cases)</li>
<li><code>mlogloss</code>: ==多分类log损失==</li>
<li><code>auc</code>: 曲线下的面积</li>
<li><code>ndcg</code>: Normalized Discounted Cumulative Gain</li>
<li><code>map</code>: 平均正确率</li>
</ul>
<p>一般来说，我们都会使用<code>xgboost.train(params, dtrain)</code>函数来训练我们的模型。这里的<code>params</code>指的是<code>booster</code>参数。</p>
<h1 id="XGBoostQ-amp-A"><a href="#XGBoostQ-amp-A" class="headerlink" title="XGBoostQ&amp;A"></a>XGBoostQ&amp;A</h1><ul>
<li>推荐收藏 | 又有10道XGBoost面试题送给你：<a href="https://cloud.tencent.com/developer/article/1518305">https://cloud.tencent.com/developer/article/1518305</a></li>
</ul>
<h3 id="1、XGBoost模型如果过拟合了怎么解决"><a href="#1、XGBoost模型如果过拟合了怎么解决" class="headerlink" title="1、XGBoost模型如果过拟合了怎么解决?"></a><strong>1、XGBoost模型如果过拟合了怎么解决?</strong></h3><ul>
<li><strong>正则项</strong>：叶子结点的数目和叶子结点权重的L2模的平方</li>
<li><strong>列抽样</strong>：训练的时候只用一部分特征，不仅可以降低过拟合，还可以加速</li>
<li><strong>子采样</strong>：每轮计算可以不使用全部样本</li>
<li><strong>shrinkage</strong>: 步长(学习率)，消弱训练出的每棵树的影响，让后面的训练有更大的学习空间</li>
</ul>
<p>当出现过拟合时，有两类参数可以缓解：</p>
<p>第一类参数：用于<strong>直接控制模型的复杂度</strong>。包括<code>max_depth,min_child_weight,gamma</code> 等参数</p>
<p>第二类参数：用于<strong>增加随机性</strong>，从而使得模型在训练时对于噪音不敏感。包括<code>subsample,colsample_bytree</code></p>
<p>还有就是直接减小<code>learning rate</code>，但需要同时增加<code>estimator</code> 参数。</p>
<h3 id="2、怎么理解决策树、xgboost能处理缺失值？而有的模型-svm-对缺失值比较敏感呢"><a href="#2、怎么理解决策树、xgboost能处理缺失值？而有的模型-svm-对缺失值比较敏感呢" class="headerlink" title="2、怎么理解决策树、xgboost能处理缺失值？而有的模型(svm)对缺失值比较敏感呢?"></a>2、怎么理解决策树、xgboost能处理缺失值？而有的模型(svm)对缺失值比较敏感呢?</h3><blockquote>
<p>   微调的回答 - 知乎 <a href="https://www.zhihu.com/question/58230411/answer/242037063">https://www.zhihu.com/question/58230411/answer/242037063</a></p>
<p>  XGBoost是一种<strong>boosting</strong>的集成学习模型：支持的弱学习器（即单个的学习器，也称基学习器）有<strong>树模型</strong>和<strong>线性模型</strong>（<strong>gblinear</strong>），默认为<strong>gbtree</strong>。</p>
<ul>
<li><p><strong>gblinear</strong>，<strong>由于线性模型不支持缺失值，会将缺失值填充为0</strong>；</p>
</li>
<li><p><strong>gbtree</strong>或者<strong>dart</strong>，则支持缺失值；</p>
</li>
</ul>
</blockquote>
<ul>
<li>工具包自动处理数据缺失<strong>不代表</strong>具体的算法可以<strong>处理缺失项</strong></li>
<li>对于有缺失的数据：以<a href="https://www.zhihu.com/search?q=决策树&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A242037063}">决策树</a>为原型的模型<strong>优于</strong>依赖距离度量的模型</li>
</ul>
<h3 id="3、-Histogram-VS-Pre-sorted"><a href="#3、-Histogram-VS-Pre-sorted" class="headerlink" title="3、 Histogram VS Pre-sorted"></a>3、 Histogram VS Pre-sorted</h3><h4 id="Pre-sorted"><a href="#Pre-sorted" class="headerlink" title="Pre-sorted"></a>Pre-sorted</h4><p><strong>预排序还是有一定优点的，如果不用预排序的话，在分裂节点的时候，选中某一个特征后，需要对A按特征值大小进行排序，然后计算每个阈值的增益，这个过程需要花费很多时间</strong>。</p>
<p>预排序算法在计算最优分裂时，各个特征的增益可以并行计算，并且能精确地找到分割点。但是<strong>预排序后需要保存特征值及排序后的索引，因此需要消耗两倍于训练数据的内存，时间消耗大</strong>。另外预排序后，<strong>特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化，时间消耗也大</strong>。最后，在每一层，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样。</p>
<h4 id="Historgram"><a href="#Historgram" class="headerlink" title="Historgram"></a>Historgram</h4><p>首先需要指出的是，XGBoost在寻找树的分裂节点的也是支持直方图算法的，就是论文中提到的近视搜索算法（Approximate Algorithm）。<strong>只是，无论特征值是否为0，直方图算法都需要对特征的分箱值进行索引，因此对于大部分实际应用场景当中的稀疏数据优化不足。</strong></p>
<p>回过头来，为了能够发挥直方图算法的优化威力，LightGBM提出了另外两个新技术：<strong>单边梯度采样（Gradient-based One-Side Sampling</strong>）和<strong>互斥特征合并（Exclusive Feature Bundling）</strong>，<strong><font color="red"> 在减少维度和下采样上面做了优化以后才能够将直方图算法发挥得淋漓尽致。</font></strong></p>
<h3 id="4、Xgboost中的树如何剪枝？"><a href="#4、Xgboost中的树如何剪枝？" class="headerlink" title="4、Xgboost中的树如何剪枝？"></a>4、<strong>Xgboost中的树如何剪枝？</strong></h3><p><strong>在loss中增加了正则项</strong>：使用叶子结点的数目和叶子结点权重的L2模的平方，控制树的复杂度在每次分裂时，如果分裂后增益小于设置的阈值，则不分裂，则对应于Gain需要大于0才会分裂。(预剪枝)</p>
<p>则对于目标函数来说，分裂后的收益为：<strong>MAX</strong>【<strong>obj1 - obj2 （分裂后越小越好）</strong>】</p>
<p><img src="https://www.zhihu.com/equation?tex=Gain%3D%5Cfrac12+%5Cleft%5B+%5Cfrac%7BG_L%5E2%7D%7BH_L%2B%5Clambda%7D+%2B+%5Cfrac%7BG_R%5E2%7D%7BH_R%2B%5Clambda%7D+-+%5Cfrac%7B%28G_L%2BG_R%29%5E2%7D%7BH_L%2BH_R%2B%5Clambda%7D%5Cright%5D+-+%5Cgamma+%5C%5C" alt="[公式]"></p>
<p>注意<strong>该特征收益也可作为特征重要性输出的重要依据</strong>。</p>
<p>我们可以发现对于所有的分裂点 <img src="https://www.zhihu.com/equation?tex=a" alt="[公式]"> ，我们只要做一遍从左到右的扫描就可以枚举出所有分割的梯度和 <img src="https://www.zhihu.com/equation?tex=G_L" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=G_R" alt="[公式]"> 。然后用上面的公式计算每个分割方案的分数就可以了。<font color="red">观察分裂后的收益，我们会发现节点划分不一定会使得结果变好，因为我们有一个引入<strong>新叶子的惩罚项（gamma)</strong>，也就是说引入的分割带来的<strong>增益如果小于一个阀值</strong>的时候，我们可以剪掉这个分割。 </font></p>
<ul>
<li>当一次分裂后，计算新生成的左、右叶子节点样本权重和。如果任一个叶子结点的样本权重低于某一个阈值（最小样本权重和），也会收回此次分裂。</li>
<li>完成完整一棵树的分裂之后，再从底到顶反向检查是否有不满足分裂条件的结点，进行回溯剪枝。</li>
</ul>
<h3 id="5、Xgboost采样是有放回还是无放回的？"><a href="#5、Xgboost采样是有放回还是无放回的？" class="headerlink" title="5、Xgboost采样是有放回还是无放回的？"></a>5、<strong>Xgboost采样是有放回还是无放回的？</strong></h3><p>xgboost时基于boosting的方法，样本是不放回的 ，每轮样本不重复。</p>
<h3 id="6、Xgboost在工程上有哪些优化？为什么要做这些工程化优化？"><a href="#6、Xgboost在工程上有哪些优化？为什么要做这些工程化优化？" class="headerlink" title="6、Xgboost在工程上有哪些优化？为什么要做这些工程化优化？"></a>6、<strong>Xgboost在工程上有哪些优化？为什么要做这些工程化优化？</strong></h3><h4 id="块结构设计"><a href="#块结构设计" class="headerlink" title="块结构设计"></a><strong>块结构设计</strong></h4><p>我们知道，决策树的学习<strong>最耗时的一个步骤就是在每次寻找最佳分裂点是都需要对特征的值进行排序</strong>。而 <strong><font color="red"> XGBoost 在训练之前对根据特征对数据进行了排序，然后保存到块结构中，并在每个块结构中都采用了稀疏矩阵存储格式（Compressed Sparse Columns Format，CSC）进行存储，后面的训练过程中会重复地使用块结构，可以大大减小计算量。</font></strong></p>
<blockquote>
<p>  预排序 + 块设计【独立】 + 稀疏矩阵存储 </p>
</blockquote>
<ul>
<li><strong>每一个块结构包括一个或多个已经排序好的特征</strong>；</li>
<li><strong>缺失特征值将不进行排序</strong>；</li>
<li>每个特征会存储指向<strong>样本梯度统计值</strong>的索引，方便计算一阶导和二阶导数值；</li>
</ul>
<p>这种块结构存储的特征之间相互独立，方便计算机进行并行计算。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个<strong>特征的增益计算可以同时进行</strong>，这也是 Xgboost 能够实现分布式或者多线程计算的原因。</p>
<h4 id="缓存访问优化算法【索引访问梯度统计-gt-缓存空间不连续】"><a href="#缓存访问优化算法【索引访问梯度统计-gt-缓存空间不连续】" class="headerlink" title="缓存访问优化算法【索引访问梯度统计 -&gt; 缓存空间不连续】"></a><strong>缓存访问优化算法</strong>【索引访问梯度统计 -&gt; 缓存空间不连续】</h4><p>块结构的设计可以减少节点分裂时的计算量，但<strong>特征值通过索引访问样本梯度统计值的设计会导致访问操作的内存空间不连续</strong>，这样会造成缓存命中率低，从而影响到算法的效率。</p>
<p>为了解决缓存命中率低的问题，XGBoost 提出了缓存访问优化算法：为每个线程分配一个连续的缓存区，将需要的梯度信息存放在缓冲区中，这样就是实现了非连续空间到连续空间的转换，提高了算法效率。此外适当调整块大小，也可以有助于缓存优化。</p>
<p>于exact greedy算法中, 使用<strong>缓存预取（cache-aware prefetching）</strong>。具体来说，<strong>对每个线程分配一个连续的buffer</strong>，读取梯度信息并存入Buffer中（这样就实现了非连续到连续的转化）</p>
<h4 id="“核外”块计算"><a href="#“核外”块计算" class="headerlink" title="“核外”块计算"></a><strong>“核外”块计算</strong></h4><p>当数据量过大时无法将数据全部加载到内存中，只能先将无法加载到内存中的数据暂存到硬盘中，直到需要时再进行加载计算，而这种操作必然涉及到因内存与硬盘速度不同而造成的资源浪费和性能瓶颈。为了解决这个问题，<strong>XGBoost 独立一个线程专门用于从硬盘读入数据，以实现处理数据和读入数据同时进行</strong>。</p>
<p>此外，XGBoost 还用了两种方法来降低硬盘读写的开销：</p>
<ul>
<li><strong>块压缩：</strong>对 Block 进行按列压缩，并在读取时进行解压；</li>
<li><strong>块拆分：</strong>将每个块存储到不同的磁盘中，从多个磁盘读取可以增加吞吐量。</li>
</ul>
<h3 id="7、Xgboost与GBDT有什么联系和不同？【基模型、算法、工程设计】"><a href="#7、Xgboost与GBDT有什么联系和不同？【基模型、算法、工程设计】" class="headerlink" title="7、Xgboost与GBDT有什么联系和不同？【基模型、算法、工程设计】"></a>7、<strong>Xgboost与GBDT有什么联系和不同？</strong>【基模型、算法、工程设计】</h3><ol>
<li><strong>基分类器</strong>：GBDT 以 CART 作为基分类器，而Xgboost的基分类器不仅支持CART决策树，还支持线性分类器，此时Xgboost相当于带L1和L2正则化项的Logistic回归（分类问题）或者线性回归（回归问题）。</li>
<li><strong>导数信息</strong>：GBDT只用了一阶导数信息，Xgboost中对损失函数进行二阶泰勒展开，引入二阶导数信息，并且XGBoost还支持自定义损失函数，只要损失函数一阶和二阶可导即可。</li>
<li><strong>正则项</strong>：Xgboost的目标函数加入正则项(叶子结点的数目和叶子结点权重的L2模的平方)，相当于分裂预剪枝过程，降低过拟合。</li>
<li><strong>列抽样</strong>：Xgboost支持列采样，与随机森林类似，用于防止过拟合且加速。(列采样就是训练的时候随机使用一部分特征)，也同时支持子采样，即每轮迭代计算可以不使用全部样本，对样本数据进行采样。</li>
<li><strong>缺失值处理</strong>：Xgboost可以处理缺失值(具体，查看上方问答)</li>
<li><strong>并行化</strong>：Xgboost可以在特征维度进行并行化，在训练前预先将每个特征按照特征值大小进行预排序，按块的形式存储，后续可以重复使用这个结构，减小计算量，分裂时可以用多线程并行计算每个特征的增益，最终选增益最大的那个特征去做分裂，提高训练速度。</li>
</ol>
<h3 id="8、-XGBoost特征重要性"><a href="#8、-XGBoost特征重要性" class="headerlink" title="8、 XGBoost特征重要性"></a>8、<strong><font color="red"> XGBoost特征重要性</font></strong></h3><blockquote>
<p>  <strong>何时使用shap value分析特征重要性？</strong> -  知乎 <a href="https://www.zhihu.com/question/527570173/answer/2472253431">https://www.zhihu.com/question/527570173/answer/2472253431</a></p>
</blockquote>
<p>这一思路，通常被用来做<strong>特征筛选</strong>。剔除贡献度不高的尾部特征，增强模型的<a href="https://www.zhihu.com/search?q=鲁棒性&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;355884348&quot;}">鲁棒性</a>的同时，起到特征降维的作用。另一个方面，则是用来做<strong>模型的可解释性</strong>。我们期望的结果是：重要的特征是符合业务直觉的；符合业务直觉的特征排名靠前。</p>
<h4 id="XGB内置的三种特征重要性计算方法"><a href="#XGB内置的三种特征重要性计算方法" class="headerlink" title="XGB内置的三种特征重要性计算方法"></a>XGB内置的三种特征重要性计算方法</h4><ul>
<li><strong>weight</strong>：<code>xgb.plot_importance</code>,<strong>子树模型分裂时，用到的特征次数。这里计算的是所有的树。</strong></li>
<li><strong>gain</strong>:<code>model.feature_importances_</code>,信息增益的泛化概念。这里是指，<strong>节点分裂时，该特征带来信息增益（目标函数）优化的平均值。</strong></li>
<li><strong>cover</strong>:<code>model = XGBRFClassifier(importance_type = &#39;cover&#39;)</code> 这个计算方法，需要在定义模型时定义。之后再调用<code>model.feature_importances_</code> 得到的便是基于<code>cover</code>得到的贡献度。<strong>树模型在分裂时，特征下的叶子结点涵盖的样本数除以特征用来分裂的次数。分裂越靠近根部，cover 值越大。</strong></li>
</ul>
<h4 id="其他重要性计算方法"><a href="#其他重要性计算方法" class="headerlink" title="其他重要性计算方法"></a>其他重要性计算方法</h4><ul>
<li><strong>permutation</strong>:<strong>如果这个特征很重要，那么我们打散所有样本中的该特征，则最后的优化目标将折损。这里的折损程度，就是特征的重要程度。</strong></li>
<li><strong>shap</strong>:<strong>轮流去掉每一个特征，算出剩下特征的贡献情况，以此来推导出被去除特征的边际贡献。该方法是目前唯一的逻辑严密的特征解释方法</strong></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8814%EF%BC%89%E8%81%9A%E7%B1%BB*-Kmeans/</url>
    <content><![CDATA[<h2 id="聚类算法-【无监督】"><a href="#聚类算法-【无监督】" class="headerlink" title="聚类算法 【无监督】"></a>聚类算法 【无监督】</h2><blockquote>
<p>  常用聚类算法 - 小胡子的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/104355127">https://zhuanlan.zhihu.com/p/104355127</a></p>
<p>  <strong>K-means, K-medians, K-mediods and K-centers</strong> - 仲基的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/398600714">https://zhuanlan.zhihu.com/p/398600714</a></p>
</blockquote>
<p>什么是聚类算法？聚类是一种机器学习技术，它涉及到数据点的分组。给定一组数据点，我们可以使用聚类算法将每个数据点划分为一个特定的组。理论上，同一组中的数据点应该具有相似的属性和/或特征，而不同组中的数据点应该具有高度不同的属性和/或特征。<strong>聚类是一种无监督学习的方法</strong>，是许多领域中常用的统计数据分析技术。</p>
<p><strong>聚类算法主要包括以下五类：</strong></p>
<ul>
<li><strong>基于分层的聚类（hierarchical methods）</strong></li>
</ul>
<p>这种方法对给定的数据集进行逐层，直到某种条件满足为止。具体可分为合并型的“自下而上”和分裂型的“自下而上”两种方案。如在“自下而上”方案中，初始时每一个数据记录都组成一个单独的组，在接下来的迭代中，它把那些相互邻近的组合并成一个组，直到所有的记录组成一个分组或者某个条件满足为止。<strong>代表算法有：<em>BIRCH算法</em>（1996）、<em>CURE算法</em>、CHAMELEON算法等。</strong></p>
<blockquote>
<p>  层次聚类通过计算不同类别数据点间的相似度来创建一棵有层次的嵌套聚类树。在聚类树中，不同类别的原始数据点是树的最低层，树的顶层是一个聚类的根节点。</p>
<p>  <strong>最小距离的层次聚类算法</strong>通过自下而上合并创建聚类树，合并算法通过计算两类数据点间的欧式距离来计算不同类别数据点间的相似度，对所有数据点中最为相似的两个数据点进行组合，组合后，最小距离（Single Linkage）的计算方法是将两个组合数据点中距离最近的两个数据点间的距离作为这两个组合数据点的距离。并反复迭代这一过程。</p>
</blockquote>
<ul>
<li><strong>基于划分的聚类（partitioning methods）</strong></li>
</ul>
<p>给定一个有N个记录的数据集，分裂法将构造K个分组，每一个分组就代表一个聚类，K&lt;N,而且这K个分组满足下列条件：（1）每一个分组至少包含一个数据记录；（2）每一个数据记录属于且仅属于一个分组（咋某些模糊聚类算法中可以放宽条件）。对于给定的K，算法首先给出一个初始的分组方法，以后通过反复迭代的方法改变分组，使得每一次改进之后的分组方案都较前一次好，而所谓好的标准是：同一分组中的记录越近越好，而不同分组中的记录越远越好。使用这个基本思想的算法有：<strong><em>==K-means算法==</em>、<em>K-medoids算法</em>、<em>CLARANS算法</em></strong></p>
<ul>
<li><strong>基于密度的聚类（density-based methods）</strong></li>
</ul>
<p>基于密度的方法和其他方法的一个根本区别是：它不是基于各种各样的距离的，而是基于魔都的，这样就能克服基于距离的算法只能发现“类圆形”的聚类的缺点。这个方法的指导思想为：只要一个区域的点的密度大过某个阈值，就把它加到与之相近的聚类中去，代表算法有<strong>：<em>==DBSCAN（Density-Based Spatial Clustering of Applic with Noise）==算法（1996）</em>、<em>OPTICS（Ordering Points to Identify Clustering Structure）算法（1999）</em>、<em>DENCLUE算法（1998）</em>、<em>WaveCluster算法（1998，具有O（N）时间复杂性，但只适用于低维数据）</em></strong></p>
<ul>
<li><strong>基于网格的聚类（grid-based methods）</strong></li>
</ul>
<p>这种方法首先将数据空间划分成为有限个单元（cell）的网络结构，所有的处理都是以单个的单元为对象的。这么处理的一个突出的优点就是处理速度很快，通常这是与目标数据库中记录的个数无关，它只与把数据空间分成多少个单元有关。代表算法有：<strong><em>STING（Statistical Information Grid）</em>、<em>CLIQUE（Clustering In Quest）算法（1998）</em>、<em>WaveCluster算法</em>。</strong>其中STRING算法把数据空间层次地划分为单元格，依赖于存储在网格单元中的统计信息进行聚类；CLIQUE算法结合了密度和网格的方法。</p>
<ul>
<li><strong>基于模型的聚类（model-based methods）</strong></li>
</ul>
<p>基于模型的方法给每一个聚类假定一个模型，然后去寻找能够很好地满足这个模型的数据集。这样一个模型可能是数据点在空间中的密度分布函数或者其它。它的一个潜在的假定就是：目标数据集是由一系列的概率分布所决定的。通常有两种尝试方向：统计的方案和神经网络的方案。</p>
<h2 id="一、K-means-【基于划分】-K值的选择？"><a href="#一、K-means-【基于划分】-K值的选择？" class="headerlink" title="一、K-means 【基于划分】[==K值的选择？==]"></a>一、K-means 【基于划分】[==K值的选择？==]</h2><p><img src="https://pic1.zhimg.com/v2-e7195b6620e2e6ec743fb77702b1d3ff_1440w.jpg?source=172ae18b" alt="【机器学习】K-means（非常详细）" style="zoom:51%;"></p>
<blockquote>
<p>  K-means 聚类的迭代算法实际上是 EM 算法。EM 算法解决的是在概率模型中含有无法观测的隐含变量情况下的参数估计问题。在 K-means 中的隐变量是每个类别所属类别。</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/20463356">K-means 笔记（三）数学原理</a></li>
<li><a href="https://link.zhihu.com/?target=http%3A//sofasofa.io/forum_main_post.php%3Fpostid%3D1000282">K-means 怎么选 K?</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/161733843">K-Means：隐变量、聚类、EM</a></li>
</ol>
</blockquote>
<p>k近邻法中，当<strong>训练集</strong>、<strong>距离度量</strong>、<strong>K值</strong>以及<strong>分类决策规则</strong>确定后，对于任何一个新的输入实例，它所属的类唯一地确定。这相当于根据上述要素将特征空间划分为一些子空间，确定子空间里的每个点所属的类。</p>
<p><strong>K-均值是一个迭代算法，假设我们想要将数据聚类成 n 个组，其方法为:</strong></p>
<ul>
<li>首先选择𝐾个<strong>随机</strong>的点，称为<strong>聚类中心</strong>（cluster centroids）；</li>
<li>对于数据集中的每一个数据，按照<strong>距离𝐾个中心点的距离</strong>，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类。</li>
<li>计算每一个组的平均值，将该组所<strong>关联的中心点移动到平均值</strong>的位置。</li>
<li>重复步骤，直至中心点不再变化。</li>
</ul>
<p>K-均值算法也可以很便利地用于将数据分为许多不同组，即使在没有非常明显区分的组群的情况下也可以。下图所示的数据集包含身高和体重两项特征构成的，利用 K-均值算法将数据分为三类，用于帮助确定将要生产的 T-恤衫的三种尺寸。</p>
<p><img src="https://camo.githubusercontent.com/86b1cfa2d801f27862bcc8cab59f04401e01defd5248311eb77ec75a02286c5f/687474703a2f2f7778332e73696e61696d672e636e2f6d773639302f30303633304465666c79316735623734367a776a676a33306668306337676e6a2e6a7067" alt="img" style="zoom: 50%;"></p>
<h3 id="1-1-损失函数"><a href="#1-1-损失函数" class="headerlink" title="1.1 损失函数"></a>1.1 损失函数</h3><p><strong>K-均值最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和</strong>，因此 <strong>K-均值的代价函数（又称==畸变函数 Distortion function）==为</strong>：</p>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20220707191400653.png" alt="image-20220707191400653" style="zoom:50%;"></p>
<p>其中 <a href="https://camo.githubusercontent.com/c0d78bacde143a412a432d0f2c8d1a746fc34802fec6dfd079a07708e30a98f4/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f755f25374263253545253742286929253744253744"><img src="https://camo.githubusercontent.com/c0d78bacde143a412a432d0f2c8d1a746fc34802fec6dfd079a07708e30a98f4/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f755f25374263253545253742286929253744253744" alt="img"></a>代表与 <a href="https://camo.githubusercontent.com/b14a6424262c05d4fb45a600d8fb5b4881cee4801e8699dcc0c58ef503164f94/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f78253545253742286929253744"><img src="https://camo.githubusercontent.com/b14a6424262c05d4fb45a600d8fb5b4881cee4801e8699dcc0c58ef503164f94/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f78253545253742286929253744" alt="img"></a>最近的聚类中心点。 我们的的优化目标便是找出使得代价函数最小的 <a href="https://camo.githubusercontent.com/c48ec5ec6d35ce0993ee193bc86c0d4eddb3dbac31e30fa1f38fbf56b1401083/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f632535452537422831292537442c632535452537422832292537442c2e2e2e2c63253545253742286d29253744"><img src="https://camo.githubusercontent.com/c48ec5ec6d35ce0993ee193bc86c0d4eddb3dbac31e30fa1f38fbf56b1401083/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f632535452537422831292537442c632535452537422832292537442c2e2e2e2c63253545253742286d29253744" alt="img"></a>和 <a href="https://camo.githubusercontent.com/d287d301a22d8bb905fe7e82874a282adff45c972a158b7a2cb91f0354a4ae84/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f755f312c755f322c2e2e2e2c755f6b"><img src="https://camo.githubusercontent.com/d287d301a22d8bb905fe7e82874a282adff45c972a158b7a2cb91f0354a4ae84/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f755f312c755f322c2e2e2e2c755f6b" alt="img"></a>。</p>
<h3 id="1-2-k值的选择-【肘部法则】"><a href="#1-2-k值的选择-【肘部法则】" class="headerlink" title="1.2 k值的选择 【肘部法则】"></a>1.2 k值的选择 【肘部法则】</h3><p>在运行 K-均值算法的之前，我们首先要随机初始化所有的聚类中心点，下面介绍怎样做：</p>
<ol>
<li>我们应该选择𝐾 &lt; 𝑚，即聚类中心点的个数要小于所有训练集实例的数量。</li>
<li>随机选择𝐾个训练实例，然后令𝐾个聚类中心分别与这𝐾个训练实例相等K-均值的一个问题在于，它有可能会<strong>停留在一个局部最小值</strong>处，而这取决于初始化的情况。</li>
</ol>
<p>为了解决这个问题，我们通常需要多次运行 K-均值算法，每一次都重新进行随机初始化，最后再比较多次运行 K-均值的结果，选择代价函数最小的结果。这种方法在𝐾较小的时候（2—10）还是可行的，<strong>但是如果𝐾较大，这么做也可能不会有明显地改善。</strong></p>
<p>没有所谓最好的选择聚类数的方法，通常是需要根据不同的问题，人工进行选择的。选择的时候思考我们运用 K-均值算法聚类的动机是什么。有一个可能会谈及的方法叫作<strong>“肘部法则”</strong>。关 于“肘部法则”，我们所需要做的是改变𝐾值，也就是聚类类别数目的总数。我们用一个聚类来运行 K 均值聚类方法。这就意味着，所有的数据都会分到一个聚类里，然后<strong>计算成本函数或者计算畸变函数</strong>𝐽。𝐾代表聚类数字。</p>
<p><a href="https://camo.githubusercontent.com/8888198abee1b3069d27a6bff19f1830a94ac4141ebe7dd300f8ee4000262c6d/687474703a2f2f7778322e73696e61696d672e636e2f6d773639302f30303633304465666c7931673562377062616561766a3330716f3063777463392e6a7067"><img src="https://camo.githubusercontent.com/8888198abee1b3069d27a6bff19f1830a94ac4141ebe7dd300f8ee4000262c6d/687474703a2f2f7778322e73696e61696d672e636e2f6d773639302f30303633304465666c7931673562377062616561766a3330716f3063777463392e6a7067" alt="img"></a></p>
<p>我们可能会得到一条类似于这样的曲线。像一个人的肘部。这就是“肘部法则”所做的，让我们来看这样一个图，看起来就好像有一个很清楚的肘在那儿。你会发现这种模式，它的畸变值会迅速下降，从 1 到 2，从 2 到 3 之后，你会在 3 的时候达到一个肘点。在此之后，畸变值就下降的非常慢，看起来就像使用 3 个聚类来进行聚类是正确的，<strong>这是因为那个点是曲线的肘点，畸变值下降得很快，𝐾 = 3之后就下降得很慢，那么我们就选𝐾 = 3。</strong>当你应用“肘部法则”的时候，如果你得到了一个像上面这样的图，那么这将是一种用来选择聚类个数的合理方法。</p>
<h3 id="1-3-KNN与K-means区别？"><a href="#1-3-KNN与K-means区别？" class="headerlink" title="1.3 KNN与K-means区别？"></a>1.3 KNN与K-means区别？</h3><p>K最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。</p>
<h4 id="区别："><a href="#区别：" class="headerlink" title="区别："></a>区别：</h4><div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>KNN</th>
<th>K-Means</th>
</tr>
</thead>
<tbody>
<tr>
<td>类别</td>
<td>1.KNN是<strong>分类</strong>算法 2.属于<strong>监督学习</strong> 3.训练数据集是带label的数据</td>
<td>1.K-Means是<strong>聚类</strong>算法 2.属于<strong>非监督学习</strong> 3.训练数据集是无label的数据，是杂乱无章的，经过聚类后变得有序，先无序，后有序。</td>
</tr>
<tr>
<td></td>
<td>没有明显的前期训练过程，属于memory based learning</td>
<td>有明显的前期训练过程</td>
</tr>
<tr>
<td>k值的含义</td>
<td>K的含义：一个样本x，对它进行分类，就从训练数据集中，<strong>在x附近找离它最近的K个数据点</strong>，这K个数据点，类别c占的个数最多，就把x的label设为c。</td>
<td>K的含义：<strong>K是人工固定好的数字，假设数据集合可以分为K个蔟</strong>，那么就利用训练数据来训练出这K个分类。</td>
</tr>
</tbody>
</table>
</div>
<h4 id="相似点："><a href="#相似点：" class="headerlink" title="相似点："></a><strong>相似点</strong>：</h4><p>都包含这样的过程，给定一个点，在数据集中找离它最近的点。即二者都用到了NN(Nears Neighbor)算法思想。</p>
<h3 id="1-4-K-Means优缺点及改进"><a href="#1-4-K-Means优缺点及改进" class="headerlink" title="1.4 K-Means优缺点及改进"></a>1.4 K-Means优缺点及改进</h3><p>k-means：在大数据的条件下，<strong>会耗费大量的时间和内存</strong>。 优化k-means的建议：</p>
<ol>
<li><p>减少聚类的数目K。因为，每个样本都要跟类中心计算距离。</p>
</li>
<li><p>减少样本的特征维度。比如说，<strong>通过PCA等进行降维</strong>。</p>
</li>
<li><p>考察其他的聚类算法，通过选取toy数据，去测试不同聚类算法的性能。</p>
</li>
<li><p><strong>hadoop集群</strong>，K-means算法是很容易进行并行计算的。</p>
</li>
<li><p>算法可能找到局部最优的聚类，而不是全局最优的聚类。使用改进的二分k-means算法。</p>
<p>二分k-means算法：首先将整个数据集看成一个簇，然后进行一次k-means（k=2）算法将该簇一分为二，并计算每个簇的误差平方和，选择平方和最大的簇迭代上述过程再次一分为二，直至簇数达到用户指定的k为止，此时可以达到的全局最优。</p>
</li>
</ol>
<h3 id="二、K-means的调优与改进"><a href="#二、K-means的调优与改进" class="headerlink" title="二、K - means的调优与改进"></a>二、K - means的调优与改进</h3><p>针对 K-means 算法的缺点，我们可以有很多种调优方式：如<strong>数据预处理</strong>（去除异常点），<strong>合理选择 K 值</strong>，<strong>高维映射</strong>等。以下将简单介绍：</p>
<h3 id="2-1-数据预处理"><a href="#2-1-数据预处理" class="headerlink" title="2.1 数据预处理"></a>2.1 数据预处理</h3><p>K-means 的本质是基于欧式距离的数据划分算法，均值和方差大的维度将对数据的聚类产生决定性影响。所以<strong>未做归一化处理和统一单位的数据是无法直接参与运算和比较</strong>的。常见的数据预处理方式有：<strong>数据归一化，数据标准化</strong>。</p>
<p>此外，离群点或者噪声数据会对均值产生较大的影响，导致中心偏移，因此我们还需要对数据进行异常点检测。</p>
<h3 id="2-2-合理选择-K-值"><a href="#2-2-合理选择-K-值" class="headerlink" title="2.2 合理选择 K 值"></a>2.2 合理选择 K 值</h3><p>K 值的选取对 K-means 影响很大，这也是 K-means 最大的缺点，常见的选取 K 值的方法有：<strong>手肘法、Gap statistic 方法</strong>。</p>
<p><strong>【手肘法】</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-5ca4a5fe0b06b25a2b97262abb401a16_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>当 K &lt; 3 时，曲线急速下降；当 K &gt; 3 时，曲线趋于平稳，通过手肘法我们认为拐点 3 为 K 的最佳值。</p>
<p>==【<strong>Gap statistic</strong>】==</p>
<p><img src="https://www.zhihu.com/equation?tex=Gap%28K%29%3D%5Ctext%7BE%7D%28%5Clog+D_k%29-%5Clog+D_k+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=D_k" alt="[公式]"> 为损失函数，这里 <img src="https://www.zhihu.com/equation?tex=E%28logD_k%29" alt="[公式]"> 指的是 <img src="https://www.zhihu.com/equation?tex=logD_k" alt="[公式]"> 的期望。这个数值通常通过<strong>蒙特卡洛模拟</strong>产生，我们在样本里所在的区域中按照<strong>均匀分布随机产生和原始样本数一样多的随机样本</strong>，并对这个<strong>随机样本做 K-Means</strong>，从而得到一个 <img src="https://www.zhihu.com/equation?tex=D_k+" alt="[公式]"> 。如此往复多次，通常 20 次，我们可以得到 20 个 <img src="https://www.zhihu.com/equation?tex=logD_k" alt="[公式]"> 。对这 20 个数值求平均值，就得到了 <img src="https://www.zhihu.com/equation?tex=E%28logD_k%29" alt="[公式]">  的近似值。最终可以计算 Gap Statisitc。而 Gap statistic 取得最大值所对应的 K 就是最佳的 K。</p>
<p><img src="https://pic3.zhimg.com/80/v2-9a39a8dad143e5dd52a506d83c2cbb36_1440w.jpg" alt="img"></p>
<p>由图可见，当 K=3 时，Gap(K) 取值最大，所以最佳的簇数是 K=3。</p>
<p>Github 上一个项目叫 <a href="https://link.zhihu.com/?target=https%3A//github.com/milesgranger/gap_statistic">gap_statistic</a> ，可以更方便的获取建议的类簇个数。</p>
<h3 id="2-3-采用核函数"><a href="#2-3-采用核函数" class="headerlink" title="2.3 采用核函数"></a>2.3 采用核函数</h3><p><strong>基于欧式距离的 K-means 假设了了各个数据簇的数据具有一样的的先验概率并呈现球形分布</strong>，但这种分布在实际生活中并不常见。面对非凸的数据分布形状时我们可以引入核函数来优化，这时算法又称为核 K-means 算法，是核聚类方法的一种。<strong>核聚类方法的主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的特征空间中进行聚类。</strong>非线性映射增加了数据点线性可分的概率，从而在经典的聚类算法失效的情况下，通过引入核函数可以达到更为准确的聚类结果。</p>
<h3 id="2-4-K-means"><a href="#2-4-K-means" class="headerlink" title="==2.4 K-means++=="></a>==2.4 K-means++==</h3><blockquote>
<p>  <strong>K-means++ 就是选择离已选中心点最远的点</strong>。这也比较符合常理，聚类中心当然是互相离得越远越好。</p>
</blockquote>
<p>我们知道初始值的选取对结果的影响很大，对初始值选择的改进是很重要的一部分。在所有的改进算法中，K-means++ 最有名。</p>
<p>K-means++ 算法步骤如下所示：</p>
<ol>
<li>随机选取一个中心点 <img src="https://www.zhihu.com/equation?tex=a_1" alt="[公式]"> ；</li>
<li>计算数据到之前 n 个聚类中心最远的距离 <img src="https://www.zhihu.com/equation?tex=D%28x%29" alt="[公式]"> ，并以一定概率 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7BD%28x%29%5E2%7D%7B%5Csum%7BD%28x%29%5E2%7D%7D" alt="[公式]"> 选择新中心点 <img src="https://www.zhihu.com/equation?tex=a_i" alt="[公式]"> ；</li>
<li>重复第二步。</li>
</ol>
<p>简单的来说，就是 <strong>K-means++ 就是选择离已选中心点最远的点</strong>。这也比较符合常理，聚类中心当然是互相离得越远越好。</p>
<p>但是这个算法的缺点在于，难以并行化。所以 k-means II 改变取样策略，并非按照 k-means++ 那样每次遍历只取样一个样本，而是每次遍历取样 k 个，重复该取样过程 <img src="https://www.zhihu.com/equation?tex=log%28n+%29" alt="[公式]"> 次，则得到 <img src="https://www.zhihu.com/equation?tex=klog%28n%29" alt="[公式]"> 个样本点组成的集合，然后从这些点中选取 k 个。当然一般也不需要 <img src="https://www.zhihu.com/equation?tex=log%28n%29" alt="[公式]"> 次取样，5 次即可。</p>
<h3 id="2-5-ISODATA"><a href="#2-5-ISODATA" class="headerlink" title="2.5 ISODATA"></a>2.5 ISODATA</h3><p>ISODATA 的全称是<strong>迭代自组织数据分析法</strong>。它解决了 K 的值需要预先人为的确定这一缺点。而当遇到高维度、海量的数据集时，人们往往很难准确地估计出 K 的大小。ISODATA 就是针对这个问题进行了改进，它的思想也很直观：当属于某个类别的样本数过少时把这个类别去除，当属于某个类别的样本数过多、分散程度较大时把这个类别分为两个子类别。</p>
<h3 id="三、-收敛证明【EM算法】"><a href="#三、-收敛证明【EM算法】" class="headerlink" title="==三、 收敛证明【EM算法】=="></a>==三、 收敛证明【EM算法】==</h3><p>我们先来看一下 K-means 算法的步骤：先随机选择初始节点，然后计算每个样本所属类别，然后通过类别再跟新初始化节点。这个过程有没有想到之前介绍的 <a href="https://zhuanlan.zhihu.com/p/78311644">EM 算法</a> 。</p>
<p>我们需要知道的是 K-means 聚类的迭代算法实际上是 EM 算法。EM 算法解决的是在概率模型中含有无法观测的隐含变量情况下的参数估计问题。在 <strong>==K-means 中的隐变量是每个样本所属类别==</strong>。</p>
<p>K-means 算法迭代步骤中的每次确认中心点以后重新进行标记对应 EM 算法中的 <strong>E 步</strong>：<strong>求当前参数条件下的 Expectation</strong>。而根据标记重新求中心点 对应 EM 算法中的 <strong>M 步</strong>：<strong>求似然函数最大化时（损失函数最小时）对应的参数 。</strong></p>
<p>首先我们看一下损失函数的形式：</p>
<p><img src="https://www.zhihu.com/equation?tex=J%3D%5Csum_%7Bi%3D1%7D%5E%7BC%7D%7B%5Csum_%7Bj%3D1%7D%5E%7BN%7D%7Br_%7Bij%7D%5Ccdot+%7B%5Cnu%28x_j%2C%7B%5Cmu%7D_i%29%7D%7D%7D+%5C%5C" alt="[公式]"></p>
<p>其中：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cnu%28%7Bx_j%7D%2C%5Cmu_i%29%3D%7B%7C%7Cx_j-%7B%5Cmu%7D_i%7C%7C%7D%5E%7B2%7D+%2C%5Cquad++%7Br%7D_%7Bnk%7D%3D%5Cleft+%5C%7B+%5Cbegin%7Baligned%7D+%261+%5Cquad+if+%5C%3B+x_n+%5Cin+k+%5C%5C+%260+%5Cquad+else+%5Cend%7Baligned%7D+%5Cright.+%5C%5C" alt="[公式]"></p>
<p>为了求极值，我们令损失函数求偏导数且等于 0：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%7BJ%7D%7D%7B%5Cpartial+%5Cmu_k%7D%3D2+%5Csum_%7Bi%3D1%7D%5E%7BN%7D%7Br_%7Bik%7D%28x_i-%7B%5Cmu%7D_%7Bk%7D%29%7D%3D0+%5C%5C" alt="[公式]"></p>
<p>k 是指第 k 个中心点，于是我们有：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cmu_k%3D%5Cfrac%7B%5Csum_%7Bi%3D1%7D%5E%7BN%7D%7Br_%7Bik%7Dx_i%7D%7D%7B%5Csum_%7Bi%3D1%7D%5E%7BN%7D%7Br_%7Bik%7D%7D%7D+%5C%5C" alt="[公式]"></p>
<p>可以看出，新的中心点就是所有该类的<strong>质心</strong>。</p>
<p><strong>EM 算法的缺点就是，容易陷入局部极小值，这也是 K-means 有时会得到局部最优解的原因。</strong></p>
<h3 id="四、高斯混合模型-GMM"><a href="#四、高斯混合模型-GMM" class="headerlink" title="四、高斯混合模型(GMM)"></a>四、高斯混合模型(GMM)</h3><h3 id="4-1-GMM的思想"><a href="#4-1-GMM的思想" class="headerlink" title="4.1 GMM的思想"></a>4.1 GMM的思想</h3><p>高斯混合模型（Gaussian Mixed Model，GMM）也是一种常见的聚类算法，与K均值算法类似，同样使用了EM算法进行迭代计算。<strong>高斯混合模型假设每个簇的数据都是符合高斯分布（又叫正态分布）的</strong>，当前<strong>数据呈现的分布就是各个簇的高斯分布叠加在一起的结果。</strong></p>
<p>第一张图是一个数据分布的样例，如果只用一个高斯分布来拟合图中的数据，图 中所示的椭圆即为高斯分布的二倍标准差所对应的椭圆。直观来说，图中的数据 明显分为两簇，因此只用一个高斯分布来拟和是不太合理的，需要推广到用多个 高斯分布的叠加来对数据进行拟合。第二张图是用两个高斯分布的叠加来拟合得到的结果。<strong>这就引出了高斯混合模型，即用多个高斯分布函数的线形组合来对数据分布进行拟合。</strong>理论上，高斯混合模型可以拟合出任意类型的分布。</p>
<p>高斯混合模型的核心思想是，假设数据可以看作从多个高斯分布中生成出来 的。在该假设下，每个单独的分模型都是标准高斯模型，其均值 $u_i$ 和方差 $\sum_i$ 是待估计的参数。此外，每个分模型都还有一个参数 $\pi_i$，可以理解为权重或生成数据的概 率。高斯混合模型的公式为：</p>
<p><a href="https://camo.githubusercontent.com/4055f35cd39fe2e095b0fc70f8cccb1e3cab924a2ebd6bc56ca7bdcf026c79ec/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f702878293d25354373756d5f253742693d312537442535452537426b25374425354370695f694e2878253743755f692c25354373756d5f6929"><img src="https://camo.githubusercontent.com/4055f35cd39fe2e095b0fc70f8cccb1e3cab924a2ebd6bc56ca7bdcf026c79ec/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f702878293d25354373756d5f253742693d312537442535452537426b25374425354370695f694e2878253743755f692c25354373756d5f6929" alt="img"></a></p>
<p>通常我们并不能直接得到高斯混合模型的参数，而是观察到了一系列 数据点，给出一个类别的数量K后，希望求得最佳的K个高斯分模型。因此，<strong>高斯混合模型的计算，便成了最佳的均值μ，方差Σ、权重π的寻找</strong>，这类问题通常通过最大似然估计来求解。遗憾的是，此问题中直接使用最大似然估计，得到的是一个复杂的非凸函数，目标函数是和的对数，难以展开和对其求偏导。</p>
<p><strong>在这种情况下，可以用EM算法。 </strong>EM算法是在最大化目标函数时，先固定一个变量使整体函数变为凸优化函数，求导得到最值，然后利用最优参数更新被固定的变量，进入下一个循环。具体到高 斯混合模型的求解，EM算法的迭代过程如下。</p>
<p>首先，初始随机选择各参数的值。然后，重复下述两步，直到收敛。</p>
<ul>
<li>E步骤。根据当前的参数，计算每个点由某个分模型生成的概率。</li>
<li>M步骤。使用E步骤估计出的概率，来改进每个分模型的均值，方差和权重。</li>
</ul>
<blockquote>
<p>  高斯混合模型是一个生成式模型。可以这样理解数据的生成过程，假设一个最简单的情况，即只有两个一维标准高斯分布的分模型<em>N</em>(0,1)和<em>N</em>(5,1)，其权重分别为0.7和0.3。那么，在生成第一个数据点时，先按照权重的比例，随机选择一个分布，比如选择第一个高斯分布，接着从<em>N</em>(0,1)中生成一个点，如−0.5，便是第一个数据点。在生成第二个数据点时，随机选择到第二个高斯分布<em>N</em>(5,1)，生成了第二个点4.7。如此循环执行，便生成出了所有的数据点。</p>
</blockquote>
<p>也就是说，我们并不知道最佳的K个高斯分布的各自3个参数，也不知道每个 数据点究竟是哪个高斯分布生成的。所以每次循环时，先固定当前的高斯分布不 变，获得每个数据点由各个高斯分布生成的概率。然后固定该生成概率不变，根据数据点和生成概率，获得一个组更佳的高斯分布。循环往复，直到参数的不再变化，或者变化非常小时，便得到了比较合理的一组高斯分布。</p>
<h3 id="4-2-GMM与K-Means相比"><a href="#4-2-GMM与K-Means相比" class="headerlink" title="4.2 GMM与K-Means相比"></a>4.2 GMM与K-Means相比</h3><p>高斯混合模型与K均值算法的相同点是：</p>
<ul>
<li><strong>都需要指定K值</strong>；</li>
<li><strong>都是使用EM算法来求解</strong>；</li>
<li>都往往只能收敛于局部最优。</li>
</ul>
<p>而它相比于K 均值算法的优点是，可以给出一个样本属于某类的<strong>概率</strong>是多少；不仅仅可以用于聚类，还可以用于概率密度的估计；<strong>并且可以用于生成新的样本点</strong>。</p>
<h3 id="五、聚类算法如何评估"><a href="#五、聚类算法如何评估" class="headerlink" title="五、聚类算法如何评估"></a>五、聚类算法如何评估</h3><p>由于数据以及需求的多样性，没有一种算法能够适用于所有的数据类型、数据簇或应用场景，似乎每种情况都可能需要一种不同的评估方法或度量标准。例 如，K均值聚类可以用<strong>误差平方</strong>和来评估，但是基于密度的数据簇可能不是球形， 误差平方和则会失效。在许多情况下，判断聚类算法结果的好坏强烈依赖于主观解释。尽管如此，聚类算法的评估还是必需的，它是聚类分析中十分重要的部分之一。</p>
<p>聚类评估的任务是估计在数据集上进行聚类的可行性，以及聚类方法产生结 果的质量。这一过程又分为三个子任务。</p>
<ol>
<li><p><strong>估计聚类趋势。</strong></p>
<p>这一步骤是检测数据分布中是否存在非随机的簇结构。如果数据是基本随机 的，那么聚类的结果也是毫无意义的。我们可以观察聚类误差是否随聚类类别数 量的增加而单调变化，如果数据是基本随机的，即不存在非随机簇结构，那么聚 类误差随聚类类别数量增加而变化的幅度应该较不显著，并且也找不到一个合适 的K对应数据的真实簇数。</p>
</li>
<li><p><strong>判定数据簇数。</strong></p>
<p>确定聚类趋势之后，我们需要找到与真实数据分布最为吻合的簇数，据此判定聚类结果的质量。数据簇数的判定方法有很多，例如<strong>手肘法</strong>和<strong>Gap Statistic</strong>方 法。需要说明的是，用于评估的最佳数据簇数可能与程序输出的簇数是不同的。 例如，有些聚类算法可以自动地确定数据的簇数，但可能与我们通过其他方法确定的最优数据簇数有所差别。</p>
</li>
<li><p><strong>测定聚类质量。</strong></p>
<p>在无监督的情况下，我们可以通过考察簇的分离情况和簇的紧凑情况来评估聚类的效果。定义评估指标可以展现面试者实际解决和分析问题的能力。事实上测量指标可以有很多种，以下列出了几种常用的度量指标，更多的指标可以阅读相关文献。</p>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8812%EF%BC%89%E9%99%8D%E7%BB%B4/</url>
    <content><![CDATA[<h2 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h2><blockquote>
<ul>
<li>数据降维算法: <a href="https://www.zhihu.com/column/c_1194552337170214912">https://www.zhihu.com/column/c_1194552337170214912</a></li>
</ul>
</blockquote>
<p><img src="https://pic2.zhimg.com/v2-e47296e78fff3d97eea11d0657ddcb81_1440w.jpg?source=172ae18b" alt="【机器学习】降维——PCA（非常详细）" style="zoom:51%;"></p>
<h2 id="一、PCA"><a href="#一、PCA" class="headerlink" title="一、PCA"></a>一、PCA</h2><blockquote>
<p>  <strong><font color="red"> 降维问题的优化目标：将一组 N 维向量降为 K 维，其目标是选择 K 个单位正交基，使得原始数据变换到这组基上后，各变量两两间协方差为 0，而变量方差则尽可能大（在正交的约束下，取最大的 K 个方差）。</font></strong></p>
<p>  要找的 <strong>==P 是能让原始协方差矩阵对角化的 P==</strong>。换句话说，优化目标变成了<strong>寻找一个矩阵 P，满足</strong> <img src="https://www.zhihu.com/equation?tex=PCP%5ET" alt="[公式]"> <strong>是一个对角矩阵，并且对角元素按从大到小依次排列，那么 P 的前 K 行就是要寻找的基，用 P 的前 K 行组成的矩阵乘以 X 就使得 X 从 N 维降到了 K 维并满足上述优化条件</strong>。</p>
</blockquote>
<p><strong>PCA（Principal Component Analysis） 是一种常见的数据分析方式，常用于高维数据的降维，可用于提取数据的主要特征分量</strong>。PCA 的数学推导可以从<strong>==最大可分型==</strong>和<strong>最近重构性</strong>两方面进行，前者的优化条件为划分后方差最大，后者的优化条件为点到划分平面距离最小，这里我将从最大可分性的角度进行证明。</p>
<h3 id="1-向量表示与基变换"><a href="#1-向量表示与基变换" class="headerlink" title="1. 向量表示与基变换"></a>1. 向量表示与基变换</h3><p>我们先来介绍些线性代数的基本知识。</p>
<h3 id="1-1-内积"><a href="#1-1-内积" class="headerlink" title="1.1 内积"></a>1.1 内积</h3><p><strong>两个向量的 A 和 B 内积</strong>我们知道形式是这样的：</p>
<p><img src="https://www.zhihu.com/equation?tex=%28a_1%2Ca_2%2C%5Ccdots%2Ca_n%29%5Ccdot+%28b_1%2Cb_2%2C%5Ccdots%2Cb_n%29%5E%5Cmathsf%7BT%7D%3Da_1b_1%2Ba_2b_2%2B%5Ccdots%2Ba_nb_n+%5C%5C" alt="[公式]"></p>
<p>内积运算将两个向量映射为实数，其计算方式非常容易理解，但我们无法看出其物理含义。接下来我们从几何角度来分析，为了简单起见，我们假设 A 和 B 均为二维向量，则：</p>
<p><img src="https://www.zhihu.com/equation?tex=A%3D%28x_1%2Cy_1%29%EF%BC%8CB%3D%28x_2%2Cy_2%29+%5C+A+%5Ccdot+B+%3D+%7CA%7C%7CB%7Ccos%28%5Calpha%29+%5C%5C" alt="[公式]"></p>
<p>其几何表示见下图：</p>
<p><img src="https://pic3.zhimg.com/80/v2-cf4c0041c8459d2894b9a57d8f679a0a_1440w.jpg" alt="img"></p>
<p>我们看出 A 与 B 的内积等于 <strong>A 到 B 的投影长度乘以 B 的模</strong>。</p>
<p>如果假设 B 的模为 1，即让 <img src="https://www.zhihu.com/equation?tex=%7CB%7C%3D1" alt="[公式]"> ，那么就变成了：</p>
<p><img src="https://www.zhihu.com/equation?tex=A%5Ccdot+B%3D%7CA%7Ccos%28a%29+%5C%5C" alt="[公式]"></p>
<p>也就是说，<strong>A 与 B 的内积值等于 A 向 B 所在直线投影的标量大小。</strong></p>
<h3 id="1-2-基"><a href="#1-2-基" class="headerlink" title="1.2 基"></a>1.2 基</h3><p>在我们常说的坐标系种，向量 (3,2) 其实隐式引入了一个定义：以 x 轴和 y 轴上正方向长度为 1 的向量为标准。向量 (3,2) 实际是说在 x 轴投影为 3 而 y 轴的投影为 2。<strong>注意投影是一个标量，所以可以为负。</strong></p>
<p>所以，对于向量 (3, 2) 来说，如果我们想求它在 <img src="https://www.zhihu.com/equation?tex=%281%2C0%29%2C%280%2C1%29" alt="[公式]"> 这组基下的坐标的话，分别内积即可。当然，内积完了还是 (3, 2)。</p>
<p>所以，我们大致可以得到一个结论，我们<strong>要准确描述向量，首先要确定一组基，然后给出在基所在的各个直线上的投影值，就可以了</strong>。为了方便求坐标，我们希望这组基向量模长为 1。因为向量的内积运算，当模长为 1 时，内积可以直接表示投影。然后还需要这组基是线性无关的，我们一般用正交基，非正交的基也是可以的，不过正交基有较好的性质。</p>
<h3 id="1-3-基变换的矩阵表示"><a href="#1-3-基变换的矩阵表示" class="headerlink" title="1.3 基变换的矩阵表示"></a>1.3 基变换的矩阵表示</h3><p>这里我们先做一个练习：对于向量 (3,2) 这个点来说，在 <img src="https://www.zhihu.com/equation?tex=%28%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%2C%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%29" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%28-%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%2C+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%29" alt="[公式]"> 这组基下的坐标是多少？</p>
<p>我们拿 (3,2) 分别与之内积，得到 <img src="https://www.zhihu.com/equation?tex=%28%5Cfrac%7B5%7D%7B%5Csqrt%7B2%7D%7D%2C-%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%29" alt="[公式]"> 这个新坐标。</p>
<p>我们可以用矩阵相乘的形式简洁的表示这个变换：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bpmatrix%7D++1%2F%5Csqrt%7B2%7D+%26+1%2F%5Csqrt%7B2%7D+%5C%5C+-1%2F%5Csqrt%7B2%7D+%26+1%2F%5Csqrt%7B2%7D+%5Cend%7Bpmatrix%7D+%5Cbegin%7Bpmatrix%7D+3+%5C%5C+2+%5Cend%7Bpmatrix%7D+%3D+%5Cbegin%7Bpmatrix%7D+5%2F%5Csqrt%7B2%7D+%5C%5C+-1%2F%5Csqrt%7B2%7D++%5Cend%7Bpmatrix%7D++%5C%5C" alt="[公式]"></p>
<p>左边矩阵的两行分别为两个基，乘以原向量，其结果刚好为新基的坐标。推广一下，如果我们有 m 个二维向量，只要将二维向量按列排成一个两行 m 列矩阵，然后用“基矩阵”乘以这个矩阵就可以得到了所有这些向量在新基下的值。例如对于数据点 <img src="https://www.zhihu.com/equation?tex=%281%2C1%29%EF%BC%8C%282%2C2%29%EF%BC%8C%283%2C3%29" alt="[公式]"> 来说，想变换到刚才那组基上，则可以这样表示：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bpmatrix%7D+1%2F%5Csqrt%7B2%7D+%26+1%2F%5Csqrt%7B2%7D+%5C%5C+-1%2F%5Csqrt%7B2%7D+%26+1%2F%5Csqrt%7B2%7D+%5Cend%7Bpmatrix%7D+%5Cbegin%7Bpmatrix%7D+1+%26+2+%26+3+%5C%5C+1+%26+2+%26+3+%5Cend%7Bpmatrix%7D+%3D+%5Cbegin%7Bpmatrix%7D+2%2F%5Csqrt%7B2%7D+%26+4%2F%5Csqrt%7B2%7D+%26+6%2F%5Csqrt%7B2%7D+%5C%5C+0+%26+0+%26+0+%5Cend%7Bpmatrix%7D+%5C%5C" alt="[公式]"></p>
<p>我们可以把它写成通用的表示形式：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bpmatrix%7D+p_1+%5C%5C+p_2+%5C%5C+%5Cvdots+%5C%5C+p_R+%5Cend%7Bpmatrix%7D+%5Cbegin%7Bpmatrix%7D+a_1+%26+a_2+%26+%5Ccdots+%26+a_M+%5Cend%7Bpmatrix%7D+%3D+%5Cbegin%7Bpmatrix%7D+p_1a_1+%26+p_1a_2+%26+%5Ccdots+%26+p_1a_M+%5C%5C+p_2a_1+%26+p_2a_2+%26+%5Ccdots+%26+p_2a_M+%5C%5C+%5Cvdots+%26+%5Cvdots+%26+%5Cddots+%26+%5Cvdots+%5C%5C+p_Ra_1+%26+p_Ra_2+%26+%5Ccdots+%26+p_Ra_M+%5Cend%7Bpmatrix%7D+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=p_i" alt="[公式]"> 是一个行向量，表示第 i 个基， <img src="https://www.zhihu.com/equation?tex=a_j" alt="[公式]"> 是一个列向量，表示第 j 个原始数据记录。实际上也就是做了一个向量矩阵化的操作。</p>
<p>==上述分析给矩阵相乘找到了一种物理解释：<strong>两个矩阵相乘的意义是将右边矩阵中的每一列向量</strong> <img src="https://www.zhihu.com/equation?tex=a_i" alt="[公式]"> <strong>变换到左边矩阵中以每一行行向量为基所表示的空间中去。</strong>也就是说一个矩阵可以表示一种线性变换。==</p>
<h3 id="2-最大可分性"><a href="#2-最大可分性" class="headerlink" title="2. 最大可分性"></a>2. 最大可分性</h3><p>上面我们讨论了选择不同的基可以对同样一组数据给出不同的表示，<strong>如果基的数量少于向量本身的维数，则可以达到降维的效果</strong>。</p>
<p><strong>但是我们还没回答一个最关键的问题：如何选择基才是最优的。或者说，如果我们有一组 N 维向量，现在要将其降到 K 维（K 小于 N），那么我们应该如何选择 K 个基才能最大程度保留原有的信息？</strong></p>
<p>一种直观的看法是：<strong><font color="red"> 希望投影后的投影值尽可能分散，因为如果重叠就会有样本消失。当然这个也可以从熵的角度进行理解，熵越大所含信息越多。</font></strong></p>
<h4 id="2-1-方差"><a href="#2-1-方差" class="headerlink" title="2.1 方差"></a>2.1 方差</h4><p>我们知道数值的分散程度，可以用数学上的方差来表述。<strong>一个变量的方差可以看做是每个元素与变量均值的差的平方和的均值</strong>，即：</p>
<p><img src="https://www.zhihu.com/equation?tex=Var%28a%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7B%28a_i-%5Cmu%29%5E2%7D+%5C%5C" alt="[公式]"></p>
<p><strong>为了方便处理，我们将每个变量的均值都化为 0</strong> ，因此方差可以直接用每个元素的平方和除以元素个数表示：</p>
<p><img src="https://www.zhihu.com/equation?tex=Var%28a%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Ba_i%5E2%7D+%5C%5C" alt="[公式]"></p>
<p>于是上面的问题被形式化表述为：<strong>寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，方差值最大。</strong></p>
<h4 id="2-2-协方差"><a href="#2-2-协方差" class="headerlink" title="2.2 协方差"></a>2.2 协方差</h4><p>在一维空间中我们可以用方差来表示数据的分散程度。而对于高维数据，我们用协方差进行约束，<strong>协方差可以表示两个变量的相关性</strong>。<strong><font color="red"> 为了让两个变量尽可能表示更多的原始信息，我们希望它们之间不存在线性相关性</font></strong>，因为相关性意味着两个变量不是完全独立，必然存在重复表示的信息。</p>
<p>协方差公式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=Cov%28a%2Cb%29%3D%5Cfrac%7B1%7D%7Bm-1%7D%5Csum_%7Bi%3D1%7D%5Em%7B%28a_i-%5Cmu_a%29%28b_i-%5Cmu_b%29%7D+%5C%5C" alt="[公式]"></p>
<p>由于均值为 0，所以我们的协方差公式可以表示为：</p>
<p><img src="https://www.zhihu.com/equation?tex=Cov%28a%2Cb%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Ba_ib_i%7D+%5C%5C" alt="[公式]"></p>
<p>当样本数较大时，不必在意其是 m 还是 m-1，为了方便计算，我们分母取 m。</p>
<p><strong><font color="red"> 协方差为 0 时，表示两个变量完全不相关</font></strong>。为了让协方差为 0，我们选择第二个基时只能在与第一个基正交的方向上进行选择，因此最终选择的两个方向一定是正交的。</p>
<p>（<strong>补充</strong>：协方差为 0 时，两个变量只是线性不相关。完全独立是有问题的，才疏学浅，还望见谅。）</p>
<p><strong><font color="red"> 至此，我们得到了降维问题的优化目标：将一组 N 维向量降为 K 维，其目标是选择 K 个单位正交基，使得原始数据变换到这组基上后，各变量两两间协方差为 0，而变量方差则尽可能大（在正交的约束下，取最大的 K 个方差）。</font></strong></p>
<h4 id="2-3-协方差矩阵"><a href="#2-3-协方差矩阵" class="headerlink" title="2.3 协方差矩阵"></a>2.3 协方差矩阵</h4><p>针对我们给出的优化目标，接下来我们将从数学的角度来给出优化目标。我们看到，最终要达到的目的与<strong>变量内方差及变量间协方差</strong>有密切关系。因此我们希望能将两者统一表示，仔细观察发现，两者均可以表示为内积的形式，而内积又与矩阵相乘密切相关。于是我们有：</p>
<p>假设我们只有 a 和 b 两个变量，那么我们将它们按行组成矩阵 X：</p>
<p><img src="https://www.zhihu.com/equation?tex=X%3D%5Cbegin%7Bpmatrix%7D++a_1+%26+a_2+%26+%5Ccdots+%26+a_m+%5C%5C+b_1+%26+b_2+%26+%5Ccdots+%26+b_m++%5Cend%7Bpmatrix%7D+%5C%5C" alt="[公式]"></p>
<p>然后：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7Bm%7DXX%5E%5Cmathsf%7BT%7D%3D+%5Cbegin%7Bpmatrix%7D++%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Ba_i%5E2%7D+%26+%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Ba_ib_i%7D+%5C%5C+%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Ba_ib_i%7D+%26+%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%7Bb_i%5E2%7D++%5Cend%7Bpmatrix%7D+%3D+%5Cbegin%7Bpmatrix%7D++Cov%28a%2Ca%29+%26+Cov%28a%2Cb%29+%5C%5C++Cov%28b%2Ca%29+%26+Cov%28b%2Cb%29+%5Cend%7Bpmatrix%7D+%5C%5C" alt="[公式]"></p>
<p>我们可以看到这个矩阵对角线上的分别是两个变量的方差，而其它元素是 a 和 b 的协方差。两者被统一到了一个矩阵里。</p>
<p><strong>设我们有 m 个 n 维数据记录，将其排列成矩阵</strong> <img src="https://www.zhihu.com/equation?tex=X_%7Bn%2Cm%7D" alt="[公式]"> <strong>，设</strong> <img src="https://www.zhihu.com/equation?tex=C%3D%5Cfrac%7B1%7D%7Bm%7DXX%5ET" alt="[公式]"> <strong>，则 C 是一个对称矩阵，其对角线分别对应各个变量的方差，而第 i 行 j 列和 j 行 i 列元素相同，表示 i 和 j 两个变量的协方差</strong>。</p>
<h4 id="2-4-矩阵对角化"><a href="#2-4-矩阵对角化" class="headerlink" title="2.4 矩阵对角化"></a>2.4 矩阵对角化</h4><p>根据我们的优化条件，<strong>我们需要将除对角线外的其它元素化为 0，并且在对角线上将元素按大小从上到下排列（变量方差尽可能大）</strong>，这样我们就达到了优化目的。这样说可能还不是很明晰，我们进一步看下原矩阵与基变换后矩阵协方差矩阵的关系。</p>
<p>设原始数据矩阵 X 对应的协方差矩阵为 C，而 P 是一组基按行组成的矩阵，设 Y=PX，则 Y 为 X 对 P 做基变换后的数据。设 Y 的协方差矩阵为 D，我们推导一下 D 与 C 的关系：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D++D+%26+%3D++%5Cfrac%7B1%7D%7Bm%7DYY%5ET+%5C%5C++%26+%3D+%5Cfrac%7B1%7D%7Bm%7D%28PX%29%28PX%29%5ET+%5C%5C+%26+%3D+%5Cfrac%7B1%7D%7Bm%7DPXX%5ETP%5ET+%5C%5C++%26+%3D+P%28%5Cfrac%7B1%7D%7Bm%7DXX%5ET%29P%5ET+%5C%5C++%26+%3D+PCP%5ET++%5Cend%7Baligned%7D++%5C%5C" alt="[公式]"></p>
<p>这样我们就看清楚了，我们要找的 <strong>==P 是能让原始协方差矩阵对角化的 P==</strong>。换句话说，优化目标变成了<strong>寻找一个矩阵 P，满足</strong> <img src="https://www.zhihu.com/equation?tex=PCP%5ET" alt="[公式]"> <strong>是一个对角矩阵，并且对角元素按从大到小依次排列，那么 P 的前 K 行就是要寻找的基，用 P 的前 K 行组成的矩阵乘以 X 就使得 X 从 N 维降到了 K 维并满足上述优化条件</strong>。</p>
<p>至此，我们离 PCA 还有仅一步之遥，我们还需要完成对角化。</p>
<p><strong>由上文知道，协方差矩阵 C 是一个是对称矩阵，在线性代数中实对称矩阵有一系列非常好的性质：</strong></p>
<ol>
<li><strong>实对称矩阵不同特征值对应的特征向量必然正交</strong>。</li>
<li><strong>设特征向量 <img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="[公式]"> 重数为 r，则必然存在 r 个线性无关的特征向量对应于 <img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="[公式]"> ，因此可以将这 r 个特征向量单位正交化。</strong></li>
</ol>
<p><strong>由上面两条可知，一个 n 行 n 列的实对称矩阵一定可以找到 n 个单位正交特征向量，设这 n 个特征向量为 <img src="https://www.zhihu.com/equation?tex=e_1%2Ce_2%2C%5Ccdots%2Ce_n" alt="[公式]"> ，我们将其按列组成矩阵： <img src="https://www.zhihu.com/equation?tex=E%3D%28e_1+%2C+e_2+%2C+%5Ccdots+%2C+e_n+%29" alt="[公式]"> 。</strong></p>
<p>则对协方差矩阵 C 有如下结论：</p>
<p><img src="https://www.zhihu.com/equation?tex=E%5ETCE%3D%5CLambda%3D%5Cbegin%7Bpmatrix%7D+%5Clambda_1+%26+%26+%26+%5C%5C+%26+%5Clambda_2+%26+%26+%5C%5C+%26+%26+%5Cddots+%26+%5C%5C+%26+%26+%26+%5Clambda_n+%5Cend%7Bpmatrix%7D+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%5CLambda" alt="[公式]"> 为对角矩阵，其对角元素为各特征向量对应的特征值（可能有重复）。到这里，我们发现我们已经找到了需要的矩阵 P： <img src="https://www.zhihu.com/equation?tex=P%3DE%5E%5Cmathsf%7BT%7D" alt="[公式]"> 。</p>
<p><strong>P 是协方差矩阵的特征向量单位化后按行排列出的矩阵</strong>，其中每一行都是 C 的一个特征向量。如果设 P 按照 <img src="https://www.zhihu.com/equation?tex=%5CLambda" alt="[公式]"> 中特征值的从大到小，将特征向量从上到下排列，则用 P 的前 K 行组成的矩阵乘以原始数据矩阵 X，就得到了我们需要的降维后的数据矩阵 Y。</p>
<blockquote>
<p>  <strong>拉格朗日乘子法证明</strong>:<strong>方差就是协方差矩阵的特征值</strong></p>
</blockquote>
<h4 id="2-5-最近重构性-思路"><a href="#2-5-最近重构性-思路" class="headerlink" title="2.5 最近重构性-思路"></a>2.5 最近重构性-思路</h4><p>以上的证明思路主要是基于最大可分性的思想，<strong>通过一条直线使得样本点投影到该直线上的方差最大</strong>。除此之外，我们还可以<strong>将其转换为线型回归问题，其目标是求解一个线性函数使得对应直线能够更好地拟合样本点集合</strong>。这就<strong>使得我们的优化目标从方差最大转化为平方误差最小</strong>，因为映射距离越短，丢失的信息也会越小。区别于最大可分性，这是从最近重构性的角度进行论证。</p>
<h3 id="3-求解步骤"><a href="#3-求解步骤" class="headerlink" title="==3. 求解步骤=="></a>==3. 求解步骤==</h3><h4 id="总结一下-PCA-的算法步骤：设有-m-条-n-维数据。"><a href="#总结一下-PCA-的算法步骤：设有-m-条-n-维数据。" class="headerlink" title="总结一下 PCA 的算法步骤：设有 m 条 n 维数据。"></a>总结一下 PCA 的算法步骤：<strong>设有 m 条 n 维数据。</strong></h4><ol>
<li><strong>将原始数据按列组成 n 行 m 列矩阵 X；</strong></li>
<li><strong>将 X 的每一行进行==零均值化==，即减去这一行的均值</strong>；【<strong>零均值化</strong>】【<strong>方差、协方差好计算</strong>】</li>
<li><strong>==求出协方差矩阵==</strong> <img src="https://www.zhihu.com/equation?tex=C%3D%5Cfrac%7B1%7D%7Bm%7DXX%5E%5Cmathsf%7BT%7D" alt="[公式]"> ；</li>
<li><strong>求出协方差矩阵的特征值及对应的特征向量</strong>；</li>
<li><strong>将特征向量按对应特征值大小从上到下按行排列成矩阵，取前 k 行组成矩阵 P</strong>；</li>
<li><img src="https://www.zhihu.com/equation?tex=Y%3DPX" alt="[公式]"> <strong>即为降维到 k 维后的数据</strong>。</li>
</ol>
<h4 id="4-性质【维度灾难、降噪、过拟合、特征独立】"><a href="#4-性质【维度灾难、降噪、过拟合、特征独立】" class="headerlink" title="4. 性质【维度灾难、降噪、过拟合、特征独立】"></a>4. 性质【维度灾难、降噪、过拟合、特征独立】</h4><ol>
<li><strong>==缓解维度灾难==</strong>：PCA 算法通过舍去一部分信息之后能使得样本的采样密度增大（因为维数降低了），这是缓解维度灾难的重要手段；</li>
<li><strong>==降噪==</strong>：当数据受到噪声影响时，最小特征值对应的特征向量往往与噪声有关，将它们舍弃能在一定程度上起到降噪的效果；</li>
<li><strong>==过拟合==</strong>：PCA 保留了主要信息，但这个主要信息只是针对训练集的，而且这个主要信息未必是重要信息。有可能舍弃了一些看似无用的信息，但是这些看似无用的信息恰好是重要信息，只是在训练集上没有很大的表现，所以 PCA 也可能加剧了过拟合；</li>
<li><strong>==特征独立==</strong>：PCA 不仅将数据压缩到低维，它也使得<strong>降维之后的数据各特征相互独立</strong>；</li>
</ol>
<h3 id="5-细节"><a href="#5-细节" class="headerlink" title="5. 细节"></a>5. 细节</h3><h4 id="5-1-零均值化"><a href="#5-1-零均值化" class="headerlink" title="5.1 零均值化"></a>5.1 零均值化</h4><p>当对训练集进行 PCA 降维时，也需要对验证集、测试集执行同样的降维。==而<strong>对验证集、测试集执行零均值化操作时，均值必须从训练集计算而来</strong>，不能使用验证集或者测试集的中心向量。==</p>
<p>其原因也很简单，因为我们的训练集时可观测到的数据，测试集不可观测所以不会知道其均值，而验证集再大部分情况下是在处理完数据后再从训练集中分离出来，一般不会单独处理。如果真的是单独处理了，不能独自求均值的原因是和测试集一样。</p>
<p>另外我们也需要保证一致性，我们拿训练集训练出来的模型用来预测测试集的前提假设就是两者是独立同分布的，如果不能保证一致性的话，会出现 Variance Shift 的问题。</p>
<h4 id="5-2-SVD-的对比"><a href="#5-2-SVD-的对比" class="headerlink" title="==5.2 SVD 的对比=="></a>==5.2 SVD 的对比==</h4><p>这是两个不同的数学定义。我们先给结论：<strong>特征值和特征向量是针对方阵</strong>才有的，而<strong>对任意形状的矩阵都可以做奇异值分解</strong>。</p>
<p><strong>PCA</strong>：<strong>方阵的特征值分解</strong>，对于一个方阵 A。其中，Q 是这个矩阵 A 的特征向量组成的矩阵， <img src="https://www.zhihu.com/equation?tex=%5CLambda" alt="[公式]"> 是一个对角矩阵，每一个对角线元素就是一个特征值，里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变化方向（从主要的变化到次要的变化排列)。也就是说矩阵 A 的信息可以由其特征值和特征向量表示。</p>
<p><strong>SVD</strong>：<strong>矩阵的奇异值分解其实就是对于矩阵 A 的协方差矩阵 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=AA%5ET" alt="[公式]"> 做特征值分解推导出来的</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=A_%7Bm%2Cn%7D%3DU_%7Bm%2Cm%7D%5CLambda_%7Bm%2Cn%7DV%5ET_%7Bn%2Cn%7D+%5Capprox+U_%7Bm%2Ck%7D%5CLambda_%7Bk%2Ck%7DV%5ET_%7Bk%2Cn%7D+%5C%5C" alt="[公式]"></p>
<p>其中：U V 都是正交矩阵，有 <img src="https://www.zhihu.com/equation?tex=U%5ETU%3DI_m%2C+V%5ETV%3DI_n" alt="[公式]"> 。这里的约等于是因为 <img src="https://www.zhihu.com/equation?tex=%5CLambda" alt="[公式]"> 中有 n 个奇异值，但是由于排在后面的很多接近 0，所以我们可以仅保留比较大的 k 个奇异值。</p>
<p><img src="https://www.zhihu.com/equation?tex=A%5ETA%3D%28U+%5CLambda+V%5ET%29%5ETU+%5CLambda+V%5ET+%3DV+%5CLambda%5ET+U%5ETU+%5CLambda+V%5ET++%3D+V%5CLambda%5E2+V%5ET+%5C%5C+AA%5ET%3DU+%5CLambda+V%5ET%28U+%5CLambda+V%5ET%29%5ET+%3DU+%5CLambda+V%5ETV+%5CLambda%5ET+U%5ET+%3D+U%5CLambda%5E2+U%5ET++%5C%5C" alt="[公式]"></p>
<p>所以，V U 两个矩阵分别是 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=AA%5ET" alt="[公式]"> 的特征向量，中间的矩阵对角线的元素是 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=AA%5ET" alt="[公式]"> 的特征值。我们也很容易看出 A 的奇异值和 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 的特征值之间的关系。</p>
<p>PCA 需要对协方差矩阵 <img src="https://www.zhihu.com/equation?tex=C%3D%5Cfrac%7B1%7D%7Bm%7DXX%5ET" alt="[公式]"> 。进行特征值分解； SVD 也是对 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 进行特征值分解。如果取 <img src="https://www.zhihu.com/equation?tex=A%3D%5Cfrac%7BX%5ET%7D%7B%5Csqrt%7Bm%7D%7D" alt="[公式]"> 则两者基本等价。所以 PCA 问题可以转换成 SVD 求解。</p>
<p><strong>==而实际上 Sklearn 的 PCA 就是用 SVD 进行求解的==</strong>，原因有以下几点：</p>
<ol>
<li>当样本维度很高时，协方差矩阵计算太慢；</li>
<li>方阵特征值分解计算效率不高；</li>
<li><strong>==SVD 除了特征值分解这种求解方式外，还有更高效更准确的迭代求解方式，避免了 <img src="https://www.zhihu.com/equation?tex=A%5ETA" alt="[公式]"> 的计算；==</strong></li>
<li><strong>其实 PCA 与 SVD 的右奇异向量的压缩效果相同</strong>。</li>
</ol>
<blockquote>
<ol>
<li>《机器学习》周志华</li>
<li><a href="https://link.zhihu.com/?target=https%3A//blog.codinglabs.org/articles/pca-tutorial.html">PCA 的数学原理</a></li>
<li><a href="https://link.zhihu.com/?target=http%3A//web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm">Singular Value Decomposition (SVD) tutorial</a></li>
<li><a href="https://link.zhihu.com/?target=https%3A//www.cnblogs.com/LeftNotEasy/archive/2011/01/08/lda-and-pca-machine-learning.html">机器学习中的数学（4）——线性判别分析（LDA）, 主成分分析（PCA）</a></li>
<li><a href="https://link.zhihu.com/?target=https%3A//my.oschina.net/findbill/blog/535044">从SVD到PCA——奇妙的数学游戏</a></li>
<li>scikit-learn：降维算法PCA和SVD <a href="https://blog.csdn.net/HHG20171226/article/details/102981822">https://blog.csdn.net/HHG20171226/article/details/102981822</a></li>
</ol>
</blockquote>
<h2 id="二、线性判别分析（LDA）【监督】"><a href="#二、线性判别分析（LDA）【监督】" class="headerlink" title="二、线性判别分析（LDA）【监督】"></a>二、线性判别分析（LDA）【监督】</h2><blockquote>
<p>  ==<strong>“投影后类内方差最小，类间方差最大”</strong>==</p>
<ul>
<li><a href="https://blog.csdn.net/liuweiyuxiang/article/details/78874106">https://blog.csdn.net/liuweiyuxiang/article/details/78874106</a></li>
</ul>
</blockquote>
<h3 id="2-1-概念"><a href="#2-1-概念" class="headerlink" title="2.1 概念"></a>2.1 概念</h3><p><strong>线性判别分析（Linear Discriminant Analysis，LDA）是一种经典的降维方法。和主成分分析PCA不考虑样本类别输出的无监督降维技术不同，LDA是一种监督学习的降维技术，数据集的每个样本有类别输出。</strong></p>
<p><strong>LDA分类思想简单总结如下：</strong></p>
<ol>
<li>多维空间中，数据处理分类问题较为复杂，LDA算法将多维空间中的数据投影到一条直线上，将d维数据转化成1维数据进行处理。</li>
<li>对于训练数据，设法将多维数据投影到一条直线上，<strong>同类数据的投影点尽可能接近，异类数据点尽可能远离</strong>。</li>
<li>对数据进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定样本的类别。</li>
</ol>
<p><strong><font color="red"> 如果用一句话概括LDA思想，即“投影后类内方差最小，类间方差最大”。</font></strong></p>
<p>假设有红、蓝两类数据，这些数据特征均为二维，如下图所示。我们的目标是将这些数据投影到一维，让每一类相近的数据的投影点尽可能接近，不同类别数据尽可能远，即图中红色和蓝色数据中心之间的距离尽可能大。</p>
<p><img src="image-20220526135646769.png" alt="image-20220526135646769"></p>
<p> 从上图直观看出，右图红色数据和蓝色数据在各自的区域来说相对集中，根据数据分布直方图也可看出，所以右图的投影效果好于左图，左图中间直方图部分有明显交集。 以上例子是基于数据是二维的，分类后的投影是一条直线。如果原始数据是多维的，则投影后的分类面是一低维的超平面。</p>
<h3 id="2-2-原理"><a href="#2-2-原理" class="headerlink" title="2.2 原理"></a>2.2 原理</h3><p> LDA的原理是，将带上标签的数据（点），通过投影的方法，投影到维度更低的空间中，使得投影后的点，会形成按类别区分，一簇一簇的情况，相同类别的点，将会在投影后的空间中更接近。要说明白LDA，首先得弄明白线性分类器(<a href="http://en.wikipedia.org/wiki/Linear_classifier">Linear Classifier</a>)：因为LDA是一种线性分类器。对于<strong>K-分类的一个分类问题，会有K个线性函数</strong>：</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455464493.png" alt="image"></p>
<p>当满足条件：对于所有的j，都有Yk &gt; Yj,的时候，我们就说x属于类别k。对于每一个分类，都有一个公式去算一个分值，在所有的公式得到的分值中，找一个最大的就是所属的分类了。</p>
<p>上式实际上就是一种投影，是将一个高维的点投影到一条高维的直线上，LDA最求的目标是，给出一个标注了类别的数据集，投影到了一条直线之后，能够使得点尽量的按类别区分开，当k=2即二分类问题的时候，如下图所示：</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455475507.gif" alt="clip_image002" style="zoom:67%;"></p>
<p>红色的方形的点为0类的原始点、蓝色的方形点为1类的原始点，经过原点的那条线就是投影的直线，从图上可以清楚的看到，红色的点和蓝色的点被<strong>原点</strong>明显的分开了，这个数据只是随便画的，如果在高维的情况下，看起来会更好一点。下面我来推导一下二分类LDA问题的公式：假设用来区分二分类的直线（投影函数)为：</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455471885.png" alt="image"></p>
<p> <strong>LDA分类的一个目标是使得==不同类别==之间的距离越远越好，==同一类别==之中的距离越近越好</strong>，所以我们需要定义几个关键的值。</p>
<ul>
<li><p><strong>==类别i的原始中心点为==</strong>：（Di表示属于类别i的点)</p>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455478264.png" alt="image"></p>
</li>
<li><p>类别i投影后的中心点为：</p>
</li>
</ul>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455488231.png" alt="image"></p>
<ul>
<li><strong>==衡量类别i投影后，类别点之间的分散程度（方差）为==</strong>：</li>
</ul>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455487326.png" alt="image"></p>
<ul>
<li><strong>==最终我们可以得到一个下面的公式，表示LDA投影到w后的损失函数==</strong>：</li>
</ul>
<p><img src="https://images.cnblogs.com/cnblogs_com/LeftNotEasy/201101/201101081455484785.png" alt="image"></p>
<p>我们<strong>分类的目标是，使得类别内的点距离越近越好（集中），类别间的点越远越好。</strong>分母表示每一个类别内的方差之和，方差越大表示一个类别内的点越分散，分子为两个类别各自的中心点的距离的平方，我们最大化J(w)就可以求出最优的w了。想要求出最优的w，可以使用拉格朗日乘子法，但是现在我们得到的J(w)里面，w是不能被单独提出来的，我们就得想办法将w单独提出来。</p>
<p> 我们定义一个<strong>投影前的==各类别分散程度的矩阵==</strong>，这个矩阵看起来有一点麻烦，其实意思是，如果某一个分类的<strong>输入点集Di里面的点距离这个分类的中心店mi越近</strong>，则Si里面元素的值就越小，如果分类的点都紧紧地围绕着mi，则Si里面的元素值越更接近0.</p>
<script type="math/tex; mode=display">
S_{i}=\sum_{x \in D_{i}}\left(x-m_{i}\right)\left(x-m_{i}\right)^{T}</script><p>带入 $\mathrm{Si}$, 将 $\mathrm{J}(\mathrm{w})$ 分母化为:</p>
<p>$\tilde{s}_{i}=\sum_{x \in D_{i}}\left(w^{T} x-w^{T} m_{i}\right)^{2}=\sum_{x \in D_{i}} w^{T}\left(x-m_{i}\right)\left(x-m_{i}\right)^{T} w=w^{T} S_{i} w$</p>
<script type="math/tex; mode=display">{\tilde{S_{1}}}^{2}+{\tilde{S_{2}}}^{2}=w^{T}\left(S_{1}+S_{2}\right) w=w^{T} S_{w} w</script><p>同样的将 $\mathrm{J}(\mathrm{w})$ 分子化为:</p>
<script type="math/tex; mode=display">
\left|\widetilde{m_{1}}-\widetilde{m_{2}}\right|^{2}=w^{T}\left(m_{1}-m_{2}\right)\left(m_{1}-m_{2}\right)^{T} w=w^{T} S_{B} w</script><p>这样<strong>损失函数</strong>可以化成下面的形式:</p>
<script type="math/tex; mode=display">
J(w)=\frac{w^{T} S_{B} w}{w^{T} S_{w} w}</script><p>这样就可以用最喜欢的<strong>==拉格朗日乘子法==</strong>了, 但是还有一个问题, 如果分子、分母是都可以取任意值的, 那就会 使得有无穷解, 我们将分母限制为长度为 1, 并作为拉格朗日乘子法的限制条件, 带入得到:</p>
<script type="math/tex; mode=display">
\begin{aligned}
&c(w)=w^{T} S_{B} w-\lambda\left(w^{T} S_{w} w-1\right) \\
&\Rightarrow \frac{d c}{d w}=2 S_{B} w-2 \lambda S_{w} w=0 \\
&\Rightarrow S_{B} w=\lambda S_{w} w
\end{aligned}</script><p><strong>==这样的式子就是一个求特征值的问题了。==</strong><br>对于 $N(N&gt;2)$ 分类的问题, 我就直接写出下面的结论了:</p>
<script type="math/tex; mode=display">
\begin{aligned}
&S_{W}=\sum_{i=1}^{c} S_{i} \\
&S_{B}=\sum_{i=1}^{c} n_{i}\left(m_{i}-m\right)\left(m_{i}-m\right)^{T} \\
&S_{B} w_{i}=\lambda S_{w} w_{i}
\end{aligned}</script><p>这同样是一个求特征值的问题，我们求出的第i大的特征向量，就是对应的Wi了。</p>
<blockquote>
<p>  这里想多谈谈特征值，特征值在纯数学、量子力学、固体力学、计算机等等领域都有广泛的应用，特征值表示的是矩阵的性质，当我们取到矩阵的前N个最大的特征值的时候，我们可以说提取到的矩阵主要的成分（这个和之后的PCA相关，但是不是完全一样的概念）。在机器学习领域，不少的地方都要用到特征值的计算，比如说图像识别、pagerank、LDA、还有之后将会提到的PCA等等。</p>
</blockquote>
<p><strong>优缺点</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>优缺点</th>
<th>简要说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>优点</td>
<td>1. 可以使用类别的先验知识； 2. 以标签、类别衡量差异性的有监督降维方式，相对于PCA的模糊性，其目的更明确，更能反映样本间的差异；</td>
</tr>
<tr>
<td>缺点</td>
<td>1. LDA不适合对非高斯分布样本进行降维； 2. <strong>LDA降维最多降到分类数k-1维</strong>； 3. LDA在样本分类信息依赖方差而不是均值时，降维效果不好； 4. LDA可能过度拟合数据。</td>
</tr>
</tbody>
</table>
</div>
<h2 id="三、t-SNE-高维数据可视化"><a href="#三、t-SNE-高维数据可视化" class="headerlink" title="三、t-SNE 高维数据可视化"></a>三、t-SNE 高维数据可视化</h2><blockquote>
<p>  高维数据可视化之t-SNE算法🌈:<a href="https://zhuanlan.zhihu.com/p/57937096">https://zhuanlan.zhihu.com/p/57937096</a></p>
</blockquote>
<p><strong>T-SNE算法是用于可视化的算法中效果最好的算法之一</strong>，相信大家也对T-SNE算法略有耳闻，本文参考T-SNE作者<strong>Laurens van der Maaten</strong>给出的源代码自己实现T-SNE算法代码，以此来加深对T-SNE的理解。先简单介绍一下T-SNE算法，T-SNE将数据点变换映射到概率分布上。</p>
<h4 id="3-1-t-SNE数据算法的目的"><a href="#3-1-t-SNE数据算法的目的" class="headerlink" title="3.1 t-SNE数据算法的目的"></a>3.1 t-SNE数据算法的目的</h4><p><strong>主要是将数据从高维数据转到低维数据，并在低维空间里也保持其在高维空间里所携带的信息（比如高维空间里有的清晰的分布特征，转到低维度时也依然存在）。</strong></p>
<p><strong>==t-SNE将欧氏距离距离转换为条件概率，来表达点与点之间的相似度，再优化两个分布之间的距离-KL散度，从而保证点与点之间的分布概率不变。==</strong></p>
<h4 id="3-2-SNE原理"><a href="#3-2-SNE原理" class="headerlink" title="3.2 SNE原理"></a>3.2 SNE原理</h4><p>$S N E$ 是<strong>通过仿射变换将数据点映射到相应概率分布上</strong>, 主要包括下面两个步骤:</p>
<ol>
<li>通过在高维空间中构建数据点之间的概率分布 $P$, 使得相似的数据点有更高的概率被选择, 而 不相似的数据点有较低的概率被选择;</li>
<li>然后在低维空间里重构这些点的概率分布 $Q$, 使得这两个概率分布尽可能相似。</li>
</ol>
<p>令输入空间是 $X \in \mathbb{R}^{n}$, 输出空间为 $Y \in \mathbb{R}^{t}(t \ll n)$ 。不妨假设含有 $m$ 个样本数据 $\left\{x^{(1)}, x^{(2)}, \cdots, x^{(m)}\right\}$, 其中 $x^{(i)} \in X$, 降维后的数据为 $\left\{y^{(1)}, y^{(2)}, \cdots, y^{(m)}\right\}, y^{(i)} \in Y$ 。 $S N E$ 是<strong>先将欧几里得距离转化为条件概率来表达点与点之间的相似度</strong>, 即首先是计算条件概 率 $p_{j \mid i}$, 其正比于 $x^{(i)}$ 和 $x^{(j)}$ 之间的相似度, $p_{j \mid i}$ 的计算公式为:</p>
<script type="math/tex; mode=display">
p_{j \mid i}=\frac{\exp \left(-\frac{\left\|x^{(i)}-x^{(j)}\right\|^{2}}{2 \sigma_{i}^{2}}\right)}{\sum_{k \neq i} \exp \left(-\frac{\left\|x^{(i)}-x^{(k)}\right\|^{2}}{2 \sigma_{i}^{2}}\right)}</script><p>在这里引入了一个参数 $\sigma_{i}$, 对于不同的数据点 $x^{(i)}$ 取值亦不相同, 因为我们关注的是不同数据 点两两之间的相似度, 故可设置 $p_{i \mid i}=0$ 。对于低维度下的数据点 $y^{(i)}$, 通过条件概率 $q_{j \mid i}$ 来 刻画 $y^{(i)}$ 与 $y^{(j)}$ 之间的相似度, $q_{j \mid i}$ 的计算公式为:</p>
<script type="math/tex; mode=display">
q_{j \mid i}=\frac{\exp \left(-\left\|y^{(i)}-y^{(j)}\right\|^{2}\right)}{\sum_{k \neq i} \exp \left(-\left\|y^{(i)}-y^{(k)}\right\|^{2}\right)}</script><p>同理, 设置 $q_{i \mid i}=0$ 。<br>如果降维的效果比较好, 局部特征保留完整, 那么有 $p_{i \mid j}=q_{i \mid j}$ 成立, 因此通过优化两个分布之 间的 <strong>$K L$ 散度构造出的损失函数为</strong>:</p>
<script type="math/tex; mode=display">
C\left(y^{(i)}\right)=\sum_{i} K L\left(P_{i} \| Q_{i}\right)=\sum_{i} \sum_{j} p_{j \mid i} \log \frac{p_{j \mid i}}{q_{j \mid i}}</script><p>这里的 $P_{i}$ 表示在给定高维数据点 $x^{(i)}$ 时, 其他所有数据点的条件概率分布; $Q_{i}$ 则表示在给定 低维数据点 $y^{(i)}$ 时, 其他所有数据点的条件概率分布。从损失函数可以看出, 当 $p_{j \mid i}$ 较大 $q_{j \mid i}$ 较小时, 惩罚较高; 而 $p_{j \mid i}$ 较小 $q_{j \mid i}$ 较大时, 惩罚较低。换句话说就是高维空间中两个数据点距 离较近时, 若映射到低维空间后距离较远, 那么将得到一个很高的惩罚; 反之, 高维空间中两个数 据点距离较远时, 若映射到低维空间距离较近, 将得到一个很低的惩罚值。也就是说, <strong>$S N E$ 的 损失函数更关注于局部特征, 而忽视了全局结构</strong>。</p>
<h4 id="3-3-目标函数求解"><a href="#3-3-目标函数求解" class="headerlink" title="3.3 目标函数求解"></a>3.3 目标函数求解</h4><h4 id="3-4-对称性-SNE"><a href="#3-4-对称性-SNE" class="headerlink" title="3.4 对称性-SNE"></a>3.4 对称性-SNE</h4><p><strong>优化 <img src="https://www.zhihu.com/equation?tex=KL%28P%5CVert+Q%29" alt="[公式]"> 的一种替换思路是使用联合概率分布来替换条件概率分布</strong>，即 <img src="https://www.zhihu.com/equation?tex=P" alt="[公式]"> 是高维空间里数据点的联合概率分布， <img src="https://www.zhihu.com/equation?tex=Q" alt="[公式]"> 是低维空间里数据点的联合概率分布，此时的损失函数为：</p>
<p><img src="https://www.zhihu.com/equation?tex=C%28y%5E%7B%28i%29%7D%29%3DKL%28P%5CVert+Q%29%3D%5Csum%5Climits_i%5Csum%5Climits_jp_%7Bij%7D%5Clog%5Cdfrac%7Bp_%7Bij%7D%7D%7Bq_%7Bij%7D%7D%5C%5C" alt="[公式]"></p>
<p>同样的 <img src="https://www.zhihu.com/equation?tex=p_%7Bii%7D%3Dq_%7Bii%7D%3D0" alt="[公式]"> ，这种改进下的 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 称为对称 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> ，因为它的先验假设为对 <img src="https://www.zhihu.com/equation?tex=%5Cforall+i" alt="[公式]"> 有 <img src="https://www.zhihu.com/equation?tex=p_%7Bij%7D%3Dp_%7Bji%7D%2Cq_%7Bij%7D%3Dq_%7Bji%7D" alt="[公式]"> 成立，故概率分布可以改写成：</p>
<p><img src="https://www.zhihu.com/equation?tex=p_%7Bij%7D%3D%5Cdfrac%7Bexp%28-%5Cfrac%7B%5CVert+x%5E%7B%28i%29%7D-x%5E%7B%28j%29%7D%5CVert%5E2%7D%7B2%5Csigma%5E2%7D%29%7D%7B%5Csum%5Climits_%7Bk%5Cneq+l%7Dexp%28-%5Cfrac%7B%5CVert+x%5E%7B%28k%29%7D-x%5E%7B%28l%29%7D+%5CVert%5E2%7D%7B2%5Csigma%5E2%7D%29%7D%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+%5C+q_%7Bij%7D%3D%5Cdfrac%7Bexp%28-%5CVert+y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D+%5CVert%5E2%29%7D%7B%5Csum%5Climits_%7Bk%5Cneq+l%7Dexp%28-%5CVert+y%5E%7B%28k%29%7D-y%5E%7B%28l%29%7D+%5CVert%5E2%29%7D%5C%5C" alt="[公式]"></p>
<p>这种改进方法使得表达式简洁很多，但是容易受到异常点数据的影响，为了解决这个问题通过对联合概率分布定义修正为： <img src="https://www.zhihu.com/equation?tex=p_%7Bij%7D%3D%5Cfrac%7Bp_%7Bj%7Ci%7D%2Bp_%7Bi%7Cj%7D%7D%7B2%7D" alt="[公式]"> ，这保证了 <img src="https://www.zhihu.com/equation?tex=%5Csum%5Climits_jp_%7Bij%7D+%5Cgt+%5Cfrac%7B1%7D%7B2m%7D" alt="[公式]"> ，使得每个点对于损失函数都会有贡献。对称 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 最大的优点是简化了梯度计算，梯度公式改写为：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7B%5Cpartial+C%28y%5E%7B%28i%29%7D%29%7D%7B%5Cpartial+y%5E%7B%28i%29%7D%7D%3D4%5Csum%5Climits_j%28p_%7Bij%7D-q_%7Bij%7D%29%28y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D%29%5C%5C" alt="[公式]"></p>
<p>研究表明，对称 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 的效果差不多，有时甚至更好一点。</p>
<h4 id="3-5-t-SNE"><a href="#3-5-t-SNE" class="headerlink" title="3.5 t-SNE"></a>3.5 t-SNE</h4><p><img src="https://www.zhihu.com/equation?tex=t%5Ctext%7B-%7DSNE" alt="[公式]"> 在对称 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 的改进是，首先<strong>通过在高维空间中使用高斯分布将距离转换为概率分布，然后在低维空间中，使用更加偏重长尾分布的方式来将距离转换为概率分布</strong>，使得高维度空间中的中低等距离在映射后能够有一个较大的距离。</p>
<p><img src="https://pic4.zhimg.com/80/v2-928a3ada308128f26b719d510a728fbb_1440w.jpg" alt="img"></p>
<p>从图中可以看到，在没有异常点时， <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 分布与高斯分布的拟合结果基本一致。而在第二张图中，出现了部分异常点，由于高斯分布的尾部较低，对异常点比较敏感，为了照顾这些异常点，高斯分布的拟合结果偏离了大多数样本所在位置，方差也较大。<strong>相比之下， <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 分布的尾部较高，对异常点不敏感，保证了其鲁棒性，因此拟合结果更为合理，较好的捕获了数据的全局特征。</strong></p>
<p>使用 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 分布替换高斯分布之后 <img src="https://www.zhihu.com/equation?tex=q_%7Bij+%7D" alt="[公式]"> 的变化如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=q_%7Bij%7D%3D%5Cdfrac%7B%281%2B%5CVert+y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D+%5CVert%5E2%29%5E%7B-1%7D%7D%7B%5Csum%5Climits_%7Bk%5Cneq+l%7D%281%2B%5CVert+y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D+%5CVert%5E2%29%5E%7B-1%7D%7D%5C%5C" alt="[公式]"></p>
<p>此外，随着自由度的逐渐增大， <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 分布的密度函数逐渐接近标准正态分布，因此在计算梯度方面会简单很多，优化后的梯度公式如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7B%5Cpartial+C%28y%5E%7B%28i%29%7D%29%7D%7B%5Cpartial+y%5E%7B%28i%29%7D%7D%3D4%5Csum%5Climits_%7Bj%7D%28p_%7Bij%7D-q_%7Bij%7D%29%28y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D%29%281%2B%5CVert+y%5E%7B%28i%29%7D-y%5E%7B%28j%29%7D+%5CVert%5E2%29%5E%7B-1%7D%5C%5C" alt="[公式]"></p>
<p>总的来说， <img src="https://www.zhihu.com/equation?tex=t%5Ctext%7B-%7DSNE" alt="[公式]"> 的梯度更新具有以下两个优势：</p>
<ul>
<li><strong>对于低维空间中不相似的数据点，用一个较小的距离会产生较大的梯度让这些数据点排斥开来</strong>；</li>
<li><strong>这种排斥又不会无限大，因此避免了不相似的数据点距离太远</strong>。</li>
</ul>
<h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><p><img src="https://www.zhihu.com/equation?tex=t%5Ctext%7B-%7D+SNE" alt="[公式]"> 算法其实就是在 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 算法的基础上增加了两个改进：</p>
<ul>
<li>把 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 修正为对称 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> ，提高了计算效率，效果稍有提升；</li>
<li>在低维空间中采用了 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 分布替换原来的高斯分布，解决了高维空间映射到低维空间所产生的拥挤问题，优化了 <img src="https://www.zhihu.com/equation?tex=SNE" alt="[公式]"> 过于关注局部特征而忽略全局特征的问题 。</li>
</ul>
<h2 id="四、AutoEncoder"><a href="#四、AutoEncoder" class="headerlink" title="四、AutoEncoder"></a>四、AutoEncoder</h2><blockquote>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/80377698">【全】一文带你了解自编码器（<em>AutoEncoder</em>）</a></li>
</ul>
</blockquote>
<p>理解为：（下图）高维数据（左测蓝色）通过某种网络变成低位数据（中间红色）后，又经过某种网络变回高维数据（右侧蓝色）。数据经过该模型前后没有变化，而中间的低维数据完全具有输入输出的高维数据的全部信息，所以可以用<a href="https://www.zhihu.com/search?q=低维数据&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;157482881&quot;}">低维数据</a>代表高维数据。</p>
<p>之所以叫AutoEncoder，而不叫AutoEncoderDecoder，是因为训练好之后只有encoder部分有用，<a href="https://www.zhihu.com/search?q=decoder&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;157482881&quot;}">decoder</a>部分就不用了。</p>
<p><img src="https://pic2.zhimg.com/v2-47f6429e5ffb379205ba0bcb0db399d1_b.jpg" alt="img"></p>
<p>进入深度学习的思路之后，编码的网络是开放的，可以自由设计的。一个思路是端到端，将网络的输出设为你任务要的结果（如类别、序列等），<strong>过程中的某层嵌入都可以作为降维的低维结果</strong>。当然，这种低维结果其实是模型的副产品，因为任务已经解决。比如bert模型得到（中文的）字嵌入。</p>
<h4 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h4><ul>
<li>能够学习到非线性特性</li>
<li>降低数据维度</li>
</ul>
<h4 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h4><ul>
<li>训练的<strong>计算成本高</strong></li>
<li><strong>可解释性较差</strong></li>
<li>背后的数学知识复杂</li>
<li>容易产生<strong>过度拟合</strong>的问题，尽管可以通过引入正则化策略缓解</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/04/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8814%EF%BC%89%E3%80%90Nan%E3%80%91LDA(%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B)/</url>
    <content><![CDATA[<h2 id="LDA-Latent-Dirichlet-Allocation-主题模型"><a href="#LDA-Latent-Dirichlet-Allocation-主题模型" class="headerlink" title="LDA(Latent Dirichlet Allocation) 主题模型"></a><a href="https://zhuanlan.zhihu.com/p/36394491"><em>LDA</em>(Latent Dirichlet Allocation) 主题模型</a></h2><p><strong>同一个主题，在不同的文章中，他出现的比例(概率)是不同的</strong>，看到这里，读者可能已经发现，文档和主题之间的关系和主题和词汇的关系是多么惊人的类似！</p>
<blockquote>
<p>  LDA于2003年由 David Blei, Andrew Ng和 Michael I. Jordan提出，因为模型的简单和有效，掀起了主题模型研究的波浪。虽然说LDA模型简单，但是它的数学推导却不是那么平易近人，一般初学者会深陷数学细节推导中不能自拔。于是牛人们看不下去了，纷纷站出来发表了各种教程。国内方面rickjin有著名的《<a href="https://link.zhihu.com/?target=http%3A//www.52nlp.cn/author/rickjin">LDA数学八卦</a>》，国外的Gregor Heinrich有著名的《<a href="https://link.zhihu.com/?target=https%3A//users.soe.ucsc.edu/~amichelo/docs/text-est2.pdf">Parameter estimation for text analysis</a>》。其实有了这两篇互补的通俗教程，大家沉住心看个4、5遍，基本就可以明白LDA为什么是简单的了。那么其实也没我什么事了，然而心中总有一种被大牛点播的豁然开朗的快感，实在是不吐不快啊。</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8815%EF%BC%89%E8%81%9A%E7%B1%BB*-DBSCAN/</url>
    <content><![CDATA[<h2 id="二、DBSCAN算法【基于密度】"><a href="#二、DBSCAN算法【基于密度】" class="headerlink" title="二、DBSCAN算法【基于密度】"></a>二、DBSCAN算法【基于密度】</h2><blockquote>
<p>  （3）聚类算法之DBSCAN算法 - GISer.Wang的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/77043965">https://zhuanlan.zhihu.com/p/77043965</a></p>
</blockquote>
<p>密度聚类方法的指导思想是，只要样本点的密度大于某阈值，则将该样本添加到最近的簇中。这类算法能克服基于距离的算法只能发现“类圆”（凸）的聚类的缺点，可发现任意形状的聚类，且对噪声数据不敏感。但计算密度单元的计算复杂度大，需要建立空间索引来降低计算量。其代表算法为<strong>DBSCAN算法</strong>和<strong>密度最大值</strong>算法。</p>
<h3 id="2-1-DBSCAN算法原理"><a href="#2-1-DBSCAN算法原理" class="headerlink" title="2.1 DBSCAN算法原理"></a>2.1 DBSCAN算法原理</h3><p><strong><font color="red"> DBCSAN（Density-Based Spatial Clustering of Applications with Noise）是一个比较有代表性的基于密度的聚类算法。</font></strong>与划分和层次聚类方法不同，它将簇定义为密度相连的点的最大集合，能够把具有足够高密度的区域划分为簇，并<strong>可在有“噪声”的数据中发现任意形状的聚类</strong>。</p>
<h3 id="2-2-若干概念"><a href="#2-2-若干概念" class="headerlink" title="2.2 若干概念"></a>2.2 若干概念</h3><p><strong>DBSCAN是基于一组邻域来描述样本集的紧密程度的，参数 <img src="https://www.zhihu.com/equation?tex=%28%CF%B5%2C+MinPts%29" alt="[公式]"> 用来描述邻域的样本分布紧密程度</strong>。其中， <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 描述了某一数据点的<strong>邻域距离阈值（半径）</strong>， <img src="https://www.zhihu.com/equation?tex=MinPts" alt="[公式]"> 描述了数据点<strong>半径为</strong> <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> <strong>的邻域</strong>中数据点个数的最小个数。下面是与密度聚类相关的定义（假设我的样本集是 <img src="https://www.zhihu.com/equation?tex=D%3D%5C%7Bx_1%2Cx_2%2C...%2Cx_m%5C%7D" alt="[公式]"> )：</p>
<ul>
<li><p><strong>对象的ε领域</strong>：给定对象在半径<strong>ε</strong>内的区域；对于 <img src="https://www.zhihu.com/equation?tex=x_j%E2%88%88D" alt="[公式]"> ，其 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域包含样本集 <img src="https://www.zhihu.com/equation?tex=D" alt="[公式]"> 中与 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 的距离不大于 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 的子样本集。即 <img src="https://www.zhihu.com/equation?tex=N_%CF%B5%28x_j%29%3D%5C%7Bx_i%E2%88%88D%7Cdistance%28x_i%2Cx_j%29%E2%89%A4%CF%B5%5C%7D" alt="[公式]"> , 这个子样本集的个数记为 <img src="https://www.zhihu.com/equation?tex=%7CN_%CF%B5%28x_j%29%7C" alt="[公式]"> 。 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域是一个集合</p>
</li>
<li><p><strong>核心对象</strong>：对于任一样本 <img src="https://www.zhihu.com/equation?tex=x_j%E2%88%88D" alt="[公式]"> ，如果其 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域对应的 <img src="https://www.zhihu.com/equation?tex=N_%CF%B5%28x_j%29" alt="[公式]"> 至少包含 <img src="https://www.zhihu.com/equation?tex=MinPts" alt="[公式]"> 个样本，即如果 <img src="https://www.zhihu.com/equation?tex=+%7CN_%CF%B5%28x_j%29%7C%E2%89%A5MinPts" alt="[公式]"> ，则 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 是核心对象。</p>
</li>
<li><p><strong>直接密度可达</strong>：如果 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 位于 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 的 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域中，且 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 是核心对象，则称 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 由 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 密度直达。反之不一定成立，即此时不能说 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 由 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 密度直达, 除非 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 也是核心对象，<strong>即密度直达不满足对称性</strong>。如图ε=1,m=5，q是一个核心对象，从对象q出发到对象p是<strong>直接密度可达</strong>的。</p>
</li>
</ul>
<p><img src="https://i.loli.net/2019/08/01/5d42afb2323b988730.jpg" alt="2019-05-18-061126.jpg" style="zoom:50%;"></p>
<ul>
<li><strong>密度可达</strong>：对于 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> ,如果存在样本样本序列 <img src="https://www.zhihu.com/equation?tex=p_1%2Cp_2%2C...%2Cp_T" alt="[公式]"> ,满足 <img src="https://www.zhihu.com/equation?tex=p1%3Dx_i%2Cp_T%3Dx_j" alt="[公式]"> , 且 <img src="https://www.zhihu.com/equation?tex=p_%7Bt%2B1%7D" alt="[公式]"> 由 <img src="https://www.zhihu.com/equation?tex=p_t" alt="[公式]"> 密度直达，则称 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 由 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 密度可达。也就是说，密度可达满足传递性。此时序列中的传递样本 <img src="https://www.zhihu.com/equation?tex=p_1%2Cp_2%2C...%2Cp_%7BT%E2%88%921%7D" alt="[公式]"><strong>均为核心对象</strong>，因为只有核心对象才能使其他样本密度直达。<strong>密度可达也不满足对称性</strong>，这个可以由密度直达的不对称性得出。</li>
</ul>
<p><img src="https://i.loli.net/2019/08/01/5d42afbfa514735525.jpg" alt="2019-05-18-061154.jpg" style="zoom:50%;"></p>
<ul>
<li><strong>密度相连</strong>：对于 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> ,如果存在核心对象样本 <img src="https://www.zhihu.com/equation?tex=x_k" alt="[公式]"> ，使<strong><img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 均由 <img src="https://www.zhihu.com/equation?tex=x_k" alt="[公式]"> 密度可达</strong>，则称 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 密度相连。<strong>密度相连关系满足对称性</strong>。</li>
</ul>
<p><img src="https://i.loli.net/2019/08/01/5d42afd32fc7340149.jpg" alt="2019-05-18-061202.jpg" style="zoom:50%;"></p>
<ul>
<li><p><strong>==簇：一个基于密度的簇是最大的密度相连对象的集合。==</strong></p>
</li>
<li><p><strong>噪声</strong>：不包含在任何簇中的对象称为噪声。</p>
</li>
</ul>
<p>从下图可以很容易看出理解上述定义，图中 <img src="https://www.zhihu.com/equation?tex=MinPts%3D5" alt="[公式]"> ，红色的点都是核心对象，因为其 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域至少有 <img src="https://www.zhihu.com/equation?tex=5" alt="[公式]"> 个样本。黑色的样本是非核心对象。所有核心对象密度直达的样本在以红色核心对象为中心的圆内，如果不在圆内，则不能密度直达。图中用绿色箭头连起来的核心对象组成了密度可达的样本序列，此序列是一个簇集。在这些密度可达的样本序列的 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域内所有的样本相互都是密度相连的 <strong>(注意，此图中有两个簇集)</strong>。</p>
<p><img src="https://pic2.zhimg.com/80/v2-7d15fc871942e0287be42a12d6d615dd_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h3 id="2-3-DBSCAN密度聚类思想"><a href="#2-3-DBSCAN密度聚类思想" class="headerlink" title="2.3 DBSCAN密度聚类思想"></a>2.3 DBSCAN密度聚类思想</h3><p><strong>DBSCAN的聚类定义很简单</strong>： <strong>由密度可达关系导出的最大密度相连的样本集合，即为我们最终聚类的一个类别，或者说一个簇。（注意是密度相连的集合）</strong>，簇里面可以有一个或者多个核心对象。<strong>如果只有一个核心对象，则簇里其他的非核心对象样本都在这个核心对象的</strong> <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> <strong>-邻域里；如果有多个核心对象，则簇里的任意一个核心对象的</strong> <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -<strong>邻域中一定有一个其他的核心对象，否则这两个核心对象无法密度可达</strong>。这些核心对象的 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域里所有的样本的集合组成的一个DBSCAN聚类簇。</p>
<p>那么怎么才能找到这样的簇样本集合呢？DBSCAN使用的方法很简单，它任意选择一个没有类别的核心对象作为种子，然后找到所有这个核心对象能够<strong>密度可达</strong>的样本集合，即为一个聚类簇。接着继续选择另一个没有类别的核心对象去寻找<strong>密度可达</strong>的样本集合，这样就得到另一个聚类簇 <strong>（这样的得到都肯定是密度相连的）</strong>。一直运行到<strong>所有核心对象都有类别为止。</strong></p>
<p>基本上这就是DBSCAN算法的主要内容了，是不是很简单？<strong>但是我们还是有三个问题没有考虑。</strong></p>
<ul>
<li><strong>异常点问题：</strong>一些异常样本点或者说少量游离于簇外的样本点，这些点不在任何一个核心对象在周围，在DBSCAN中，我们一般将这些样本点标记为噪音点。</li>
<li><strong>距离度量问题</strong>：<strong><font color="red"> 即如何计算某样本和核心对象样本的距离</font></strong>。在DBSCAN中，一般采用最近邻思想，采用某一种距离度量来衡量<strong>样本距离，比如欧式距离、曼哈顿距离</strong>等。</li>
<li><strong>数据点优先级分配问题</strong>：例如某些样本可能到两个核心对象的距离都小于 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> ，但是这两个核心对象由于不是密度直达，又不属于同一个聚类簇，那么如果界定这个样本的类别呢？一般来说，<strong>此时 DBSCAN采用先来后到，先进行聚类的类别簇会标记这个样本为它的类别。也就是说DBSCAN的算法不是完全稳定的算法。</strong></li>
</ul>
<h3 id="2-4-算法步骤"><a href="#2-4-算法步骤" class="headerlink" title="2.4 算法步骤"></a>2.4 算法步骤</h3><p><strong>输入：样本集 <img src="https://www.zhihu.com/equation?tex=D%3D%5C%7Bx_1%2Cx_2%2C...%2Cx_m%5C%7D" alt="[公式]"> ，邻域参数 <img src="https://www.zhihu.com/equation?tex=%28%CF%B5%2CMinPts%29" alt="[公式]"></strong></p>
<ol>
<li>初始化核心对象集合 <img src="https://www.zhihu.com/equation?tex=%CE%A9%3D%E2%88%85%2C" alt="[公式]"> 初始化类别 <img src="https://www.zhihu.com/equation?tex=k%3D0" alt="[公式]"></li>
<li>遍历 <img src="https://www.zhihu.com/equation?tex=D" alt="[公式]"> 的元素，如果是核心对象，则将其加入到核心对象集合 <img src="https://www.zhihu.com/equation?tex=%CE%A9" alt="[公式]"> 中</li>
<li>如果核心对象集合 <img src="https://www.zhihu.com/equation?tex=%CE%A9" alt="[公式]"> 中元素都已经被<strong>访问</strong>，<strong>则算法结束</strong>，<strong>否则转入步骤4</strong>.</li>
<li>在核心对象集合 <img src="https://www.zhihu.com/equation?tex=%CE%A9" alt="[公式]"> 中，随机选择一个<strong>未访问</strong>的核心对象 <img src="https://www.zhihu.com/equation?tex=o" alt="[公式]"> ，首先将 <img src="https://www.zhihu.com/equation?tex=o" alt="[公式]"> 标记为<strong>已访问</strong>，然后将 <img src="https://www.zhihu.com/equation?tex=o" alt="[公式]"> 标记类别 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> ，最后将 <img src="https://www.zhihu.com/equation?tex=o" alt="[公式]"> 的 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> -邻域中<strong>未访问</strong>的数据，存放到种子集合 <img src="https://www.zhihu.com/equation?tex=Seeds" alt="[公式]"> 中。</li>
<li>如果种子集合 <img src="https://www.zhihu.com/equation?tex=Seeds%3D%E2%88%85" alt="[公式]"> ，则当前聚类簇 <img src="https://www.zhihu.com/equation?tex=C_k" alt="[公式]"> 生成完毕, 且 <img src="https://www.zhihu.com/equation?tex=k%3Dk%2B1" alt="[公式]"> ，<strong>跳转到3</strong>。否则，从种子集合 <img src="https://www.zhihu.com/equation?tex=Seeds" alt="[公式]"> 中挑选一个种子点 <img src="https://www.zhihu.com/equation?tex=seed" alt="[公式]"> ，首先将其标记为已访问、标记类别 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]"> ，然后判断 <img src="https://www.zhihu.com/equation?tex=seed" alt="[公式]"> 是否为核心对象，如果是将 <img src="https://www.zhihu.com/equation?tex=seed" alt="[公式]"> 中<strong>未访问</strong>的种子点加入到种子集合中，<strong>跳转到5</strong>。</li>
</ol>
<p><strong>从上述算法可知：</strong></p>
<ul>
<li><strong>每个簇至少包含一个核心对象</strong>；</li>
<li>非核心对象可以是簇的一部分，构成了簇的边缘（edge）；</li>
<li>包含过少对象的簇被认为是噪声；</li>
</ul>
<h3 id="2-5-总结"><a href="#2-5-总结" class="headerlink" title="2.5 总结"></a>2.5 总结</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ol>
<li><strong>可以对任意形状的稠密数据集进行聚类</strong>，相对的，K-Means之类的聚类算法一般只适用于凸数据集。</li>
<li><strong>可以在聚类的同时发现异常点</strong>，对数据集中的异常点不敏感。</li>
<li>聚类结果没有偏倚，相对的，K-Means之类的聚类算法初始值对聚类结果有很大影响。</li>
</ol>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ol>
<li><strong>不能处理密度差异过大（密度不均匀）的聚类</strong>：如果样本集的密度不均匀、聚类间距差相差很大时，聚类质量较差，这时用DBSCAN聚类一般不适合。</li>
<li>如果样本集较大时，聚类收敛时间较长;<strong>此时可以对搜索最近邻时建立的KD树或者球树进行规模限制来改进；</strong></li>
<li>调参相对于传统的K-Means之类的聚类算法稍复杂，<strong>主要需要对距离阈值ϵ，邻域样本数阈值MinPts联合调参，不同的参数组合对最后的聚类效果有较大影响</strong>。【OPTICS算法】</li>
<li><strong>边界点不完全确定性</strong></li>
</ol>
<h3 id="2-6-OPTICS算法"><a href="#2-6-OPTICS算法" class="headerlink" title="2.6 OPTICS算法:"></a>2.6 OPTICS算法:</h3><p><strong>OPTICS主要针对输入参数$ϵ$过敏感做的改进</strong>，OPTICS和DBSCNA的输入参数一样（ <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=MinPts" alt="[公式]"> ），虽然OPTICS算法中也需要两个输入参数，但该算法对 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 输入不敏感（一般将 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 固定为无穷大），同时该算法中并不显式的生成数据聚类，只是对数据集合中的对象进行排序，得到一个有序的对象列表，通过该有序列表，可以得到一个决策图，通过决策图可以不同 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 参数的数据集中检测簇集，即：<strong>先通过固定的 <img src="https://www.zhihu.com/equation?tex=MinPts" alt="[公式]"> 和无穷大的 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 得到有序列表，然后得到决策图，通过决策图可以知道当 <img src="https://www.zhihu.com/equation?tex=%CF%B5" alt="[公式]"> 取特定值时（比如 <img src="https://www.zhihu.com/equation?tex=%CF%B5%3D3" alt="[公式]"> )数据的聚类情况。</strong></p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8816%EF%BC%89%E8%81%9A%E7%B1%BB*-HDBSCAN/</url>
    <content><![CDATA[<h2 id="一、HDBSCAN聚类"><a href="#一、HDBSCAN聚类" class="headerlink" title="一、HDBSCAN聚类"></a>一、HDBSCAN聚类</h2><blockquote>
<p>  <strong>图解HDBSCANS - Mr.g的文章</strong> - 知乎 <a href="https://zhuanlan.zhihu.com/p/412918565">https://zhuanlan.zhihu.com/p/412918565</a></p>
<p>  原文: <a href="https://link.zhihu.com/?target=https%3A//nbviewer.jupyter.org/github/scikit-learn-contrib/hdbscan/blob/master/notebooks/How%20HDBSCAN%20Works.ipynb">How HDBSCAN works</a></p>
<p>  聚类算法(Clustering Algorithms)之层次聚类(Hierarchical Clustering) - 小玉的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/363879425">https://zhuanlan.zhihu.com/p/363879425</a></p>
</blockquote>
<p><strong>HDBSCAN 是由 Campello、Moulavi 和 Sander 开发的聚类算法。它通过将 DBSCAN 转换为层次聚类算法，然后用一种稳定的聚类技术提取出一个扁平的聚类来扩展 DBSCAN</strong>。这篇文章的目标是让你大致了解这个算法的工作原理及其背后的动机。与 HDBSCAN 的原论文不一样，我们这里将不将 DBSCAN 进行对照分析。作者这里更倾向将这算法类比成一种扁平聚类提取方法（ Robust Single Linkage ）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> sklearn.datasets <span class="keyword">as</span> data</span><br><span class="line">%matplotlib inline</span><br><span class="line">sns.set_context(<span class="string">&#x27;poster&#x27;</span>)</span><br><span class="line">sns.set_style(<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">sns.set_color_codes()</span><br><span class="line">plot_kwds = &#123;<span class="string">&#x27;alpha&#x27;</span> : <span class="number">0.5</span>, <span class="string">&#x27;s&#x27;</span> : <span class="number">80</span>, <span class="string">&#x27;linewidths&#x27;</span>:<span class="number">0</span>&#125;</span><br><span class="line"></span><br><span class="line">moons, _ = data.make_moons(n_samples=<span class="number">50</span>, noise=<span class="number">0.05</span>)</span><br><span class="line">blobs, _ = data.make_blobs(n_samples=<span class="number">50</span>, centers=[(-<span class="number">0.75</span>,<span class="number">2.25</span>), (<span class="number">1.0</span>, <span class="number">2.0</span>)], cluster_std=<span class="number">0.25</span>)</span><br><span class="line">test_data = np.vstack([moons, blobs])</span><br><span class="line">plt.scatter(test_data.T[<span class="number">0</span>], test_data.T[<span class="number">1</span>], color=<span class="string">&#x27;b&#x27;</span>, **plot_kwds)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hdbscan</span><br><span class="line">clusterer = hdbscan.HDBSCAN(min_cluster_size=<span class="number">5</span>, gen_min_span_tree=<span class="literal">True</span>)</span><br><span class="line">clusterer.fit(test_data)</span><br></pre></td></tr></table></figure>
<p><strong>现在我们已经对数据聚类完了——但实际发生了什么我们还不知道。我们将拆解成下面5个步骤来进行分析：</strong></p>
<ol>
<li>根据 密度/稀疏度 进行<strong>空间转换</strong>。</li>
<li>构建基于加权距离图的最小生成树。</li>
<li>构建组件之间的层次簇结构。</li>
<li>用最小簇大小压缩层次聚类。</li>
<li>利用压缩好的生成树进行分类。</li>
</ol>
<h3 id="1-1-空间转换"><a href="#1-1-空间转换" class="headerlink" title="1.1 空间转换"></a>1.1 空间转换</h3><p><strong>聚类时我们希望在稀疏带噪声的数据中找到密度更高的族类——噪声的假设很重要</strong>：因为在真实情况下，数据都比较复杂，会有异常值的、缺失的数据和噪声等情况。算法的核心是单链聚类，它对噪声非常敏感：如果噪声数据点放在两个岛屿之间，可能就会将它们连在一起（也就是本来是两个族类的被分成一个）。显然，我们希望我们的算法对噪声具有鲁棒性，因此我们需要在运行单链算法之前找到一种方法来减少噪声。（作者用岛屿来比喻族类，海洋来表示噪声，下面“海洋”和“岛屿”代表这个意思。）</p>
<p><strong>我们要如何在不进行聚类的情况下找出“海洋”和“岛屿”？</strong>只要我们能够估算出样本集的密度，我们就可以认为密度较低的点都是“海洋”。要注意的是这里的目标不是完全区分出“海洋”和“岛屿”——现在只是聚类的初始步骤，并不是最终的输出——现在只是为了使我们的聚类中心对噪声更加鲁棒。因此，要识别出“海洋”的话，我们可以降低海平面（也就是加大容错范围）。出于实际目的，这意味着使每个“海洋”之间以及“海洋”与“岛屿”之间的距离会增加。</p>
<p>当然这只是直觉。它在实际中是如何工作的？我们需要一个计算量少的密度估计方式，简单到只要计算 k 个最近邻点的距离就可以。<strong><font color="red"> 我们可以直接从一个距离矩阵（不管怎样后面都要生成的）中地读取到这个距离；或者，如果我们的指标支持（并且维度较低），用 <a href="https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/neighbors.html%23k-d-tree">kd-trees</a> 来做这种检索就很适合。</font></strong>下面正式将点 x 的参数 k 定义为<strong>核心距离</strong>，并表示为 <img src="https://www.zhihu.com/equation?tex=core_k%28x%29" alt="[公式]"> （与DBSCAN、LOF 和 HDBSCAN 文献一样）。现在我们需要一种降维方法来拉开点之间的距离（相对高维距离）。简单的方法是定义一种新距离公式，我们将其称为（与论文一样)<strong>相互可达距离（mutual reachability distance)。相互可达距离的定义如下：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=d_%7B%5Cmathrm%7Bmreach-%7Dk%7D%28a%2Cb%29+%3D+%5Cmax+%5C%7B%5Cmathrm%7Bcore%7D_k%28a%29%2C+%5Cmathrm%7Bcore%7D_k%28b%29%2C+d%28a%2Cb%29+%5C%7D" alt="[公式]" style="zoom: 150%;"></p>
<p><strong>其中 d(a,b) 是 a 和 b 之间的原始距离</strong>。在这个度量下，密集点（具有低核心距离）之间的距离保持不变，但稀疏的点与其他点的距离被拉远到用core距离来计算。这有效地“降低了海平面”，减少稀疏的“海”点，同时使“陆地”保持原状。需要注意的是，显然 k 取值很关键；较大的 k 值将更多的点圈到“海”中。下面用图片来解析更容易理解，先让k=5。然后对于给定的点，我们可以为核心距离绘制一个圆刚好圈到第六个临近点（包括点本身），如下所示：</p>
<p><img src="https://pic2.zhimg.com/80/v2-dbf4559853b0d81f1c5ae2205a7b97a9_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p><strong>再选择另一个点</strong>，进行同样的操作，这次选到另一组临近点集合（其中一些点可能是上一组的临近点）。</p>
<p><img src="https://pic3.zhimg.com/80/v2-308c1bb09e8f779232aac217bee2507e_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p>我们再选一个点再做一遍，得到第三组临近点。</p>
<p><img src="https://pic4.zhimg.com/80/v2-0e0e83ecf594b202cea6d3c208e45f0f_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>如果我们现在想知道蓝绿两组之间的相互可达距离，我们可以像下图，先画一个箭头连接蓝绿两个圆心：它穿过蓝色圆心，但不穿过绿色圆圈——绿色的核心距离大于蓝色和绿色之间的距离。<strong>因此，我们认为蓝色和绿色之间的相互可达距离更大——也就是绿色圆圈的半径（如果我们将一端设在绿色点上，则最容易想象）。</strong></p>
<p>实际上，有<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1506.06422v2.pdf">基础理论</a>可以证明<strong>相互可达距离</strong>作为一种变换，在允许单链接聚类的情况下，更接近层次水平上的真实密度分布。</p>
<h3 id="1-2-构建最小生成树"><a href="#1-2-构建最小生成树" class="headerlink" title="1.2 构建最小生成树"></a><strong>1.2 构建最小生成树</strong></h3><p><strong>为了从密集的数据集上找到“岛屿”，现在我们有了新的指标：相互可达性</strong>。当然密集区是相对的，不同的“岛屿”可能会有不同的密度。<strong><font color="red"> 理论上，我们要做的是：将数据当成是一个加权图，以数据点作为顶点，任意两点之间的边的权重等于这些点的相互可达距离。</font></strong></p>
<p>现在考虑一个阈值，一开始很高，然后逐渐变小。丢弃权重高于该阈值的任何边。我们删除边的同时，连接的组件从图里断开。最终，我们将拥有不同阈值级别的连接元件（从完全连接到完全断开）的层次结构。</p>
<p>实际当中，这样操纵非常耗时：有 <a href="https://zhuanlan.zhihu.com/p/412918565/edit#">n^2</a> 条边，我们不想多次计算连通组件算法。正确的做法是找到最小的边集，从这个集合中删除任何边都会导致组件的连接断开。但是我们还需要找到更多这样的边，使得找不到更小的边来连接组件。幸运的是，图论为我们提供了这样的东西：<strong>图的最小生成树</strong>。</p>
<p>我们可以通过 Prim 的算法非常有效地构建最小生成树——我们一次构建一条边，每次都把当前最小权重的边去连接一个尚未加入到树中的节点。可以看到下面HDBSCAN构造的树 ；请注意，这是相互可达距离的最小生成树，与图中的纯距离不同。在这种情况下，我们的 k 值为 5。 在这个例子中，存在一种更快的方法，例如用 <strong>Dual Tree Boruvka 来构建最小生成树。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">clusterer.minimum_spanning_tree_.plot(edge_cmap=<span class="string">&#x27;viridis&#x27;</span>, </span><br><span class="line">                                      edge_alpha=<span class="number">0.6</span>, </span><br><span class="line">                                      node_size=<span class="number">80</span>, </span><br><span class="line">                                      edge_linewidth=<span class="number">2</span>)   </span><br></pre></td></tr></table></figure>
<p><img src="https://pic2.zhimg.com/80/v2-a4b387ac9c43b1f681589529c82fe68d_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h3 id="1-3-构建层次聚类"><a href="#1-3-构建层次聚类" class="headerlink" title="1.3 构建层次聚类"></a>1.3 <strong>构建层次聚类</strong></h3><p><strong>给定最小生成树，下一步是将其转换为层次结构的组件</strong>。这最容易以相反的顺序完成：按距离（按递增顺序）对树的边进行排序，然后迭代，为每条边新建一个合并后的簇。这里唯一困难是识别每条边将连接在哪两个簇上，但这通过联合查找数据结构很容易。我们可以将结果视为树状图，如下所示：</p>
<p><img src="https://pic1.zhimg.com/80/v2-33a8cb27ae3ea0009e1ad77b438cf458_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>这图可以告诉我们这个鲁棒的单一链接会在哪挺下来。我们想知道；层次结构结构的聚类虽好，但我们想要的是一个扁平的聚类。我们可以通过在上图中画一条水平线并选择它穿过的聚类，来做到这一点。这实际上是 DBSCAN 里用到的操作（将只能切割成单一集群的作为噪声）。<strong>问题是，我们怎么知道在哪里画这条线？ DBSCAN 只是把它作为一个（非常不直观的）参数</strong>。更糟糕的是，我们真的要用来处理可变密度的聚类，并希望任何切割线都是通过相互可达距离选出来的，并且今后固定在一个密度水平上。理想情况下，我们希望能够在不同的地方切割树，来选择我们的聚类。这是 HDBSCAN 下一步开始的地方，并与鲁棒的单一链接产生差异。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8817%EF%BC%89KNN/</url>
    <content><![CDATA[<h2 id="1-什么是KNN【KD树-SIFT-BBF算法】"><a href="#1-什么是KNN【KD树-SIFT-BBF算法】" class="headerlink" title="1. 什么是KNN【KD树 + SIFT+BBF算法】"></a>1. 什么是KNN【KD树 + SIFT+BBF算法】</h2><blockquote>
<p>  KNN与KD树：<a href="https://www.joinquant.com/view/community/detail/dd60bd4e89761b916fe36dc4d14bb272">https://www.joinquant.com/view/community/detail/dd60bd4e89761b916fe36dc4d14bb272</a></p>
<p>  【数学】kd 树算法之详细篇 - 椰了的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/23966698">https://zhuanlan.zhihu.com/p/23966698</a></p>
<p>  <strong>KNN是生成式模型还是判别式的</strong>，为什么？ - 风控算法小白的回答 - 知乎 <a href="https://www.zhihu.com/question/475072467/answer/2027766449">https://www.zhihu.com/question/475072467/answer/2027766449</a></p>
</blockquote>
<h3 id="1-1-KNN的通俗解释"><a href="#1-1-KNN的通俗解释" class="headerlink" title="1.1 KNN的通俗解释"></a>1.1 KNN的通俗解释</h3><p>何谓K近邻算法，即K-Nearest Neighbor algorithm，简称KNN算法，单从名字来猜想，可以简单粗暴的认为是：K个最近的邻居，当K=1时，算法便成了最近邻算法，即寻找最近的那个邻居。</p>
<p>用官方的话来说，所谓K近邻算法，即是给定一个训练数据集，对新的输入实例，<strong>在训练数据集中找到与该实例最邻近的K个实例（也就是上面所说的K个邻居），这K个实例的多数属于某个类，就把该输入实例分类到这个类中。</strong></p>
<p>​                                                                     <a href="https://camo.githubusercontent.com/f0eabe33161ae7f977f082590a3690be147319df428ad1695c79127ad406729d/68747470733a2f2f6a756c796564752d696d672e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f717565736261736536343135353238333936333437323839353636302e6a7067"><img src="https://camo.githubusercontent.com/f0eabe33161ae7f977f082590a3690be147319df428ad1695c79127ad406729d/68747470733a2f2f6a756c796564752d696d672e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f717565736261736536343135353238333936333437323839353636302e6a7067" alt="img"></a></p>
<p>​                                                                <a href="https://camo.githubusercontent.com/a8942eed547ab4f08494126b0d2e5480fdfc795252e4a34a956c2b959cb5c6b8/68747470733a2f2f6a756c796564752d696d672e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f717565736261736536343135353238333936363635343430333634362e706e67"><img src="https://camo.githubusercontent.com/a8942eed547ab4f08494126b0d2e5480fdfc795252e4a34a956c2b959cb5c6b8/68747470733a2f2f6a756c796564752d696d672e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f717565736261736536343135353238333936363635343430333634362e706e67" alt="img"></a></p>
<p>如上图所示，有两类不同的样本数据，分别用蓝色的小正方形和红色的小三角形表示，而图正中间的那个绿色的圆所标示的数据则是待分类的数据。也就是说，现在，我们不知道中间那个绿色的数据是从属于哪一类（蓝色小正方形or红色小三角形），KNN就是解决这个问题的。</p>
<p>如果<strong>K=3</strong>，绿色圆点的最近的3个邻居是2个红色小三角形和1个蓝色小正方形，少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于<strong>红色</strong>的三角形一类。</p>
<p>如果<strong>K=5</strong>，绿色圆点的最近的5个邻居是2个红色三角形和3个蓝色的正方形，还是少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于<strong>蓝色</strong>的正方形一类。</p>
<p><strong>于此我们看到，当无法判定当前待分类点是从属于已知分类中的哪一类时，我们可以依据统计学的理论看它所处的位置特征，衡量它周围邻居的权重，而把它归为(或分配)到权重更大的那一类。这就是K近邻算法的核心思想。</strong></p>
<h3 id="1-2-近邻的距离度量"><a href="#1-2-近邻的距离度量" class="headerlink" title="1.2 近邻的距离度量"></a>1.2 近邻的距离度量</h3><p>我们看到，K近邻算法的核心在于找到实例点的邻居，这个时候，问题就接踵而至了，如何找到邻居，邻居的判定标准是什么，用什么来度量。这一系列问题便是下面要讲的距离度量表示法。</p>
<p><strong>有哪些距离度量的表示法</strong>(普及知识点，可以跳过)：</p>
<ol>
<li><p><strong>==欧氏距离==</strong>，最常见的两点之间或多点之间的距离表示法，又称之为<strong>欧几里得度量</strong>，它定义于欧几里得空间中，如点 x = (x1,…,xn) 和 y = (y1,…,yn) 之间的距离为：</p>
<p><a href="https://camo.githubusercontent.com/0699ac91c0bb89297e4cf418ad7d46cac175652d1a1de30fccc66a16a0eef254/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f6428782c79293d2535437371727425374228785f312d795f3129253545322b28785f322d795f3229253545322b2e2e2e2b28785f6e2d795f6e29253545322537443d2535437371727425374225354373756d5f253742693d312537442535452537426e25374428785f692d795f692925354532253744"><img src="https://camo.githubusercontent.com/0699ac91c0bb89297e4cf418ad7d46cac175652d1a1de30fccc66a16a0eef254/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f6428782c79293d2535437371727425374228785f312d795f3129253545322b28785f322d795f3229253545322b2e2e2e2b28785f6e2d795f6e29253545322537443d2535437371727425374225354373756d5f253742693d312537442535452537426e25374428785f692d795f692925354532253744" alt="img"></a></p>
<ul>
<li><p>二维平面上两点a(x1,y1)与b(x2,y2)间的欧氏距离：</p>
<p><a href="https://camo.githubusercontent.com/b21b48fd9bce0b9f47d16d8e5505a6b600a02e1032632df73a77d5ba43012e2a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228785f312d785f3229253545322b28795f312d795f322925354532253744"><img src="https://camo.githubusercontent.com/b21b48fd9bce0b9f47d16d8e5505a6b600a02e1032632df73a77d5ba43012e2a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228785f312d785f3229253545322b28795f312d795f322925354532253744" alt="img"></a></p>
</li>
<li><p>三维空间两点a(x1,y1,z1)与b(x2,y2,z2)间的欧氏距离：</p>
<p><a href="https://camo.githubusercontent.com/ebf7fbc4dd6e6eb0d80576e7e5cd19d38ea7a8b9cd801680fc9b39f242367515/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228785f312d785f3229253545322b28795f312d795f3229253545322b287a5f312d7a5f322925354532253744"><img src="https://camo.githubusercontent.com/ebf7fbc4dd6e6eb0d80576e7e5cd19d38ea7a8b9cd801680fc9b39f242367515/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228785f312d785f3229253545322b28795f312d795f3229253545322b287a5f312d7a5f322925354532253744" alt="img"></a></p>
</li>
<li><p>两个n维向量a(x11,x12,…,x1n)与 b(x21,x22,…,x2n)间的欧氏距离：</p>
<p><a href="https://camo.githubusercontent.com/62f0123f5d52ed280b23c7972c60f635d52a02d0b4958bd5bf0a7c61328f3225/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374225354373756d5f2537426b3d312537442535452537426e25374428785f253742316b2537442d785f253742326b2537442925354532253744"><img src="https://camo.githubusercontent.com/62f0123f5d52ed280b23c7972c60f635d52a02d0b4958bd5bf0a7c61328f3225/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374225354373756d5f2537426b3d312537442535452537426e25374428785f253742316b2537442d785f253742326b2537442925354532253744" alt="img"></a></p>
<p>也可以用表示成向量运算的形式：</p>
<p><a href="https://camo.githubusercontent.com/8e7528374c22f456904f868c6619a94ba0e51180896315eb3b019f9d7b358742/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228612d622928612d622925354554253744"><img src="https://camo.githubusercontent.com/8e7528374c22f456904f868c6619a94ba0e51180896315eb3b019f9d7b358742/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d2535437371727425374228612d622928612d622925354554253744" alt="img"></a></p>
</li>
</ul>
</li>
<li><p><strong>曼哈顿距离</strong>，我们可以定义曼哈顿距离的正式意义为L1-距离或城市区块距离，也就是在<strong>==欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和==</strong>。例如在平面上，坐标（x1, y1）的点P1与坐标（x2, y2）的点P2的曼哈顿距离为： <a href="https://camo.githubusercontent.com/eeacd6c593ac3eadb18eebfdaf9e27626a54b8f8bdb9f53bc11a90713e8b0bf8/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f253743785f312d785f322537432b253743795f312d795f32253743"><img src="https://camo.githubusercontent.com/eeacd6c593ac3eadb18eebfdaf9e27626a54b8f8bdb9f53bc11a90713e8b0bf8/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f253743785f312d785f322537432b253743795f312d795f32253743" alt="img"></a>，要注意的是，曼哈顿距离依赖座标系统的转度，而非系统在座标轴上的平移或映射。</p>
<p>通俗来讲，想象你在曼哈顿要从一个十字路口开车到另外一个十字路口，驾驶距离是两点间的直线距离吗？显然不是，除非你能穿越大楼。而实际驾驶距离就是这个“曼哈顿距离”，此即曼哈顿距离名称的来源， 同时，曼哈顿距离也称为城市街区距离(City Block distance)。</p>
<ul>
<li><p>二维平面两点a(x1,y1)与b(x2,y2)间的曼哈顿距离</p>
<p><a href="https://camo.githubusercontent.com/c914feff78b9ccb3f920a67c8dba69b110d641abde5f2533f184a656780cb94d/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d253743785f312d785f322537432b253743795f312d795f32253743"><img src="https://camo.githubusercontent.com/c914feff78b9ccb3f920a67c8dba69b110d641abde5f2533f184a656780cb94d/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d253743785f312d785f322537432b253743795f312d795f32253743" alt="img"></a></p>
</li>
<li><p>两个n维向量a(x11,x12,…,x1n)与 b(x21,x22,…,x2n)间的曼哈顿距离</p>
<p><a href="https://camo.githubusercontent.com/eb4a219d2fbe50979339a7e1a83464ec27957562f106da7a3b08da8cc3394795/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d25354373756d5f2537426b3d312537442535452537426e253744253743785f253742316b2537442d785f253742326b253744253743"><img src="https://camo.githubusercontent.com/eb4a219d2fbe50979339a7e1a83464ec27957562f106da7a3b08da8cc3394795/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d25354373756d5f2537426b3d312537442535452537426e253744253743785f253742316b2537442d785f253742326b253744253743" alt="img"></a></p>
</li>
</ul>
</li>
<li><p><strong>切比雪夫距离</strong>，若二个向量或二个点p 、and q，其座标分别为Pi及qi，则两者之间的切比雪夫距离定义如下：</p>
<p><a href="https://camo.githubusercontent.com/3a305bb0cf8cdcd6a77f9e2e2cc1085542ae46f8c70c5b43c67be9728d3d99d6/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f445f25374243686562797368657625374428702c71293d6d61785f6928253743705f692d715f6925374329"><img src="https://camo.githubusercontent.com/3a305bb0cf8cdcd6a77f9e2e2cc1085542ae46f8c70c5b43c67be9728d3d99d6/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f445f25374243686562797368657625374428702c71293d6d61785f6928253743705f692d715f6925374329" alt="img"></a></p>
<p>这也等于以下Lp度量的极值： <a href="https://camo.githubusercontent.com/8fe6945bfb5795e12cfe28b72758c59a598e0c5a89b1ffb874f01cc8ff77a7ba/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d32345f32322d31392d34312e706e67"><img src="https://camo.githubusercontent.com/8fe6945bfb5795e12cfe28b72758c59a598e0c5a89b1ffb874f01cc8ff77a7ba/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d32345f32322d31392d34312e706e67" alt="img"></a>，因此切比雪夫距离也称为L∞度量。</p>
<p>以数学的观点来看，切比雪夫距离是由一致范数（uniform norm）（或称为上确界范数）所衍生的度量，也是超凸度量（injective metric space）的一种。</p>
<p>在平面几何中，若二点p及q的直角坐标系坐标为(x1,y1)及(x2,y2)，则切比雪夫距离为：</p>
<p><a href="https://camo.githubusercontent.com/2c68232279b3d8c857a5ebf5bcb91f6792abeb47daedeb22214391611680dd97/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f445f25374243686573732537443d6d617828253743785f322d785f312537432c253743795f322d795f3125374329"><img src="https://camo.githubusercontent.com/2c68232279b3d8c857a5ebf5bcb91f6792abeb47daedeb22214391611680dd97/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f445f25374243686573732537443d6d617828253743785f322d785f312537432c253743795f322d795f3125374329" alt="img"></a></p>
<p><strong>玩过国际象棋的朋友或许知道，国王走一步能够移动到相邻的8个方格中的任意一个。那么国王从格子(x1,y1)走到格子(x2,y2)最少需要多少步？。你会发现最少步数总是max( | x2-x1 | , | y2-y1 | ) 步 。有一种类似的一种距离度量方法叫切比雪夫距离。</strong></p>
<ul>
<li><p>二维平面两点a(x1,y1)与b(x2,y2)间的切比雪夫距离 ：</p>
<p><a href="https://camo.githubusercontent.com/9387d181258b2a722bcabf891beb2d616a2ec297f35bade87679099641f27f09/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d6d617828253743785f322d785f312537432c253743795f322d795f3125374329"><img src="https://camo.githubusercontent.com/9387d181258b2a722bcabf891beb2d616a2ec297f35bade87679099641f27f09/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d6d617828253743785f322d785f312537432c253743795f322d795f3125374329" alt="img"></a></p>
</li>
<li><p>两个n维向量a(x11,x12,…,x1n)与 b(x21,x22,…,x2n)间的切比雪夫距离：</p>
<p><a href="https://camo.githubusercontent.com/ea4a630eab19efb4c0270f3808dde70fec7bb5f21d37f76ab016316277fbb730/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d6d61785f6928253743785f25374231692537442d785f253742326925374425374329"><img src="https://camo.githubusercontent.com/ea4a630eab19efb4c0270f3808dde70fec7bb5f21d37f76ab016316277fbb730/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f645f25374231322537443d6d61785f6928253743785f25374231692537442d785f253742326925374425374329" alt="img"></a></p>
</li>
</ul>
</li>
</ol>
<p><strong>==简单说来，各种“距离”的应用场景简单概括为：==</strong></p>
<ul>
<li><strong>空间：欧氏距离</strong>，</li>
<li><strong>路径：曼哈顿距离，国际象棋国王：切比雪夫距离</strong>，</li>
<li>以上三种的统一形式:闵可夫斯基距离，</li>
<li>加权：标准化欧氏距离，</li>
<li>排除量纲和依存：马氏距离，</li>
<li>向量差距：夹角余弦，</li>
<li><strong>编码差别：汉明距离</strong>，</li>
<li>集合近似度：杰卡德类似系数与距离，</li>
<li>相关：相关系数与相关距离。</li>
</ul>
<h3 id="1-3-K值选择"><a href="#1-3-K值选择" class="headerlink" title="1.3 K值选择"></a>1.3 K值选择</h3><ol>
<li>如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，<strong>K值的减小就意味着整体模型变得复杂，容易发生过拟合；</strong></li>
<li>如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且<strong>K值的增大就意味着整体的模型变得简单。</strong></li>
<li>K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的累，模型过于简单，忽略了训练实例中大量有用信息。</li>
</ol>
<p>在实际应用中，K值一般取一个比较小的数值，<strong>例如采用交叉验证法（简单来说，就是一部分样本做训练集，一部分做测试集）来选择最优的K值。</strong></p>
<h3 id="1-4-KNN最近邻分类算法的过程"><a href="#1-4-KNN最近邻分类算法的过程" class="headerlink" title="1.4 KNN最近邻分类算法的过程"></a>1.4 KNN最近邻分类算法的过程</h3><ol>
<li>计算测试样本和训练样本中每个样本点的距离（常见的距离度量有欧式距离，马氏距离等）；</li>
<li>对上面所有的距离值进行排序；</li>
<li>选前 k 个最小距离的样本；</li>
<li>根据这 k 个样本的标签进行投票，得到最后的分类类别；</li>
</ol>
<h2 id="关于KNN的一些问题"><a href="#关于KNN的一些问题" class="headerlink" title="关于KNN的一些问题"></a>关于KNN的一些问题</h2><ol>
<li><p>在k-means或kNN，我们是用欧氏距离来计算最近的邻居之间的距离。为什么不用<strong>曼哈顿距离</strong>？</p>
<p><strong>答：</strong>我们不用曼哈顿距离，因为它只计算水平或垂直距离，有维度的限制。另一方面，欧式距离可用于任何空间的距离计算问题。因为，数据点可以存在于任何空间，欧氏距离是更可行的选择。例如：想象一下国际象棋棋盘，象或车所做的移动是由曼哈顿距离计算的，因为它们是在各自的水平和垂直方向的运动。</p>
</li>
<li><p>KD-Tree相比KNN来进行快速图像特征比对的好处在哪里?</p>
<p>答：极大的节约了时间成本．点线距离如果 &gt;　最小点，无需回溯上一层，如果&lt;,则再上一层寻找。</p>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8818%EF%BC%89TF-IDF/</url>
    <content><![CDATA[<h2 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h2><blockquote>
<p>  <a href="https://blog.csdn.net/u010417185/article/details/87905899">https://blog.csdn.net/u010417185/article/details/87905899</a></p>
</blockquote>
<p><strong>TF-IDF(Term Frequency-Inverse Document Frequency, 词频-逆文件频率)</strong>是一种用于资讯检索与资讯探勘的常用<a href="https://www.zhihu.com/search?q=加权技术&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;97273457&quot;}">加权技术</a>。TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。</p>
<p>上述引用总结就是, <strong>一个词语在一篇文章中出现次数越多, 同时在所有文档中出现次数越少, 越能够代表该文章。</strong>这也就是TF-IDF的含义。</p>
<h4 id="1-1-TF"><a href="#1-1-TF" class="headerlink" title="1.1 TF"></a><strong>1.1 TF</strong></h4><p><strong>TF(Term Frequency, ==词频==)</strong>表示词条在文本中出现的频率，这个数字通常会被归一化(一般是词频除以文章总词数), 以防止它偏向长的文件（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否）。TF用公式表示如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=TF_%7Bi%2Cj%7D%3D%5Cfrac%7Bn_%7Bi%2Cj%7D%7D%7B%5Csum_%7Bk%7D%7Bn_%7Bk%2Cj%7D%7D%7D%5Ctag%7B1%7D+%5C%5C" alt="[公式]"></p>
<p>其中，<img src="https://www.zhihu.com/equation?tex=n_%7Bi%2Cj%7D" alt="[公式]"> 表示词条 <img src="https://www.zhihu.com/equation?tex=t_i" alt="[公式]"> 在文档 <img src="https://www.zhihu.com/equation?tex=d_j" alt="[公式]"> 中出现的次数，<img src="https://www.zhihu.com/equation?tex=TF_%7Bi%2Cj%7D" alt="[公式]"> 就是表示词条 <img src="https://www.zhihu.com/equation?tex=t_i" alt="[公式]"> 在文档 <img src="https://www.zhihu.com/equation?tex=d_j" alt="[公式]"> 中出现的频率。</p>
<p>但是，需要注意， 一些<strong>通用的词语对于主题并没有太大的作用</strong>， <strong>反倒是一些出现频率较少的词才能够表达文章的主题</strong>， 所以单纯使用是TF不合适的。权重的设计必须满足：一个词预测主题的能力越强，权重越大，反之，权重越小。所有统计的文章中，一些词只是在其中很少几篇文章中出现，那么这样的词对文章的主题的作用很大，这些词的权重应该设计的较大。IDF就是在完成这样的工作。</p>
<h4 id="1-2-IDF"><a href="#1-2-IDF" class="headerlink" title="1.2 IDF"></a><strong>1.2 IDF</strong></h4><p><strong>IDF(Inverse Document Frequency, ==逆文件频率==)</strong>表示关键词的普遍程度。如果包含词条 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]"> 的文档越少， <strong>IDF</strong>越大，则说明该词条具有很好的类别区分能力。某一特定词语的<strong>IDF</strong>，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到:</p>
<p><img src="https://www.zhihu.com/equation?tex=IDF_i%3D%5Clog%5Cfrac%7B%5Cleft%7CD+%5Cright%7C%7D%7B1%2B%5Cleft%7Cj%3A+t_i+%5Cin+d_j%5Cright%7C%7D%5Ctag%7B2%7D+%5C%5C" alt="[公式]"></p>
<p>其中，<img src="https://www.zhihu.com/equation?tex=%5Cleft%7CD+%5Cright%7C" alt="[公式]"> 表示所有<strong>文档的数量</strong>，<img src="https://www.zhihu.com/equation?tex=%5Cleft%7Cj%3A+t_i+%5Cin+d_j%5Cright%7C" alt="[公式]"> 表示包<strong>含词条 <img src="https://www.zhihu.com/equation?tex=t_i" alt="[公式]"> 的文档数量</strong>，为什么这里要加 1 呢？主要是<strong>防止包含词条 <img src="https://www.zhihu.com/equation?tex=t_i" alt="[公式]"> 的数量为 0 从而导致运算出错的现象发生</strong>。</p>
<p>某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于<strong>过滤掉常见的词语，保留重要的词语</strong>，表达为</p>
<p><img src="https://www.zhihu.com/equation?tex=TF+%5Ctext%7B-%7DIDF%3D+TF+%5Ccdot+IDF%5Ctag%7B3%7D+%5C%5C" alt="[公式]"></p>
<p>==<strong>最后</strong>在计算完文档中每个字符的tfidf之后，对其进行归一化，将值保留在0-1之间，并保存成稀疏矩阵。==</p>
<h2 id="TF-IDF-Q-amp-A"><a href="#TF-IDF-Q-amp-A" class="headerlink" title="TF-IDF Q&amp;A"></a>TF-IDF Q&amp;A</h2><h3 id="1、究竟应该是对整个语料库进行tf-idf呢？还是先对训练集进行tf-idf，然后再对xtest进行tf-idf呢？两者有什么区别？"><a href="#1、究竟应该是对整个语料库进行tf-idf呢？还是先对训练集进行tf-idf，然后再对xtest进行tf-idf呢？两者有什么区别？" class="headerlink" title="1、究竟应该是对整个语料库进行tf-idf呢？还是先对训练集进行tf-idf，然后再对xtest进行tf-idf呢？两者有什么区别？"></a><strong>1、究竟应该是对整个语料库进行tf-idf呢？还是先对训练集进行tf-idf，然后再对xtest进行tf-idf呢？两者有什么区别？</strong></h3><blockquote>
<h4 id="fit"><a href="#fit" class="headerlink" title="fit"></a>fit</h4><p>  学习输入的数据有多少个不同的单词，以及每个单词的idf</p>
<h4 id="transform-训练集"><a href="#transform-训练集" class="headerlink" title="transform 训练集"></a>transform 训练集</h4><p>  返回我们一个document-term matrix.</p>
<h4 id="transform-测试集"><a href="#transform-测试集" class="headerlink" title="transform 测试集"></a>transform 测试集</h4></blockquote>
<p>transform的过程也很让人好奇。要知道，他是将测试集的数据中的文档数量纳入进来，重新计算每个词的idf呢，还是<strong>直接用训练集学习到的idf去计算测试集里面每一个tf-idf</strong>呢？</p>
<p><strong>如果纳入了测试集新词，就等于预先知道测试集中有什么词，影响了idf的权重。这样预知未来的行为，会导致算法丧失了泛化性。</strong></p>
<h3 id="2、TF-IDF-模型加载太慢"><a href="#2、TF-IDF-模型加载太慢" class="headerlink" title="2、TF-IDF 模型加载太慢"></a>2、TF-IDF 模型加载太慢</h3><blockquote>
<p>  <a href="https://thiagomarzagao.com/2015/12/08/saving-TfidfVectorizer-without-pickles/">https://thiagomarzagao.com/2015/12/08/saving-TfidfVectorizer-without-pickles/</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> idfs <span class="keyword">import</span> idfs <span class="comment"># numpy array with our pre-computed idfs</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># subclass TfidfVectorizer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyVectorizer</span>(<span class="title class_ inherited__">TfidfVectorizer</span>):</span><br><span class="line">    <span class="comment"># plug our pre-computed IDFs</span></span><br><span class="line">    TfidfVectorizer.idf_ = idfs</span><br><span class="line"></span><br><span class="line"><span class="comment"># instantiate vectorizer</span></span><br><span class="line">vectorizer = MyVectorizer(lowercase = <span class="literal">False</span>,</span><br><span class="line">                          min_df = <span class="number">2</span>,</span><br><span class="line">                          norm = <span class="string">&#x27;l2&#x27;</span>,</span><br><span class="line">                          smooth_idf = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plug _tfidf._idf_diag</span></span><br><span class="line">vectorizer._tfidf._idf_diag = sp.spdiags(idfs,</span><br><span class="line">                                         diags = <span class="number">0</span>,</span><br><span class="line">                                         m = <span class="built_in">len</span>(idfs),</span><br><span class="line">                                         n = <span class="built_in">len</span>(idfs))</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2023/04/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%8819%EF%BC%89%E3%80%90TODO%E3%80%91FP-growth/</url>
    <content><![CDATA[<h2 id="FP-growth"><a href="#FP-growth" class="headerlink" title="FP-growth"></a>FP-growth</h2><blockquote>
<ul>
<li>数据挖掘随笔（一）频繁模式挖掘与关联规则挖掘以及Apriori算法（python实现）：<a href="https://zhuanlan.zhihu.com/p/410019734">https://zhuanlan.zhihu.com/p/410019734</a></li>
<li>数据挖掘随笔（二）FP-growth算法——一种用于频繁模式挖掘的模式增长方式(Python实现)：<a href="https://zhuanlan.zhihu.com/p/411594391">https://zhuanlan.zhihu.com/p/411594391</a></li>
</ul>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%882%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/</url>
    <content><![CDATA[<h2 id="六、A-B-测试"><a href="#六、A-B-测试" class="headerlink" title="六、A/B 测试"></a>六、A/B 测试</h2><blockquote>
<p>  【AB测试最全干货】史上最全知识点及常见面试题（上篇） - 数据分析狗一枚的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/375902281">https://zhuanlan.zhihu.com/p/375902281</a></p>
</blockquote>
<h4 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h4><p>科学家门捷列夫说「没有测量，就没有科学」，在AI场景下我们同样需要定量的数值化指标来指导我们更好地应用模型对数据进行学习和建模。</p>
<p>事实上，在机器学习领域，对模型的测量和评估至关重要。选择与问题相匹配的评估方法，能帮助我们快速准确地发现在模型选择和训练过程中出现的问题，进而对模型进行优化和迭代。本文我们系统地讲解一下机器学习模型评估相关知识。</p>
<h4 id="6-1-模型评估的目标"><a href="#6-1-模型评估的目标" class="headerlink" title="6.1 模型评估的目标"></a>6.1 模型评估的目标</h4><p><strong>模型评估的目标是选出泛化能力强的模型完成机器学习任务</strong>。实际的机器学习任务往往需要进行大量的实验，经过反复调参、使用多种模型算法（甚至多模型融合策略）来完成自己的机器学习问题，并观察哪种模型算法在什么样的参数下能够最好地完成任务。</p>
<p>但是我们无法提前获取「未知的样本」，因此我们会基于已有的数据进行切分来完成模型训练和评估，借助于切分出的数据进行评估，可以很好地判定模型状态（过拟合 or 欠拟合），进而迭代优化。</p>
<p>在建模过程中，为了获得泛化能力强的模型，我们需要一整套方法及评价指标。</p>
<ul>
<li><strong>评估方法</strong>：为保证客观地评估模型，对数据集进行的有效划分实验方法。</li>
<li><strong>性能指标</strong>：量化地度量模型效果的指标。</li>
</ul>
<h4 id="6-2-离线与在线实验方法"><a href="#6-2-离线与在线实验方法" class="headerlink" title="6.2 离线与在线实验方法"></a>6.2 离线与在线实验方法</h4><p>进行评估的实验方法可以分为「离线」和「在线」两种。</p>
<h4 id="离线实验方法："><a href="#离线实验方法：" class="headerlink" title="离线实验方法："></a>离线实验方法：</h4><blockquote>
<p>  在<strong>离线评估</strong>中，经常使用<strong>准确率（Accuracy）、查准率（Precision）、召回率（Recall）、ROC、AUC、PRC</strong>等指标来评估模型。</p>
</blockquote>
<p><strong>模型评估通常指离线试验</strong>。原型设计（Prototyping）阶段及离线试验方法，包含以下几个过程：</p>
<ul>
<li>使用历史数据训练一个适合解决目标任务的一个或多个机器学习模型。</li>
<li>对模型进行验证（Validation）与离线评估（Offline Evaluation）。</li>
<li>通过评估指标选择一个较好的模型。</li>
</ul>
<h4 id="在线实验方法："><a href="#在线实验方法：" class="headerlink" title="在线实验方法："></a>在线实验方法：</h4><blockquote>
<p>  <strong>在线评估</strong>与离线评估所用的评价指标不同，一般使用一些商业评价指标，如<strong>用户生命周期值（Customer Lifetime value）、广告点击率（Click Through Rate）、用户流失率</strong>（Customer Churn Rate）等标。</p>
</blockquote>
<p>除了离线评估之外，其实还有一种在线评估的实验方法。由于模型是在老的模型产生的数据上学习和验证的，而线上的数据与之前是不同的，因此离线评估并不完全代表线上的模型结果。因此我们需要在线评估，来验证模型的有效性。</p>
<p><img src="https://www.zhihu.com/equation?tex=A%2FB%20%5Cquad%20Test" alt="公式"> <strong>是目前在线测试中最主要的方法</strong>。<img src="https://www.zhihu.com/equation?tex=A%2FB%20%5Cquad%20Test" alt="公式"> 是为同一个目标制定两个方案让一部分用户使用 <img src="https://www.zhihu.com/equation?tex=A" alt="公式"> 方案，另一部分用户使用 <img src="https://www.zhihu.com/equation?tex=B" alt="公式"> 方案，记录下用户的使用情况，看哪个方案更符合设计目标。如果不做AB实验直接上线新方案，新方案甚至可能会毁掉你的产品。</p>
<h4 id="6-3-模型离线评估后，为什么要进行ab测试？"><a href="#6-3-模型离线评估后，为什么要进行ab测试？" class="headerlink" title=" 6.3 模型离线评估后，为什么要进行ab测试？"></a><strong><font color="red"> 6.3 模型离线评估后，为什么要进行ab测试？</font></strong></h4><ul>
<li><strong>离线评估无法消除过拟合的影响</strong>，因此离线评估结果无法代替线上的评估效果</li>
<li><strong>离线评估过程中无法模拟线上的真实环境，例如数据丢失、样本反馈延迟</strong></li>
<li>线上的<strong>某些商业指标例如收益、留存等无法通过离线计算</strong></li>
</ul>
<h4 id="6-4-如何进行线上ab测试？"><a href="#6-4-如何进行线上ab测试？" class="headerlink" title="6.4 如何进行线上ab测试？"></a>6.4 <strong>如何进行线上ab测试？</strong></h4><p>进行ab测试的主要手段时对用户进行分桶，即将<strong>用户分成实验组和对照组</strong>。实验组使用新模型，对照组使用base模型。<strong>分桶过程中需要保证样本的独立性和采样的无偏性</strong>，确保每个用户只划分到一个桶中，分桶过程中需要保证user id是一个<a href="https://www.zhihu.com/search?q=随机数&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;440144351&quot;}">随机数</a>，才能保证数据无偏的。</p>
<h2 id="七、模型评估"><a href="#七、模型评估" class="headerlink" title="七、模型评估"></a>七、模型评估</h2><h4 id="7-1-holdout"><a href="#7-1-holdout" class="headerlink" title="7.1 holdout"></a>7.1 holdout</h4><p><strong>留出法是机器学习中最常见的评估方法之一，它会从训练数据中保留出验证样本集，这部分数据不用于训练，而用于模型评估</strong>。</p>
<h4 id="7-2-交叉验证"><a href="#7-2-交叉验证" class="headerlink" title="7.2 交叉验证"></a>7.2 交叉验证</h4><p><strong>留出法的数据划分，可能会带来偏差</strong>。在机器学习中，另外一种比较常见的评估方法是交叉验证法—— <img src="https://www.zhihu.com/equation?tex=K" alt="公式"> <strong>折交叉验证对 <img src="https://www.zhihu.com/equation?tex=K" alt="公式"> 个不同分组训练的结果进行平均来减少方差</strong>。</p>
<h4 id="7-3-自助法"><a href="#7-3-自助法" class="headerlink" title="7.3 自助法"></a>7.3 自助法</h4><p>Bootstrap 是一种用小样本估计总体值的一种非参数方法，在进化和生态学研究中应用十分广泛。<strong>Bootstrap通过有放回抽样生成大量的伪样本，通过对伪样本进行计算，获得统计量的分布，从而估计数据的整体分布</strong>。</p>
<h2 id="八、超参数调优"><a href="#八、超参数调优" class="headerlink" title="八、超参数调优"></a>八、超参数调优</h2><p>神经网咯是有许多超参数决定的，例如网络深度，学习率，正则等等。如何寻找最好的超参数组合，是一个老人靠经验，新人靠运气的任务。</p>
<h4 id="8-1-网格搜索"><a href="#8-1-网格搜索" class="headerlink" title="8.1 网格搜索"></a>8.1 网格搜索</h4><h4 id="8-2-随机搜索"><a href="#8-2-随机搜索" class="headerlink" title="8.2 随机搜索"></a>8.2 随机搜索</h4><h4 id="8-3-贝叶斯优化"><a href="#8-3-贝叶斯优化" class="headerlink" title="==8.3 贝叶斯优化=="></a>==8.3 贝叶斯优化==</h4><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/390373572"><em>贝叶斯优化</em>(原理+代码解读)</a></p>
<p>  <a href="https://zhuanlan.zhihu.com/p/27916208">LightGBM调参指南(带贝叶斯优化代码)</a></p>
<ul>
<li>贝叶斯调参采用高斯过程，考虑之前的参数信息，不断地更新先验；网格搜索未考虑之前的参数信息</li>
<li>贝叶斯调参迭代次数少，速度快；网格搜索速度慢,参数多时易导致维度爆炸</li>
<li><p>贝叶斯调参针对非凸问题依然稳健；网格搜索针对非凸问题易得到局部最优</p>
<h4 id="可用的贝叶斯优化框架"><a href="#可用的贝叶斯优化框架" class="headerlink" title="可用的贝叶斯优化框架"></a>可用的贝叶斯优化框架</h4></li>
</ul>
<ol>
<li>BayesianOptimization：<a href="https://link.zhihu.com/?target=https%3A//github.com/fmfn/BayesianOptimization">https://github.com/fmfn/BayesianOptimization</a></li>
<li>清华开源的openbox：<a href="https://link.zhihu.com/?target=https%3A//open-box.readthedocs.io/zh_CN/latest/index.html">https://open-box.readthedocs.io/zh_CN/latest/index.html</a></li>
<li>华为开源的HEBO：<a href="https://link.zhihu.com/?target=https%3A//github.com/huawei-noah/HEBO">https://github.com/huawei-noah/HEBO</a></li>
<li><strong>Hyperopt</strong>：<a href="https://link.zhihu.com/?target=http%3A//hyperopt.github.io/hyperopt/">http://hyperopt.github.io/hype</a></li>
</ol>
</blockquote>
<h4 id="贝叶斯优化什么-【黑盒优化】"><a href="#贝叶斯优化什么-【黑盒优化】" class="headerlink" title="贝叶斯优化什么?【黑盒优化】"></a>贝叶斯优化什么?【黑盒优化】</h4><p>求助 gradient-free 的优化算法了，这类算法也很多了，<strong>贝叶斯优化就属于无梯度优化算法</strong>中的一种，它希望在尽可能少的试验情况下去尽可能获得优化命题的全局最优解。</p>
<p><img src="https://pic1.zhimg.com/v2-75933a225ab1875a27188013ce0d8740_b.jpg" alt="img" style="zoom: 33%;"></p>
<ul>
<li>目标函数 <img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]"> 及其导数未知，否则就可以用梯度下降等方法求解。</li>
<li>计算目标函数时间成本大，意味着像蚁群算法、遗传算法这种方法也失效了，因为计算一次要花费很多时间。</li>
</ul>
<h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>贝叶斯优化，是一种使用<strong>贝叶斯定理来指导搜索以找到目标函数的最小值或最大值的方法</strong>，就是在每次迭代的时候，利用之前观测到的历史信息（先验知识）来进行下一次优化，通俗点讲，<strong>就是在进行一次迭代的时候，先回顾下之前的迭代结果，结果太差的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 附近就不去找了，尽量往结果好一点的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 附近去找最优解，</strong>这样一来搜索的效率就大大提高了，这其实和人的思维方式也有点像，每次在学习中试错，并且在下次的时候根据这些经验来找到最优的策略。</p>
<h4 id="贝叶斯优化过程"><a href="#贝叶斯优化过程" class="headerlink" title="贝叶斯优化过程"></a>贝叶斯优化过程</h4><p>首先，假设有一个这样的函数 <img src="https://www.zhihu.com/equation?tex=c%28x%29" alt="[公式]"> ，我们需要找到他的最小值，如下图所示，这也是我们所需要优化的目标函数，但是我们并不能够知道他的具体形状以及表达形式是怎么样的。</p>
<p><img src="https://pic3.zhimg.com/v2-ddb9527a36ddcdb539d573fa5124d576_b.jpg" alt="img"></p>
<p>贝叶斯优化是通过一种叫做代理优化的方式来进行的，就是不知道真实的目标函数长什么样，我们就用一个<strong>代理函数（surrogate function）来代替目标函数</strong>，<strong>而这个代理函数就可以通过先采样几个点，再通过这几个点来给他拟合出来</strong>，如下图虚线所示：</p>
<p><img src="https://pic2.zhimg.com/v2-53769125b87835a74445a472415c22a1_b.jpg" alt="img"></p>
<p>基于构造的代理函数，<strong>我们就可以在可能是最小值的点附近采集更多的点</strong>，或者在还没有采样过的区域来采集更多的点，有了更多点，就可以<strong>更新代理函数</strong>，使之更逼近真实的目标函数的形状，这样的话也更容易找到目标函数的最小值，这个采样的过程同样可以通过构建一个采集函数来表示，也就是知道了当前代理函数的形状，如何选择下一个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 使得收益最大。</p>
<p><strong>然后重复以上过程，最终就可以找到函数的最小值点了，这大致就是贝叶斯优化的一个过程：</strong></p>
<ol>
<li><strong>初始化一个代理函数的先验分布</strong></li>
<li><strong>选择数据点 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> ，使得采集函数 <img src="https://www.zhihu.com/equation?tex=a%28x%29" alt="[公式]"> 取最大值</strong></li>
<li><strong>在目标函数 <img src="https://www.zhihu.com/equation?tex=+c%28x%29" alt="[公式]"> 中评估数据点 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 并获取其结果 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"></strong> </li>
<li><strong>使用新数据 <img src="https://www.zhihu.com/equation?tex=%28x%2Cy%29" alt="[公式]"> 更新代理函数，得到一个后验分布（作为下一步的先验分布)</strong></li>
<li>重复2-4步，直到达到最大迭代次数</li>
</ol>
<p>举个例子，如图所示，一开始只有两个点（t=2），代理函数的分布是紫色的区域那块，然后根据代理函数算出一个采集函数（绿色线），取采集函数的最大值所在的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> （红色三角处），算出 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> ，然后根据新的点 <img src="https://www.zhihu.com/equation?tex=%28x%2Cy%29" alt="[公式]"> 更新代理函数和采集函数（t=3），继续重复上面步骤，选择新的采集函数最大值所在的 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> ，算出 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> ，再更新代理函数和采集函数，然后继续迭代。</p>
<p><img src="https://pic1.zhimg.com/v2-82ed7dc24fca93f3c2c5820ab519a5f8_b.jpg" alt="img" style="zoom: 67%;"></p>
<p>问题的核心就在于代理函数和采集函数如何构建，常用的代理函数有：</p>
<ol>
<li><strong>高斯过程（Gaussian processes）</strong></li>
<li><strong>Tree Parzer Estimator</strong></li>
<li><strong>概率随机森林：针对类别型变量</strong></li>
</ol>
<p>采集函数则需要兼顾两方面的性质：</p>
<ol>
<li>利用当前已开发的区域（Exploitation）：即在当前最小值附近继续搜索</li>
<li>探索尚未开发的区域（Exploration）：即在还没有搜索过的区域里面搜索，可能那里才是全局最优解</li>
</ol>
<p><strong>常用的采集函数有：</strong></p>
<ol>
<li>Probability of improvement（PI）</li>
<li>Expected improvement（EI）</li>
<li>Confidence bound criteria，包括LCB和UCB</li>
</ol>
<h4 id="8-4-Hyperopt"><a href="#8-4-Hyperopt" class="headerlink" title="8.4 Hyperopt"></a>8.4 Hyperopt</h4><p>Hyperopt 是一个强大的 Python 库，用于超参数优化，由 jamesbergstra 开发。Hyperopt 使用贝叶斯优化的形式进行参数调整，允许你为给定模型获得最佳参数。它可以在大范围内优化具有数百个参数的模型。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<h2 id="机器学习模型评价指标"><a href="#机器学习模型评价指标" class="headerlink" title="机器学习模型评价指标"></a>机器学习模型评价指标</h2><blockquote>
<p>  一文看懂机器学习指标：准确率、精准率、召回率、F1、ROC曲线、AUC曲线:<a href="https://zhuanlan.zhihu.com/p/93107394">https://zhuanlan.zhihu.com/p/93107394</a></p>
<p>  <strong>机器学习-最全面的评价指标体系: <a href="https://zhuanlan.zhihu.com/p/359997979">https://zhuanlan.zhihu.com/p/359997979</a></strong></p>
<p>  <a href="https://github.com/HaoMood/homepage/blob/master/files/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E5%AE%9D%E5%85%B8-03-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0.pdf">机器学习工程师面试宝典-03-模型评估</a></p>
<p>  <strong><a href="http://www.china-nb.cn/gongsidongtai/17-85.html">分类模型评估指标——准确率、精准率、召回率、F1、ROC曲线、AUC曲线</a></strong></p>
</blockquote>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/image-20220421165422230.png" alt="image-20220421165422230" style="zoom:50%;"></p>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/image-20220421165436795.png" alt="image-20220421165436795" style="zoom:50%;"></p>
<h3 id="一、二分类问题"><a href="#一、二分类问题" class="headerlink" title="一、二分类问题"></a>一、二分类问题</h3><blockquote>
<p>  <strong>阈值调节问题？</strong></p>
</blockquote>
<ul>
<li><strong>准确率 (Accuracy)</strong>：<strong>预测正确的概率</strong>  【<strong>(TP+TN)/(TP+TN+FP+FN)</strong>】</li>
<li><strong>精确率（查准率 Precision )：==预测为正的样本==中实际为正的样本的概率</strong> 【<strong>TP/(TP+FP)</strong>】</li>
<li>错误发现率（FDR）= 1 - 精确率 = ==预测为正的样本==中实际为负的样本的概率 【<strong>FP/(TP+FP)</strong>】</li>
<li><strong>召回率（查全率）- Recall</strong>：<strong>==实际为正的样本==中被预测为正样本的概率</strong>【<strong>TP/(TP+FN)</strong>】</li>
<li><strong>真正率（TPR） = 灵敏度（==召回率==） =</strong> <strong>TP/(TP+FN)</strong></li>
<li><strong>假正率（FPR） = 1- 特异度 =</strong> <strong>FP/(FP+TN)</strong></li>
<li><strong>F1=是准确率和召回率的==调和平均值== (2×Precision×Recall)/（Precision+Recall）</strong></li>
<li><strong>G-mean（GM）= 是准确率和召回率的==几何平均值==</strong> <img src="https://image.jiqizhixin.com/uploads/editor/c9841ee6-28df-4eb9-aace-8902a6e525a5/640.svg" alt="img"></li>
</ul>
<h3 id="1-1-F1-2×Precision×Recall-（Precision-Recall）"><a href="#1-1-F1-2×Precision×Recall-（Precision-Recall）" class="headerlink" title="1.1 F1=(2×Precision×Recall) /（Precision+Recall）"></a>1.1 <strong>F1=(2×Precision×Recall) /（Precision+Recall）</strong></h3><p>精确率（Precision）和召回率（Recall）之间的关系用图来表达，就是下面的PR曲线。可以发现他们俩的关系是「两难全」的关系。为了综合两者的表现，在两者之间找一个平衡点，就出现了一个 F1分数。</p>
<h4 id="F1-2×Precision×Recall-（Precision-Recall）"><a href="#F1-2×Precision×Recall-（Precision-Recall）" class="headerlink" title="F1=(2×Precision×Recall)  /（Precision+Recall）"></a><strong>F1=(2×Precision×Recall)  /（Precision+Recall）</strong></h4><p>P意义类似于每通过准确预测得到TP个正例需要TP+FP个预测类别为正例的样本。</p>
<p>R意义类似于每通过成功召回得到TP个正例需要TP+FN个真实类别为正例的样本。</p>
<p>F1度量了给定一批样本，对这一批样本进行预测与召回，最终得到的正例的多少。<strong>其中一半的正例是通过预测得到的，一半的正例是通过召回得到的。</strong></p>
<p>有一种把预测所需的预测类别为正例的样本和召回所需的真实类别为正例的样本看作原料，而我们的目标正例样本看作产品的感觉。<strong>所以也能解释为什么P跟R其中一者比较低的时候，F1会偏低。因为跟算术平均数不一样，两者不能互相替代，两部分各负责一半。那么加权调和平均Fbeta也可以很好的理解了。</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7BF_%7B%5Cbeta%7D%7D%3D%5Cfrac%7B1%7D%7B1%2B%5Cbeta%5E%7B2%7D%7D%5Ccdot%5Cleft%28+%5Cfrac%7B1%7D%7BP%7D%2B+%5Cfrac%7B%5Cbeta%5E%7B2%7D%7D%7BR%7D%5Cright%29" alt="[公式]"></p>
<p>各自负责的比例不一样了。因此beta越大，Fbeta越着重考虑召回能力。</p>
<h3 id="1-2-ROC-AUC的概念"><a href="#1-2-ROC-AUC的概念" class="headerlink" title="1.2 ROC/AUC的概念"></a>1.2 ROC/AUC的概念</h3><p><strong>1. 灵敏度，特异度，真正率，假正率</strong></p>
<p>在正式介绍ROC/AUC之前，我们还要再介绍两个指标，<strong>这两个指标的选择也正是ROC和AUC可以无视样本不平衡的原因。</strong> 这两个指标分别是：<strong>灵敏度和（1-特异度），也叫做真正率（TPR）和假正率（FPR）</strong>。其实我们可以发现<strong>灵敏度和召回率是一模一样的，只是名字换了而已</strong>。由于我们比较关心正样本，所以需要查看有多少负样本被错误地预测为正样本，所以使用（1-特异度），而不是特异度。</p>
<p><strong>真正率（TPR） = 灵敏度（==召回率==） =</strong> <strong>TP/(TP+FN)</strong></p>
<p><strong>假正率（FPR） = 1- 特异度 =</strong> <strong>FP/(FP+TN)</strong></p>
<p>下面是真正率和假正率的示意，我们发现<strong>TPR和FPR分别是基于实际表现1和0出发的，也就是说它们分别在实际的正样本和负样本中来观察相关概率问题。</strong> </p>
<blockquote>
<p>  正因为如此，所以无论样本是否平衡，都不会被影响。还是拿之前的例子，总样本中，90%是正样本，10%是负样本。我们知道用准确率是有水分的，但是用TPR和FPR不一样。这里，TPR只关注90%正样本中有多少是被真正覆盖的，而与那10%毫无关系，同理，FPR只关注10%负样本中有多少是被错误覆盖的，也与那90%毫无关系，</p>
</blockquote>
<p><strong>如果我们从实际表现的各个结果角度出发，就可以避免样本不平衡的问题了，这也是为什么选用TPR和FPR作为ROC/AUC的指标的原因。</strong></p>
<h4 id="2-ROC（接受者操作特征曲线）"><a href="#2-ROC（接受者操作特征曲线）" class="headerlink" title="2. ROC（接受者操作特征曲线）"></a><strong>2. ROC（接受者操作特征曲线）</strong></h4><blockquote>
<p>  ROC（Receiver Operating Characteristic）曲线，又称接受者操作特征曲线。该曲线最早应用于雷达信号检测领域，用于区分信号与噪声。后来人们将其用于评价模型的预测能力，ROC曲线是基于<strong>混淆矩阵</strong>得出的。</p>
</blockquote>
<p>ROC曲线中的主要两个指标就是<strong>真正率</strong>和<strong>假正率，</strong> 上面也解释了这么选择的好处所在。其中<strong>横坐标为假正率（FPR），纵坐标为真正率（TPR）</strong>，下面就是一个标准的ROC曲线图。</p>
<h4 id="AUC的缺陷？"><a href="#AUC的缺陷？" class="headerlink" title="AUC的缺陷？"></a>AUC的缺陷？</h4><p><strong>优点</strong>：目前普遍认为接收器工作特性曲线（ROC）曲线下的面积—AUC是评估分类模型准确性的标准方法。<strong>它避免了在阈值选择过程中假定的主观性</strong>，当连续的概率得到的分数被转换为二分类标签时，通过总结整体模型表现，其衡量模型区分正负样本的性能优于通过阈值来判断的其他方法（比如准确率、召回率等）。</p>
<ul>
<li><strong>忽略了预测的概率值和模型的拟合优度</strong></li>
<li><strong>AUC反应了太过笼统的信息。无法反应召回率、精确率等在实际业务中经常关心的指标</strong></li>
<li><font color="red"> **对FPR和TPR两种错误的代价同等看待**</font></li>
<li>它没有给出模型误差的空间分布信息</li>
<li>最重要的一点，AUC的misleading的问题</li>
</ul>
<p><strong>==auc仅反应模型的排序能力==，无法反应模型的拟合优度；auc很多时候无法直接反应细粒度的和业务目标更相关的metric信息，例如 top k的准确率，召回率等等（例如同auc的模型在不同的区间的预测能力是存在差别的）；</strong></p>
<h3 id="1-3、K-S曲线"><a href="#1-3、K-S曲线" class="headerlink" title="1.3、K-S曲线"></a>1.3、K-S曲线</h3><blockquote>
<p>  <strong>K-S曲线</strong>，又称作洛伦兹曲线。实际上，K-S曲线的数据来源以及本质和ROC曲线是一致的，只是ROC曲线是把真正率（ <img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> ）和假正率（ <img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> ）当作横纵轴，<strong>而K-S曲线是把真正率（ <img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> ）和假正率（ <img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> )都当作是纵轴，横轴则由选定的阈值来充当。从 </strong>K-S 曲线<strong>就能衍生出 <img src="https://www.zhihu.com/equation?tex=KS" alt="[公式]"> 值， <img src="https://www.zhihu.com/equation?tex=KS+%3D+max%28TPR+-+FPR%29" alt="[公式]"> ，即是两条曲线之间的最大间隔距离。</strong></p>
</blockquote>
<p><strong>K-S曲线的画法：</strong></p>
<ol>
<li><p><strong>排序：</strong>对于二元分类器来说，模型训练完成之后每个样本都会得到一个类概率值，把样本按这个类概率值从大到小进行排序；</p>
</li>
<li><p><strong>找阈值：</strong>取排序后前 <img src="https://www.zhihu.com/equation?tex=10%5C%25%5Ctimes+k%28k%3D1%2C2%2C3%2C...%2C9%29" alt="[公式]"> 处的值（概率值）作为阈值，分别计算出不同的 <img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> 和<img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> 值，以<img src="https://www.zhihu.com/equation?tex=10%5C%25%5Ctimes+k%28k%3D1%2C2%2C3%2C...%2C9%29" alt="[公式]">为横坐标，分别以<img src="https://www.zhihu.com/equation?tex=TPR" alt="[公式]"> 和<img src="https://www.zhihu.com/equation?tex=FPR" alt="[公式]"> 值为纵坐标，就可以画出两个曲线，这就是K-S曲线，类似于下图。</p>
</li>
<li><p><strong>KS值</strong>：</p>
<p>从 <strong>K-S 曲线</strong>就能衍生出 <img src="https://www.zhihu.com/equation?tex=KS" alt="[公式]"> 值， <img src="https://www.zhihu.com/equation?tex=KS+%3D+max%28TPR+-+FPR%29" alt="[公式]"> ，即是两条曲线之间的最大间隔距离。KS值越大表示模型 的区分能力越强。</p>
</li>
</ol>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/v2-f913b42cefcd32f9fdbfa027de2dfbc8_1440w.jpg" alt="img" style="zoom: 50%;"></p>
<h3 id="1-4-Lift曲线"><a href="#1-4-Lift曲线" class="headerlink" title="1.4 Lift曲线"></a>1.4 Lift曲线</h3><p><strong>Lift曲线它衡量的是，与不利用模型相比，模型的预测能力“变好”了多少，lift(提升指数)越大，模型的运行效果越好。实质上它强调的是投入与产出比</strong>。</p>
<p><strong>tip:</strong>理解<strong>Lift</strong>可以先看一下Quora上的一篇文章：<strong><a href="https://link.zhihu.com/?target=https%3A//www.quora.com/Whats-Lift-curve">What’s Lift curve?</a></strong></p>
<p><strong>Lift计算公式：</strong>先介绍几个相关的指标，以免混淆：</p>
<ul>
<li><strong>准确率（accuracy，ACC）</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=ACC%3D%5Cfrac%7BTP%2BTN%7D%7BFP%2BFN%2BTP%2BTN%7D%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>正确率(Precision，PRE)，查准率</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=PRE+%3D+%5Cfrac%7BTP%7D%7BTP%2BFP%7D+%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>真阳性率(True Positive Rate，TPR)，灵敏度(Sensitivity)，召回率(Recall)</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=TPR%3D%5Cfrac%7BTP%7D%7BTP%2BFN%7D+%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>假阳性率(False Positice Rate，FPR)，误诊率( = 1 - 特异度)</strong>：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=FPR%3D%5Cfrac%7BFP%7D%7BFP%2BTN%7D%5C%5C" alt="[公式]"></p>
<p><strong>Lift计算公式：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=Lift%3D%5Cfrac%7B%5Cfrac%7BTP%7D%7BTP%2BFP%7D%7D%7B%5Cfrac%7BTP%2BFN%7D%7BTP%2BFP%2BTN%2BFN%7D%7D%3D%5Cfrac%7BPRE%7D%7B%E6%AD%A3%E4%BE%8B%E5%8D%A0%E6%AF%94%7D%5C%5C" alt="[公式]"></p>
<p>根据以上公式可知，<strong>Lift指标可以这样理解：</strong>在不使用模型的情况下，我们用先验概率估计正例的比例，即上式子分母部分，以此作为正例的命中率；利用模型后，我们不需要从整个样本中来挑选正例，只需要从我们预测为正例的那个样本的子集 <img src="https://www.zhihu.com/equation?tex=TP%2BFP" alt="[公式]"> 中挑选正例，这时正例的命中率为 <img src="https://www.zhihu.com/equation?tex=PRE" alt="[公式]"> ，后者除以前者即可得提升值<strong>Lift。</strong></p>
<h4 id="Lift曲线："><a href="#Lift曲线：" class="headerlink" title="Lift曲线："></a><strong>Lift曲线：</strong></h4><p>为了作出<strong>LIft</strong>曲线，首先引入 <img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]"> 的概念：</p>
<p><img src="https://www.zhihu.com/equation?tex=depth%3D%5Cfrac%7BTP%2BFP%7D%7BTP%2BFP%2BTN%2BFN%7D%5C%5C" alt="[公式]"></p>
<p><strong>从公式可以看出</strong>，<img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]">代表的是预测为正例的样本占整个样本的比例。</p>
<p>当阈值为0时，所有的样本都被预测为正例，因此 <img src="https://www.zhihu.com/equation?tex=depth%3D1" alt="[公式]"> ，于是 <img src="https://www.zhihu.com/equation?tex=Lift%3D1" alt="[公式]"> ，模型未起提升作用。随着阈值逐渐增大，被预测为正例的样本数逐渐减少，<img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]">减小，而较少的预测正例样本中的真实正例比例逐渐增大。当阈值增大至1时，没有样本被预测为正例，此时 <img src="https://www.zhihu.com/equation?tex=depth%3D0" alt="[公式]"> ，而 <img src="https://www.zhihu.com/equation?tex=Lift%3D0" alt="[公式]"> 。由此可见， <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 与<img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]">存在相反方向变化的关系。在此基础上作出 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 图：</p>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/v2-4cfa1e77335b91d9a47acb7238383c1e_1440w.jpg" alt="img" style="zoom: 50%;"></p>
<p>一般要求，在尽量大的 <img src="https://www.zhihu.com/equation?tex=depth" alt="[公式]"> 下得到尽量大的 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]">，所以 <img src="https://www.zhihu.com/equation?tex=Lift" alt="[公式]"> 曲线的右半部分应该尽量陡峭。</p>
<h3 id="1-5-P-R曲线"><a href="#1-5-P-R曲线" class="headerlink" title="1.5 P-R曲线"></a>1.5 <strong>P-R曲线</strong></h3><ul>
<li><p><strong>精确率（查准率）- Precision ：==预测为正的样本==中实际为正的样本的概率</strong> 【<strong>TP/(TP+FP)</strong>】</p>
</li>
<li><p><strong>召回率（查全率）- Recall</strong>：<strong>==实际为正的样本==中被预测为正样本的概率</strong>【<strong>TP/(TP+FN)</strong>】</p>
</li>
</ul>
<p>P-R曲线刻画<strong>查准率</strong>和<strong>查全率（召回率）</strong>之间的关系，查准率指的是在所有预测为正例的数据中，真正例所占的比例，查全率是指预测为真正例的数据占所有正例数据的比例。查准率和查全率是一对矛盾的度量，一般来说，查准率高时，查全率往往偏低，查全率高时，查准率往往偏低。</p>
<p>在很多情况下，我们可以根据学习器的预测结果对样例进行排序，排在前面的是学习器认为最可能是正例的样本，排在后面的是学习器认为最不可能是正例的样本，按此顺序逐个把样本作为正例进行预测，则每次可计算当前的查全率和查准率，以查准率为y轴，以查全率为x轴，可以画出下面的P-R曲线。</p>
<p><img src="apple/Documents/Tynote/%E5%B7%A5%E4%BD%9C/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/AI%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0*/pic/v2-dc6abbb24e2dfbfefe4777408d2a8e5c_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>如果一个学习器的P-R曲线被另一个学习器的P-R曲线完全包住，则可断言后者的性能优于前者，当然我们可以根据曲线下方的面积大小来进行比较，但更常用的是<strong>平衡点</strong>或者是F1值。</p>
<ul>
<li><strong>平衡点（BEP）</strong>是查准率=查全率时的取值，如果这个值较大，则说明学习器的性能较好。F1值越大，我们可以认为该学习器的性能较好。</li>
<li><font color="red"> **F1度量**：**BEP过于简单，这个平衡点是建立在”查准率=查全率“的前提下，无法满足实际不同场景的应用。**</font>

</li>
</ul>
<p>我们先来引入加权调和平均： <img src="https://www.zhihu.com/equation?tex=F_%5Cbeta" alt="[公式]">：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+%5Cfrac+%7B1%7D%7BF_%7B%5Cbeta%7D%7D%3D%5Cfrac+%7B1%7D%7B1%2B%7B%5Cbeta%7D%5E2%7D%28%5Cfrac%7B1%7D%7BP%7D%2B%5Cfrac%7B%5Cbeta%5E2%7D%7BR%7D%29++++%5Cquad+%E5%85%AC%E5%BC%8F%281%29" alt="[公式]"></p>
<p>加权调和平均与<strong>算术平均</strong> <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7BP%2BR%7D%7B2%7D" alt="[公式]"> 和<strong>几何平均</strong> <img src="https://www.zhihu.com/equation?tex=%5Csqrt%7BP%2BR%7D" alt="[公式]"> 相比，<strong>调和平均更重视较小值（这可以从倒数上看出来）</strong>。当 <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3D1+" alt="[公式]"> ，即F1是基于查准率和查全率的调和平均定义的，F1的公式如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+%5Cfrac+%7B1%7D%7BF_%7B1%7D%7D%3D%5Cfrac+%7B1%7D%7B2%7D%28%5Cfrac%7B1%7D%7BP%7D%2B%5Cfrac%7B1%7D%7BR%7D%29" alt="[公式]"></p>
<p>我们把公式求倒数，即可得：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+F1%3D%5Cfrac%7B2%2AP%2AR%7D%7BP%2BR%7D" alt="[公式]"></p>
<p>在一些应用中，对查准率和查全率的重视程度不同。例如在商品推荐中，为了尽可能少打扰用户，更希望推荐的内容确实是用户感兴趣的，此时查准率更重要；而在罪犯信息检索或者病人检查系统中，更希望尽可能少的漏判，此时查全率更重要。F1度量的一般形式是 <img src="https://www.zhihu.com/equation?tex=F_%7B%5Cbeta%7D" alt="[公式]"> ，能让我们自定义对查准率/查全率的不同偏好：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+F_%7B%5Cbeta%7D%3D%5Cfrac%7B%281%2B%5Cbeta%5E2%29%2AP%2AR%7D%7B%28%5Cbeta%5E2%2AP%29%2BR%7D" alt="[公式]"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3E0+" alt="[公式]"> 度量了查全率对查准率的相对重要性（不明白的同学可以回看公式1）， <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3D1" alt="[公式]"> 时退化为标准F1，<img src="https://www.zhihu.com/equation?tex=%5Cbeta%3E1+" alt="[公式]">==时查全率有更大影响； <img src="https://www.zhihu.com/equation?tex=%5Cbeta%3C1" alt="[公式]"> 时，查准率有更大影响。==</p>
<h3 id="1-6-对数损失-Log-Loss"><a href="#1-6-对数损失-Log-Loss" class="headerlink" title="1.6 对数损失(Log Loss)"></a>1.6 <strong>对数损失(Log Loss)</strong></h3><p><strong>AUC ROC考虑用于确定模型性能的预测概率</strong>。然而，AUC ROC存在问题，它只考虑概率的顺序，因此<strong>没有考虑模型预测更可能为正样本的更高概率的能力(即考虑了大小，但没有考虑更高精度)</strong>。<strong>在这种情况下，我们可以使用对数损失，即每个实例的正例预测概率的对数的负平均值。</strong></p>
<p>对数损失（Logistic Loss，logloss）是对预测概率的似然估计，其标准形式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+logloss%3DlogP%28Y%7CX%29" alt="[公式]"></p>
<p>对数损失最小化本质是上利用样本中的已知分布，求解拟合这种分布的最佳模型参数，使这种分布出现概率最大。</p>
<p>对数损失对应的二分类的计算公式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=logloss%3D-%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_ilog%5Chat%7By_i%7D%2B%281-y_i%29log%281-%5Chat%7By_i%7D%29%29+%2C%5Cquad%5Cquad%5Cquad+y%5Cin%5B0%2C1%5D" alt="[公式]"></p>
<p>其中N为样本数， <img src="https://www.zhihu.com/equation?tex=%5Chat+y_i" alt="[公式]"> 为预测为1的概率。对数损失在多分类问题中也可以使用，其计算公式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=logloss%3D-%5Cfrac%7B1%7D%7BN%7D%5Cfrac%7B1%7D%7BC%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%5Csum_%7Bj%3D1%7D%5E%7BC%7D%28y_%7Bij%7Dlog%5Chat%7By_%7Bij%7D%7D%29+%2C%5Cquad%5Cquad%5Cquad+y%5Cin%5B0%2C1%5D" alt="[公式]"></p>
<p>其中，N为样本数，C为类别数，logloss衡量的是预测概率分布和真实概率分布的差异性，取值越小越好。</p>
<h3 id="1-7-多分类"><a href="#1-7-多分类" class="headerlink" title="1.7 多分类"></a>1.7 多分类</h3><p>很多时候我们有多个<strong>二分类混淆矩阵</strong>，例如进行多次训练/测试，每次得到一个混淆矩阵；或是在多个数据集上进行训练/测试，希望估计算法的全局性能；或者是执行分类任务，每两两类别的组合都对应一个混淆矩阵；总之是在<strong>n个二分类混淆矩阵上综合考察查准率和查全率</strong>。</p>
<ul>
<li><strong>宏观</strong>：在各个混淆军阵上分别计算出查准率和查全率，记为(P1,R1)，(P2,R2),…(Pn,Rn)，在<strong>计算平均值</strong>，这样就得到“宏观查准率”(macro-P)，“宏观查全率”(macro-R)、“宏观F1”(macro-F1)：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+macro-P+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7DP_i" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+macro-R+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7DR_i" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+macro-F1%3D%5Cfrac%7B2%2Amacro-P%2Amacro-R%7D%7Bmacro-P%2Bmacro-R%7D" alt="[公式]"></p>
<ul>
<li><strong>微观</strong>：<strong>将个混淆矩阵对应的元素进行平均，得到TP、FP、TN、FN的平均值</strong>，分别记为 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BTP%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BFP%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BFN%7D" alt="[公式]"> 、 <img src="https://www.zhihu.com/equation?tex=%5Coverline%7BTN%7D" alt="[公式]"> ，再基于这些平均值计算出“微观查准率”(micro-P)，“微观查全率”(micro-R)、“微观F1”(micro-F1)：</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+micro-P%3D%5Cfrac%7B%5Coverline%7BTP%7D%7D%7B%5Coverline%7BTP%7D%2B%5Coverline%7BFP%7D%7D" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+micro-R%3D%5Cfrac%7B%5Coverline%7BTP%7D%7D%7B%5Coverline%7BTP%7D%2B%5Coverline%7BFN%7D%7D" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cquad+%5Cquad+micro-F1%3D%5Cfrac%7B2%2Amicro-P%2Amicro-R%7D%7Bmicro-P%2Bmicro-R%7D" alt="[公式]"></p>
<h2 id="二、回归问题评价指标"><a href="#二、回归问题评价指标" class="headerlink" title="二、回归问题评价指标"></a>二、回归问题评价指标</h2><blockquote>
<p>  <strong>均方差损失 Mean Squared Loss、平均绝对误差损失 Mean Absolute Error Loss、Huber Loss、分位数损失 Quantile Loss</strong></p>
</blockquote>
<p>机器学习中的监督学习本质上是给定一系列训练样本 <img src="https://www.zhihu.com/equation?tex=%28x_i%2C+y_i%29" alt="[公式]"> ，尝试学习 <img src="https://www.zhihu.com/equation?tex=x%5Crightarrow+y" alt="[公式]"> 的映射关系，使得给定一个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> ，即便这个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 不在训练样本中，也能够得到尽量接近真实 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 的输出 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D" alt="[公式]"> 。而损失函数（Loss Function）则是这个过程中关键的一个组成部分，用来<strong>衡量模型的输出</strong> <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D" alt="[公式]"> <strong>与真实的</strong> <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> <strong>之间的差距</strong>，给模型的优化指明方向。</p>
<h3 id="2-1-均方差损失-MSE、L2-loss"><a href="#2-1-均方差损失-MSE、L2-loss" class="headerlink" title="2.1 均方差损失 MSE、L2 loss"></a>2.1 均方差损失 MSE、L2 loss</h3><h5 id="基本形式与原理"><a href="#基本形式与原理" class="headerlink" title="基本形式与原理"></a><strong>基本形式与原理</strong></h5><p><strong>均方差Mean Squared Error (MSE)损失是机器学习、深度学习回归任务中最常用的一种损失函数</strong>，也称为 <strong>L2 Loss</strong>。其基本形式如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=J_%7BMSE%7D+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_i+-+%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>从直觉上理解均方差损失，这个损失函数的最小值为 0（当预测等于真实值时），最大值为无穷大。下图是对于真实值 <img src="https://www.zhihu.com/equation?tex=y%3D0" alt="[公式]"> ，不同的预测值 <img src="https://www.zhihu.com/equation?tex=%5B-1.5%2C+1.5%5D" alt="[公式]"> 的均方差损失的变化图。横轴是不同的预测值，纵轴是均方差损失，可以看到随着预测与真实值绝对误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y-+%5Chat%7By%7D%5Crvert" alt="[公式]"> 的增加，均方差损失呈二次方地增加。</p>
<p><img src="https://pic1.zhimg.com/80/v2-f13a4355c21d16cad8b3f30e8a24b5cc_1440w.jpg" alt="img"></p>
<blockquote>
<h4 id="背后的假设"><a href="#背后的假设" class="headerlink" title="背后的假设"></a>背后的假设</h4><p>  <strong>【独立同分布-中心极限定理】</strong>：<br>  如果 <img src="https://www.zhihu.com/equation?tex=%5C%7BX_n%5C%7D" alt="[公式]"> 独立同分布，且 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb+EX%3D%5Cmu%2C%5Cquad+%5Cmathbb+D+X%3D%5Csigma%5E2%3E0" alt="[公式]"> ，则n足够大时 <img src="https://www.zhihu.com/equation?tex=%5Coverline+X_n" alt="[公式]"> 近似服从正态分布 <img src="https://www.zhihu.com/equation?tex=N%5Cleft%28%5Cmu%2C%5Cfrac%7B%5Csigma%5E2%7Dn%5Cright%29" alt="[公式]"> ，即</p>
<p>  <img src="https://www.zhihu.com/equation?tex=%5Clim_%7Bn%5Cto%5Cinfty%7DP%5Cleft%28%5Cfrac%7B%5Coverline+X_n-%5Cmu%7D%7B%5Csigma%2F%5Csqrt+n%7D%3Ca%5Cright%29%3D%5CPhi%28a%29%3D%5Cint_%7B-%5Cinfty%7D%5Ea%5Cfrac1%7B%5Csqrt%7B2%5Cpi%7D%7De%5E%7B-t%5E2%2F2%7Ddt%5C%5C" alt="[公式]"></p>
<p>  实际上在一定的假设下，我们可以使用最大化似然得到均方差损失的形式。假设<strong>模型预测与真实值之间的误差服从标准高斯分布</strong>（ <img src="https://www.zhihu.com/equation?tex=%5Cmu%3D0%2C+%5Csigma%3D1" alt="[公式]"> ），则给定一个 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 模型输出真实值 <img src="https://www.zhihu.com/equation?tex=y_i" alt="[公式]"> 的概率为</p>
<p>  <img src="https://www.zhihu.com/equation?tex=p%28y_i%7Cx_i%29+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%7D%5Cmathbb%7Bexp%7D%5Cleft+%28-%5Cfrac%7B%28y_i-%5Chat%7By_i%7D%29%5E2%7D%7B2%7D%5Cright+%29+%5C%5C" alt="[公式]"></p>
<p>  <strong>进一步我们假设数据集中 N 个样本点之间相互独立，则给定所有 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 输出所有真实值 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 的概率，即似然 Likelihood</strong>，为所有 <img src="https://www.zhihu.com/equation?tex=p%28y_i+%5Cvert+x_i%29" alt="[公式]"> 的累乘</p>
<p>  <img src="https://www.zhihu.com/equation?tex=L%28x%2C+y%29+%3D+%5Cprod_%7Bi%3D1%7D%5E%7BN%7D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%7D%5Cmathbb%7Bexp%7D%5Cleft+%28-%5Cfrac%7B%28y_i-%5Chat%7By_i%7D%29%5E2%7D%7B2%7D%5Cright%29+%5C%5C" alt="[公式]"></p>
<p>  通常为了计算方便，我们通常最大化对数似然 Log-Likelihood</p>
<p>  <img src="https://www.zhihu.com/equation?tex=LL%28x%2C+y%29%3D%5Cmathbb%7Blog%7D%28L%28x%2C+y%29%29%3D-%5Cfrac%7BN%7D%7B2%7D%5Cmathbb%7Blog%7D2%5Cpi+-+%5Cfrac%7B1%7D%7B2%7D+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%28y_i-%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>  去掉与 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D" alt="[公式]"> 无关的第一项，然后转化为最小化负对数似然 Negative Log-Likelihood</p>
<p>  <img src="https://www.zhihu.com/equation?tex=NLL%28x%2C+y%29+%3D+%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_i+-+%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>  可以看到这个实际上就是均方差损失的形式。也就是说<strong>在模型输出与真实值的误差服从高斯分布的假设下，最小化均方差损失函数与极大似然估计本质上是一致的</strong>，因此在这个假设能被满足的场景中（比如回归），均方差损失是一个很好的损失函数选择；当这个假设没能被满足的场景中（比如分类），均方差损失不是一个好的选择。</p>
</blockquote>
<h3 id="hulu-百面机器学习-——-平方根误差的”意外“"><a href="#hulu-百面机器学习-——-平方根误差的”意外“" class="headerlink" title=" hulu 百面机器学习 —— 平方根误差的”意外“"></a><strong><font color="red"> hulu 百面机器学习 —— 平方根误差的”意外“</font></strong></h3><h4 id="95-的时间区间效果很好，RMSE指标居高不下的原因？"><a href="#95-的时间区间效果很好，RMSE指标居高不下的原因？" class="headerlink" title="95%的时间区间效果很好，RMSE指标居高不下的原因？"></a>95%的时间区间效果很好，RMSE指标居高不下的原因？</h4><p><img src="https://www.zhihu.com/equation?tex=J_%7BMSE%7D+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%28y_i+-+%5Chat%7By_i%7D%29%5E2+%5C%5C" alt="[公式]"></p>
<p>一般情况下RSME能反应预测值与真实值的偏离程度，但是<strong>易受离群点</strong>的影响；</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>数据预处理将噪音去掉</li>
<li>将离群点的产生机制建模进去</li>
<li>更鲁棒的模型评估指标：<strong>平均绝对百分比误差</strong>（MAPE），<strong>分位数损失</strong></li>
</ul>
<h4 id="2-2-平均绝对误差-MAE"><a href="#2-2-平均绝对误差-MAE" class="headerlink" title="2.2 平均绝对误差 MAE"></a>2.2 <strong>平均绝对误差 MAE</strong></h4><p><strong>平均绝对误差 Mean Absolute Error (MAE）</strong> 是另一类常用的损失函数，也称为 <strong>L1 Loss</strong>。其基本形式如下</p>
<p><img src="https://www.zhihu.com/equation?tex=+J_%7BMAE%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D%5Cleft+%7C+y_i+-+%5Chat%7By_i%7D+%5Cright+%7C+%5C%5C" alt="[公式]"></p>
<p>同样的我们可以对这个损失函数进行可视化如下图，MAE 损失的最小值为 0（当预测等于真实值时），最大值为无穷大。可以看到随着预测与真实值绝对误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y-+%5Chat%7By%7D%5Crvert" alt="[公式]"> 的增加，MAE 损失呈线性增长。</p>
<p><img src="https://pic3.zhimg.com/80/v2-fd248542b6b5aa9fadcab44340045dee_1440w.jpg" alt="img"></p>
<blockquote>
<h4 id="背后的假设-1"><a href="#背后的假设-1" class="headerlink" title="背后的假设"></a>背后的假设</h4><p>  同样的我们可以在一定的假设下通过最大化似然得到 MAE 损失的形式，假设<strong>模型预测与真实值之间的误差服从拉普拉斯分布 Laplace distribution</strong>（ <img src="https://www.zhihu.com/equation?tex=%5Cmu%3D0%2C+b%3D1" alt="[公式]"> ），则给定一个 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 模型输出真实值 <img src="https://www.zhihu.com/equation?tex=y_i" alt="[公式]"> 的概率为</p>
<p>  <img src="https://www.zhihu.com/equation?tex=p%28y_i%7Cx_i%29+%3D+%5Cfrac%7B1%7D%7B2%7D%5Cmathbb%7Bexp%7D%28-%5Cleft+%7Cy_i-%5Chat%7By_i%7D%5Cright%7C%29+%5C%5C" alt="[公式]"></p>
<p>  与上面推导 MSE 时类似，我们可以得到的负对数似然实际上就是 MAE 损失的形式</p>
<p>  <img src="https://www.zhihu.com/equation?tex=L%28x%2C+y%29+%3D+%5Cprod_%7Bi%3D1%7D%5E%7BN%7D%5Cfrac%7B1%7D%7B2%7D%5Cmathbb%7Bexp%7D%28-%7Cy_i-%5Chat%7By_i%7D%7C%29%5C%5C+++LL%28x%2C+y%29+%3D+N%5Cln%7B%5Cfrac%7B1%7D%7B2%7D%7D+-+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%7Cy_i-%5Chat%7By_i%7D%7C+%5C%5C+++NLL%28x%2C+y%29+%3D+%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%7Cy_i-%5Chat%7By_i%7D%7C++%5C%5C" alt="[公式]"></p>
</blockquote>
<h3 id="2-3-MAE-与-MSE-区别"><a href="#2-3-MAE-与-MSE-区别" class="headerlink" title="2.3 MAE 与 MSE 区别"></a>2.3 MAE 与 MSE 区别</h3><p>MAE 和 MSE 作为损失函数的主要区别是：<strong>MSE 损失相比 MAE 通常可以更快地收敛，但 MAE 损失对于 outlier 更加健壮</strong>，即更加不易受到 outlier 影响。</p>
<ul>
<li><p><strong>MSE 通常比 MAE 可以更快地收敛</strong>。当使用梯度下降算法时，MSE 损失的梯度为 <img src="https://www.zhihu.com/equation?tex=-%5Chat%7By_i%7D" alt="[公式]"> ，而 MAE 损失的梯度为 <img src="https://www.zhihu.com/equation?tex=%5Cpm1" alt="[公式]"> ，即 MSE 的梯度的 scale 会随误差大小变化，而 MAE 的梯度的 scale 则一直保持为 1，即便在绝对误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y_i-%5Chat%7By_i%7D+%5Crvert" alt="[公式]"> 很小的时候 MAE 的梯度 scale 也同样为 1，这实际上是非常不利于模型的训练的。当然你可以通过在训练过程中动态调整学习率缓解这个问题，但是总的来说，损失函数梯度之间的差异导致了 MSE 在大部分时候比 MAE 收敛地更快。这个也是 MSE 更为流行的原因。</p>
</li>
<li><p><strong>MAE 对于异常值（outlier） 更加 robust</strong>。我们可以从两个角度来理解这一点：</p>
<ul>
<li>第一个角度是直观地理解，下图是 MAE 和 MSE 损失画到同一张图里面，由于MAE 损失与绝对误差之间是线性关系，MSE 损失与误差是平方关系，当误差非常大的时候，MSE 损失会远远大于 MAE 损失。<strong>因此当数据中出现一个误差非常大的 outlier 时，MSE 会产生一个非常大的损失，对模型的训练会产生较大的影响</strong>。<img src="https://pic2.zhimg.com/80/v2-c8edffe0406dafae41a042e412cd3251_1440w.jpg" alt="img"></li>
<li>第二个角度是从两个损失函数的假设出发，MSE 假设了误差服从高斯分布，MAE 假设了误差服从拉普拉斯分布。拉普拉斯分布本身对于 outlier 更加 robust。参考下图（来源：<a href="https://link.zhihu.com/?target=https%3A//www.cs.ubc.ca/~murphyk/MLbook/">Machine Learning: A Probabilistic Perspective</a> 2.4.3 The Laplace distribution Figure 2.8），当右图右侧出现了 outliers 时，拉普拉斯分布相比高斯分布受到的影响要小很多。因此以拉普拉斯分布为假设的 MAE 对 outlier 比高斯分布为假设的 MSE 更加 robust。<img src="https://pic1.zhimg.com/80/v2-93ad65845f5b0dc0327fde4ded661804_1440w.jpg" alt="img" style="zoom: 67%;"></li>
</ul>
</li>
</ul>
<h3 id="2-4-Huber-Loss"><a href="#2-4-Huber-Loss" class="headerlink" title="2.4 Huber Loss"></a>2.4 Huber Loss</h3><blockquote>
<ul>
<li>在误差接近 0 时使用 MSE，使损失函数可导并且梯度更加稳定</li>
<li>在误差较大时使用 MAE 可以降低 outlier 的影响，使训练对 outlier 更加健壮。</li>
</ul>
</blockquote>
<p>上文我们分别介绍了 MSE 和 MAE 损失以及各自的优缺点，MSE 损失收敛快但容易受 outlier 影响，MAE 对 outlier 更加健壮但是收敛慢，<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Huber_loss">Huber Loss</a> 则是一种将 MSE 与 MAE 结合起来，取两者优点的损失函数，也被称作 Smooth Mean Absolute Error Loss 。其原理很简单，就是在误差接近 0 时使用 MSE，误差较大时使用 MAE，公式为</p>
<p><img src="https://www.zhihu.com/equation?tex=J_%7Bhuber%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN%5Cmathbb%7BI%7D_%7B%7C+y_i+-+%5Chat%7By_i%7D%7C+%5Cleq+%5Cdelta%7D+%5Cfrac%7B%28y_i+-+%5Chat%7By_i%7D%29%5E2%7D%7B2%7D%2B+%5Cmathbb%7BI%7D_%7B%7C+y_i+-+%5Chat%7By_i%7D%7C+%3E+%5Cdelta%7D+%28%5Cdelta+%7Cy_i+-+%5Chat%7By_i%7D%7C+-+%5Cfrac%7B1%7D%7B2%7D%5Cdelta%5E2%29+%5C%5C" alt="[公式]"></p>
<p>上式中 <img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="[公式]"> 是 Huber Loss 的一个超参数，<img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="[公式]"> 的值是 MSE 和 MAE 两个损失连接的位置。上式等号右边第一项是 MSE 的部分，第二项是 MAE 部分，在 MAE 的部分公式为 <img src="https://www.zhihu.com/equation?tex=%5Cdelta+%5Clvert+y_i+-+%5Chat%7By_i%7D%5Crvert+-+%5Cfrac%7B1%7D%7B2%7D%5Cdelta%5E2" alt="[公式]"> 是为了保证误差 <img src="https://www.zhihu.com/equation?tex=%5Clvert+y+-+%5Chat%7By%7D%5Crvert%3D%5Cpm+%5Cdelta" alt="[公式]"> 时 MAE 和 MSE 的取值一致，进而保证 Huber Loss 损失连续可导。</p>
<p>下图是 <img src="https://www.zhihu.com/equation?tex=%5Cdelta%3D1.0" alt="[公式]"> 时的 Huber Loss，可以看到在 <img src="https://www.zhihu.com/equation?tex=%5B-%5Cdelta%2C+%5Cdelta%5D" alt="[公式]"> 的区间内实际上就是 MSE 损失，在 <img src="https://www.zhihu.com/equation?tex=%28-%5Cinfty%2C+%5Cdelta%29" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%28%5Cdelta%2C+%5Cinfty%29" alt="[公式]"> 区间内为 MAE损失。</p>
<p><img src="https://pic4.zhimg.com/80/v2-b4260d38f70dd920fa46b8717596bda7_1440w.jpg" alt="img"></p>
<h3 id="2-5-分位数损失-Quantile-Loss"><a href="#2-5-分位数损失-Quantile-Loss" class="headerlink" title="2.5 分位数损失 Quantile Loss"></a>2.5 分位数损失 Quantile Loss</h3><blockquote>
<p>  <strong>MAE 中分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong></p>
</blockquote>
<p><strong>分位数回归 Quantile Regression 是一类在实际应用中非常有用的回归算法</strong>，通常的回归算法是拟合目标值的期望或者中位数，而分位数回归可以通过给定不同的分位点，<strong>拟合目标值的不同分位数</strong>。</p>
<p><img src="https://pic1.zhimg.com/80/v2-8eb8ecfcdd8031a16a471905217934a0_1440w.jpg" alt="img"></p>
<p>分位数回归是通过使用分位数损失 Quantile Loss 来实现这一点的，分位数损失形式如下，式中的 r 分位数系数。</p>
<p><img src="https://www.zhihu.com/equation?tex=J_%7Bquant%7D+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%5Cmathbb%7BI%7D_%7B%5Chat%7By_i%7D%5Cgeq+y_i%7D%281-r%29%7Cy_i+-+%5Chat%7By_i%7D%7C+%2B+%5Cmathbb%7BI%7D_%7B%5Chat%7By_i%7D%3C+y_i%7Dr%7Cy_i-%5Chat%7By_i%7D%7C+%5C%5C" alt="[公式]"></p>
<p>我们如何理解这个损失函数呢？这个损失函数是一个分段的函数 ，将 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D+%5Cgeq+y_i" alt="[公式]"> （高估） 和 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D+%3C+y_i" alt="[公式]"> （低估） 两种情况分开来，并分别给予不同的系数。当 <img src="https://www.zhihu.com/equation?tex=r%3E0.5" alt="[公式]"> 时，低估的损失要比高估的损失更大，反过来当 <img src="https://www.zhihu.com/equation?tex=r+%3C+0.5" alt="[公式]"> 时，高估的损失比低估的损失大；分位数损失实现了<strong>分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong>。特别地，当 <img src="https://www.zhihu.com/equation?tex=r%3D0.5" alt="[公式]"> 时，分位数损失退化为 MAE 损失，从这里可以看出 MAE 损失实际上是分位数损失的一个特例 — 中位数回归。</p>
<p>下图是取不同的分位点 0.2、0.5、0.6 得到的三个不同的分位损失函数的可视化，可以看到 0.2 和 0.6 在高估和低估两种情况下损失是不同的，而 0.5 实际上就是 MAE。</p>
<p><img src="https://pic4.zhimg.com/80/v2-f8ed385f32a517c784bce841e6da1daf_1440w.jpg" alt="img"></p>
<h3 id="2-6-平均绝对百分误差-MAPE"><a href="#2-6-平均绝对百分误差-MAPE" class="headerlink" title="2.6  平均绝对百分误差 MAPE"></a>2.6  平均绝对百分误差 MAPE</h3><p>虽然平均绝对误差能够获得一个评价值，但是你并不知道这个值代表模型拟合是优还是劣，只有通过对比才能达到效果。当需要以相对的观点来衡量误差时，则使用MAPE。</p>
<p><strong>平均绝对百分误差</strong>（<strong>Mean Absolute Percentage Error，MAPE</strong>）是对 MAE 的一种改进，考虑了绝对误差相对真实值的比例。</p>
<ul>
<li><strong>优点</strong>：考虑了预测值与真实值的误差。考虑了误差与真实值之间的比例。</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=MAPE%3D%5Cfrac%7B100%7D%7Bm%7D%20%5Csum_%7Bi%3D1%7D%5E%7Bm%7D%20%5Cleft%20%7C%20%20%5Cfrac%7By_%7Bi%7D-f%5Cleft%28x_%7Bi%7D%5Cright%29%7D%7By_%7Bi%7D%7D%20%5Cright%20%7C" alt="公式"></p>
<blockquote>
<p>  在某些场景下，如房价从 <img src="https://www.zhihu.com/equation?tex=5K" alt="公式"> 到 <img src="https://www.zhihu.com/equation?tex=50K" alt="公式"> 之间，<img src="https://www.zhihu.com/equation?tex=5K" alt="公式"> 预测成 <img src="https://www.zhihu.com/equation?tex=10K" alt="公式"> 与 <img src="https://www.zhihu.com/equation?tex=50K" alt="公式"> 预测成 <img src="https://www.zhihu.com/equation?tex=45K" alt="公式"> 的差别是非常大的，而平均绝对百分误差考虑到了这点。</p>
</blockquote>
<h2 id="三、相似性度量指标"><a href="#三、相似性度量指标" class="headerlink" title="三、相似性度量指标"></a>三、相似性度量指标</h2><blockquote>
<p>  机器学习中的相似性度量方法 - 天下客的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/411876558">https://zhuanlan.zhihu.com/p/411876558</a></p>
</blockquote>
<p>描述样本之间相似度的方法有很多种，一般来说常用的有相关系数和欧式距离。本文对机器学习中常用的相似性度量方法进行了总结。<strong>在做分类时，常常需要估算不同样本之间的相似性度量（Similarity Measurement），</strong>这时通常采用的方法就是计算样本间的“距离”（distance）。采用什么样的方法计算距离是很讲究的，甚至关系到分类的正确与否。</p>
<ul>
<li><strong>欧式距离</strong>：k-means</li>
<li><strong>曼哈顿距离</strong>：</li>
<li><strong>切比雪夫距离</strong>：</li>
<li>闵可夫斯基距离</li>
<li>标准化欧氏距离</li>
<li>马氏距离</li>
<li><a href="https://www.zhihu.com/search?q=夹角余弦&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;article&quot;%2C&quot;sourceId&quot;%3A&quot;55493039&quot;}">夹角余弦</a></li>
<li><strong>汉明距离</strong>：simhash</li>
<li><strong>杰卡德距离&amp;杰卡德相似系数</strong>: <strong>杰卡德相似系数是衡量两个集合的相似度一种指标。</strong></li>
<li>相关系数&amp;相关距离</li>
<li>信息熵</li>
</ul>
<h2 id="四、推荐算法评价指标"><a href="#四、推荐算法评价指标" class="headerlink" title="四、推荐算法评价指标"></a>四、推荐算法评价指标</h2><ul>
<li>推荐算法评价指标 - 一干正事就犯困的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/359528909">https://zhuanlan.zhihu.com/p/359528909</a></li>
</ul>
<h4 id="4-1-AP"><a href="#4-1-AP" class="headerlink" title="4.1 AP"></a>4.1 AP</h4><p><code>AP</code> 衡量的是训练好的模型在每个类别上的好坏；</p>
<p><img src="https://pic2.zhimg.com/80/v2-e8656365e7eee25065d6bdfec33368e5_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p><strong>AP总结了一个精确召回曲线，作为在每个阈值处获得的精度的加权平均值，并且与以前的阈值相比，召回率的增加用作权重</strong>：</p>
<p><img src="/Users/apple/Library/Application Support/typora-user-images/image-20220711160205051.png" alt="image-20220711160205051" style="zoom:50%;"></p>
<p>其中和分别是第n个阈值[1]时的精度和召回率。此实现未进行插值，并且与使用梯形规则计算精确调用曲线下的面积有所不同，后者使用线性插值并且可能过于乐观。</p>
<h4 id="4-2-MAP"><a href="#4-2-MAP" class="headerlink" title="4.2 MAP"></a>4.2 MAP</h4><p><strong>MAP（Mean Average Precision）常用于排序任务，MAP的计算涉及另外两个指标：Precision和Recall</strong></p>
<ul>
<li><strong>Precision和Precision@k</strong></li>
</ul>
<p>推荐算法中的精度precision计算如下： </p>
<p><img src="https://www.zhihu.com/equation?tex=precision%3D%5Cfrac%7B%E7%AE%97%E6%B3%95%E7%BB%93%E6%9E%9C%E4%B8%AD%E7%9B%B8%E5%85%B3%E7%9A%84item%E6%95%B0%E9%87%8F%7D%7B%E6%8E%A8%E8%8D%90%E7%9A%84item%E6%80%BB%E6%95%B0%E9%87%8F%7D+%5C%5C" alt="[公式]"></p>
<p>可以看出Precision的计算没有考虑结果列表中item的顺序，Precision@k则通过切片的方式将顺序隐含在结果中。Precision@k表示列表前k项的Precision，随着k的变化，可以得到一系列precision值，用 <img src="https://www.zhihu.com/equation?tex=P%28k%29" alt="[公式]"> 表示。</p>
<ul>
<li><strong>Recall和Recall@k</strong></li>
</ul>
<p>推荐算法中的召回率recall计算如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=+recall%3D%5Cfrac%7B%E7%AE%97%E6%B3%95%E7%BB%93%E6%9E%9C%E4%B8%AD%E7%9B%B8%E5%85%B3%E7%9A%84item%E6%95%B0%E9%87%8F%7D%7B%E6%89%80%E6%9C%89%E7%9B%B8%E5%85%B3%E7%9A%84item%E6%95%B0%E9%87%8F%7D%5C%5C" alt="[公式]"></p>
<p>与Precision@k相似，recall@k表示结果列表前k项的recall，随着k的变化，可以得到一系列的recall值，用 <img src="https://www.zhihu.com/equation?tex=r%28k%29" alt="[公式]"> 表示。</p>
<ul>
<li><h5 id="AP-N"><a href="#AP-N" class="headerlink" title="AP@N"></a>AP@N</h5></li>
</ul>
<p>AP（Average Precision）平均精度的计算以Precision@k为基础，可以体现出结果列表中item顺序的重要性，其计算过程如下： </p>
<p><img src="https://www.zhihu.com/equation?tex=AP%40N%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum%5EN_%7Bk%3D1%7D%28P%28k%29%5Cquad+if%5C%2C+kth%5C%2C+item%5C%2C+is%5C%2C+relevant%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum%5EN_%7Bk%3D1%7DP%28k%29%5Ccdot+rel%28k%29+%5C%5C" alt="[公式]"></p>
<p>其中，N表示要求推荐的N个item，m表示所有相关的item总数， <img src="https://www.zhihu.com/equation?tex=rel%28k%29" alt="[公式]"> 表示第k个item是否相关，相关为1，反之为0</p>
<p><strong>AP@N的值越大，表示推荐列表中相关的item数量越多以及相关item的排名越靠前</strong></p>
<ul>
<li><h5 id="MAP-N"><a href="#MAP-N" class="headerlink" title="MAP@N"></a>MAP@N</h5></li>
</ul>
<p><strong>AP@N评价了算法对单个用户的性能，MAP@N则是算法对多个用户的平均值，是平均数的平均，其计算过程如下</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=MAP%40N%3D%5Cfrac%7B1%7D%7B%7CU%7C%7D%5Csum_%7Bu%3D1%7D%5E%7B%7CU%7C%7D%28AP%40N%29u%3D%5Cfrac%7B1%7D%7B%7CU%7C%7D%5Csum%7Bu%3D1%7D%5E%7B%7CU%7C%7D%28%5Cfrac%7B1%7D%7Bm%7D%5Csum%5EN_%7Bk%3D1%7DP_u%28k%29%5Ccdot+rel_u%28k%29%29+%5C%5C" alt="[公式]"></p>
<h2 id="五、聚类算法评价指标"><a href="#五、聚类算法评价指标" class="headerlink" title="五、聚类算法评价指标"></a>五、聚类算法评价指标</h2><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/343667804">https://zhuanlan.zhihu.com/p/343667804</a></p>
<p>  十分钟掌握聚类算法的评估指标：<a href="https://juejin.cn/post/6997913127572471821">https://juejin.cn/post/6997913127572471821</a></p>
</blockquote>
<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>如同之前介绍的其它算法模型一样，对于聚类来讲我们同样会通过一些评价指标来衡量聚类算法的优与劣。在聚类任务中，常见的评价指标有：<strong>纯度（Purity）</strong>、<strong>兰德系数（Rand Index, RI）</strong>、<strong>F值（F-score）</strong>和<strong>调整兰德系数（Adjusted Rand Index,ARI）</strong>。同时，这四种评价指标也是聚类相关论文中出现得最多的评价方法。下面，我们就来对这些算法一一进行介绍。</p>
<p><img src="https://pic3.zhimg.com/80/v2-e62c8b4b793c89b1cd70f2aaebf690c6_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>好的聚类算法，一般要求类簇具有：</p>
<ul>
<li><strong>簇内 (intra-cluster) 相似度高</strong></li>
<li><strong>簇间 (inter-cluster) 相似度底</strong></li>
</ul>
<p>一般来说，评估聚类质量有两个标准，内部评估评价指标和外部评估指标。</p>
<h3 id="【外部评估】"><a href="#【外部评估】" class="headerlink" title="【外部评估】"></a>【外部评估】</h3><h3 id="5-1聚类纯度-聚类的准确率"><a href="#5-1聚类纯度-聚类的准确率" class="headerlink" title="5.1聚类纯度 - 聚类的准确率"></a><strong>5.1聚类纯度</strong> - 聚类的准确率</h3><p>在聚类结果的评估标准中，一种最简单最直观的方法就是计算它的<strong>聚类纯度</strong>（purity），别看纯度听起来很陌生，但实际上和<strong>分类问题中的准确率有着异曲同工之妙</strong>。因为聚类纯度的总体思想也<strong>用聚类正确的样本数除以总的样本数，因此它也经常被称为聚类的准确率</strong>。只是对于聚类后的结果我们并不知道每个簇所对应的真实类别，因此需要取每种情况下的最大值。具体的，纯度的计算公式定义如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+P%3D%28%5COmega%2C%5Cmathbb%7BC%7D%29%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bk%7D%5Cmax_%7Bj%7D%7C%5Comega_k%5Ccap+c_j%7C+%5Cend%7Baligned%7D%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%281%29+%5C%5C" alt="[公式]"></p>
<p>其中<img src="https://www.zhihu.com/equation?tex=N" alt="[公式]">表示总的样本数；<img src="https://www.zhihu.com/equation?tex=%5COmega%3D%5C%7B%5Comega_1%2C%5Comega_2%2C...%2C%5Comega_K%5C%7D" alt="[公式]">表示一个个聚类后的簇，而<img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BC%7D%3D%5C%7Bc_1%2C_2%2C...c_J%5C%7D" alt="[公式]">表示正确的类别；<img src="https://www.zhihu.com/equation?tex=%5Comega_k" alt="[公式]">表示聚类后第<img src="https://www.zhihu.com/equation?tex=k" alt="[公式]">个簇中的所有样本，<img src="https://www.zhihu.com/equation?tex=c_j" alt="[公式]">表示第<img src="https://www.zhihu.com/equation?tex=j" alt="[公式]">个类别中真实的样本。在这里<img src="https://www.zhihu.com/equation?tex=P" alt="[公式]">的取值范围为<img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[公式]">，越大表示聚类效果越好。</p>
<h3 id="5-2-兰德系数与F值-同簇混淆矩阵"><a href="#5-2-兰德系数与F值-同簇混淆矩阵" class="headerlink" title="5.2 兰德系数与F值  [同簇混淆矩阵]"></a><strong>5.2 兰德系数与F值</strong>  [同簇混淆矩阵]</h3><p>在介绍完了纯度这一评价指标后，我们再来看看兰德系数（Rand Index）和F值。虽然兰德系数听起来是一个陌生的名词，但它的计算过程却也与准确率的计算过程类似。同时，虽然这里也有一个叫做F值的指标，并且它的计算过程也和分类指标中的F值类似，但是两者却有着本质的差别。说了这么多，那这两个指标到底该怎么算呢？同分类问题中的混淆矩阵类似，这里我们也要先定义四种情况进行计数，然后再进行指标的计算。</p>
<p><strong>为了说明兰德系数背后的思想，我们还是以图1中的聚类结果为例进行说明（为了方便观察，我们再放一张图在这里）:</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-e62c8b4b793c89b1cd70f2aaebf690c6_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=TP" alt="[公式]">：表示两个<strong>同类样本点</strong>在<strong>同一个簇</strong>（布袋）中的情况数量；</li>
<li><img src="https://www.zhihu.com/equation?tex=FP" alt="[公式]">：表示两个<strong>非同类样本点</strong>在<strong>同一个簇</strong>中的情况数量；</li>
<li><img src="https://www.zhihu.com/equation?tex=TN" alt="[公式]">：表示两个<strong>非同类样本点</strong>分别在<strong>两个簇</strong>中的情况数量；</li>
<li><img src="https://www.zhihu.com/equation?tex=FN" alt="[公式]">：表示两个同类样本点分别在<strong>两个簇</strong>中的情况数量；</li>
</ul>
<p>由此，我们便能得到如下所示的对<strong>混淆矩阵（Pair Confusion Matrix）</strong>：</p>
<p><img src="https://pic3.zhimg.com/80/v2-a9e709a995b006be04d026aebc721c4e_1440w.png" alt="img" style="zoom:75%;"></p>
<p>有了上面各种情况的统计值，我们就可以定义出兰德系数和F值的计算公式：</p>
<p><img src="https://www.zhihu.com/equation?tex=RI%3D%5Cfrac%7BTP%2BTN%7D%7BTP%2BFP%2BFN%2BTN%7D%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%283%29+%5C%5C" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+Precision%26%3D%5Cfrac%7BTP%7D%7BTP%2BFP%7D%5C%5C%5B2ex%5D+Recall%26%3D%5Cfrac%7BTP%7D%7BTP%2BFN%7D%5C%5C%5B2ex%5D+F_%7B%5Cbeta%7D%26%3D%281%2B%5Cbeta%5E2%29%5Cfrac%7BPrecision%5Ccdot+Recall%7D%7B%5Cbeta%5E2%5Ccdot+Precision%2BRecall%7D+%5Cend%7Baligned%7D%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%5C%3B%284%29+%5C%5C" alt="[公式]"></p>
<p>从上面的计算公式来看，<img src="https://www.zhihu.com/equation?tex=%283%29%284%29" alt="[公式]">从形式上看都非常像分类问题中的准确率与F值，但是有着本质的却别。同时，在这里<img src="https://www.zhihu.com/equation?tex=RI" alt="[公式]">和<img src="https://www.zhihu.com/equation?tex=F_%7B%5Cbeta%7D" alt="[公式]">的取值范围均为<img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[公式]">，越大表示聚类效果越好。</p>
<h4 id="5-3-调整兰德系数（Adjusted-Rand-index）【归一化】"><a href="#5-3-调整兰德系数（Adjusted-Rand-index）【归一化】" class="headerlink" title="5.3 调整兰德系数（Adjusted Rand index）【归一化】"></a>5.3 调整兰德系数（Adjusted Rand index）【归一化】</h4><p>对于随机结果，RI并不能保证分数接近零。<strong>为了实现“在聚类结果随机产生的情况下，指标应该接近零”</strong>，调整兰德系数（Adjusted rand index）被提出，它具有更高的区分度。</p>
<p>其公式为：</p>
<script type="math/tex; mode=display">
\mathrm{ARI}=\frac{\mathrm{RI}-E[\mathrm{RI}]}{\max (\mathrm{RI})-E[\mathrm{RI}]}</script><p>$A R$ 取值范围为 $[-1,1]$, 值越大意味着聚类结果与真实情况越吻合。从广义的角度来讲, ARI衡量的是两个数据分布的吻合程度。</p>
<p>优点:</p>
<ul>
<li>对任意数量的聚类中心和样本数, 随机聚类的ARI都非常接近于 0 。</li>
<li>取值在 $[-1,1]$ 之间, 负数代表结果不好, 越接近于1越好。</li>
<li>对簇的结构不需作出任何假设：可以用于比较聚类算法。</li>
</ul>
<p>缺点:</p>
<ul>
<li>ARI 需要 ground truth classes 的相关知识, ARI需要真实标签, 而在实践中几乎不可用, 或者需要人工 标注者手动分配（如在监督学习环境中）。</li>
</ul>
<h3 id="5-4-标准化互信息（NMI-Normalized-Mutual-Information）"><a href="#5-4-标准化互信息（NMI-Normalized-Mutual-Information）" class="headerlink" title="5.4  标准化互信息（NMI, Normalized Mutual Information）"></a>5.4 <strong><font color="red"> 标准化互信息（NMI, Normalized Mutual Information）</font></strong></h3><p>互信息是用来衡量两个数据分布的吻合程度。它也是一有用的信息度量，它是指两个事件集合之间的相关性。互信息越大，词条和类别的相关程度也越大。</p>
<h3 id="【内部指标】"><a href="#【内部指标】" class="headerlink" title="【内部指标】"></a>【内部指标】</h3><p>内部评估指标主要基于数据集的集合结构信息从紧致性、分离性、连通性和重叠度等方面对聚类划分进行评价。即基于数据聚类自身进行评估的。</p>
<h3 id="5-5-轮廓系数（Silhouette-Coefficient）"><a href="#5-5-轮廓系数（Silhouette-Coefficient）" class="headerlink" title="5.5  轮廓系数（Silhouette Coefficient）"></a>5.5 <strong><font color="red"> 轮廓系数（Silhouette Coefficient）</font></strong></h3><p>轮廓系数适用于实际类别信息未知的情况。</p>
<p>对于单个样本，设<strong>a是与它同类别中其他样本的平均距离</strong>，<strong>b是与它距离最近不同类别中样本的平均距离</strong>，其轮廓系数为：</p>
<p>$s = \frac {b-a} {max(a, b)}$</p>
<p>对于一个样本集合，它的轮廓系数是所有样本轮廓系数的平均值。轮廓系数的取值范围是[-1,1]，同类别样本距离越相近，不同类别样本距离越远，值越大。当值为负数时，说明聚类效果很差。</p>
<h3 id="5-6-Calinski-Harabaz指数（Calinski-Harabaz-Index）"><a href="#5-6-Calinski-Harabaz指数（Calinski-Harabaz-Index）" class="headerlink" title="5.6 Calinski-Harabaz指数（Calinski-Harabaz Index）"></a>5.6 Calinski-Harabaz指数（Calinski-Harabaz Index）</h3><p>在真实的分群label不知道的情况下，Calinski-Harabasz可以作为评估模型的一个指标。</p>
<p>Calinski-Harabasz指数通过<strong>计算类中各点与类中心的距离平方和来度量类内的紧密度</strong>，通过<strong>==计算各类中心点与数据集中心点距离平方和来度量数据集的分离度==</strong>，CH指标<strong>由分离度与紧密度的比值得到</strong>。从而，CH越大代表着类自身越紧密，类与类之间越分散，即更优的聚类结果。</p>
<p><strong>优点</strong></p>
<ul>
<li>当簇的密集且分离较好时，分数更高。</li>
<li>得分计算很快，与轮廓系数的对比，最大的优势：快！相差几百倍！毫秒级。</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li>凸的簇的CH指数通常高于其他类型的簇。例如，通过 DBSCAN 获得基于密度的簇；所以，不适合基于密度的聚类算法（DBSCAN）。</li>
</ul>
<h3 id="5-7-戴维森堡丁指数（DBI-Davies-Bouldin-Index）"><a href="#5-7-戴维森堡丁指数（DBI-Davies-Bouldin-Index）" class="headerlink" title="5.7 戴维森堡丁指数（DBI, Davies-Bouldin Index）"></a>5.7 戴维森堡丁指数（DBI, Davies-Bouldin Index）</h3><p><strong>DB指数是计算任意两类别的类内距离平均距离之和除以两聚类中心距离求最大值</strong>。DB越小，意味着类内距 离越小同时类间距离越大。<strong>零是可能的最低值, 接近零的值表示更好的分区</strong>。</p>
<script type="math/tex; mode=display">
\begin{gathered}
R_{i j}=\frac{s_{i}+s_{j}}{d_{i j}} \\
D B=\frac{1}{k} \sum_{i=1}^{k} \max _{i \neq j} R_{i j}
\end{gathered}</script><p>其中, $s_{i}$ 表示簇的每个点与该簇的质心之间的平均距离, 也称为簇直径。 $d_{i j}$ 表示聚类和的质心之间的距 离。<br>算法生成的聚类结果越是朝着簇内距离最小（类内相似性最大）和笶间距离最大（类间相似性最小）变化， 那么Davies-Bouldin指数就会越小。<br><strong>缺点</strong>:</p>
<ul>
<li>因使用欧式距离, 所以对于环状分布聚类评测很差。</li>
</ul>
<h2 id="六、评分总结（sklearn）"><a href="#六、评分总结（sklearn）" class="headerlink" title="六、评分总结（sklearn）"></a>六、评分总结（sklearn）</h2><blockquote>
<p>  sklearn.metrics - 回归/分类模型的评估方法:<a href="https://zhuanlan.zhihu.com/p/408078074">https://zhuanlan.zhihu.com/p/408078074</a></p>
</blockquote>
<h3 id="6-1-分类模型"><a href="#6-1-分类模型" class="headerlink" title="6.1 分类模型"></a>6.1 分类模型</h3><h4 id="accuracy-score"><a href="#accuracy-score" class="headerlink" title="accuracy_score"></a><strong>accuracy_score</strong></h4><p><strong>分类准确率分数是指所有分类正确的百分比</strong>。分类准确率这一衡量分类器的标准比较容易理解，但是它不能告诉你响应值的潜在分布，并且它也不能告诉你分类器犯错的类型。所以在使用的时候，一般需要搭配matplotlib等数据可视化工具来观察预测的分类情况，与实际的结果做更加直观的比较。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score  </span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>]  </span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]  </span><br><span class="line">accuracy_score(y_true, y_pred)  <span class="comment"># 默认normalization = True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.5</span></span><br><span class="line">accuracy_score(y_true, y_pred, normalize=<span class="literal">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">2</span></span><br></pre></td></tr></table></figure>
<h4 id="recall-score"><a href="#recall-score" class="headerlink" title="recall_score"></a><strong>recall_score</strong></h4><p>召回率 =<strong>提取出的正确信息条数 /样本中的信息条数</strong>。通俗地说，就是所有准确的条目有多少被检索出来了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">recall_score(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>,average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">参数average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br></pre></td></tr></table></figure>
<p>将一个二分类matrics拓展到多分类或多标签问题时，我们可以将数据看成多个二分类问题的集合，每个类都是一个二分类。接着，我们可以通过跨多个分类计算每个二分类metrics得分的均值，这在一些情况下很有用。你可以使用<strong>average参数</strong>来指定。 </p>
<ul>
<li>macro：计算二分类metrics的均值，为每个类给出相同权重的分值。</li>
<li>weighted:对于不均衡数量的类来说，计算二分类metrics的平均，通过在每个类的score上进行加权实现。 </li>
<li>micro：给出了每个样本类以及它对整个metrics的贡献的pair（sample-weight），而非对整个类的metrics求和，它会每个类的metrics上的权重及因子进行求和，来计算整个份额。</li>
<li>samples：应用在multilabel问题上。它不会计算每个类，相反，它会在评估数据中，通过计算真实类和预测类的差异的metrics，来求平均（sample_weight-weighted） </li>
<li>average：average=None将返回一个数组，它包含了每个类的得分.</li>
</ul>
<h4 id="roc-curve"><a href="#roc-curve" class="headerlink" title="roc_curve"></a><strong>roc_curve</strong></h4><p>ROC曲线指受试者工作特征曲线/接收器操作特性(receiver operating characteristic，ROC)曲线,是<strong>反映灵敏性和特效性连续变量的综合指标</strong>,是用构图法揭示敏感性和特异性的相互关系，它通过将连续变量设定出多个不同的临界值，从而计算出一系列敏感性和特异性。ROC曲线是根据一系列不同的二分类方式（分界值或决定阈），<strong>以真正例率（也就是灵敏度）（True Positive Rate,TPR）为纵坐标，假正例率（1-特效性）（False Positive Rate,FPR）为横坐标</strong>绘制的曲线。</p>
<p>通过ROC我们可以观察到模型正确识别的正例的比例与模型错误地把负例数据识别成正例的比例之间的权衡。TPR的增加以FPR的增加为代价。ROC曲线下的面积是模型准确率的度量，<strong>AUC</strong>（Area under roc curve）。</p>
<p><strong>TPR</strong> = TP /（TP + FN） （正样本<strong>预测数</strong> / 正样本<strong>实际数</strong>）</p>
<p><strong>FPR</strong> = FP /（FP + TN） （负样本<strong>预测数</strong> /负样本<strong>实际数</strong>）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics  </span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>])  </span><br><span class="line">scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=<span class="number">2</span>)  </span><br><span class="line">fpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.</span> ,  <span class="number">0.5</span>,  <span class="number">0.5</span>, <span class="number">1.</span> ])  </span><br><span class="line">tpr  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.5</span>,  <span class="number">0.5</span>,  <span class="number">1.</span> , <span class="number">1.</span> ])  </span><br><span class="line">thresholds  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>array([<span class="number">0.8</span> ,  <span class="number">0.4</span> ,  <span class="number">0.35</span>, <span class="number">0.1</span> ])  </span><br><span class="line"></span><br><span class="line"><span class="comment"># check auc score</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> auc   </span><br><span class="line">metrics.auc(fpr, tpr)   </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>   </span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以直接根据预测值+真实值来计算出auc值，略过roc的计算过程</span></span><br><span class="line">‘’‘</span><br><span class="line">sklearn.metrics.roc_auc_score(y_true, y_score, average=<span class="string">&#x27;macro&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br><span class="line">average : string, [<span class="literal">None</span>, ‘micro’, ‘macro’(default), ‘samples’, ‘weighted’]</span><br><span class="line">’‘’</span><br><span class="line"><span class="comment"># 真实值（必须是二值）、预测值（可以是0/1,也可以是proba值）</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score  </span><br><span class="line">y_true = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>])  </span><br><span class="line">y_scores = np.array([<span class="number">0.1</span>, <span class="number">0.4</span>, <span class="number">0.35</span>, <span class="number">0.8</span>])  </span><br><span class="line">roc_auc_score(y_true, y_scores)  </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">0.75</span>  </span><br></pre></td></tr></table></figure>
<h4 id="confusion-metric"><a href="#confusion-metric" class="headerlink" title="confusion metric"></a><strong>confusion metric</strong></h4><p>混淆矩阵（confusion matrix），又称为可能性表格或是错误矩阵。它是一种特定的矩阵用来呈现算法性能的可视化效果。其每一列代表预测值，每一行代表的是实际的类别。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">confusion_matric(y_true, y_pred, labels=<span class="literal">None</span>, pos_label=<span class="number">1</span>, average=<span class="string">&#x27;binary&#x27;</span>, sample_weight=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h4 id="precision-score"><a href="#precision-score" class="headerlink" title="precision_score"></a><strong>precision_score</strong></h4><p>计算精确度——precision <img src="https://www.zhihu.com/equation?tex=%3DTP%2F%28TP%2FFP%29" alt="[公式]"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">precision_score(y_true, y_pred, labels=None, pos_label=1, average=&#x27;binary&#x27;)</span><br></pre></td></tr></table></figure>
<p><img src="https://pic2.zhimg.com/v2-a3b6092e30d2eab7d2372007aec15105_r.jpg" alt="preview"></p>
<h2 id="评价指标Q-amp-A"><a href="#评价指标Q-amp-A" class="headerlink" title="评价指标Q&amp;A"></a>评价指标Q&amp;A</h2><h4 id="精度指标存在的问题？"><a href="#精度指标存在的问题？" class="headerlink" title="精度指标存在的问题？"></a><strong>精度指标存在的问题</strong>？</h4><ul>
<li>有倾向性的问题。比如，判断空中的飞行物是导弹还是其他飞行物，很显然为了减少损失，我们更倾向于相信是导弹而采用相应的防护措施。此时判断为导弹实际上是其他飞行物与判断为其他飞行物实际上是导弹这两种情况的重要性是不一样的；</li>
<li>样本类别数量严重不均衡的情况。比如银行客户样本中好客户990个，坏客户10个。如果一个模型直接把所有客户都判断为好客户，得到精度为99%，但这显然是没有意义的。</li>
</ul>
<h4 id="为什么-ROC-和-AUC-都能应用于非均衡的分类问题？"><a href="#为什么-ROC-和-AUC-都能应用于非均衡的分类问题？" class="headerlink" title="为什么 ROC 和 AUC 都能应用于非均衡的分类问题？"></a><strong>为什么 ROC 和 AUC 都能应用于非均衡的分类问题？</strong></h4><p><strong>ROC曲线只与横坐标 (FPR) 和 纵坐标 (TPR) 有关系</strong> 。我们可以发现TPR只是正样本中预测正确的概率，而FPR只是负样本中预测错误的概率，和正负样本的比例没有关系。因此 ROC 的值与实际的正负样本比例无关，因此既可以用于均衡问题，也可以用于非均衡问题。而 AUC 的几何意义为ROC曲线下的面积，因此也和实际的正负样本比例无关。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/05/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%883%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/</url>
    <content><![CDATA[<h2 id="「融合」机器学习模型：一种提升预测能力的方法"><a href="#「融合」机器学习模型：一种提升预测能力的方法" class="headerlink" title="「融合」机器学习模型：一种提升预测能力的方法"></a><a href="https://zhuanlan.zhihu.com/p/33589222">「融合」机器学习模型：一种提升预测能力的方法</a></h2><p>没有哪个机器学习模型可以常胜，如何找到当前问题的最优解是一个永恒的问题。</p>
<p>幸运的是，<strong>结合/融合/整合 (integration/ combination/ fusion)多个机器学习模型往往可以提高整体的预测能力。</strong>这是一种非常有效的提升手段，在多分类器系统(multi-classifier system)和集成学习(ensemble learning)中，融合都是最重要的一个步骤。</p>
<p>一般来说，<strong>模型融合或多或少都能提高的最终的预测能力，且一般不会比最优子模型差</strong>。举个实用的例子，Kaggle比赛中常用的stacking方法就是模型融合，通过结合多个各有所长的子学习器，我们实现了更好的预测结果。基本的理论假设是：<strong>不同的子模型在不同的数据上有不同的表达能力，我们可以结合他们擅长的部分，得到一个在各个方面都很“准确”的模型</strong>。当然，最基本的假设是子模型的误差是互相独立的，这个一般是不现实的。但即使子模型间的误差有相关性，适当的结合方法依然可以各取其长，从而达到提升效果。</p>
<p>我们今天介绍几种简单、有效的模型结合方法。</p>
<h3 id="1-案例分析"><a href="#1-案例分析" class="headerlink" title="1. 案例分析"></a><strong>1. 案例分析</strong></h3><p>让我们给出一个简单的分析。假设我们有天气数据X和对应的标签y，现在希望实现一个可以预测明天天气的模型 <img src="https://www.zhihu.com/equation?tex=%5Cpsi" alt="[公式]"> 。但我们并不知道用什么算法效果最好，于是尝试了十种算法，包括</p>
<ul>
<li>算法1: 逻辑回归 - <img src="https://www.zhihu.com/equation?tex=C_%7B1%7D" alt="[公式]"> </li>
<li>算法2：支持向量机（SVM）-  <img src="https://www.zhihu.com/equation?tex=C_%7B2%7D" alt="[公式]"> </li>
<li>…</li>
<li>算法10：随机森林 -  <img src="https://www.zhihu.com/equation?tex=C_%7B10%7D" alt="[公式]"> </li>
</ul>
<p>结果发现他们表现都一般，在验证集上的误分率比较高。我们现在期待找到一种方法，可以有效提高最终预测结果。</p>
<h3 id="2-平均法-投票法"><a href="#2-平均法-投票法" class="headerlink" title="2. 平均法/投票法"></a><strong>2. 平均法/投票法</strong></h3><p>一种比较直白的方法就是对让10个算法模型同时对需要预测的数据进行预测，并对结果取平均数/众数。假设10个分类器对于测试数据 <img src="https://www.zhihu.com/equation?tex=X_%7Bt%7D" alt="[公式]"> 的预测结果是<img src="https://www.zhihu.com/equation?tex=%5BC_%7B1%7D%28X_t%29%2CC_%7B2%7D%28X_t%29%2C...%2CC_%7B10%7D%28X_t%29%5D%3D%5B0%2C1%2C1%2C1%2C1%2C1%2C0%2C1%2C1%2C0%5D" alt="[公式]"> ，那很显然少数服从多数，我们应该选择1作为 <img src="https://www.zhihu.com/equation?tex=X_%7Bt%7D" alt="[公式]"> 的预测结果。如果取平均值的话也可以那么会得到0.7，高于阈值0.5，因此是等价的。</p>
<p>但这个时候需要有几个注意的地方：</p>
<p><strong>首先，不同分类器的输出结果取值范围不同</strong>，不一定是[0,1]，而可以是无限定范围的值。举例，逻辑回归的输出范围是0-1（概率），而k-近邻的输出结果可以是大于0的任意实数，其他算法的输出范围可能是负数。<strong>因此整合多个分类器时，需要注意不同分类器的输出范围，并统一这个取值范围</strong>。</p>
<ul>
<li>比如可以先转化为如<strong>二分类结果</strong>，把输出的范围统一后再进行整合。但这种方法的问题在于我们丢失了很多信息，0.5和0.99都会被转化为1，但明显其可靠程度差别很大。</li>
<li>也可以转化为排序（ranking），再对不同的ranking进行求平均。</li>
<li>更加稳妥的方法是对每个分类器的输出结果做标准化，也就是调整到正态分布上去。之后就可以对多个调整后的结果进行整合。同理，用归一化也可以有类似的效果。</li>
</ul>
<p><strong>其次，就是整合稳定性的问题</strong>。采用平均法的另一个风险在于可能被极值所影响。正态分布的取值是 <img src="https://www.zhihu.com/equation?tex=%5B-%5Cinfty%2C%2B%5Cinfty%5D" alt="[公式]"> ，在少数情况下平均值会受到少数极值的影响。一个常见的解决方法是，用中位数（median)来代替平均数进行整合。</p>
<p><strong>同时，模型整合面临的另一个问题是子模型良莠不齐</strong>。如果10个模型中有1个表现非常差，那么会拖累最终的效果，适得其反。==因此，简单、粗暴的把所有子模型通过平均法整合起来效果往往一般。==</p>
<h3 id="3-寻找优秀的子模型准而不同"><a href="#3-寻找优秀的子模型准而不同" class="headerlink" title="3. 寻找优秀的子模型准而不同"></a>3. 寻找优秀的子模型准而不同</h3><p>不难看出，一个较差的子模型会拖累整体的集成表现，那么这就涉及到另一个问题？什么样的子模型是优秀的。</p>
<p>一般来说，我们希望子模型：<strong>准而不同 -&gt; accurate but diversified</strong>。好的子模型应该首先是准确的，这样才会有所帮助。其次不同子模型间应该有差别，比如独立的误差，这样作为一个整体才能起到<strong>互补作用</strong>。</p>
<p>因此，如果想实现良好的结合效果，就必须对子模型进行筛选，去粗取精。在这里我们需要做出一点解释，我们今天说的融合方法和bagging还有boosting中的思路不大相同。==bagging和boosting中的子模型都是<strong>很简单的且基数庞大</strong>，而我们今天的模型融合是<strong>结合少量但较为复杂的模型</strong>。==</p>
<h3 id="4-筛选方法：赋予不同子模型不同的权重"><a href="#4-筛选方法：赋予不同子模型不同的权重" class="headerlink" title="4. 筛选方法：赋予不同子模型不同的权重"></a><strong>4. 筛选方法：赋予不同子模型不同的权重</strong></h3><p>因此我们不能再简单的取平均了，而应该给优秀的子模型更大的权重。在这种前提下，一个比较直白的方法就是根据子<strong>模型的准确率给出一个参考权重</strong> <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> ，子模型越准确那么它的权重就更大，对于最终预测的影响就更强： <img src="https://www.zhihu.com/equation?tex=w_%7Bi%7D%3D%5Cfrac%7BAcc%28C_%7Bi%7D%29%7D%7B%5Csum_%7B1%7D%5E%7B10%7D%7BAcc%28C_%7Bj%7D%29%7D%7D" alt="[公式]"> 。简单取平均是这个方法的一个特例，即假设子模型准确率一致。</p>
<h3 id="5-更进一步：学习分类器权重"><a href="#5-更进一步：学习分类器权重" class="headerlink" title="5. 更进一步：学习分类器权重"></a><strong>5. 更进一步：学习分类器权重</strong></h3><p>在4中提到的方法在一定程度上可以缓解问题，但效果有限。那么另一个思路是，我们是否可以学习每个分类器的权重呢？</p>
<p>答案是肯定，这也就是Stacking的核心思路。通过增加一层来学习子模型的权重。</p>
<p><img src="https://pic3.zhimg.com/v2-13396e65c2bcc1c270ca536310686d07_720w.jpg?source=d16d100b" alt="img"></p>
<p><strong>图片来源</strong>：<a href="https://www.quora.com/What-is-stacking-in-machine-learning">https://www.quora.com/What-is-stacking-in-machine-learning</a></p>
<p>更多有关于stacking的讨论可以参考我最近的文章：<a href="https://zhuanlan.zhihu.com/p/32896968">「Stacking」与「神经网络」</a>。简单来说，就是加一层逻辑回归或者SVM，把子模型的输出结果当做训练数据，来自动赋予不同子模型不同的权重。</p>
<p>==<strong>一般来看，这种方法只要使用得当，效果应该比简单取平均值、或者根据准确度计算权重的效果会更好。</strong>==</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%884%EF%BC%89%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/</url>
    <content><![CDATA[<h2 id="机器学习优化方法-Optimization"><a href="#机器学习优化方法-Optimization" class="headerlink" title="机器学习优化方法 (Optimization)"></a>机器学习优化方法 (Optimization)</h2><blockquote>
<p>  机器学习与优化基础（Machine Learning and Optimization）:<a href="https://zhuanlan.zhihu.com/p/169835477">https://zhuanlan.zhihu.com/p/169835477</a></p>
<p>  最优化方法复习笔记：<a href="https://github.com/LSTM-Kirigaya/OptimizeNote">https://github.com/LSTM-Kirigaya/OptimizeNote</a></p>
<p>  <strong>FreeWill</strong>：<a href="https://plushunter.github.io/2017/07/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%8825%EF%BC%89%EF%BC%9A%E6%9C%80%E9%80%9F%E4%B8%8B%E9%99%8D%E6%B3%95%E3%80%81%E7%89%9B%E9%A1%BF%E6%B3%95%E3%80%81%E6%8B%9F%E7%89%9B%E9%A1%BF%E6%B3%95/">机器学习算法系列（25）：最速下降法、牛顿法、拟牛顿法</a></p>
</blockquote>
<h3 id="一、什么是凸优化"><a href="#一、什么是凸优化" class="headerlink" title="一、什么是凸优化"></a>一、什么是凸优化</h3><p><strong>凸函数</strong>的严格定义为，函数L(·) 是凸函数当且仅当对定义域中的任意两点x，y和任意实数λ∈[0,1]总有：</p>
<p><a href="https://camo.githubusercontent.com/d50ff64d3e458ed576babbb0c25c3f88b9f791b9f3df7435102dc77545df5147/687474703a2f2f7778342e73696e61696d672e636e2f6d773639302f30303633304465666c7931673565357769736474756a333064343031696a72612e6a7067"><img src="https://camo.githubusercontent.com/d50ff64d3e458ed576babbb0c25c3f88b9f791b9f3df7435102dc77545df5147/687474703a2f2f7778342e73696e61696d672e636e2f6d773639302f30303633304465666c7931673565357769736474756a333064343031696a72612e6a7067" alt="img"></a></p>
<p>该不等式的一个直观解释是，凸函数曲面上任意两点连接而成的线段，其上的任 意一点都不会处于该函数曲面的下方，如下图所示所示。</p>
<p><a href="https://camo.githubusercontent.com/4fbcceabdb43cc783d5adc0fb906cda38aeddd8790ce66b2d8e01b46b98cf467/687474703a2f2f7778342e73696e61696d672e636e2f6d773639302f30303633304465666c793167356366706d7336776f6a3330653130343977657a2e6a7067"><img src="https://camo.githubusercontent.com/4fbcceabdb43cc783d5adc0fb906cda38aeddd8790ce66b2d8e01b46b98cf467/687474703a2f2f7778342e73696e61696d672e636e2f6d773639302f30303633304465666c793167356366706d7336776f6a3330653130343977657a2e6a7067" alt="img"></a></p>
<p>凸优化问题的例子包括支持向量机、线性回归等 线性模型，非凸优化问题的例子包括低秩模型（如矩阵分解）、深度神经网络模型等。</p>
<h3 id="二、正则化项"><a href="#二、正则化项" class="headerlink" title="二、正则化项"></a>二、正则化项</h3><p>使用正则化项，也就是给loss function加上一个参数项，正则化项有<strong>L1正则化、L2正则化、ElasticNet</strong>。加入这个正则化项好处：</p>
<ul>
<li>控制参数幅度，不让模型“无法无天”。</li>
<li>限制参数搜索空间</li>
<li>解决欠拟合与过拟合的问题。</li>
</ul>
<p>详细请参考之前的文章：<a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine Learning/Liner Regression">线性回归—第5点</a></p>
<h3 id="三、常见的几种最优化方法"><a href="#三、常见的几种最优化方法" class="headerlink" title="==三、常见的几种最优化方法=="></a>==三、常见的几种最优化方法==</h3><ol>
<li><p><strong>梯度下降法</strong></p>
<p>梯度下降法是最早最简单，也是最为常用的最优化方法。梯度下降法实现简单，当<strong>目标函数是凸函数时，梯度下降法的解是全局解</strong>。一般情况下，其解不保证是全局最优解，梯度下降法的速度也未必是最快的。梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向，所以也被称为是”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢。梯度下降法的搜索迭代示意图如下图所示：</p>
<p><a href="https://camo.githubusercontent.com/bc08cfbd80c5299970c01cde376a8855269944fca897fb91eb9ff3d5076383b1/68747470733a2f2f696d61676573323031372e636e626c6f67732e636f6d2f626c6f672f313032323835362f3230313730392f313032323835362d32303137303931363230313933323733352d3234333634363139392e706e67"><img src="https://camo.githubusercontent.com/bc08cfbd80c5299970c01cde376a8855269944fca897fb91eb9ff3d5076383b1/68747470733a2f2f696d61676573323031372e636e626c6f67732e636f6d2f626c6f672f313032323835362f3230313730392f313032323835362d32303137303931363230313933323733352d3234333634363139392e706e67" alt="img"></a></p>
<p>缺点：靠近极小值时收敛速度减慢；直线搜索时可能会产生一些问题；可能会“之字形”地下降。</p>
</li>
<li><p><strong>牛顿法</strong></p>
<p>牛顿法是一种在实数域和复数域上近似求解方程的方法。方法使用函数f (x)的泰勒级数的前面几项来寻找方程f (x) = 0的根。牛顿法最大的特点就在于它的收敛速度很快。具体步骤：</p>
<ul>
<li><p>首先，选择一个接近函数 f (x)零点的 x0，计算相应的 f (x0) 和切线斜率f ‘ (x0)（这里f ‘ 表示函数 f 的导数）。</p>
</li>
<li><p>然后我们计算穿过点(x0, f (x0)) 并且斜率为f ‘(x0)的直线和 x 轴的交点的x坐标，也就是求如下方程的解：</p>
<p><a href="https://camo.githubusercontent.com/03d83e51c9348519324fd1b60c8aa7e5497e5cbb592c43e93f7d11fbac453681/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f782a662535452537422725374428785f30292b6628785f30292d785f302a662535452537422725374428785f30293d30"><img src="https://camo.githubusercontent.com/03d83e51c9348519324fd1b60c8aa7e5497e5cbb592c43e93f7d11fbac453681/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f782a662535452537422725374428785f30292b6628785f30292d785f302a662535452537422725374428785f30293d30" alt="img"></a></p>
</li>
<li><p>我们将新求得的点的 x 坐标命名为x1，通常x1会比x0更接近方程f (x) = 0的解。因此我们现在可以利用x1开始下一轮迭代。</p>
</li>
</ul>
<p>由于牛顿法是基于当前位置的切线来确定下一次的位置，所以牛顿法又被很形象地称为是”切线法”。牛顿法搜索动态示例图：</p>
<p><a href="https://camo.githubusercontent.com/7de2bde3d0eb6ad59fb428c06b904198c2cac6bd7e31f788f73b6bbbc4980709/68747470733a2f2f696d61676573323031372e636e626c6f67732e636f6d2f626c6f672f313032323835362f3230313730392f313032323835362d32303137303931363230323731393037382d313538383434363737352e676966"><img src="https://camo.githubusercontent.com/7de2bde3d0eb6ad59fb428c06b904198c2cac6bd7e31f788f73b6bbbc4980709/68747470733a2f2f696d61676573323031372e636e626c6f67732e636f6d2f626c6f672f313032323835362f3230313730392f313032323835362d32303137303931363230323731393037382d313538383434363737352e676966" alt="img"></a></p>
<p>从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。<strong>缺点：</strong></p>
<ul>
<li>牛顿法是一种迭代算法，每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。</li>
<li>在高维情况下这个矩阵非常大，计算和存储都是问题。</li>
<li>在小批量的情况下，牛顿法对于二阶导数的估计噪声太大。</li>
<li>目标函数非凸的时候，牛顿法容易受到鞍点或者最大值点的吸引。</li>
</ul>
</li>
<li><p><strong>拟牛顿法</strong></p>
<p>拟牛顿法是求解非线性优化问题最有效的方法之一，<strong>本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。</strong>拟牛顿法和梯度下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于梯度下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。</p>
</li>
<li><p><strong>共轭梯度法</strong></p>
<p>共轭梯度法是介于梯度下降法与牛顿法之间的一个方法，它仅需利用一阶导数信息，但克服了梯度下降法收敛慢的缺点，又避免了牛顿法需要存储和计算Hesse矩阵并求逆的缺点，共轭梯度法不仅是解决大型线性方程组最有用的方法之一，也是解大型非线性最优化最有效的算法之一。 在各种优化算法中，共轭梯度法是非常重要的一种。其优点是所需存储量小，具有步收敛性，稳定性高，而且不需要任何外来参数。</p>
<p>具体的实现步骤请参加wiki百科<a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method#Example_code_in_MATLAB">共轭梯度法</a>。下图为共轭梯度法和梯度下降法搜索最优解的路径对比示意图：</p>
<p><a href="https://camo.githubusercontent.com/6b3d0a2120d546206dbf7ae0e114fe52d4c0fd4e4634c5c90520c2c63b3f6286/687474703a2f2f7778322e73696e61696d672e636e2f6d773639302f30303633304465666c7931673563683072327034386a3330387a30616c6d79342e6a7067"><img src="https://camo.githubusercontent.com/6b3d0a2120d546206dbf7ae0e114fe52d4c0fd4e4634c5c90520c2c63b3f6286/687474703a2f2f7778322e73696e61696d672e636e2f6d773639302f30303633304465666c7931673563683072327034386a3330387a30616c6d79342e6a7067" alt="img"></a></p>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%885%EF%BC%89SVM*/</url>
    <content><![CDATA[<h2 id="支持向量机-SVM"><a href="#支持向量机-SVM" class="headerlink" title="支持向量机 SVM"></a>支持向量机 SVM</h2><p><strong>以几何的角度，在丰富的数据理论的基础上，简化了通常的分类和回归问题。</strong></p>
<h2 id><a href="#" class="headerlink" title></a><img src="https://pic1.zhimg.com/v2-e833772fe2044ad9c353fb0173bd0b79_1440w.jpg?source=172ae18b" alt="【机器学习】支持向量机 SVM（非常详细）" style="zoom:51%;"></h2><p>SVM 是一个非常优雅的算法，具有完善的数学理论，虽然如今工业界用到的不多，但还是决定花点时间去写篇文章整理一下。</p>
<h2 id="1-支持向量"><a href="#1-支持向量" class="headerlink" title="1. 支持向量"></a>1. 支持向量</h2><blockquote>
<p>  <strong>本质：SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</strong>为了对数据中的噪声有一定的容忍能力。</p>
<p>  <strong>几何意义</strong>：找到一个超平面将特征空间的正负样本分开，最大分隔（对噪音有一定的容忍能力）</p>
<p>  <strong>间隔表示</strong>：划分超平面到属于不同标记的最近样本的距离之和</p>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/52168498">https://zhuanlan.zhihu.com/p/52168498</a></p>
<p><strong>KKT条件</strong>：<strong>判断不等式约束问题是否为最优解的必要条件</strong></p>
</li>
</ul>
</blockquote>
<h3 id="1-1-线性可分"><a href="#1-1-线性可分" class="headerlink" title="1.1 线性可分"></a>1.1 线性可分</h3><p>首先我们先来了解下什么是线性可分。</p>
<p><img src="https://pic4.zhimg.com/80/v2-a75409cca671ad0819cd28ff9f40a01b_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>在二维空间上，两类点被一条直线完全分开叫做线性可分。</p>
<p>严格的数学定义是：</p>
<p><img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 是 n 维欧氏空间中的两个点集。如果存在 n 维向量 w 和实数 b，使得所有属于 <img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 的点 <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 都有 <img src="https://www.zhihu.com/equation?tex=wx_i+%2B+b+%3E+0" alt="[公式]"> ，而对于所有属于 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 的点 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 则有 <img src="https://www.zhihu.com/equation?tex=wx_j+%2B+b+%3C+0" alt="[公式]"> ，则我们称 <img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 线性可分。</p>
<h3 id="1-2-最大间隔超平面"><a href="#1-2-最大间隔超平面" class="headerlink" title="1.2 最大间隔超平面"></a>1.2 最大间隔超平面</h3><p>从二维扩展到多维空间中时，将 <img src="https://www.zhihu.com/equation?tex=D_0" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 完全正确地划分开的 <img src="https://www.zhihu.com/equation?tex=wx%2Bb%3D0" alt="[公式]"> 就成了一个超平面。</p>
<p>为了使这个超平面更具鲁棒性，我们会去找最佳超平面，以最大间隔把两类样本分开的超平面，也称之为最大间隔超平面。</p>
<ul>
<li>两类样本分别分割在该超平面的两侧；</li>
<li><strong>两侧距离超平面最近的样本点到超平面的距离被最大化了。</strong>【附近点】</li>
</ul>
<h3 id="1-3-支持向量-【距离超平面最近的点】"><a href="#1-3-支持向量-【距离超平面最近的点】" class="headerlink" title="1.3 支持向量 【距离超平面最近的点】"></a>1.3 支持向量 【距离超平面最近的点】</h3><p><img src="https://pic4.zhimg.com/80/v2-0f1ccaf844905148b7e75cab0d0ee2e3_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>样本中距离超平面最近的一些点，这些点叫做支持向量。</p>
<h3 id="1-4-SVM-最优化问题"><a href="#1-4-SVM-最优化问题" class="headerlink" title="1.4 SVM 最优化问题"></a>1.4 SVM 最优化问题</h3><p><strong>==SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面==</strong>。任意超平面可以用下面这个线性方程来描述：</p>
<p>​                                 <img src="https://www.zhihu.com/equation?tex=w%5ETx%2Bb%3D0+%5C%5C" alt="[公式]"></p>
<p>二维空间点 <img src="https://www.zhihu.com/equation?tex=%28x%2Cy%29" alt="[公式]"> 到直线 <img src="https://www.zhihu.com/equation?tex=Ax%2BBy%2BC%3D0" alt="[公式]"> 的距离公式是：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7CAx%2BBy%2BC%7C%7D%7B%5Csqrt%7BA%5E2%2BB%5E2%7D%7D+%5C%5C" alt="[公式]"></p>
<p><strong>扩展到 n 维空间后，点 <img src="https://www.zhihu.com/equation?tex=x%3D%28x_1%2Cx_2%E2%80%A6x_n%29" alt="[公式]"> 到直线 <img src="https://www.zhihu.com/equation?tex=w%5ETx%2Bb%3D0" alt="[公式]"> 的距离为</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B%7Cw%5ETx%2Bb%7C%7D%7B%7C%7Cw%7C%7C%7D+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%7C%7Cw%7C%7C%3D%5Csqrt%7Bw_1%5E2%2B%E2%80%A6w_n%5E2%7D" alt="[公式]"> 。</p>
<p>如图所示，根据支持向量的定义我们知道，支持向量到超平面的距离为 d，其他点到超平面的距离大于 d。</p>
<p><img src="https://pic4.zhimg.com/80/v2-1510522df255bd2987bf9ce8541f45af_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>于是我们有这样的一个公式：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+%5Cbegin%7Baligned%7D+%5Cfrac%7Bw%5ETx%2Bb%7D%7B%7C%7Cw%7C%7C%7D+%26%5Cgeq+d+%5Cquad++y%3D1+%5C%5C+%5Cfrac%7Bw%5ETx%2Bb%7D%7B%7C%7Cw%7C%7C%7D+%26%5Cleq+-d++%5Cquad+y%3D-1++%5Cend%7Baligned%7D+%5Cright.+%5C%5C" alt="[公式]"></p>
<p>将两个方程合并，我们可以简写为：</p>
<p><img src="https://www.zhihu.com/equation?tex=y%28w%5ETx%2Bb%29+%5Cgeq+1+%5C%5C" alt="[公式]"></p>
<p>至此我们就可以得到最大间隔超平面的上下两个超平面：</p>
<p><img src="image-20220409203050568.png" alt="image-20220409203050568" style="zoom:50%;"></p>
<p><strong>间隔</strong>：<strong>训练集中离划分超平面最近的样本到划分超平面距离的两倍</strong>。有了间隔的定义，划分超平面“离正负样本都比较远”这一目标可以等价描述为正负样本里划分超平面的距离尽可能远。即<strong>让离划分超平面最近的样本到划分超平面距离尽可能远</strong>。==优化目标==：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\max _{\boldsymbol{w}, b} \gamma &=\max _{\boldsymbol{w}, b}\left(2 \min _{i} \frac{1}{\|\boldsymbol{w}\|}\left|\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right|\right) \\
&=\max _{\boldsymbol{w}, b} \min _{i} \frac{2}{\|\boldsymbol{w}\|}\left|\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right|
\end{aligned}</script><p><strong>简化过程</strong>：</p>
<ul>
<li><p><strong>缩放</strong>：为了简化优化问题, 我们可以通过调整 $(\boldsymbol{w}, b)$ 使得：</p>
<script type="math/tex; mode=display">
\min _{i}\left|\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right|=1 .</script></li>
<li><p><strong>标签替换绝对值</strong>：</p>
<script type="math/tex; mode=display">
s.t. \min _{i} y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)=1</script></li>
<li><p><strong>简化约束条件</strong>【<strong>反正法</strong>】</p>
</li>
</ul>
<h4 id="硬间隔线性SVM的基本型："><a href="#硬间隔线性SVM的基本型：" class="headerlink" title=" 硬间隔线性SVM的基本型："></a><strong><font color="red"> 硬间隔线性SVM的基本型：</font></strong></h4><script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w} \\
\text { s.t. } & y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right) \geq 1, \quad i=1,2, \ldots, m
\end{array}</script><p><img src="image-20220423163130805.png" alt="image-20220423163130805" style="zoom:50%;"></p>
<p><strong>二次规划是指目标函数是==二次函数==，约束是==线性不等式约束==的一类优化问题</strong> + 凸函数</p>
<h2 id="2-硬间隔线性SVM对偶型"><a href="#2-硬间隔线性SVM对偶型" class="headerlink" title="2. 硬间隔线性SVM对偶型"></a>2. 硬间隔线性SVM对偶型</h2><blockquote>
<p>  本科高等数学学的<strong>拉格朗日程数法</strong>是<strong>等式约束优化问题</strong>：</p>
<p>  <img src="https://www.zhihu.com/equation?tex=%5Cmin+f%28x_%7B1%7D+%2Cx_%7B2%7D+%2C...%2Cx_%7Bn%7D+%29+%5C%5C+s.t.+%5Cquad+h_%7Bk%7D+%28x_%7B1%7D+%2Cx_%7B2%7D+%2C...%2Cx_%7Bn%7D+%29%3D0+%5Cquad+k+%3D1%2C2%2C...%2Cl%5C%5C" alt="[公式]"></p>
<p>  我们令 <img src="https://www.zhihu.com/equation?tex=L%28x%2C%5Clambda+%29+%3D+f%28x%29+%2B+%5Csum%5Climits_%7Bk+%3D+1%7D%5El+%5Clambda+_k+h_k+%28x%29" alt="[公式]"> ，函数 <img src="https://www.zhihu.com/equation?tex=L%28x%2Cy%29" alt="[公式]"> 称为 Lagrange 函数，参数 <img src="https://www.zhihu.com/equation?tex=%5Clambda" alt="[公式]"> 称为 Lagrange 乘子<strong>==没有非负要求。==</strong></p>
<p>  利用必要条件找到可能的极值点：</p>
<p>  <img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+%5Cbegin%7Baligned%7D++%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+x_i%7D+%3D+0+%5Cquad+i%3D1%2C2%2C...%2Cn+%5C%5C+%5Cfrac%7B%5Cpartial+L%7D%7B%5Cpartial+%5Clambda_k%7D+%3D+0+%5Cquad+k%3D1%2C2%2C...%2Cl++%5Cend%7Baligned%7D+%5Cright.+%5C%5C" alt="[公式]"></p>
<p>  具体是否为极值点需根据问题本身的具体情况检验。这个方程组称为等式约束的极值必要条件。</p>
<p>  等式约束下的 Lagrange 乘数法引入了 <img src="https://www.zhihu.com/equation?tex=l" alt="[公式]"> 个 Lagrange 乘子，我们将 <img src="https://www.zhihu.com/equation?tex=x_%7Bi%7D" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bk%7D" alt="[公式]"> 一视同仁，把 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bk%7D+" alt="[公式]"> 也看作优化变量，共有 <img src="https://www.zhihu.com/equation?tex=%28n%2Bl%29" alt="[公式]"> 个优化变量。</p>
</blockquote>
<h5 id="（1）写成约束优化问题的基本型"><a href="#（1）写成约束优化问题的基本型" class="headerlink" title="（1）写成约束优化问题的基本型"></a>（1）写成约束优化问题的基本型</h5><script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w} \\
\text { s.t. } & 1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right) \leq 0, \quad i=1,2, \ldots, m
\end{array}</script><h5 id="（2）-构建基本型的拉格朗日函数"><a href="#（2）-构建基本型的拉格朗日函数" class="headerlink" title="（2） 构建基本型的拉格朗日函数"></a>（2） 构建基本型的拉格朗日函数</h5><script type="math/tex; mode=display">
\mathcal{L}(\boldsymbol{w}, b, \boldsymbol{\alpha}):=\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right)</script><h5 id="（3）交换min-max顺序"><a href="#（3）交换min-max顺序" class="headerlink" title="（3）交换min, max顺序"></a>（3）交换min, max顺序</h5><blockquote>
<p>  ==<strong>解得最优解 $\boldsymbol{u}^{\star}$ 。这样两层优化问题将变为一层最大化（max）问题, 问题难度大大降低, 称为对偶问题 (Dual Problem) :</strong>==【<strong>对偶问题是原问题的下界</strong>】</p>
<ul>
<li><script type="math/tex; mode=display">
\max _{\boldsymbol{\alpha}, \boldsymbol{\beta}} \min _{\boldsymbol{u}} \mathcal{L}(\boldsymbol{u}, \boldsymbol{\alpha}, \boldsymbol{\beta}) \leq \min _{\boldsymbol{u}} \max _{\boldsymbol{\alpha}, \boldsymbol{\beta}} \mathcal{L}(\boldsymbol{u}, \boldsymbol{\alpha}, \boldsymbol{\beta})</script></li>
<li><p>硬间隔线性SVM满足<strong>Slater条件</strong>， <strong>因此原问题和对偶问题等价</strong></p>
</li>
</ul>
</blockquote>
<script type="math/tex; mode=display">
\begin{array}{cl}
\max _{\boldsymbol{\alpha}} \min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right) \\
\text { s.t. } & \alpha_{i} \geq 0, \quad i=1,2, \ldots, m .
\end{array}</script><p>首先计算 $\boldsymbol{w}$ 的最优值, 令 $\frac{\partial \mathcal{L}}{\partial \boldsymbol{w}}=\mathbf{0}$</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial \boldsymbol{w}} &=\frac{\partial}{\partial \boldsymbol{w}}\left(\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right)\right) \\
&=\boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(-y_{i} \boldsymbol{x}_{i}\right) \\
&=\boldsymbol{w}-\sum_{i=1}^{m} \alpha_{i} y_{i} \boldsymbol{x}_{i} \\
&=\mathbf{0}
\end{aligned}</script><p>==可以解得最优值==$\boldsymbol{w}$</p>
<script type="math/tex; mode=display">
\boldsymbol{w}^{\star}=\sum_{i=1}^{m} \alpha_{i} y_{i} \boldsymbol{x}_{i}</script><p>然后计算 $b$ 的最优值, 令 $\frac{\partial \mathcal{L}}{\partial b}=0$</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial b} &=\frac{\partial}{\partial b}\left(\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+\sum_{i=1}^{m} \alpha_{i}\left(1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right)\right)\right) \\
&=\sum_{i=1}^{m} \alpha_{i}\left(-y_{i}\right) \\
&=-\sum_{i=1}^{m} \alpha_{i} y_{i} \\
&=0
\end{aligned}</script><p>==可以得到一个等式== $b^{\star}$ </p>
<script type="math/tex; mode=display">
\sum_{i=1}^{m} \alpha_{i} y_{i}=0</script><p>注意到这里并没有给出最优值 $b^{\star}$ 应该是多少, 而是一个等式, 该等式是一个约束项, 而最优值通过后面的 <strong>KKT 条件</strong>的互补松弛可以计算得到。</p>
<h4 id="硬性间隔线性SVM的对偶型："><a href="#硬性间隔线性SVM的对偶型：" class="headerlink" title=" 硬性间隔线性SVM的对偶型："></a><strong><font color="red"> 硬性间隔线性SVM的对偶型：</font></strong></h4><script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{\alpha}} & \frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha_{i} \alpha_{j} y_{i} y_{j} \boldsymbol{x}_{i}^{\top} \boldsymbol{x}_{j}-\sum_{i=1}^{m} \alpha_{i} \\
\text { s.t. } & \alpha_{i} \geq 0, \quad i=1,2, \ldots, m \\
& \sum_{i=1}^{m} \alpha_{i} y_{i}=0
\end{array}</script><h5 id="（4）利用KKT条件得到主问题的最优解"><a href="#（4）利用KKT条件得到主问题的最优解" class="headerlink" title="==（4）利用KKT条件得到主问题的最优解=="></a>==（4）利用KKT条件得到主问题的最优解==</h5><p><strong>KKT 条件是指优化问题在最优处（包括基本型的最优值，对偶问题的最优值）必须满足的条件</strong>。</p>
<p>线性支持向量机的 <strong>KKT 条件</strong>:</p>
<ul>
<li><strong>主问题可行</strong>: $g_{i}\left(\boldsymbol{u}^{\star}\right)=1-y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right) \leq 0$ ；</li>
<li><strong>对偶问题可行</strong>: $\alpha_{i}^{\star} \geq 0$;</li>
<li><strong>主变量最优</strong>: $\boldsymbol{w}^{\star}=\sum_{i=1}^{m} \alpha_{i} y_{i} \boldsymbol{x}_{i}, \sum_{i=1}^{m} \alpha_{i} y_{i}=0$;</li>
<li><strong><font color="red"> 互补松弛: $\alpha_{i}^{\star} g_{i}\left(\boldsymbol{u}^{\star}\right)=\alpha_{i}^{\star}\left(1-y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right)\right)=0$ ；</font></strong></li>
</ul>
<p><strong>根据 KKT 条件中的 $\alpha_{i}^{\star} \geq 0$, 我们可以根据 $\alpha_{i}^{\star}$ 的取值将训练集 $D$ 中所有的样本分成两类</strong>, 如 图 17 所示。</p>
<ul>
<li>如果 $\alpha_{i}^{\star}&gt;0$, <strong>对应的样本称为支持向量 (Support Vector)</strong>, 根据 $\alpha_{i}^{\star}\left(1-y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right)\right)=0$ , 那么一定有 $y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right)=1$, 该样本是距离划分超平面最近的样本, 位于最大间隔边界 （见第 $2.3$ 节）;</li>
<li>如果 $\alpha_{i}^{\star}=0$, 对应的样本不是非支持向量, 那么有 $y_{i}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}_{i}+b^{\star}\right) \geq 1$, 该样本不一定是距离 划分超平面最近的样本, <strong>位于最大间隔边界或之外</strong>。</li>
</ul>
<p><img src="image-20220409212350705.png" alt="image-20220409212350705" style="zoom:50%;"></p>
<p><strong>结论</strong>：</p>
<ul>
<li><strong><font color="red"> 参数 w， b 仅由支持向量决定，与训练集的其他样本无关；</font></strong></li>
<li><strong><font color="red"> 对偶性是非参数模型，预测阶段不仅需要$\alpha_{i}$参数，还支持向量；</font></strong></li>
</ul>
<script type="math/tex; mode=display">
\begin{aligned}
&h(\boldsymbol{x}):=\operatorname{sign}\left(\boldsymbol{w}^{\star \top} \boldsymbol{x}+b^{\star}\right) \quad \text { （硬间隔线性 SVM 的基本型的假设函数） }\\
&=\operatorname{sign}\left(\sum_{i \in S V} \alpha_{i}^{\star} y_{i} \boldsymbol{x}_{i}^{\top} \boldsymbol{x}+b^{\star}\right) \text {.(硬间隔线性 SVM 的对偶型的假设函数） }
\end{aligned}</script><h3 id="3、SVM优化方法"><a href="#3、SVM优化方法" class="headerlink" title="3、SVM优化方法"></a>3、SVM优化方法</h3><h5 id="SMO算法求解"><a href="#SMO算法求解" class="headerlink" title="==SMO算法求解=="></a>==SMO算法求解==</h5><p>我们可以看出来这是一个<strong>二次规划问题</strong>，问题规模正比于训练样本数，我们常用 SMO(Sequential Minimal Optimization) 算法求解。</p>
<p><strong>==SMO(Sequential Minimal Optimization)，序列最小优化算法【基于坐标下降算法】，其核心思想非常简单：每次只优化一个参数，其他参数先固定住，仅求当前这个优化参数的极值。我们来看一下 SMO 算法在 SVM 中的应用。==</strong></p>
<p>我们刚说了 SMO 算法每次只优化一个参数，但我们的优化目标有约束条件： <img src="https://www.zhihu.com/equation?tex=%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bn%7D%5Clambda_iy_i+%3D+0" alt="[公式]"> ，没法一次只变动一个参数。所以我们选择了一次选择两个参数。具体步骤为：</p>
<ol>
<li>选择两个需要更新的参数 <img src="https://www.zhihu.com/equation?tex=%5Clambda_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Clambda_j" alt="[公式]"> ，固定其他参数。于是我们有以下约束：</li>
</ol>
<p>这样约束就变成了：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Clambda_i+y_i%2B%5Clambda_j+y_j+%3D+c+%5Cquad+%5Clambda_i+%5Cgeq+0%2C%5Clambda_j+%5Cgeq+0+%5C%5C" alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=c%3D-%5Csum%5Climits_%7Bk+%5Cne+i%2Cj%7D%5Clambda_ky_k" alt="[公式]"> ，由此可以得出 <img src="https://www.zhihu.com/equation?tex=%5Clambda_j%3D%5Cfrac%7Bc-%5Clambda_iy_i%7D%7By_j%7D" alt="[公式]"> ，也就是说我们可以用 <img src="https://www.zhihu.com/equation?tex=%5Clambda_i" alt="[公式]"> 的表达式代替 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bj%7D" alt="[公式]"> 。这样就相当于把目标问题转化成了仅有一个约束条件的最优化问题，仅有的约束是 <img src="https://www.zhihu.com/equation?tex=%5Clambda_i+%5Cgeq+0" alt="[公式]"> 。</p>
<ol>
<li><p>对于仅有一个约束条件的最优化问题，我们完全可以在 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi%7D" alt="[公式]"> 上对优化目标求偏导，令导数为零，从而求出变量值 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi_%7Bnew%7D%7D" alt="[公式]"> ，然后根据 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi_%7Bnew%7D%7D" alt="[公式]"> 求出 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bj_%7Bnew%7D%7D" alt="[公式]"> 。</p>
</li>
<li><p>多次迭代直至收敛。</p>
</li>
</ol>
<p>通过 SMO 求得最优解 <img src="https://www.zhihu.com/equation?tex=%5Clambda%5E%2A" alt="[公式]"> 。</p>
<h3 id="4-软间隔线性SVM"><a href="#4-软间隔线性SVM" class="headerlink" title="4. 软间隔线性SVM"></a>4. 软间隔线性SVM</h3><p>在实际应用中，完全线性可分的样本是很少的，如果遇到了不能够完全线性可分的样本，我们应该怎么办？比如下面这个：</p>
<p><img src="https://pic1.zhimg.com/80/v2-ec8ef880d21fe3479e6bcdcd16d7e050_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p>于是我们就有了软间隔，相比于硬间隔的苛刻条件，我们允许个别样本点出现在间隔带里面，比如：</p>
<p><img src="https://pic3.zhimg.com/80/v2-834c7a5f310e187b448831676b7eeeee_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p>我们允许部分样本点不满足约束条件：</p>
<p><img src="https://www.zhihu.com/equation?tex=1-y_i%28w%5ETx_i+%2B+b%29+%5Cleq+0+%5C%5C" alt="[公式]"></p>
<p>为了度量这个间隔软到何种程度，我们为每个样本引入一个松弛变量 <img src="https://www.zhihu.com/equation?tex=%5Cxi_%7Bi%7D" alt="[公式]"> ，令 <img src="https://www.zhihu.com/equation?tex=%5Cxi_%7Bi%7D+%5Cgeq+0" alt="[公式]"> ，且 <img src="https://www.zhihu.com/equation?tex=1+-+y_i%28w%5ETx_i+%2B+b%29-%5Cxi_i+%5Cleq+0" alt="[公式]"> 。对应如下图所示：</p>
<p><img src="https://pic1.zhimg.com/80/v2-8e3d96fd9f9cad298628c7e2c4c8a8b8_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p><strong>这边要注意一个问题，在间隔内的那部分样本点是不是支持向量？</strong></p>
<p>我们可以由求参数 w 的那个式子可看出，只要 <img src="https://www.zhihu.com/equation?tex=%5Clambda_%7Bi%7D+%3E+0" alt="[公式]"> 的点都能够影响我们的超平面，因此都是支持向量。</p>
<p><strong>==硬间隔线性SVM的基本型：==</strong>【凸二次规划问题， 具有全局最小值】</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w} \\
\text { s.t. } & y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{x}_{i}+b\right) \geq 1, \quad i=1,2, \ldots, m
\end{array}</script><p>约束中要求所有的样本都满足 $y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1$, 也就是让所有的样本都满足 $y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right)&gt;0$。<br>现在我们想对<strong>该约束进行一点放松</strong>, 我们希望在优化间隔的同时, 允许分类错误的样本出现, 但这类样本应尽可能少:</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\min _{\boldsymbol{w}, b} & \frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}+C \sum_{i=1}^{m} \mathbb{I}\left(y_{i} \neq \operatorname{sign}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right)\right) \\
\text { s.t. } & y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1, \quad \text { 若 } y_{i}=\operatorname{sign}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) .
\end{array}</script><p>其中, 优化目标的第一项 $\frac{1}{2} \boldsymbol{w}^{\top} \boldsymbol{w}$ 源自硬间隔核化 SVM 的基本型, 即优化间隔。优化目标的第二项 中的 $\mathbb{I}(\cdot)$ 是指示函数, 函数的参数通常是一个条件, 如果条件为真（True）, 则指示函数值为 1 ; 如果条件为假 (False), 则指示函数值为 0 。<br>$\sum_{i=1}^{m} \mathbb{I}\left(y_{i} \neq \operatorname{sign}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right)\right)$ 的含义是统计训练集 $D$ 中所有<strong>预测错误的样本总数</strong>。因此, 公式 162 的目标函数是同时优化间隔和最小化训练集预测错误的样本总数, <strong>==$C$ 是个可调节的超参数, 用于权衡优化间隔和出现少量分类错误的样本这两个目标。==</strong></p>
<p>但是, 由于<strong>==指示函数 $I(\cdot)$ 不是连续函数, 更不是凸函数, 使得优化问题不再是二次规划问题==</strong>, 求解起来十分困难, 所以我们需要对其进行简化。另外<strong>==指示函数没有区分预测错误的不同程度==</strong>,因此, 我们<strong>引入松他变量</strong> (Slack Variable) $\xi_{i} \in \mathbb{R}$, 用于<strong>度量训练集 $D$ 中第 $i$ 个样本违背约束的程度</strong>。当第 $i$ 个样本<strong>==违背约束的程度==</strong>越大, 松弛变量 $\xi_{i}$ 的值越大</p>
<script type="math/tex; mode=display">
\xi_{i}:= \begin{cases}0 & \text { 若 } y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1 ; \\ 1-y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) & \text { 否则. }\end{cases}</script><p>基于以上定义, 松弛变量 $\xi_{i}$ 的取值有以下四种情况, 如图 27 所示, 注意图 27 只是示意图, 用于理 解概念, 不表示用图中数据训练得到的分类边界一定是这样:</p>
<ul>
<li>当 $\xi_{i}=0$ 时, 训练集 $D$ 中第 $i$ 个样本分类正确 $h\left(\boldsymbol{x}_{i}\right)=y_{i}$, 且满足大间隔约束 $y_{i}\left(\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b\right) \geq 1$;</li>
<li>当 $0&lt;\xi_{i}&lt;1$ 时, 训练集 $D$ 中第 $i$ 个样本分类正确 $h\left(\boldsymbol{x}_{i}\right)=y_{i}$, 但是不满足大间隔约束;</li>
<li>当 $\xi_{i}=1$ 时, 训练集 $D$ 中第 $i$ 个样本恰好位于划分超平面 $\boldsymbol{w}^{\top} \boldsymbol{\phi}\left(\boldsymbol{x}_{i}\right)+b=0$ 上, 且不满足大间 隔约束;</li>
<li>当 $\xi&gt;0$ 时, 训练集 $D$ 中第 $i$ 个样本分类错误 $h\left(\boldsymbol{x}_{i}\right) \neq y_{i}$, 且不满足大间隔约束。</li>
</ul>
<p><img src="image-20220409230106609.png" alt="image-20220409230106609" style="zoom:50%;"></p>
<h4 id="软间隔核化SVM基本型-：（-合页损失函数-）"><a href="#软间隔核化SVM基本型-：（-合页损失函数-）" class="headerlink" title="==软间隔核化SVM基本型==：（==合页损失函数==）"></a><strong>==软间隔核化SVM基本型==：</strong>（<strong>==合页损失函数==</strong>）</h4><p><img src="image-20220401163522598.png" alt="image-20220401163522598" style="zoom:50%;"></p>
<p><img src="image-20220401164527480.png" alt="image-20220401164527480" style="zoom:50%;"></p>
<p><strong>变为：</strong></p>
<p><img src="image-20220401164354384.png" alt="image-20220401164354384" style="zoom:50%;"></p>
<p>令<img src="image-20220401164559373.png" alt="image-20220401164559373" style="zoom:50%;">：<strong>==合页损失==</strong></p>
<p><img src="image-20220401164608500.png" alt="image-20220401164608500" style="zoom:50%;"></p>
<blockquote>
<h5 id="回顾：对数几率回归："><a href="#回顾：对数几率回归：" class="headerlink" title="回顾：对数几率回归："></a>回顾：对数几率回归：</h5><p>  <img src="image-20220401164913393.png" alt="image-20220401164913393" style="zoom:50%;"></p>
</blockquote>
<p>==<strong>软间隔核化SVM对偶性：</strong>== <strong>软间隔的对偶性是在硬间隔的对偶性对拉格朗日参数添加一个上界</strong>。</p>
<p><img src="image-20220401161707141.png" alt="image-20220401161707141" style="zoom:50%;"></p>
<h3 id="5-核函数【对偶性】"><a href="#5-核函数【对偶性】" class="headerlink" title="5. 核函数【对偶性】"></a>5. 核函数【对偶性】</h3><h4 id="5-1-线性不可分"><a href="#5-1-线性不可分" class="headerlink" title="5.1 线性不可分"></a>5.1 线性不可分</h4><blockquote>
<p>  <strong>==对于在有限维度向量空间中线性不可分的样本，我们将其映射到更高维度的向量空间里，再通过间隔最大化的方式，学习得到支持向量机，就是非线性 SVM。==</strong></p>
</blockquote>
<p>我们刚刚讨论的<strong>硬间隔</strong>和<strong>软间隔</strong>都是在说样本的完全线性可分或者大部分样本点的线性可分。</p>
<p>但我们可能会碰到的一种情况是样本点不是线性可分的，比如：</p>
<p><img src="https://pic1.zhimg.com/80/v2-a17603302d58b3747118084aa25fe758_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>这种情况的解决方法就是：将<strong>==二维线性不可分样本映射到高维空间中，让样本点在高维空间线性可分==</strong>，比如：</p>
<p><img src="https://pic1.zhimg.com/80/v2-9758d49e634c15a3e684ab84bad913ec_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p>对于在有限维度向量空间中线性不可分的样本，我们将其映射到更高维度的向量空间里，再通过间隔最大化的方式，学习得到支持向量机，就是非线性 SVM。</p>
<p>我们用 x 表示原来的样本点，用 <img src="https://www.zhihu.com/equation?tex=%5Cphi%28x%29" alt="[公式]"> 表示 x 映射到特征新的特征空间后到新向量。那么分割超平面可以表示为： <img src="https://www.zhihu.com/equation?tex=f%28x%29%3Dw+%5Cphi%28x%29%2Bb" alt="[公式]"> 。</p>
<p>对于非线性 SVM 的对偶问题就变成了：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cmin%5Climits_%7B%5Clambda%7D+%5B%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%5Clambda_i+%5Clambda_j+y_i+y_j+%28%5Cphi%28x_i%29+%5Ccdot+%5Cphi%28x_j%29%29-%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%5Clambda_i%5D+%5C%5C+s.t.++%5Cquad+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Clambda_iy_i+%3D+0%2C+%5Cquad+%5Clambda_i+%5Cgeq+0%2C+%5Cquad+C-%5Clambda_i-%5Cmu_i%3D0+%5C%5C" alt="[公式]"></p>
<p>可以看到与线性 SVM 唯一的不同就是：之前的 <img src="https://www.zhihu.com/equation?tex=%28x_i+%5Ccdot+x_j%29" alt="[公式]"> 变成了 <img src="https://www.zhihu.com/equation?tex=%28%5Cphi%28x_i%29+%5Ccdot+%5Cphi%28x_j%29%29" alt="[公式]"> 。</p>
<h3 id="5-2-核函数的作用"><a href="#5-2-核函数的作用" class="headerlink" title="5.2 核函数的作用"></a>5.2 核函数的作用</h3><p>我们不禁有个疑问：只是做个内积运算，为什么要有核函数的呢？</p>
<p>这是因为<strong>低维空间映射到高维空间后维度可能会很大，如果将全部样本的点乘全部计算好，这样的计算量太大</strong>了。</p>
<p>但如果我们有这样的一==核函数== <img src="https://www.zhihu.com/equation?tex=k%28x%2Cy%29+%3D+%28%5Cphi%28x%29%2C%5Cphi%28y%29%29" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=x_i" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=x_j" alt="[公式]"> 在特征空间的内积等于它们在原始样本空间中通过函数 <img src="https://www.zhihu.com/equation?tex=k%28+x%2C+y%29" alt="[公式]"> 计算的结果，我们就不需要计算高维甚至无穷维空间的内积了。</p>
<p>举个例子：假设我们有一个<strong>==多项式核函数==</strong>：</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x%2Cy%29%3D%28x+%5Ccdot+y+%2B+1%29%5E2+%5C%5C" alt="[公式]"></p>
<p>带进样本点的后：</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x%2Cy%29+%3D+%28%5Csum_%7Bi%3D1%7D%5En%28x_i+%5Ccdot+y_i%29+%2B+1%29%5E2+%5C%5C" alt="[公式]"></p>
<p>而它的展开项是：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi%3D1%7D%5Enx_i%5E2y_i%5E2%2B%5Csum_%7Bi%3D2%7D%5En%5Csum_%7Bj%3D1%7D%5E%7Bi-1%7D%28%5Csqrt2x_ix_j%29%28%5Csqrt2y_iy_j%29%2B%5Csum_%7Bi%3D1%7D%7Bn%7D%28%5Csqrt2x_i%29%28%5Csqrt2y_i%29%2B1+%5C%5C" alt="[公式]"></p>
<p>如果没有核函数，我们则需要把向量映射成：</p>
<p><img src="https://www.zhihu.com/equation?tex=x%5E%7B%27%7D+%3D+%28x_1%5E2%2C...%2Cx_n%5E2%2C...%5Csqrt2x_1%2C...%2C%5Csqrt2x_n%2C1%29+%5C%5C" alt="[公式]"></p>
<p>然后在进行内积计算，才能与多项式核函数达到相同的效果。</p>
<p>可见核函数的引入一方面减少了我们计算量，另一方面也减少了我们存储数据的内存使用量。</p>
<h3 id="5-3-常见核函数"><a href="#5-3-常见核函数" class="headerlink" title="5.3 常见核函数"></a>5.3 常见核函数</h3><p>我们常用核函数有：</p>
<p><strong>线性核函数</strong>【无映射】</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x_i%2Cx_j%29+%3D+x_i%5ETx_j+%5C%5C" alt="[公式]"></p>
<ul>
<li>优点：有加速算法库、没有特征映射、过拟合风险低</li>
<li>缺点：只能处理线性</li>
</ul>
<p><strong>多项式核函数</strong>【映射，超参数】</p>
<p><img src="https://www.zhihu.com/equation?tex=+k%28x_i%2Cx_j%29+%3D+%28x_i%5ETx_j%29%5Ed%5C%5C" alt="[公式]"></p>
<p><strong>高斯核函数</strong>【映射，超参数】</p>
<p><img src="https://www.zhihu.com/equation?tex=k%28x_i%2Cx_j%29+%3D+exp%28-%5Cfrac%7B%7C%7Cx_i-x_j%7C%7C%7D%7B2%5Cdelta%5E2%7D%29+%5C%5C" alt="[公式]"></p>
<ul>
<li><strong>表示能力强，但容易过拟合</strong></li>
<li><strong>高斯核没有多项核不稳定的问题</strong></li>
<li><strong>只有一个超参数</strong></li>
</ul>
<h3 id="5-4-如何选择核函数？"><a href="#5-4-如何选择核函数？" class="headerlink" title="==5.4 如何选择核函数？=="></a>==5.4 <strong>如何选择核函数？</strong>==</h3><blockquote>
<p>  <strong>其他核函数：拉普拉斯、sigmod、卡方、直方图交叉</strong></p>
<p>  可自定义和组合核函数</p>
</blockquote>
<ul>
<li>如果特征的数量大到和样本数量差不多，则选用LR或者线性核的SVM；</li>
<li>如果特征的数量小，样本的数量正常，则选用SVM+高斯核函数；</li>
<li>如果特征的数量小，而样本的数量很大，则需要手工添加一些特征从而变成第一种情况。</li>
</ul>
<p><img src="image-20220331203905843.png" alt="image-20220331203905843" style="zoom:50%;"></p>
<h3 id="5-5-核方法"><a href="#5-5-核方法" class="headerlink" title="5.5 核方法"></a>5.5 核方法</h3><h4 id="核化LR-非线性"><a href="#核化LR-非线性" class="headerlink" title="核化LR [非线性]"></a>核化LR [非线性]</h4><p>正类: y = +1 负类 y= -1</p>
<p><img src="image-20220331205845613.png" alt="image-20220331205845613" style="zoom:50%;"></p>
<p><img src="image-20220331211740625.png" alt="image-20220331211740625" style="zoom:50%;"></p>
<p><img src="image-20220331211757367.png" alt="image-20220331211757367" style="zoom:50%;"></p>
<p><strong>梯度下降求解：</strong></p>
<p>核化LR的参数通常都非0，并且几乎用到所有训练的样本，预测效率比较低。</p>
<p><img src="image-20220331212433609.png" alt="image-20220331212433609" style="zoom:50%;"></p>
<h3 id="5-6-支持向量回归-SVR-？核化岭回归？"><a href="#5-6-支持向量回归-SVR-？核化岭回归？" class="headerlink" title="5.6 支持向量回归 SVR = ？核化岭回归？"></a>5.6 支持向量回归 SVR = ？核化岭回归？</h3><blockquote>
<p>  <a href="https://blog.csdn.net/ch18328071580/article/details/94168411">https://blog.csdn.net/ch18328071580/article/details/94168411</a></p>
<p>  <strong>支持向量在隔代之外</strong></p>
</blockquote>
<h4 id="SVR与一般线性回归的区别"><a href="#SVR与一般线性回归的区别" class="headerlink" title="SVR与一般线性回归的区别"></a>SVR与一般线性回归的区别</h4><div class="table-container">
<table>
<thead>
<tr>
<th>SVR</th>
<th>线性回归</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据在间隔带内则不计算损失，<strong>当且仅当f(x)与y之间的差距的绝对值大于ϵ才计算损失</strong></td>
<td>只要f(x)与y不相等时，就计算损失</td>
</tr>
<tr>
<td><strong>通过最大化间隔带的宽度与最小化总损失</strong>来优化模型</td>
<td>通过梯度下降之后求均值来优化模型</td>
</tr>
</tbody>
</table>
</div>
<p><strong>岭回归：</strong><img src="image-20220401144206172.png" alt="image-20220401144206172" style="zoom:50%;"></p>
<h5 id="支持向量回归：-我们假设f-x-与y之间最多有一定的偏差，大于偏差才计数损失"><a href="#支持向量回归：-我们假设f-x-与y之间最多有一定的偏差，大于偏差才计数损失" class="headerlink" title="支持向量回归：==我们假设f(x)与y之间最多有一定的偏差，大于偏差才计数损失=="></a>支持向量回归：==我们假设f(x)与y之间最多有一定的偏差，大于偏差才计数损失==</h5><script type="math/tex; mode=display">
\min _{w, b} \frac{1}{2}\|w\|^{2}+C \sum_{i=1}^{m} l_{\epsilon}\left(f\left(x_{i}\right), y_{i}\right)</script><p>其中C为正则化常数, $l_{\epsilon}$ 是图中所示的 $\epsilon$-不敏感损失 ( $\epsilon$-insensitive loss)函数:</p>
<script type="math/tex; mode=display">
l_{\epsilon}(\mathrm{z})= \begin{cases}0, & \text { if }|z| \leq \epsilon \\ |z|-\epsilon, & \text { otherwise }\end{cases}</script><p>引入松弛变量 $\xi_{i}$ 和 $\left(\xi_{i}\right)$, 可将式重写为:</p>
<script type="math/tex; mode=display">
\begin{array}{ll}
\min _{w, b, \xi_{i}, \xi_{i}} & \frac{1}{2}\|w\|^{2}+C \sum_{i=1}^{m}\left(\xi_{i}, \widehat{\xi}_{i}\right) \\
\text { s.t. } & f\left(x_{i}\right)-y_{i} \leq \epsilon+\xi_{i} \\
& y_{i}-f\left(x_{i}\right) \leq \epsilon+\widehat{\xi}_{i} \\
& \xi_{i} \geq 0, \hat{\xi}_{i} \geq 0, i=1,2, \ldots m
\end{array}</script><p>引入拉格朗日乘子 $\mu_{i}$,</p>
<p>$L(w, b, \alpha, \hat{\alpha}, \xi, \hat{\xi}, \mu, \hat{\mu})$<br>$=\frac{1}{2}|w|^{2}+C \sum_{i=1}^{m}\left(\xi_{i}+\widehat{\xi}_{i}\right)-\sum_{i=1}^{m} \xi_{i} \mu_{i}-\sum_{i=1}^{m} \widehat{\xi}_{i} \widehat{\mu_{i}}$<br>$+\sum_{i=1}^{m} \alpha_{i}\left(f\left(x_{i}\right)-y_{i}-\epsilon-\xi_{i}\right)+\sum_{i=1}^{m} \widehat{\alpha_{i}}\left(y_{i}-f\left(x_{i}\right)-\epsilon-\widehat{\xi}_{i}\right)$</p>
<p>再令 $L(w, b, a, \hat{a}, \xi, \hat{\xi}, \mu, \mu)$ 对 $w, b, \xi_{i}, \hat{\xi}_{i}$ 的偏导为零可得:</p>
<script type="math/tex; mode=display">
w=\sum_{i=1}^{m}\left(\widehat{\alpha_{i}}-\alpha_{i}\right) x_{i}</script><p>上述过程中需满足KKT条件, 即要求:</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{c}
\alpha_{i}\left(f\left(x_{i}\right)-y_{i}-\epsilon-\xi_{i}\right)=0 \\
\widehat{\alpha_{i}}\left(y_{i}-f\left(x_{i}\right)-\epsilon-\widehat{\xi}_{i}\right)=0 \\
\alpha_{i} \widehat{\alpha_{i}}=0, \xi_{i} \widehat{\xi}_{i}=0 \\
\left(C-\alpha_{i}\right) \xi_{i}=0,\left(C-\widehat{\alpha_{i}}\right) \widehat{\xi}_{i}=0 .
\end{array}\right.</script><h3 id="5-7-多分类-SVM"><a href="#5-7-多分类-SVM" class="headerlink" title="5.7 多分类 SVM"></a>5.7 多分类 SVM</h3><h4 id="5-7-1-多分类问题"><a href="#5-7-1-多分类问题" class="headerlink" title="5.7.1 多分类问题"></a>5.7.1 多分类问题</h4><ul>
<li>多分类问题拆解成若干个二分类问题，对于每个二分类训练一个分类器。<ul>
<li><strong>one vs one 拆解</strong>：K(K-1)/2 个分类器。</li>
<li><strong>one vs Rest 拆解</strong>：K个分类器</li>
</ul>
</li>
</ul>
<p><img src="image-20220401192909167.png" alt="image-20220401192909167" style="zoom:50%;"></p>
<ul>
<li><p><strong>根据模型特点设计：多分类线性SVM</strong></p>
<ul>
<li><p><strong>层次支持向量机</strong></p>
</li>
<li><p><strong>回顾二分类</strong>；</p>
<p><img src="image-20220401193645250.png" alt="image-20220401193645250" style="zoom:50%;"></p>
</li>
<li><p><strong>多分类线性SVM</strong>：</p>
<p><img src="image-20220401194059380.png" alt="image-20220401194059380" style="zoom:50%;"></p>
</li>
</ul>
</li>
</ul>
<h2 id="6-优缺点"><a href="#6-优缺点" class="headerlink" title="6. 优缺点"></a>6. 优缺点</h2><h3 id="6-1-优点"><a href="#6-1-优点" class="headerlink" title="6.1 优点"></a>6.1 优点</h3><ul>
<li>有严格的<strong>==数学理论支持==</strong>，<strong>==可解释性强==</strong>，<strong>==不依靠统计方法==</strong>，从而<strong>简化了通常的分类和回归问题</strong>；</li>
<li>能找出对任务至关重要的<strong>==关键样本==</strong>（即：<strong>支持向量</strong>）；</li>
<li>采用<strong>==核技巧==</strong>之后，<strong>==可以处理非线性分类/回归任务==</strong>；</li>
<li><strong>==最终决策函数只由少数的支持向量所确定，计算的复杂性取决于支持向量的数目，而不是样本空间的维数，这在某种意义上避免了“维数灾难”。==</strong></li>
</ul>
<h3 id="6-2-缺点"><a href="#6-2-缺点" class="headerlink" title="6.2 缺点"></a>6.2 缺点</h3><ul>
<li><strong>训练时间长</strong>：当采用 SMO 算法时，由于每次都需要挑选一对参数，因此时间复杂度为 <img src="https://www.zhihu.com/equation?tex=O%28N%5E2%29" alt="[公式]"> ，其中 N 为训练样本的数量；</li>
<li><strong>存储空间大</strong>：当采用核技巧时，如果需要存储核矩阵，则空间复杂度为 <img src="https://www.zhihu.com/equation?tex=O%28N%5E2%29" alt="[公式]"> ；</li>
<li><strong>预测时间长</strong>：模型预测时，预测时间与支持向量的个数成正比。当支持向量的数量较大时，预测计算复杂度较高。</li>
</ul>
<p><strong>==因此支持向量机目前只适合小批量样本的任务，无法适应百万甚至上亿样本的任务。==</strong></p>
<h2 id="SVM-Q-amp-A"><a href="#SVM-Q-amp-A" class="headerlink" title="SVM Q&amp;A"></a>SVM Q&amp;A</h2><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/93715996">https://zhuanlan.zhihu.com/p/93715996</a></p>
</blockquote>
<h3 id="1、原理："><a href="#1、原理：" class="headerlink" title="1、原理："></a>1、原理：</h3><ul>
<li>简单介绍SVM（详细原理）：从分类平面，到求两类间的最大间隔，到转化为求间隔分之一，等优化问题，然后就是优化问题的解决办法，首先是用拉格拉日乘子把约束优化转化为无约束优化，对各个变量求导令其为零，得到的式子带入拉格朗日式子从而转化为对偶问题， 最后再利用SMO（序列最小优化）来解决这个对偶问题。<strong>svm里面的超参数c有啥用：软间隔SVM去权衡优化目标和少量分错样本的目标。</strong></li>
<li><p>SVM的推导，解释原问题和对偶问题，<strong>SVM原问题和对偶问题的关系</strong>，<strong>KKT限制条件</strong>，<strong>KKT条件用哪些</strong>，完整描述；软间隔问题，解释支持向量、核函数（哪个地方引入、画图解释高维映射，高斯核可以升到多少维，如何选择核函数），引入拉格朗日的优化方法的原因，最大的特点，损失函数解释</p>
<ul>
<li><strong>KKT限制</strong>：主问题可行、对偶问题可行、主变量最优、<strong>互补松弛</strong></li>
</ul>
</li>
<li><p><strong>为什么要把原问题转换为对偶问题？</strong></p>
<ul>
<li>因为原问题是凸二次规划问题，转换为对偶问题更加高效。为什么求解对偶问题更加高效？因为只用求解alpha系数，而alpha系数只有支持向量才非0，其他全部为0.alpha系数有多少个？样本点的个数</li>
</ul>
</li>
</ul>
<h3 id="2、SVM与LR最大区别，LR和SVM对于outlier的敏感程度分析，逻辑回归与SVM的区别？"><a href="#2、SVM与LR最大区别，LR和SVM对于outlier的敏感程度分析，逻辑回归与SVM的区别？" class="headerlink" title="2、SVM与LR最大区别，LR和SVM对于outlier的敏感程度分析，逻辑回归与SVM的区别？"></a>2、SVM与LR最大区别，LR和SVM对于outlier的敏感程度分析，逻辑回归与SVM的区别？</h3><h3 id="3、SVM如何解决-多分类问题-、可以做-回归-吗，怎么做？"><a href="#3、SVM如何解决-多分类问题-、可以做-回归-吗，怎么做？" class="headerlink" title="3、SVM如何解决==多分类问题==、可以做==回归==吗，怎么做？"></a>3、SVM如何解决==多分类问题==、可以做==回归==吗，怎么做？</h3><h3 id="4、机器学习有很多关于核函数的说法，核函数的定义和作用是什么？"><a href="#4、机器学习有很多关于核函数的说法，核函数的定义和作用是什么？" class="headerlink" title="4、机器学习有很多关于核函数的说法，核函数的定义和作用是什么？"></a>4、机器学习有很多关于核函数的说法，核函数的定义和作用是什么？</h3><p><a href="https://www.zhihu.com/question/24627666">https://www.zhihu.com/question/24627666</a></p>
<h3 id="5、Linear-SVM-和-LR-有什么异同？"><a href="#5、Linear-SVM-和-LR-有什么异同？" class="headerlink" title="5、Linear SVM 和 LR 有什么异同？"></a>5、Linear SVM 和 LR 有什么异同？</h3><h4 id="SVM和LR相同点："><a href="#SVM和LR相同点：" class="headerlink" title="SVM和LR相同点："></a>SVM和LR相同点：</h4><ul>
<li>SVM和LR都属于机器学习的监督学习中的<strong>判别式模型</strong>（判别式模型对$p(y|x)$进行建模或直接基于x预测y，生成模型：$p(x|y)$和$p(y)$进行建模,预测后验概率）。</li>
<li>SVM和LR都是线性二分类模型，<strong>分类边界为一个超平面</strong>。</li>
<li>线性SVM和对数几率回归都可以基于表示定理和<strong>核技巧处理非线性可分问题</strong>。</li>
<li><strong>SVM的基本型和对数几率函数都属于参数模型。SVM的对偶性和核化对数几率回归都属于非参数模型</strong>。</li>
<li>SVM和LR优化目标都表示成：经验风险+结构风险（正则项）的形式；均是0，1损失的替代函数。风险结构都是L2正则化。</li>
<li><strong>SVM和LR都是凸优化问题，都能收敛到全局最优解。</strong></li>
<li>SVM和对数几率函数的优化目标相似，性能相当。</li>
<li><strong>SVM多分类：多分类SVM；LR多分类：Softmax回归。</strong></li>
</ul>
<h3 id="SVM和LR的区别："><a href="#SVM和LR的区别：" class="headerlink" title=" SVM和LR的区别："></a><strong><font color="red"> SVM和LR的区别：</font></strong></h3><blockquote>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>SVM</th>
<th>LR</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>思想</strong></td>
<td><strong>SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面</strong>。</td>
<td><strong>逻辑回归</strong>是使用线性回归模型的预测值逼近分类任务真实标记的对数几率。</td>
</tr>
<tr>
<td><strong>输出</strong></td>
<td><strong>非概率方法</strong>；</td>
<td><strong>概率方法</strong>；需要对$p(y</td>
<td>x)$进行假设，具有概率意义。</td>
</tr>
<tr>
<td><strong>经验损失函数</strong></td>
<td><strong>合页损失函数</strong>；有一段平的零区域、使得SVM的对偶性有稀疏性。</td>
<td><strong>交叉熵损失函数</strong></td>
</tr>
<tr>
<td><strong>训练样本</strong></td>
<td>支持向量（少数样本），SVM的参数和假设函数只和支持向量有关。</td>
<td>全样本</td>
</tr>
<tr>
<td><strong>优化方法</strong></td>
<td>次梯度下降和坐标梯度下降 【<strong>SMO算法</strong>】</td>
<td><strong>梯度下降</strong></td>
</tr>
<tr>
<td>多分类</td>
<td><strong>多分类SVM</strong></td>
<td><strong>Softmax回归</strong></td>
</tr>
<tr>
<td><strong>敏感程度</strong></td>
<td>SVM考虑分类边界线附近的样本（决定分类超平面的样本）。在支持向量外添加或减少任何样本点对分类决策面没有任何影响；</td>
<td>LR受所有数据点的影响。直接依赖数据分布，每个样本点都会影响决策面的结果。如果训练数据不同类别严重不平衡。</td>
</tr>
</tbody>
</table>
</div>
<p><a href="https://www.zhihu.com/question/26768865">https://www.zhihu.com/question/26768865</a></p>
<h3 id="6、支持向量机-SVM-是否适合大规模数据？【速度】"><a href="#6、支持向量机-SVM-是否适合大规模数据？【速度】" class="headerlink" title="6、支持向量机(SVM)是否适合大规模数据？【速度】"></a>6、支持向量机(SVM)是否适合大规模数据？【速度】</h3><p><a href="https://www.zhihu.com/question/19591450">https://www.zhihu.com/question/19591450</a></p>
<h3 id="7、SVM和逻辑斯特回归对同一样本A进行训练，如果某类中增加一些数据点，那么原来的决策边界分别会怎么变化？"><a href="#7、SVM和逻辑斯特回归对同一样本A进行训练，如果某类中增加一些数据点，那么原来的决策边界分别会怎么变化？" class="headerlink" title="7、SVM和逻辑斯特回归对同一样本A进行训练，如果某类中增加一些数据点，那么原来的决策边界分别会怎么变化？"></a>7、SVM和逻辑斯特回归对同一样本A进行训练，如果某类中增加一些数据点，那么原来的决策边界分别会怎么变化？</h3><p><a href="https://www.zhihu.com/question/30123068">https://www.zhihu.com/question/30123068</a></p>
<h3 id="8、各种机器学习的应用场景分别是什么？例如，k近邻-贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。"><a href="#8、各种机器学习的应用场景分别是什么？例如，k近邻-贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。" class="headerlink" title="8、各种机器学习的应用场景分别是什么？例如，k近邻,贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。"></a>8、各种机器学习的应用场景分别是什么？例如，k近邻,贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。</h3><p><a href="https://www.zhihu.com/question/26726794">https://www.zhihu.com/question/26726794</a></p>
<h3 id="9、SVM与感知器的联系和优缺点比较"><a href="#9、SVM与感知器的联系和优缺点比较" class="headerlink" title="==9、SVM与感知器的联系和优缺点比较=="></a>==9、SVM与感知器的联系和优缺点比较==</h3><p><strong>感知机用误分类样本点的几何距离之和</strong>来表示模型的损失函数，用梯度下降算法优化，直至没有误分类点。</p>
<script type="math/tex; mode=display">
L(w, b)=-\sum_{x^{(i)} \in M} y^{(i)}\left(w^{T} x^{(i)}+b\right)</script><h4 id="感知机与SVM区别："><a href="#感知机与SVM区别：" class="headerlink" title="==感知机与SVM区别：=="></a>==感知机与SVM区别：==</h4><p><strong>SVM可以视为对感知器的二阶改进</strong>：第一阶改进是加入了 <img src="https://www.zhihu.com/equation?tex=%5Cgamma" alt="[公式]"> 获得hinge loss，从而具备了产生大间隔的潜质；第二阶改进是加入了权向量的L2正则化项，从而避免产生无意义的大函数间隔，而是产生大的几何间隔。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>感知机</th>
<th>SVM</th>
</tr>
</thead>
<tbody>
<tr>
<td>思想</td>
<td>分离超平面基于误分类的损失函数<img src="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5En+max%280%2C+-y_i%28w%5ETx_i%2Bb%29%29%5C%5C" alt="[公式]"></td>
<td><img src="https://www.zhihu.com/equation?tex=%5Cmin_%7Bw%2Cb%7D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5En+max%280%2C+1-y_i%28w%5ETx_i%2Bb%29%29+%2B+%5Calpha+%7C%7Cw%7C%7C_2%5E2+%5C%5C" alt="[公式]" style="zoom:150%;"></td>
</tr>
<tr>
<td>超平面</td>
<td>因采用的初值不同而得到不同的超平面</td>
<td>让离划分超平面最近的样本到划分超平面距离尽可能远</td>
</tr>
<tr>
<td>关键样本</td>
<td>每步的分错样本</td>
<td><strong>支持向量</strong></td>
</tr>
<tr>
<td>非线性问题</td>
<td>无</td>
<td>核化</td>
</tr>
</tbody>
</table>
</div>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%885%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>机器学习中的监督学习本质上是给定一系列训练样本 <img src="https://www.zhihu.com/equation?tex=%28x_i%2C+y_i%29" alt="[公式]"> ，尝试学习 <img src="https://www.zhihu.com/equation?tex=x%5Crightarrow+y" alt="[公式]"> 的映射关系，使得给定一个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> ，即便这个 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 不在训练样本中，也能够得到尽量接近真实 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 的输出 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D" alt="[公式]"> 。而损失函数（Loss Function）则是这个过程中关键的一个组成部分，用来<strong>衡量模型的输出</strong> <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D" alt="[公式]"> <strong>与真实的</strong> <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> <strong>之间的差距</strong>，给模型的优化指明方向。</p>
<p>本文将介绍机器学习、深度学习中分类与回归常用的几种损失函数，包括<strong>均方差损失 Mean Squared Loss、平均绝对误差损失 Mean Absolute Error Loss、Huber Loss、分位数损失 Quantile Loss、交叉熵损失函数 Cross Entropy Loss、Hinge 损失 Hinge Loss</strong>。主要介绍各种损失函数的基本形式、原理、特点等方面。</p>
<p><img src="https://pic3.zhimg.com/80/v2-d42728029b6f2f9db86fc34c63dd5ff8_1440w.jpg?source=1940ef5c" alt="img" style="zoom: 67%;"></p>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在正文开始之前，先说下关于 Loss Function、Cost Function 和 Objective Function 的区别和联系。在机器学习的语境下这三个术语经常被交叉使用。</p>
<ul>
<li><strong>损失函数</strong> Loss Function 通常是<strong>针对单个训练样本而言</strong>，给定一个模型输出 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D" alt="[公式]"> 和一个真实 <img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> ，损失函数输出一个实值损失 <img src="https://www.zhihu.com/equation?tex=L%3Df%28y_i%2C+%5Chat%7By_i%7D%29" alt="[公式]"></li>
<li><strong>代价函数</strong> Cost Function 通常是<strong>针对整个训练集</strong>（或者在使用 mini-batch gradient descent 时一个 mini-batch）的总损失 <img src="https://www.zhihu.com/equation?tex=J%3D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+f%28y_i%2C%5Chat%7By_i%7D%29" alt="[公式]"></li>
<li><strong>目标函数</strong> Objective Function 是一个更通用的术语，表示任意希望被优化的函数，用于机器学习领域和非机器学习领域（比如运筹优化）</li>
</ul>
<p>一句话总结三者的关系就是：<font color="red"> <strong>A loss function is a part of a cost function which is a type of an objective function.</strong></font></p>
<p>由于损失函数和代价函数只是在针对样本集上有区别，因此在本文中统一使用了损失函数这个术语，但下文的相关公式实际上采用的是代价函数 Cost Function 的形式，请读者自行留意。</p>
<h4 id="结构风险函数"><a href="#结构风险函数" class="headerlink" title="结构风险函数"></a>结构风险函数</h4><p>损失函数（loss function）是用来估量模型的预测值f(x)与真实值$Y$不一致的程度，它是一个非负实数值函数，通常使用$L(Y,f(x))$来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数的重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下的式子：</p>
<p><img src="image-20220821223950768.png" alt="image-20220821223950768" style="zoom:50%;"></p>
<p>前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的Φ是正则化项（regularizer）或者叫惩罚项（penalty term）,它可以是L1，也可以是L2等其他的正则函数。整个式子表示的意思是找到使目标函数最小时的θ值。下面列出集中常见的损失函数。</p>
<h3 id="一、-对数损失函数（逻辑回归）MLE-【交叉熵损失函数】"><a href="#一、-对数损失函数（逻辑回归）MLE-【交叉熵损失函数】" class="headerlink" title="一、 对数损失函数（逻辑回归）MLE  【交叉熵损失函数】"></a>一、 对数损失函数（逻辑回归）MLE  【交叉熵损失函数】</h3><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/52100927">https://zhuanlan.zhihu.com/p/52100927</a></p>
<p>  <a href="https://blog.csdn.net/tsyccnh/article/details/79163834">一文搞懂交叉熵在机器学习中的使用，透彻理解交叉熵背后的直觉</a></p>
<p>  <a href="https://zhuanlan.zhihu.com/p/35709485">损失函数｜交叉熵损失函数</a></p>
</blockquote>
<p>有些人可能觉得逻辑回归的损失函数就是平方损失，其实并不是。<strong>平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到</strong>，而逻辑回归得到的并不是平方损失。在逻辑回归的推导中，<strong>它假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数</strong>，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：</p>
<p><strong>最小化负的似然函数</strong>（即$maxF(y,f(x))—&gt;min−F(y,f(x))$)。从损失函数的视角来看，它就成了<strong>log损失函数了。</strong></p>
<h4 id="原理解释1：-条件概率下方便计算极大似然估计"><a href="#原理解释1：-条件概率下方便计算极大似然估计" class="headerlink" title="原理解释1：==条件概率下方便计算极大似然估计=="></a>原理解释1：<strong>==条件概率下方便计算极大似然估计==</strong></h4><p>Log损失函数的标准形式：</p>
<p>$L(Y,P(Y|X))=−logP(Y|X)$</p>
<p>刚刚说到，<strong>取对数是为了方便计算极大似然估计</strong>，因为在MLE中，直接求导比较困难，所以通常都是先取对数再求导找极值点。损失函数$L(Y.P(Y|X))$表达的是样本在分类$Y$的情况下，使概率$P(Y|X)$达到最大值（换言之，就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者什么样的参数才能使我们观测到目前这组数据的概率最大）。因为log函数是单调递增的，所以$logP(Y|X)$也会达到最大值，因此在前面加上负号之后，最大化$P(Y|X)$就等价于最小化$L$了。</p>
<p><strong>logistic回归</strong>的$P(y|x)$表达式如下（为了将类别标签y统一为1和0，下面将表达式分开表示）：</p>
<p><img src="image-20220322202521355.png" alt="image-20220322202521355" style="zoom:50%;"></p>
<p>将上面的公式合并在一起，可得到第i个样本正确预测的概率：</p>
<p><img src="image-20220322202548296.png" alt="image-20220322202548296" style="zoom:50%;"></p>
<p>上式是对一个样本进行建模的数据表达。对于所有的样本，假设每条样本生成过程独立，在整个样本空间中（N个样本）的概率分布为：</p>
<p><img src="image-20220322202618734.png" alt="image-20220322202618734" style="zoom:50%;"></p>
<p>将上式代入到对数损失函数中，得到最终的损失函数为：</p>
<p><img src="image-20220322202653661.png" alt="image-20220322202653661" style="zoom:50%;"></p>
<h4 id="原理解释2：相对熵（KL散度）推理"><a href="#原理解释2：相对熵（KL散度）推理" class="headerlink" title="原理解释2：相对熵（KL散度）推理"></a>原理解释2：相对熵（KL散度）推理</h4><blockquote>
<p>  相对熵又称KL散度,如果我们对于同一个随机变量 x 有两个单独的概率分布 P(x) 和 Q(x)，我们可以使用 KL 散度（Kullback-Leibler (KL) divergence）来衡量这两个分布的差异.$DKL$的值越小，表示q分布和p分布越接近.</p>
</blockquote>
<h5 id="相对熵"><a href="#相对熵" class="headerlink" title="相对熵:"></a>相对熵:</h5><p><img src="image-20220330133351613.png" alt="image-20220330133351613" style="zoom:50%;"></p>
<h5 id="相对熵-信息熵-交叉熵-："><a href="#相对熵-信息熵-交叉熵-：" class="headerlink" title="相对熵 = 信息熵 + 交叉熵 ："></a>相对熵 = 信息熵 + 交叉熵 ：</h5><p><img src="image-20220330134202064.png" alt="image-20220330134202064" style="zoom:50%;"></p>
<p><strong>【对数损失函数（Log loss function）】和【交叉熵损失函数（Cross-entroy loss funtion）】在很多文献内是一致的，因为他们的表示式的本质是一样的。</strong></p>
<h3 id="二、-平方损失函数（线性回归，GBDT，最小二乘法，Ordinary-Least-Squares）MSE"><a href="#二、-平方损失函数（线性回归，GBDT，最小二乘法，Ordinary-Least-Squares）MSE" class="headerlink" title="二、 平方损失函数（线性回归，GBDT，最小二乘法，Ordinary Least Squares）MSE"></a>二、 平方损失函数（线性回归，GBDT，最小二乘法，Ordinary Least Squares）MSE</h3><p>最小二乘法是线性回归的一种，OLS 将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（为什么假设成高斯分布呢？其实这里隐藏了一个小知识点，就是中心极限定理，可以参考【central limit theorem】），最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。换言之，OLS是基于<strong>距离</strong>的，而这个距离就是我们用的最多的欧几里得距离。为什么它会选择使用欧式距离作为误差度量呢（即Mean squared error， MSE），主要有以下几个原因：</p>
<ul>
<li>简单，计算方便；</li>
<li>欧氏距离是一种很好的相似性度量标准；</li>
<li>在不同的表示域变换后特征性质不变。</li>
</ul>
<p>平方损失（Square loss）的标准形式如下：$L(Y,f(X))=(Y−f(x))^2$当样本个数为n时，此时的损失函数变为：</p>
<p><img src="image-20220322202912962.png" alt="image-20220322202912962" style="zoom:50%;"></p>
<p>$Y−f(X)$ 表示的是<strong>残差</strong>，整个式子表示的是残差的平方和，而我们的目的就是最小化这个目标函数值（注：该式子未加入正则项），也就是最小化残差的平方和（residual sum of squares，RSS）。</p>
<p>而在实际应用中，通常会使用<strong>均方差</strong>（MSE）作为一项衡量指标，公式如下：</p>
<p><img src="image-20220322202957484.png" alt="image-20220322202957484" style="zoom:50%;"></p>
<h3 id="三、-指数损失函数（Adaboost）"><a href="#三、-指数损失函数（Adaboost）" class="headerlink" title="三、 指数损失函数（Adaboost）"></a>三、 指数损失函数（Adaboost）</h3><blockquote>
<p>  Adaboost训练误差以指数下降。所以说，指数损失本身并没有带来优化上的特殊，优点在于计算和表达简单。</p>
</blockquote>
<p>学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。在Adaboost中，经过m此迭代之后，可以得到$fm(x)$:</p>
<p><img src="image-20220322203050695.png" alt="image-20220322203050695" style="zoom:50%;"></p>
<p><strong>Adaboost</strong>每次迭代时的目的是为了找到最小化下列式子时的参数 $a$ 和 $G$：</p>
<p><img src="image-20220322203141435.png" alt="image-20220322203141435" style="zoom:50%;"></p>
<p>而指数损失函数(exp-loss）的标准形式如下:</p>
<p><img src="image-20220322203221432.png" alt="image-20220322203221432" style="zoom:50%;"></p>
<p>可以看出，Adaboost的目标式子就是指数损失，在给定N个样本的情况下，Adaboost的损失函数为：</p>
<p><img src="image-20220322203238853.png" alt="image-20220322203238853" style="zoom:50%;"></p>
<h3 id="四、-Hinge-合页损失函数-（SVM，advGAN）"><a href="#四、-Hinge-合页损失函数-（SVM，advGAN）" class="headerlink" title="四、 ==Hinge 合页损失函数==（SVM，advGAN）"></a>四、 ==Hinge 合页损失函数==（SVM，advGAN）</h3><p><img src="image-20220401165315551.png" alt="image-20220401165315551" style="zoom:50%;"></p>
<p>线性支持向量机学习除了原始最优化问题，还有另外一种解释，就是最优化以下目标函数：</p>
<p><img src="image-20220322205741804.png" alt="image-20220322205741804" style="zoom:50%;"></p>
<p>目标函数的第一项是经验损失或经验风险函数：</p>
<p><img src="image-20220322205801232.png" alt="image-20220322205801232" style="zoom:50%;"></p>
<p>称为<strong>合页损失函数</strong>（hinge loss function）。下标”+”表示以下取正值的函数：</p>
<p><img src="image-20220322205844003.png" alt="image-20220322205844003" style="zoom:50%;"></p>
<p>这就是说，当样本点$(xi,yi)$被正确分类且函数间隔（确信度）$yi(w·xi+b)$大于1时，损失是0，否则损失是$1−yi(w·xi+b)$。目标函数的第二项是系数为 $λ$ 的 $w$ 的 $L2$ 范数，是正则化项。</p>
<p>接下来证明线性支持向量机原始最优化问题：</p>
<p><img src="image-20220322210000477.png" alt="image-20220322210000477" style="zoom:50%;"></p>
<p><img src="image-20220322210121285.png" alt="image-20220322210121285" style="zoom:50%;"></p>
<p>先令$[1−yi(w·xi+b)]+=ξi$，则$ξi≥0$，第二个约束条件成立；由$[1−yi(w·xi+b)]+=ξi$，当$1−yi(w·xi+b)&gt;0$时，有$yi(w·xi+b)=1−ξi$;当$1−yi(w·xi+b)≤0$时，$ξi=0$，有$yi(w·xi+b)≥1−ξi$，所以第一个约束条件成立。所以两个约束条件都满足，最优化问题可以写作</p>
<p><img src="image-20220322210943775.png" alt="image-20220322210943775" style="zoom:50%;"></p>
<p>若取 $λ=1/2C$ 则:</p>
<p><img src="image-20220322211012150.png" alt="image-20220322211012150" style="zoom:50%;"></p>
<h3 id="五、Softmax函数和Sigmoid函数的区别与联系"><a href="#五、Softmax函数和Sigmoid函数的区别与联系" class="headerlink" title="五、Softmax函数和Sigmoid函数的区别与联系"></a>五、Softmax函数和Sigmoid函数的区别与联系</h3><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/356976844">https://zhuanlan.zhihu.com/p/356976844</a></p>
</blockquote>
<h4 id="5-1-分类任务"><a href="#5-1-分类任务" class="headerlink" title="5.1 分类任务"></a>5.1 分类任务</h4><h4 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h4><blockquote>
<p>  Sigmoid =<strong>==多标签分类问题==</strong>=多个正确答案=非独占输出（例如胸部X光检查、住院）。构建分类器，解决有多个正确答案的问题时，用Sigmoid函数分别处理各个原始输出值。</p>
<p>  Softmax =<strong>多类别分类问题</strong>=只有一个正确答案=互斥输出（例如手写数字，鸢尾花）。构建分类器，解决只有唯一正确答案的问题时，用Softmax函数处理各个原始输出值。Softmax函数的分母综合了原始输出值的所有因素，这意味着，Softmax函数得到的不同概率之间相互关联。</p>
</blockquote>
<p><strong>Sigmoid函数</strong>是一种logistic函数，它将任意的值转换到 <img src="https://www.zhihu.com/equation?tex=%5B0%2C+1%5D" alt="[公式]"> 之间，如图1所示，函数表达式为： <img src="https://www.zhihu.com/equation?tex=Sigmoid%28x%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-x%7D%7D" alt="[公式]"> 。</p>
<p>它的导函数为： <img src="https://www.zhihu.com/equation?tex=Sigmoid%5E%7B%27%7D%28x%29%3DSigmoid%28x%29%5Ccdot+%281-Sigmoid%28x%29%29" alt="[公式]"> 。</p>
<p><img src="https://pic1.zhimg.com/80/v2-17889947ad7bc75ba672e41363b54788_1440w.jpg" alt="img">图1：Sigmoid函数</p>
<p><strong>优点</strong>：</p>
<ol>
<li>Sigmoid函数的输出在(0,1)之间，输出范围有限，优化稳定，可以用作<strong>输出层</strong>。</li>
<li>连续函数，便于<strong>求导</strong>。</li>
</ol>
<p><strong>缺点</strong>：</p>
<ol>
<li><p>最明显的就是<strong>饱和性</strong>，从上图也不难看出其两侧导数逐渐趋近于0，容易造成<strong>梯度消失</strong>。</p>
<p>2.激活函数的偏移现象。Sigmoid函数的输出值均大于0，使得输出不是0的均值，这会导致后一层的神经元将得到上一层非0均值的信号作为输入，这会对梯度产生影响。</p>
</li>
<li><p>计算复杂度高，因为Sigmoid函数是指数形式。</p>
</li>
</ol>
<h4 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h4><p><strong>Softmax函数</strong>，又称<strong>归一化指数函数</strong>，函数表达式为： <img src="https://www.zhihu.com/equation?tex=Softmax%28x%29%3D%5Cfrac%7Be%5E%7Bx_%7Bi%7D%7D%7D%7B%5Csum_%7Bj%3D1%7D%5E%7Bn%7D%7Be%5E%7Bx_%7Bj%7D%7D%7D%7D" alt="[公式]"> 。</p>
<p><img src="https://pic2.zhimg.com/80/v2-3c2edc906b299c33ae2e08376bd76689_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p><strong>Softmax函数是二分类函数Sigmoid在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。</strong>如图2所示，Softmax直白来说就是将原来输出是3,1,-3通过Softmax函数一作用，就映射成为(0,1)的值，而这些值的累和为1（满足概率的性质），那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大（也就是值对应最大的）结点，作为我们的预测目标。</p>
<p>由于Softmax函数先拉大了输入向量元素之间的差异（通过指数函数），然后才归一化为一个概率分布，在应用到分类问题时，它使得各个类别的概率差异比较显著，最大值产生的概率更接近1，这样输出分布的形式更接近真实分布。</p>
<p><strong>Softmax可以由三个不同的角度来解释。从不同角度来看softmax函数，可以对其应用场景有更深刻的理解：</strong></p>
<ol>
<li><strong>softmax可以当作argmax的一种平滑近似</strong>，与arg max操作中暴力地选出一个最大值（产生一个one-hot向量）不同，softmax将这种输出作了一定的平滑，即将one-hot输出中最大值对应的1按输入元素值的大小分配给其他位置。</li>
<li><strong>softmax将输入向量归一化映射到一个类别概率分布</strong>，即 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 个类别上的概率分布（前文也有提到）。这也是为什么在深度学习中常常将softmax作为MLP的最后一层，并配合以交叉熵损失函数（对分布间差异的一种度量)。</li>
<li>从<strong>概率图模型</strong>的角度来看，softmax的这种形式可以理解为一个概率无向图上的联合概率。因此你会发现，条件最大熵模型与softmax回归模型实际上是一致的，诸如这样的例子还有很多。由于概率图模型很大程度上借用了一些热力学系统的理论，因此也可以从物理系统的角度赋予softmax一定的内涵。</li>
</ol>
<h4 id="5-2-总结"><a href="#5-2-总结" class="headerlink" title="5.2 总结"></a>5.2 总结</h4><ol>
<li>如果模型输出为非互斥类别，且可以同时选择多个类别，则采用Sigmoid函数计算该网络的原始输出值。</li>
<li>如果模型输出为<strong>互斥类别</strong>，且只能选择一个类别，则采用Softmax函数计算该网络的原始输出值。</li>
<li><strong>Sigmoid函数</strong>可以用来解决<strong>多标签问题</strong>，<strong>Softmax</strong>函数用来解决<strong>单标签问题</strong>。</li>
<li>对于某个分类场景，当Softmax函数能用时，Sigmoid函数一定可以用。</li>
</ol>
<h3 id="6-损失函数Q-amp-A"><a href="#6-损失函数Q-amp-A" class="headerlink" title="6 损失函数Q&amp;A"></a>6 损失函数Q&amp;A</h3><h4 id="平方误差损失函数和交叉熵损失函数分别适合什么场景？"><a href="#平方误差损失函数和交叉熵损失函数分别适合什么场景？" class="headerlink" title="==平方误差损失函数和交叉熵损失函数分别适合什么场景？=="></a>==平方误差损失函数和交叉熵损失函数分别适合什么场景？==</h4><p>一般还说，平方损失函数更适合输出为连续，并且最后一层不含sigmod或softmax激活函数的神经网络；交叉熵损失函数更适合二分类或多分类的场景。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/03/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%887%EF%BC%89%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
    <content><![CDATA[<h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><p><a href="https://scikit-learn.org/dev/modules/naive_bayes.html#naive-bayes">https://scikit-learn.org/dev/modules/naive_bayes.html#naive-bayes</a></p>
<ul>
<li><p><a href="https://plushunter.github.io/2017/02/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%EF%BC%8810%EF%BC%89%EF%BC%9A%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/">FREE WILL 机器学习算法系列（10）：朴素贝叶斯</a></p>
</li>
<li><h5 id="最大似然估计、最大后验估计、贝叶斯估计的对比"><a href="#最大似然估计、最大后验估计、贝叶斯估计的对比" class="headerlink" title="最大似然估计、最大后验估计、贝叶斯估计的对比"></a><a href="https://www.cnblogs.com/jiangxinyang/p/9378535.html">最大似然估计、最大后验估计、贝叶斯估计的对比</a></h5></li>
</ul>
<h3 id="一、朴素贝叶斯的学习与分类"><a href="#一、朴素贝叶斯的学习与分类" class="headerlink" title="一、朴素贝叶斯的学习与分类"></a>一、朴素贝叶斯的学习与分类</h3><blockquote>
<p>  朴素贝叶斯（Naive Bayes）是基于<strong>贝叶斯定理</strong>与<strong>特征条件假设</strong>的<strong>分类</strong>方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入、输出的联合分布；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。朴素贝叶斯是<strong>选出各个分类类别后验概率最大</strong>的作为最终分类。</p>
<ul>
<li><strong>优点</strong>：对小规模的数据表现很好，适合多分类任务，<strong>适合增量式训练</strong>。</li>
<li><strong>缺点</strong>：对输入数据的表达形式很敏感<strong>（离散、连续，值极大极小之类的）</strong>。</li>
</ul>
</blockquote>
<h4 id="1-1贝叶斯定理"><a href="#1-1贝叶斯定理" class="headerlink" title="1.1贝叶斯定理"></a>1.1贝叶斯定理</h4><p><strong>条件概率:</strong></p>
<p>$P(A|B)$  表示事件B已经发生的前提下，事件B已经发生的前提下，事件A发生的概率，叫做事件 $B$<br>发生下事件 $A$ 的条件概率。其基本求解公式为</p>
<p><img src="image-20220325172121116.png" alt="image-20220325172121116" style="zoom:50%;"></p>
<p><strong>贝叶斯定理</strong>便是基于<strong>条件概率</strong>，通过$P(A|B)$来求$P(B|A)$：【通过<strong>先验概率</strong>计算<strong>后验概率</strong>】</p>
<p><img src="image-20220325172351101.png" alt="image-20220325172351101" style="zoom:50%;"></p>
<p>顺便提一下，上式中的分母，可以根据<strong>全概率公式</strong>分解为：</p>
<p><img src="image-20220325172306652.png" alt="image-20220325172306652" style="zoom:50%;"></p>
<h4 id="1-2-特征条件独立假设"><a href="#1-2-特征条件独立假设" class="headerlink" title="1.2 特征条件独立假设"></a>1.2 特征条件独立假设</h4><p>这一部分开始朴素贝叶斯的理论推导，从中你会深刻地理解什么是特征条件<strong>独立假设</strong>。给定训练数据集$(X,Y)$，其中每个样本$X$都包括 $n$ 维特征，即$x=(x1,x2,···,xn)$，类标记集合含有$K$种类别，即$y=(y1,y2,···,yk)$.</p>
<p>如果现在来了一个新样本 $x$ 我们要怎么判断它的类别?从概率的角度来看，这个问题就是给定$x$，它属于哪个类别的概率更大。那么问题就转化为求解 $P(y1|x),P(y2|x),P(yk|x)P(y1|x),P(y2|x),P(yk|x)$ 中最大的那个，即求<strong>后验概率最大</strong>的输出：==$arg max_{y_k}P(y_k|x)$==</p>
<p><img src="image-20220325203314162.png" alt="image-20220325203314162" style="zoom:50%;"></p>
<p>根据<strong>全概率公式</strong>，可以进一步分解上式中的分母：</p>
<p><img src="image-20220325203335825.png" alt="image-20220325203335825" style="zoom:50%;"></p>
<ul>
<li><p><img src="image-20220325205350669.png" alt="image-20220325205350669" style="zoom:50%;">：<strong>先验概率</strong> 【训练集计算】</p>
</li>
<li><p><img src="image-20220325205444531.png" alt="image-20220325205444531" style="zoom:50%;">：<strong>条件概率</strong>，它的参数规模是<strong>指数</strong>数量级别的。假设第i维特征xi可取值的个数有Si个，类别取值个数为k个，那么参数个数为$k∏S_j$。</p>
</li>
<li><p><strong>独立性的假设</strong>：通俗地讲就是说假设各个维度的特征互相独立，这样<strong>参数规模</strong>就降到了$∑S_ik$, 【积-&gt;和】</p>
<p><img src="image-20220325211846297.png" alt="image-20220325211846297" style="zoom:50%;"></p>
</li>
<li><p>代入公式1得出：</p>
<p><img src="image-20220325213643901.png" alt="image-20220325213643901" style="zoom:50%;"></p>
</li>
<li><p>于是朴素贝叶斯分类器可表示为：</p>
<p><img src="image-20220325213705861.png" alt="image-20220325213705861" style="zoom:50%;"></p>
</li>
<li><p>由于分母值都是一样的：<strong>==极大后验概率估计==</strong></p>
</li>
</ul>
<p><img src="image-20220325213802190.png" alt="image-20220325213802190" style="zoom:50%;"></p>
<h4 id="1-3-朴素贝叶斯法的参数估计【求解】"><a href="#1-3-朴素贝叶斯法的参数估计【求解】" class="headerlink" title="1.3 朴素贝叶斯法的参数估计【求解】"></a>1.3 朴素贝叶斯法的参数估计【求解】</h4><p>朴素贝叶斯要学习的东西就是：<img src="image-20220325215221520.png" alt="image-20220325215221520" style="zoom:50%;"> 和 <img src="image-20220325215238733.png" alt="image-20220325215238733" style="zoom:50%;">【极大似然函数 + 拉格朗日乘数法】</p>
<ul>
<li><p><strong>先验概率</strong>$P(Y=ck)$的极大似然估计是, <strong>样本在$c_k$出现的次数除以样本容量</strong>：</p>
<p><img src="image-20220325215849572.png" alt="image-20220325215849572" style="zoom:50%;"></p>
</li>
<li><p>$设第 j 个特征x(j)可能取值的集合为a_{j1},a_{j2},···,a_{jl}, 条件概率P(X_j=a_{jl} |Y=ck)的极大似然估计是$：</p>
<p><img src="image-20220325221320810.png" alt="image-20220325221320810" style="zoom:50%;"></p>
</li>
</ul>
<h4 id="1-4-贝叶斯估计【缺失值处理】【拉普拉斯平滑】"><a href="#1-4-贝叶斯估计【缺失值处理】【拉普拉斯平滑】" class="headerlink" title="1.4 贝叶斯估计【缺失值处理】【拉普拉斯平滑】"></a>1.4 贝叶斯估计【缺失值处理】【拉普拉斯平滑】</h4><p><strong>先验概率</strong>的贝叶斯估计：</p>
<p><img src="image-20220325222259483.png" alt="image-20220325222259483" style="zoom:50%;"></p>
<p><strong>条件概率</strong>的贝叶斯估计：【<strong>离散型</strong>】</p>
<p><img src="image-20220325222226643.png" alt="image-20220325222226643" style="zoom:50%;"></p>
<h4 id="1-5-朴素贝叶斯有什么优缺点？"><a href="#1-5-朴素贝叶斯有什么优缺点？" class="headerlink" title=" 1.5 朴素贝叶斯有什么优缺点？"></a><strong><font color="red"> 1.5 朴素贝叶斯有什么优缺点？</font></strong></h4><h5 id="优点：【数学理论、缺失异常不敏感、快、增量式训练】"><a href="#优点：【数学理论、缺失异常不敏感、快、增量式训练】" class="headerlink" title="优点：【数学理论、缺失异常不敏感、快、增量式训练】"></a>优点：【数学理论、缺失异常不敏感、快、增量式训练】</h5><ul>
<li>朴素贝叶斯模型<strong>发源于古典数学理论</strong>，有稳定的分类效率。</li>
<li><strong>对缺失数据和异常数据不太敏感</strong>，算法也比较简单，常用于文本分类。</li>
<li><strong>分类准确度高，速度快</strong>。</li>
<li><strong>对小规模的数据表现很好，能处理多分类任务，适合增量式训练，当数据量超出内存时，我们可以一批批的去增量训练</strong>(朴素贝叶斯在训练过程中只需要计算各个类的概率和各个属性的类条件概率，这些概率值可以快速地根据增量数据进行更新，无需重新全量计算)。</li>
</ul>
<h5 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h5><ul>
<li><strong>对输入数据的表达形式很敏感（离散、连续，值极大极小之类的）</strong>。</li>
<li><strong>对训练数据的依赖性很强</strong>，如果训练数据误差较大，那么预测出来的效果就会不佳。</li>
<li>理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。 但是在实际中，因为朴素贝叶斯“朴素，”的特点，<strong>导致在属性个数比较多或者属性之间相关性较大时，分类效果不好。</strong>而在属性相关性较小时，朴素贝叶斯性能最为良好。对于这一点，有半朴素贝叶斯之类的算法通过考虑部分关联性适度改进。</li>
<li>需要知道<strong>先验概率</strong>，且先验概率很多时候是基于假设或者已有的训练数据所得的，这在某些时候可能会因为假设先验概率的原因出现分类决策上的错误。</li>
</ul>
<h2 id="二、高斯贝叶斯模型"><a href="#二、高斯贝叶斯模型" class="headerlink" title="二、高斯贝叶斯模型"></a>二、高斯贝叶斯模型</h2><blockquote>
<p>  classifier = naive_bayes.MultinomialNB()</p>
</blockquote>
<h4 id="2-1-朴素贝叶斯-连续型数据处理"><a href="#2-1-朴素贝叶斯-连续型数据处理" class="headerlink" title="2.1 朴素贝叶斯(连续型数据处理)"></a>2.1 朴素贝叶斯(连续型数据处理)</h4><ul>
<li>每一个连续的<strong>数据离散化</strong>，然后用相应的离散区间替换连续数值。这种方法对于划分离散区间的粒度要求较高，不能太细，也不能太粗。</li>
<li>假设<strong>连续数据服从某个概率分布</strong>，<strong>使用训练数据估计分布参数</strong>，通常我们用<strong>高斯分布</strong>来表示<strong>连续数据的类条件概率分布</strong>。</li>
</ul>
<p><strong>==GaussianNB 的条件概率密度计算：其中均值和方差可以通过极大似然估计得出。==</strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
&p\left(X^{(j)}=a_{j l} \mid y=c_{k}\right)=\frac{1}{\sqrt{2 \pi} \sigma_{j k}} e^{-\frac{\left(a_{j l}-\mu_{j k}\right)^{2}}{2 \sigma_{j k}^{2}}}
\end{aligned}</script><h2 id="三、贝叶斯网络"><a href="#三、贝叶斯网络" class="headerlink" title="三、贝叶斯网络"></a>三、贝叶斯网络</h2><h4 id="3-1-概率图模型"><a href="#3-1-概率图模型" class="headerlink" title="3.1 概率图模型"></a>3.1 概率图模型</h4><p>概率图模型分为<strong>贝叶斯网络（Bayesian Network）和马尔可夫网络（Markov Network）</strong>两大类。贝叶斯网络可以用一个有向图结构表示，马尔可夫网络可以表示成一个无向图的网络结构。更详细地说，<strong>概率图模型包括了朴素贝叶斯模型、最大熵模型、隐马尔可夫模型、条件随机场、主题模型</strong>等，在机器学习的诸多场景中都有着广泛的应用。</p>
<ul>
<li><strong>贝叶斯网络</strong> — 结点与结点之间是以有向箭头相连接，代表是这个结点会影响下一个结点</li>
<li><strong>马尔可夫网络</strong> — 结点与结点之间是以无向箭头相连接，代表是结点与结点之间会相互影响</li>
</ul>
<h2 id="四、最大似然估计、最大后验估计、贝叶斯估计的对比"><a href="#四、最大似然估计、最大后验估计、贝叶斯估计的对比" class="headerlink" title="四、最大似然估计、最大后验估计、贝叶斯估计的对比"></a>四、最大似然估计、最大后验估计、贝叶斯估计的对比</h2><h4 id="4-1-贝叶斯公式"><a href="#4-1-贝叶斯公式" class="headerlink" title="4.1 贝叶斯公式"></a>4.1 <strong>贝叶斯公式</strong></h4><p>这三种方法都和贝叶斯公式有关，所以我们先来了解下贝叶斯公式：</p>
<script type="math/tex; mode=display">
p(\theta \mid X)=\frac{p(X \mid \theta) p(\theta)}{p(X)}</script><p>每一项的表示如下:</p>
<script type="math/tex; mode=display">
\text { posterior }=\frac{\text { likehood } * \text { prior }}{\text { evidence }}</script><ul>
<li>posterior: 通过样本X得到参数 $\theta$ 的概率, 也就是后验概率。</li>
<li>likehood: 通过参数 $\theta$ 得到样本X的概率, 似然函数, 通常就是我们的数据集的表现。</li>
<li>prior: 参数 $\theta$ 的先验概率, 一般是根据人的先验知识来得出的。</li>
</ul>
<h4 id="4-2-极大似然估计-MLE"><a href="#4-2-极大似然估计-MLE" class="headerlink" title="4.2 极大似然估计 (MLE)"></a>4.2 极大似然估计 (MLE)</h4><p>极大似然估计的核心思想是: 认为当前发生的事件是概率最大的事件。<strong>因此就可以给定的数据集, 使得该数据集发生的概率最大来求得模型中的参数</strong>。似然函数如下:</p>
<script type="math/tex; mode=display">
p(X \mid \theta)=\prod_{x 1}^{x n} p(x i \mid \theta)</script><p>为了便于计算, 我们对似然函数两边取对数, 生成新的对数似然函数（因为对数函数是单调增函数, 因此求似然函数最大化就可 以转换成对数似然函数最大化）：</p>
<script type="math/tex; mode=display">
p(X \mid \theta)=\prod_{x 1}^{x n} p(x i \mid \theta)=\sum_{x 1}^{x n} \log p(x i \mid \theta)</script><p>求对数似然函数最大化, 可以通过导数为 0 来求解。<strong><font color="red"> 极大似然估计只关注当前的样本, 也就是只关注当前发生的事情, 不考虑事情的先验情况</font></strong>。由于计算简单, 而且不需要关注先验 知识, 因此在机器学习中的应用非常广, 最常见的就是逻辑回归。</p>
<h4 id="4-3-最大后验估计-MAP"><a href="#4-3-最大后验估计-MAP" class="headerlink" title="4.3 最大后验估计 (MAP)"></a>4.3 最大后验估计 (MAP)</h4><p>和最大似然估计不同的是, 最大后验估计中引入了<strong>先验概率</strong>（先验分布属于贝叶斯学派引入的, 像L1, L2正则化就是对参数引入 了拉普拉斯先验分布和高斯先验分布）, 而且最大后验估计要求的是 $p(\theta \mid X)$<br>最大后验估计可以写成下面的形式:</p>
<script type="math/tex; mode=display">
\operatorname{argmaxp}(\theta \mid X)=\operatorname{argmax} \frac{p(X \mid \theta) p(\theta)}{p(X)}=\operatorname{argmaxp}(X \mid \theta) p(\theta)=\operatorname{argmax}\left(\prod_{x 1}^{x n} p(x i \mid \theta)\right) p(\theta)</script><p>在求最大后验概率时, 可以忽略分母 $p(x)$, 因为该值不影响对 $\theta$ 的估计。同样为了便于计算, 对两边取对数, 后验概率最大化就变成了:</p>
<script type="math/tex; mode=display">
\operatorname{argmax}\left(\sum_{x 1}^{x n} \operatorname{logp}(x i \mid \theta)+\log p(\theta)\right)</script><p><strong><font color="red"> 最大后验估计不只是关注当前的样本的情况，还关注已经发生过的先验知识。在朴素贝叶斯中会有最大后验概率的应用，但并没有用上最大后验估计来求参数（因为朴素贝叶斯中的θ其实就是分类的类别）。</font></strong></p>
<p><strong>最大后验估计和最大似然估计的区别：</strong>最大后验估计允许我们把先验知识加入到估计模型中，<strong>这在样本很少的时候是很有用的（因此朴素贝叶斯在较少的样本下就能有很好的表现）</strong>，因为样本很少的时候我们的观测结果很可能出现偏差，此时先验知识会把估计的结果“拉”向先验，实际的预估结果将会在先验结果的两侧形成一个顶峰。通过调节先验分布的参数，比如beta分布的α，β，我们还可以调节把估计的结果“拉”向先验的幅度，α，β越大，这个顶峰越尖锐。这样的参数，我们叫做预估模型的“超参数”。</p>
<h2 id="朴素贝叶斯-Q-amp-A"><a href="#朴素贝叶斯-Q-amp-A" class="headerlink" title="朴素贝叶斯 Q&amp;A"></a>朴素贝叶斯 Q&amp;A</h2><blockquote>
<ul>
<li>朴素贝叶斯分类器原理以及公式，出现估计概率值为 0 怎么处理（拉普拉斯平滑），缺点；</li>
<li>解释贝叶斯公式和朴素贝叶斯分类。</li>
<li>贝叶斯分类，这是一类分类方法，主要代表是朴素贝叶斯，朴素贝叶斯的原理，重点在假设各个属性类条件独立。然后能根据贝叶斯公式具体推导。考察给你一个问题，如何利用朴素贝叶斯分类去分类，比如：给你一个人的特征，判断是男是女，比如身高，体重，头发长度等特征的的数据，那么你要能推到这个过程。给出最后的分类器公式。</li>
<li>那你说说贝叶斯怎么分类啊？<strong>比如说看看今天天气怎么样？</strong>我：blabla，，，利用天气的历史数据，可以知道天气类型的先验分布，以及每种类型下特征数据（比如天气数据的特征：温度啊，湿度啊）的条件分布，这样我们根据贝叶斯公式就能求得天气类型的后验分布了。。。。面试官：en（估计也比较满意吧）<strong>那你了解关于求解模型的优化方法吗？一般用什么优化方法来解？</strong></li>
<li>贝叶斯分类器的优化和特殊情况的处理</li>
</ul>
</blockquote>
<h3 id="1、朴素贝叶斯、SVM和LR的区别？"><a href="#1、朴素贝叶斯、SVM和LR的区别？" class="headerlink" title=" 1、朴素贝叶斯、SVM和LR的区别？"></a><strong><font color="red"> 1、朴素贝叶斯、SVM和LR的区别？</font></strong></h3><p><strong>朴素贝叶斯是生成模型</strong>，根据已有样本进行贝叶斯估计学习出先验概率P(Y)和条件概率P(X|Y)，进而求出联合分布概率P(XY),最后利用贝叶斯定理求解P(Y|X)。</p>
<p><strong>LR是判别模型</strong>，根据极大化对数似然函数直接求出条件概率P(Y|X)；朴素贝叶斯是基于很强的条件独立假设（在已知分类Y的条件下，各个特征变量取值是相互独立的），而LR则对此没有要求；<strong>朴素贝叶斯适用于数据集少的情景，而LR适用于大规模数据集。</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>SVM</th>
<th>LR</th>
<th>朴素贝叶斯</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>思想</strong></td>
<td><strong>想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面</strong>。</td>
<td>使用线性回归模型的预测值逼近分类任务真实标记的对数几率。</td>
<td>基于<strong>贝叶斯定理</strong>与<strong>特征条件假设</strong>的<strong>分类</strong>方法。选出各个分类类别后验概率最大的作为最终分类。</td>
</tr>
<tr>
<td><strong>输出</strong></td>
<td>判别模型、<strong>非概率方法</strong>；</td>
<td><strong>概率方法</strong>；需要对$p(y</td>
<td>x)$进行假设，具有概率意义。</td>
<td>生成模型</td>
</tr>
<tr>
<td><strong>经验损失函数</strong></td>
<td><strong>合页损失函数</strong>；有一段平的零区域、使得SVM的对偶性有稀疏性。</td>
<td><strong>交叉熵损失函数</strong></td>
<td><strong>后验概率最大</strong></td>
</tr>
<tr>
<td><strong>训练样本</strong></td>
<td><strong>支持向量</strong>（少数样本），SVM的参数和假设函数只和支持向量有关。</td>
<td>全样本</td>
<td>全样本</td>
</tr>
<tr>
<td><strong>优化方法</strong></td>
<td>次梯度下降和坐标梯度下降 【<strong>SMO算法</strong>】</td>
<td><strong>梯度下降</strong></td>
<td>无</td>
</tr>
<tr>
<td>多分类</td>
<td><strong>多分类SVM</strong></td>
<td><strong>Softmax回归</strong></td>
<td>后验概率最大</td>
</tr>
<tr>
<td><strong>敏感程度</strong></td>
<td><strong>SVM考虑分类边界线附近的样本</strong>（决定分类超平面的样本）。在支持向量外添加或减少任何样本点对分类决策面没有任何影响；【不敏感】</td>
<td><strong>LR受所有数据点的影响</strong>。直接依赖数据分布，每个样本点都会影响决策面的结果。如果训练数据不同类别严重不平衡。【敏感】</td>
<td><strong>特征值是基于频数进行统计的。</strong>一个值的异常（变成了别的数），<strong>只是贝叶斯公式里的计算概率的分子或者分母发生微小的变化，整体结果影响不大</strong>，不敏感【概率排序】</td>
</tr>
</tbody>
</table>
</div>
<h3 id="2、朴素贝叶斯“朴素”在哪里？"><a href="#2、朴素贝叶斯“朴素”在哪里？" class="headerlink" title="2、朴素贝叶斯“朴素”在哪里？"></a>2、<strong>朴素贝叶斯“朴素”在哪里？</strong></h3><p>简单来说：它假定<strong>所有的特征在数据集中的作用是同样重要和独立的</strong>，正如我们所知，这个假设在现实世界中是很不真实的，因此，说朴素贝叶斯真的很“朴素”。</p>
<p>利用贝叶斯定理求解联合概率P(XY)时，需要计算条件概率P(X|Y)。在计算P(X|Y)时，朴素贝叶斯做了一个很强的条件独立假设（当Y确定时，X的各个分量取值之间相互独立），即P(X1=x1,X2=x2,…Xj=xj|Y=yk) = P(X1=x1|Y=yk)P(X2=x2|Y=yk)…*P(Xj=xj|Y=yk)。 多个特征全是独立的，需要分别相乘。</p>
<h3 id="3、在估计条件概率P-X-Y-时出现概率为0的情况怎么办？"><a href="#3、在估计条件概率P-X-Y-时出现概率为0的情况怎么办？" class="headerlink" title="3、在估计条件概率P(X|Y)时出现概率为0的情况怎么办？"></a>3、<strong>在估计条件概率P(X|Y)时出现概率为0的情况怎么办？</strong></h3><p><strong>拉普拉斯平滑法</strong>是朴素贝叶斯中处理零概率问题的一种修正方式。在进行分类的时候，可能会出现某个属性在训练集中没有与某个类同时出现过的情况，如果直接基于朴素贝叶斯分类器的表达式进行计算的话就会出现<strong>零概率现象</strong>。</p>
<p>为了避免其他属性所携带的信息被训练集中未出现过的属性值“抹去”，所以才使用拉普拉斯估计器进行修正。具体的方法是：<strong>在分子上加1,对于先验概率，在分母上加上训练集中label的类别数；对于特征i 在label下的条件概率，则在分母上加上第i个属性可能的取值数（特征 i 的unique()）</strong></p>
<p><strong>先验概率</strong>的贝叶斯估计：</p>
<p><img src="image-20230129161943432.png" alt="image-20230129161943432" style="zoom:50%;"></p>
<p><strong>条件概率</strong>的贝叶斯估计：【<strong>离散型</strong>】</p>
<p><img src="image-20230129162002522.png" alt="image-20230129162002522" style="zoom:50%;"></p>
<h3 id="4、先验概率和后验概率都是？"><a href="#4、先验概率和后验概率都是？" class="headerlink" title="4、先验概率和后验概率都是？"></a>4、<strong>先验概率和后验概率都是？</strong></h3><p><strong>先验概率是指根据以往经验和分析得到的概率</strong>,如全概率公式,它往往作为”由因求果”问题中的”因”出现.<strong>后验概率是基于新的信息，修正原来的先验概率后所获得的更接近实际情况的概率估计。</strong></p>
<p><strong>先验概率和后验概率是相对的。</strong>如果以后还有新的信息引入，更新了现在所谓的后验概率，得到了新的概率值，那么这个新的概率值被称为后验概率。</p>
<h3 id="5、朴素贝叶斯算法的前提假设是什么？"><a href="#5、朴素贝叶斯算法的前提假设是什么？" class="headerlink" title="5、朴素贝叶斯算法的前提假设是什么？"></a>5、<strong>朴素贝叶斯算法的前提假设是什么？</strong></h3><ol>
<li>特征之间相互独立</li>
<li>每个特征同等重要</li>
</ol>
<h3 id="6、面试的时候怎么标准回答朴素贝叶斯呢？"><a href="#6、面试的时候怎么标准回答朴素贝叶斯呢？" class="headerlink" title="6、面试的时候怎么标准回答朴素贝叶斯呢？"></a>6、<strong>面试的时候怎么标准回答朴素贝叶斯呢？</strong></h3><p>首先朴素贝斯是一个<strong>生成模型（很重要）</strong>，其次它通过学习已知样本，计算出联合概率，再求条件概率。</p>
<h4 id="生成模式和判别模式的区别-常见-："><a href="#生成模式和判别模式的区别-常见-：" class="headerlink" title="生成模式和判别模式的区别(常见)："></a><strong>生成模式和判别模式的区别(常见)：</strong></h4><p><strong>生成模式</strong>：由数据学得<strong>联合概率分布，求出条件概率分布P(Y|X)的预测模型</strong>；<strong>比较在乎数据是怎么生成的</strong>；常见的生成模型有：朴素贝叶斯、隐马尔可夫模型、高斯混合模型、文档主题生成模型（LDA）、限制玻尔兹曼机。</p>
<p><strong>判别模式</strong>：由数据学得<strong>决策函数或条件概率分布作为预测模型</strong>，<strong>要关注在数据的差异分布上，而不是生成</strong>；常见的判别模型有：K近邻、SVM、决策树、感知机、线性判别分析（LDA）、线性回归、传统的神经网络、逻辑斯蒂回归、boosting、条件随机场。</p>
<h3 id="7、为什么属性独立性假设在实际情况中很难成立，但朴素贝叶斯仍能取得较好的效果-【排序能力】"><a href="#7、为什么属性独立性假设在实际情况中很难成立，但朴素贝叶斯仍能取得较好的效果-【排序能力】" class="headerlink" title="7、为什么属性独立性假设在实际情况中很难成立，但朴素贝叶斯仍能取得较好的效果?【排序能力】"></a>7、<strong>为什么属性独立性假设在实际情况中很难成立，但朴素贝叶斯仍能取得较好的效果?</strong>【排序能力】</h3><p>首先独立性假设在实际中不存在，确实会导致朴素贝叶斯不如一些其他算法，但是就算法本身而言，朴素贝叶斯也会有不错的分类效果，原因是：</p>
<ul>
<li><strong>分类问题看中的是类别的条件概率的排序</strong>，而不是具体的概率值，所以这里面对精准概率值的计算是有一定的容错的。</li>
<li>如果特征属性之间的依赖对所有类别影响相同，或依赖关系的影响能相互抵消，则属性条件独立性假设在降低计算开销的同时不会对性能产生负面影响。</li>
</ul>
<h3 id="8、朴素贝叶斯中概率计算的下溢问题如何解决？"><a href="#8、朴素贝叶斯中概率计算的下溢问题如何解决？" class="headerlink" title=" 8、朴素贝叶斯中概率计算的下溢问题如何解决？"></a><strong><font color="red"> 8、朴素贝叶斯中概率计算的下溢问题如何解决？</font></strong></h3><p><strong>在朴素贝叶斯的计算过程中，需要对特定分类中各个特征出现的概率进行连乘</strong>，小数相乘，越乘越小，这样就造成下溢出。在程序中，在相应小数位置进行四舍五入，计算结果可能就变成0了。</p>
<p>为了解决这个问题，<strong>对乘积结果取自然对数</strong>。将小数的乘法操作转化为取对数后的加法操作，规避了变为0的风险同时并不影响分类结果。</p>
<h3 id="9、朴素贝叶斯分类器对异常值和缺失值敏感吗？"><a href="#9、朴素贝叶斯分类器对异常值和缺失值敏感吗？" class="headerlink" title="9、朴素贝叶斯分类器对异常值和缺失值敏感吗？"></a>9、<strong>朴素贝叶斯分类器对异常值和缺失值敏感吗？</strong></h3><p>回想朴素贝叶斯的计算过程，它在推理的时候，输入的某个特征组合，<strong>他们的特征值在训练的时候在贝叶斯公式中都是基于频数进行统计的。</strong>所以一个值的异常（变成了别的数），<strong>只是贝叶斯公式里的计算概率的分子或者分母发生微小的变化，整体结果影响不大</strong>，就算微微影响最终概率值的获得，由于<strong>分类问题只关注概率的排序而不关注概率的值，所以影响不大</strong>，保留异常值还可以提高模型的泛化性能。</p>
<p>缺失值也是一样，如果一个数据实例缺失了一个属性的数值，在建模的时将被忽略，不影响类条件概率的计算，在预测时，计算数据实例是否属于某类的概率时也将忽略缺失属性，不影响最终结果。</p>
<h3 id="10、朴素贝叶斯中有没有超参数可以调？"><a href="#10、朴素贝叶斯中有没有超参数可以调？" class="headerlink" title="10、朴素贝叶斯中有没有超参数可以调？"></a>10、<strong>朴素贝叶斯中有没有超参数可以调？</strong></h3><p><strong>朴素贝叶斯是没有超参数可以调的，所以它不需要调参</strong>，朴素贝叶斯是根据训练集进行分类，分类出来的结果基本上就是确定了的，拉普拉斯估计器不是朴素贝叶斯中的参数，不能通过拉普拉斯估计器来对朴素贝叶斯调参。</p>
<h3 id="11、朴素贝叶斯有哪三个模型？"><a href="#11、朴素贝叶斯有哪三个模型？" class="headerlink" title="11、朴素贝叶斯有哪三个模型？"></a>11、<strong>朴素贝叶斯有哪三个模型？</strong></h3><ul>
<li><strong>多项式模型对应于离散变量</strong>，其中离散变量指的是category型变量，也就是类别变量，比如性别；连续变量一般是数字型变量，比如年龄，身高，体重。</li>
<li><strong>高斯模型 对应于连续变量</strong>（每一维服从正态分布）</li>
<li><strong>伯努利模型</strong> <strong>对应于文本分类</strong> （特征只能是0或者1）</li>
</ul>
<h3 id="12、朴素贝叶斯为什么适合增量计算？"><a href="#12、朴素贝叶斯为什么适合增量计算？" class="headerlink" title=" 12、朴素贝叶斯为什么适合增量计算？"></a><strong><font color="red"> 12、朴素贝叶斯为什么适合增量计算？</font></strong></h3><p>朴素贝叶斯在训练过程中实际上需要<strong>计算出各个类别的概率和各个特征的条件概率</strong>，这些概率以频数统计比值（对于多项式模型而言）的形式产生概率值，<strong>可以快速根据增量数据进行更新，无需重新全量训练，所以其十分适合增量计算。</strong></p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/07/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%888%EF%BC%89%E3%80%90Nan%E3%80%91CRF/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/06/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%888%EF%BC%89%E3%80%90Nan%E3%80%91%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="马尔可夫模型"><a href="#马尔可夫模型" class="headerlink" title="马尔可夫模型"></a>马尔可夫模型</h2><blockquote>
<p>  如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？ - Scofield的回答 - 知乎 <a href="https://www.zhihu.com/question/35866596/answer/236886066">https://www.zhihu.com/question/35866596/answer/236886066</a></p>
</blockquote>
<h3 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a>一、概念</h3><h4 id="1-1-随机过程"><a href="#1-1-随机过程" class="headerlink" title="1.1 随机过程"></a>1.1 随机过程</h4><p><strong>随机过程就是一些统计模型，利用这些统计模型可以对自然界的一些事物进行预测和处理</strong>，比如天气预报，比如股票，比如市场分析，比如人工智能。它的应用还真是多了去了。</p>
<h4 id="1-2-马尔可夫链-（Markov-Chain）"><a href="#1-2-马尔可夫链-（Markov-Chain）" class="headerlink" title="1.2 马尔可夫链 （Markov Chain）"></a>1.2 马尔可夫链 （Markov Chain）</h4><blockquote>
<p>  马尔可夫链 （Markov Chain）是什么鬼 - 车卡门的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/26453269">https://zhuanlan.zhihu.com/p/26453269</a></p>
</blockquote>
<p>马尔可夫链就是这样一个任性的过程，它将来的状态分布只取决于现在，跟过去无关！实际上就是一个随机变量随时间按照Markov性进行变化的过程。</p>
<h4 id="1-3-马尔可夫模型（Hidden-Markov-Models）"><a href="#1-3-马尔可夫模型（Hidden-Markov-Models）" class="headerlink" title="1.3 马尔可夫模型（Hidden Markov Models）"></a>1.3 马尔可夫模型（Hidden Markov Models）</h4><p>既是马尔可夫模型，就一定存在<a href="https://www.zhihu.com/search?q=马尔可夫链&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A&quot;64187492&quot;}">马尔可夫链</a>，该马尔可夫链服从马尔可夫性质：即无记忆性。也就是说，这一时刻的状态，受且只受前一时刻的影响，而不受更往前时刻的状态的影响。在这里我们仍然使用非常简单的天气模型来做说明。</p>
<p><img src="https://picx.zhimg.com/80/648a55725e67d718d97d6a475891d70b_1440w.png" alt="img" style="zoom:50%;"></p>
<p>在这个马尔可夫模型中，存在三个状态，Sunny， Rainy， Cloudy，同时图片上标的是各个状态间的转移概率（如果不明白什么是转移概率，那建议先去学习什么是马尔可夫再来看HMM）。</p>
<p><strong><font color="red"> 现在我们要说明什么是 HMM。既是隐形，说明这些状态是观测不到的，相应的，我们可以通过其他方式来『猜测』或是『推断』这些状态，这也是 HMM 需要解决的问题之一。</font></strong></p>
<blockquote>
<p>  举个例子，我女朋友现在在北京工作，而我还在法国读书。每天下班之后，她会根据天气情况有相应的活动：或是去商场购物，或是去公园散步，或是回家收拾房间。我们有时候会通电话，她会告诉我她这几天做了什么，而闲着没事的我呢，则要通过她的行为猜测这几天对应的天气最有可能是什么样子的。</p>
<p>  以上就是一个简单的 HMM，天气状况属于状态序列，而她的行为则属于观测序列。天气状况的转换是一个马尔可夫序列。而根据天气的不同，有相对应的概率产生不同的行为。在这里，为了简化，把天气情况简单归结为晴天和雨天两种情况。雨天，她选择去散步，购物，收拾的概率分别是0.1，0.4，0.5， 而如果是晴天，她选择去散步，购物，收拾的概率分别是0.6，0.3，0.1。而天气的转换情况如下：这一天下雨，则下一天依然下雨的概率是0.7，而转换成晴天的概率是0.3；这一天是晴天，则下一天依然是晴天的概率是0.6，而转换成雨天的概率是0.4. 同时还存在一个初始概率，也就是第一天下雨的概率是0.6， 晴天的概率是0.4.</p>
<p>  <img src="https://pic4.zhimg.com/80/792e033ff9b0418b3b6c9bbaef30fd83_1440w.png" alt="img" style="zoom:50%;"></p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/02/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%889%EF%BC%89%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<h2 id="【机器学习】决策树（上）——ID3、C4-5、CART"><a href="#【机器学习】决策树（上）——ID3、C4-5、CART" class="headerlink" title="【机器学习】决策树（上）——ID3、C4.5、CART"></a>【机器学习】决策树（上）——ID3、C4.5、CART</h2><p><strong>决策树</strong>是一个非常常见并且优秀的机器学习算法，它易于理解、可解释性强，其可作为分类算法，也可用于回归模型。本文将分三篇介绍决策树，第一篇介绍基本树（包括 <strong>ID3、C4.5、CART</strong>），第二篇介绍 <strong>Random Forest、Adaboost、GBDT</strong>，第三篇介绍 <strong>Xgboost</strong> 和 <strong>LightGBM</strong>。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>ID3（==分类==）</th>
<th>C4.5（==分类==）</th>
<th>CART（==分类和回归==）</th>
</tr>
</thead>
<tbody>
<tr>
<td>思想</td>
<td>奥卡姆剃刀：越是小型的决策树越优于大的决策树;ID3 算法的核心思想就是以<strong>信息增益</strong>来度量特征选择，选择信息增益最大的特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间。</td>
<td>C4.5 算法最大的特点是<strong>克服了 ID3 对特征数目的偏重</strong>这一缺点，引入<strong>信息增益率</strong>来作为分类标准。</td>
<td>CART 算法的二分法可以<strong>简化决策树的规模</strong>，提高生成决策树的效率。CART 包含的基本过程有<strong>分裂</strong>，<strong>剪枝</strong>和<strong>树选择</strong>。</td>
</tr>
<tr>
<td><strong>划分标准</strong></td>
<td><strong>信息增益</strong>  =  类别熵 - 特征类别熵                                <strong>类别熵</strong>：$H(D)=-\sum_{k=1}^{K} \frac{\left</td>
<td>C_{k}\right</td>
<td>}{</td>
<td>D</td>
<td>} \log _{2} \frac{\left</td>
<td>C_{k}\right</td>
<td>}{</td>
<td>D</td>
<td>}$                 <strong>特征类别熵</strong>：$H(D \mid A)=\sum_{i=1}^{n} \frac{\left</td>
<td>D_{i}\right</td>
<td>}{</td>
<td>D</td>
<td>} H\left(D_{i}\right)$</td>
<td>先从候选划分特征中找到信息增益高于平均值的特征，再从中选择<strong>增益率</strong>最高的。</td>
<td><strong>Gini 系数</strong>作为变量的<strong>不纯度量</strong>，<strong>减少了大量的对数运算</strong>；$G i n i(D)=\sum_{k=1}^{K} \frac{\left</td>
<td>C_{k}\right</td>
<td>}{</td>
<td>D</td>
<td>}\left(1-\frac{\left</td>
<td>C_{k}\right</td>
<td>}{</td>
<td>D</td>
<td>}\right)$</td>
</tr>
<tr>
<td>剪枝策略</td>
<td><strong>无</strong></td>
<td><strong>悲观剪枝策略</strong></td>
<td>基于<strong>代价复杂度剪枝</strong></td>
</tr>
<tr>
<td>数据差异</td>
<td><strong>离散</strong>数据且<strong>缺失值</strong>敏感</td>
<td><strong>离散</strong>、<strong>连续特征离散化</strong>；【排序+离散化】</td>
<td><strong>连续型、离散型</strong></td>
</tr>
<tr>
<td><strong>连续值处理</strong></td>
<td>无</td>
<td><strong>排序</strong>并取相邻两样本值的<strong>平均数</strong>。</td>
<td><strong>排序</strong>并取相邻两样本值的<strong>平均数</strong>。<strong>CART 分类树</strong>【<strong>基尼系数</strong>】。<strong>回归树</strong>【<strong>和方差度量</strong>】。</td>
</tr>
<tr>
<td>缺失值处理</td>
<td><strong>无</strong></td>
<td>1、有缺失值特征，用没有缺失的样本子集所占比重来折算；2、将样本同时划分到所有子节点</td>
<td><strong>代理测试</strong>来估计缺失值</td>
</tr>
<tr>
<td>类别不平衡</td>
<td><strong>无</strong></td>
<td><strong>无</strong></td>
<td><strong>先验机制</strong>：其作用相当于对数据自动重加权，对类别进行均衡。</td>
</tr>
<tr>
<td><strong>==缺点==</strong></td>
<td>1、ID3 没有剪枝策略，容易过拟合；2、信息增益准则对可取值<strong>数目较多的特征有所偏好</strong>，类似“编号”的特征其信息增益接近于 1； 3、只能用于处理离散分布的特征； 没有考虑缺失值。</td>
<td>1、<strong>多叉树</strong>。2、<strong>只能用于分类</strong>。3、熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>。4、驻留于内存的数据集。</td>
<td>熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>。</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><strong>划分标准的差异：</strong>ID3 使用信息增益偏向特征值多的特征，C4.5 使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART 使用基尼指数克服 C4.5 需要求 log 的巨大计算量，偏向于特征值较多的特征。</li>
<li><strong>使用场景的差异：</strong>ID3 和 C4.5 都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5 是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li>
<li><strong>样本数据的差异：</strong>ID3 只能处理离散数据且缺失值敏感，C4.5 和 CART 可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议 C4.5、大样本建议 CART。C4.5 处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART 本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li>
<li><strong>样本特征的差异：</strong>ID3 和 C4.5 层级之间只使用一次特征，==CART 可多次重复使用特征==；</li>
<li><strong>剪枝策略的差异：</strong>ID3 没有剪枝策略，C4.5 是通过<strong>悲观剪枝策略</strong>来修正树的准确性，而 CART 是通过<strong>代价复杂度</strong>剪枝。</li>
</ul>
<h2 id="1-ID3【删特征】"><a href="#1-ID3【删特征】" class="headerlink" title="1. ID3【删特征】"></a>1. ID3【删特征】</h2><p>ID3 算法是建立在奥卡姆剃刀[<strong>“切勿浪费较多东西去做，用较少的东西，同样可以做好的事情”</strong>]（用较少的东西，同样可以做好事情）的基础上：越是小型的决策树越优于大的决策树。</p>
<h3 id="1-1-思想"><a href="#1-1-思想" class="headerlink" title="1.1 思想"></a>1.1 思想</h3><p>从信息论的知识中我们知道：信息熵越大，从而样本纯度越低，。ID3 算法的核心思想就是以<strong>信息增益</strong>来度量特征选择，选择信息增益最大的特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间（C4.5 也是贪婪搜索）。 其大致步骤为：</p>
<ol>
<li>初始化特征集合和数据集合；</li>
<li>计算数据集合信息熵和所有特征的条件熵，选择信息增益最大的特征作为当前决策节点；</li>
<li>更新数据集合和特征集合（删除上一步使用的特征，并按照特征值来划分不同分支的数据集合）；</li>
<li>重复 2，3 两步，若子集值包含单一特征，则为分支叶子节点。</li>
</ol>
<h3 id="1-2-划分标准"><a href="#1-2-划分标准" class="headerlink" title="1.2 划分标准"></a>1.2 划分标准</h3><p>ID3 使用的分类标准是信息增益，它表示得知特征 A 的信息而使得样本集合不确定性减少的程度。</p>
<p>数据集的<strong>信息熵</strong>：</p>
<p>$H(D)=-\sum_{k=1}^{K} \frac{\left|C_{k}\right|}{|D|} \log _{2} \frac{\left|C_{k}\right|}{|D|}$</p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=C_k" alt="[公式]"> 表示集合 D 中属于第 k 类样本的样本子集。针对某个特征 A，对于数据集 D 的条件熵 $H(D \mid A)$为：</p>
<p>$\begin{aligned} H(D \mid A) &amp;=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} H\left(D_{i}\right) \\ &amp;=-\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|}\left(\sum_{k=1}^{K} \frac{\left|D_{i k}\right|}{\left|D_{i}\right|} \log _{2} \frac{\left|D_{i k}\right|}{\left|D_{i}\right|}\right) \end{aligned}$</p>
<p><strong>信息增益</strong> = 信息熵 - 条件熵。信息增益越大表示使用特征 A 来划分所获得的“纯度提升越大”。</p>
<p><img src="https://www.zhihu.com/equation?tex=Gain%28D%2CA%29%3DH%28D%29-H%28D%7CA%29++%5C%5C" alt="[公式]"></p>
<p>信息增益越大表示使用特征 A 来划分所获得的“纯度提升越大”。</p>
<h3 id="1-3-缺点【没有剪枝、特征偏好、缺失值】"><a href="#1-3-缺点【没有剪枝、特征偏好、缺失值】" class="headerlink" title="1.3 缺点【没有剪枝、特征偏好、缺失值】"></a>1.3 缺点【没有剪枝、特征偏好、缺失值】</h3><ul>
<li>ID3 没有剪枝策略，容易过拟合；</li>
<li>信息增益准则==对可取值数目较多的特征==有所偏好，类似“编号”的特征其信息增益接近于 1；</li>
<li>只能用于处理离散分布的特征；</li>
<li>没有考虑缺失值。</li>
</ul>
<h2 id="2-C4-5"><a href="#2-C4-5" class="headerlink" title="2. C4.5"></a>2. C4.5</h2><p>C4.5 算法最大的特点是克服了 ID3 对==特征数目的偏重==这一缺点，引入信息增益率来作为分类标准。</p>
<p>C4.5 相对于 ID3 的缺点对应有以下改进方式： </p>
<ul>
<li>引入<strong>悲观剪枝策略进行后剪枝</strong>； </li>
<li>引入<strong>信息增益率</strong>作为划分标准； </li>
<li><strong>将连续特征离散化</strong>，假设 n 个样本的连续特征 A 有 m 个取值，C4.5 将其排序并取相邻两样本值的平均数共 m-1 个划分点，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点； </li>
<li>对于<strong>缺失值的处理</strong>可以分为两个子问题：</li>
<li>问题一：在特征值缺失的情况下进行划分特征的选择？（即如何计算特征的信息增益率）<ul>
<li>C4.5 的做法是：对于具有缺失值特征，用没有缺失的样本子集所占比重来折算；</li>
</ul>
</li>
<li>问题二：选定该划分特征，对于缺失该特征值的样本如何处理？（即到底把这个样本划分到哪个结点里） <ul>
<li>C4.5 的做法是：将样本同时划分到所有子节点，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</li>
</ul>
</li>
</ul>
<h3 id="2-2-划分标准"><a href="#2-2-划分标准" class="headerlink" title="2.2 划分标准"></a>2.2 划分标准</h3><p>利用信息增益率可以克服信息增益的缺点，其公式为</p>
<p>$\begin{aligned} \operatorname{Gain}_{\text {ratio }}(D, A) &amp;=\frac{\operatorname{Gain}(D, A)}{H_{A}(D)}     \\ H_{A}(D)=-\sum_{i=1}^{n}   \frac{\left|D_{i}\right|}{|D|} \log _{2} \frac{\left|D_{i}\right|}{|D|} \end{aligned}$</p>
<p>信息增益率对可取值较少的特征有所偏好（分母越小，整体越大），因此 C4.5 并不是直接用增益率最大的特征进行划分，而是使用一个<strong>启发式方法</strong>：先从候选划分特征中找到信息增益高于平均值的特征，再从中选择增益率最高的。</p>
<h3 id="2-3-剪枝策略"><a href="#2-3-剪枝策略" class="headerlink" title="2.3 剪枝策略"></a>2.3 剪枝策略</h3><p>为什么要剪枝：<strong>过拟合的树在泛化能力的表现非常差。</strong></p>
<p><strong>预剪枝和悲观剪枝</strong></p>
<h4 id="2-3-1-预剪枝"><a href="#2-3-1-预剪枝" class="headerlink" title="2.3.1 预剪枝"></a><strong>2.3.1 预剪枝</strong></h4><p>在节点划分前来确定是否继续增长，及早停止增长的主要方法有：</p>
<ul>
<li>节点内数据样本低于<strong>某一阈值</strong>；</li>
<li>所有节点特征都已分裂；</li>
<li>节点划分前准确率比划分后准确率高。</li>
</ul>
<p>预剪枝不仅可以降低过拟合的风险而且还可以减少训练时间，但另一方面它是基于“贪心”策略，会带来欠拟合风险。</p>
<h4 id="2-3-2-后剪枝【悲观剪枝方法】-http-gitlinux-net-2019-06-04-C45"><a href="#2-3-2-后剪枝【悲观剪枝方法】-http-gitlinux-net-2019-06-04-C45" class="headerlink" title="2.3.2 后剪枝【悲观剪枝方法】  http://gitlinux.net/2019-06-04-C45/"></a><strong>2.3.2 后剪枝</strong>【悲观剪枝方法】  <a href="http://gitlinux.net/2019-06-04-C45/">http://gitlinux.net/2019-06-04-C45/</a></h4><p>在已经生成的决策树上进行剪枝，从而得到简化版的剪枝决策树。</p>
<p>C4.5 采用的<strong>悲观剪枝方法</strong>，用递归的方式从低往上针对每一个非叶子节点，评估用一个最佳叶子节点去代替这课子树是否有益。如果剪枝后与剪枝前相比其错误率是保持或者下降，则这棵子树就可以被替换掉。<strong>C4.5 通过训练数据集上的错误分类数量来估算未知样本上的错误率</strong>。</p>
<p>后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但同时其训练时间会大的多。</p>
<h3 id="2-4-缺点"><a href="#2-4-缺点" class="headerlink" title="2.4 缺点"></a>2.4 缺点</h3><ul>
<li><strong>剪枝策略</strong>可以再优化；</li>
<li>C4.5 用的是<strong>多叉树</strong>，用二叉树效率更高；</li>
<li>C4.5 只能用于<strong>分类</strong>；</li>
<li>C4.5 使用的熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>；</li>
<li>C4.5 在构造树的过程中，<strong>对数值属性值需要按照其大小进行排序</strong>，从中选择一个分割点，所以只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时，程序无法运行。</li>
</ul>
<h2 id="3-CART"><a href="#3-CART" class="headerlink" title="3. CART"></a>3. CART</h2><p>ID3 和 C4.5 虽然在对训练样本集的学习中可以尽可能多地挖掘信息，但是其生成的决策树分支、规模都比较大，CART 算法的二分法可以简化决策树的规模，提高生成决策树的效率。</p>
<h3 id="3-1-思想"><a href="#3-1-思想" class="headerlink" title="3.1 思想"></a>3.1 思想</h3><p>CART 包含的基本过程有分裂，剪枝和树选择。 </p>
<ul>
<li><strong>分裂：</strong>分裂过程是一个二叉递归划分过程，其输入和预测特征既可以是连续型的也可以是离散型的，CART 没有停止准则，会一直生长下去； </li>
<li><strong>剪枝：</strong>采用<strong>代价复杂度剪枝</strong>，从最大树开始，每次选择训练数据熵对整体性能贡献最小的那个分裂节点作为下一个剪枝对象，直到只剩下根节点。CART 会产生一系列嵌套的剪枝树，需要从中选出一颗最优的决策树； </li>
<li><strong>树选择：</strong>用单独的测试集评估每棵剪枝树的预测性能（也可以用交叉验证）。</li>
</ul>
<p>CART 在 C4.5 的基础上进行了很多提升。 </p>
<ul>
<li>C4.5 为多叉树，运算速度慢，CART 为<strong>二叉树</strong>，运算速度快； </li>
<li>C4.5 只能分类，CART 既可以分类也可以<strong>回归</strong>； </li>
<li>CART 使用 ==<strong>Gini 系数作为变量的不纯度量</strong>，减少了<strong>大量的对数运算</strong>；== </li>
<li>CART 采用<strong>代理测试来估计缺失值</strong>，而 C4.5 以不同概率划分到不同节点中； </li>
<li>CART 采用<strong>“基于代价复杂度剪枝”方法进行剪枝，而 C4.5 采用悲观剪枝方法</strong>。</li>
</ul>
<h3 id="3-2-划分标准"><a href="#3-2-划分标准" class="headerlink" title="3.2 划分标准"></a>3.2 划分标准</h3><p><strong>熵模型拥有大量耗时的对数运算</strong>，基尼指数在简化模型的同时还保留了熵模型的优点。基尼指数代表了模型的不纯度，基尼系数越小，不纯度越低，特征越好。这和信息增益（率）正好相反。</p>
<p>$\begin{aligned} \operatorname{Gini}(D) &amp;=\sum_{k=1}^{K} \frac{\left|C_{k}\right|}{|D|}\left(1-\frac{\left|C_{k}\right|}{|D|}\right) =1- \sum_{k=1}^{K}\left(\frac{\left|C_{k}\right|}{|D|}\right)^{2}  &amp;\operatorname{Gini}(D \mid A) =\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} \operatorname{Gini}\left(D_{i}\right) \end{aligned}$</p>
<p>==<strong>基尼指数</strong>反映了从<strong>数据集中随机抽取两个样本，其类别标记不一致的概率</strong>==。因此基尼指数越小，则数据集纯度越高。基尼指数偏向于特征值较多的特征，类似信息增益。基尼指数可以用来度量任何不均匀分布，是介于 0~1 之间的数，0 是完全相等，1 是完全不相等，<strong>基尼指数可以理解为熵模型的一阶泰勒展开。</strong></p>
<blockquote>
<p>  <strong><em>基尼指数是信息熵中﹣logP在P=1处一阶泰勒展开后的结果！所以两者都可以用来度量数据集的纯度</em></strong></p>
</blockquote>
<h3 id="3-3-缺失值处理"><a href="#3-3-缺失值处理" class="headerlink" title="3.3 缺失值处理"></a>3.3 缺失值处理</h3><p>上文说到，模型对于缺失值的处理会分为两个子问题：</p>
<ul>
<li><strong>如何在特征值缺失的情况下进行划分特征的选择？</strong></li>
</ul>
<p>对于问题 1，<strong>CART 一开始严格要求分裂特征评估时只能使用在该特征上没有缺失值的那部分数据，在后续版本中，CART 算法使用了一种惩罚机制来抑制提升值，从而反映出缺失值的影响</strong>（例如，如果一个特征在节点的 20% 的记录是缺失的，那么这个特征就会减少 20% 或者其他数值）。</p>
<ul>
<li><strong>选定该划分特征，模型对于缺失该特征值的样本该进行怎样处理？</strong></li>
</ul>
<p>对于问题 2，CART 算法的机制是为树的每个节点都找到<strong>代理分裂器</strong>，无论在训练数据上得到的树是否有缺失值都会这样做。在代理分裂器中，特征的分值必须超过默认规则的性能才有资格作为代理（即代理就是<strong>代替缺失值特征作为划分特征的特征</strong>），<strong>当 CART 树中遇到缺失值时，这个实例划分到左边还是右边是决定于其排名最高的代理，如果这个代理的值也缺失了，那么就使用排名第二的代理</strong>，以此类推，如果所有代理值都缺失，那么默认规则就是把样本划分到较大的那个子节点。代理分裂器可以确保无缺失训练数据上得到的树可以用来处理包含确实值的新数据。</p>
<h3 id="3-4-剪枝策略"><a href="#3-4-剪枝策略" class="headerlink" title="3.4 剪枝策略"></a>3.4 剪枝策略</h3><p><strong>基于代价复杂度的剪枝</strong>:<a href="https://www.bilibili.com/read/cv11066239">https://www.bilibili.com/read/cv11066239</a></p>
<p>采用一种<strong>“基于代价复杂度的剪枝</strong>”方法进行<strong>后剪枝</strong>，这种方法会生成一系列树，每<strong>个树都是通过将前面的树的某个或某些子树替换成一个叶节点而得到的，这一系列树中的最后一棵树仅含一个用来预测类别的叶节点</strong>。然后用一种成本复杂度的度量准则来判断哪棵子树应该被一个预测类别值的叶节点所代替。<strong>这种方法需要使用一个单独的测试数据集来评估所有的树，根据它们在测试数据集熵的分类性能选出最佳的树</strong>。</p>
<blockquote>
<p>  从完整子树 $T0$ 开始， 通过在 $Ti$ 子树序列中裁剪真实误差最小【考虑叶子节点的个数】的子树，得到 $Ti+1$。 </p>
<p>  <img src="image-20220321203204744.png" alt="image-20220321203204744" style="zoom: 25%;">【剪枝之后的误差 - 剪枝前的误差 / 叶子节点数 - 1】</p>
<p>  每次误差增加率最小的节点，得到一系列的子树，从中选择效果最好的【独立剪枝数据集】和【K折交叉验证】</p>
</blockquote>
<p><img src="image-20220320215056933.png" alt="image-20220320215056933" style="zoom:50%;"></p>
<p>我们来看具体看一下代价复杂度剪枝算法：</p>
<p>首先我们将最大树称为 <img src="https://www.zhihu.com/equation?tex=T_0" alt="[公式]"> ，我们希望减少树的大小来防止过拟合，但又担心去掉节点后预测误差会增大，所以我们定义了一个损失函数来达到这两个变量之间的平衡。损失函数定义如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=C_%5Calpha%28T%29%3DC%28T%29%2B%5Calpha%7CT%7C++%5C%5C" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=T" alt="[公式]"> 为任意子树， <img src="https://www.zhihu.com/equation?tex=C%28T%29" alt="[公式]"> 为预测误差， <img src="https://www.zhihu.com/equation?tex=%7CT%7C" alt="[公式]"> 为子树 <img src="https://www.zhihu.com/equation?tex=T" alt="[公式]"> 的叶子节点个数， <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> 是参数， <img src="https://www.zhihu.com/equation?tex=C%28T%29" alt="[公式]"> 衡量训练数据的拟合程度， <img src="https://www.zhihu.com/equation?tex=%7CT%7C" alt="[公式]"> 衡量树的复杂度， <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> <strong>权衡拟合程度与树的复杂度</strong>。</p>
<h3 id="3-5-类别不平衡"><a href="#3-5-类别不平衡" class="headerlink" title="3.5 类别不平衡"></a>3.5 类别不平衡</h3><p>CART 的一大优势在于：无论训练数据集有多失衡，它都可以将其子冻消除不需要建模人员采取其他操作。</p>
<p>CART 使用了一种先验机制，其作用相当于对类别进行加权。这种先验机制嵌入于 CART 算法判断分裂优劣的运算里，在 CART 默认的分类模式中，总是要计算每个节点关于根节点的类别频率的比值，这就相当于对数据自动重加权，对类别进行均衡。</p>
<p>对于一个二分类问题，节点 node 被分成类别 1 当且仅当：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cfrac%7BN_1%28node%29%7D%7BN_1%28root%29%7D+%3E+%5Cfrac%7BN_0%28node%29%7D%7BN_0%28root%29%7D++%5C%5C" alt="[公式]"></p>
<p>比如二分类，根节点属于 1 类和 0 类的分别有 20 和 80 个。在子节点上有 30 个样本，其中属于 1 类和 0 类的分别是 10 和 20 个。如果 10/20&gt;20/80，该节点就属于 1 类。</p>
<p>通过这种计算方式就无需管理数据真实的类别分布。假设有 K 个目标类别，就可以确保根节点中每个类别的概率都是 1/K。这种默认的模式被称为“先验相等”。</p>
<p>先验设置和加权不同之处在于先验不影响每个节点中的各类别样本的数量或者份额。先验影响的是每个节点的类别赋值和树生长过程中分裂的选择。</p>
<h3 id="3-6-连续值处理"><a href="#3-6-连续值处理" class="headerlink" title="3.6 连续值处理"></a>3.6 连续值处理</h3><h4 id="3-6-1-分类树"><a href="#3-6-1-分类树" class="headerlink" title="3.6.1 分类树"></a>3.6.1 分类树</h4><ul>
<li><p><strong><font color="red">如果特征值是连续值：CART的处理思想与C4.5是相同的，即将连续特征值离散化。唯一不同的地方是度量的标准不一样，</font></strong> <strong>CART采用基尼指数，而C4.5采用信息增益比</strong>。</p>
</li>
<li><p>如果当前节点为连续属性，<strong>CART树中该属性（剩余的属性值）后面还可以参与子节点的产生选择过程</strong>。</p>
</li>
</ul>
<h3 id="3-7-回归树"><a href="#3-7-回归树" class="headerlink" title="3.7 回归树"></a>3.7 回归树</h3><p><strong>CART（Classification and Regression Tree，分类回归树），从名字就可以看出其不仅可以用于分类，也可以应用于回归</strong>。其回归树的建立算法上与分类树部分相似，这里简单介绍下不同之处。</p>
<h5 id="连续值处理：-RSS残差平方和"><a href="#连续值处理：-RSS残差平方和" class="headerlink" title="连续值处理：==RSS残差平方和=="></a><strong>连续值处理</strong>：==RSS<strong>残差平方和</strong>==</h5><p>对于连续值的处理，<strong>CART 分类树采用基尼系数的大小来度量特征的各个划分点</strong>。<strong>在回归模型中，我们使用常见的和方差度量方式</strong>，对于任意划分特征 A，对应的任意划分点 s 两边划分成的数据集 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> ，求出使 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> 各自<strong>集合的均方差最小</strong>，同时 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> 的均方差之和最小所对应的特征和特征值划分点。表达式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=+%5Cmin%5Climits_%7Ba%2Cs%7D%5CBigg%5B%5Cmin%5Climits_%7Bc_1%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_1%7D%28y_i+-+c_1%29%5E2+%2B+%5Cmin%5Climits_%7Bc_2%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_2%7D%28y_i+-+c_2%29%5E2%5CBigg%5D+%5C%5C" alt="[公式]"></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=c_1" alt="[公式]"> 为 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 数据集的样本输出均值， <img src="https://www.zhihu.com/equation?tex=c_2" alt="[公式]"> 为 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> 数据集的样本输出均值。</p>
<h5 id="预测方式"><a href="#预测方式" class="headerlink" title="预测方式"></a><strong>预测方式</strong></h5><p>对于决策树建立后做预测的方式，上面讲到了 CART 分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。而回归树输出不是类别，它采用的是用最终叶子的均值或者中位数来预测输出结果。</p>
<h3 id="3-7-CART分类树建模时，预测变量中存在连续和离散时，会自动分别进行处理吗？"><a href="#3-7-CART分类树建模时，预测变量中存在连续和离散时，会自动分别进行处理吗？" class="headerlink" title="3.7 CART分类树建模时，预测变量中存在连续和离散时，会自动分别进行处理吗？"></a>3.7 CART分类树建模时，预测变量中存在连续和离散时，会自动分别进行处理吗？</h3><blockquote>
<p>  在使用sklearn的决策树CART建模时，预测变量中存在连续和离散时，会自动分别进行处理吗？ - 月来客栈的回答 - 知乎 <a href="https://www.zhihu.com/question/472579561/answer/2002434993">https://www.zhihu.com/question/472579561/answer/2002434993</a></p>
</blockquote>
<p><strong>对于这种连续型的特征变量，Sklearn中的具体做法（包括ID3、CART、随机森林等）是先对连续型特征变量进行排序处理</strong>，<strong><font color="red"> 然后取所有连续两个值的均值来离散化整个连续型特征变量。</font></strong></p>
<p>假设现在某数据集其中一个特征维度为：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5B0.5%2C+0.2%2C+0.8%2C+0.9%2C+1.2%2C+2.1%2C+3.2%2C+4.5%5D+%5C%5C" alt="[公式]"></p>
<p>则首先需要对其进行排序处理，排序后的结果为：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5B0.2%2C+0.5%2C+0.8%2C+0.9%2C+1.2%2C+2.1%2C+3.2%2C+4.5%5D+%5C%5C" alt="[公式]"></p>
<p>接着再计算所有连续两个值之间的平均值：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5B0.35%2C+0.65%2C+0.85%2C+1.05%2C+1.65%2C+2.65%2C+3.85%5D+%5C%5C" alt="[公式]"></p>
<p>这样，便得到了该特征离散化后的结果。最后在构造<a href="https://www.zhihu.com/search?q=决策树&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra={&quot;sourceType&quot;%3A&quot;answer&quot;%2C&quot;sourceId&quot;%3A&quot;2002434993&quot;}">决策树</a>时，只需要使用式最后离散化后的特征进行划分指标的计算即可。同时，值得一说的地方是<strong>目前Sklearn在实际处理时，会把所有的特征均看作连续型变量进行处理</strong>。</p>
<p>下图所示为iris数据集根据sklearn中CART算法所建模的决策树的可视化结果：</p>
<p><img src="https://picx.zhimg.com/v2-9081bc3cd5f2ec069212b79d5c5ff7d3_b.jpg" alt="img" style="zoom:50%;"></p>
<p>从图中可以看到，<code>petal width</code>这个特征在前两次分类时的分割点分别为0.8和1.75。下面先来看看原始特征<code>petal width</code>的取值情况：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">1.</span>  <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">1.4</span> <span class="number">2.5</span> <span class="number">1.3</span> <span class="number">2.1</span> <span class="number">1.5</span> <span class="number">0.2</span> <span class="number">2.</span>  <span class="number">1.</span>  <span class="number">0.2</span> <span class="number">0.3</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">0.2</span> <span class="number">0.5</span> <span class="number">1.3</span> <span class="number">0.2</span> <span class="number">1.2</span> <span class="number">2.2</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">2.</span>  <span class="number">0.2</span> <span class="number">1.8</span> <span class="number">1.9</span> <span class="number">1.</span>  <span class="number">1.5</span> <span class="number">2.3</span> <span class="number">1.3</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">1.9</span> <span class="number">0.2</span> <span class="number">0.2</span> <span class="number">1.1</span> <span class="number">1.7</span> <span class="number">0.2</span> <span class="number">2.4</span> <span class="number">0.2</span> <span class="number">0.6</span> <span class="number">1.8</span> <span class="number">1.1</span> <span class="number">2.3</span> <span class="number">1.6</span> <span class="number">1.4</span> <span class="number">2.3</span> <span class="number">1.3</span> <span class="number">0.2</span> <span class="number">0.1</span> <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">0.3</span> <span class="number">0.2</span> <span class="number">1.5</span> <span class="number">2.4</span> <span class="number">0.3</span> <span class="number">2.1</span> <span class="number">2.5</span> <span class="number">0.2</span> <span class="number">1.4</span> <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">1.4</span> <span class="number">2.3</span> <span class="number">0.2</span> <span class="number">2.1</span> <span class="number">1.5</span> <span class="number">2.</span>  <span class="number">1.</span>  <span class="number">1.4</span> <span class="number">1.4</span> <span class="number">0.3</span> <span class="number">1.3</span> <span class="number">1.2</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">1.8</span> <span class="number">2.1</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">2.5</span> <span class="number">1.6</span> <span class="number">0.1</span> <span class="number">2.4</span> <span class="number">0.2</span> <span class="number">1.5</span> <span class="number">1.9</span> <span class="number">1.8</span> <span class="number">1.3</span> <span class="number">1.8</span> <span class="number">1.3</span> <span class="number">1.3</span> <span class="number">2.</span>  <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">1.7</span> <span class="number">0.2</span> <span class="number">1.2</span> <span class="number">2.1</span>]</span><br></pre></td></tr></table></figure>
<p>可以发现上面并没有0.8和1.75这两个取值。接着按上面的方法先排序，再取相邻两个值的平均作为离散化的特征，其结果为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">0.1</span>, <span class="number">0.15000000000000002</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, </span><br><span class="line"><span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.25</span>, <span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.35</span>, <span class="number">0.4</span>, <span class="number">0.4</span>,</span><br><span class="line"> <span class="number">0.45</span>, <span class="number">0.55</span>, <span class="number">0.8</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.05</span>, <span class="number">1.1</span>, <span class="number">1.15</span>, <span class="number">1.2</span>, <span class="number">1.2</span>, <span class="number">1.25</span>, <span class="number">1.3</span>,</span><br><span class="line"> <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.35</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.45</span>, <span class="number">1.5</span>, </span><br><span class="line"><span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.55</span>, <span class="number">1.6</span>, <span class="number">1.65</span>, <span class="number">1.7</span>, <span class="number">1.75</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, </span><br><span class="line"><span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.85</span>, <span class="number">1.9</span>, <span class="number">1.9</span>, <span class="number">1.95</span>, <span class="number">2.0</span>, <span class="number">2.0</span>, <span class="number">2.0</span>, <span class="number">2.05</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, </span><br><span class="line"><span class="number">2.1500000000000004</span>, <span class="number">2.25</span>, <span class="number">2.3</span>, <span class="number">2.3</span>, <span class="number">2.3</span>, <span class="number">2.3499999999999996</span>, <span class="number">2.4</span>, <span class="number">2.4</span>, <span class="number">2.45</span>, <span class="number">2.5</span>, <span class="number">2.5</span>]</span><br></pre></td></tr></table></figure>
<h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h2><p>最后通过总结的方式对比下 ID3、C4.5 和 CART 三者之间的差异。</p>
<p>除了之前列出来的划分标准、剪枝策略、连续值确实值处理方式等之外，我再介绍一些其他差异：</p>
<ul>
<li><strong>划分标准的差异：</strong>ID3 使用信息增益偏向特征值多的特征，C4.5 使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART 使用基尼指数克服 C4.5 需要求 log 的巨大计算量，偏向于特征值较多的特征。</li>
<li><strong>使用场景的差异：</strong>ID3 和 C4.5 都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5 是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li>
<li><strong>样本数据的差异：</strong>ID3 只能处理离散数据且缺失值敏感，C4.5 和 CART 可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议 C4.5、大样本建议 CART。C4.5 处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART 本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li>
<li><strong>样本特征的差异：</strong>ID3 和 C4.5 层级之间只使用一次特征，CART 可多次重复使用特征（连续型）；</li>
<li><strong>剪枝策略的差异：</strong>ID3 没有剪枝策略，C4.5 是通过悲观剪枝策略来修正树的准确性，而 CART 是通过代价复杂度剪枝。</li>
</ul>
<h2 id="一、决策树"><a href="#一、决策树" class="headerlink" title="一、决策树"></a>一、决策树</h2><h3 id="1-1-介绍决策树ID2、C4-5、CART-3种决策树及其区别和适应场景？"><a href="#1-1-介绍决策树ID2、C4-5、CART-3种决策树及其区别和适应场景？" class="headerlink" title="1.1 介绍决策树ID2、C4.5、CART, 3种决策树及其区别和适应场景？"></a>1.1 介绍决策树ID2、C4.5、CART, 3种决策树及其区别和适应场景？</h3><h3 id="1-2-决策树处理连续值的方法"><a href="#1-2-决策树处理连续值的方法" class="headerlink" title="1.2 决策树处理连续值的方法?"></a>1.2 决策树处理连续值的方法?</h3><p><strong>ID3 只能离散型</strong>。<strong>C4.5 将连续特征离散化</strong>，假设 n 个样本的连续特征 A 有 m 个取值，<strong>C4.5 将其排序并取相邻两样本值的平均数共 m-1 个划分点</strong>，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点； </p>
<p><strong>CART分类树：离散化+基尼指数，</strong></p>
<p><strong>CART回归树：均方差之和度量方式</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=+%5Cmin%5Climits_%7Ba%2Cs%7D%5CBigg%5B%5Cmin%5Climits_%7Bc_1%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_1%7D%28y_i+-+c_1%29%5E2+%2B+%5Cmin%5Climits_%7Bc_2%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_2%7D%28y_i+-+c_2%29%5E2%5CBigg%5D+%5C%5C" alt="[公式]"></p>
<h3 id="1-3-决策树处理缺失值的方式？"><a href="#1-3-决策树处理缺失值的方式？" class="headerlink" title="1.3 决策树处理缺失值的方式？"></a>1.3 决策树处理缺失值的方式？</h3><blockquote>
<p>  <a href="https://zhuanlan.zhihu.com/p/84519568">ID3、c4.5、cart、rf到底是如何处理缺失值的？</a></p>
</blockquote>
<h4 id="1-3-1-在特征值缺失的情况下进行划分特征的选择？"><a href="#1-3-1-在特征值缺失的情况下进行划分特征的选择？" class="headerlink" title="1.3.1 在特征值缺失的情况下进行划分特征的选择？"></a>1.3.1 <strong>在特征值缺失的情况下进行划分特征的选择？</strong></h4><p><strong>ID3</strong> 没有缺失值处理；</p>
<p><strong>C4.5</strong>：对于具有缺失值特征，用没有缺失的<strong>样本子集所占比重来折算</strong>；</p>
<p><strong>CART</strong>：<strong>初期</strong>：分裂特征评估时只能使用在该特征上没有缺失值的那部分数据<strong>；后续</strong>：CART 算法使用了一种惩罚机制来抑制提升值，从而反映出缺失值的影响。</p>
<h4 id="1-3-2-选定该划分特征，对于缺失该特征值的样本如何处理？"><a href="#1-3-2-选定该划分特征，对于缺失该特征值的样本如何处理？" class="headerlink" title="1.3.2 选定该划分特征，对于缺失该特征值的样本如何处理？"></a>1.3.2 <strong>选定该划分特征，对于缺失该特征值的样本如何处理？</strong></h4><p><strong>ID3</strong> 没有缺失值处理；</p>
<p><strong>C4.5</strong>：<strong>将样本同时划分到所有子节点</strong>，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</p>
<p>==<strong>CART</strong>：==sklearn中的cart的实现是没有对缺失值做任何处理的，也就是说sklearn的cart无法处理存在缺失值的特征。</p>
<h3 id="1-4-决策树如何剪枝？"><a href="#1-4-决策树如何剪枝？" class="headerlink" title="1.4 决策树如何剪枝？"></a>1.4 决策树如何剪枝？</h3><ul>
<li><strong>预剪枝</strong>：在树的生成过程中，提前停止生长。简单，适合解决大规模问题。<ul>
<li>深度</li>
<li>节点样本数</li>
<li>对测试集准确率的提升过小</li>
</ul>
</li>
<li><strong>后剪枝</strong>：生成一颗完全生长的二叉树，从低向上剪枝，将子树删除用叶子节点代替。【类别：多数投票】常见的剪枝方法：错误率降低剪枝（REP）、<strong>悲观剪枝（PEP）、代价复杂度剪枝（CCP）</strong>、最小误差剪枝（MEP）等。</li>
</ul>
<p><strong>代价复杂度剪枝（CCP）【CART树】</strong></p>
<p>从完整子树 $T0$ 开始， 通过在 $Ti$ 子树序列中裁剪真实误差最小【考虑叶子节点的个数】的子树，得到 $Ti+1$。 </p>
<p><img src="image-20220321203204744.png" alt="image-20220321203204744" style="zoom: 25%;">【剪枝之后的误差 - 剪枝前的误差 / 叶子节点数 - 1】</p>
<p>每次误差增加率最小的节点，得到一系列的子树，从中选择效果最好的【独立剪枝数据集】和【K折交叉验证】</p>
<h3 id="1-5-决策树特征选择？特征重要性判断？"><a href="#1-5-决策树特征选择？特征重要性判断？" class="headerlink" title="1.5 决策树特征选择？特征重要性判断？"></a>1.5 决策树特征选择？特征重要性判断？</h3><p><strong>XGBoost</strong>：</p>
<ul>
<li><p>该特征在所有树中被用作分割样本的特征的总次数。</p>
</li>
<li><p>该特征在其出现过的所有树中产生的平均增益。</p>
</li>
<li><p>该特征在其出现过的所有树中的平均覆盖范围。</p>
<blockquote>
<p>  注意：覆盖范围这里指的是一个特征用作分割点后，其影响的样本数量，即有多少样本经过该特征分割到两个子节点。</p>
</blockquote>
</li>
</ul>
<h3 id="1-6-SVM、LR、决策树的对比？"><a href="#1-6-SVM、LR、决策树的对比？" class="headerlink" title="1.6 SVM、LR、决策树的对比？"></a>1.6 SVM、LR、决策树的对比？</h3><blockquote>
<p>  逻辑回归，决策树，支持向量机 选择方案: <a href="https://cloud.tencent.com/developer/article/1435642">https://cloud.tencent.com/developer/article/1435642</a></p>
<p>  广义线性模型？</p>
<p>  sigmod、softmax</p>
<p>  为什么逻辑回归的连续值也需要离散化？</p>
<p>  为什么逻辑回归要用交叉熵？</p>
<p>  交叉熵和KL散度（相对熵）和GAN的损失函数的区别？</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>线性回归</th>
<th>LR 逻辑回归</th>
<th>SVM</th>
<th>朴素贝叶斯</th>
<th>决策树</th>
</tr>
</thead>
<tbody>
<tr>
<td>场景</td>
<td>【回归问题】</td>
<td>逻辑回归 = 线性回归 + Sigmoid 函数（非线形）【分类问题】==【参数模型】==【统计方法】</td>
<td>【分类问题】【几何方法】【非参数模型】</td>
<td>【生成式模型】</td>
<td>【分类问题】【回归问题】【非参数模型】</td>
</tr>
<tr>
<td><strong>思想</strong></td>
<td></td>
<td><strong>思路：</strong>先拟合决策边界(不局限于线性，还可以是多项式)，再建立这个边界与分类的概率联系，从而得到了二分类情况下的概率。<strong>细节</strong>：通过<strong>非线性映射减小了离分类平面较远的点的权重</strong>，相对提升了与分类最相关的数据点的权重；</td>
<td><strong>思想</strong>：SVM 想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</td>
<td></td>
<td><strong>思想</strong>：用启发算法来度量特征选择，选择特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间。</td>
</tr>
<tr>
<td><strong>关键样本</strong></td>
<td></td>
<td><strong>所有样本</strong>（通过非线性映射，大大减小了离分类平面较远的点的权重）</td>
<td><strong>支持向量</strong>（超平面到距离最近的不同标记样本集合）</td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>目标函数</strong></td>
<td></td>
<td>$y=\frac{1}{1+e^{-\left(w^{T} x+b\right)}}$ 【极大似然函数】</td>
<td><img src="image-20220322131856478.png" alt="image-20220322131856478" style="zoom:150%;"> <img src="https://pic2.zhimg.com/80/v2-0e87b3bf410cd798efd05a2837b83589_1440w.png" alt="img"></td>
<td></td>
<td>信息增益、信息增益率、Gini指数</td>
</tr>
<tr>
<td><strong>损失函数</strong></td>
<td></td>
<td><img src="https://pic3.zhimg.com/80/v2-ee1ddd22da5171fa44e079582cefe20a_1440w.png" alt="img" style="zoom:150%;"></td>
<td><strong><a href="https://www.zhihu.com/question/47746939">HingeLoss</a></strong>【合页损失函数】：<img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi%3D1%7D%5EN%5B1-y_i%28w%C2%B7x_i+%2B+b%29%5D_%2B+%2B+%5Clambda%7C%7Cw%7C%7C%5E2+%5C%5C+%5Bz%5D_%2B+%3D+%5Cbegin%7Bequation%7D+%5Cleft%5C%7B++++++++++++++%5Cbegin%7Barray%7D%7Blr%7D+++++++++++z%2C+z%3E0+%26++%5C%5C++++++++++++++0.z%5Cleq0+%26+++++++++++++++%5Cend%7Barray%7D++%5Cright.+%5Cend%7Bequation%7D+%5C%5C+" alt="[公式]" style="zoom:150%;"></td>
<td></td>
<td>信息增益、信息增益率、Gini指数【方差和】</td>
</tr>
<tr>
<td>决策面</td>
<td></td>
<td>线性可分</td>
<td>【核函数映射】从而使得样本数据线性可分</td>
<td></td>
<td>矩形【非线性】</td>
</tr>
<tr>
<td>连续值处理</td>
<td></td>
<td>==离散化？==</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>输出</strong></td>
<td></td>
<td>类别的概率</td>
<td>类别</td>
<td></td>
<td>类别、回归</td>
</tr>
<tr>
<td>过拟合</td>
<td></td>
<td><strong>正则化</strong> L1: <img src="image-20220316144906846.png" alt="image-20220316144906846" style="zoom:50%;"> L2: <img src="image-20220316145437180.png" alt="image-20220316145437180" style="zoom:50%;"></td>
<td>\</td>
<td></td>
<td>预剪枝和后剪枝</td>
</tr>
<tr>
<td>优势</td>
<td></td>
<td><strong>本质其实是为了模型参数服从某一分布</strong>；1、对观测样本的概率值输出 2、实现简单高效3、<strong>多重共线性的问题可以通过L2正则化来应对</strong>。 4、大量的工业界解决方案5、支持online learning</td>
<td>1、可以处理<strong>高维特征</strong> 2、使用<strong>核函数</strong>轻松应对非线的性特征空间 3、分类面不依赖于所有数据4、关重要的<strong>关键样本</strong></td>
<td></td>
<td>1、直观的决策过程 2、能够处理非线性特征 3、考虑了<strong>特征相关性</strong></td>
</tr>
<tr>
<td>劣势</td>
<td></td>
<td>1、特征空间太大时表现不太好 2、对于大量的分类变量无能为力 3、对于非线性特征需要做特征变换 4、依赖所有的样本数据</td>
<td>1、<strong>对于大量的观测样本，效率会很低</strong> 2、找到一个“合适”的核函数还是很tricky的</td>
<td></td>
<td>1、极易过拟合 2、无法输出score，只能给出直接的分类结果</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>  <strong><a href="https://blog.csdn.net/Alphonse_Huang/article/details/114278377">多重共线性问题</a></strong></p>
<p>  多重共线性问题就是指一个解释变量的变化引起另一个解释变量地变化。多重共<a href="https://so.csdn.net/so/search?q=线性&amp;spm=1001.2101.3001.7020">线性</a>是使用线性回归算法时经常要面对的一个问题。在其他算法中，例如决策树或者朴素贝叶斯，前者的建模过程时逐渐递进，每次都只有一个变量参与，这种机制含有抗多重共线性干扰的功能；后者假设变量之间是相互独立的。但对于回归算法来说，都要同时考虑多个预测因子，因此多重共线性不可避免。</p>
<ul>
<li>PCA等降维方法。因为在原始特征空间中变量之间相关性大，很容易想到通过降低维度的形式来去除这种共线性。</li>
<li>正则化。使用<strong>岭回归（L2</strong>）或者lasso回归（L1）或者elasticnet回归（L1+L2）</li>
<li><p>逐步回归法</p>
<p><strong><a href="https://blog.csdn.net/FrankieHello/article/details/94022594">机器学习中参数模型和非参数模型理解</a></strong></p>
<p>参数模型通常假设总体服从某个分布，这个分布可以由一些参数确定，如正态分布由均值和标准差确定，在此基础上构建的模型称为参数模型；非参数模型对于总体的分布不做任何假设或者说是数据分布假设自由，只知道其分布是存在的，所以就无法得到其分布的相关参数，只能通过非参数统计的方法进行推断。</p>
</li>
</ul>
</blockquote>
]]></content>
  </entry>
</search>
