<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"powerlzy.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="相比到达的地方，同行的人更重要！">
<meta property="og:type" content="website">
<meta property="og:title" content="PowerLZY&#39;s Blog">
<meta property="og:url" content="https://powerlzy.github.io/page/13/index.html">
<meta property="og:site_name" content="PowerLZY&#39;s Blog">
<meta property="og:description" content="相比到达的地方，同行的人更重要！">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="lzy">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://powerlzy.github.io/page/13/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/13/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>PowerLZY's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">PowerLZY's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">本博客主要用于记录个人学习笔记（测试阶段）</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="lzy"
      src="/images/cat_mac.jpg">
  <p class="site-author-name" itemprop="name">lzy</p>
  <div class="site-description" itemprop="description">相比到达的地方，同行的人更重要！</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">236</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">43</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/PowerLZY" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;PowerLZY" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:3289218653@qq.com" title="E-Mail → mailto:3289218653@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/3931MT5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/3931MT5/" class="post-title-link" itemprop="url">工业落地-AVClass2-自动恶意软件标记工具</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-15 18:50:25" itemprop="dateCreated datePublished" datetime="2022-05-15T18:50:25+08:00">2022-05-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-18 15:17:21" itemprop="dateModified" datetime="2023-04-18T15:17:21+08:00">2023-04-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%B7%A5%E4%B8%9A%E8%90%BD%E5%9C%B0/" itemprop="url" rel="index"><span itemprop="name">工业落地</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%B7%A5%E4%B8%9A%E8%90%BD%E5%9C%B0/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1><span id="如何利用多杀软结果提取恶意软件标签">如何利用多杀软结果提取恶意软件标签</span></h1>
<ul>
<li>secrss.com/articles/33242</li>
<li><strong>通过多杀软结果挖掘得到更多关于样本的上下文信息是一个经久不衰的研究点</strong></li>
</ul>
<p><strong>从杀软标签中自动提取标签是对大量样本进行分类和索引的有效方法</strong>。此前的
AVClass 和 Euphony
等工作已经能够从杀软标签中提取家族名称。而杀软标签包含有价值的信息不止是家族，还有类别（例如勒索软件、下载器、广告软件）和行为（例如垃圾邮件、DDoS、信息窃取）等。</p>
<p><strong>恶意软件属性枚举和表征（MAEC）等标准定义了一种用于共享恶意软件分析结果的语言</strong>。然而，由于使用严格的受控词汇表（即预定义标签），这些词汇表可能并不总是符合分析师的需求，需要频繁更新，并且必然是不完整的，因此它们的采用率很低，例如，MAEC
中就不包括<strong>恶意软件家族</strong>。</p>
<p>杀软引擎有一些通用标签，标明恶意软件的类别、家族、文件属性和动态行为。也有一个通用标签（malicious,
application）和特定杀软引擎（deepscan,
cloud）才有的，或者是恶意软件家族变种（aghr, bcx）标签。</p>
<h3><span id="工作设计">工作设计</span></h3>
<p><strong>AVClass2 的目标是分辨提供有用信息的 Token，识别不同杀软引擎
Token 之间的关系，最后转换成分类法的标签。</strong></p>
<p>AVClass2
是一个自动恶意软件标记工具，可为样本提取一组干净的标签。AVClass2
附带一个默认的开放分类法，可将杀软标签的名词分类到不同的类别，捕获标签之间关系的默认标记规则和扩展规则。AVClass2
有一个更新模块，使用标签共现来识别标签之间的关系，以在杀软厂商引入新标签时保持工具更新。</p>
<p>AVCalss2 基于 AVClass 进行了最少必要更改，继承了 AVClass
的主要特点：可扩展性好、杀软引擎独立性好、平台无关性好、不需要样本文件、开源。</p>
<p>基本架构如下所示：</p>
<figure>
<img src="https://s.secrss.com/anquanneican/13c4e4d7d81462e10c618bee59fbf971.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>主要是两大模块：Labeling 模块和 Update 模块。</strong></p>
<ul>
<li>Labeling
模块将<strong>多个杀软的标签结果作为输入</strong>，同时可以提供使用的杀软引擎列表，如果不提供默认使用所有杀软引擎的标签结果。给出一组<strong>标记规则</strong>、一个<strong>可选扩展规则</strong>以及可将标签<strong>分类合并</strong>的分类法。</li>
<li>Update
模块将<strong>共现统计、标记规则、扩展规则和分类法作为输入</strong>。识别标签之间的<strong>强关联</strong>，生成新的标记规则、扩展规则和分类法。</li>
</ul>
<h3><span id="标签">标签</span></h3>
<p><strong>Labeling
模块分为三部分：标记化（Tokenization）、标记（Tagging）、扩展（Expansion）。</strong></p>
<ul>
<li><strong>标记化（Tokenization）将每个杀软标签拆分为一个 Token
列表</strong>。标记化是与厂商无关的，VirusTotal
现在已经支持超过一百个引擎。每个厂商的格式也不完全一致，经常修改。如果尝试为引擎的标签定义格式或者自动推断格式，可能会得到数百个格式模板。不仅选择正确格式进行解析很困难，遇到未知格式的标签还可能出现错误。</li>
<li><strong>标记（Tagging）会用分类法中的一组 Tag 替换杀软标签中的
Token，即将杀软标签中的 Token 转换为分类法中概念明确的
Tag</strong>。大多数标记规则会映射到单个标记，例如 downldr、dloader
会被映射到 downloader 上；finloski 和 fynloski 会被映射到 darkkomet
上。也存在一对多的关系，比如 ircbot 会映射到 irc 和 bot。</li>
<li><strong>扩展（Expansion）用于处理未知的
Token，使用扩展规则定义一个标签隐含一组其他标签</strong>。例如有 95%
的标签在带有 virut 的同时也带有 virus，virut 就会是 virus
的扩展规则。扩展规则一共分为两类，一类是类内规则一类是类间规则，处理顺序是先类间规则再类内规则。类内规则由分类法中统一类别的父子关系隐式定义，例如
adware 是 grayware
的子类。类间规则由分类法中不同类别的隐式关系定义，例如 filemodify
行为归属于 virus 类。</li>
</ul>
<p><strong>整体流程如下所示：</strong></p>
<figure>
<img src="https://s.secrss.com/anquanneican/018d45d7ed61a0cca153cfd53d145ade.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="分类法">分类法</span></h3>
<blockquote>
<p><strong>行为、类型、文件属性和家族</strong></p>
</blockquote>
<p>分类法定义了标记规则使用的标签之间的父子关系。AVClass2
的分类法被构造为树型结构，默认包含四个类型（<strong>行为 BEH、类型
CLASS、文件属性 FILE、家族 FAM</strong>）。</p>
<figure>
<img src="https://s.secrss.com/anquanneican/070902d5885e1c46d17142d43813a9fe.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>标签是自上而下进行描述的，例如 CLASS:grayware:adware。</p>
<p><strong>自带的默认分类法如下所示：</strong></p>
<figure>
<img src="https://s.secrss.com/anquanneican/45bbf65333720324166aeab69f49ece1.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li><strong>行为</strong>：例如
infosteal（信息窃取）、sendssms（发送短信）、spam（垃圾邮件）、mining（挖矿）等</li>
<li><strong>类别</strong>：例如
worm（蠕虫）、virus（病毒）、ransomware（勒索）、downloader（下载）。Trojan
问题很大，原来特指某类，后来变成了默认类型，故而认为 Trojan 为通用
Token。</li>
<li><strong>文件属性</strong>：例如<strong>文件类型</strong>（例如
pdf、flash、msword）、<strong>操作系统</strong>（android、linux、windows）、<strong>壳类型</strong>（pecompact、themida、vmprotect）、<strong>编程语言</strong>（autoit、delphi、java）</li>
<li><strong>家族</strong>：默认分类家族不包括父子关系</li>
</ul>
<h3><span id="update">Update</span></h3>
<p>为了新的家族、新的行为都能够通过 AVClass2
自动更新，需要根据共现关系识别数据集中的强关系，迭代更新到规则中。基于
VAMO 引用的杀软标签共现关系，在 AVClass 和 Euphony
中也用于合并家族。（Roberto Perdisci and U. ManChon. 2012. VAMO: Towards
a Fully Automated Malware Clustering Validity Analysis. In Annual
Computer Security Applications
Conference.）。共现的判断需要确定阈值，以AVClass的经验选择 𝑛 = 20 和 𝑇 =
0.94。</p>
<figure>
<img src="https://s.secrss.com/anquanneican/9d67ba609a2c45feb86dcd605dd5c06f.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="工作准备">工作准备</span></h3>
<p>使用 11 个数据集进行评估，数据集之间存在重复（例如 Drebin 是
MalGenome 的超集）但并未去重，为了便于单独映射结果。</p>
<figure>
<img src="https://s.secrss.com/anquanneican/18030348ab876b5fed8137aa52b61655.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="工作评估">工作评估</span></h3>
<p>通过在 4200 万恶意样本中评估 AVClass2，并且与 AVClass 和 Euphony
进行了比较，测试其效果。</p>
<h3><span id="标记覆盖">标记覆盖</span></h3>
<p>标签覆盖率如下所示：</p>
<figure>
<img src="https://s.secrss.com/anquanneican/0060066c74a362e126f439c6efc4b669.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li><p>选择至少四个杀软引擎标记为恶意的样本，最近的研究表明 2-14
个杀软引擎判定的筛选范围有利于平衡精度和召回率。</p>
<blockquote>
<p>Shuofei Zhu, Jianjun Shi, Limin Yang, Boqin Qin, Ziyi Zhang, Linhai
Song, and Gang Wang. 2020. <strong>Measuring and Modeling the Label
Dynamics of Online Anti-Malware Engines</strong></p>
</blockquote></li>
<li><p>AVClass2 可以为 89%
以上的样本提取至少一个标签，无法提取的基本都是检测结果较少的文件</p></li>
<li><p>测试时可识别的 975 个标签已经超过了 VirusTotal 的 335
个标签，VirusTotal 的标签基本都对应于文件属性和样本行为。其中，与
VirusTotal 重合的共有 259 个标签</p></li>
</ul>
<p>每个类别 TOP10 的标签如下所示：</p>
<figure>
<img src="https://s.secrss.com/anquanneican/9a1f118fb14f2944de07888d2beb9a08.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>超过 10% 的样本对应了四个类别的标签。例如
CLASS:grayware:adware:multiplug
是通过浏览器插件进行广告推广的软件。</li>
<li>Trojan 如果不是通用Token被剔除的话，会被分配给 86% 的样本。</li>
<li>最多的家族是 vobfus，占到了总数的十分一。</li>
<li>除了恶意软件外，grayware
也是常见家族的大赢家（loadmoney、softpulse、installererex、domaiq、firseria）。</li>
</ul>
<h3><span id="知识更新">知识更新</span></h3>
<p>使用 Andropup 数据集举例说明 update 模块的用法。首次测试观察到 65%
的样本包含一个未知标签，执行 update 模块后会下降到 16%。</p>
<figure>
<img src="https://s.secrss.com/anquanneican/78fad75a47f80238fc0ca5a40ea263b4.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>共现关系共计 30107 个，有归属于 11 类的 968 个强关联。96%
的强关联涉及未知 Token，从中自动识别出了 486 个新类别实体、216
个新标记规则、461 个扩展规则。处理完成后只剩下 3
个强关联不能自动更新，需要手动处理。</p>
<p>手动检查了更新的内容，1163 个更新中只有 11 个（0.9%）是需要调整的、3
个是需要手动检查的。</p>
<h4><span id="执行速度">执行速度</span></h4>
<figure>
<img src="https://s.secrss.com/anquanneican/3cee7fc69bc91ff6f01b24c764ed46ef.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>AVClass2 和 AVClass* 在四个数据集中获得了最好的 F1 成绩，而 AVClass
在 Malheur 上排名第一。</li>
<li>AVClass 最快，AVClass2 其次，Euphony 则比 AVClass 慢 7 到 34
倍。对特大的数据集 Euphony 会很慢或者因内存不足而崩溃。</li>
</ul>
<h2><span id="工作思考">工作思考</span></h2>
<p>AVClass2 对通过多杀软结果处理实现提取 VirusTotal 类的 Tag
标签很有帮助，实际上没有必要合并成一个完整的分类法的语法树结构。<strong>通过多杀软结果挖掘得到更多关于样本的上下文信息是一个经久不衰的研究点</strong>，本文作者也在
AVClass 的基础上再进一步做出了 AVClass2，<strong>==两个工作分别发表在
RAID 2016 与 ACSAC 2020 都是很不错的成绩。==</strong></p>
<p>像 AVClass++ 指出的那样，AVClass
在杀软引擎结果较少时效果较差，那些新提交到 VirusTotal
的样本会因此效果较差。另外就是杀软结果中也存在随机生成类的结果，这两点实际上都可能是未来在这条路上的研究进展，AVClass++
的解决方法是否很优则见仁见智，但仍不失为一个极佳的参考。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/C7WFJN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/C7WFJN/" class="post-title-link" itemprop="url">安全场景（4）Webshell检测</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-15 17:20:29" itemprop="dateCreated datePublished" datetime="2022-05-15T17:20:29+08:00">2022-05-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-05-20 16:07:03" itemprop="dateModified" datetime="2022-05-20T16:07:03+08:00">2022-05-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" itemprop="url" rel="index"><span itemprop="name">应用场景</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>382</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="深度学习phpwebshell查杀引擎demo">深度学习PHP
webshell查杀引擎demo</span></h2>
<blockquote>
<ul>
<li>https://www.cdxy.me/?p=788</li>
<li><strong>==Webshell研究综述：检测与对抗技术的动态博弈进展==</strong>：https://zhuanlan.zhihu.com/p/259985000</li>
</ul>
</blockquote>
<h5><span id="传统webshell查杀思路">传统webshell查杀思路</span></h5>
<ul>
<li>规则系统</li>
<li>旁路执行</li>
<li>沙箱</li>
</ul>
<h5><span id="基于机器学习深度学习的webshell查杀引擎通过专家知识提取特征训练分类器其结果受样本-特征-结构等多种因素影响">基于机器学习/深度学习的webshell查杀引擎，通过专家知识提取特征训练分类器，其结果受样本、特征、结构等多种因素影响。</span></h5>
<h5><span id="特征维度">特征维度：</span></h5>
<ul>
<li><strong>统计特征</strong> (信息熵/重合指数/最长词/可压缩比)</li>
<li><strong>历史数据特征</strong>
(计算单个文件的落盘时间/文件创建进程/文件类型/代码风格/权限和同目录下其他文件的"距离")</li>
<li><strong>OP指令层特征</strong> (指令/调用链/参数文本特征)</li>
<li><strong>动态特征</strong>
(文件读写/网络连接，可依靠沙箱或旁路执行能力解决编码混淆类case)</li>
<li><strong>文本语义</strong> (n-gram/TF-IDF/word2vec/CNN/RNN)</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/QAPBHZ/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/QAPBHZ/" class="post-title-link" itemprop="url">深度学习（8）Attention</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-14 23:08:42" itemprop="dateCreated datePublished" datetime="2022-05-14T23:08:42+08:00">2022-05-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-07-12 19:40:02" itemprop="dateModified" datetime="2022-07-12T19:40:02+08:00">2022-07-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Seq2Seq/" itemprop="url" rel="index"><span itemprop="name">Seq2Seq</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1><span id="attention-注意力机制">Attention-注意力机制</span></h1>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://paddlepedia.readthedocs.io/en/latest/tutorials/deep_learning/model_tuning/attention/attention_description.html">注意力机制</a></p>
<p>如何理解attention中的Q,K,V？ - 林亿的回答 - 知乎
https://www.zhihu.com/question/298810062/answer/2274132657</p>
<p>Self-attention中dot-product操作为什么要被缩放：https://www.zhihu.com/question/339723385/answer/782509914</p>
</blockquote>
<h3><span id="一-注意力机制是什么">一、注意力机制是什么</span></h3>
<p>假设有一天热爱绘画的你决定去户外写生，你来到一片山坡上，极目远去，心旷神怡。头顶一片蔚蓝，脚踩一席草绿，远处山川连绵，眼前花草送香，暖阳含羞云后，轻风拂动衣襟，鸟啼虫鸣入耳，美景丹青共卷。</p>
<p>你集中精神，拿起画笔将蓝天、白云、青草等等这些元素，按照所思所想纷纷绘入画板。在绘画的过程中，你会持续地关注你构思到画板上的元素（比如蓝天，白云），而不会太多关注那些其他的元素，比如风，虫鸣，阳光等等。即你的精神是聚焦在你关心的那些事物上，这其实就是注意力的体现，这种有意识的聚焦被称为<strong>聚焦式注意力（Focus
Attention</strong>）。</p>
<p>在深度学习领域，模型往往需要接收和处理大量的数据，然而在特定的某个时刻，往往只有少部分的某些数据是重要的，这种情况就非常适合<strong>Attention机制</strong>发光发热。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220529190526010.png" alt="image-20220529190526010" style="zoom:50%;"></p>
<p>举个例子，<strong>上图</strong>展示了一个机器翻译的结果，在这个例子中，我们想将”who
are
you”翻译为”你是谁”，传统的模型处理方式是一个seq-to-seq的模型，其包含一个encoder端和一个decoder端，其中encoder端对”who
are
you”进行编码，然后将整句话的信息传递给decoder端，由decoder解码出”我是谁”。在这个过程中，decoder是逐字解码的，在每次解码的过程中，如果接收信息过多，可能会导致模型的内部混乱，从而导致错误结果的出现。</p>
<p>我们可以使用<strong>Attention机制</strong>来解决这个问题，从<strong>图中</strong>可以看到，在生成”你”的时候和单词”you”关系比较大，和”who
are”关系不大，所以我们更希望在这个过程中能够使用<strong>Attention机制</strong>，将更多注意力放到”you”上，而不要太多关注”who
are”，从而提高整体模型的表现。</p>
<blockquote>
<p>备注：在深度学习领域，无意识的<strong>显著性注意力</strong>更加常见。</p>
</blockquote>
<p>Attention机制自提出以来，出现了很多不同Attention应用方式，但大道是共同的，均是将模型的注意力聚焦在重要的事情上。本文后续将选择一些经典或常用的Attention机制展开讨论。</p>
<h3><span id="二-经典注意力机制">二、经典注意力机制</span></h3>
<h4><span id="21用机器翻译任务带你看attention机制的计算">2.1
用机器翻译任务带你看Attention机制的计算</span></h4>
<p>单独地去讲<strong>Attention机制</strong>会有些抽象，也有些枯燥，所以我们不妨以<strong>机器翻译</strong>任务为例，通过讲解<strong>Attention机制</strong>在机器翻译任务中的应用方式，来了解<strong>Attention机制</strong>的使用。</p>
<p>什么是机器翻译任务？以<strong>中译英</strong>为例，机器翻译是将一串中文语句翻译为对应的英文语句，如<strong>图1</strong>所示。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220529201640683.png" alt="image-20220529201640683" style="zoom:50%;"></p>
<p>图1展示了一种经典的机器翻译结构Seq-to-Seq,
并且向其中添加了Attention计算。<strong>Seq-to-Seq结
构包含两个部分：Encoder和Decoder</strong>。其中Encoder用于将中文语句进行编码,
这些编码后续将提 供给Decoder进行使用;
Decoder将根据Encoder的数据进行解码。我们还是以图1为例详细解释一
下Decoder的解码过程。 更明确的讲,
图1展示的是生成单词"machine"时的计算方式。首先将前一个时刻的输出状态
<span class="math inline">\(q_{2}\)</span> 和 Encoder的输出 <span class="math inline">\(h=\left[h_{1}, h_{2}, h_{3}, h_{4}\right]\)</span>
进行Attention计算, 得到一个当前时刻的 context, 用公式可 以这样组织:
<span class="math display">\[
\begin{aligned}
{\left[a_{1}, a_{2}, a_{3}, a_{4}\right] }
&amp;=\operatorname{softmax}\left(\left[s\left(q_{2}, h_{1}\right),
s\left(q_{2}, h_{2}\right), s\left(q_{2}, h_{3}\right), s\left(q_{2},
h_{4}\right)\right]\right) \\
\text { context } &amp;=\sum_{i=1}^{4} a_{i} \cdot h_{i}
\end{aligned}
\]</span> 我们来解释一下, 这里的 <span class="math inline">\(s\left(q_{i}, h_{j}\right)\)</span>
表示注意力打分函数, 它是个标量, 其大小描述了当前时刻在这
些Encoder的结果上的关注程度,
这个函数在后边会展开讨论。然后用softmax对这个结果进行归一 化,
最后使用加权评价获得当前时刻的上下文向量 context。这个context
可以解释为：截止到当前 已经有了"I love",
在此基础上下一个时刻应该更加关注源中文语句的那些内容。这就是关于
Attention机制的一个完整计算。</p>
<p><strong>最后,
将这个context和上个时刻的输出”love"进行融合作为当前时刻RNN单元的输入</strong>。图1中采用了继续融合上一步的输出结果,
例如上述描述中融合了"love", 在有些实现中, 并没 有融入这个上一步的输出,
默认 <span class="math inline">\(q_{2}\)</span>
中已经携带了"love"的信息, 这也是合理的。</p>
<h4><span id="22-注意力机制的正式引入">2.2 注意力机制的正式引入</span></h4>
<p>前边我们通过机器翻译任务介绍了<strong>Attention机制</strong>的整体计算。但是还有点<strong>小尾巴</strong>没有展开，就是那个<strong>注意力打分函数</strong>的计算，现在我们将来讨论这个事情。但在讲这个函数之前，我们先来对上边的<strong>Attention机制</strong>的计算做个总结，<strong>图2</strong>详细地描述了Attention机制的计算原理。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220529202937945.png" alt="image-20220529202937945" style="zoom:50%;"></p>
<p>假设现在我们要对一组输入 <span class="math inline">\(H=\left[h_{1},
h_{2}, h_{3}, \ldots, h_{n}\right]\)</span>
使用<strong>Attention机制</strong>计算重要的内容, 这里往
往需要一个<strong>查询向量</strong> <span class="math inline">\(q\)</span> (这个向量往往和你做的任务有关,
比如机器翻译中用到的那个 <span class="math inline">\(q_{2}\)</span> ),
然后通 过一个<strong>打分函数</strong>计算查询向量 <span class="math inline">\(q\)</span> 和每个输入 <span class="math inline">\(h_{i}\)</span> 之间的相关性,
得出一个分数。<strong>接下来使用softmax 对这些分数进行归一化,
归一化后的结果便是查询向量 <span class="math inline">\(q\)</span>
在各个输入 <span class="math inline">\(h_{i}\)</span>
上的注意力分布</strong><span class="math inline">\(a=\left[a_{1}, a_{2},
a_{3}, \ldots, a_{n}\right]\)</span>, 其中每一项数值和原始的输入<span class="math inline">\(H=\left[h_{1}, h_{2}, h_{3}, \ldots,
h_{n}\right]\)</span> 一一对应。以 <span class="math inline">\(a_{i}\)</span> 为例, 相关计算公式如下: <span class="math display">\[
a_{i}=\operatorname{softmax}\left(s\left(h_{i},
q\right)\right)=\frac{\exp \left(s\left(h_{i},
q\right)\right)}{\sum_{j=1}^{n} \exp \left(s\left(h_{j},
q\right)\right)}
\]</span> 最后根据这些注意力分布可以去有选择性的从输入信息 <span class="math inline">\(H\)</span> 中提取信息, 这里比较常用的信息提取方式,
是一种”软性”的信息提取（图2展示的就是一种"软性"注意力）,
即根据注意力分布对输入信 息进行加权求和，最终的这个结果 context
体现了模型当前应该关注的内容： <span class="math display">\[
\text { context }=\sum_{i=1}^{n} a_{i} \cdot h_{i}
\]</span> 现在我们来解决之前一直没有展开的小尾巴-打分函数,
它可以使用以下几种方式来计算: - <strong>加性模型</strong>: <span class="math inline">\(s(h, q)=v^{T} \tanh (W h+U q)\)</span> -
<strong>点积模型</strong>: <span class="math inline">\(s(h, q)=h^{T}
q\)</span> - <strong><font color="red"> 缩放点积模型</font></strong>:
<span class="math inline">\(s(h, q)=\frac{h^{T} q}{\sqrt{D}}\)</span> -
<strong>双线性模型</strong>: <span class="math inline">\(s(h, q)=h^{T} W
q\)</span></p>
<p>以上公式中的参数 <span class="math inline">\(W 、 U\)</span> 和 <span class="math inline">\(v\)</span> 均是可学习的参数矩阵或向量, <span class="math inline">\(D\)</span> 为输入向量的维度。下边我们来分
析一下这些分数计算方式的差别。</p>
<p><strong>加性模型</strong>引入了可学习的参数, 将查询向量 <span class="math inline">\(q\)</span> 和原始输入向量 <span class="math inline">\(h\)</span> 映射到不同的向量空间后进行计算打分,
显然相较于加性模型, <strong>点积模型</strong>具有更好的计算效率。</p>
<p>另外, 当输入向量的维度比较高的时候,
<strong>点积模型</strong>通常有比较大的方差, 从而导致Softmax函数的
梯度会比较小。因此<strong>缩放点积模型</strong>通过除以一个<strong>平方根项</strong>来平滑分数数值,
也相当于平滑最终的<strong>注意力分布</strong>, 缓解这个问题。</p>
<p>最后, <strong>双线性模型</strong>可以重塑为 <span class="math inline">\(s\left(h_{i}, q\right)=h^{T} W q=h^{T}\left(U^{T}
V\right) q=(U h)^{T}(V q)\)</span>, 即分别对查询向量 <span class="math inline">\(q\)</span> 和原始输入向量 <span class="math inline">\(h\)</span> 进行线性变换之后,
再计算点积。<strong>相比点积模型, 双线性模型在计算相似度时
引入了非对称性</strong>。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/VR9NEX/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/VR9NEX/" class="post-title-link" itemprop="url">深度学习（8）Self Attention*-p1</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-14 23:08:42" itemprop="dateCreated datePublished" datetime="2022-05-14T23:08:42+08:00">2022-05-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-08-25 23:34:26" itemprop="dateModified" datetime="2022-08-25T23:34:26+08:00">2022-08-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Seq2Seq/" itemprop="url" rel="index"><span itemprop="name">Seq2Seq</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>12 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="一-李宏毅-selfattention自注意力机制-p1"><font color="red"> 一、李宏毅-Self
Attention自注意力机制 - p1</font></span></h2>
<blockquote>
<p>相关性查询（q, k）-softmax - 乘上v</p>
<p>视频链接：https://www.bilibili.com/video/BV1JK4y1D7Wb?p=26&amp;vd_source=29387dc08d18f642078183a6816e93e8</p>
</blockquote>
<blockquote>
<p>跟自己计算关联性重要吗？</p>
<p>为什么用softmax？relu也行</p>
</blockquote>
<p>到目前为止,我们的Network的<strong>Input</strong>都是<strong>一个向量</strong>,不管是在预测这个,YouTube观看人数的问题上啊,还是影像处理上啊,我们的输入都可以看作是一个向量,然后我们的输出,可能是一个<strong>数值</strong>,这个是<strong>Regression</strong>,可能是一个<strong>类别</strong>,这是<strong>Classification</strong></p>
<h3><span id="11-what-is-the-output">1.1 What is the output?</span></h3>
<p>我们刚才已经看说输入是一堆向量,它可以是文字,可以是语音,可以是Graph,那这个时候,我们有可能有什么样的<strong>输出呢,</strong>有三种可能性。</p>
<h4><span id="111每一个向量都有一个对应的label">1.1.1
每一个向量都有一个对应的Label</span></h4>
<p>当你的模型,看到输入是四个向量的时候,它就要输出四个Label,而每一个Label,它可能是一个数值,那就是Regression的问题,如果每个Label是一个Class,那就是一个Classification的问题。</p>
<p><img src="image-20220612171420908.png" alt="image-20220612171420908" style="zoom: 33%;"></p>
<p>举例来说 在文字处理上,假设你今天要做的是==<strong>POS
Tagging</strong>==,POS Tagging就是词性标註,你要让机器自动决定每一个词汇
它是什么样的词性,它是名词 还是动词 还是形容词等等。</p>
<p>这个任务啊,其实并没有很容易,举例来说,你现在看到一个句子,I saw a
saw。这并不是打错,并不是“我看一个看”,而是“我看到一个锯子”,这个第二个saw当名词用的时候,它是锯子，那所以机器要知道,第一个saw是个动词,第二个saw虽然它也是个saw,但它是名词,但是每一个输入的词汇,都要有一个对应的输出的词性。</p>
<h4><span id="112一整个sequence只需要输出一个label">1.1.2
一整个Sequence,只需要输出一个Label</span></h4>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220612171433616.png" alt="image-20220612171433616" style="zoom:50%;"></p>
<p>举例来说,如果是文字的话,我们就说<strong>Sentiment
Analysis</strong>。Sentiment
Analysis就是给机器看一段话,它要<strong>决定说这段话是正面的还是负面的</strong>。</p>
<p>那你可以想像说这种应用很有用,假设你的公司开发了一个产品,这个产品上线了,你想要知道网友的评价怎么样,但是你又不可能一则一则网友的留言都去分析,那也许你就可以用这种,Sentiment
Analysis的技术,让机器自动去判读说,当一则贴文里面有提到某个产品的时候,它是正面的
还是负面的,那你就可以知道你的产品,在网友心中的评价怎么样,这个是Sentiment
Analysis给一整个句子,只需要一个Label,那Positive或Negative,那这个就是第二类的输出。</p>
<p>那如果是语音的例子的话呢,在作业四里面我们会做语者辨认,机器要听一段声音,然后决定他是谁讲的。或者是如果是Graph的话呢,今天你可能想要给一个分子,然后要预测说这个分子,比如说它有没有毒性,或者是它的亲水性如何,那这就是给一个Graph
输出一个Label。</p>
<h4><span id="113机器要自己决定应该要输出多少个label">1.1.3
机器要自己决定,应该要输出多少个Label</span></h4>
<p>我们不知道应该输出多少个Label,机器要自己决定,应该要输出多少个Label,可能你输入是N个向量,输出可能是N'个Label,为什么是N',机器自己决定。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220612171446043.png" alt="image-20220612171446043" style="zoom:50%;"></p>
<p>这种任务又叫做==sequence to
sequence==的任务,那我们在作业五会有sequence to
sequence的作业,所以这个之后我们还会再讲</p>
<ul>
<li>翻译就是sequence to
sequence的任务,因为输入输出是不同的语言,它们的词汇的数目本来就不会一样多</li>
<li>或者是语音辨识也是,真正的语音辨识也是一个sequence to
sequence的任务,输入一句话,然后输出一段文字,这也是一个sequence to
sequence的任务</li>
</ul>
<p>第二种类型有作业四,感兴趣可以去看看作业四的程式，那因为上课时间有限,所以上课,我们今天就先只讲第一个类型,也就是输入跟输出数目一样多的状况。</p>
<h3><span id="12-sequence-labeling">1.2 Sequence Labeling</span></h3>
<p>那这种输入跟输出数目一样多的状况又叫做<strong>Sequence
Labeling</strong>,你要给Sequence里面的每一个向量,都给它一个Label,那要怎么解Sequence
Labeling的问题呢？那直觉的想法就是我们就拿个<strong>Fully-Connected的Network</strong>。</p>
<p>然后虽然这个输入是一个Sequence,但我们就各个击破,不要管它是不是一个Sequence,把每一个向量,分别输入到Fully-Connected的Network里面，然后Fully-Connected的Network就会给我们输出,那现在看看,你要做的是Regression还是Classification,产生正确的对应的输出,就结束了,</p>
<p><font color="red">
那这么做显然有<strong>非常大的瑕疵</strong>,假设今天是,词性标记的问题,你给机器一个句子,I
saw a saw,对Fully-Connected
Network来说,<strong>后面这一个saw跟前面这个saw完全一模一样</strong>,它们是同一个词汇啊。</font></p>
<h4><span id="方案一window">方案一：Window</span></h4>
<p>既然Fully-Connected的Network<strong>输入同一个词汇,它没有理由输出不同的东西</strong>。但实际上,你期待第一个saw要输出动词,第二个saw要输出名词,但对Network来说它不可能做到,因为这两个saw
明明是一模一样的,你叫它一个要输出动词,一个要输出名词,它会非常地困惑,完全不知道要怎么处理。所以怎么办,有没有可能<strong>让Fully-Connected的Network,考虑更多的,比如说上下文的Context的资讯</strong>呢。这是有可能的,你就<strong>把前后几个向量都串起来,一起丢到Fully-Connected的Network就结束了</strong>。</p>
<p>所以我们可以给Fully-Connected的Network,一整个Window的资讯,让它可以考虑一些上下文的,跟我现在要考虑的这个向量,相邻的其他向量的资讯。把Window开大一点啊,大到可以把整个Sequence盖住就结束了。</p>
<p>如果你今天说我真的要开一个Window,把整个Sequence盖住,那你可能要<strong>统计一下你的训练资料</strong>,然后看看你的训练资料里面,最长的Sequence有多长,然后开一个Window比最长的Sequence还要长,你才有可能把整个Sequence盖住但是你开一个这么大的Window,意味著说你的Fully-Connected的Network,它需要非常多的参数,那可能不只<strong>运算量很大,可能还容易Overfitting</strong>。</p>
<h4><span id="方案二self-attention">方案二：self-attention</span></h4>
<p>Self-Attention的运作方式就是,<strong>Self-Attention会吃一整个Sequence的资讯</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613211233215.png" alt="image-20220613211233215" style="zoom:50%;"></p>
<p>然后你Input几个Vector,它就输出几个Vector,比如说你这边Input一个深蓝色的Vector,这边就给你一个另外一个Vector。这边给个浅蓝色,它就给你另外一个Vector,这边输入4个Vector,它就Output
4个Vector。那这4个Vector有什么特别的地方呢,<strong>这4个Vector,他们都是考虑一整个Sequence以后才得到的</strong>,那等一下我会讲说Self-Attention,怎么考虑一整个Sequence的资讯。</p>
<p><strong><font color="red">
如此一来你这个Fully-Connected的Network,它就不是只考虑一个非常小的范围,或一个小的Window,而是考虑整个Sequence的资讯,再来决定现在应该要输出什么样的结果，这个就是Self-Attention</font></strong>。<strong>Self-Attention不是只能用一次,你可以叠加很多次</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613211415203.png" alt="image-20220613211415203" style="zoom:50%;"></p>
<p>可以Self-Attention的输出,通过Fully-Connected
Network以后,再做一次Self-Attention,Fully-Connected的Network,再过一次Self-Attention,再重新考虑一次整个Input
Sequence的资讯,再丢到另外一个Fully-Connected的Network,最后再得到最终的结果。</p>
<p>所以<strong>可以把Fully-Connected的Network,跟Self-Attention交替使用</strong></p>
<ul>
<li>Self-Attention处理整个Sequence的资讯</li>
<li>Fully-Connected的Network,专注于处理某一个位置的资讯</li>
<li>再用Self-Attention,再把整个Sequence资讯再处理一次</li>
<li>然后交替使用Self-Attention跟Fully-Connected</li>
</ul>
<p>有关Self-Attention,最知名的相关的文章,就是《Attention is all you
need》.那在这篇Paper里面呢,Google提出了==Transformer==这样的Network架构,那Transformer就是变形金刚,所以提到这个Network的时候呢,我们就会有变形金刚这个形象。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613211500443.png" alt="image-20220613211500443" style="zoom:50%;"></p>
<p>Transformer我们今天还不会讲到,但我们之后会讲到,Transformer里面一个最重要的Module就是Self-Attention,它就是变形金刚的火种源。那这篇Paper最厉害的地方,就是它有一个<strong>霸气的名字Attention
is all you need.</strong></p>
<p>那其实像Self-Attention这样的架构,最早我并不会说它是出现在《Attention
is all you
need》这样的Paper,因为其实很多更早的Paper,就有提出过类似的架构,只是不见得叫做Self-Attention,比如说叫做Self-Matching,或者是叫别的名字,不过呢是Attention
is all you need.这篇Paper,把Self-Attention这个Module,把它发扬光大。</p>
<h3><span id="13-self-attention过程">1.3 Self-Attention过程</span></h3>
<p><strong><font color="red">
Self-Attention的Input,它就是一串的Vector,那这个Vector可能是你整个Network的Input,它也可能是某个Hidden
Layer的Output,所以我们这边不是用<span class="math inline">\(x\)</span>来表示它，用<span class="math inline">\(a\)</span>来表示它。</font></strong></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613211620957.png" alt="image-20220613211620957" style="zoom:50%;"></p>
<p>我们用<span class="math inline">\(a\)</span>来表示它，代表它有可能是前面已经做过一些处理,它是某个Hidden
Layer的Output,那Input一排a这个向量以后,Self-Attention要Output另外一排b这个向量。那这<strong>每一个b都是考虑了所有的a以后才生成出来的</strong>,所以这边刻意画了非常非常多的箭头,告诉你$b^1
<span class="math inline">\(考虑了\)</span>a<sup>1<span class="math inline">\(到\)</span>a</sup>4<span class="math inline">\(产生的,\)</span>b<sup>2<span class="math inline">\(考虑\)</span>a</sup>1<span class="math inline">\(到\)</span>a<sup>4<span class="math inline">\(产生的,\)</span>b</sup>3
b^4$也是一样,考虑整个input的sequence,才产生出来的。</p>
<p>那接下来呢就是要跟大家说明,<strong>怎么产生<span class="math inline">\(b^1\)</span>这个向量</strong>,那你知道怎么产生<span class="math inline">\(b^1\)</span>这个向量以后,你就知道怎么产生剩下<span class="math inline">\(b^1 b^2 b^3 b^4\)</span>剩下的向量。</p>
<p><font color="red">
这里有一个<strong>特别的机制</strong>,<strong>这个机制是根据<span class="math inline">\(a^1\)</span>这个向量,找出整个很长的sequence里面,到底哪些部分是重要的,哪些部分跟判断<span class="math inline">\(a^1\)</span>是哪一个label是有关系的,哪些部分是我们要决定<span class="math inline">\(a^1\)</span>的class,决定<span class="math inline">\(a^1\)</span>的regression数值的时候,所需要用到的资讯</strong>。</font></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613212112611.png" alt="image-20220613212112611" style="zoom:50%;"></p>
<p><strong>每一个向量跟<span class="math inline">\(a^1\)</span>的关联的程度,用一个数值叫α来表示</strong>，这个self-attention的module,<strong>怎么自动决定两个向量之间的关联性</strong>呢,你给它两个向量<span class="math inline">\(a^1\)</span>跟<span class="math inline">\(a^4\)</span>,它怎么决定<span class="math inline">\(a^1\)</span>跟<span class="math inline">\(a^4\)</span>有多相关,然后给它一个数值α呢,那这边呢你就需要一个<strong>计算attention的模组</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613212206065.png" alt="image-20220613212206065" style="zoom:50%;"></p>
<p>这个计算attention的模组,就是拿<strong>两个向量作为输入</strong>,然后它就直接输出α那个数值,计算这个α的数值有各种不同的做法：</p>
<ul>
<li><p>==dot
product==：<strong>输入的这两个向量分别乘上两个不同的矩阵</strong>,左边这个向量乘上<span class="math inline">\(W^q\)</span>这个矩阵得到矩阵<span class="math inline">\(q\)</span>,右边这个向量乘上<span class="math inline">\(W^k\)</span>这个矩阵得到矩阵<span class="math inline">\(k\)</span></p>
<p>再把<span class="math inline">\(q\)</span>跟<span class="math inline">\(k\)</span>做dot product,就是把他们做element-wise
的相乘,再全部加起来以后就得到一个
scalar,这个scalar就是α,这是一种计算α的方式</p></li>
<li><p>==Additive==：把同样这两个向量通过<span class="math inline">\(W^q\)</span> <span class="math inline">\(W^k\)</span>,得到<span class="math inline">\(q\)</span>跟<span class="math inline">\(k\)</span>,那我们不是把它做Dot-Product,是把它这个串起来,然后丢到这个过一个Activation
Function，然后再通过一个Transform,然后得到α。</p></li>
</ul>
<p>总之有非常多不同的方法,可以计算Attention,可以计算这个α的数值,可以计算这个关联的程度，但是在接下来的讨论里面,我们都<strong>只用左边这个方法</strong>,这也是今日最常用的方法,也<strong>是用在Transformer里面的方法</strong>。那你就要把这边的<span class="math inline">\(a^1\)</span>去跟这边的<span class="math inline">\(a^2 a^3
a^4\)</span>,分别都去计算他们之间的关联性,也就是计算他们之间的α。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613212357947.png" alt="image-20220613212357947" style="zoom:50%;"></p>
<p>你把<span class="math inline">\(a^1\)</span>乘上$W^q <span class="math inline">\(得到\)</span>q^1$,那这个q有一个名字,我们叫做==Query==,它就像是你搜寻引擎的时候,去搜寻相关文章的问题,就像搜寻相关文章的关键字,所以这边叫做Query。</p>
<p>然后接下来呢,<span class="math inline">\(a^2 a^3
a^4\)</span>你都要去把它乘上<span class="math inline">\(W^k\)</span>,得到<span class="math inline">\(k\)</span>这个Vector,<span class="math inline">\(k\)</span>这个Vector叫做==Key==,那你把这个<font color="red">
<strong>Query q1,跟这个Key k2,算 Inner-Product就得到 α‘
（注意力矩阵）</strong>。</font>我们这边用<span class="math inline">\(α_{1,2}\)</span>来代表说,Query是1提供的,Key是2提供的时候,这个1跟2他们之间的关联性,这个α这个关联性叫做==Attention的Score==,叫做Attention的分数。</p>
<p>接下来也要跟<span class="math inline">\(a^3
a^4\)</span>来计算，把<span class="math inline">\(a_3\)</span>乘上<span class="math inline">\(W^k\)</span>,得到另外一个Key也就是<span class="math inline">\(k^3\)</span>,<span class="math inline">\(a^4\)</span>乘上<span class="math inline">\(W^k\)</span>得到<span class="math inline">\(k^4\)</span>,然后你再把<span class="math inline">\(k^3\)</span>这个Key,跟<span class="math inline">\(q^1\)</span>这个Query做Inner-Product,得到1跟3之间的关联性,得到1跟3的Attention,你把<span class="math inline">\(k^4\)</span>跟<span class="math inline">\(q^1\)</span>做Dot-Product,得到<span class="math inline">\(α_{1,4}\)</span>,得到1跟4之间的关联性。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613212536289.png" alt="image-20220613212536289" style="zoom:50%;"></p>
<p><font color="red"> 其实一般在实作时候,<strong><span class="math inline">\(q^1\)</span>也会跟自己算关联性</strong>,自己跟自己计算关联性这件事情有多重要。</font>计算出,a1跟每一个向量的关联性以后,接下来这边会<strong>接入一个Soft-Max</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613221201944.png" alt="image-20220613221201944" style="zoom:50%;"></p>
<p><strong><font color="red">这个Soft-Max跟分类的时候的那个Soft-Max是一模一样的
</font></strong>,所以Soft-Max的输出就是一排α,所以本来有一排α,通过Soft-Max就得到<span class="math inline">\(α&#39;\)</span>。</p>
<p>这边你<strong>不一定要用Soft-Max,用别的替代也没问题</strong>,比如说有人尝试过说做个ReLU,这边通通做个ReLU,那结果发现还比Soft-Max好一点,所以这边你不一定要用Soft-Max,这边你要用什么Activation
Function都行,你高兴就好,你可以试试看,那Soft-Max是最常见的,那你可以自己试试看,看能不能试出比Soft-Max更好的结果。</p>
<p>接下来得到这个<span class="math inline">\(α&#39;\)</span>以后,我们就要根据这个<span class="math inline">\(α&#39;\)</span>去抽取出这个Sequence里面重要的资讯,根据这个α我们已经知道说,哪些向量跟<span class="math inline">\(a^1\)</span>是最有关系的,<strong>怎么抽取重要的资讯呢？</strong></p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220613221501080.png" alt="image-20220613221501080" style="zoom:50%;"></p>
<ul>
<li><p>首先把<span class="math inline">\(a^1\)</span>到<span class="math inline">\(a^4\)</span>这边每一个向量,乘上$W^v <span class="math inline">\(得到新的向量,这边分别就是用\)</span>v^1 v^2 v^3
v^4$来表示</p></li>
<li><p>接下来把这边的<span class="math inline">\(v^1\)</span>到<span class="math inline">\(v^4\)</span>,每一个向量都去乘上Attention的分数,都去乘上<span class="math inline">\(α&#39;\)</span></p></li>
<li><p>然后再把它加起来,得到<span class="math inline">\(b^1\)</span></p></li>
</ul>
<p><span class="math display">\[
b^1=\sum_i\alpha&#39;_{1,i}v^i
\]</span></p>
<p>如果某一个向量它得到的分数越高,比如说如果<span class="math inline">\(a^1\)</span>跟<span class="math inline">\(a^2\)</span>的关联性很强,这个<span class="math inline">\(α&#39;\)</span>得到的值很大,那我们今天在做Weighted
Sum以后,得到的<span class="math inline">\(b^1\)</span>的值,就可能会比较接近<span class="math inline">\(v^2\)</span>，所以<strong>谁的那个Attention的分数最大,谁的那个<span class="math inline">\(v\)</span>就会Dominant你抽出来的结果</strong>。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/2Q8V137/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/2Q8V137/" class="post-title-link" itemprop="url">深度学习（8）Self Attention*-p2</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-14 23:08:42" itemprop="dateCreated datePublished" datetime="2022-05-14T23:08:42+08:00">2022-05-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-08-25 23:31:11" itemprop="dateModified" datetime="2022-08-25T23:31:11+08:00">2022-08-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Seq2Seq/" itemprop="url" rel="index"><span itemprop="name">Seq2Seq</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>16k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>29 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="二-李宏毅-selfattention自注意力机制-p2"><font color="red"> 二、李宏毅-Self
Attention自注意力机制 - p2</font></span></h2>
<p><img src="image-20220613221835154.png" alt="image-20220613221835154" style="zoom:50%;"></p>
<p>从这一排 vector 得到 <span class="math inline">\(b^1\)</span>,跟从这一排 vector 得到 <span class="math inline">\(b^2\)</span>,它的操作是一模一样的.要强调一点是,这边的
<span class="math inline">\(b^1\)</span> 到 <span class="math inline">\(b^4\)</span>,它们并<strong>不需要依序产生</strong>,它们是一次同时被计算出来的。</p>
<p>怎么计算这个 <span class="math inline">\(b^2\)</span>？我们现在的主角,就变成 <span class="math inline">\(a^2\)</span></p>
<p><img src="image-20220613221854934.png" alt="image-20220613221854934" style="zoom:50%;"></p>
<ul>
<li><p>把 <span class="math inline">\(a^2\)</span> 乘上一个 matrix,变成
<span class="math inline">\(q^2\)</span></p></li>
<li><p>然后接下来根据 <span class="math inline">\(q^2\)</span>,去对<span class="math inline">\(a^1\)</span>到 <span class="math inline">\(a^4\)</span> 这四个位置,都去计算 attention 的
score</p>
<ul>
<li>把 <span class="math inline">\(q^2\)</span> 跟 <span class="math inline">\(k^1\)</span> 做个这个 dot product</li>
<li>把 <span class="math inline">\(q^2\)</span> 跟 <span class="math inline">\(k^2\)</span> 也做个 dot product</li>
<li>把 <span class="math inline">\(q^2\)</span> 跟 <span class="math inline">\(k^3\)</span> 也做 dot product</li>
<li>把 <span class="math inline">\(q^2\)</span> 跟 <span class="math inline">\(k^4\)</span> 也做 dot product,得到四个分数</li>
</ul></li>
<li><p>得到这四个分数以后,可能还会做一个 <strong>normalization
</strong>和 <strong>softmax</strong>,然后得到最后的 attention 的
score,<span class="math inline">\(α&#39;_{2,1} \space α&#39;_{2,2}
\space α&#39;_{2,3} \space α&#39;_{2,4}\)</span>那我们这边用 <span class="math inline">\(α&#39;\)</span>表示经过 normalization
以后的attention score</p></li>
<li><p>接下来拿这四个数值,分别乘上 <span class="math inline">\(v^1
\space v^2 \space v^3 \space v^4\)</span></p>
<p><img src="image-20220613221952411.png" alt="image-20220613221952411" style="zoom:50%;"></p>
<ul>
<li>把 <span class="math inline">\(α&#39;_{2,1}\)</span>乘上 <span class="math inline">\(v^1\)</span></li>
<li>把 <span class="math inline">\(α&#39;_{2,2}\)</span> 乘上 <span class="math inline">\(v^2\)</span></li>
<li>把 <span class="math inline">\(α&#39;_{2,3}\)</span> 乘上 <span class="math inline">\(v^3\)</span></li>
<li>把 <span class="math inline">\(α&#39;_{2,4}\)</span> 乘上 <span class="math inline">\(v^4\)</span>,然后全部加起来就是 $ b^2$</li>
</ul>
<p><span class="math display">\[
  b^2=\sum_iα&#39;_{2,i}v^i
  \]</span></p></li>
</ul>
<p>同理就可以,由 <span class="math inline">\(a^3\)</span> 乘一个
transform 得到 <span class="math inline">\(q^3\)</span>,然后就计算 <span class="math inline">\(b^3\)</span>,从 <span class="math inline">\(a^4\)</span> 乘一个 transform 得到 <span class="math inline">\(q^4\)</span>,就计算 <span class="math inline">\(b^4\)</span>,以上说的是 Self-attention
它运作的过程。</p>
<h3><span id="22-矩阵的角度">2.2 矩阵的角度</span></h3>
<p>接下来我们从矩阵乘法的角度,再重新讲一次我们刚才讲的,Self-attention
是怎么运作的，我们现在已经知道每一个 a 都产生 q k v。</p>
<p><img src="image-20220613222115187.png" alt="image-20220613222115187" style="zoom:50%;"></p>
<h5><span id="如果要用矩阵运算表示这个操作的话是什么样子呢">如果要用矩阵运算表示这个操作的话,是什么样子呢</span></h5>
<p>我们每一个 a,都乘上一个矩阵,我们这边用 <span class="math inline">\(W^q\)</span> 来表示它,得到 <span class="math inline">\(q^i\)</span>,每一个 a 都要乘上 <span class="math inline">\(W^q\)</span>,得到<span class="math inline">\(q^i\)</span>,<strong>这些不同的 a
你可以把它合起来,当作一个矩阵来看待</strong>。</p>
<p><img src="image-20220613222137478.png" alt="image-20220613222137478" style="zoom:50%;"></p>
<p>一样$a<sup>2a</sup>3a^4 $也都乘上 <span class="math inline">\(W^q\)</span> 得到$q^2 q^3 $跟 <span class="math inline">\(q^4\)</span>,那你可以<strong>把 a1 到 a4
拼起来</strong>,看作是一个矩阵,这个矩阵我们用 I 来表示，这个矩阵的四个
column 就是 <span class="math inline">\(a^1\)</span> 到 <span class="math inline">\(a^4\)</span>。</p>
<p><span class="math inline">\(I\)</span> 乘上 <span class="math inline">\(W^q\)</span> 就得到另外一个矩阵,我们用 <span class="math inline">\(Q\)</span> 来表示它,这个 <span class="math inline">\(Q\)</span> 就是把 <span class="math inline">\(q^1\)</span> 到 <span class="math inline">\(q^4\)</span> 这四个 vector 拼起来,就是 <span class="math inline">\(Q\)</span> 的四个 column。</p>
<p>所以我们从 <span class="math inline">\(a^1\)</span> 到 <span class="math inline">\(a^4\)</span>,得到 <span class="math inline">\(q^1\)</span> 到 <span class="math inline">\(q^4\)</span>这个操作,其实就是<strong>把 I
这个矩阵,乘上另外一个矩阵 <span class="math inline">\(W^q\)</span>，得到矩阵<span class="math inline">\(Q\)</span></strong>。<span class="math inline">\(I\)</span> 这个矩阵它里面的 column就是我们
Self-attention 的 input是 <span class="math inline">\(a^1\)</span> 到
<span class="math inline">\(a^4\)</span>；<strong><span class="math inline">\(W^q\)</span>其实是 network
的参数,它是等一下会被learn出来的</strong> ；<span class="math inline">\(Q\)</span> 的四个 column,就是 <span class="math inline">\(q^1\)</span> 到 <span class="math inline">\(q^4\)</span>。接下来产生 k 跟 v 的操作跟 q
是一模一样的。</p>
<p><img src="image-20220613222206939.png" alt="image-20220613222206939" style="zoom:50%;"></p>
<p>所以每一个 a 得到 q k v ,其实就是把输入的这个,vector sequence
乘上三个不同的矩阵,你就得到了 q,得到了 k,跟得到了 v。下一步是,每一个 q
都会去跟每一个 k,去计算这个 inner product,去<strong>得到这个 attention
的分数</strong>。那得到 attention
分数这一件事情,如果从矩阵操作的角度来看,它在做什么样的事情呢？</p>
<p><img src="image-20220613222251046.png" alt="image-20220613222251046" style="zoom:50%;"></p>
<p>你就是把 <span class="math inline">\(q^1\)</span> 跟 <span class="math inline">\(k^1\)</span> 做 inner product,得到 <span class="math inline">\(α_{1,1}\)</span>,所以 <span class="math inline">\(α_{1,1}\)</span>就是 <span class="math inline">\(q^1\)</span> 跟<span class="math inline">\(k^1\)</span> 的 inner
product,那这边我就把这个,<span class="math inline">\(k^1\)</span>它背后的这个向量,把它画成比较宽一点代表说它是
transpose。同理 <span class="math inline">\(α_{1,2}\)</span> 就是 <span class="math inline">\(q^1\)</span> 跟 <span class="math inline">\(k^2\)</span>,做 inner product, <span class="math inline">\(α_{1,3}\)</span> 就是 <span class="math inline">\(q^1\)</span> 跟 <span class="math inline">\(k^3\)</span> 做 inner product,这个 <span class="math inline">\(α_{1,4}\)</span> 就是 <span class="math inline">\(q^1\)</span> 跟 <span class="math inline">\(k^4\)</span> 做 inner
product。那这个四个步骤的操作,你其实可以把它拼起来,看作是<strong>矩阵跟向量相乘</strong>。</p>
<p><img src="image-20220613222335546.png" alt="image-20220613222335546" style="zoom:50%;"></p>
<p>这四个动作,你可以看作是我们<strong>把 <span class="math inline">\(k^1\)</span> 到 <span class="math inline">\(k^4\)</span> 拼起来,当作是一个矩阵的四个
row</strong>。那我们刚才讲过说,我们不只是 <span class="math inline">\(q^1\)</span>,要对<span class="math inline">\(k^1\)</span> 到 <span class="math inline">\(k^4\)</span> 计算 attention,<span class="math inline">\(q^2,q^3,q^4\)</span>也要对 <span class="math inline">\(k^1\)</span> 到 <span class="math inline">\(k^4\)</span> 计算
attention,操作其实都是一模一样的。</p>
<p><img src="image-20220613222430034.png" alt="image-20220613222430034" style="zoom:50%;"></p>
<p>所以这些 <strong>attention
的分数可以看作是两个矩阵的相乘</strong>,一个矩阵它的 row,就是 <span class="math inline">\(k^1\)</span> 到 <span class="math inline">\(k^4\)</span>,另外一个矩阵它的 column 。我们会在
attention 的分数,<strong>做一下 normalization</strong>,比如说你会做
softmax,你会对这边的每一个 column,每一个 column 做 softmax,让每一个
column 里面的值相加是 1。</p>
<p>之前有讲过说 其实这边做
<strong>softmax不是唯一的选项</strong>,你完全可以选择其他的操作,比如说
ReLU 之类的,那其实得到的结果也不会比较差,通过了 softmax
以后,它得到的值有点不一样了,所以我们用 <span class="math inline">\(A&#39;\)</span>,来表示通过 softmax
以后的结果。</p>
<p>我们已经计算出 $A' <span class="math inline">\(，那我们把这个\)</span>v^1$ 到 <span class="math inline">\(v^4\)</span>乘上这边的 α 以后,就可以得到 b。</p>
<p><img src="image-20220613223101872.png" alt="image-20220613223101872" style="zoom:50%;"></p>
<p>你就把<span class="math inline">\(v^1\)</span> 到 <span class="math inline">\(v^4\)</span> 拼起来,你<strong>把 <span class="math inline">\(v^1\)</span> 到 <span class="math inline">\(v^4\)</span>当成是V 这个矩阵的四个
column</strong>,把它拼起来,然后接下来你把 v 乘上,<span class="math inline">\(A&#39;\)</span> 的第一个 column
以后,你得到的结果就是 <span class="math inline">\(b^1\)</span></p>
<p>如果你熟悉线性代数的话,你知道说把这个 <span class="math inline">\(A&#39;\)</span> 乘上 V,就是把 <span class="math inline">\(A&#39;\)</span>的第一个 column,乘上 V
这一个矩阵,你会得到你 output 矩阵的第一个 column。而把 A 的第一个
column乘上 V 这个矩阵做的事情,其实就是把 V 这个矩阵里面的每一个
column,<strong>根据第 <span class="math inline">\(A&#39;\)</span>
这个矩阵里面的每一个 column 里面每一个 element,做 weighted
sum</strong>,那就得到 <span class="math inline">\(b^1\)</span></p>
<p>那就是这边的操作,把 <span class="math inline">\(v^1\)</span> 到 <span class="math inline">\(v^4\)</span> 乘上 weight,全部加起来得到 <span class="math inline">\(b^1\)</span>,如果你是用矩阵操作的角度来看它,就是把$
A'$ 的第一个 column 乘上 V,就得到 <span class="math inline">\(b^1\)</span>,然后接下来就是以此类推。</p>
<p><img src="image-20220613223143878.png" alt="image-20220613223143878" style="zoom:50%;"></p>
<p>就是以此类推,把 <span class="math inline">\(A&#39;\)</span> 的第二个
column 乘上 V,就得到 <span class="math inline">\(b^2\)</span>,<span class="math inline">\(A&#39;\)</span> 的第三个 column 乘上 V 就得到
<span class="math inline">\(b^3\)</span>,<span class="math inline">\(A&#39;\)</span> 的最后一个 column 乘上 V,就得到
<span class="math inline">\(b^4\)</span>。所以我们等于就是把 <span class="math inline">\(A&#39;\)</span> 这个矩阵,乘上 V 这个矩阵,得到 O
这个矩阵,O 这个矩阵里面的每一个 column,就是 Self-attention 的输出,也就是
<span class="math inline">\(b^1\)</span> 到 <span class="math inline">\(b^4\)</span>,</p>
<p><strong><font color="red"> 所以其实整个
Self-attention,我们在讲操作的时候,我们在最开始的时候
跟你讲的时候我们讲说,我们先产生了 q k v,然后再根据这个 q
去找出相关的位置,然后再对 v 做 weighted
sum,其实这一串操作,就是一连串矩阵的乘法而已</font></strong>。</p>
<h3><span id="23-self-attention-流程">2.3 Self-attention 流程</span></h3>
<h5><span id="我们再复习一下我们刚才看到的矩阵乘法">我们再复习一下我们刚才看到的矩阵乘法：</span></h5>
<p><img src="image-20220613223238727.png" alt="image-20220613223238727" style="zoom:50%;"></p>
<ul>
<li><p>I 是 Self-attention 的 input,Self-attention 的 input
是一排的vector,这排 vector 拼起来当作矩阵的 column,就是 I；</p></li>
<li><p>这个 input 分别乘上三个矩阵,<span class="math inline">\(W^q\)</span> <span class="math inline">\(W^k\)</span> 跟$ W^v$,得到 Q K V ；</p></li>
<li><p>这三个矩阵,接下来 Q 乘上 K 的 transpose,得到 A 这个矩阵,A
的矩阵你可能会做一些处理,得到 <span class="math inline">\(A&#39;\)</span>,那有时候我们会把这个 <span class="math inline">\(A&#39;\)</span>,叫做 <strong>Attention
Matrix</strong>，<strong>生成Q矩阵就是为了得到Attention的score</strong>；</p></li>
<li><p>然后接下来你把 <span class="math inline">\(A&#39;\)</span> 再乘上
V,就得到 O,O 就是 Self-attention 这个 layer
的输出,<strong>生成V是为了计算最后的b，也就是矩阵O；</strong></p></li>
</ul>
<p>所以 Self-attention 输入是 I,输出是 O,那你会发现说虽然是叫
attention,但是<strong>其实 Self-attention layer
里面,唯一需要学的参数,就只有 <span class="math inline">\(W^q\)</span>
<span class="math inline">\(W^k\)</span> 跟$ W^v$ 而已,只有<span class="math inline">\(W^q\)</span> <span class="math inline">\(W^k\)</span> 跟$
W^v$是未知的</strong>,是需要透过我们的训练资料把它找出来的。但是其他的操作都没有未知的参数,都是我们人为设定好的,都不需要透过
training data 找出来,那这整个就是 Self-attention 的操作,从 I 到 O
就是做了 Self-attention。</p>
<h3><span id="24-multi-head-self-attention">2.4 Multi-head Self-attention</span></h3>
<p><strong>Self-attention 有一个进阶的版本,叫做 ==Multi-head
Self-attention==, Multi-head
Self-attention,其实今天的使用是非常地广泛的</strong>。在作业 4
里面,助教原来的 code 4 有,Multi-head Self-attention,它的 head
的数目是设成 2,那刚才助教有给你提示说,把 head 的数目改少一点 改成
1,其实就可以过medium baseline。</p>
<p>但并不代表所有的任务,都适合用比较少的
head,有一些任务,比如说翻译,比如说语音辨识,其实用比较多的
head,你反而可以得到比较好的结果。至于<strong>需要用多少的
head,这个又是另外一个 hyperparameter</strong>,也是你需要调的。</p>
<h5><span id="那为什么我们会需要比较多的head-呢你可以想成说相关这件事情">那为什么我们会需要比较多的
head 呢,你可以想成说相关这件事情？</span></h5>
<p>我们在做这个 Self-attention 的时候,我们就是用 q 去找相关的
k,但是<strong>==相关==这件事情有很多种不同的形式</strong>,有很多种不同的定义,所以也许我们不能只有一个
q,我们应该要有多个 q,<strong>不同的 q
负责不同种类的相关性</strong>。</p>
<h5><span id="所以假设你要做multi-head-self-attention-的话你会怎么操作呢">所以假设你要做
Multi-head Self-attention 的话,你会怎么操作呢?</span></h5>
<p><img src="image-20220613223634261.png" alt="image-20220613223634261" style="zoom:50%;"></p>
<ul>
<li>先把 a 乘上一个矩阵得到 q</li>
<li>再把 q 乘上另外两个矩阵,分别得到 <span class="math inline">\(q^1\)</span> 跟 <span class="math inline">\(q^2\)</span>,那这边还有 这边是用两个上标,i
代表的是位置,然后这个 1 跟 2 代表是,这个位置的第几个 q,所以这边有 <span class="math inline">\(q^{i,1}\)</span> 跟 <span class="math inline">\(q^{i,2}\)</span>,代表说我们有两个 head</li>
</ul>
<p>我们认为这个问题,里面有两种不同的相关性,是我们需要产生两种不同的
head,来找两种不同的相关性。既然 q 有两个,那 k 也就要有两个,那 v
也就要有两个,从 q 得到 <span class="math inline">\(q^1 q^2\)</span>,从 k
得到 <span class="math inline">\(k^1 k^2\)</span>,从 v 得到 <span class="math inline">\(v^1 v^2\)</span>,那其实就是把 q 把 k 把
v,分别乘上两个矩阵,得到这个不同的
head,就这样子而已,对另外一个位置,也做一样的事情只是现在<span class="math inline">\(q^1\)</span>,它在算这个 attention
的分数的时候,它就不要管那个 <span class="math inline">\(k^2\)</span>
了。</p>
<p><img src="image-20220613223730387.png" alt="image-20220613223730387" style="zoom:50%;"></p>
<ul>
<li><p>所以 <span class="math inline">\(q_{i,1}\)</span> 就跟 <span class="math inline">\(k^{i,1}\)</span> 算 attention</p></li>
<li><p><span class="math inline">\(q_{i,1}\)</span> 就跟 <span class="math inline">\(k^{j,1}\)</span> 算 attention,也就是算这个 dot
product,然后得到这个 attention 的分数</p></li>
<li><p>然后今天在做 weighted sum 的时候,也不要管 <span class="math inline">\(v^2\)</span> 了,看 <span class="math inline">\(V^{i,1}\)</span> 跟 <span class="math inline">\(v^{j,1}\)</span> 就好,所以你把 attention 的分数乘
<span class="math inline">\(v^{i,1}\)</span>,把 attention 的分数乘 <span class="math inline">\(v^{j,1}\)</span></p></li>
<li><p>然后接下来就得到 <span class="math inline">\(b^{i,1}\)</span></p></li>
</ul>
<p>这边只用了其中一个 head,那你会用另外一个
head,也做一模一样的事情。</p>
<p><img src="image-20220613223749217.png" alt="image-20220613223749217" style="zoom:50%;"></p>
<p>所以 <span class="math inline">\(q^2\)</span> 只对 <span class="math inline">\(k^2\)</span> 做 attention,它们在做 weighted sum
的时候,只对 <span class="math inline">\(v^2\)</span> 做 weighted
sum,然后接下来你就得到 <span class="math inline">\(b^{i,2}\)</span></p>
<p>如果你有多个 head,有 8 个 head 有 16 个
head,那也是一样的操作,那这边是用两个 head 来当作例子,来给你看看有两个
head 的时候,是怎么操作的,现在得到 <span class="math inline">\(b^{i,1}\)</span> 跟 <span class="math inline">\(b^{i,2}\)</span>。<strong>然后接下来你可能会把
<span class="math inline">\(b^{i,1}\)</span> 跟 <span class="math inline">\(b^{i,2}\)</span>,把它接起来,然后再通过一个
transform。</strong></p>
<p><img src="image-20220613223832789.png" alt="image-20220613223832789" style="zoom:50%;"></p>
<p>也就是再乘上一个矩阵,然后得到 bi,然后再送到下一层去,那这个就是
Multi-head attention,一个这个 Self-attention 的变形。</p>
<h3><span id="25-positional-encoding">2.5 Positional Encoding</span></h3>
<blockquote>

</blockquote>
<h4><span id="no-positioninformation-in-self-attention">No position
information in self-attention</span></h4>
<p>那讲到目前为止,你会发现说 Self-attention 的这个
layer,它少了一个也许很重要的资讯,这个资讯是<strong>位置的资讯</strong>。对一个
Self-attention layer 而言,每一个 input,它是出现在 sequence
的最前面,还是最后面,它是完全没有这个资讯的。</p>
<p><font color="red"> 对 Self-attention 而言,<strong>位置 1 跟位置 2
跟位置 3 跟位置
4,完全没有任何差别,这四个位置的操作其实是一模一样</strong>,对它来说 q1
到跟 q4 的距离,并没有特别远,1 跟 4 的距离并没有特别远,2 跟 3
的距离也没有特别近。</font></p>
<p>对它来说就是天涯若比邻,所有的位置之间的距离都是一样的,没有任何一个位置距离比较远,也没有任何位置距离比较近,也没有谁在整个
sequence 的最前面,也没有谁在整个 sequence
的最后面。但是这样子设计可能会有一些问题,因为有时候位置的资讯也许很重要,举例来说,我们在做这个
POS
tagging,就是词性标记的时候,也许你知道说<strong>动词比较不容易出现在句首</strong>,所以如果我们知道说,某一个词汇它是放在句首的,那它是动词的可能性可能就比较低,这样子的位置的资讯往往也是有用的。</p>
<h4><span id="each-positon-hasa-unique-positional-vector-ei">Each positon has
a unique positional vector <span class="math inline">\(e^i\)</span></span></h4>
<p>可是在我们到目前为止,讲的 Self-attention
的操作里面,根本就没有位置的资讯,所以怎么办呢,所以你做 Self-attention
的时候,如果你觉得位置的资讯是一个重要的事情,那你可以把位置的资讯把它塞进去,怎么把位置的资讯塞进去呢,这边就要用到一个叫做,==positional
encoding== 的技术。</p>
<p><img src="image-20220613224025472.png" alt="image-20220613224025472" style="zoom:50%;"></p>
<p><font color="red"> <strong>你为每一个位置设定一个 vector,叫做
positional vector</strong>,这边<strong>用 <span class="math inline">\(e^i\)</span> 来表示,上标 i
代表是位置,每一个不同的位置</strong></font>,就有不同的 vector,就是 <span class="math inline">\(e^1\)</span> 是一个 vector,<span class="math inline">\(e^2\)</span> 是一个vector,<span class="math inline">\(e^{128}\)</span>
是一个vector,不同的位置都有一个它专属的 e,然后把这个 e 加到 <span class="math inline">\(a^i\)</span> 上面,就结束了。就是告诉你的
Self-attention,位置的资讯,如果它看到说 <span class="math inline">\(a^i\)</span> 好像有被加上 $
e^i$,它就知道说现在出现的位置,应该是在 i 这个位置。</p>
<p><strong>最早的这个 transformer,就 Attention Is All You Need 那篇
paper 里面,它用的 $ e^i$长的是这个样子</strong>。</p>
<p><img src="image-20220613224248928.png" alt="image-20220613224248928" style="zoom:50%;"></p>
<h4><span id="hand-crafted-or-learned-fromdata">Hand-crafted or Learned from
data</span></h4>
<p><strong>这样子的 positional vector,它是 handcrafted
的,也就是它是人设的</strong>,那人设的这个 vector
有很多问题,就假设我现在在定这个 vector 的时候,只定到 128,那我现在
sequence 的长度,如果是 129 怎么办呢？不过在最早的那个,Attention Is All
You Need paper里面,没有这个问题,<strong>它 vector
是透过某一个规则所产生的</strong>,透过一个很神奇的sin和cos 的 function
所产生的。</p>
<p>其实你不一定要这么产生, <strong>positional
encoding仍然是一个尚待研究的问题</strong>,你可以创造自己新的方法,或甚至
positional encoding,是可以根据资料学出来的。那有关 positional
encoding,你可以再参考一下文献,这个是一个尚待研究的问题,比如说我这边引用了一篇,这个是去年放在
arxiv 上的论文,所以可以想见这其实都是很新的论文。</p>
<p><img src="image-20220613224538933.png" alt="image-20220613224538933" style="zoom:50%;"></p>
<p>里面就是比较了跟提出了,新的 positional encoding</p>
<ul>
<li>比如说这个是最早的 positional encoding,它是用一个神奇的 sin function
所产生的</li>
<li>那如果你的 positional encoding,你把 positional encoding
里面的数值,当作 network 参数的一部分,直接 learn
出来,看起来是这个样子的,这个图是那个横著看的,它是横著看的,它是每一个
row,代表一个 position,好 所以这个是这个最原始的,用 sin function
产生的,这个是 learn 出来的</li>
<li>它里面又有神奇的做法,比如说这个,这个是用 RNN 生出来的,positional
encording 是用 RNN 出来的,这篇 paper 提出来的叫做 FLOATER,是用个神奇的
network 生出来的,</li>
</ul>
<p>总之你有各式各样不同的方法,来产生 positional
encoding,那目前我们还不知道哪一种方法最好,这是一个尚待研究中的问题,所以你不用纠结说,为什么
Sinusoidal 最好,<strong>你永远可以提出新的做法</strong>。</p>
<h3><span id="26-applications">2.6 Applications …</span></h3>
<p><strong>Self-attention 当然是用得很广,我们已经提过很多次 transformer
这个东西</strong>。</p>
<p><img src="image-20220613224644049.png" alt="image-20220613224644049" style="zoom:50%;"></p>
<p>那我们大家也都知道说,在 NLP 的领域有一个东西叫做 BERT,BERT 里面也用到
Self-attention,所以 Self-attention 在 NLP
上面的应用,是大家都耳熟能详的。但 <strong>Self-attention,不是只能用在
NLP 相关的应用上,它还可以用在很多其他的问题上</strong>。</p>
<h3><span id="self-attention-for-speech">Self-attention for Speech</span></h3>
<p>比如说在做语音的时候,你也可以用
Self-attention,不过在做语音的时候,你可能会对
Self-attention,做一些小小的改动。因为一般语音的,如果你要把一段声音讯号,表示成一排向量的话,这排<strong>向量可能会非常地长</strong>。</p>
<p><img src="image-20220613224723147.png" alt="image-20220613224723147" style="zoom:50%;"></p>
<p>而每一个向量,其实只代表了 10 millisecond 的长度而已,所以如果今天是 1
秒鐘的声音讯号,它就有 100 个向量了,5 秒鐘的声音讯号,就 500
个向量了,你随便讲一句话,都是上千个向量了。所以一段声音讯号,你要描述它的时候,那个像这个
vector 的 sequence 它的长度是非常可观的,那可观的
sequence,可观的长度,会造成什么问题呢？</p>
<p>你想想看,我们今天在<strong>计算这个 attention matrix
的时候,它的计算complexity 是长度的平方。</strong></p>
<p><img src="image-20220613224807917.png" alt="image-20220613224807917" style="zoom:50%;"></p>
<p><strong>计算这个 attention matrix A′你需要做 L 乘以 L 次的 inner
product,那如果这个 L 的值很大的话,它的计算量就很可观,你也需要很大的这个
memory,才能够把这个矩阵存下来。</strong></p>
<p>所以今天如果在做语音辨识的时候,一句话所产生的这个 attention
matrix,可能会太大,大到你根本就不容易处理,不容易训练,所以怎么办呢？<strong>在做语音的时候,有一招叫做
==Truncated Self-attention==</strong>。</p>
<p><img src="image-20220613224906348.png" alt="image-20220613224906348" style="zoom:50%;"></p>
<p><font color="red"><strong>Truncated Self-attention</strong>
做的事情就是,我们今天在做 Self-attention
的时候,<strong>不要看一整句话,就我们就只看一个小的范围就好</strong>，那至于<strong>这个范围应该要多大,那个是人设定的。</strong></font></p>
<p>那为什么我们知道说,今天在做语音辨识的时候,也许只需要看一个小的范围就好,那就是<strong>取决于你对这个问题的理解</strong>,也许我们要辨识这个位置有什么样的<strong>phoneme</strong>,这个位置有什么样的内容,我们并不需要看整句话,只要看这句话,跟它前后一定范围之内的资讯,其实就可以判断。</p>
<p>所以如果在做 Self-attention
的时候,也许没有必要看过一整个句子,也许没有必要让 Self-attention
考虑一整个句子,也许只需要考虑一个小范围就好,这样就可以加快运算的速度，这个是
Truncated Self-attention。</p>
<h3><span id="self-attention-for-image">Self-attention for Image</span></h3>
<p>那其实 Self-attention
,还可以被用在影像上,Self-attention那到目前为止,我们在讲 Self-attention
的时候,我们都说 <strong>Self-attention 适用的范围是：输入是一个 vector
set
的时候</strong>，一张图片啊,我们把它看作是一个很长的向量,那<strong>其实一张图片,我们也可以换一个观点,把它看作是一个
vector 的 set。</strong></p>
<p><img src="image-20220613225206980.png" alt="image-20220613225206980" style="zoom:50%;"></p>
<p><strong>这个是一个解析度 5 乘以 10
的图片,那这一张图片呢,可以看作是一个 tensor,这个 tensor 的大小是 5 乘以
10 乘以 3,3 代表 RGB 这 3 个 channel。你可以把每一个位置的
pixel,看作是一个三维的向量,所以每一个
pixel,其实就是一个三维的向量,那整张图片,其实就是 5 乘以 10
个向量的set</strong>。</p>
<p>所以我们其实可以换一个角度,影像这个东西,其实也是一个 vector
set,它既然也是一个 vector set 的话,你完全可以用 Self-attention
来处理一张图片,那有没有人用 Self-attention
来处理一张图片呢,是有的。那这边就举了两个例子,来给大家参考,那现在把
Self-attention 用在影像处理上,也不算是一个非常石破天惊的事情。</p>
<p><img src="image-20220613225244115.png" alt="image-20220613225244115" style="zoom:50%;"></p>
<h3><span id="self-attention-vs-cnn">==Self-attention v.s. CNN==</span></h3>
<p>我们可以来比较一下,<strong>Self-attention 跟 CNN
之间,有什么样的差异或者是关联性</strong>。如果我们今天,是用
Self-attention 来处理一张图片,代表说,假设这个是你要考虑的 pixel,那它产生
query,其他 pixel 产生 key。</p>
<p><img src="image-20220613225357976.png" alt="image-20220613225357976" style="zoom:50%;"></p>
<p>你今天在<strong>做 inner product 的时候,你考虑的不是一个小的receptive
field的信息,而是整张影像的资讯</strong>，但是今天在做 CNN
的时候,,会画出一个 receptive field,每一个 filter,每一个 neural,只考虑
receptive field 范围里面的资讯。</p>
<p><img src="image-20220613225442244.png" alt="image-20220613225442244" style="zoom:50%;"></p>
<ul>
<li>所以如果我们比较 CNN 跟 Self-attention
的话,<strong><font color="red">CNN 可以看作是一种简化版的 Self-attention
</font></strong>，因为在做CNN的时候,我们只考虑 receptive field
里面的资讯,而在做 Self-attention 的时候,我们是考虑整张图片的资讯,所以
CNN,是简化版的
Self-attention。或者是你可以反过来说,<strong><font color="red">
Self-attention 是一个复杂化的 CNN</font></strong></li>
<li>在 CNN 里面,我们要划定 receptive field,每一个 neural,只考虑
receptive field 里面的资讯,而 <strong><font color="red"> receptive field
的范围跟大小,是人决定的。而对 Self-attention 而言,我们用
attention,去找出相关的 pixel,就好像是 receptive field
是自动被学出的,network 自己决定说,receptive field
的形状长什么样子,network 自己决定说,以这个 pixel 为中心,哪些 pixel
是我们真正需要考虑的,那些 pixel 是相关的</font></strong>。<strong>所以
receptive field
的范围,不再是人工划定,而是让机器自己学出来</strong>。</li>
</ul>
<p>其实你可以读一篇 paper,叫做 On the Relationship,between
Self-attention and Convolutional Layers。</p>
<p><img src="image-20220613230146104.png" alt="image-20220613230146104" style="zoom:50%;"></p>
<p>在这篇 paper 里面,会用数学的方式严谨的告诉你说,其实这个
<strong>CNN就是 Self-attention 的特例,Self-attention
只要设定合适的参数,它可以做到跟 CNN 一模一样的事情</strong>。所以 self
attention,是更 flexible 的 CNN,而 CNN 是有受限制的
Self-attention,Self-attention 只要透过某些设计,某些限制,它就会变成
CNN。</p>
<p><img src="image-20220613230212397.png" alt="image-20220613230212397" style="zoom:50%;"></p>
<p>那这也不是很旧的 paper,你发现它放到网路上的时间呢,是 19 年的 11
月,所以你知道这些,我们今天上课里面讲的东西,其实都是很新的资讯。<strong><font color="red">
既然Self-attention 比较 flexible,之前有讲说比较 flexible 的
model,比较需要更多的 data,如果你 data 不够,就有可能
overfitting。</font></strong></p>
<p>如果你今天用不同的 data 量,来训练 CNN 跟
Self-attention,你确实可以看到我刚才讲的现象。</p>
<p><img src="image-20220613230309663.png" alt="image-20220613230309663" style="zoom:50%;"></p>
<p>那这个实验结果,来自于 An image is worth 16 乘以 16 的 words,这个是
Google 的 paper,它就是把这个 Self-attention,apply
在影像上面。那其实<strong>把一张影像呢,拆成 16 乘以 16 个
patch,它把每一个 patch想像成是一个 word</strong>,因为一般我们这个
Self-attention,比较常用在 NLP 上面,所以他就说,想像每一个 patch
其实就是一个 word,所以他就取了一个很 fancy 的 title,叫做<strong>一张图值
16 乘以 16 个文字</strong>。</p>
<p>横轴是训练的影像的量,那你发现说,对 Google 来说
用的,所谓的资料量比较少,也是你没有办法用的资料量啦这边有 10 个 million
就是,1000 万张图,是资料量比较小的 setting,然后资料量比较大的 setting
呢,有 3 亿张图片,在这个实验里面呢,比较了 Self-attention
是浅蓝色的这一条线,跟 CNN 是深灰色的这条线。</p>
<p>就会发现说,<strong>随著资料量越来越多,那 Self-attention
的结果就越来越好,最终在资料量最多的时候,Self-attention 可以超过
CNN,但在资料量少的时候,CNN 它是可以比
Self-attention,得到更好的结果的。</strong></p>
<p>那为什么会这样,你就可以从 CNN 跟
Self-attention,它们的弹性来加以解释：</p>
<ul>
<li><strong><font color="red"> Self-attention
它弹性比较大,所以需要比较多的训练资料,训练资料少的时候,就会
overfitting。</font></strong></li>
<li>CNN
它弹性比较小,在训练资料少的时候,结果比较好,但训练资料多的时候,它没有办法从更大量的训练资料得到好处。</li>
</ul>
<p>所以这个就是 Self-attention 跟 CNN 的比较，那 Self-attention 跟
CNN,谁比较好呢,<strong>我应该选哪一个呢,事实上你也可以都用</strong>,在我们作业四里面,如果你要做
strong baseline 的话,就特别给你一个提示,就是用 conformer,里面就是有用到
Self-attention,也有用到 CNN。</p>
<h3><span id="self-attention-vs-rnn"><strong><font color="red">
Self-attention v.s. RNN</font></strong></span></h3>
<p>我们来比较一下,Self-attention 跟 RNN,RNN就是 recurrent neural
network,这门课里面现在就不会讲recurrent neural network,因为 recurrent
neural network 的角色,很大一部分都可以用 Self-attention 来取代了,但是
RNN 是什么呢,假设你想知道的话,那这边很快地三言两语把它带过去,RNN 跟
Self-attention 一样,都是要处理 input 是一个 sequence 的状况。</p>
<p><img src="image-20220613230659968.png" alt="image-20220613230659968" style="zoom:50%;"></p>
<p>在 RNN 里面呢</p>
<ul>
<li>左边是你的 input sequence,你有一个 <strong>memory</strong> 的
vector</li>
<li>然后你有一个 RNN 的 block,这个 RNN 的 block 呢,它吃 memory 的
vector,吃第一个 input 的 vector</li>
<li>然后 output 一个东西,然后根据这个 output 的东西,我们通常叫做这个
hidden,这个 hidden 的 layer 的 output</li>
<li>然后通过这个 fully connected network,然后再去做你想要的
prediction</li>
</ul>
<p>接下来当sequence 里面,第二个 vector 作为 input
的时候,也会把前一个时间点吐出来的东西,当做下一个时间点的输入,再丢进 RNN
里面,然后再产生新的 vector,再拿去给 fully connected network。然后第三个
vector 进来的时候,你把第三个 vector 跟前一个时间点的输出,一起丢进
RNN,再产生新的输出,然后在第四个时间点。第四个 vector 输入的时候,把第四个
vector 跟前一个时间点,产生出来的输出,再一起做处理,得到新的输出,再通过
fully connected network 的 layer,这个就是 RNN。</p>
<p>Recurrent Neural Network跟 Self-attention 做的事情其实也非常像,它们的
<strong>input 都是一个 vector sequence</strong>，Self-attention output
是另外一个 vector sequence,这里面的每一个 vector,都<strong>考虑了整个
input sequence 以后</strong>,再给 fully connected network 去做处理。</p>
<p>那 RNN 呢,它也会 output 另外一群 vector,这<strong>另外一排
vector</strong> 也会给,fully connected network 做进一步的处理,那
Self-attention 跟 RNN 有什么不同呢。</p>
<p><img src="image-20220613230944896.png" alt="image-20220613230944896" style="zoom:50%;"></p>
<p><strong>当然一个非常显而易见的不同,你可能会说,这边的每一个
vector,它都考虑了整个 input 的 sequence,而 RNN 每一个
vector,只考虑了左边已经输入的 vector,它没有考虑右边的
vector,那这是一个很好的观察。</strong></p>
<p>但是 <strong>RNN 其实也可以是双向的</strong>,所以如果你 RNN 用双向的
RNN 的话,其实这边的每一个 hidden 的 output,每一个 memory 的
output,其实也可以看作是考虑了整个 input 的 sequence。但是假设我们把 RNN
的 output,跟 Self-attention 的 output 拿来做对比的话,就算你用
bidirectional 的 RNN,还是有一些差别的。</p>
<ul>
<li><p><strong><font color="red">对RNN 来说,假设最右边这个黄色的
vector,要考虑最左边的这个输入,那它必须要把最左边的输入存在 memory
里面,然后接下来都不能够忘掉,一路带到最右边,才能够在最后一个时间点被考虑。</font></strong></p></li>
<li><p><strong><font color="red"> 对 Self-attention
来说没有这个问题,它只要这边输出一个 query,这边输出一个 key,只要它们
match 得起来,天涯若比邻,你可以从非常远的 vector,在整个 sequence
上非常远的 vector,轻易地抽取资讯,所以这是 RNN 跟
Self-attention,一个不一样的地方。</font></strong></p></li>
<li><p>RNN 今天在处理的时候, input 一排 sequence,output 一排 sequence
的时候,<strong><font color="red"> RNN
是没有办法平行化的。</font></strong>RNN 它今天 input 一排是
vector,output 另外一排 vector
的时候,它没有办法一次处理,没有办法平行处理所有的 output。但
Self-attention 有一个优势,是它可以平行处理所有的输出,你今天 input 一排
vector,再 output 这四个 vector 的时候,<strong>这四个 vector
是平行产生的,并不需要等谁先运算完才把其他运算出来</strong>,output 的这个
vector,里面的 output 这个 vector sequence 里面,每一个 vector
都是同时产生出来的。<strong><font color="red">
所以在运算速度上,Self-attention 会比 RNN
更有效率。</font></strong></p></li>
</ul>
<p><img src="image-20220613231148500.png" alt="image-20220613231148500" style="zoom:50%;"></p>
<p>那你今天发现说,<strong>很多的应用都往往把 RNN 的架构,逐渐改成
Self-attention 的架构了</strong>,如果你想要更进一步了解,RNN 跟
Self-attention 的关係的话,你可以看下面这篇文章,Transformers are
RNNs,里面会告诉你说,Self-attention 你加上了什么东西以后,其实它就变成了
RNN,发现说这也不是很旧的 paper,这个是去年的六月放到 arXiv 上。</p>
<h3><span id="self-attention-for-graph">Self-attention for Graph</span></h3>
<p>Graph 也可以看作是一堆 vector,那如果是一堆 vector,就可以用
Self-attention 来处理,所以 Self-attention 也可以用在 Graph
上面,但是<strong>当我们把 Self-attention,用在Graph
上面的时候,有什么样特别的地方呢？</strong></p>
<p><strong><font color="red"> Graph 往往是人为根据某些 domain knowledge
建出来的,那 domain knowledge
告诉我们说,这两个向量彼此之间没有关联,我们就没有必要再用机器去学习这件事情。</font></strong></p>
<p><img src="image-20220613231411144.png" alt="image-20220613231411144" style="zoom:50%;"></p>
<p>在 Graph 上面,每一个 node 可以表示成一个向量,但<strong>不只有 node
的资讯,还有 edge 的资讯</strong>,我们知道哪些 node
之间是有相连的,也就是哪些 node 是有关联的。</p>
<p>我们知道哪些向量间是有关联,那之前我们在做 Self-attention
的时候,所谓的关联性是 network 自己找出来的,但是现在既然有了 Graph
的资讯,<strong>有了 edge
的资讯,那关联性也许就不需要透过机器自动找出来,这个图上面的 edge
已经暗示了我们,node 跟 node 之间的关联性</strong>。</p>
<p>所以今天当你把 Self-attention,用在 Graph
上面的时候,你有一个选择是你在做这个,Attention Matrix
计算的时候,你可以<strong>只计算有 edge 相连的 node
就好</strong>。那如果两个 node
之间没有相连,那其实很有可能就暗示我们,这两个 node
之间没有关係,<strong>既然没有关係,我们就不需要再去计算它的 attention
score,直接把它设为 0 就好了</strong>。</p>
<h3><span id="27-more">2.7 More</span></h3>
<p>其实Self-attention 有非常非常多的变形,你可以看一篇 paper
叫做,<strong>Long Range Arena</strong>,里面比较了各种不同的
Self-attention 的变形。</p>
<p><img src="image-20220613231703000.png" alt="image-20220613231703000" style="zoom:50%;"></p>
<p>Self-attention
它最大的问题就是,<strong>它的运算量非常地大</strong>,所以怎么样减少
Self-attention 的运算量,是一个未来的重点,可以看到这边有,各种各式各样
Self-attention 的变形。</p>
<p><strong>Self-attention 最早是,用在 Transformer 上面,所以很多人讲
Transformer 的时候,其实它指的就是这个 Self-attention,有人说广义的
Transformer,指的就是
Self-attention</strong>。那所以后来各式各样的,Self-attention
的变形都这样做,都叫做是什么 former,比如说 Linformer Performer Reformer
等等,所以 Self-attention 的变形,现在都叫做 xxformer。</p>
<p>那可以看到，往右代表它运算的速度,所以有很多各式各样新的
xxformer,它们的速度会比原来的 Transformer 快,但是快的速度带来的就是
performance 变差。这个纵轴代表是 performance,所以它们往往比原来的
Transformer,performance 差一点,但是速度会比较快。那到底什么样的
Self-attention,才能够真的又快又好,这仍然是一个尚待研究的问题,如果你对
Self-attention,想要进一步研究的话,你还可以看一下,<strong>Efficient
Transformers: A Survey 这篇 paper,里面会跟你介绍,各式各样 Self-attention
的变形。</strong></p>
<h2><span id="三-注意力机制-qampa">三、注意力机制 Q&amp;A</span></h2>
<h3><span id="31self-attention-cnn-rnn对比">3.1
Self-Attention、CNN、RNN对比？</span></h3>
<h4><span id="self-attention-vs-cnn">Self-Attention vs CNN</span></h4>
<ul>
<li><strong><font color="red">CNN 可以看作是一种简化版的 Self-attention
</font></strong>，因为在做CNN的时候,我们只考虑 receptive field
里面的资讯,而在做 Self-attention 的时候,我们是考虑整张图片的资讯。</li>
<li>在 CNN 里面 <strong><font color="red"> receptive field
的范围跟大小,是人决定的。而对 Self-attention
,不再是人工划定,而是让机器自己学出来</font></strong>。</li>
<li><strong>Self-attention 比较 flexible,之前有讲说比较 flexible 的
model,比较需要更多的 data,如果你 data 不够,就有可能
overfitting</strong>。</li>
</ul>
<h4><span id="self-attention-vs-rnn">Self-Attention vs RNN</span></h4>
<ul>
<li><strong><font color="red">RNN 右边的
vector,要考虑最左边的这个输入,那它必须要把最左边的输入存在 memory
里面,然后接下来都不能够忘掉,一路带到最右边,才能够在最后一个时间点被考虑。</font></strong>
Self-attention 只要a1输出一个 query,a4输出一个 key,只要它们 match
得起来,天涯若比邻,你可以从非常远的 vector,在整个 sequence 上非常远的
vector,轻易地抽取资讯,所以这是 RNN 跟
Self-attention一个不一样的地方。</li>
<li><strong><font color="red"> RNN
是没有办法平行化的。所以在运算速度上,Self-attention 会比 RNN
更有效率。</font></strong></li>
</ul>
<h3><span id="32self-attention-cnn-rnn时间复杂度对比">3.2
Self-Attention、CNN、RNN时间复杂度对比？</span></h3>
<blockquote>
<p>##### 计算效率: 一个形状为 <img src="https://www.zhihu.com/equation?tex=N%5Ctimes+M" alt="[公式]">
的矩阵，与另一个形状为 <img src="https://www.zhihu.com/equation?tex=M%5Ctimes+P" alt="[公式]">
的矩阵相乘，其运算复杂度来源于乘法操作的次数，时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28NMP%29" alt="[公式]"></p>
</blockquote>
<h4><span id="self-attention">Self-Attention</span></h4>
<figure>
<img src="https://www.zhihu.com/equation?tex=A%28Q%2CK%2CV%29%3D%5Cmathrm%7BSoftmax%7D%28QK%5ET%29V+%5C%5C+" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<ul>
<li><figure>
<img src="https://www.zhihu.com/equation?tex=Q%2CK%2CV%3An%5Ctimes+d" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure></li>
<li>相似度计算 <img src="https://www.zhihu.com/equation?tex=QK%5ET" alt="[公式]"> ： <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=d%5Ctimes+n" alt="[公式]"> 运算，得到 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+n" alt="[公式]">
矩阵，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"></li>
<li>softmax计算：对每行做softmax，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%29" alt="[公式]"> ，则n行的复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2%29" alt="[公式]"></li>
<li>加权和： <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+n" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]">
运算，得到 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]"> 矩阵，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"></li>
</ul>
<p>故最后self-attention的时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"></p>
<p>对于受限的self-attention，每个元素仅能和周围 <img src="https://www.zhihu.com/equation?tex=r" alt="[公式]">
个元素进行交互，即和 <img src="https://www.zhihu.com/equation?tex=r" alt="[公式]"> 个 <img src="https://www.zhihu.com/equation?tex=d" alt="[公式]"> 维向量做内积运算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28rd%29" alt="[公式]"> ，则 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 个元素的总时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%28rnd%29%7D" alt="[公式]"></p>
<h4><span id="multi-head-attention">Multi-Head Attention</span></h4>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BMultiHead%7D%28Q%2CK%2CV%29%3D%5Cmathrm%7BConcat%28head_1%2C...%2Chead_h%29%7DW%5EO+%5C%5C+%5Cmathrm%7Bwhere%5Cquad+head_i%7D%3DA%28QW_i%5EQ%2CKW_i%5EK%2CVW_i%5EV%29%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>对于multi-head attention，假设有 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]"> 个head，这里
<img src="https://www.zhihu.com/equation?tex=h" alt="[公式]">
是一个常数，对于每个head，首先需要把三个矩阵分别映射到 <img src="https://www.zhihu.com/equation?tex=d_q%2Cd_k%2Cd_v" alt="[公式]">
维度。这里考虑一种简化情况： <img src="https://www.zhihu.com/equation?tex=d_q%3Dd_k%3Dd_v%3D%5Cfrac%7Bd%7D%7Bh%7D" alt="[公式]"> 。(对于dot-attention计算方式， <img src="https://www.zhihu.com/equation?tex=d_k" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=d_v" alt="[公式]">
可以不同)。</p>
<ul>
<li>输入线性映射的复杂度： <img src="https://www.zhihu.com/equation?tex=n+%5Ctimes+d" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=d%5Ctimes+%5Cfrac%7Bd%7D%7Bh%7D" alt="[公式]"> 运算，忽略常系数，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nd%5E2%29" alt="[公式]"> 。</li>
<li>Attention操作复杂度：主要在相似度计算及加权和的开销上， <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+%5Cfrac%7Bd%7D%7Bh%7D" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7Bd%7D%7Bh%7D%5Ctimes+%7Bn%7D" alt="[公式]"> 运算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7B%7D" alt="[公式]"></li>
<li>输出线性映射的复杂度：concat操作拼起来形成 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]">
的矩阵，然后经过输出线性映射，保证输入输出相同，所以是 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=d%5Ctimes+d" alt="[公式]"> 计算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nd%5E2%29" alt="[公式]"></li>
</ul>
<p>故最后的复杂度为： <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%2Bnd%5E2%29" alt="[公式]"></p>
<blockquote>
<p>注意：多头的计算并不是通过循环完成的，而是通过 transposes and
reshapes，用矩阵乘法来完成的。假设有 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]">
个head，则新的representation dimension： <img src="https://www.zhihu.com/equation?tex=m%3D%5Cfrac%7Bd%7D%7Bh%7D" alt="[公式]"> 。因为，我们将 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]">
的矩阵拆为 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+h%5Ctimes+m" alt="[公式]"> 的张量，再利用转置操作转为 <img src="https://www.zhihu.com/equation?tex=h%5Ctimes+n+%5Ctimes+m" alt="[公式]"> 的张量。故 <img src="https://www.zhihu.com/equation?tex=QK%5ET" alt="[公式]">
的计算为： <img src="https://www.zhihu.com/equation?tex=h%5Ctimes+n%5Ctimes+m" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=h%5Ctimes+m+%5Ctimes+n" alt="[公式]"> 做计算，得到 <img src="https://www.zhihu.com/equation?tex=h%5Ctimes+n%5Ctimes+n" alt="[公式]"> 的张量，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28h%5E2n%5E2m%29" alt="[公式]"> ，即 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2dh%29" alt="[公式]"> 。注意，此处 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]">
实际是一个常数，故 <img src="https://www.zhihu.com/equation?tex=QK%5ET" alt="[公式]"> 复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28n%5E2d%29" alt="[公式]"> 。</p>
</blockquote>
<h4><span id="recurrent">Recurrent</span></h4>
<figure>
<img src="https://www.zhihu.com/equation?tex=h_t%3Df%28Ux_t%2BWh_%7Bt-1%7D%29+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=Ux_t" alt="[公式]">
： <img src="https://www.zhihu.com/equation?tex=d%5Ctimes+m" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=m%5Ctimes+1" alt="[公式]">
运算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28md%29" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=m" alt="[公式]"> 为input size</li>
<li><img src="https://www.zhihu.com/equation?tex=Wh_%7Bt-1%7D" alt="[公式]"> ： <img src="https://www.zhihu.com/equation?tex=d%5Ctimes+d" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=d%5Ctimes+1" alt="[公式]"> 运算，复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28d%5E2%29" alt="[公式]"></li>
</ul>
<p>故一次操作的时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28d%5E2%29" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 次序列操作后的总时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nd%5E2%29" alt="[公式]"></p>
<h4><span id="convolution">Convolution</span></h4>
<blockquote>
<p>注: 这里保证输入输出都是一样的，即均是 <img src="https://www.zhihu.com/equation?tex=n%5Ctimes+d" alt="[公式]"></p>
</blockquote>
<ul>
<li>为了保证输入和输出在第一个维度都相同，故需要对输入进行padding操作，因为这里kernel
size为 <img src="https://www.zhihu.com/equation?tex=k" alt="[公式]">
，（实际kernel的形状为 <img src="https://www.zhihu.com/equation?tex=k%5Ctimes+d" alt="[公式]">
）如果不padding的话，那么输出的第一个维度为 <img src="https://www.zhihu.com/equation?tex=n-k%2B1" alt="[公式]">
，因为这里stride是为1的。为了保证输入输出相同，则需要对序列的前后分别padding长度为
<img src="https://www.zhihu.com/equation?tex=%28k-1%29%2F2" alt="[公式]"> 。</li>
<li>大小为 <img src="https://www.zhihu.com/equation?tex=k%5Ctimes+d" alt="[公式]"> 的卷积核一次运算的复杂度为： <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28kd%29" alt="[公式]"> ，一共做了 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]">
次，故复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nkd%29" alt="[公式]"></li>
<li>为了保证第二个维度在第二个维度都相同，故需要 <img src="https://www.zhihu.com/equation?tex=d" alt="[公式]">
个卷积核，所以卷积操作总的时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28nkd%5E2%29" alt="[公式]"></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/32X3GH2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/32X3GH2/" class="post-title-link" itemprop="url">深度学习（7）Seq2Seq</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-14 23:08:19" itemprop="dateCreated datePublished" datetime="2022-05-14T23:08:19+08:00">2022-05-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-18 21:31:52" itemprop="dateModified" datetime="2023-04-18T21:31:52+08:00">2023-04-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Seq2Seq/" itemprop="url" rel="index"><span itemprop="name">Seq2Seq</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="一-seq2seq">一、Seq2Seq</span></h2>
<blockquote>
<p>CS224n笔记[7]:整理了12小时，只为让你20分钟搞懂Seq2seq - 蝈蝈的文章 -
知乎 https://zhuanlan.zhihu.com/p/147310766</p>
<p>目录：</p>
<ul>
<li><p>机器翻译</p></li>
<li><ul>
<li>传统机器翻译，SMT</li>
<li>神经机器翻译，NMT</li>
</ul></li>
<li><p>Seq2seq</p></li>
<li><ul>
<li>Seq2seq结构详解</li>
<li>为什么训练和预测时的Decoder不一样？</li>
<li>Seq2seq的损失函数</li>
<li>Decoding和Beam Search</li>
</ul></li>
<li><p>总结</p></li>
<li><ul>
<li>NMT的优缺点</li>
<li>机器翻译的评价指标</li>
</ul></li>
</ul>
</blockquote>
<h3><span id="11-seq2seq结构详解">1.1 <strong>seq2seq结构详解</strong></span></h3>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182130235.png" alt="CS224n笔记[7]:整理了12小时，只为让你20分钟搞懂Seq2seq">
<figcaption aria-hidden="true">CS224n笔记[7]:整理了12小时，只为让你20分钟搞懂Seq2seq</figcaption>
</figure>
<p>这张图，展示了在<strong>「训练时」</strong>，seq2seq内部的详细结构。</p>
<p>在Encoder端，我们将source文本的词序列先经过embedding层转化成向量，然后输入到一个RNN结构（可以是普通RNN，LSTM，GRU等等）中。另外，这里的RNN也可以是多层、双向的。经过了RNN的一系列计算，最终隐层的输入，就作为源文本整体的一个表示向量，称为<strong>「context
vector」</strong>。</p>
<p>Decoder端的操作就稍微复杂一些了。首先，Decoder的输入是什么呢？Decoder的输入，训练和测试时是不一样的！
<strong>「在训练时，我们使用真实的目标文本，即“标准答案”作为输入」</strong>（注意第一步使用一个特殊的<code>&lt;start&gt;</code>字符，表示句子的开头）。每一步根据当前正确的输出词、上一步的隐状态来预测下一步的输出词。</p>
<p>下图则展示了在<strong>「预测时」</strong>，seq2seq的内部结构：</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182130580.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>预测时，Encoder端没什么变化，在Decoder端，由于此时没有所谓的“真实输出”或“标准答案”了，所以只能<strong>「自产自销：每一步的预测结果，都送给下一步作为输入」</strong>，直至输出<code>&lt;end&gt;</code>就结束。如果你对我之前写的笔记很熟悉的话，会发现，<strong>「这时的Decoder就是一个语言模型」</strong>。由于这个语言模型是根据context
vector来进行文本的生成的，因此这种类型的语言模型，被称为“条件语言模型”：Conditional
LM。正因为如此，在训练过程中，我们可以使用一些预训练好的语言模型来对Decoder的参数进行初始化，从而加快迭代过程。</p>
<h3><span id="12为什么训练和预测时的decoder不一样"><strong>1.2
为什么训练和预测时的Decoder不一样？</strong></span></h3>
<p>很多人可能跟我一样，对此感到疑惑：为什么在训练的时候，不能直接使用这种语言模型的模式，使用上一步的预测来作为下一步的输入呢？</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182130314.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>我们称这两种模式，根据标准答案来decode的方式为<strong>「teacher
forcing」</strong>，而根据上一步的输出作为下一步输入的decode方式为<strong>「free
running」</strong>。</p>
<p>其实，free
running的模式真的不能在训练时使用吗？——当然是可以的！从理论上没有任何的问题，又不是不能跑。但是，在实践中人们发现，这样训练太南了。因为没有任何的引导，一开始会完全是瞎预测，正所谓“一步错，步步错”，而且越错越离谱，这样会导致训练时的累积损失太大（<strong>「误差爆炸」</strong>问题，exposure
bias），训练起来就很费劲。这个时候，如果我们能够在每一步的预测时，让老师来指导一下，即提示一下上一个词的正确答案，decoder就可以快速步入正轨，训练过程也可以更快收敛。因此大家把这种方法称为teacher
forcing。所以，这种操作的目的就是为了使得训练过程更容易。</p>
<p><strong>所以，更好的办法，更常用的办法，是老师只给适量的引导，学生也积极学习</strong>。即我们设置一个概率p，每一步，以概率p靠自己上一步的输入来预测，以概率1-p根据老师的提示来预测，这种方法称为<strong>「计划采样」</strong>（scheduled
sampling）：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182130613.jpg" alt="img" style="zoom: 67%;"></p>
<p>另外有一个小细节：在seq2seq的训练过程中，decoder即使遇到了<code>&lt;end&gt;</code>标识也不会结束，因为训练的时候并不是一个生成的过程
，我们需要等到“标准答案”都输入完才结束。</p>
<h3><span id="13-seq2seq的损失函数">1.3 <strong>Seq2Seq的损失函数</strong></span></h3>
<p>在上面的图中，我们看到<strong>decoder的每一步产生隐状态后，会通过一个projection层映射到对应的词</strong>。那怎么去计算每一步的损失呢？实际上，<strong>这个projection层，通常是一个softmax神经网络层，假设词汇量是V，则会输出一个V维度的向量，每一维代表是某个词的概率</strong>。映射的过程就是把最大概率的那个词找出来作为预测出的词。</p>
<p>在计算损失的时候，我们使用交叉熵作为损失函数，所以我们要找出这个V维向量中，正确预测对应的词的那一维的概率大小<img src="https://www.zhihu.com/equation?tex=%5Chat%7Bp%7D" alt="[公式]">，则这一步的损失就是它的负导数<img src="https://www.zhihu.com/equation?tex=-log%28%5Chat%7Bp%7D%29" alt="[公式]">，将每一步的损失求和，即得到总体的损失函数：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D+J%26%3D-log%28p%28%5Chat%7By_1%7D%29%29-log%28p%28%5Chat%7By_2%7D%29%29-...-log%28p%28%5Chat%7By_n%7D%29%29-log%28p%28%5BEOS%5D%29%29+%5Cnonumber+%5C%5C+%26%3D+-%5Cfrac%7B1%7D%7BT%7D%5Csum%5E%7BT%7D_%7Bi%7Dlog%28p%28%5Chat%7By_i%7D%29%29+%5Cnonumber+%5Cend%7Balign%7D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中T代表Decoder有多少步，[EOS]代表‘end of sentence’这个特殊标记.</p>
<h3><span id="14-decoding和beamsearch">1.4 <strong>Decoding和Beam
search</strong></span></h3>
<p>前面画的几个图展示的预测过程，其实就是最简单的decoding方式——<strong>「Greedy
Decoding」</strong>，即每一步，都预测出概率最大的那个词，然后输入给下一步。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182130276.jpg" alt="img" style="zoom:67%;"></p>
<p>这种Greedy的方式，简单快速，但是既然叫“贪心”，肯定会有问题，那就是<strong>「每一步最优，不一定全局最优」</strong>，这种方式很可能“捡了芝麻，丢了西瓜”。</p>
<p>改进的方法，就是使用<strong>「Beam
Search」</strong>方法：每一步，多选几个作为候选，最后综合考虑，选出最优的组合。</p>
<p>下面我们来具体看看Beam Search的操作步骤：</p>
<ul>
<li>首先，我们需要设定一个候选集的大小beam size=k；</li>
<li>每一步的开始，我们从每个当前输入对应的所有可能输出，计算每一条路的“序列得分”；</li>
<li>保留“序列得分”最大的k个作为下一步的输入；</li>
<li>不断重复上述过程，直至结束，选择“序列得分”最大的那个序列作为最终结果。</li>
</ul>
<p>这里的重点就在于这个“序列得分”的计算。</p>
<p>我们使用如下的score函数来定义<strong>「序列得分」</strong>：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=score%28y_1%2C...%2Cy_t%29%3D%5Csum%5E%7Bt%7D_%7Bi%3D1%7DlogP%28y_i%7Cy_1%2Cy_2%2C...%2Cy_%7Bi-1%7D%2Cx%29+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>这个score代表了当前到第t步的输出序列的一个综合得分，越高越好。其中<img src="https://www.zhihu.com/equation?tex=logP%28y_i%7Cy_1%2Cy_2%2C...%2Cy_%7Bi-1%7D%2Cx%29" alt="[公式]">类似于前面我们写的第t步的交叉熵损失的负数。所以这个score越到，就意味着到当前这一步为止，输出序列的累积损失越小。</p>
<p>再多描述不如一张图直观，我用下图描绘一个极简的案例（只有3个词的语料，k=2）：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182131550.jpg" alt="img" style="zoom: 67%;"></p>
<p>最后还有一个问题：由于会有多个分支，所以很有可能我们会遇到多个<code>&lt;end&gt;</code>标识，由于分支较多，如果等每一个分支都遇到<code>&lt;end&gt;</code>才停的话，可能耗时太久，因此一般我们会设定一些规则，比如已经走了T步，或者已经积累了N条已完成的句子，就终止beam
search过程。</p>
<p>在search结束之后，我们需要对已完成的N个序列做一个抉择，挑选出最好的那个，那不就是通过前面定义的score函数来比较吗？确实可以，但是如果直接使用score来挑选的话，会导致那些很短的句子更容易被选出。<strong>因为score函数的每一项都是负的，序列越长，score往往就越小。因此我们可以使用长度来对score函数进行细微的调整：对每个序列的得分，除以序列的长度。根据调整后的结果来选择best
one。</strong></p>
<p>Beam Search的使用，往往可以得到比Greedy
Search更好的结果，道理很容易理解，高手下棋想三步，深思熟虑才能走得远。</p>
<h3><span id="15-nmt的优缺点">1.5 <strong>NMT的优缺点</strong></span></h3>
<p>NMT相比于SMT，最大的优点当然就如前面所说的——简洁。我们<strong>不需要什么人工的特征工程，不需要各种复杂的前后组件，就是一个端到端的神经网络，整个结构一起进行优化</strong>。</p>
<p>另外，由于使用了深度学习的方法，我们可以引入很多语义特征，比如利用文本的相似度，利用文本内隐含的多层次特征，这些都是统计学方法没有的。</p>
<p>但是，没有什么东西是绝对好或绝对差的，NMT也有其不足。它的不足也是跟深度学习的黑箱本质息息相关。<strong>NMT的解释性差，难以调试，难以控制，我们谁也不敢保证遇到一个新的文本它会翻译出什么奇怪的玩意儿，所以NMT在重要场合使用是有明显风险的。</strong></p>
<h3><span id="16-nmt的评价">1.6 <strong>NMT的评价</strong></span></h3>
<p>机器翻译的效果如何评价呢？——<strong>「BLEU」</strong>指标。<strong>BLEU，全称是Bilingual
Evaluation
Understudy，它的主要思想是基于N-gram等特征来比较人工翻译和机器翻译结果的相似程度。</strong></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/3EQCSMJ/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/3EQCSMJ/" class="post-title-link" itemprop="url">深度学习（3）Normalization*</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-14 22:12:43" itemprop="dateCreated datePublished" datetime="2022-05-14T22:12:43+08:00">2022-05-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-18 21:10:47" itemprop="dateModified" datetime="2023-04-18T21:10:47+08:00">2023-04-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">理论基础</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>15k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>27 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="batchnormalization的原理作用和实现">BatchNormalization的原理、作用和实现</h1>
<blockquote>
<p>Transformer中的归一化(一)：什么是归一化&amp;为什么要归一化 - Gordon
Lee的文章 - 知乎 https://zhuanlan.zhihu.com/p/476102712</p>
<p>Transformer中的归一化(二)：机器学习中的特征归一化方法 - Gordon
Lee的文章 - 知乎 https://zhuanlan.zhihu.com/p/477116352</p>
<p>Transformer中的归一化(三)：特征归一化在深度神经网络的作用 - Gordon
Lee的文章 - 知乎 https://zhuanlan.zhihu.com/p/481179310</p>
<p><strong>Transformer中的归一化(四)：BatchNormalization的原理、作用和实现</strong>:https://zhuanlan.zhihu.com/p/481277619?utm_source=wechatMessage_undefined_bottom</p>
<p><strong>Transformer中的归一化(五)：Layer Norm的原理和实现 &amp;
为什么Transformer要用LayerNorm</strong> - Gordon Lee的文章 - 知乎
https://zhuanlan.zhihu.com/p/492803886</p>
</blockquote>
<h4 id="归一化的作用">归一化的作用：</h4>
<ul>
<li><strong>可解释性</strong>：<strong>回归模型</strong>中自变量X的量纲不一致导致了<strong>==回归系数无法直接解读==</strong>或者错误解读；需要将X都处理到统一量纲下，这样才可比【可解释性】；<strong>取决于我们的逻辑回归是不是用了正则化</strong>。如果你不用正则，标准化并不是必须的，如果用正则，那么标准化是必须的。</li>
<li><strong>距离计算</strong>：机器学习任务和统计学任务中有很多地方要用到<strong>==“距离”的计算==</strong>，比如<strong>PCA，比如KNN，比如kmeans</strong>等等，假使算欧式距离，不同维度量纲不同可能会导致距离的计算依赖于量纲较大的那些特征而得到不合理的结果；</li>
<li><strong>加速收敛（BN）</strong>：参数估计时使用<strong>==梯度下降==</strong>，在使用梯度下降的方法求解最优化问题时，
归一化/标准化后可以加快梯度下降的求解速度，即<strong>==提升模型的收敛速度==</strong>。</li>
</ul>
<h4 id="batch-normalization-作用">Batch Normalization 作用：</h4>
<ul>
<li><strong>更好的尺度不变性：</strong>也就是说不管低层的参数如何变化，逐层的输入分布都保持相对稳定。
<ul>
<li><strong><font color="red">尺度不变性能够提高梯度下降算法的效率，从而加快收敛</font></strong>;</li>
<li><strong><font color="red">归一化到均值为0，方差为1的分布也能够使得经过sigmoid，tanh等激活函数以后，尽可能落在梯度非饱和区，缓解梯度消失的问题。</font></strong>【<strong>bn和ln都可以比较好的抑制梯度消失和梯度爆炸的情况</strong>】;</li>
</ul></li>
<li><strong>更平滑的优化地形：</strong>更平滑的优化地形意味着<strong>局部最小值的点更少</strong>，能够使得梯度更加reliable和predictive，从而让我们有更大的”信心”迈出更大的step来优化，即可以使用更大的学习率来加速收敛。</li>
<li><strong><font color="red">
对参数初始化和学习率大小不太敏感：</font></strong>BN操作可以抑制参数微小变化随网络加深的影响，使网络可以对参数初始化和尺度变化适应性更强，从而可以使用更大的学习率而不用担心参数更新step过大带来的训练不稳定。</li>
<li><strong>隐性的正则化效果：（Batch）</strong>训练时采用随机选取mini-batch来计算均值和方差，不同mini-batch的均值和方差不同，近似于引入了随机噪音，使得模型不会过拟合到某一特定的均值和方差参数下，提高网络泛化能力。</li>
</ul>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/posts/3EQCSMJ/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/ZQ2GRE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/ZQ2GRE/" class="post-title-link" itemprop="url">异常检测（2）Isolation Forest</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-14 21:23:06" itemprop="dateCreated datePublished" datetime="2022-05-14T21:23:06+08:00">2022-05-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-18 20:29:01" itemprop="dateModified" datetime="2023-04-18T20:29:01+08:00">2023-04-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/" itemprop="url" rel="index"><span itemprop="name">异常检测</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="一-isolation-forest">==一、Isolation Forest==</span></h2>
<blockquote>
<p>孤立森林(isolation Forest)-一个通过瞎几把乱分进行异常检测的算法 -
小伍哥聊风控的文章 - 知乎 https://zhuanlan.zhihu.com/p/484495545</p>
<p>##### <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/131406753">Isolation
Forest算法梳理🌳</a>Isolation Forest算法梳理🌳</p>
</blockquote>
<h3><span id="11-概述">1.1 概述</span></h3>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182028365.png" alt="Isolation Forest算法梳理🌳">
<figcaption aria-hidden="true">Isolation Forest算法梳理🌳</figcaption>
</figure>
<p><strong>异常检测 (anomaly
detection)</strong>，或者又被称为“<strong>离群点检测</strong>” (outlier
detection)，是机器学习研究领域中跟现实紧密联系、有广泛应用需求的一类问题。但是，什么是异常，并没有标准答案，通常因具体应用场景而异。如果要给一个比较通用的定义，很多文献通常会引用
Hawkins
在文章开头那段话。很多后来者的说法，跟这个定义大同小异。这些定义虽然笼统，但其实暗含了认定“异常”的两个标准或者说假设：</p>
<p><strong>孤立森林 <img src="https://www.zhihu.com/equation?tex=%28Isolation%5C+Forest%29" alt="[公式]"> 是一个基于 <img src="https://www.zhihu.com/equation?tex=Ensemble" alt="[公式]">
的快速异常检测方法，具有线性时间复杂度和高精准度。</strong>其可以用于网络安全中的攻击检测，金融交易欺诈检测，疾病侦测，和噪声数据过滤等。</p>
<p>孤立森林算法的理论基础有两点：</p>
<ul>
<li>异常数据占总样本量的比列很小</li>
<li>异常点的特征值与正常点的差异很大</li>
</ul>
<h3><span id="12-itree的构建">1.2 iTREE的构建</span></h3>
<p><img src="https://www.zhihu.com/equation?tex=iTree" alt="[公式]">
是一棵随机二叉树，每一个节点要么有两个孩子，要么就是叶子节点。假设给定一堆数据集
<img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BD%7D" alt="[公式]"> ，这里 <img src="https://www.zhihu.com/equation?tex=%5Cmathbb%7BD%7D" alt="[公式]"> 的所有属性都是连续型的变量， <img src="https://www.zhihu.com/equation?tex=+iTree" alt="[公式]">
的构建过程如下：</p>
<ol type="1">
<li><p><strong>随机选择一个属性</strong> <img src="https://www.zhihu.com/equation?tex=Attr" alt="[公式]">
；</p></li>
<li><p><strong>随机选择该属性的一个值</strong> <img src="https://www.zhihu.com/equation?tex=Value" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=%5Cmin%5C%7BAttr%5C%7D%3CValue%3C%5Cmax%5C%7BAttr%5C%7D" alt="[公式]"> ;</p></li>
<li><p><strong>根据 <img src="https://www.zhihu.com/equation?tex=Attr+" alt="[公式]"> 对每条记录进行分类，把 <img src="https://www.zhihu.com/equation?tex=Attr" alt="[公式]"> 小于 <img src="https://www.zhihu.com/equation?tex=Value" alt="[公式]">
的记录放在左子树，把大于等于 <img src="https://www.zhihu.com/equation?tex=Value" alt="[公式]">
的记录放在右子树</strong>；</p></li>
<li><p><strong>递归构造左右子树，直到满足下列条件</strong>：（1）传入的数据集只有一条记录或者多条同样的记录；（2）树的深度达到了限定深度。</p></li>
</ol>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182028147.jpg" alt="img" style="zoom:50%;"></p>
<p><img src="https://www.zhihu.com/equation?tex=iTree" alt="[公式]">
构建完成之后，只需要追踪测试数据落在 <img src="https://www.zhihu.com/equation?tex=iTree" alt="[公式]">
哪个叶子节点上即可评估该数据是否为异常数据，由图中 <img src="https://www.zhihu.com/equation?tex=iTree" alt="[公式]">
的构造过程可以发现异常数据通常会很快被分配到叶子节点上，因此可以使用叶子结点到根结点的路径长度（即边的条数）
<img src="https://www.zhihu.com/equation?tex=h%28x%29" alt="[公式]">
来判断一条记录 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 是否是异常点。</p>
<h3><span id="13-iforest-构建">1.3 iForest 构建</span></h3>
<p>由于 <img src="https://www.zhihu.com/equation?tex=iTree" alt="[公式]">
是随机选择属性和随机选择属性值来构建的，因此可以预见对于单棵 <img src="https://www.zhihu.com/equation?tex=iTree" alt="[公式]">
的预测效果肯定不会很理想，因此通过引入多棵 <img src="https://www.zhihu.com/equation?tex=iTree" alt="[公式]">
共同来预测那么从效果上看肯定会更具有说服力。 <img src="https://www.zhihu.com/equation?tex=iForest" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=Random%5C+Forest" alt="[公式]">
的方法有些类似，都是通过随机采样，利用部分采样数据来构造每一棵树，以保证不同树之间的差异性。在构建
<img src="https://www.zhihu.com/equation?tex=iForest" alt="[公式]">
的过程中有，采样的样本大小 <img src="https://www.zhihu.com/equation?tex=+%5Cpsi" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=iTree" alt="[公式]"> 的数量
<img src="https://www.zhihu.com/equation?tex=t" alt="[公式]">
这两个超参数需要确定，样本采样大小超过 <img src="https://www.zhihu.com/equation?tex=256" alt="[公式]">
效果就提升不大了。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182028401.jpg" alt="img" style="zoom:67%;"></p>
<p>通过采样数据不仅可以降低计算时间的上面的浪费，而且还能够解决一些其它的小问题：</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182028205.jpg" alt="preview" style="zoom:67%;"></p>
<p>左图是原始数据，右图是经过采样了的数据，蓝色代表正常样本，红色代表异常样本。可以看出，在采样之前，正常样本和异常样本出现了重叠，因此很难分开，但通过采样之后，异常样本和正常样本可以明显的分开。
<img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 控制了
<img src="https://www.zhihu.com/equation?tex=iTree" alt="[公式]">
的数量即 <img src="https://www.zhihu.com/equation?tex=Ensemble%5C+size" alt="[公式]"> ，孤立森林算法提出者通过实验发现，当 <img src="https://www.zhihu.com/equation?tex=+t%3D100" alt="[公式]">
之前时，算法就会收敛，故通常设置 <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"> 为默认值 <img src="https://www.zhihu.com/equation?tex=100" alt="[公式]"> ，训练一个
<img src="https://www.zhihu.com/equation?tex=+iForest" alt="[公式]">
最差情况下的时间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BO%7D%28t%5Cpsi%5E2%29" alt="[公式]"> 空间复杂度为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal++O%28t%5Cpsi%29+" alt="[公式]"> 。</p>
<h3><span id="14-评估">1.4 评估</span></h3>
<p>为了更好的归一化和比较，<strong>孤立森林通过引入异常值函数</strong>
<img src="https://www.zhihu.com/equation?tex=s%28x%2C+n%29" alt="[公式]"> 来衡量记录 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]">
是否为异常点。</p>
<blockquote>
<p>给定一个包含 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 个样本的数据集，<strong>树的平均路径长度为：
c(n)</strong>。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=c(n)%3D2H(n-1)-\frac%7B2(n-1)%7D%7Bn%7D+\" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中， <img src="https://www.zhihu.com/equation?tex=H%28%2A%29" alt="[公式]"> 为调和数， <img src="https://www.zhihu.com/equation?tex=H%28%2A%29%3D%5Cln%28%2A%29%2B%5Cxi" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=%5Cxi" alt="[公式]"> 为欧拉常数，约为 <img src="https://www.zhihu.com/equation?tex=0.5772156649" alt="[公式]"> 。
<img src="https://www.zhihu.com/equation?tex=c%28n%29" alt="[公式]">
为给定样本数 <img src="https://www.zhihu.com/equation?tex=n" alt="[公式]"> 时，路径长度的平均值，用来标准化记录 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 的路径长度
<img src="https://www.zhihu.com/equation?tex=h%28x%29" alt="[公式]">
。</p>
</blockquote>
<p><strong>故记录 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 的异常得分可以定义为：s(x, n)</strong>.其中，
<strong><font color="red"> <img src="https://www.zhihu.com/equation?tex=E%28h%28x%29%29" alt="[公式]">
为记录 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]">
在多个 <img src="https://www.zhihu.com/equation?tex=iTree" alt="[公式]"> 中的路径长度的期望值。</font></strong>可视化 <img src="https://www.zhihu.com/equation?tex=s%28x%2Cn%29" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=E%28h%28x%29%29" alt="[公式]"> 的关系：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=s%28x%2C+n%29%3D2%5E%7B-%5Cfrac%7BE%28h%28x%29%29%7D%7Bc%28n%29%7D%7D%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><img src="https://pic4.zhimg.com/80/v2-b7f0fe8132465c0b1919b7c283d1e887_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>可以得出以下结论：</p>
<ul>
<li>当 <img src="https://www.zhihu.com/equation?tex=E%28h%28x%29%29%5Crightarrow+c%28n%29" alt="[公式]"> 时， <img src="https://www.zhihu.com/equation?tex=s%5Crightarrow+0.5" alt="[公式]"> ，即记录 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]">
的平均长度与树的平均路径长度相近时，则不能区分是否为异常；</li>
<li>当 <img src="https://www.zhihu.com/equation?tex=E%28h%28x%29%29%5Crightarrow+0" alt="[公式]"> ， <img src="https://www.zhihu.com/equation?tex=s%5Crightarrow+1" alt="[公式]"> ，即记录 <img src="https://www.zhihu.com/equation?tex=x" alt="[公式]"> 的异常分数接近 <img src="https://www.zhihu.com/equation?tex=1" alt="[公式]">
时，被判定为异常数据；</li>
<li>当 <img src="https://www.zhihu.com/equation?tex=E%28h%28x%29%29%5Crightarrow+n-1" alt="[公式]"> 时， <img src="https://www.zhihu.com/equation?tex=s%5Crightarrow+0+" alt="[公式]"> ，被判定为正常数据。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/GTE114/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/GTE114/" class="post-title-link" itemprop="url">特征工程（4）Auto工具</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-05-14 19:33:31 / 修改时间：19:36:59" itemprop="dateCreated datePublished" datetime="2022-05-14T19:33:31+08:00">2022-05-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">特征工程</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="四-autoeda-工具">四、AutoEDA 工具</span></h2>
<blockquote>
<p>盘点Kaggle中常见的AutoEDA工具库：
https://zhuanlan.zhihu.com/p/444405236</p>
</blockquote>
<h4><span id="41-pandas-profiling">4.1 <strong>Pandas Profiling</strong></span></h4>
<ul>
<li><a href="http://link.zhihu.com/?target=https%3A//pandas-profiling.github.io/pandas-profiling/docs/master/index.html">https://pandas-profiling.github.io/pandas-profiling/docs/master/index.html</a></li>
</ul>
<p><strong>Pandas
Profiling</strong>是款比较成熟的工具，可以直接传入DataFrame即可完成分析过程，将结果展示为HTML格式，同时分析功能也比较强大。</p>
<ul>
<li>功能：<strong>字段类型分析、变量分布分析、相关性分析、缺失值分析、重复行分析</strong></li>
<li>耗时：较少</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-97af4843870e76e9d9ef1a4518a27bb2_720w.jpg?source=d16d100b" alt="img" style="zoom: 67%;"></p>
<h4><span id="42-autoviz"><strong>4.2 AutoViz</strong></span></h4>
<ul>
<li><a href="http://link.zhihu.com/?target=https%3A//github.com/AutoViML/AutoViz">https://github.com/AutoViML/AutoViz</a></li>
</ul>
<p><strong>AutoViz是款美观的数据分析工具</strong>，在进行可视化的同时将结果保存为图片格式。</p>
<ul>
<li>功能：<strong>相关性分析、数值变量箱线图、数值变量分布图</strong></li>
<li>耗时：较多</li>
</ul>
<p><img src="https://pic2.zhimg.com/80/v2-cc73734146a68cd619ed33dd8e5525b1_1440w.jpg?source=d16d100b" alt="img" style="zoom: 67%;"></p>
<h4><span id="43-dataprep">==4.3 <strong>Dataprep</strong>==</span></h4>
<ul>
<li><a href="http://link.zhihu.com/?target=https%3A//dataprep.ai/">https://dataprep.ai/</a></li>
</ul>
<p><strong>Dataprep是款比较灵活也比较强大的工具，也是笔者最喜欢的。它可以指定列进行分析，同时也可以在Notebook中进行交互式分析。</strong></p>
<ul>
<li>功能：<strong>字段类型分析、变量分布分析、相关性分析、缺失值分析、交互式分析</strong>。</li>
<li>耗时：较多</li>
</ul>
<p><img src="https://pic1.zhimg.com/80/v2-622241d523ff43ded380d414d040c5d7_1440w.jpg?source=d16d100b" alt="img" style="zoom: 67%;"></p>
<h4><span id="44-sweetviz"><strong>4.4 SweetViz</strong></span></h4>
<ul>
<li><a href="http://link.zhihu.com/?target=https%3A//github.com/fbdesignpro/sweetviz">https://github.com/fbdesignpro/sweetviz</a></li>
</ul>
<p><strong>SweetViz是款强大的数据分析工具，可以很好的分析训练集和测试集，以及目标标签与特征之间的关系</strong>。</p>
<ul>
<li>功能：数据集对比分析、字段类型分析、变量分布分析、目标变量分析</li>
<li>耗时：中等<img src="https://pica.zhimg.com/80/v2-45b365b953f62a41680381891eedca9b_1440w.jpg?source=d16d100b" alt="img" style="zoom:67%;"></li>
</ul>
<h4><span id="45-d-tale">4.5 D-Tale</span></h4>
<ul>
<li><a href="http://link.zhihu.com/?target=https%3A//github.com/man-group/dtale">https://github.com/man-group/dtale</a></li>
</ul>
<p><code>D-Tale</code>是款功能最为强大的数据分析工具，对单变量的分析过程支持比较好。</p>
<ul>
<li>功能：字段类型分析、变量分布分析、相关性分析、缺失值分析、交互式分析。</li>
<li>耗时：中等</li>
</ul>
<p><img src="https://pic2.zhimg.com/80/v2-7c66f31393a92e6ba7c87e03478277e1_1440w.jpg?source=d16d100b" alt="img" style="zoom:67%;"></p>
<h2><span id="五-警惕特征工程中的陷阱">五、</span></h2>
<blockquote>
<p>特征工程(Feature
Engineering)是机器学习中的重要环节。在传统的项目中，百分之七十以上的时间都花在了预处理数据上(Data
Preprocessing)，其中特征工程消耗了很多时间。</p>
<p>一般来说，特征工程涵盖的内容非常广泛，包括从<strong>缺失值补全、特征选择、维度压缩，到对输入数据的范围进行变换（Data
Scaling）等</strong>。举个简单的例子，一个K-近邻算法的输入数据有两个特征
<img src="https://www.zhihu.com/equation?tex=%7BX_1%2CX_2%7D" alt="[公式]"> ，但 <img src="https://www.zhihu.com/equation?tex=X_1" alt="[公式]"> 这个特征的取值范围在 <img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[公式]"> 而
<img src="https://www.zhihu.com/equation?tex=X_2" alt="[公式]">
的范围在<img src="https://www.zhihu.com/equation?tex=%5B-1000%2C1000%5D" alt="[公式]">
。不可避免的，K-近邻的结果取决于距离，那么很容易被取值范围大的特征，也就是此处的
<img src="https://www.zhihu.com/equation?tex=X_2" alt="[公式]">
所“垄断”。在这种情况下，把 <img src="https://www.zhihu.com/equation?tex=%7BX_1%2CX_2%7D" alt="[公式]">
的取值调整到可比较的范围上就成了必须。常见的做法有归一化或者标准化，此处不再赘述，可以参考[1]。为了简化内容，本文中的例子仅以归一化作为唯一的特征工程。今天主要说的是：特征工程中的面临的进退两难。</p>
</blockquote>
<h4><span id="51-如何保证训练集-测试集-预测数据-有相同的输入">5.1 <strong>如何保证
训练集、测试集、预测数据 有相同的输入？</strong></span></h4>
<p>以刚才的例子为基础，我们把所有数据按照70:30的比例分为训练集和测试集，并打算使用K-近邻进行训练。那么一个令人困扰的问题是，对训练集的特征做归一化后，测试集的特征怎么办？这是一个非常关键的问题，因为训练集<strong>特征归一化</strong>后，测试集的特征范围可能就不同了，因此模型失效。一般有几种思路：</p>
<ul>
<li><strong>方法1：把训练集和测试集合在一起做归一化</strong>，这样特征范围就统一了。之后用训练集做训练，那测试集做测试。<strong>但很明显的，在训练模型时，不应该包括任何测试集的信息</strong>。这种做法会导致存在人为偏差的模型，不能用。</li>
<li><strong>方法2：对训练集单独做归一化，之后对测试集单独做归一化</strong>。这种看法看似也可以，重点在于数据量以及数据的排列顺序。<strong>在数据量大且数据被充分打乱的前提下，这种做法是可行的</strong>。但换句话说，如果有这样的前提假设，那么方法1的结论也是可行的。</li>
<li><strong>方法3：对训练集先做归一化，并保留其归一化参数（如最大、最小值），之后用训练集的归一化参数对测试集做处理。</strong>这种做法看似是可以的。<strong>但风险在于数据量有限的前提下，训练集的参数会导致测试集的结果异常，如产生极大或者极小的数值</strong>。</li>
</ul>
<blockquote>
<p>其实不难看出，从某种意义上说，三种做法是等价的。在数据量大且充分打乱的前提下，训练集和验证集有相同的分布假设，因此用任意一种其实差别不大。然而这样的假设过于乐观，<strong>且我们在真实情况下应该只有{==训练集+1个测试数据==}，因此方法2是明显不行的</strong>。</p>
<p>方法1常常被认为是错误的操作，原因是在训练阶段引入了测试数据，这属于未知数据。即使仅仅引入了1个测试数据，如果取值非常极端，依然会导致输出范围有较大的波动。其次，如果对于每一个测试数据都需要用整个训练集来归一的话，那么运算开销会非常大。</p>
<p>那么似乎备选的只有方案3，即保<strong>留验证集上的归一化参数</strong>，并运用于测试集。这样的做法看似可以，但有不少风险：</p>
<ul>
<li><strong>不是每种特征工程都可以保存参数，很多特征工程是非常繁复的</strong>。</li>
<li>如果测试集数据和训练集数据有很大的差别，那么用测试集的参数会产生异常数据。</li>
</ul>
</blockquote>
<h4><span id="52-可能的解决方案">5.2 可能的解决方案</span></h4>
<p>在<strong>模型评估阶段</strong>，如果我们假设拥有大量数据，且充分打乱其顺序。那么在划分训练集和测试集前，可以对整体数据进行统一的特征工程。不难看出，这和统计学的大数定理有异曲同工之妙。这种做法是最为高效的，需要的运算量最小。而将“测试数据”暴露给训练模型的风险也并不大，因为大数据量使得分布比较稳定，可以忽略。换个角度来看，当数据量非常大的时候，使用其他方法进行特征工程的开销会过大，不利于模型评估。因此，在<strong>模型评估阶段</strong>，如果符合以上假设，可以用这种方法（也就是上文的方法1）。但退一步说，如果满足这个条件，那么方法3也是等价的。</p>
<p>在<strong>预测阶段</strong>，每次假设我们只有1个测试点，那么最佳方案还是保存训练集上特征工程的参数或者模型，并直接用于未知数据的特征工程（也就是上文的方法3）。</p>
<p>但在<strong>预测阶段</strong>，一个一个数据的预测是非常昂贵的，我们一般会做<strong>“批处理”(batch
operation)</strong>。换句话说，就是攒够一定量的预测数据后统一进行预测。在这种情况下，我们：</p>
<ul>
<li>利用方法3，按照顺序对每个训练数据进行处理</li>
<li>利用方法1，风险在于（方法1）会影响训练数据且需要重新训模型</li>
<li><strong>利用方法2，此时较为稳妥</strong>。在批的尺寸较大，且与训练数据分布相同（接近）时，效果应该与方法3一致，但效率可以得到提升</li>
</ul>
<h3><span id="53-总结"><strong>5.3 总结</strong></span></h3>
<p>这篇文章的重点是：“特征工程虽然重要，但极容易在使用中带来风险。”比如在训练时同时误用了测试数据进行特征工程，也叫做数据泄露(data
leakage)。但数据泄露其实也是个伪命题，<strong>当数据量大且分布相同时，使用哪一种方法得到结果应该都近似等价，而更重要的是运行效率</strong>。分类讨论的话，方法1、2、3都有可能是适合的方法。</p>
<p>但我们依然希望能避免类似的风险，因此尽量避免不必要的特征工程，有以下建议：</p>
<ul>
<li><strong>选择对于特征学习能力强的模型，在数据量允许的情况下可以选择深度学习</strong></li>
<li><strong>避免不必要的特征工程，数据范围比较良好的情况下省略某些特征工程</strong></li>
<li><strong>优先选择对于特征工程要求低的模型，如xgboost等</strong></li>
</ul>
<h2><span id="六-业务角度看特征工程">六、业务角度看特征工程</span></h2>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/505480353">如何从业务角度看特征工程</a></p>
</blockquote>
<p>前两天刷某知名社交软件的时候看到有人问特征工程现在还重要吗？觉得是个很有意思的事情。其实工业界能够支持的起大规模稀疏向量的场景大概并不是想象中的那么多，大多数场景面对极为稀疏的行为数据下都很难在ID层面得到很好的emb表达。在这个前提下，没有好的特征工程，其余的模型结构优化或者各种花里胡哨的模型结构都是纸上谈兵。真正被小场景捶打过的朋友，比如我，绝对会在一次又一次的生活毒打中明白，抛弃那些ppt上的高级多塔多注意力，直面特征工程的人生吧！</p>
<p>有竞赛经验的小伙伴都明白，一个强特能一飞冲天，一个灵机一动能直上top榜。但是，长久的可持续的特征工程决不能够靠简单的灵机一动来实现，特别是当手上有无数的芝麻大小的场景时，一个系统的特征工程思维就尤为重要了。本文将从以下几个方面来阐述特征工程中的方方面面。提前说明的是，一般的特征工程常用方法，例如one-hot，hash-encoding，分桶等等不会作为本文的重点，因为这是器的维度，文末有一篇非常全面的文章供参考，本文主要聚焦在术的维度，也就是怎么去思考和选用方法的层面。<strong>首先，我会给出一个特征工程树，这个属于一个主流版本，希望在屏蔽场景特殊性的情况下，给出一般场景的思考方法</strong>。接下来，我会介绍上文提到的特征树的细节，包括涉及到的具体特征例子。第三部分，则包括特征之间可能存在的相互作用和不同特征适合的模型类型。最后，我给出了一个具体场景的具体例子，并说明这个场景的一般性和特殊性，给出针对具体业务场景的特征工程思路。</p>
<p>此外，一个基础认知是，这里的特征是指输入模型的信息，包括偏置或者先验，这些特征的使用方式除了作为模型的输入，也可以通过其他的方式引入，例如样本工程或者损失函数，这个就不在本文讨论范围之内了。当然还是那句老话，个人的认知是有限的，欢迎有经验的小伙伴交流和指正。</p>
<h3><span id="6-1-基础特征树">6. 1 基础特征树</span></h3>
<p>不管是基于已有的模型迭代优化，又或者是从0到1构建一个场景的全部特征，都需要自己梳理一个完整的基础特征树。这是了解一个场景的开始。做这件事情我推荐的方法是<strong>先体验这个场景，然后分类列出所有可能影响你优化目标决策的因素以及优化目标的历史信息</strong>。</p>
<p>对于绝大多数业务来讲，基础的特征树都可以分为以下3大部分。</p>
<ul>
<li><strong>供给侧</strong>：对于大部分to
c的互联网应用，供给侧都是item，可能是音乐，doc或者一条推送消息。</li>
<li><strong>消费侧</strong>：有关用户的一切描述，其中比较特殊的是序列特征。</li>
<li><strong>上下文</strong>：场景测的因素，包括特定的时刻，特定的展现形式等。</li>
<li><strong>交叉特征</strong>：以上三个部分任意两部分或全部的交叉特征。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/21E1VBV/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/21E1VBV/" class="post-title-link" itemprop="url">深度学习（10）AutoEncoder</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-13 19:15:40" itemprop="dateCreated datePublished" datetime="2022-05-13T19:15:40+08:00">2022-05-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-06-15 21:23:07" itemprop="dateModified" datetime="2022-06-15T21:23:07+08:00">2022-06-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Seq2Seq/" itemprop="url" rel="index"><span itemprop="name">Seq2Seq</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>21 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="自编码器autoencoder">自编码器（AutoEncoder）</span></h2>
<h4><span id="引言">引言</span></h4>
<p>    当你在看论文的时候，经常会遇到编码器、解码器、自编码器（Autoencoder）这些字眼，它们到底是干什么的呢？其主要作用又是什么呢？那么本篇主要带大家了解自编码器（Autoencoder）。</p>
<h3><span id="一-自编码器autoencoder介绍">一、自编码器（Autoencoder）介绍</span></h3>
<p>暂且不谈神经网络、深度学习等，仅仅是自编码器的话，其原理其实很简单。自编码器可以理解为一个试图去还原其原始输入的系统。自编码器模型如下图所示。</p>
<p><img src="https://pic4.zhimg.com/80/v2-f4444b7343ef311fd04f0dc0dc1db3b7_1440w.jpg" alt="img" style="zoom:67%;"></p>
<p>从上图可以看出，自编码器模型主要由编码器（Encoder）和解码器（Decoder）组成，其主要目的是将输入x转换成中间变量y，然后再将y转换成
<img src="https://www.zhihu.com/equation?tex=%5Coverline+x" alt="[公式]"> ，然后对比输入x和输出 <img src="https://www.zhihu.com/equation?tex=%5Coverline+x" alt="[公式]">
使得他们两个无限接近。</p>
<h4><span id="11-神经网络自编码模型">1.1 神经网络自编码模型</span></h4>
<p>在深度学习中，自动编码器是一种无监督的神经网络模型，它可以学习到输入数据的隐含特征，这称为编码(coding)，同时用学习到的新特征可以重构出原始输入数据，称之为解码(decoding)。从直观上来看，自动编码器可以用于特征降维，类似主成分分析PCA，但是其相比PCA其性能更强，这是由于神经网络模型可以提取更有效的新特征。除了进行特征降维，自动编码器学习到的新特征可以送入有监督学习模型中，所以自动编码器可以起到特征提取器的作用<strong>。举个例子，我有一张清晰图片，首先我通过编码器压缩这张图片的大小（如果展现出来可能比较模型），然后在需要解码的时候将其还原成清晰的图片</strong>。具体过程如下图所示。</p>
<h4><span id="12-神经网络自编码器三大特点">1.2 神经网络自编码器三大特点</span></h4>
<ul>
<li><strong>自动编码器是数据相关</strong>的（data-specific 或
data-dependent），这意味着自动编码器只能压缩那些与训练数据类似的数据。比如，使用人脸训练出来的自动编码器在压缩别的图片，比如树木时性能很差，因为它学习到的特征是与人脸相关的。</li>
<li><strong>自动编码器是有损的</strong>，意思是解压缩的输出与原来的输入相比是退化的，MP3，JPEG等压缩算法也是如此。这与无损压缩算法不同。</li>
<li>自动编码器是从数据样本中自动学习的，这意味着很容易对指定类的输入训练出一种特定的编码器，而不需要完成任何新工作。</li>
</ul>
<h4><span id="13-自编码器autoencoder搭建">1.3 自编码器（Autoencoder）搭建</span></h4>
<p>搭建一个自动编码器需要完成下面三样工作：搭建<strong>编码器</strong>，搭建<strong>解码器</strong>，设定一个<strong>损失函数，用以衡量由于压缩而损失掉的信息</strong>。编码器和解码器一般都是参数化的方程，并关于损失函数可导，典型情况是使用神经网络。编码器和解码器的参数可以通过最小化损失函数而优化，例如<strong>SGD</strong>。举个例子：根据上面介绍，自动编码器看作由两个级联网络组成。</p>
<ul>
<li>第一个网络是一个编码器，负责接收输入 x，并将输入通过函数 h
变换为信号 y：</li>
</ul>
<figure>
<img src="https://pic3.zhimg.com/80/v2-b9331fbb152409c69a14c056b6d56c52_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>第二个网络将编码的信号 y 作为其输入，通过函数f得到重构的信号
r：</li>
</ul>
<figure>
<img src="https://pic2.zhimg.com/80/v2-38e2787955e83ebf81b74992ac77da79_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>定义误差 e 为原始输入 x 与重构信号 r
之差，e=x–r，网络训练的目标是减少<strong>均方误差（MSE）</strong>，同
MLP 一样，误差被反向传播回隐藏层。</li>
</ul>
<h4><span id="14-几种常见编码器">1.4 几种常见编码器</span></h4>
<p>自编码器（autoencoder）是神经网络的一种，经过训练后能尝试将输入复制到输出。自编码器（）autoencoder）内部有一个隐藏层
h，可以产生编码（code）表示输入。该网络可以看作由两部分组成：一个由函数
h = f(x) 表示的编码器和一个生成重构的解码器 r =
g(h)。如果一个自编码器只是简单地学会将处处设置为 g(f(x)) =
x，那么这个自编码器就没什么特别的用处。相反，<strong>我们不应该将自编码器设计成输入到输出完全相等</strong>。这通常需要向自编码器强加一些约束，使它只能近似地复制，并只能复制与训练数据相似的输入。这些约束强制模型考虑输入数据的哪些部分需要被优先复制，因此它往往能学习到数据的有用特性。</p>
<ul>
<li><strong>堆栈自动编码器</strong>
前面讲的自编码器只是简答的含有一层，其实可以采用更深层的架构，这就是堆栈自动编码器或者深度自动编码器，本质上就是增加中间特征层数。这里我们以MNIST数据为例来说明自动编码器，建立两个隐含层的自动编码器，如下图所示：</li>
</ul>
<figure>
<img src="https://pic4.zhimg.com/80/v2-e1b65e3d86fd1a8fbb56df20eeefd113_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>    对于MNIST来说，其输入是<span class="math inline">\(28*28=784\)</span>维度的特征，这里使用了两个隐含层其维度分别为300和150，可以看到是不断降低特征的维度了。得到的最终编码为150维度的特征，使用这个特征进行反向重构得到重建的特征，我们希望重建特征和原始特征尽量相同。</p>
<ul>
<li><p><strong>欠完备自编码器</strong>从自编码器获得有用特征的一种方法是限制
h的维度比 x
小，这种编码维度小于输入维度的自编码器称为欠完备（undercomplete）自编码器。<strong>学习欠完备的表示将强制自编码器捕捉训练数据中最显著的特征</strong>。</p></li>
<li><p><strong>正则自编码器</strong>使用的损失函数可以鼓励模型学习其他特性（除了将输入复制到输出），而不必限制使用浅层的编码器和解码器以及小的编码维数来限制模型的容量。这些特性包括稀疏表示、表示的小导数、以及对噪声或输入缺失的鲁棒性。即使模型容量大到足以学习一个无意义的恒等函数，非线性且过完备的正则自编码器仍然能够从数据中学到一些关于数据分布的有用信息。</p></li>
<li><p><strong>去噪自编码器</strong>（denoisingautoencoder,
DAE）是一类接受损坏数据作为输入，并训练来预测原始未被损坏数据作为输出的自编码器。</p></li>
</ul>
<h2><span id="二-李宏毅-auto-encoder-p1">二、李宏毅-Auto-Encoder P1</span></h2>
<h3><span id="21-self-supervisedlearning-framework"><strong>2.1 Self-supervised
Learning Framework</strong></span></h3>
<p>在讲 Auto-Encoder 之前,其实 Auto-Encoder 也可以算是,Self-Supervised
Learning 的一环,所以再让我们用非常短的时间,来看一下Self-Supervised
Learning 的 Framework。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615182816027.png" alt="image-20220615182816027" style="zoom:50%;"></p>
<p>首先你有大量的没有标注的资料,用这些没有标注的资料,你可以去训练一个模型,你必须发明一些不需要标注资料的任务,比如说做填空题,比如说预测下一个
Token。</p>
<p>这个不用标注资料的学习叫做,==Self-Supervised
Learning==,或者是也有人叫
==Pre-Training==,那用这些不用标注资料的任务,学完一个模型以后,它本身没有什麽用,BERT
只能做填空题,GPT
只能够把一句话补完,但是你可以把它用在其他下游的任务里面。你可以把
Self-Supervised Learning 的
Model,做一点点的微微的调整,就可以用在下游的任务里面。</p>
<p><strong><font color="red"> 在有 BERT 在有 GPT
之前,其实有一个更古老的任务,更古老的不需要用标注资料的任务,就叫做
Auto-Encoder,所以你也可以把 Auto-Encoder,看作是 Self-Supervised Learning
的,一种 Pre-Train 的方法。</font></strong></p>
<p>当然可能不是所有人都会同意这个观点,有人可能会说这个
Auto-Encoder,不算是 Self-Supervised Learning,这个 Auto-Encoder
很早就有了嘛,2006 年 15 年前就有了嘛,然后 Self-Supervised Learning 是,19
年才有这个词彙嘛,所以 Auto-Encoder,不算 Self-Supervised Learning
的一环。</p>
<p>那这个都是见仁见智的问题,这种名词定义的问题,真的我们就不用太纠结在这个地方,从
Self-Supervised Learning,它是不需要用 Label Data
来训练,这个观点来看,<strong>Auto-Encoder
我认为它可以算是,Self-Supervised Learning 的其中的一种方法,它就跟填空
预测,接下来的 Token
是很类似的概念,只是用的是另外不一样的想法</strong>。</p>
<h3><span id="22-auto-encoder">2.2 Auto-encoder</span></h3>
<p>Auto-Encoder 是怎麽运作的呢,那现在我们,因为刚才在讲 Self-Supervised
Learning 的时候,都是用文字做例子,那现在我们换成用影像来做例子：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615183004489.png" alt="image-20220615183004489" style="zoom:50%;"></p>
<p>假设你有非常大量的图片,在 Auto-Encoder 里面你有两个 Network,一个叫做
Encoder,一个叫做 Decoder,他们就是两个 Network</p>
<ul>
<li><p><strong>Encoder 把一张图片读进来,它把这张图片变成一个向量,就
Encoder 它可能是很多层的
CNN,把一张图片读进来,它的输出是一个向量,接下来这个向量会变成 Decoder
的输入</strong></p></li>
<li><p><strong>Decoder 会产生一张图片,所以 Decoder 的 Network
的架构,可能会像是 GAN 里面的 Generator,它是 11
个向量输出一张图片</strong></p></li>
</ul>
<p><strong><font color="red"> 训练的目标是希望,Encoder 的输入跟 Decoder
的输出,越接近越好，假设你把图片看作是一个很长的向量的话,我们就希望这个向量跟
Decoder
的输出,这个向量,这两个向量他们的距离越接近越好,也有人把这件事情叫做
==Reconstruction==,叫做重建。</font></strong></p>
<p>所以它是一个 <strong>Unsupervised Learning 的方法</strong>,跟
Self-Supervised 那一系列,Pre-Training
的做法一样,你<strong>完全不需要任何的标注资料</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615183155224.png" alt="image-20220615183155224" style="zoom: 50%;"></p>
<p>那像这样子这个 <strong>Encoder 的输出,有时候我们叫它
Embedding</strong>,我们在讲 BERT 的时候,也提过 Embedding
这个词彙了,那有的人叫它 Representation,有的人叫它 Code,因为 Encoder
是一个编码嘛,所以这个有人把这个 Vector 叫做
Code,那其实指的都是同一件事情。</p>
<h5><span id="怎麽把train-的-auto-encoder用在-downstream-的任务里面呢">怎麽把
Train 的 Auto-Encoder,用在 Downstream 的任务里面呢？</span></h5>
<p>常见的用法就是,原来的图片,你也可以把它看作是一个很长的向量,但这个<strong>向量太长了不好处理</strong>,那怎麽办呢？你把这个图片丢到
<strong>Encoder
以后,输出另外一个向量,这个向量你会让它比较短</strong>,比如说只有 10 维
只有 100
维,那你拿这个新的向量来做你接下来的任务,也就是图片不再是一个很高维度的向量,它通过
Encoder
的压缩以后,变成了一个低维度的向量,你再拿这个低维度的向量,来做接下来想做的事情,这就是常见的,Auto-Encoder用在
Downstream 的任务,用在下游任务的方法。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615183309937.png" alt="image-20220615183309937" style="zoom:50%;"></p>
<p><strong><font color="red"> 而 Encoder
做的事情,是把本来很高维度的东西,转成低维度的东西,把高维度的东西转成低维度的东西又叫做
==Dimension Reduction==。</font></strong></p>
<p>Dimension Reduction 这个技术,我相信你在 Machine Learning
相关的应用上,应该常常听到这个名词,那有关 Dimension Reduction
的技术,它其实牵涉的非常非常地广,所以我们这边就不再细讲,因为这门课,我们只专注在深度学习相关的技术,你可以把
Auto-Encoder 的 Encoder,当作拿来做 Dimension
Reduction,那其他还有很多不是 Deep Learning
Base的,不是以深度学习为基础的,Dimension Reduction的技术。<strong>比如说
PCA 比如说 T-SNE</strong>。</p>
<h3><span id="24-de-noising-auto-encoder">2.4 De-noising Auto-encoder</span></h3>
<p>那 Auto-Encoder 还有一个常见的变形,叫做 De-Noising 的
Auto-Encoder</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615185731272.png" alt="image-20220615185731272" style="zoom:67%;"></p>
<p>De-Noising 的 Auto-Encoder 是说,我们把原来要输进去给 Encoder
的图片,<strong>加上一些杂讯</strong>,就自己随便找一个杂讯把它加进去,然后一样通过
Encoder,一样再通过 Decoder,试图还原原来的图片。那我们现在还原的,不是
Encoder 的输入,Encoder 的输入的图片是有加杂讯的,我们要还原的不是 Encoder
的输入,我们<strong>要还原的是加入杂讯之前的结果</strong>。</p>
<p>所以你会发现说,现在 Encoder 跟
Decoder,除了还原原来的图片这个任务以外,它还<strong>多了一个任务</strong>,这个任务是什麽,这个任务就是,它必须要<strong>自己学会把杂讯去掉</strong>。Encoder
看到的是没有杂讯的图片,但 Decode要还原的目标是,Encoder
看到的是有加杂讯的图片,但 Decoder 要还原的目标是,没有加杂讯的图片,所以
Encoder 加
Decoder,他们合起来必须要联手能够把杂讯去掉,这样你才能够把,De-Noising 的
Auto-Encoder 训练起来。</p>
<p>但是如果你看今天的 BERT 的话,其实你也可以把它看作就是一个,De-Noising
的 Auto-Encoder：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615185813727.png" alt="image-20220615185813727" style="zoom:50%;"></p>
<p>输入我们会加 Masking,那些 <strong>Masking 其实就是
Noise</strong>,BERT 的模型就是 Encoder,它的输出就是 Embedding。在讲 BERT
的技术的时候,我们就告诉你说这个输出就叫做 Embedding,接下来有一个 Linear
的模型,就是Decoder,所以我们可以说,BERT 其实就是一个,De-Noising 的
Auto-Encoder。</p>
<h2><span id="三-auto-encoder-p2">三、Auto-Encoder P2</span></h2>
<h3><span id="31-feature-disentangle">3.1 Feature Disentangle</span></h3>
<p><strong><font color="red"> 除了 Aauto-Encoder,可以用来做当 strime
的任务以外,我还想跟大家分享一下,Aauto-Encoder 其他有意思的应用：
==Feature Disentanglement==。Disentangle
的意思就是,把一堆本来纠缠在一起的东西把它解开。</font></strong></p>
<h5><span id="那为什么会有disentangle-这个议题呢我们来想想看aauto-encoder它在做的事情是什么">那为什么会有
Disentangle 这个议题呢,我们来想想看,Aauto-Encoder
它在做的事情是什么？</span></h5>
<h5><span id="auto-encoder-在做的事情是">Auto-Encoder 在做的事情是：</span></h5>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615190047133.png" alt="image-20220615190047133" style="zoom: 67%;"></p>
<ul>
<li>如果是图片的话,就是把一张图片变成一个 Code,再把 Code 呢
变回图片,既然这个 Code 可以变回图片,代表说这个 Code
里面啊,有很多的资讯,包含图片里面所有的资讯,举例来说,图片里面有什么样的东西啊,图片的色泽纹理啊等等</li>
<li>Auto-Encoder
这个概念也不是只能用在影像上,如果用在语音上,你可以把一段声音丢到 Encoder
里面,变成向量 再丢回
Decoder,变回原来的声音,代表这个向量包含了,语音里面所有重要的资讯,包括这句话的内容是什么,就是
Encoder 的资讯,还有这句话是谁说的,就是 Speaker 语者的资讯</li>
<li>那如果今天是一篇文章,丢到 Encoder 里面变成向量,这个向量通过 Decoder
会变回原来的文章,那这个向量里面有什么,它可能包含文章里面,文句的句法的资讯,也包含了语意的资讯,但是这些资讯是全部纠缠在一个向量里面,我们并不知道一个向量的哪些维,代表了哪些资讯</li>
</ul>
<p>举例来说,如果我们今天把一段声音讯号丢进
Encoder,它会给我们一个向量,但是这个向量里面,哪些维度代表了这句话的内容,哪些维度代表这句话的语者,也就是谁说的,我们没有这样的资讯。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615190127357.png" alt="image-20220615190127357" style="zoom:67%;"></p>
<p>而 Feature Disentangle 想要做到的事情就是,我们有没有可能想办法,在
Train 一个 Aauto-Encoder 的时候,同时有办法知道,这个
Representation,或又叫做 Embedding,或又叫做 Code,我们这个
<strong><font color="red"> Embedding
的哪些维度代表了哪些资讯呢？</font></strong></p>
<p>这边举一个语音上的应用,这个应用叫做 Voice Conversion,Voice Conversion
的中文叫做语者转换,所以也许你没有听过语者转换这个词彙,但是你一定看过它的应用,它就是柯南的领结变身器。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615190304137.png" alt="image-20220615190304137" style="zoom:67%;"></p>
<p>这个在二十年前,阿笠博士就已经做得很成功了啦</p>
<p>那只是过去,阿笠博士在做这个 Voice Conversion
的时候啊,我们需要成对的声音讯号,也就是假设你要把 A 的声音转成 B
的声音,你必须把 A 跟 B 都找来,叫他唸一模一样的句子。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615190330572.png" alt="image-20220615190330572" style="zoom:67%;"></p>
<p>就 A 说好 How are you,B 也说好 How are you,A 说 Good morning,B 也说
Good morning,他们两个各说一样的句子,说个 1000 句,接下来呢,就结束了,就是
<strong>Supervised Learning 的问题</strong>啊,你有成对的资料,Train 一个
Supervised 的 Model,把 A 的声音丢进去,输出就变成 B 的声音,就结束了。</p>
<p>但是如果 A 跟 B 都需要唸一模一样的句子,念个 500 1000
句,显然是不切实际的,举例来说,假设我想要把我的声音转成新垣结衣的声音,我得把新垣结衣找来,更退一万步说,假设我真的把新垣结衣找来,她也不会说中文啊,所以她没有办法跟我唸一模一样的句子</p>
<p>而今天有了 Feature Disentangle
的技术以后,也许我们期待机器可以做到,<strong>就给它 A 的声音 给它 B
的声音,A 跟 B
不需要唸同样的句子,甚至不需要讲同样的语言,机器也有可能学会把 A
的声音转成 B 的声音</strong></p>
<p>那实际上是怎么做的呢,假设我们收集到一大堆人类的声音讯号,然后拿这堆声音讯号呢,去
Train 一个 Aauto-Encoder,同时我们又做了 Feature Disentangle
的技术,所以我们<strong>知道在 Encoder
的输出里面,哪些维度代表了语音的内容,哪些维度代表了语者的特徵</strong>。接下来,我们就可以<strong>把两句话,声音跟内容的部分互换</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191019338.png" alt="image-20220615191019338" style="zoom: 67%;"></p>
<p>举例来说,这边是我的声音,我说 How are you,丢进 Encoder
以后,那你就可以抽出,你就知道说这个 Encoder 里面,<strong>某些维度代表 How
are you 的内容,某些维度代表我的声音</strong>。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191033830.png" alt="image-20220615191033830" style="zoom:67%;"></p>
<p>今天你把这个你老婆的声音丢进
Encoder,它就知道某一些维度,代表你老婆说的话的内容,某一些维度,代表你老婆声音的特徵,接下来我们只要<strong>把我说话的内容的部分取出来</strong>,<strong>把你老婆说话的声音特徵的部分取出来,把它拼起来</strong>,丢到
Decoder
里面,就可以用<strong>你老婆的声音,讲我说的话的内容</strong>。</p>
<p>这件事情真的有可能办到吗,以下是真正的例子,听起来像是这个样子,Do you
want to study a PhD,这个是我的声音，那把我的声音丢到 Encoder
里面以后呢,你可以想像说在 Encoder
里面,我们知道哪些维度代表了念博班这件事,哪些维度代表了我的声音。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191448638.png" alt="image-20220615191448638" style="zoom: 67%;"></p>
<p>那为了简化起见,它输出 100 维的向量,前 50 维代表内容,后 50
维代表说话人的特徵,好 接下来这句话是你老婆说的,仕事忙しいのがな,不知道
不太确定在说什么,就是日文啊</p>
<p>接下来呢,就把我的声音的前 50
维,代表内容的部分取出来,把你老婆的,把你老婆的声音丢进 Encoder 以后,后 50
维的部分抽出来,拼起来,一样是一个 100 维的向量,丢到 Decoder
里面,看看输出来的声音,是不是就是你老婆叫你念博班的声音,听起来像是这个样子,Do
you want to study a PhD</p>
<p>那其实反过来也可以啦,就是换成把日文的部分拿出来,把我的声音的特徵拿出来,一样串成一个
100 维的向量,丢到 Decoder
里面,它听起来就会变成这样,仕事忙しいのがな,我也不知道自己在说什么就是了</p>
<p>所以确实用 Feature Disentangle,你有机会做到 Voice
Conversion,那其实在影像上,在 NLP
上,也都可以有类似的应用,所以可以想想看,Feature Disentangle
可以做什么样的事情</p>
<h3><span id="32-discrete-latentrepresentation">3.2 Discrete Latent
Representation</span></h3>
<p>下一个要跟大家讲的应用,叫做 Discrete Latent
Representation。到目前为止我们都假设这个
Embedding,它就是一个向量,这样就是一串数字,它是 Real
Numbers,那它可不可以是别的东西呢？</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191527797.png" alt="image-20220615191527797" style="zoom:67%;"></p>
<ul>
<li>举例来说,它可不可以是 Binary,Binary
的好处也许是说,每一个维度,它就代表了某种特徵的有或者是没有,举例来说,输入的这张图片,如果是女生,可能第一维就是
1,男生第一维就是 0,如果有戴眼镜,就是第三维 1,没有戴眼镜 就是第三维是
0,也许我们把这个向量,这个 Embedding 变成 Binary,变成只有 0 跟 1
的数字,可以让我们再解释 Encoder 输出的时候,更为容易</li>
<li>甚至有没有可能这个向量,强迫它一定要是 One-Hot 呢,也就只有一维是
1,其他就是 0,如果我们强迫它是
One-Hot,也就是每一个东西图片丢进去,你只可以有,你的 Embedding
里面只可以有一维是 1,其他都是 0
的话,那可以做到什么样的效果呢,也许可以做到 unSupervised
的分类,举例来说,假设你有一大堆的,假设你想要做那个手写数字辨识,你有 0 到
9 的图片,你把 0 到 9 的图片统统收集起来,Train 一个这样子的
Aauto-Encoder,然后强迫中间的 Latent Representation,强迫中间的这个 Code
啊,一定要是 One-Hot Vector,那你这个 Code 正好设个 10 维,也许每一个
One-Hot 的 Code,所以这 10 维,就有 10 种可能的 One-Hot 的 Code,也许每一种
One-Hot 的 Code,正好就对应到一个数字也说不定,所以今天如果用 One-Hot 的
Vector,来当做你的 Embedding 的话,也许就可以做到完全在没有,完全没有Llabel
Data 的情况下,让机器自动学会分类。</li>
</ul>
<p>其实还有其他,在这种啊 Discrete 的 Representation
的这个,技术里面啊,其中最知名的就是 ==VQVAE==,Vector Quantized
Variational Aauto-Encoder,VQVAE
啊,是这样子运作的,就是你输入一张图片,Encoder 呢
输出一个向量,这个向量它是一般的向量,它是 Continuous 的,但接下来你有一个
==Codebook==。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191635308.png" alt="image-20220615191635308" style="zoom:67%;"></p>
<p>所谓 Codebook 的意思就是,你有一排向量,这排向量也是 Learn 出来的,你把
Encoder
的输出,去跟这排向量都去算个<strong>相似度</strong>,那你发现这件事情啊,其实跟
Self-attention 有点像,上面这个 Vector 就是 Query,下面这些 Vector 就是
Key,那接下来呢就看这些 Vector
里面,谁的<strong>相似度最大</strong>,那你把相似度最大的那个 Vector
拿出来。==【类似self-attention】==</p>
<p>这边就是那个,这个 Key 跟那个 Value,是等于是共用同一个 Vector。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615191720041.png" alt="image-20220615191720041" style="zoom:67%;"></p>
<p>如果你把这整个 Process,用 Self-attention 来比喻的话,那就等于是 Key 跟
Value 是共同的 Vector,然后把这个 Vector 呢,丢到 Decoder
里面,然后要它输出一张图片,然后接下来 Training
的时候,就是要让输入跟输出越接近越好</p>
<p>这一个 Decoder,这个 Encoder,这一个
Codebook,都是一起从资料里面被学出来的,这样做的好处就是你就可以,你就有
Discrete 的这个 Latent Representation,也就是说这边 Decoder
的输入,一定是这边这个 Codebook,里面的向量的其中一个,假设你 Codebook
里面有 32 个向量,那你 Decoder 的输入,就只有 32
种可能,你等于就是让你的这个
Embedding,它是离散的,它没有无穷无尽的可能,它只有 32 种可能而已</p>
<p>那其实像这样子的技术啊,如果你拿它
把它用在语音上,你就是一段声音讯号输进来,通过 Encoder
以后产生一个向量,接下来呢,你去计算这个相似度,把最像的那个向量拿出来丢给
Decoder,再输出一样的声音讯号,这个时候你会发现说你的 Codebook
啊,可能可以学到最基本的发音部位</p>
<p>举例来说 你的,这个最基本的发音单位啊,又叫做
==Phonetic==,那如果你不知道 Phonetic 是什么的话,你就把它想成是 KK
音标,那你就会发现说,这个 Codebook 里面每一个
Vector,它就对应到某一个发音,就对应到 KK 音标里面的某一个符号,这个是
VQVAE。</p>
<h3><span id="33-anomalydetection"><strong><font color="red"> 3.3 Anomaly
Detection </font></strong></span></h3>
<p>那接下来,就是我们在作业里面要使用的技术,在作业里面我们会拿
Aauto-Encoder,来做 Anomaly 的
Detection,那我在规划作业的时候,其实就是想要 Aauto-Encoder 出一个作业,那
Aauto-Encoder 的技术很多,那最后我决定做 Anomaly 的
Detection，因为这个是你在非常多的场合,都有机会应用到的一个技术。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615194339007.png" alt="image-20220615194339007" style="zoom:67%;"></p>
<p>Anomaly 的 Detection ,假设你有一堆的训练资料,这边用 X1 到 XN
来表示我们的训练资料,而 Anomaly
Detection,它的中文通常翻译成异常检测。</p>
<p><strong><font color="red">
异常检测要做的事情就是,来了一笔新的资料,它到底跟我们之前在训练资料里面看过的资料,相不相似呢？</font></strong>也就是说你需要找出,你需要有一个异常检测的系统,这个异常检测的系统,是透过大量你已经看过的资料训练出来的。</p>
<ul>
<li>给它一笔新的资料,如果这笔新的资料,看起来像是训练资料里面的
Data,就说它是正常的</li>
<li>如果看起来不像是训练资料里面的 Data,就说它是异常的</li>
</ul>
<p>那其实 Anomaly,Anomaly
这个词啊,有很多不同的其他的称呼,比如说有时候你会叫它
<strong>Outlier</strong>,有时候你会叫它 Novelty,有时候你会叫它
Exceptions,但其实指的都是同样的事情,你就是要看某一笔新的资料,它跟之前看过的资料到底相不相似,但是所谓的<strong>相似这件事啊,其实并没有非常明确的定义</strong>,它是见仁见智的,会根据你的应用情境而有所不同。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615194546961.png" alt="image-20220615194546961" style="zoom:67%;"></p>
<p>举例来说</p>
<ul>
<li>假设现在你的训练资料这个都是雷丘,那这个皮卡丘就算是异常的东西</li>
<li>但是假设你的训练资料里面,你所有的动物都是皮卡丘,那雷丘就是异常的东西,所以我们并不会说,某一个东西它一定就是
Normal,一定就是
Anomaly,我们不会说某个东西它一定是正常或异常,它<strong>是正常或异常,取决于你的训练资料长什么样子</strong></li>
<li>或者是说假设你的训练资料里面,通通都是宝可梦,那雷丘跟皮卡丘通通都算是正常的,而可能数码宝贝,亚古兽知道吗,这应该是亚古兽
对不对,亚古兽算是异常的</li>
</ul>
<h4><span id="那个这个异常检测有什么样的应用呢">那个这个异常检测有什么样的应用呢？</span></h4>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615194611806.png" alt="image-20220615194611806" style="zoom:67%;"></p>
<ul>
<li>举例来说,它可以来做<strong>诈欺侦测</strong>,假设你的训练资料里面,有一大堆信用卡的交易纪录,那我们可以想像说,多数信用卡的交易都是正常的,那你拿这些正常的信用卡训练的交易纪录,来训练一个异常检测的模型,那有一笔新的交易纪录进来,你就可以让机器帮你判断说,这笔纪录算是正常的
还是异常的,所以这种异常检测的技术,可以拿来做诈欺侦测。</li>
<li>或者是它可以拿来做网路的这个<strong>侵入侦测</strong>,举例来说,你有很多连线的纪录资料,那你相信多数人连到你的网站的时候,他的行为都是正常的,多数人都是好人,你收集到一大堆正常的连线的纪录,那接下来有一笔新的连线进来,你可以根据过去正常的连线,训练出一个异常检测的模型,看看新的连线,它是正常的连线
还是异常的连线,它是有攻击性的
还是正常的连线,或者是它在医学上也可能有应用,你收集到一大堆正常细胞的资料,拿来训练一个异常检测的模型,那也许看到一个新的细胞,它可以知道这个细胞有没有突变,也许有突变,它就是一个癌细胞等等。</li>
</ul>
<p>那讲到这边有人可能会想说,Anomaly Detection
异常检测的问题,我们能不能够把它当做<strong>二元分类</strong>的问题来看啊？</p>
<figure>
<img src="../../../../../Library/Application%20Support/typora-user-images/image-20220615194724455.png" alt="image-20220615194724455">
<figcaption aria-hidden="true">image-20220615194724455</figcaption>
</figure>
<p>你说你要做诈欺侦测,你就收集一大堆正常的信用卡纪录,一堆诈欺的信用卡纪录,训练一个
Binary 的
Classifier,就结束啦,就这样子不是吗？比较<strong>难点就是你要收资料</strong>。</p>
<p>这种异常检测的问题它的难点,正在就在收资料上面,通常你<strong>比较有办法收集到正常的资料,你比较不容易收集到异常的资料</strong>,你可能有一大堆信用卡交易的纪录,但是多数信用卡交易的纪录可能都是正常的,异常的资料相较于正常的资料,可能非常地少,甚至有一些异常的资料混在正常的里面,你也不太可,你可能也完全没有办法侦测出来,所以在这一种异常检测的问题里面。</p>
<p><strong><font color="red">
我们往往假设,我们有一大堆正常的资料,但我们几乎没有异常的资料,所以它不是一个一般的分类的问题,这种分类的问题又叫做
==One Class
的分类问题==。</font></strong>就是我们只有一个类别的资料,那你怎么训练一个模型,因为你想你要训练一个分类器,你得有两个类别的资料,你才能训练分类器啊,如果只有一个类别的资料,那我们可以训练什么东西,这个时候就是
Aauto-Encoder,可以派得上用场的时候了。</p>
<p>举例来说,假设我们现在想要做一个系统,这个系统是要侦测说一张图片：</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615194856711.png" alt="image-20220615194856711" style="zoom:67%;"></p>
<p>举例来说,它是不是真人的人脸,那你可以找到一大堆图片,它都是真正的人脸,那我们就拿这些真人的人脸,来训练一个
Aauto-Encoder。这个是你老婆的照片,那你可以拿它来训练一个
Aauto-Encoder,那你训练完这个 Aauto-Encoder
以后,在测试的时候,如果进来的也是你老婆的照片,那因为在训练的时候有看过这样的照片,所以它可以顺利地被还原回来。</p>
<p>你可以计算这一张照片通过 Encoder,再通过 Decoder
以后,它的变化有多大,你可以去<strong>计算这个输入的照片,跟这个输出的照片,它们的差异有多大</strong>,如果差异很小,你的
Decoder
可以顺利地还原原来的照片,代表这样类型的照片,是在训练的时候有看过的,不过反过来说,假设有一张照片是训练的时候没有看过的。</p>
<p><img src="../../../../../Library/Application Support/typora-user-images/image-20220615195012966.png" alt="image-20220615195012966" style="zoom:67%;"></p>
<p>她是那个凉宫春日,但是她不是真人,她是一个动画的人物,她是二次元的人物,一个二次元人物的照片,输入
Encoder 再输出 Decoder
以后,因为这是没有看过的东西,这是训练的时候没有看过的照片,那你的
Decoder,就很难把它还原回来,<strong>如果你计算输入跟输出的差异,发现差异非常地大</strong>,那就代表说,现在输入给
Encoder
的这张照片,可能是一个异常的状况,可能是训练的时候没有看过的状况,所以你就可以<strong>看
reconstruction 的 loss</strong>,这个 reconstruction
的好坏,来决定说你现在在测试的时候,看到这张照片,是不是训练的时候有看过同类型的照片。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/12/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><span class="page-number current">13</span><a class="page-number" href="/page/14/">14</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/14/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lzy</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>-->
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("03/01/2023 10:00:00"); //此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒.";
    }
setInterval("createtime()",250);
</script>

    </div>
  </footer>

  

  <a href="https://github.com/PowerLZY" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.4.3/mermaid.min.js","integrity":"sha256-e0o3JYsdjqKajf9eOe22FhioYSz9WofRY4dLKo3F6do="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>




        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        const hasAttr = (e,a) => a.some(_=> e.attr(_)!==undefined);
        $('a').each(function() {
          const $this = $(this);
          if(hasAttr($this,["data-fancybox","ignore-external-link"])) return;
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'powerlzy.github.io' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script></body>
</html>
