<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"powerlzy.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="相比到达的地方，同行的人更重要！">
<meta property="og:type" content="website">
<meta property="og:title" content="PowerLZY&#39;s Blog">
<meta property="og:url" content="https://powerlzy.github.io/page/12/index.html">
<meta property="og:site_name" content="PowerLZY&#39;s Blog">
<meta property="og:description" content="相比到达的地方，同行的人更重要！">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="lzy">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://powerlzy.github.io/page/12/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/12/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>PowerLZY's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">PowerLZY's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">本博客主要用于记录个人学习笔记（测试阶段）</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="lzy"
      src="/images/cat_mac.jpg">
  <p class="site-author-name" itemprop="name">lzy</p>
  <div class="site-description" itemprop="description">相比到达的地方，同行的人更重要！</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">121</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/PowerLZY" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;PowerLZY" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:3289218653@qq.com" title="E-Mail → mailto:3289218653@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/YFRZTY/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/YFRZTY/" class="post-title-link" itemprop="url">机器学习（11）LGB*</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-03-11 21:13:30" itemprop="dateCreated datePublished" datetime="2022-03-11T21:13:30+08:00">2022-03-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-01-29 16:27:31" itemprop="dateModified" datetime="2023-01-29T16:27:31+08:00">2023-01-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">集成学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>11k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>20 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="参考链接">参考链接</span></h2>
<ul>
<li><p><strong>XGBoost官方文档</strong>：https://xgboost.readthedocs.io/en/latest/index.html</p></li>
<li><p>LightGBM算法梳理：https://zhuanlan.zhihu.com/p/78293497</p></li>
<li><p>详解LightGBM两大利器：基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）：https://zhuanlan.zhihu.com/p/366234433</p></li>
<li><p>【机器学习】决策树（下）——XGBoost、LightGBM（非常详细）：https://zhuanlan.zhihu.com/p/87885678</p></li>
<li><p>xgboost面试题整理:
https://xiaomindog.github.io/2021/06/22/xgb-qa/</p></li>
</ul>
<h2><span id="机器学习决策树下xgboost-lightgbm">【机器学习】决策树（下）——XGBoost、LightGBM</span></h2>
<figure>
<img src="https://pic2.zhimg.com/80/v2-358e4bfce928d0460bd5e8b4cab8f715_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Boosting 算法</th>
<th>GBDT</th>
<th>XGBoost</th>
<th>LightGBM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>思想</strong><img src="image-20220315210756470.png" alt="image-20220315210756470" style="zoom:25%;"></td>
<td>回归树、梯度迭代、缩减（Shrinkage）;<strong>GBDT
的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于
0</strong></td>
<td><strong>二阶导数、线性分类器、正则化</strong>、缩减、<strong>列抽样、并行化</strong></td>
<td><strong>更快的训练速度和更低的内存使用</strong></td>
</tr>
<tr class="even">
<td>目标函数</td>
<td><img src="image-20220315213233284.png" alt="image-20220315213233284" style="zoom: 25%;"></td>
<td><img src="image-20220315213503054.png" alt="image-20220315213503054" style="zoom: 67%;"><img src="image-20220315213608526.png" alt="image-20220315213608526" style="zoom: 33%;"></td>
<td>同上</td>
</tr>
<tr class="odd">
<td>损失函数</td>
<td>最小均方损失函数、<strong>绝对损失或者 Huber 损失函数</strong></td>
<td>【线性】最小均方损失函数、==sigmod和softmax==</td>
<td><strong>复杂度模型</strong>：<img src="image-20220315215849417.png" alt="image-20220315215849417" style="zoom: 25%;"></td>
</tr>
<tr class="even">
<td>基模型</td>
<td>CART模型</td>
<td>CART模型/ ==回归模型==</td>
<td>CART模型/ ==回归模型==</td>
</tr>
<tr class="odd">
<td>抽样算法</td>
<td>无</td>
<td><strong>列抽样</strong>：借鉴了<strong>随机森林</strong>的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</td>
<td><strong>单边梯度抽样算法；</strong>根据样本梯度来对梯度小的这边样本进行采样，一部分大梯度和随机分布</td>
</tr>
<tr class="even">
<td><strong>切分点算法</strong></td>
<td>CART模型</td>
<td><strong>预排序</strong>、<strong>贪心算法</strong>、<strong>近似算法（</strong>加权分位数缩略图<strong>）</strong></td>
<td><strong>直方图算法</strong>：内存消耗降低，计算代价减少；（不需要记录特征到样本的索引）</td>
</tr>
<tr class="odd">
<td><strong>缺失值算法</strong></td>
<td>CART模型</td>
<td><strong>稀疏感知算法</strong>：选择增益最大的枚举项即为最优<strong>缺省方向</strong>。【<strong><font color="red">
稀疏数据优化不足</font></strong>】【<strong>gblinear 补0</strong>】</td>
<td><strong>互斥特征捆绑算法</strong>：<strong>互斥</strong>指的是一些特征很少同时出现非0值。<strong>稀疏感知算法</strong>；【<strong>gblinear
补0</strong>】</td>
</tr>
<tr class="even">
<td><strong>建树策略</strong></td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Leaf-wise</strong>：每次分裂增益最大的叶子节点，直到达到停止条件。</td>
</tr>
<tr class="odd">
<td><strong>正则化</strong></td>
<td>无</td>
<td>L1 和 L2 正则化项</td>
<td>L1 和 L2 正则化项</td>
</tr>
<tr class="even">
<td><strong>Shrinkage（缩减）</strong></td>
<td>有</td>
<td>有</td>
<td>有</td>
</tr>
<tr class="odd">
<td>类别特征优化</td>
<td>无</td>
<td>无</td>
<td><strong>类别特征最优分割</strong>：<strong>many-vs-many</strong></td>
</tr>
<tr class="even">
<td>并行化设计</td>
<td>无</td>
<td><strong>块结构设计</strong>、</td>
<td><strong>特征并行</strong>、
<strong>数据并行</strong>、<strong>投票并行</strong></td>
</tr>
<tr class="odd">
<td>==缓存优化==</td>
<td>无</td>
<td>为每个线程分配一个连续的缓存区、<strong>“核外”块计算</strong></td>
<td>1、所有的特征都采用相同的方法获得梯度；2、其次，因为不需要存储特征到样本的索引，降低了存储消耗</td>
</tr>
<tr class="even">
<td><strong>缺点</strong></td>
<td>对异常点敏感；</td>
<td><strong>预排序</strong>：仍需要遍历数据集；==不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引，相当于消耗了两倍的内存。==</td>
<td><strong>内存更小</strong>： 索引值、特征值边bin、互斥特征捆绑;
<strong>速度更快</strong>：遍历直方图；单边梯度算法过滤掉梯度小的样本；基于
Leaf-wise
算法的增长策略构建树，减少了很多不必要的计算量；特征并行、数据并行方法加速计算</td>
</tr>
</tbody>
</table>
<h2><span id="一-lightgbm">一、LightGBM</span></h2>
<blockquote>
<ul>
<li>《<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=Lightgbm%3A+A+highly+efficient+gradient+boosting+decision+tree&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22165627712%22%7D">Lightgbm:
A highly efficient gradient boosting decision tree</a>》</li>
<li>《A communication-efficient <a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=parallel+algorithm+for+decision+tree&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22165627712%22%7D">parallel
algorithm for decision tree</a>》</li>
</ul>
</blockquote>
<p>LightGBM 由微软提出，主要用于解决 GDBT
在海量数据中遇到的问题，以便其可以更好更快地用于工业实践中。从 LightGBM
名字我们可以看出其是轻量级（Light）的梯度提升机（GBM），其相对 XGBoost
具有<strong>训练速度快、内存占用低</strong>的特点。下图分别显示了
XGBoost、XGBoost_hist（利用梯度直方图的 XGBoost） 和 LightGBM
三者之间针对不同数据集情况下的内存和训练时间的对比：</p>
<figure>
<img src="https://pic1.zhimg.com/80/v2-e015e3c4018f44787d74a47c9e0cd040_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>那么 LightGBM
到底如何做到<strong>更快的训练速度和更低的内存</strong>使用的呢？</p>
<h4><span id="lightgbm-为了解决这些问题提出了以下几点解决方案"><strong><font color="red">
LightGBM 为了解决这些问题提出了以下几点解决方案：</font></strong></span></h4>
<ol type="1">
<li><p><strong>【减小内存、最优分类点】直方图算法</strong>；【特征离散化
+ 内存占用 + 方差减少】</p></li>
<li><p><strong>【样本维度】
单边梯度抽样算法</strong>；【<strong>根据样本梯度来对梯度小的这边样本进行采样</strong>，一部分大梯度和随机分布】</p>
<blockquote>
<p><strong>一方面算法将更多的注意力放在训练不足的样本上，另一方面通过乘上权重来防止采样对原始数据分布造成太大的影响。</strong></p>
</blockquote></li>
<li><p><strong>【特征维度】互斥特征捆绑算法</strong>；【特征稀疏行优化
+分箱 】</p></li>
<li><p><strong>【分裂算法】基于最大深度的 Leaf-wise
的垂直生长算法</strong>；【深度限制的最大分裂收益的叶子】</p></li>
<li><p><strong>类别特征最优分割</strong>；</p></li>
<li><p><strong>特征并行和数据并行</strong>；</p></li>
<li><p><strong>缓存优化。</strong></p></li>
</ol>
<h3><span id="11-数学原理">1.1 数学原理</span></h3>
<h3><span id="111-直方图算法"><strong>1.1.1 直方图算法</strong></span></h3>
<h4><span id="1-直方图算法"><strong>(1) 直方图算法</strong></span></h4>
<p><strong><font color="red"> 直方图算法的基本思想是将连续的特征离散化为
k （默认256 1字节）个离散特征，同时构造一个宽度为 k
的直方图用于统计信息（含有 k 个
bin）。利用直方图算法我们无需遍历数据，只需要遍历 k 个 bin
即可找到最佳分裂点。</font></strong></p>
<p>我们知道特征离散化的具有很多优点，如存储方便、运算更快、鲁棒性强、模型更加稳定等等。对于直方图算法来说最直接的有以下两个优点（以
k=256 为例）：</p>
<ul>
<li><strong>内存占用更小：</strong>XGBoost 需要用 <strong>32
位的浮点数去存储特征值，并用 32 位的整形去存储排序索引</strong>，而
LightGBM 只需要用 8 位去存储直方图，<strong>相当于减少了
1/8</strong>；</li>
<li><strong>计算代价更小：</strong>计算特征分裂增益时，XGBoost
需要遍历一次数据找到最佳分裂点，而 LightGBM 只需要遍历一次 k
次，直接将时间复杂度从代价是O( feature *
<strong>distinct_values_of_the_feature</strong>); 而 histogram
只需要计算 bins次, 代价是( feature *
<strong>bins</strong>)。<strong>distinct_values_of_the_feature &gt;&gt;
bins</strong></li>
</ul>
<figure>
<img src="image-20220625171413733.png" alt="image-20220625171413733">
<figcaption aria-hidden="true">image-20220625171413733</figcaption>
</figure>
<ol type="1">
<li><strong>直方图优化算法需要在训练前预先把特征值转化为bin
value</strong>，也就是对每个特征的取值做个分段函数，将所有样本在该特征上的取值划分到某一段（bin）中。最终把特征取值从连续值转化成了离散值。需要注意得是：feature
value对应的bin value在整个训练过程中是不会改变的。</li>
<li><strong>最外面的 for
循环表示的意思是对当前模型下所有的叶子节点处理</strong>，需要遍历所有的特征，来找到增益最大的特征及其划分值，以此来分裂该叶子节点。</li>
<li>在某个叶子上，第二个 for
循环就开始遍历所有的特征了。<strong>对于每个特征，首先为其创建一个直方图
(new Histogram()
)</strong>。这个直方图存储了两类信息，分别是<strong><font color="red">
每个bin中样本的梯度之和 <span class="math inline">\(H[ f.bins[i]
].g\)</span>
</font></strong>，还有就是<strong>每个bin中样本数量</strong><span class="math inline">\(（H[f.bins[i]].n）\)</span></li>
<li>第三个 for
循环遍历所有样本，累积上述的两类统计值到样本所属的bin中。即直方图的每个
bin 中包含了一定的样本，在此计算每个 bin 中的样本的梯度之和并对 bin
中的样本记数。</li>
<li>最后一个for循环, 遍历所有bin, 分别以当前bin作为分割点,
累加其左边的bin至当前bin的梯度和（ <span class="math inline">\(\left.S_{L}\right)\)</span> 以及样本数量 <span class="math inline">\(\left(n_{L}\right)\)</span>,
并与父节点上的总梯度和 <span class="math inline">\(\left(S_{p}\right)\)</span> 以及总样本数量 <span class="math inline">\(\left(n_{p}\right)\)</span> 相减, 得到右边
所有bin的梯度和 <span class="math inline">\(\left(S_{R}\right)\)</span>
以及样本数量 <span class="math inline">\(\left(n_{R}\right)\)</span>,
带入公式, 计算出增益, 在遍历过程中取最大的增 益,
以此时的特征和bin的特征值作为分裂节点的特征和分裂特征取值。</li>
</ol>
<h4><span id="2-源码分析">(2) 源码分析</span></h4>
<blockquote>
<p>https://blog.csdn.net/anshuai_aw1/article/details/83040541</p>
<p><strong><font color="red">
『我爱机器学习』集成学习（四）LightGBM</font></strong>：https://www.hrwhisper.me/machine-learning-lightgbm/</p>
</blockquote>
<p>问题一：<strong>如何将特征映射到bin呢？即如何分桶？对于连续特征和类别特征分别怎么样处理？</strong></p>
<p>问题二：<strong>如何构建直方图？直方图算法累加的g是什么？难道没有二阶导数h吗？</strong></p>
<h4><span id="特征分桶">特征分桶：</span></h4>
<blockquote>
<p><strong>特征分桶的源码</strong>在<strong>bin.cpp</strong>文件和<strong>bin.h</strong>文件中。由于LGBM可以处理类别特征，因此对连续特征和类别特征的处理方式是不一样的。</p>
</blockquote>
<h4><span id="连续特征">连续特征:</span></h4>
<p>在<strong>bin.cpp</strong>中，我们可以看到<strong>GreedyFindBin</strong>函数和<strong>FindBinWithZeroAsOneBin</strong>函数，这两个函数得到了数值型特征取值（负数，0，正数）的各个bin的切分点，即bin_upper_bound。</p>
<h4><span id="greedyfindbin数值型根据特征不同取值的个数划分类别型">GreedyFindBin:
数值型根据特征不同取值的个数划分，类别型？？</span></h4>
<ul>
<li><em>特征取值计数的数组</em>、<em>特征的不同的取值的数组</em>、<em>特征有多少个不同的取值</em></li>
<li><strong>bin_upper_bound就是记录桶分界的数组</strong></li>
<li>特征取值数比max_bin数量少，直接取distinct_values的中点放置</li>
<li>特征取值数比max_bin来得大，说明几个特征值要共用一个bin
<ul>
<li>如果一个特征值的数目比mean_bin_size大，那么这些特征需要单独一个bin</li>
<li>剩下的特征取值的样本数平均每个剩下的bin：mean size for one bin</li>
</ul></li>
</ul>
<h4><span id="构建直方图">构建直方图：</span></h4>
<p>给定一个特征的值，我们现在已经可以转化为对应的bin了。现在我们就可以构建直方图了。</p>
<h4><span id="constructhistogram"><strong>ConstructHistogram</strong>：</span></h4>
<ul>
<li><strong>累加了一阶、二阶梯度和还有==个数==</strong></li>
<li>当然还有其它的版本，当is_constant_hessianis_constant_hessian为true的时候是不用二阶梯度的</li>
</ul>
<h4><span id="寻找最优切分点-缺失值处理-gain和xgb一样">寻找最优切分点 :
缺失值处理 + Gain和XGB一样</span></h4>
<h4><span id="3直方图算法优点"><strong><font color="red">
（3）直方图算法优点：</font></strong></span></h4>
<ul>
<li><p><strong>内存消耗降低</strong>。预排序算法需要的内存约是训练数据的两倍（2x样本数x维度x4Bytes），它需要用32位浮点来保存特征值，并且对每一列特征，都需要一个额外的排好序的索引，这也需要32位的存储空间。对于
直方图算法，则只需要(1x样本数x维
度x1Bytes)的内存消耗，仅为预排序算法的1/8。因为直方图算法仅需要存储特征的
bin
值(离散化后的数值)，不需要原始的特征值，也不用排序，而bin值用8位整型存储就足够了。</p></li>
<li><p><strong>算法时间复杂度大大降低</strong>。决策树算法在节点分裂时有两个主要操作组成，一个是“寻找分割点”，另一个是“数据分割”。从算法时间复杂度来看，在“寻找分割点”时，预排序算法对于深度为<span class="math inline">\(k\)</span>的树的时间复杂度：对特征所有取值的排序为<span class="math inline">\(O(NlogN)\)</span>，<span class="math inline">\(N\)</span>为样本点数目，若有<span class="math inline">\(D\)</span>维特征，则<span class="math inline">\(O(kDNlogN)\)</span>，而直方图算法需要<span class="math inline">\(O(kD \times bin)\)</span> (bin是histogram
的横轴的数量，一般远小于样本数量<span class="math inline">\(N\)</span>)。</p></li>
<li><p><strong>直方图算法还可以进一步加速</strong>【<strong>==两个维度==</strong>】。一个容易观察到的现象：<strong>一个叶子节点的直方图可以直接由父节点的直方图和兄弟节点的直方图做差得到（分裂时左右集合）</strong>。通常构造直方图，需要遍历该叶子上的所有数据，但直方图做差仅需遍历直方图的<span class="math inline">\(k\)</span>个bin。利用这个方法，LightGBM可以在构造一个叶子的直方图后，可以用非常微小的代价得到它兄弟叶子的直方图，在速度上可以提升一倍。</p>
<p><img src="https://pic1.zhimg.com/80/v2-86919e4fc187a11fe3fdb72780709c98_1440w.jpg" alt="img" style="zoom:67%;"></p></li>
<li><p><strong>缓存优化</strong>：上边说到 XGBoost
的预排序后的特征是通过索引给出的样本梯度的统计值，因其索引访问的结果并不连续，XGBoost
提出缓存访问优化算法进行改进。<strong><font color="red"> LightGBM
所使用直方图算法对 Cache
天生友好所有的特征都采用相同的方法获得梯度，构建直方图时bins字典同步记录一阶导、二阶导和个数，大大提高了缓存命中</font></strong>；因为<strong>不需要存储特征到样本的索引</strong>，降低了存储消耗，而且也不存在
Cache Miss的问题。</p></li>
<li><p><strong>数据并行优化</strong>，用 histgoram
可以大幅降低通信代价。用 pre-sorted
算法的话，通信代价是非常大的（几乎是没办法用的）。所以 xgoobst
在并行的时候也使用 histogram 进行通信。</p></li>
</ul>
<h4><span id="4直方图算法缺点">（4）直方图算法缺点：</span></h4>
<p><strong>当然，直方图算法并不是完美的。由于特征被离散化后，找到的并不是很精确的分割点，所以会对结果产生影响。</strong>但在不同的数据集上的结果表明，离散化的分割点对最终的精度影响并不是很大，甚至有时候会更好一点。原因是决策树本来就是弱模型，分割点是不是精确并不是太重要；<strong>较粗的分割点也有正则化的效果，可以有效地防止过拟合</strong>；即使单棵树的训练误差比精确分割的算法稍大，但在梯度提升（GradientBoosting）的框架下没有太大的影响。</p>
<h3><span id="112-单边梯度抽样算法"><strong>1.1.2 单边梯度抽样算法</strong></span></h3>
<p><font color="red">
<strong>直方图算法仍有优化的空间</strong>，建立直方图的复杂度为O(<strong>feature
×
data</strong>)，如果能<strong>降低特征数</strong>或者<strong>降低样本数</strong>，训练的时间会大大减少。</font></p>
<p><strong>GBDT
算法的梯度大小可以反应样本的权重，梯度越小说明模型拟合的越好，单边梯度抽样算法</strong>（Gradient-based
One-Side Sampling,
GOSS）利用这一信息对样本进行抽样，减少了大量梯度小的样本，在接下来的计算锅中只需关注梯度高的样本，极大的减少了计算量。</p>
<ol type="1">
<li>根据<strong>梯度的绝对值</strong>将样本进行<strong>降序</strong>排序</li>
<li>选择前a×100%的样本，这些样本称为A</li>
<li>剩下的数据(1−a)×100的数据中，随机抽取b×100%的数据，这些样本称为B</li>
<li>在计算增益的时候，放大样本B中的梯度 (1−a)/b 倍</li>
<li>关于g，在具体的实现中是一阶梯度和二阶梯度的乘积，见Github的实现（LightGBM/src/boosting/goss.hpp）</li>
</ol>
<blockquote>
<p>a%（大梯度）+ (1-a)/ b * b % 的大梯度</p>
</blockquote>
<p><strong>使用GOSS进行采样,
使得训练算法更加的关注没有充分训练(under-trained)的样本,
并且只会稍微的改变原有的数据分布</strong>。原有的在特征值为 <span class="math inline">\(\mathrm{d}\)</span> 处分数据带来的增益可以定义为：
<span class="math display">\[
V_{j \mid O}(d)=\frac{1}{n_{O}}\left(\frac{\left(\sum_{x_{i} \in O: x_{i
j} \leq d} g_{i}\right)^{2}}{n_{l \mid
O}^{j}(d)}+\frac{\left(\sum_{x_{i} \in O: x_{i j}&gt;d}
g_{i}\right)^{2}}{n_{r \mid O}^{j}(d)}\right)
\]</span> 其中: - O为在决策树待分裂节点的训练集 - <span class="math inline">\(n_{o}=\sum I\left(x_{i} \in O\right)\)</span> -
<span class="math inline">\(n_{l \mid O}^{j}(d)=\sum I\left[x_{i} \in O:
x_{i j} \leq d\right]\)</span> and <span class="math inline">\(n_{r \mid
O}^{j}(d)=\sum I\left[x_{i} \in O: x_{i j}&gt;d\right]\)</span></p>
<p><strong>而使用GOSS后, 增益定义为：</strong> <span class="math display">\[
V_{j \mid O}(d)=\frac{1}{n_{O}}\left(\frac{\left(\sum_{x_{i} \in A_{l}}
g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{l}}
g_{i}\right)^{2}}{n_{l}^{j}(d)}+\frac{\left(\sum_{x_{i} \in A_{r}}
g_{i}+\frac{1-a}{b} \sum_{x_{i} \in B_{l}}
g_{r}\right)^{2}}{n_{r}^{j}(d)}\right)
\]</span> 其中: - <span class="math inline">\(A_{l}=\left\{x_{i} \in A:
x_{i j} \leq d\right\}, A_{r}=\left\{x_{i} \in A: x_{i
j}&gt;d\right\}\)</span> - <span class="math inline">\(B_{l}=\left\{x_{i} \in B: x_{i j} \leq d\right\},
B_{r}=\left\{x_{i} \in B: x_{i j}&gt;d\right\}\)</span></p>
<p>实验表明，该做法并没有降低模型性能，反而还有一定提升。究其原因，应该是采样也会增加弱学习器的多样性，从而潜在地提升了模型的泛化能力，稍微有点像深度学习的dropout。</p>
<h3><span id="113互斥特征捆绑算法冲突小的特征可能与多个特征包组合特征集合"><strong>1.1.3
互斥特征捆绑算法</strong>【冲突小的特征可能与多个特征包组合】[特征集合]</span></h3>
<blockquote>
<p><strong>==互斥==指的是一些特征很少同时出现非0值</strong>【<strong>类似one-hot特征</strong>】</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/366234433">详解LightGBM两大利器：基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）</a></p>
</blockquote>
<p><strong><font color="red"> 互斥特征捆绑算法（Exclusive Feature
Bundling,
EFB）指出如果将一些特征进行合并，则可以降低特征数量。</font></strong>高维特征往往是稀疏的，而且特征间可能是相互排斥的（如两个特征不同时取非零值），如果两个特征并不完全互斥（如只有一部分情况下是不同时取非零值），可以用互斥率表示互斥程度。</p>
<p><strong>1）首先介绍如何判定哪些特征应该捆绑在一起？</strong></p>
<p>EFB算法采用<strong>构图（build
graph）</strong>的思想，将特征作为节点，不互斥的特征之间进行连边，然后从图中找出所有的捆绑特征集合。其实学过数据结构里的图算法就了解过，这个问题基本就是<a href="https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%E5%9B%BE%E7%9D%80%E8%89%B2%E9%97%AE%E9%A2%98/8928655%3Ffr%3Daladdin">图着色问题</a>。但是图着色问题是一个<strong>NP-hard问题</strong>，不可能在多项式时间里找到最优解。</p>
<p>因此<strong>EFB采用了一种近似的贪心策略解决办法。它允许特征之间存在少数的样本点并不互斥</strong>（比如某些对应的样本点之间并不同时为非0），并设置一个最大冲突阈值
<img src="https://www.zhihu.com/equation?tex=K" alt="[公式]">
。我们选择合适的 <img src="https://www.zhihu.com/equation?tex=K" alt="[公式]">
值，可以在准确度和训练效率上获得很好的trade-off（均衡)。</p>
<p>==<strong>下面给出EFB的特征捆绑的贪心策略流程：</strong>==</p>
<blockquote>
<p>（1）将特征作为图的顶点，对于<strong>不互斥的特征进行相连</strong>（存在同时不为0的样本），特征同时不为0的样本个数作为边的权重；
（2）根据顶点的度对特征进行降序排序，度越大表明特征与其他特征的冲突越大（越不太可能与其他特征进行捆绑）；【<strong>入度排序，转化为非零值个数排序</strong>】
（3）设置<strong>最大冲突阈值K</strong>，外层循环先对每一个上述排序好的特征，遍历已有的特征捆绑簇，如果发现该特征加入到该特征簇中的冲突数不会超过最大阈值K，则将该特征加入到该簇中。否则新建一个特征簇，将该特征加入到新建的簇中。</p>
</blockquote>
<p><img src="https://pic4.zhimg.com/80/v2-743681d9fd6cebee11f0dcc607f2f687_1440w.jpg" alt="img" style="zoom: 33%;"></p>
<p>上面时间的复杂度为 <img src="https://www.zhihu.com/equation?tex=O%28n%5E2%29" alt="[公式]">
，n为特征的数量，时间其实主要花费在建图上面，两两特征计算互斥程度的时间较长（2层for循环）。对于百万级别的特征数量来说，该复杂度仍是<strong>不可行的</strong>。==为了提高效率，可以不再构建图，将特征直接按照非零值个数排序，将特征<strong>非零值个数</strong>类比为节点的度（即冲突程度)，因为更多的非零值更容易引起冲突。只是改进了排序策略，不再构建图，下面的for循环是一样的。==</p>
<p><strong>2）如何将特征捆绑簇里面的所有特征捆绑（合并）为一个特征？</strong>【<strong>直方图偏移</strong>】</p>
<p>如何进行合并，最关键的是如何能将原始特征从合并好的特征进行分离出来。EFB采用的是加入一个<strong>偏移常量</strong>（offset）来解决。</p>
<blockquote>
<p>举个例子，我们绑定两个特征A和B，A取值范围为[0, 10)，B取值范围为[0,
20)。则我们可以加入一个偏移常量10，即将B的取值范围变为[10,30），然后合并后的特征范围就是[0,
30)，并且能很好的分离出原始特征~</p>
</blockquote>
<p>因为lgb中<strong>直方图算法</strong>对特征值进行了<strong>分桶</strong>（bin）操作，导致合并互斥特征变得更为简单。从上面伪码看到偏移常量offset直接对每个特征桶的数量累加就行，然后放入偏移常数数组（binRanges）中。</p>
<h3><span id="114-带深度限制的leaf-wise-算法"><strong>1.1.4 带深度限制的
Leaf-wise 算法</strong></span></h3>
<h4><span id="level-wise">Level-wise</span></h4>
<p>大多数GBDT框架使用的按层生长 (level-wise)
的决策树生长策略，Level-wise遍历一次数据可以同时分裂同一层的叶子，容易进行<strong>多线程优化</strong>，也好<strong>控制模型复杂度，不容易过拟合</strong>。但实际上Level-wise是一种低效的算法，因为它不加区分的对待同一层的叶子，带来了很多没必要的开销，因为实际上很多叶子的分裂增益较低，没必要进行搜索和分裂。</p>
<h4><span id="leaf-wise">Leaf-wise</span></h4>
<p>Leaf-wise则是一种更为高效的策略，每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环。因此同Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度。Leaf-wise的缺点是可能会长出比较深的决策树，产生过拟合。因此LightGBM在Leaf-wise之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合。</p>
<figure>
<img src="https://pic2.zhimg.com/80/v2-76f2f27dd24fc452a9a65003e5cdd305_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="115lightgbm类别特征最优分割">==<strong>1.1.5
LightGBM类别特征最优分割</strong>==</span></h3>
<blockquote>
<p>LightGBM中只需要提前将类别映射到非负整数即可(<code>integer-encoded categorical features</code>)</p>
</blockquote>
<p><strong>我们知道，LightGBM可以直接处理类别特征，而不需要对类别特征做额外的one-hot
encoding。那么LGB是如何实现的呢？</strong></p>
<p>类别特征的使用在实践中是很常见的。且为了解决one-hot编码处理类别特征的不足,
LightGBM优化了对类别特征的支持，可以直接输入类别特征，不需要额外的0/1展开。<strong>LightGBM
采用 many-vs-many
的切分方式将类别特征分为两个子集，实现类别特征的最优切分</strong>。假设某维
特征有 k 个类别，则有 <img src="https://www.zhihu.com/equation?tex=2%5E%7B%28k-1%29%7D-1" alt="[公式]"> 种可能, 时间复杂度为 <img src="https://www.zhihu.com/equation?tex=O%5Cleft%282%5E%7Bk%7D%5Cright%29%2C" alt="[公式]"> LightGBM 基于 Fisher的 《<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=On+Grouping+For+Maximum+Homogeneity&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22165627712%22%7D">On
Grouping For Maximum Homogeneity</a>》论文实现了 O(klogk) 的<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=时间复杂度&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22165627712%22%7D">时间复杂度</a>。</p>
<p><strong>算法流程如下图所示</strong>，在枚举分割点之前，先把直方图按照每个类别对应的label均值进行排序;
然后按照排序的结果依次枚举最优分割点。从下图可以看到, <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7BS+u+m%28y%29%7D%7B%5Coperatorname%7BCount%7D%28y%29%7D" alt="[公式]">
为类别的均值。当然，这个方法很容易过拟合，所以LightGBM里面还增加了很多对于这个方法的约束和正则化。</p>
<p><img src="https://pic1.zhimg.com/v2-0f1b7024e9da8f09c75b7f8e436a5d24_b.jpg" alt="img" style="zoom:67%;"></p>
<p><strong>在Expo数据集上的实验结果表明，相比0/1展开的方法，使用LightGBM支持的类别特征可以使训练速度加速8倍，并且精度一致。</strong>更重要的是，LightGBM是第一个直接支持类别特征的GBDT工具。</p>
<h3><span id="12-工程实现-并行计算">1.2 工程实现 - 并行计算</span></h3>
<h3><span id="121-特征并行优化最优划分点"><strong>1.2.1 特征并行</strong>【优化
最优划分点】</span></h3>
<p>传统的特征并行算法在于对数据进行垂直划分，然后使用<strong>不同机器找到不同特征的最优分裂点</strong>，<strong>基于通信整合得到最佳划分点</strong>，然后基于通信告知其他机器划分结果。==在本小节中，<strong>工作的节点称为worker</strong>==</p>
<h4><span id="传统">==<strong>传统：</strong>==</span></h4>
<ul>
<li>垂直划分数据<strong>（对特征划分）</strong>，<strong>不同的worker有不同的特征集</strong></li>
<li>每个workers找到局部最佳的切分点{feature, threshold}</li>
<li>workers使用点对点通信，找到全局最佳切分点</li>
<li><strong>具有全局最佳切分点的worker进行节点分裂，然后广播切分后的结果</strong>（<strong>左右子树的instance
indices</strong>）</li>
<li>其它worker根据收到的instance indices也进行划分</li>
</ul>
<p><img src="https://pic3.zhimg.com/v2-b0d10c5cd832402e4503e2c1220f7376_r.jpg" alt="preview" style="zoom: 67%;"></p>
<p><strong>传统的特征并行方法有个很大的缺点</strong>：</p>
<ul>
<li><strong>需要告知每台机器最终划分结果，增加了额外的复杂度</strong>（因为对数据进行垂直划分，每台机器所含数据不同，划分结果需要通过通信告知）；</li>
<li>无法加速split的过程，该过程复杂度为O(#data)O(#data)，当数据量大的时候效率不高；</li>
</ul>
<h4><span id="lightgbm"><strong>==LightGBM==</strong></span></h4>
<p><strong>LightGBM
则不进行数据垂直划分，每台机器都有训练集完整数据</strong>，在得到最佳划分方案后可在本地执行划分而减少了不必要的通信。</p>
<ul>
<li>每个workers找到局部最佳的切分点{feature, threshold}</li>
<li>workers使用点对点通信，找到全局最佳切分点</li>
<li>每个worker根据全局最佳切分点进行节点分裂</li>
</ul>
<p>缺点：</p>
<ul>
<li>split过程的复杂度仍是O(#data)，当数据量大的时候效率不高</li>
<li><strong>每个worker保存所有数据，存储代价高</strong></li>
</ul>
<h3><span id="122-数据并行"><strong>1.2.2 数据并行</strong></span></h3>
<h4><span id="传统方法">传统方法：</span></h4>
<p>数据并行目标是并行化整个决策学习的过程：</p>
<ul>
<li>水平切分数据，<strong>不同的worker拥有部分数据</strong></li>
<li>每个worker根据本地数据构建局部直方图</li>
<li>合并所有的局部直方图得到全部直方图</li>
<li>根据全局直方图找到最优切分点并进行分裂</li>
</ul>
<figure>
<img src="https://www.hrwhisper.me/images/machine-learning-lightgbm/LightGBM-data-parallelization.png" alt="LightGBM-data-parallelization">
<figcaption aria-hidden="true">LightGBM-data-parallelization</figcaption>
</figure>
<p>在第3步中，有两种合并的方式：</p>
<ul>
<li>采用点对点方式(point-to-point communication
algorithm)进行通讯，每个worker通讯量为O(#machine∗#feature∗#bin)</li>
<li>采用collective communication algorithm(如“<a target="_blank" rel="noopener" href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-collective.html">All
Reduce</a>”)进行通讯（相当于有一个中心节点，通讯后在返回结果），每个worker的通讯量为O(2∗#feature∗#bin)</li>
</ul>
<h4><span id="lightgbm中的数据并行">LightGBM中的数据并行</span></h4>
<ol type="1">
<li><strong>使用“Reduce
Scatter”将不同worker的不同特征的直方图合并，然后workers在局部合并的直方图中找到局部最优划分，最后同步全局最优划分。</strong></li>
<li>前面提到过，可以通过直方图作差法得到兄弟节点的直方图，因此只需要通信一个节点的直方图。</li>
</ol>
<p>传统的数据并行策略主要为水平划分数据，然后本地构建直方图并整合成全局直方图，最后在全局直方图中找出最佳划分点。这种数据划分有一个很大的缺点：通讯开销过大。如果使用点对点通信，一台机器的通讯开销大约为
<img src="https://www.zhihu.com/equation?tex=O%28%5C%23machine+%2A+%5C%23feature+%2A%5C%23bin+%29" alt="[公式]"> ；如果使用集成的通信，则通讯开销为 <img src="https://www.zhihu.com/equation?tex=O%282+%2A+%5C%23feature+%2A%5C%23bin+%29" alt="[公式]"> ，</p>
<p><strong>LightGBM 采用分散规约（Reduce
scatter）的方式将直方图整合的任务分摊到不同机器上，从而降低通信代价，并通过直方图做差进一步降低不同机器间的通信。</strong></p>
<h3><span id="123-投票并行"><strong>1.2.3 投票并行</strong></span></h3>
<p>LightGBM采用一种称为<strong>PV-Tree</strong>的算法进行投票并行(Voting
Parallel)，其实这本质上也是一种<strong>数据并行</strong>。PV-Tree和普通的决策树差不多，只是在寻找最优切分点上有所不同。</p>
<p>其算法伪代码描述如下：</p>
<figure>
<img src="https://www.hrwhisper.me/images/machine-learning-lightgbm/LightGBM-pv-tree.png" alt="LightGBM-pv-tree">
<figcaption aria-hidden="true">LightGBM-pv-tree</figcaption>
</figure>
<ol type="1">
<li>水平切分数据，不同的worker拥有部分数据。</li>
<li>Local voting:
<strong>每个worker构建直方图，找到top-k个最优的本地划分特征</strong></li>
<li>Global voting:
<strong>中心节点聚合得到最优的top-2k个全局划分特征（top-2k是看对各个worker选择特征的个数进行计数，取最多的2k个）</strong></li>
<li><strong>Best Attribute Identification</strong>：
<strong>中心节点向worker收集这top-2k个特征的直方图，并进行合并，然后计算得到全局的最优划分</strong></li>
<li>中心节点将全局最优划分广播给所有的worker，worker进行本地划分。</li>
</ol>
<figure>
<img src="https://www.hrwhisper.me/images/machine-learning-lightgbm/LightGBM-voting-parallelization.png" alt="LightGBM-voting-parallelization">
<figcaption aria-hidden="true">LightGBM-voting-parallelization</figcaption>
</figure>
<p><strong>可以看出，PV-tree将原本需要#feature×#bin#feature×#bin
变为了2k×#bin2k×#bin，通信开销得到降低。此外，可以证明，当每个worker的数据足够多的时候，top-2k个中包含全局最佳切分点的概率非常高。</strong></p>
<h3><span id="124-缓存优化"><strong>1.2.4 缓存优化</strong></span></h3>
<p>上边说到 XGBoost
的预排序后的特征是通过索引给出的样本梯度的统计值，因其索引访问的结果并不连续，XGBoost
提出缓存访问优化算法进行改进。</p>
<p>而 LightGBM 所使用直方图算法对 Cache 天生友好：</p>
<ol type="1">
<li>首先，<strong>所有的特征都采用相同的方法获得梯度</strong>（区别于不同特征通过不同的索引获得梯度），只需要对梯度进行排序并可实现连续访问，大大提高了缓存命中；</li>
<li>其次，因为<strong>不需要存储特征到样本的索引</strong>，降低了存储消耗，而且也不存在
Cache Miss的问题。</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/3HRFFWP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/3HRFFWP/" class="post-title-link" itemprop="url">机器学习（11）XGB*</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-03-11 21:13:30" itemprop="dateCreated datePublished" datetime="2022-03-11T21:13:30+08:00">2022-03-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-03-17 13:58:04" itemprop="dateModified" datetime="2023-03-17T13:58:04+08:00">2023-03-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">集成学习</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>17k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>31 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="参考链接">参考链接</span></h2>
<ul>
<li><p><strong>XGBoost官方文档</strong>：https://xgboost.readthedocs.io/en/latest/index.html</p></li>
<li><p>LightGBM算法梳理：https://zhuanlan.zhihu.com/p/78293497</p></li>
<li><p>详解LightGBM两大利器：基于梯度的单边采样（GOSS）和互斥特征捆绑（EFB）：https://zhuanlan.zhihu.com/p/366234433</p></li>
<li><p>【机器学习】决策树（下）——XGBoost、LightGBM（非常详细）：https://zhuanlan.zhihu.com/p/87885678</p></li>
<li><p>xgboost面试题整理:
https://xiaomindog.github.io/2021/06/22/xgb-qa/</p></li>
</ul>
<h2><span id="机器学习决策树下xgboost-lightgbm">【机器学习】决策树（下）——XGBoost、LightGBM</span></h2>
<figure>
<img src="https://pic2.zhimg.com/80/v2-358e4bfce928d0460bd5e8b4cab8f715_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<table>
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Boosting 算法</th>
<th>GBDT</th>
<th>XGBoost</th>
<th>LightGBM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>思想</strong><img src="image-20220315210756470.png" alt="image-20220315210756470" style="zoom:25%;"></td>
<td>回归树、梯度迭代、缩减（Shrinkage）;<strong>GBDT
的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于
0</strong></td>
<td><strong>二阶导数、线性分类器、正则化</strong>、缩减、<strong>列抽样、并行化</strong></td>
<td><strong>更快的训练速度和更低的内存使用</strong></td>
</tr>
<tr class="even">
<td>目标函数</td>
<td><img src="image-20220315213233284.png" alt="image-20220315213233284" style="zoom: 25%;"></td>
<td><img src="image-20220315213503054.png" alt="image-20220315213503054" style="zoom: 67%;"><img src="image-20220315213608526.png" alt="image-20220315213608526" style="zoom: 33%;"></td>
<td>同上</td>
</tr>
<tr class="odd">
<td>损失函数</td>
<td>最小均方损失函数、<strong>绝对损失或者 Huber 损失函数</strong></td>
<td>【线性】最小均方损失函数、==sigmod和softmax==</td>
<td><strong>复杂度模型</strong>：<img src="image-20220315215849417.png" alt="image-20220315215849417" style="zoom: 25%;"></td>
</tr>
<tr class="even">
<td>基模型</td>
<td>CART模型</td>
<td>CART模型/ ==回归模型==</td>
<td>CART模型/ ==回归模型==</td>
</tr>
<tr class="odd">
<td>抽样算法</td>
<td>无</td>
<td><strong>列抽样</strong>：借鉴了<strong>随机森林</strong>的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</td>
<td><strong>单边梯度抽样算法；</strong>根据样本梯度来对梯度小的这边样本进行采样，一部分大梯度和随机分布</td>
</tr>
<tr class="even">
<td><strong>切分点算法</strong></td>
<td>CART模型</td>
<td><strong>预排序</strong>、<strong>贪心算法</strong>、<strong>近似算法（</strong>加权分位数缩略图<strong>）</strong></td>
<td><strong>直方图算法</strong>：内存消耗降低，计算代价减少；（不需要记录特征到样本的索引）</td>
</tr>
<tr class="odd">
<td><strong>缺失值算法</strong></td>
<td>CART模型</td>
<td><strong>稀疏感知算法</strong>：选择增益最大的枚举项即为最优<strong>缺省方向</strong>。【<strong><font color="red">
稀疏数据优化不足</font></strong>】【<strong>gblinear 补0</strong>】</td>
<td><strong>互斥特征捆绑算法</strong>：<strong>互斥</strong>指的是一些特征很少同时出现非0值。<strong>稀疏感知算法</strong>；【<strong>gblinear
补0</strong>】</td>
</tr>
<tr class="even">
<td><strong>建树策略</strong></td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Level-wise</strong>：基于层进行生长，直到达到停止条件；</td>
<td><strong>Leaf-wise</strong>：每次分裂增益最大的叶子节点，直到达到停止条件。</td>
</tr>
<tr class="odd">
<td><strong>正则化</strong></td>
<td>无</td>
<td>L1 和 L2 正则化项</td>
<td>L1 和 L2 正则化项</td>
</tr>
<tr class="even">
<td><strong>Shrinkage（缩减）</strong></td>
<td>有</td>
<td>有</td>
<td>有</td>
</tr>
<tr class="odd">
<td>类别特征优化</td>
<td>无</td>
<td>无</td>
<td><strong>类别特征最优分割</strong>：<strong>many-vs-many</strong></td>
</tr>
<tr class="even">
<td>并行化设计</td>
<td>无</td>
<td><strong>块结构设计</strong>、</td>
<td><strong>特征并行</strong>、
<strong>数据并行</strong>、<strong>投票并行</strong></td>
</tr>
<tr class="odd">
<td>==缓存优化==</td>
<td>无</td>
<td>为每个线程分配一个连续的缓存区、<strong>“核外”块计算</strong></td>
<td>1、所有的特征都采用相同的方法获得梯度；2、其次，因为不需要存储特征到样本的索引，降低了存储消耗</td>
</tr>
<tr class="even">
<td><strong>缺点</strong></td>
<td>对异常点敏感；</td>
<td><strong>预排序</strong>：仍需要遍历数据集；==不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引，相当于消耗了两倍的内存。==</td>
<td><strong>内存更小</strong>： 索引值、特征值边bin、互斥特征捆绑;
<strong>速度更快</strong>：遍历直方图；单边梯度算法过滤掉梯度小的样本；基于
Leaf-wise
算法的增长策略构建树，减少了很多不必要的计算量；特征并行、数据并行方法加速计算</td>
</tr>
</tbody>
</table>
<h2><span id="一-xgboost线性模型多分类增量训练xgb_直方图分布式部署">一、XGBoost
[线性模型？多分类？增量训练？XGB_直方图，分布式部署]</span></h2>
<blockquote>
<p><strong>增量学习</strong>：XGBoost提供两种增量训练的方式，一种是在当前迭代树的基础上增加新树，原树不变；另一种是当前迭代树结构不变，重新计算叶节点权重，同时也可增加新树。</p>
<p><strong>线性模型</strong>：xgboost通过泰勒公式的二阶展开迭代的残差是1导/2导，线性回归迭代的是标签，xgboost需要串行多个线性回归，预测结果为多个象形线性回归的累积值......，除了用到了线性回归的原理方程式，他们两的损失函数，下降梯度都不一样，几乎没有什么共同点</p>
<p><strong>XGBoost
用泰勒展开优势在哪？</strong>：https://www.zhihu.com/question/61374305</p>
<ul>
<li><strong>xgboost是以mse为基础推导出来的</strong>，在mse的情况下，xgboost的目标函数展开就是一阶项+二阶项的形式，而其他类似logloss这样的目标函数不能表示成这种形式。为了后续推导的统一，所以将<strong>目标函数进行二阶泰勒展开，就可以直接自定义损失函数了，只要二阶可导即可，增强了模型的扩展性</strong>。</li>
<li><strong>二阶信息能够让梯度收敛的更快，类似牛顿法比SGD收敛更快</strong>。一阶信息描述梯度变化方向，二阶信息可以描述梯度变化方向是如何变化的。</li>
</ul>
<p><strong>==深入理解XGBoost==</strong>：https://bailingnan.github.io/post/shen-ru-li-jie-xgboost/</p>
</blockquote>
<p>XGBoost 是大规模并行 boosting tree 的工具，它是目前最快最好的开源
boosting tree 工具包，比常见的工具包快 10 倍以上。Xgboost 和 GBDT
两者都是 boosting
方法，除了工程实现、解决问题上的一些差异外，最大的不同就是<strong>目标函数</strong>的定义。故本文将从数学原理和工程实现上进行介绍，并在最后介绍下
Xgboost 的优点。</p>
<h3><span id="11-数学原理">1.1 数学原理</span></h3>
<p><strong>1.1.1 目标函数</strong></p>
<p>我们知道 XGBoost 是由<span class="math inline">\(k\)</span>个基模型组成的一个加法运算式： <span class="math display">\[
\hat{y}_{i}=\sum_{t=1}^{k} f_{t}\left(x_{i}\right)
\]</span> <strong>损失函数：</strong> <span class="math display">\[
L=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}\right)
\]</span>
我们知道模型的预测精度由模型的<strong>偏差</strong>和<strong>方差</strong>共同决定，损失函数代表了模型的偏差，想要方差小则需要简单的模型，所以目标函数由模型的<strong>损失函数<span class="math inline">\(L\)</span></strong>与抑<strong>制模型复杂度的正则项
<span class="math display">\[\Omega\]</span></strong>组成。支持<strong>决策树</strong>也支持<strong>线性模型</strong>。
<span class="math display">\[
O b j=\sum_{i=1}^{n} l\left(\hat{y}_{i}, y_{i}\right)+\sum_{t=1}^{k}
\Omega\left(f_{t}\right)
\]</span> <strong>Boosting模型是向前加法：</strong> <span class="math display">\[
\hat{y}_{i}^{t}=\hat{y}_{i}^{t-1}+f_{t}\left(x_{i}\right)
\]</span> 目标函数就可以写成： <span class="math display">\[
\begin{aligned}
O b j^{(t)} &amp;=\sum_{i=1}^{n} l\left(y_{i},
\hat{y}_{i}^{t}\right)+\sum_{i=1}^{t} \Omega\left(f_{i}\right) \\
&amp;=\sum_{i=1}^{n} l\left(y_{i},
\hat{y}_{i}^{t-1}+f_{t}\left(x_{i}\right)\right)+\sum_{i=1}^{t}
\Omega\left(f_{i}\right)
\end{aligned}
\]</span> 求此时最优化目标函数，就相当于求解 <span class="math display">\[f_{t}\left(x_{i}\right)\]</span>。根据泰勒展开式：
<span class="math display">\[
f(x+\Delta x) \approx f(x)+f^{\prime}(x) \Delta x+\frac{1}{2} f^{\prime
\prime}(x) \Delta x^{2}
\]</span> <strong>我们==把<span class="math display">\[\hat{y}_{i}^{t-1}\]</span>,视为x， <span class="math display">\[f_{t}\left(x_{i}\right)\]</span>视为<span class="math display">\[\Delta
x\]</span>==，故可以将目标函数写成</strong>： <span class="math display">\[
O b j^{(t)}=\sum_{i=1}^{n}\left[l\left(y_{i},
\hat{y}_{i}^{t-1}\right)+g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i}
f_{t}^{2}\left(x_{i}\right)\right]+\sum_{i=1}^{t}
\Omega\left(f_{i}\right)
\]</span>
由于<strong>第一项为常数，对优化没有影响，所以我们只需要求出每一步损失函数的一阶导和二阶导的值</strong>【==前t-1的结果和标签求==】，然后最优化目标函数，就可以得到每一步的f(x),最后根据加法模型得到一个整体模型。
<span class="math display">\[
O b j^{(t)} \approx \sum_{i=1}^{n}\left[g_{i}
f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i}
f_{t}^{2}\left(x_{i}\right)\right]+\sum_{i=1}^{t}
\Omega\left(f_{i}\right)
\]</span></p>
<blockquote>
<p>以<strong>平方损失函数</strong>【绝对值、hubor损失】为例（GBDT
残差）：</p>
<p><img src="image-20220404141858337.png" alt="image-20220404141858337" style="zoom:50%;"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=g_%7Bi%7D" alt="[公式]"> 为损失函数的一阶导， <img src="https://www.zhihu.com/equation?tex=h_%7Bi%7D" alt="[公式]">
为损失函数的二阶导，<strong>注意这里的导是对 <img src="https://www.zhihu.com/equation?tex=%5Chat%7By%7D_i%5E%7Bt-1%7D" alt="[公式]"> 求导</strong>。 <span class="math display">\[
  \begin{aligned}
  &amp;g_{i}=\frac{\partial\left(\hat{y}^{t-1}-y_{i}\right)^{2}}{\partial
\hat{y}^{t-1}}=2\left(\hat{y}^{t-1}-y_{i}\right) \\
  &amp;h_{i}=\frac{\partial^{2}\left(\hat{y}^{t-1}-y_{i}\right)^{2}}{\hat{y}^{t-1}}=2
  \end{aligned}
  \]</span></p>
</blockquote>
<h4><span id="112基于决策树的目标函数"><strong>1.1.2
基于决策树的目标函数</strong></span></h4>
<p>我们知道 Xgboost
的基模型<strong>不仅支持决策树，还支持线性模型</strong>，这里我们主要介绍基于决策树的目标函数。</p>
<p>我们可以将决<strong>策树定义为<span class="math display">\[f_{t}(x)=w_{q(x)}\]</span></strong>，x为某一样本，这里的
<img src="https://www.zhihu.com/equation?tex=q%28x%29" alt="[公式]">
代表了该样本在哪个叶子结点上，而 <img src="https://www.zhihu.com/equation?tex=w_q" alt="[公式]">
则代表了叶子结点取值 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> ，所以 <img src="https://www.zhihu.com/equation?tex=w_%7Bq%28x%29%7D" alt="[公式]"> 就代表了每个样本的取值 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]">
（即预测值)。</p>
<p><strong>决策树的复杂度</strong>可由<strong>叶子数 <img src="https://www.zhihu.com/equation?tex=T" alt="[公式]"></strong>
组成，叶子节点越少模型越简单，此外<strong>叶子节点也不应该含有过高的权重</strong>
<img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> （类比
LR 的每个变量的权重)，所以目标函数的正则项可以定义为： <span class="math display">\[
\Omega\left(f_{t}\right)=\gamma T+\frac{1}{2} \lambda \sum_{j=1}^{T}
w_{j}^{2}
\]</span>
即<strong>决策树模型的复杂度</strong>由生成的所有<strong>决策树的叶子节点数量</strong>，和所有<strong>节点权重所组成的向量的
<img src="https://www.zhihu.com/equation?tex=L_2" alt="[公式]">
范式</strong>共同决定。</p>
<p><img src="https://pic1.zhimg.com/80/v2-e0ab9287990a6098e4cdbc5a8cff4150_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>我们设 <img src="https://www.zhihu.com/equation?tex=I_j%3D+%5C%7B+i+%5Cvert+q%28x_i%29%3Dj+%5C%7D" alt="[公式]"> 为第 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]"> 个叶子节点的样本集合，故我们的目标函数可以写成： <span class="math display">\[
\begin{aligned}
O b j^{(t)} &amp; \approx \sum_{i=1}^{n}\left[g_{i}
f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i}
f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right) \\
&amp;=\sum_{i=1}^{n}\left[g_{i} w_{q\left(x_{i}\right)}+\frac{1}{2}
h_{i} w_{q\left(x_{i}\right)}^{2}\right]+\gamma T+\frac{1}{2} \lambda
\sum_{j=1}^{T} w_{j}^{2} \\
&amp;=\sum_{j=1}^{T}\left[\left(\sum_{i \in I_{j}} g_{i}\right)
w_{j}+\frac{1}{2}\left(\sum_{i \in I_{j}} h_{i}+\lambda\right)
w_{j}^{2}\right]+\gamma T
\end{aligned}
\]</span>
第二步是遍历所有的样本后求每个样本的损失函数，但样本最终会落在叶子节点上，所以我们也可以遍历叶子节点，然后获取叶子节点上的样本集合，最后在求损失函数。即我们之前样本的集合，现在都改写成叶子结点的集合，由于一个叶子结点有多个样本存在，因此才有了
<img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi+%5Cin+I_j%7Dg_i" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi+%5Cin+I_j%7Dh_i" alt="[公式]"> 这两项， <img src="https://www.zhihu.com/equation?tex=w_j" alt="[公式]"> 为第 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]">
个叶子节点取值。</p>
<p><img src="image-20220314162051124.png" alt="image-20220314162051124" style="zoom: 25%;"></p>
<p><strong><font color="red"> 这里我们要注意 <img src="https://www.zhihu.com/equation?tex=G_j" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=H_j" alt="[公式]"> 是前 <img src="https://www.zhihu.com/equation?tex=t-1" alt="[公式]">
步得到的结果，其值已知可视为常数，只有最后一棵树的叶子节点 <img src="https://www.zhihu.com/equation?tex=w_j" alt="[公式]">
不确定，那么将目标函数对 <img src="https://www.zhihu.com/equation?tex=w_j" alt="[公式]">
求一阶导，并令其等于 <img src="https://www.zhihu.com/equation?tex=0" alt="[公式]"> ，则可以求得叶子结点 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]">
对应的权值：</font></strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=w_j%5E%2A%3D-%5Cfrac%7BG_j%7D%7BH_j%2B%5Clambda%7D++%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>所以<strong>目标函数可以化简为：</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=Obj+%3D+-%5Cfrac12+%5Csum_%7Bj%3D1%7D%5ET+%5Cfrac%7BG_j%5E2%7D%7BH_j%2B%5Clambda%7D+%2B+%5Cgamma+T+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><img src="https://pic2.zhimg.com/80/v2-f6db7af6c1e683192cb0ccf48eafaf99_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<p>上图给出目标函数计算的例子，求每个节点每个样本的一阶导数 <img src="https://www.zhihu.com/equation?tex=g_i" alt="[公式]"> 和二阶导数
<img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]">
，然后针对每个节点对所含样本求和得到的 <img src="https://www.zhihu.com/equation?tex=G_j" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=H_j" alt="[公式]">
，最后遍历决策树的节点即可得到<strong>目标函数</strong>。</p>
<h4><span id="113最优切分点划分算法"><strong>1.1.3
最优切分点划分算法</strong></span></h4>
<p><strong><font color="red">
在决策树的生长过程中，一个非常关键的问题是如何找到叶子的节点的最优切分点，</font></strong>Xgboost
支持两种分裂节点的方法——<strong>贪心算法</strong>和<strong>近似算法</strong>。</p>
<p><strong>1）贪心算法</strong></p>
<ol type="1">
<li><strong>从深度为 <img src="https://www.zhihu.com/equation?tex=0" alt="[公式]"> 的树开始，对每个叶节点枚举所有的可用特征</strong>；</li>
<li>针对每个特征，把属于该节点的训练样本根据该特征值进行<strong>升序排列</strong>，通过线性扫描的方式来决定该特征的最佳分裂点，并记录该特征的分裂收益；</li>
<li>选择收益最大的特征作为分裂特征，用该特征的最佳分裂点作为分裂位置，在该节点上分裂出左右两个新的叶节点，并为每个新节点<strong>关联对应的样本集</strong>？？</li>
<li>回到第 1 步，递归执行到满足特定条件为止。（树的深度、gamma）</li>
</ol>
<h5><span id="那么如何计算每个特征的分裂收益呢">那么如何计算每个特征的分裂收益呢？</span></h5>
<p>假设我们在某一节点完成特征分裂，则分列前的目标函数可以写为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=Obj_%7B1%7D+%3D-%5Cfrac12+%5B%5Cfrac%7B%28G_L%2BG_R%29%5E2%7D%7BH_L%2BH_R%2B%5Clambda%7D%5D+%2B+%5Cgamma++%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>分裂后的目标函数为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=Obj_2+%3D++-%5Cfrac12+%5B+%5Cfrac%7BG_L%5E2%7D%7BH_L%2B%5Clambda%7D+%2B+%5Cfrac%7BG_R%5E2%7D%7BH_R%2B%5Clambda%7D%5D+%2B2%5Cgamma+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>则对于目标函数来说，分裂后的收益为：<strong>MAX</strong>【<strong>obj1
- obj2 （分裂后越小越好）</strong>】</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=Gain%3D%5Cfrac12+%5Cleft%5B+%5Cfrac%7BG_L%5E2%7D%7BH_L%2B%5Clambda%7D+%2B+%5Cfrac%7BG_R%5E2%7D%7BH_R%2B%5Clambda%7D+-+%5Cfrac%7B%28G_L%2BG_R%29%5E2%7D%7BH_L%2BH_R%2B%5Clambda%7D%5Cright%5D+-+%5Cgamma+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>注意<strong>该特征收益也可作为特征重要性输出的重要依据</strong>。</p>
<p>我们可以发现对于所有的分裂点 <img src="https://www.zhihu.com/equation?tex=a" alt="[公式]">
，我们只要做一遍从左到右的扫描就可以枚举出所有分割的梯度和 <img src="https://www.zhihu.com/equation?tex=G_L" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=G_R" alt="[公式]">
。然后用上面的公式计算每个分割方案的分数就可以了。<font color="red">观察分裂后的收益，我们会发现节点划分不一定会使得结果变好，因为我们有一个引入<strong>新叶子的惩罚项（gamma)</strong>，也就是说引入的分割带来的<strong>增益如果小于一个阀值</strong>的时候，我们可以剪掉这个分割。
</font></p>
<p><strong>2）近似算法</strong>【<strong>加权分位划分点</strong>】</p>
<p><strong>贪婪算法可以的到最优解，但当数据量太大时则无法读入内存进行计算</strong>，近似算法主要针对贪婪算法这一缺点给出了近似最优解。</p>
<p>对于每个特征，只考察分位点可以减少计算复杂度。该算法会首先根据<strong>特征分布的分位数提出候选划分点，然后将连续型特征映射到由这些候选点划分的桶中</strong>，然后聚合统计信息找到所有区间的最佳分裂点。在提出候选切分点时有两种策略：</p>
<ul>
<li><strong>Global</strong>：<strong>学习每棵树前就提出候选切分点，并在每次分裂时都采用这种分割</strong>；</li>
<li><strong>Local</strong>：每次分裂前将重新提出候选切分点。</li>
</ul>
<p><strong>下图给出近似算法的具体例子，以三分位为例：</strong></p>
<p><img src="https://pic2.zhimg.com/80/v2-5d1dd1673419599094bf44dd4b533ba9_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>根据样本特征进行排序，然后基于分位数进行划分，并统计三个桶内的 <img src="https://www.zhihu.com/equation?tex=G%2CH" alt="[公式]">
值，最终求解节点划分的增益。</p>
<h4><span id="114加权分位数缩略图xgboost-直方图算法"><strong>1.1.4
加权分位数缩略图</strong>[XGBoost 直方图算法]</span></h4>
<ul>
<li><strong>第一个 for 循环：</strong>对特征 k
<strong>根据该特征分布的分位数找到切割点的候选集合【==直方图==】</strong>
<img src="https://www.zhihu.com/equation?tex=S_k%3D%5C%7Bs_%7Bk1%7D%2Cs_%7Bk2%7D%2C...%2Cs_%7Bkl%7D+%5C%7D" alt="[公式]"> 。XGBoost 支持 Global 策略和 Local 策略。</li>
<li><strong>第二个 for
循环：</strong>针对每个特征的候选集合，将样本映射到由该特征对应的候选点集构成的分桶区间中，即
<img src="https://www.zhihu.com/equation?tex=%7Bs_%7Bk%2Cv%7D%E2%89%A5x_%7Bjk%7D%3Es_%7Bk%2Cv%E2%88%921%7D%7D" alt="[公式]"> ，对每个桶统计 <img src="https://www.zhihu.com/equation?tex=G%2CH+" alt="[公式]">
值，最后在这些统计量上寻找最佳分裂点。</li>
</ul>
<p><img src="https://pic1.zhimg.com/80/v2-161382c979557b8bae1563a459cd1ed4_1440w.jpg" alt="img" style="zoom:33%;"></p>
<p>事实上， <strong>XGBoost
不是简单地按照样本个数进行分位，而是以二阶导数值 <img src="https://www.zhihu.com/equation?tex=h_i+" alt="[公式]">
作为样本的权重进行划分</strong>，如下：</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-5f16246289eaa2a3ae72f971db198457_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h5><span id="那么问题来了为什么要用进行样本加权">==那么问题来了：为什么要用
<img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]">
进行样本加权？==</span></h5>
<p>我们知道模型的目标函数为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=+Obj%5E%7B%28t%29%7D+%5Capprox+%5Csum_%7Bi%3D1%7D%5En+%5Cleft%5B+g_if_t%28x_i%29+%2B+%5Cfrac12h_if_t%5E2%28x_i%29+%5Cright%5D+%2B+%5Csum_%7Bi%3D1%7D%5Et++%5COmega%28f_i%29+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>我们稍作整理，便可以看出 <img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]"> 有对 loss
加权的作用。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Balign%7D++Obj%5E%7B%28t%29%7D+%26+%5Capprox+%5Csum_%7Bi%3D1%7D%5En+%5Cleft%5B+g_if_t%28x_i%29+%2B+%5Cfrac12h_if_t%5E2%28x_i%29+%5Cright%5D+%2B+%5Csum_%7Bi%3D1%7D%5Et++%5COmega%28f_i%29+%5C%5C+%5C%5C++++%26%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5B+g_i+f_t%28x_i%29+%2B+%5Cfrac%7B1%7D%7B2%7Dh_i+f_t%5E2%28x_i%29+%5Ccolor%7Bred%7D%7B%2B+%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7Bg_i%5E2%7D%7Bh_i%7D%7D%5D%2B%5COmega%28f_t%29+%5Ccolor%7Bred%7D%7B%2B+C%7D+%5C%5C++++%26%3D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Ccolor%7Bred%7D%7B%5Cfrac%7B1%7D%7B2%7Dh_i%7D+%5Cleft%5B+f_t%28x_i%29+-+%5Cleft%28+-%5Cfrac%7Bg_i%7D%7Bh_i%7D+%5Cright%29+%5Cright%5D%5E2+%2B+%5COmega%28f_t%29+%2B+C+%5Cend%7Balign%7D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7B2%7D%5Cfrac%7Bg_i%5E2%7D%7Bh_i%7D" alt="[公式]"> 与 <img src="https://www.zhihu.com/equation?tex=C" alt="[公式]"> 皆为常数。我们可以看到 <img src="https://www.zhihu.com/equation?tex=h_i" alt="[公式]">
就是平方损失函数中样本的权重。</p>
<p>对于样本权值相同的数据集来说，找到候选分位点已经有了解决方案（GK
算法），但是当样本权值不一样时，该如何找到候选分位点呢？（作者给出了一个
Weighted Quantile Sketch 算法，这里将不做介绍。）</p>
<h4><span id="xgboost的近似直方图算法也类似于lightgbm这里的直方图算法为什么慢"><strong><font color="red">
xgboost的近似直方图算法也类似于lightgbm这里的直方图算法?
为什么慢？</font></strong></span></h4>
<ul>
<li><strong>xgboost在每一层都动态构建直方图</strong>，
因为<strong>xgboost的直方图算法不是针对某个特定的feature</strong>，而是所有feature共享一个直方图(每个样本的权重是二阶导),所以每一层都要重新构建直方图，而<strong>lightgbm中对每个特征都有一个直方图</strong>，所以构建一次直方图就够了。</li>
<li><strong>lightgbm有一些工程上的cache优化</strong></li>
</ul>
<h4><span id="115稀疏感知算法缺失值的处理"><strong>1.1.5
稀疏感知算法</strong>【<strong>缺失值的处理</strong>】</span></h4>
<blockquote>
<ul>
<li><strong>特征值缺失的样本无需遍历只需直接分配到左右节点</strong></li>
<li><strong>如果训练中没有数据缺失，预测时出现了数据缺失，则默认被分类到右节点.</strong>？
<ul>
<li>看c++源码是默认向左方向</li>
</ul></li>
</ul>
</blockquote>
<p>在决策树的第一篇文章中我们介绍 CART
树在应对数据缺失时的分裂策略【<strong>缺失代理</strong>】，XGBoost
也给出了其解决方案。XGBoost
在构建树的节点过程中只考虑非缺失值的数据遍历，而为每个节点增加了一个缺省方向，当样本相应的特征值缺失时，可以被归类到缺省方向上，最优的缺省方向可以从数据中学到。</p>
<p><strong>XGBoost提出的是在计算分割后的分数时，遇到缺失值，分别将缺失值带入左右两个分割节点，然后取最大值的方向为其默认方向。</strong>至于如何学到缺省值的分支，其实很简单，<strong>分别枚举特征缺省的样本归为左右分支后的增益，选择增益最大的枚举项即为最优缺省方向。</strong></p>
<p>在构建树的过程中需要枚举特征缺失的样本，乍一看该算法的计算量增加了一倍，但其实该算法在构建树的过程中只考虑了特征未缺失的样本遍历，而<strong>特征值缺失的样本无需遍历只需直接分配到左右节点</strong>，故算法所需遍历的样本量减少，下图可以看到稀疏感知算法比
basic 算法速度块了超过 50 倍。</p>
<p><img src="https://pic1.zhimg.com/80/v2-e065bea4b424ea2d13b25ed2e7004aa8_1440w.jpg" alt="img" style="zoom:67%;"></p>
<h4><span id="116-缩减与列采样"><strong>1.1.6 缩减与列采样</strong></span></h4>
<p>除了在目标函数中引入正则项，为了防止过拟合，XGBoost还引入了缩减(shrinkage)和列抽样（column
subsampling），通过在每一步的boosting中引入缩减系数，降低每个树和叶子对结果的影响；列采样是借鉴随机森林中的思想，根据反馈，列采样有时甚至比行抽样效果更好，同时，通过列采样能加速计算。</p>
<h3><span id="12-工程实现">1.2 工程实现</span></h3>
<h4><span id="121-块结构设计"><strong>1.2.1 块结构设计</strong></span></h4>
<p>我们知道，决策树的学习<strong>最耗时的一个步骤就是在每次寻找最佳分裂点是都需要对特征的值进行排序</strong>。而
<strong><font color="red"> XGBoost
在训练之前对根据特征对数据进行了排序，然后保存到块结构中，并在每个块结构中都采用了稀疏矩阵存储格式（Compressed
Sparse Columns
Format，CSC）进行存储，后面的训练过程中会重复地使用块结构，可以大大减小计算量。</font></strong></p>
<blockquote>
<p>预排序 + 块设计【独立】 + 稀疏矩阵存储</p>
</blockquote>
<ul>
<li><strong>每一个块结构包括一个或多个已经排序好的特征</strong>；</li>
<li><strong>缺失特征值将不进行排序</strong>；</li>
<li>每个特征会存储指向<strong>样本梯度统计值</strong>的索引，方便计算一阶导和二阶导数值；</li>
</ul>
<p>这种块结构存储的特征之间相互独立，方便计算机进行并行计算。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个<strong>特征的增益计算可以同时进行</strong>，这也是
Xgboost 能够实现分布式或者多线程计算的原因。</p>
<h4><span id="122缓存访问优化算法索引访问梯度统计-gt-缓存空间不连续"><strong>1.2.2
缓存访问优化算法</strong>【索引访问梯度统计 -&gt; 缓存空间不连续】</span></h4>
<p>块结构的设计可以减少节点分裂时的计算量，但<strong>特征值通过索引访问样本梯度统计值的设计会导致访问操作的内存空间不连续</strong>，这样会造成缓存命中率低，从而影响到算法的效率。</p>
<p>为了解决缓存命中率低的问题，XGBoost
提出了缓存访问优化算法：为每个线程分配一个连续的缓存区，将需要的梯度信息存放在缓冲区中，这样就是实现了非连续空间到连续空间的转换，提高了算法效率。此外适当调整块大小，也可以有助于缓存优化。</p>
<p>于exact greedy算法中, 使用<strong>缓存预取（cache-aware
prefetching）</strong>。具体来说，<strong>对每个线程分配一个连续的buffer</strong>，读取梯度信息并存入Buffer中（这样就实现了非连续到连续的转化）</p>
<h4><span id="123-核外块计算"><strong>1.2.3 “核外”块计算</strong></span></h4>
<p>当数据量过大时无法将数据全部加载到内存中，只能先将无法加载到内存中的数据暂存到硬盘中，直到需要时再进行加载计算，而这种操作必然涉及到因内存与硬盘速度不同而造成的资源浪费和性能瓶颈。为了解决这个问题，<strong>XGBoost
独立一个线程专门用于从硬盘读入数据，以实现处理数据和读入数据同时进行</strong>。</p>
<p>此外，XGBoost 还用了两种方法来降低硬盘读写的开销：</p>
<ul>
<li><strong>块压缩：</strong>对 Block
进行按列压缩，并在读取时进行解压；</li>
<li><strong>块拆分：</strong>将每个块存储到不同的磁盘中，从多个磁盘读取可以增加吞吐量。</li>
</ul>
<h4><span id="124-xgboost损失函数">==1.2.4 <strong>XGBoost损失函数</strong>==</span></h4>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_32103261/article/details/106664227">不平衡处理：xgboost
中scale_pos_weight、给样本设置权重weight、 自定义损失函数 和
简单复制正样本的区别</a></p>
</blockquote>
<p><strong>损失函数</strong>：损失函数描述了预测值和真实标签的差异，通过对损失函数的优化来获得对学习任务的一个近似求解方法。boosting类算法的损失函数的作用：
Boosting的框架, 无论是GBDT还是Adaboost, 其在每一轮迭代中,
<strong>根本没有理会损失函数具体是什么,
仅仅用到了损失函数的一阶导数通过随机梯度下降来参数更新</strong>。XGBoost是用了牛顿法进行的梯度更新。通过对损失进行分解得到一阶导数和二阶导数并通过牛顿法来迭代更新梯度。</p>
<h5><span id="1自定义损失函数">（1）==<strong>自定义损失函数</strong>==</span></h5>
<p><strong>XGBOOST是一个非常灵活的模型</strong>，允许使用者根据实际使用场景调整<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=损失函数&amp;spm=1001.2101.3001.7020">损失函数</a>，对于常见的二分类问题一般使用的binary：logistic损失函数，其形式为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=J%28%5Ctheta%29%3D-%5Cfrac%7B1%7D%7Bm%7D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cleft%28y%5E%7B%28i%29%7D+%5Clog+h_%7B%5Ctheta%7D%5Cleft%28x%5E%7B%28i%29%7D%5Cright%29%2B%5Cleft%281-y%5E%7B%28i%29%7D%5Cright%29+%5Clog+%5Cleft%281-h_%7B%5Ctheta%7D%5Cleft%28x%5E%7B%28i%29%7D%5Cright%29%5Cright%29%5Cright%29+%EF%BC%883%EF%BC%89%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>这个损失函数对于正类错分和负类错分给予的惩罚时相同的，但是<strong>对于不平衡数据集，或者某些特殊情况（两类错分代价不一样）的时候这样的损失函数就不再合理了。</strong></p>
<p>基于XGBoost的损失函数的分解求导，可以知道XGBoost的除正则项以外的核心影响因子是损失函数的1阶导和2阶导，所以对于任意的学习任务的损失函数，可以对其求一阶导数和二阶导数带入到XGBoost的自定义损失函数范式里面进行处理。
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">custom_obj</span>(<span class="params">pred, dtrain</span>):<span class="comment"># pred 和 dtrain 的顺序不能弄反</span></span><br><span class="line">    <span class="comment"># STEP1 获得label</span></span><br><span class="line">    label = dtrain.get_label()</span><br><span class="line">    <span class="comment"># STEP2 如果是二分类任务，需要让预测值通过sigmoid函数获得0～1之间的预测值</span></span><br><span class="line">    <span class="comment"># 如果是回归任务则下述任务不需要通过sigmoid</span></span><br><span class="line">    <span class="comment"># 分类任务sigmoid化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line">    sigmoid_pred = sigmoid(原始预测值)</span><br><span class="line">    <span class="comment">#回归任务</span></span><br><span class="line">    pred = 原始预测值</span><br><span class="line">    <span class="comment"># STEP3 一阶导和二阶导</span></span><br><span class="line">    grad = 一阶导</span><br><span class="line">    hess = 二阶导</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> grad, hess</span><br></pre></td></tr></table></figure></p>
<p>非平衡分类学习任务，例如首笔首期30+的风险建模任务，首期30+的逾期率比例相对ever30+的逾期率为1/3左右，<strong>通过修正占比少的正样本权重来对影响正样本对损失函数的贡献度，可以进一步提升模型的效果</strong>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">weighted_binary_cross_entropy</span>(<span class="params">pred, dtrain,imbalance_alpha=<span class="number">10</span></span>):</span><br><span class="line">    <span class="comment"># retrieve data from dtrain matrix</span></span><br><span class="line">    label = dtrain.get_label()</span><br><span class="line">    <span class="comment"># compute the prediction with sigmoid</span></span><br><span class="line">    sigmoid_pred = <span class="number">1.0</span> / (<span class="number">1.0</span> + np.exp(-pred))</span><br><span class="line">    <span class="comment"># gradient</span></span><br><span class="line">    grad = -(imbalance_alpha ** label) * (label - sigmoid_pred)</span><br><span class="line">    hess = (imbalance_alpha ** label) * sigmoid_pred * (<span class="number">1.0</span> - sigmoid_pred)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> grad, hess </span><br></pre></td></tr></table></figure>
<h5><span id="2focal-loss">（2）Focal Loss</span></h5>
<p><strong>Focal Loss for Dense Object Detection 是ICCV2017的Best
student
paper,文章思路很简单但非常具有开拓性意义，效果也非常令人称赞。</strong></p>
<ul>
<li>大家还可以看知乎的讨论：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/63581984">如何评价 Kaiming 的 Focal
Loss for Dense Object Detection？</a></li>
<li>[机器学习] XGBoost
自定义损失函数-FocalLoss：https://blog.csdn.net/zwqjoy/article/details/109311133</li>
</ul>
<p>Focal
Loss的引入主要是为了解决难易样本数量不平衡（注意，有区别于正负样本数量不平衡）的问题，实际可以使用的范围非常广泛，为了方便解释，拿目标检测的应用场景来说明</p>
<p><strong>==Focal Loss的主要思想就是改变损失函数.Focal
loss是在交叉熵损失函数基础上进行的修改==</strong></p>
<p>单阶段的目标检测器通常会产生高达100k的候选目标，只有极少数是正样本，正负样本数量非常不平衡。我们在计算分类的时候常用的损失——交叉熵。<embed src="https://private.codecogs.com/gif.latex?y%7B%7D%27">是经过激活函数的输出，所以在0-1之间。可见普通的交叉熵对于正样本而言，输出概率越大损失越小。对于负样本而言，输出概率越小则损失越小。此时的损失函数在大量简单样本的迭代过程中比较缓慢且可能无法优化至最优。</p>
<p>为了解决<strong>正负样本不平衡</strong>的问题，我们通常会在交叉熵损失的前面加上一个参数<strong>平衡因子alpha</strong>，用来平衡正负样本本身的比例不均.
文中alpha取0.25，即正样本要比负样本占比小，这是因为负例易分。</p>
<h3><span id="13-优缺点">1.3 优缺点</span></h3>
<h4><span id="131-优点"><strong>1.3.1 优点</strong></span></h4>
<ol type="1">
<li><strong>精度更高：</strong>GBDT
只用到一阶<strong>泰勒展开</strong>，而 XGBoost
对损失函数进行了二阶泰勒展开。<strong>XGBoost
引入二阶导一方面是为了增加精度，另一方面也是为了能够自定义损失函数，二阶泰勒展开可以近似大量损失函数</strong>；</li>
<li><strong>灵活性更强：</strong>GBDT 以 CART
作为<strong>基分类器</strong>，XGBoost 不仅支持 CART
还支持线性分类器，（使用线性分类器的 <strong>XGBoost 相当于带 L1 和 L2
正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）</strong>）。此外，XGBoost
工具支持自定义损失函数，只需函数支持一阶和二阶求导；</li>
<li><strong>正则化：</strong>XGBoost
在目标函数中加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、叶子节点权重的
L2
范式。正则项降低了模型的方差，使学习出来的模型更加简单，有助于防止过拟合；</li>
<li><strong>Shrinkage（缩减）：</strong>相当于学习速率。XGBoost
在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间；</li>
<li><strong>列抽样：</strong>XGBoost
借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</li>
<li><strong>缺失值处理：</strong>XGBoost
采用的稀疏感知算法极大的加快了节点分裂的速度；</li>
<li><strong>可以并行化操作：</strong>块结构可以很好的支持并行计算。</li>
</ol>
<h4><span id="132-缺点"><strong>1.3.2 缺点</strong></span></h4>
<ol type="1">
<li>虽然利用<strong>预排序</strong>和<strong>近似算法</strong>可以降低寻找最佳分裂点的计算量，但在节点分裂过程中仍需要<strong>==遍历数据集==</strong>；</li>
<li>预排序过程的空间复杂度过高，不仅需要存储特征值，还需要<strong>==存储特征对应样本的梯度统计值的索引==</strong>，相当于消耗了两倍的内存。</li>
</ol>
<h2><span id="二-xgboost常用参数">二、XGBoost常用参数</span></h2>
<h4><span id="xgboost的参数一共分为三类">XGBoost的参数一共分为三类：</span></h4>
<p><a target="_blank" rel="noopener" href="https://xgboost.apachecn.org/#/">完整参数请戳官方文档</a></p>
<p>1、<strong>通用参数</strong>：宏观函数控制。</p>
<p>2、<strong>Booster参数</strong>：控制每一步的booster(tree/regression)。booster参数一般可以调控模型的效果和计算代价。我们所说的调参，很这是大程度上都是在调整booster参数。</p>
<p>3、<strong>学习目标参数</strong>：控制训练目标的表现。我们对于问题的划分主要体现在学习目标参数上。比如我们要做分类还是回归，做二分类还是多分类，这都是目标参数所提供的。</p>
<h4><span id="通用参数">通用参数</span></h4>
<ol type="1">
<li><strong>booster</strong>：我们有两种参数选择，<code>gbtree</code>、<code>dart</code>和<code>gblinear</code>。gbtree、dart是采用树的结构来运行数据，而gblinear是基于线性模型。</li>
<li><strong>silent</strong>：静默模式，为<code>1</code>时模型运行不输出。</li>
<li><strong>nthread</strong>:
使用线程数，一般我们设置成<code>-1</code>,使用所有线程。如果有需要，我们设置成多少就是用多少线程。</li>
</ol>
<h4><span id="booster参数">Booster参数</span></h4>
<ol type="1">
<li><p><strong>==n_estimator==</strong>:
也作<code>num_boosting_rounds</code>这是生成的<strong>最大树的数目</strong>，也是最大的迭代次数。</p></li>
<li><p><strong>==learning_rate==</strong>:
有时也叫作<code>eta</code>，系统默认值为<code>0.3</code>,。<strong>每一步迭代的步长</strong>，很重要。太大了运行准确率不高，太小了运行速度慢。我们一般使用比默认值小一点，<code>0.1</code>左右就很好。</p></li>
<li><p><strong>==gamma==</strong>：系统默认为<code>0</code>,我们也常用<code>0</code>。在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。<code>gamma</code>指定了节点分裂所需的<strong>最小损失函数下降值</strong>。
这个参数的值越大，算法越保守。因为<code>gamma</code>值越大的时候，损失函数下降更多才可以分裂节点。所以树生成的时候更不容易分裂节点。范围:
<code>[0,∞]</code></p></li>
<li><p><strong>==subsample==</strong>：系统默认为<code>1</code>。这个参数控制对于每棵树，<strong>随机采样的比例</strong>。减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。
典型值：<code>0.5-1</code>，<code>0.5</code>代表平均采样，防止过拟合.
范围: <code>(0,1]</code>，<strong>注意不可取0</strong></p></li>
<li><p><strong>colsample_bytree</strong>：系统默认值为1。我们一般设置成0.8左右。用来控制每棵<strong>随机采样的列数的占比</strong>(每一列是一个特征)。
典型值：<code>0.5-1</code>范围: <code>(0,1]</code></p></li>
<li><p><strong>colsample_bylevel</strong>：默认为1,我们也设置为1.这个就相比于前一个更加细致了，它指的是每棵树每次节点分裂的时候列采样的比例</p></li>
<li><p><strong>max_depth</strong>：
系统默认值为<code>6</code>，我们常用<code>3-10</code>之间的数字。这个值为<strong>树的最大深度</strong>。这个值是用来控制过拟合的。<code>max_depth</code>越大，模型学习的更加具体。设置为<code>0</code>代表没有限制，范围:
<code>[0,∞]</code></p></li>
<li><p><strong>==max_delta_step==</strong>：默认<code>0</code>,我们常用<code>0</code>.这个参数限制了<strong>每棵树权重改变的最大步长</strong>，如果这个参数的值为<code>0</code>,则意味着没有约束。如果他被赋予了某一个正值，则是这个算法更加保守。通常，这个参数我们不需要设置，但是<strong>==当个类别的样本极不平衡的时候，这个参数对逻辑回归优化器是很有帮助的。==</strong></p></li>
<li><p><strong>==lambda==</strong>:也称<code>reg_lambda</code>,默认值为<code>0</code>。<strong>权重的L2正则化项</strong>。(和Ridge
regression类似)。这个参数是用来控制XGBoost的正则化部分的。这个参数在减少过拟合上很有帮助。</p></li>
<li><p><strong>alpha</strong>:也称<code>reg_alpha</code>默认为<code>0</code>,权重的L1正则化项。(和Lasso
regression类似)。
可以应用在很高维度的情况下，使得算法的速度更快。</p></li>
<li><p><strong>==scale_pos_weight==</strong>：默认为<code>1</code>在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛。通常可以将其设置为<strong>负样本的数目与正样本数目的比值</strong>。<strong>xgboost中==scale_pos_weight、对样本进行weight设置和简单复制正样本==得到的结果是一样的，本质上都是改变了训练的损失函数。通过自定义设置损失函数可得到验证。实际上基本思想都是通过过采样的方法处理不平衡数据。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (label == <span class="number">1.0</span>f) &#123;</span><br><span class="line">    w *= scale_pos_weight;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 见源码 src/objective/regression_obj.cu</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>在DMatrix里边设置每个样本的weight 是
怎样改变训练过程的呢，其实是改变训练的损失函数，源代码里的代码如下，可以看到对不同的样本赋予不同的权重实际上是影响了该样本在训练过程中贡献的损失，进而改变了一阶导和二阶导。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">_out_gpair[_idx] = GradientPair(Loss::FirstOrderGradient(p, label) * w,</span><br><span class="line">                   Loss::SecondOrderGradient(p, label) * w);</span><br><span class="line"><span class="comment"># 见源码 src/objective/regression_obj.cu</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h4><span id="学习目标参数">学习目标参数</span></h4>
<h5><span id="objective-缺省值reglinear">objective [缺省值=reg:linear]</span></h5>
<ul>
<li><code>reg:linear</code>– <strong>线性回归</strong></li>
<li><code>reg:logistic</code> – <strong>逻辑回归</strong></li>
<li><code>binary:logistic</code> – 二分类逻辑回归，输出为概率</li>
<li><code>binary:logitraw</code> – 二分类逻辑回归，输出的结果为wTx</li>
<li><code>count:poisson</code> –
计数问题的poisson回归，输出结果为poisson分布。在poisson回归中，max_delta_step的缺省值为0.7
(used to safeguard optimization)</li>
<li><code>multi:softmax</code> – 设置 XGBoost
使用softmax目标函数做多分类，需要设置参数num_class（类别个数）</li>
<li><code>multi:softprob</code> –
如同softmax，但是输出结果为ndata*nclass的向量，其中的值是每个数据分为每个类的概率。</li>
</ul>
<h5><span id="eval_metric缺省值通过目标函数选择">eval_metric
[缺省值=通过目标函数选择]</span></h5>
<ul>
<li><code>rmse</code>: <strong>均方根误差</strong></li>
<li><code>mae</code>: <strong>平均绝对值误差</strong></li>
<li><code>logloss</code>: negative log-likelihood</li>
<li><code>error</code>:
二分类错误率。其值通过错误分类数目与全部分类数目比值得到。对于预测，预测值大于0.5被认为是正类，其它归为负类。
error@t: 不同的划分阈值可以通过 ‘t’进行设置</li>
<li><code>merror</code>: 多分类错误率，计算公式为(wrong cases)/(all
cases)</li>
<li><code>mlogloss</code>: ==多分类log损失==</li>
<li><code>auc</code>: 曲线下的面积</li>
<li><code>ndcg</code>: Normalized Discounted Cumulative Gain</li>
<li><code>map</code>: 平均正确率</li>
</ul>
<p>一般来说，我们都会使用<code>xgboost.train(params, dtrain)</code>函数来训练我们的模型。这里的<code>params</code>指的是<code>booster</code>参数。</p>
<h1><span id="xgboostqampa">XGBoostQ&amp;A</span></h1>
<ul>
<li>推荐收藏 |
又有10道XGBoost面试题送给你：https://cloud.tencent.com/developer/article/1518305</li>
</ul>
<h3><span id="1-xgboost模型如果过拟合了怎么解决"><strong>1、XGBoost模型如果过拟合了怎么解决?</strong></span></h3>
<ul>
<li><strong>正则项</strong>：叶子结点的数目和叶子结点权重的L2模的平方</li>
<li><strong>列抽样</strong>：训练的时候只用一部分特征，不仅可以降低过拟合，还可以加速</li>
<li><strong>子采样</strong>：每轮计算可以不使用全部样本</li>
<li><strong>shrinkage</strong>:
步长(学习率)，消弱训练出的每棵树的影响，让后面的训练有更大的学习空间</li>
</ul>
<p>当出现过拟合时，有两类参数可以缓解：</p>
<p>第一类参数：用于<strong>直接控制模型的复杂度</strong>。包括<code>max_depth,min_child_weight,gamma</code>
等参数</p>
<p>第二类参数：用于<strong>增加随机性</strong>，从而使得模型在训练时对于噪音不敏感。包括<code>subsample,colsample_bytree</code></p>
<p>还有就是直接减小<code>learning rate</code>，但需要同时增加<code>estimator</code>
参数。</p>
<h3><span id="2-怎么理解决策树-xgboost能处理缺失值而有的模型svm对缺失值比较敏感呢">2、怎么理解决策树、xgboost能处理缺失值？而有的模型(svm)对缺失值比较敏感呢?</span></h3>
<blockquote>
<p>微调的回答 - 知乎
https://www.zhihu.com/question/58230411/answer/242037063</p>
<p>XGBoost是一种<strong>boosting</strong>的集成学习模型：支持的弱学习器（即单个的学习器，也称基学习器）有<strong>树模型</strong>和<strong>线性模型</strong>（<strong>gblinear</strong>），默认为<strong>gbtree</strong>。</p>
<ul>
<li><p><strong>gblinear</strong>，<strong>由于线性模型不支持缺失值，会将缺失值填充为0</strong>；</p></li>
<li><p><strong>gbtree</strong>或者<strong>dart</strong>，则支持缺失值；</p></li>
</ul>
</blockquote>
<ul>
<li>工具包自动处理数据缺失<strong>不代表</strong>具体的算法可以<strong>处理缺失项</strong></li>
<li>对于有缺失的数据：以<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=决策树&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A242037063%7D">决策树</a>为原型的模型<strong>优于</strong>依赖距离度量的模型</li>
</ul>
<h3><span id="3-histogram-vs-pre-sorted">3、 Histogram VS Pre-sorted</span></h3>
<h4><span id="pre-sorted">Pre-sorted</span></h4>
<p><strong>预排序还是有一定优点的，如果不用预排序的话，在分裂节点的时候，选中某一个特征后，需要对A按特征值大小进行排序，然后计算每个阈值的增益，这个过程需要花费很多时间</strong>。</p>
<p>预排序算法在计算最优分裂时，各个特征的增益可以并行计算，并且能精确地找到分割点。但是<strong>预排序后需要保存特征值及排序后的索引，因此需要消耗两倍于训练数据的内存，时间消耗大</strong>。另外预排序后，<strong>特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化，时间消耗也大</strong>。最后，在每一层，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样。</p>
<h4><span id="historgram">Historgram</span></h4>
<p>首先需要指出的是，XGBoost在寻找树的分裂节点的也是支持直方图算法的，就是论文中提到的近视搜索算法（Approximate
Algorithm）。<strong>只是，无论特征值是否为0，直方图算法都需要对特征的分箱值进行索引，因此对于大部分实际应用场景当中的稀疏数据优化不足。</strong></p>
<p>回过头来，为了能够发挥直方图算法的优化威力，LightGBM提出了另外两个新技术：<strong>单边梯度采样（Gradient-based
One-Side Sampling</strong>）和<strong>互斥特征合并（Exclusive Feature
Bundling）</strong>，<strong><font color="red">
在减少维度和下采样上面做了优化以后才能够将直方图算法发挥得淋漓尽致。</font></strong></p>
<h3><span id="4-xgboost中的树如何剪枝">4、<strong>Xgboost中的树如何剪枝？</strong></span></h3>
<p><strong>在loss中增加了正则项</strong>：使用叶子结点的数目和叶子结点权重的L2模的平方，控制树的复杂度在每次分裂时，如果分裂后增益小于设置的阈值，则不分裂，则对应于Gain需要大于0才会分裂。(预剪枝)</p>
<p>则对于目标函数来说，分裂后的收益为：<strong>MAX</strong>【<strong>obj1
- obj2 （分裂后越小越好）</strong>】</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=Gain%3D%5Cfrac12+%5Cleft%5B+%5Cfrac%7BG_L%5E2%7D%7BH_L%2B%5Clambda%7D+%2B+%5Cfrac%7BG_R%5E2%7D%7BH_R%2B%5Clambda%7D+-+%5Cfrac%7B%28G_L%2BG_R%29%5E2%7D%7BH_L%2BH_R%2B%5Clambda%7D%5Cright%5D+-+%5Cgamma+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>注意<strong>该特征收益也可作为特征重要性输出的重要依据</strong>。</p>
<p>我们可以发现对于所有的分裂点 <img src="https://www.zhihu.com/equation?tex=a" alt="[公式]">
，我们只要做一遍从左到右的扫描就可以枚举出所有分割的梯度和 <img src="https://www.zhihu.com/equation?tex=G_L" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=G_R" alt="[公式]">
。然后用上面的公式计算每个分割方案的分数就可以了。<font color="red">观察分裂后的收益，我们会发现节点划分不一定会使得结果变好，因为我们有一个引入<strong>新叶子的惩罚项（gamma)</strong>，也就是说引入的分割带来的<strong>增益如果小于一个阀值</strong>的时候，我们可以剪掉这个分割。
</font></p>
<ul>
<li>当一次分裂后，计算新生成的左、右叶子节点样本权重和。如果任一个叶子结点的样本权重低于某一个阈值（最小样本权重和），也会收回此次分裂。</li>
<li>完成完整一棵树的分裂之后，再从底到顶反向检查是否有不满足分裂条件的结点，进行回溯剪枝。</li>
</ul>
<h3><span id="5-xgboost采样是有放回还是无放回的">5、<strong>Xgboost采样是有放回还是无放回的？</strong></span></h3>
<p>xgboost时基于boosting的方法，样本是不放回的 ，每轮样本不重复。</p>
<h3><span id="6-xgboost在工程上有哪些优化为什么要做这些工程化优化">6、<strong>Xgboost在工程上有哪些优化？为什么要做这些工程化优化？</strong></span></h3>
<h4><span id="块结构设计"><strong>块结构设计</strong></span></h4>
<p>我们知道，决策树的学习<strong>最耗时的一个步骤就是在每次寻找最佳分裂点是都需要对特征的值进行排序</strong>。而
<strong><font color="red"> XGBoost
在训练之前对根据特征对数据进行了排序，然后保存到块结构中，并在每个块结构中都采用了稀疏矩阵存储格式（Compressed
Sparse Columns
Format，CSC）进行存储，后面的训练过程中会重复地使用块结构，可以大大减小计算量。</font></strong></p>
<blockquote>
<p>预排序 + 块设计【独立】 + 稀疏矩阵存储</p>
</blockquote>
<ul>
<li><strong>每一个块结构包括一个或多个已经排序好的特征</strong>；</li>
<li><strong>缺失特征值将不进行排序</strong>；</li>
<li>每个特征会存储指向<strong>样本梯度统计值</strong>的索引，方便计算一阶导和二阶导数值；</li>
</ul>
<p>这种块结构存储的特征之间相互独立，方便计算机进行并行计算。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个<strong>特征的增益计算可以同时进行</strong>，这也是
Xgboost 能够实现分布式或者多线程计算的原因。</p>
<h4><span id="缓存访问优化算法索引访问梯度统计-gt-缓存空间不连续"><strong>缓存访问优化算法</strong>【索引访问梯度统计
-&gt; 缓存空间不连续】</span></h4>
<p>块结构的设计可以减少节点分裂时的计算量，但<strong>特征值通过索引访问样本梯度统计值的设计会导致访问操作的内存空间不连续</strong>，这样会造成缓存命中率低，从而影响到算法的效率。</p>
<p>为了解决缓存命中率低的问题，XGBoost
提出了缓存访问优化算法：为每个线程分配一个连续的缓存区，将需要的梯度信息存放在缓冲区中，这样就是实现了非连续空间到连续空间的转换，提高了算法效率。此外适当调整块大小，也可以有助于缓存优化。</p>
<p>于exact greedy算法中, 使用<strong>缓存预取（cache-aware
prefetching）</strong>。具体来说，<strong>对每个线程分配一个连续的buffer</strong>，读取梯度信息并存入Buffer中（这样就实现了非连续到连续的转化）</p>
<h4><span id="核外块计算"><strong>“核外”块计算</strong></span></h4>
<p>当数据量过大时无法将数据全部加载到内存中，只能先将无法加载到内存中的数据暂存到硬盘中，直到需要时再进行加载计算，而这种操作必然涉及到因内存与硬盘速度不同而造成的资源浪费和性能瓶颈。为了解决这个问题，<strong>XGBoost
独立一个线程专门用于从硬盘读入数据，以实现处理数据和读入数据同时进行</strong>。</p>
<p>此外，XGBoost 还用了两种方法来降低硬盘读写的开销：</p>
<ul>
<li><strong>块压缩：</strong>对 Block
进行按列压缩，并在读取时进行解压；</li>
<li><strong>块拆分：</strong>将每个块存储到不同的磁盘中，从多个磁盘读取可以增加吞吐量。</li>
</ul>
<h3><span id="7-xgboost与gbdt有什么联系和不同基模型-算法-工程设计">7、<strong>Xgboost与GBDT有什么联系和不同？</strong>【基模型、算法、工程设计】</span></h3>
<ol type="1">
<li><strong>基分类器</strong>：GBDT 以 CART
作为基分类器，而Xgboost的基分类器不仅支持CART决策树，还支持线性分类器，此时Xgboost相当于带L1和L2正则化项的Logistic回归（分类问题）或者线性回归（回归问题）。</li>
<li><strong>导数信息</strong>：GBDT只用了一阶导数信息，Xgboost中对损失函数进行二阶泰勒展开，引入二阶导数信息，并且XGBoost还支持自定义损失函数，只要损失函数一阶和二阶可导即可。</li>
<li><strong>正则项</strong>：Xgboost的目标函数加入正则项(叶子结点的数目和叶子结点权重的L2模的平方)，相当于分裂预剪枝过程，降低过拟合。</li>
<li><strong>列抽样</strong>：Xgboost支持列采样，与随机森林类似，用于防止过拟合且加速。(列采样就是训练的时候随机使用一部分特征)，也同时支持子采样，即每轮迭代计算可以不使用全部样本，对样本数据进行采样。</li>
<li><strong>缺失值处理</strong>：Xgboost可以处理缺失值(具体，查看上方问答)</li>
<li><strong>并行化</strong>：Xgboost可以在特征维度进行并行化，在训练前预先将每个特征按照特征值大小进行预排序，按块的形式存储，后续可以重复使用这个结构，减小计算量，分裂时可以用多线程并行计算每个特征的增益，最终选增益最大的那个特征去做分裂，提高训练速度。</li>
</ol>
<h3><span id="8-xgboost特征重要性">8、<strong><font color="red">
XGBoost特征重要性</font></strong></span></h3>
<blockquote>
<p><strong>何时使用shap value分析特征重要性？</strong> - 知乎
https://www.zhihu.com/question/527570173/answer/2472253431</p>
</blockquote>
<p>这一思路，通常被用来做<strong>特征筛选</strong>。剔除贡献度不高的尾部特征，增强模型的<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=鲁棒性&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22355884348%22%7D">鲁棒性</a>的同时，起到特征降维的作用。另一个方面，则是用来做<strong>模型的可解释性</strong>。我们期望的结果是：重要的特征是符合业务直觉的；符合业务直觉的特征排名靠前。</p>
<h4><span id="xgb内置的三种特征重要性计算方法">XGB内置的三种特征重要性计算方法</span></h4>
<ul>
<li><strong>weight</strong>：<code>xgb.plot_importance</code>,<strong>子树模型分裂时，用到的特征次数。这里计算的是所有的树。</strong></li>
<li><strong>gain</strong>:<code>model.feature_importances_</code>,信息增益的泛化概念。这里是指，<strong>节点分裂时，该特征带来信息增益（目标函数）优化的平均值。</strong></li>
<li><strong>cover</strong>:<code>model = XGBRFClassifier(importance_type = 'cover')</code>
这个计算方法，需要在定义模型时定义。之后再调用<code>model.feature_importances_</code>
得到的便是基于<code>cover</code>得到的贡献度。<strong>树模型在分裂时，特征下的叶子结点涵盖的样本数除以特征用来分裂的次数。分裂越靠近根部，cover
值越大。</strong></li>
</ul>
<h4><span id="其他重要性计算方法">其他重要性计算方法</span></h4>
<ul>
<li><strong>permutation</strong>:<strong>如果这个特征很重要，那么我们打散所有样本中的该特征，则最后的优化目标将折损。这里的折损程度，就是特征的重要程度。</strong></li>
<li><strong>shap</strong>:<strong>轮流去掉每一个特征，算出剩下特征的贡献情况，以此来推导出被去除特征的边际贡献。该方法是目前唯一的逻辑严密的特征解释方法</strong></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/3TFM6N7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/3TFM6N7/" class="post-title-link" itemprop="url">线性模型（1）线性回归</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-03-08 18:56:01" itemprop="dateCreated datePublished" datetime="2022-03-08T18:56:01+08:00">2022-03-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-20 02:49:51" itemprop="dateModified" datetime="2023-04-20T02:49:51+08:00">2023-04-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/" itemprop="url" rel="index"><span itemprop="name">线性模型</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="一线性回归">一、线性回归</h2>
<p><strong>线性回归假设特征和结果满足线性关系。其实线性关系的表达能力非常强大，每个特征对结果的影响强弱可以由前面的参数体现，而且每个特征变量可以首先映射到一个函数，然后再参与线性计算。</strong>这样就可以表达特征与结果之间的非线性关系。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/posts/3TFM6N7/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/1J1QH0W/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/1J1QH0W/" class="post-title-link" itemprop="url">线性模型（2）逻辑回归</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-03-08 18:56:01" itemprop="dateCreated datePublished" datetime="2022-03-08T18:56:01+08:00">2022-03-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-20 19:08:22" itemprop="dateModified" datetime="2023-04-20T19:08:22+08:00">2023-04-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/" itemprop="url" rel="index"><span itemprop="name">线性模型</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>20k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>36 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><strong>Logistic Regression</strong>
虽然被称为回归，但其实际上是分类模型，并常用于二分类。Logistic
Regression 因其简单、可并行化、可解释强深受工业界喜爱。<strong>Logistic
回归的本质是：假设数据服从这个Logistic分布，然后使用极大似然估计做参数的估计。</strong></p>
<p><strong>逻辑回归的思路</strong>是，先拟合决策边界(不局限于线性，还可以是多项式)，再建立这个边界与分类的概率联系，从而得到了二分类情况下的概率。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/posts/1J1QH0W/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/3AGJJRV/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/3AGJJRV/" class="post-title-link" itemprop="url">机器学习（9）决策树</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-25 17:29:37" itemprop="dateCreated datePublished" datetime="2022-02-25T17:29:37+08:00">2022-02-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-19 20:00:15" itemprop="dateModified" datetime="2023-04-19T20:00:15+08:00">2023-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91/" itemprop="url" rel="index"><span itemprop="name">决策树</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>11k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>21 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="机器学习决策树上id3-c45-cart">【机器学习】决策树（上）——ID3、C4.5、CART</span></h2>
<p><strong>决策树</strong>是一个非常常见并且优秀的机器学习算法，它易于理解、可解释性强，其可作为分类算法，也可用于回归模型。本文将分三篇介绍决策树，第一篇介绍基本树（包括
<strong>ID3、C4.5、CART</strong>），第二篇介绍 <strong>Random
Forest、Adaboost、GBDT</strong>，第三篇介绍 <strong>Xgboost</strong> 和
<strong>LightGBM</strong>。</p>
<table>
<colgroup>
<col style="width: 7%">
<col style="width: 30%">
<col style="width: 30%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>ID3（==分类==）</th>
<th>C4.5（==分类==）</th>
<th>CART（==分类和回归==）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>思想</td>
<td>奥卡姆剃刀：越是小型的决策树越优于大的决策树;ID3
算法的核心思想就是以<strong>信息增益</strong>来度量特征选择，选择信息增益最大的特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间。</td>
<td>C4.5 算法最大的特点是<strong>克服了 ID3
对特征数目的偏重</strong>这一缺点，引入<strong>信息增益率</strong>来作为分类标准。</td>
<td>CART
算法的二分法可以<strong>简化决策树的规模</strong>，提高生成决策树的效率。CART
包含的基本过程有<strong>分裂</strong>，<strong>剪枝</strong>和<strong>树选择</strong>。</td>
</tr>
<tr class="even">
<td><strong>划分标准</strong></td>
<td><strong>信息增益</strong> = 类别熵 - 特征类别熵
<strong>类别熵</strong>：<span class="math inline">\(H(D)=-\sum_{k=1}^{K}
\frac{\left|C_{k}\right|}{|D|} \log _{2}
\frac{\left|C_{k}\right|}{|D|}\)</span>
<strong>特征类别熵</strong>：<span class="math inline">\(H(D \mid
A)=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|}
H\left(D_{i}\right)\)</span></td>
<td>先从候选划分特征中找到信息增益高于平均值的特征，再从中选择<strong>增益率</strong>最高的。</td>
<td><strong>Gini
系数</strong>作为变量的<strong>不纯度量</strong>，<strong>减少了大量的对数运算</strong>；<span class="math inline">\(G i n i(D)=\sum_{k=1}^{K}
\frac{\left|C_{k}\right|}{|D|}\left(1-\frac{\left|C_{k}\right|}{|D|}\right)\)</span></td>
</tr>
<tr class="odd">
<td>剪枝策略</td>
<td><strong>无</strong></td>
<td><strong>悲观剪枝策略</strong></td>
<td>基于<strong>代价复杂度剪枝</strong></td>
</tr>
<tr class="even">
<td>数据差异</td>
<td><strong>离散</strong>数据且<strong>缺失值</strong>敏感</td>
<td><strong>离散</strong>、<strong>连续特征离散化</strong>；【排序+离散化】</td>
<td><strong>连续型、离散型</strong></td>
</tr>
<tr class="odd">
<td><strong>连续值处理</strong></td>
<td>无</td>
<td><strong>排序</strong>并取相邻两样本值的<strong>平均数</strong>。</td>
<td><strong>排序</strong>并取相邻两样本值的<strong>平均数</strong>。<strong>CART
分类树</strong>【<strong>基尼系数</strong>】。<strong>回归树</strong>【<strong>和方差度量</strong>】。</td>
</tr>
<tr class="even">
<td>缺失值处理</td>
<td><strong>无</strong></td>
<td>1、有缺失值特征，用没有缺失的样本子集所占比重来折算；2、将样本同时划分到所有子节点</td>
<td><strong>代理测试</strong>来估计缺失值</td>
</tr>
<tr class="odd">
<td>类别不平衡</td>
<td><strong>无</strong></td>
<td><strong>无</strong></td>
<td><strong>先验机制</strong>：其作用相当于对数据自动重加权，对类别进行均衡。</td>
</tr>
<tr class="even">
<td><strong>==缺点==</strong></td>
<td>1、ID3
没有剪枝策略，容易过拟合；2、信息增益准则对可取值<strong>数目较多的特征有所偏好</strong>，类似“编号”的特征其信息增益接近于
1； 3、只能用于处理离散分布的特征； 没有考虑缺失值。</td>
<td>1、<strong>多叉树</strong>。2、<strong>只能用于分类</strong>。3、熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>。4、驻留于内存的数据集。</td>
<td>熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>。</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>划分标准的差异：</strong>ID3
使用信息增益偏向特征值多的特征，C4.5
使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART
使用基尼指数克服 C4.5 需要求 log
的巨大计算量，偏向于特征值较多的特征。</li>
<li><strong>使用场景的差异：</strong>ID3 和 C4.5
都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5
是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li>
<li><strong>样本数据的差异：</strong>ID3
只能处理离散数据且缺失值敏感，C4.5 和 CART
可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议
C4.5、大样本建议 CART。C4.5
处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART
本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li>
<li><strong>样本特征的差异：</strong>ID3 和 C4.5
层级之间只使用一次特征，==CART 可多次重复使用特征==；</li>
<li><strong>剪枝策略的差异：</strong>ID3 没有剪枝策略，C4.5
是通过<strong>悲观剪枝策略</strong>来修正树的准确性，而 CART
是通过<strong>代价复杂度</strong>剪枝。</li>
</ul>
<h2><span id="1-id3删特征">1. ID3【删特征】</span></h2>
<p>ID3
算法是建立在奥卡姆剃刀[<strong>“切勿浪费较多东西去做，用较少的东西，同样可以做好的事情”</strong>]（用较少的东西，同样可以做好事情）的基础上：越是小型的决策树越优于大的决策树。</p>
<h3><span id="11-思想">1.1 思想</span></h3>
<p>从信息论的知识中我们知道：信息熵越大，从而样本纯度越低，。ID3
算法的核心思想就是以<strong>信息增益</strong>来度量特征选择，选择信息增益最大的特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间（C4.5
也是贪婪搜索）。 其大致步骤为：</p>
<ol type="1">
<li>初始化特征集合和数据集合；</li>
<li>计算数据集合信息熵和所有特征的条件熵，选择信息增益最大的特征作为当前决策节点；</li>
<li>更新数据集合和特征集合（删除上一步使用的特征，并按照特征值来划分不同分支的数据集合）；</li>
<li>重复 2，3 两步，若子集值包含单一特征，则为分支叶子节点。</li>
</ol>
<h3><span id="12-划分标准">1.2 划分标准</span></h3>
<p>ID3 使用的分类标准是信息增益，它表示得知特征 A
的信息而使得样本集合不确定性减少的程度。</p>
<p>数据集的<strong>信息熵</strong>：</p>
<p><span class="math inline">\(H(D)=-\sum_{k=1}^{K}
\frac{\left|C_{k}\right|}{|D|} \log _{2}
\frac{\left|C_{k}\right|}{|D|}\)</span></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=C_k" alt="[公式]"> 表示集合 D 中属于第 k 类样本的样本子集。针对某个特征
A，对于数据集 D 的条件熵 <span class="math inline">\(H(D \mid
A)\)</span>为：</p>
<p><span class="math inline">\(\begin{aligned} H(D \mid A)
&amp;=\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} H\left(D_{i}\right)
\\ &amp;=-\sum_{i=1}^{n}
\frac{\left|D_{i}\right|}{|D|}\left(\sum_{k=1}^{K} \frac{\left|D_{i
k}\right|}{\left|D_{i}\right|} \log _{2} \frac{\left|D_{i
k}\right|}{\left|D_{i}\right|}\right) \end{aligned}\)</span></p>
<p><strong>信息增益</strong> = 信息熵 - 条件熵。信息增益越大表示使用特征
A 来划分所获得的“纯度提升越大”。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=Gain%28D%2CA%29%3DH%28D%29-H%28D%7CA%29++%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>信息增益越大表示使用特征 A 来划分所获得的“纯度提升越大”。</p>
<h3><span id="13缺点没有剪枝-特征偏好-缺失值">1.3
缺点【没有剪枝、特征偏好、缺失值】</span></h3>
<ul>
<li>ID3 没有剪枝策略，容易过拟合；</li>
<li>信息增益准则==对可取值数目较多的特征==有所偏好，类似“编号”的特征其信息增益接近于
1；</li>
<li>只能用于处理离散分布的特征；</li>
<li>没有考虑缺失值。</li>
</ul>
<h2><span id="2-c45">2. C4.5</span></h2>
<p>C4.5 算法最大的特点是克服了 ID3
对==特征数目的偏重==这一缺点，引入信息增益率来作为分类标准。</p>
<p>C4.5 相对于 ID3 的缺点对应有以下改进方式：</p>
<ul>
<li>引入<strong>悲观剪枝策略进行后剪枝</strong>；</li>
<li>引入<strong>信息增益率</strong>作为划分标准；</li>
<li><strong>将连续特征离散化</strong>，假设 n 个样本的连续特征 A 有 m
个取值，C4.5 将其排序并取相邻两样本值的平均数共 m-1
个划分点，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点；</li>
<li>对于<strong>缺失值的处理</strong>可以分为两个子问题：</li>
<li>问题一：在特征值缺失的情况下进行划分特征的选择？（即如何计算特征的信息增益率）
<ul>
<li>C4.5
的做法是：对于具有缺失值特征，用没有缺失的样本子集所占比重来折算；</li>
</ul></li>
<li>问题二：选定该划分特征，对于缺失该特征值的样本如何处理？（即到底把这个样本划分到哪个结点里）
<ul>
<li>C4.5
的做法是：将样本同时划分到所有子节点，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</li>
</ul></li>
</ul>
<h3><span id="22-划分标准">2.2 划分标准</span></h3>
<p>利用信息增益率可以克服信息增益的缺点，其公式为</p>
<p><span class="math inline">\(\begin{aligned}
\operatorname{Gain}_{\text {ratio }}(D, A)
&amp;=\frac{\operatorname{Gain}(D, A)}{H_{A}(D)} \\
H_{A}(D)=-\sum_{i=1}^{n} \frac{\left|D_{i}\right|}{|D|} \log _{2}
\frac{\left|D_{i}\right|}{|D|} \end{aligned}\)</span></p>
<p>信息增益率对可取值较少的特征有所偏好（分母越小，整体越大），因此 C4.5
并不是直接用增益率最大的特征进行划分，而是使用一个<strong>启发式方法</strong>：先从候选划分特征中找到信息增益高于平均值的特征，再从中选择增益率最高的。</p>
<h3><span id="23-剪枝策略">2.3 剪枝策略</span></h3>
<p>为什么要剪枝：<strong>过拟合的树在泛化能力的表现非常差。</strong></p>
<p><strong>预剪枝和悲观剪枝</strong></p>
<h4><span id="231-预剪枝"><strong>2.3.1 预剪枝</strong></span></h4>
<p>在节点划分前来确定是否继续增长，及早停止增长的主要方法有：</p>
<ul>
<li>节点内数据样本低于<strong>某一阈值</strong>；</li>
<li>所有节点特征都已分裂；</li>
<li>节点划分前准确率比划分后准确率高。</li>
</ul>
<p>预剪枝不仅可以降低过拟合的风险而且还可以减少训练时间，但另一方面它是基于“贪心”策略，会带来欠拟合风险。</p>
<h4><span id="232后剪枝悲观剪枝方法-httpgitlinuxnet2019-06-04-c45"><strong>2.3.2
后剪枝</strong>【悲观剪枝方法】 http://gitlinux.net/2019-06-04-C45/</span></h4>
<p>在已经生成的决策树上进行剪枝，从而得到简化版的剪枝决策树。</p>
<p>C4.5
采用的<strong>悲观剪枝方法</strong>，用递归的方式从低往上针对每一个非叶子节点，评估用一个最佳叶子节点去代替这课子树是否有益。如果剪枝后与剪枝前相比其错误率是保持或者下降，则这棵子树就可以被替换掉。<strong>C4.5
通过训练数据集上的错误分类数量来估算未知样本上的错误率</strong>。</p>
<p>后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但同时其训练时间会大的多。</p>
<h3><span id="24-缺点">2.4 缺点</span></h3>
<ul>
<li><strong>剪枝策略</strong>可以再优化；</li>
<li>C4.5 用的是<strong>多叉树</strong>，用二叉树效率更高；</li>
<li>C4.5 只能用于<strong>分类</strong>；</li>
<li>C4.5
使用的熵模型拥有大量耗时的<strong>对数运算</strong>，连续值还有<strong>排序运算</strong>；</li>
<li>C4.5
在构造树的过程中，<strong>对数值属性值需要按照其大小进行排序</strong>，从中选择一个分割点，所以只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时，程序无法运行。</li>
</ul>
<h2><span id="3-cart">3. CART</span></h2>
<p>ID3 和 C4.5
虽然在对训练样本集的学习中可以尽可能多地挖掘信息，但是其生成的决策树分支、规模都比较大，CART
算法的二分法可以简化决策树的规模，提高生成决策树的效率。</p>
<h3><span id="31-思想">3.1 思想</span></h3>
<p>CART 包含的基本过程有分裂，剪枝和树选择。</p>
<ul>
<li><strong>分裂：</strong>分裂过程是一个二叉递归划分过程，其输入和预测特征既可以是连续型的也可以是离散型的，CART
没有停止准则，会一直生长下去；</li>
<li><strong>剪枝：</strong>采用<strong>代价复杂度剪枝</strong>，从最大树开始，每次选择训练数据熵对整体性能贡献最小的那个分裂节点作为下一个剪枝对象，直到只剩下根节点。CART
会产生一系列嵌套的剪枝树，需要从中选出一颗最优的决策树；</li>
<li><strong>树选择：</strong>用单独的测试集评估每棵剪枝树的预测性能（也可以用交叉验证）。</li>
</ul>
<p>CART 在 C4.5 的基础上进行了很多提升。</p>
<ul>
<li>C4.5 为多叉树，运算速度慢，CART
为<strong>二叉树</strong>，运算速度快；</li>
<li>C4.5 只能分类，CART 既可以分类也可以<strong>回归</strong>；</li>
<li>CART 使用 ==<strong>Gini
系数作为变量的不纯度量</strong>，减少了<strong>大量的对数运算</strong>；==</li>
<li>CART 采用<strong>代理测试来估计缺失值</strong>，而 C4.5
以不同概率划分到不同节点中；</li>
<li>CART 采用<strong>“基于代价复杂度剪枝”方法进行剪枝，而 C4.5
采用悲观剪枝方法</strong>。</li>
</ul>
<h3><span id="32-划分标准">3.2 划分标准</span></h3>
<p><strong>熵模型拥有大量耗时的对数运算</strong>，基尼指数在简化模型的同时还保留了熵模型的优点。基尼指数代表了模型的不纯度，基尼系数越小，不纯度越低，特征越好。这和信息增益（率）正好相反。</p>
<p><span class="math inline">\(\begin{aligned} \operatorname{Gini}(D)
&amp;=\sum_{k=1}^{K}
\frac{\left|C_{k}\right|}{|D|}\left(1-\frac{\left|C_{k}\right|}{|D|}\right)
=1- \sum_{k=1}^{K}\left(\frac{\left|C_{k}\right|}{|D|}\right)^{2}
&amp;\operatorname{Gini}(D \mid A) =\sum_{i=1}^{n}
\frac{\left|D_{i}\right|}{|D|} \operatorname{Gini}\left(D_{i}\right)
\end{aligned}\)</span></p>
<p>==<strong>基尼指数</strong>反映了从<strong>数据集中随机抽取两个样本，其类别标记不一致的概率</strong>==。因此基尼指数越小，则数据集纯度越高。基尼指数偏向于特征值较多的特征，类似信息增益。基尼指数可以用来度量任何不均匀分布，是介于
0~1 之间的数，0 是完全相等，1
是完全不相等，<strong>基尼指数可以理解为熵模型的一阶泰勒展开。</strong></p>
<blockquote>
<p><strong><em>基尼指数是信息熵中﹣logP在P=1处一阶泰勒展开后的结果！所以两者都可以用来度量数据集的纯度</em></strong></p>
</blockquote>
<h3><span id="33-缺失值处理">3.3 缺失值处理</span></h3>
<p>上文说到，模型对于缺失值的处理会分为两个子问题：</p>
<ul>
<li><strong>如何在特征值缺失的情况下进行划分特征的选择？</strong></li>
</ul>
<p>对于问题 1，<strong>CART
一开始严格要求分裂特征评估时只能使用在该特征上没有缺失值的那部分数据，在后续版本中，CART
算法使用了一种惩罚机制来抑制提升值，从而反映出缺失值的影响</strong>（例如，如果一个特征在节点的
20% 的记录是缺失的，那么这个特征就会减少 20% 或者其他数值）。</p>
<ul>
<li><strong>选定该划分特征，模型对于缺失该特征值的样本该进行怎样处理？</strong></li>
</ul>
<p>对于问题 2，CART
算法的机制是为树的每个节点都找到<strong>代理分裂器</strong>，无论在训练数据上得到的树是否有缺失值都会这样做。在代理分裂器中，特征的分值必须超过默认规则的性能才有资格作为代理（即代理就是<strong>代替缺失值特征作为划分特征的特征</strong>），<strong>当
CART
树中遇到缺失值时，这个实例划分到左边还是右边是决定于其排名最高的代理，如果这个代理的值也缺失了，那么就使用排名第二的代理</strong>，以此类推，如果所有代理值都缺失，那么默认规则就是把样本划分到较大的那个子节点。代理分裂器可以确保无缺失训练数据上得到的树可以用来处理包含确实值的新数据。</p>
<h3><span id="34-剪枝策略">3.4 剪枝策略</span></h3>
<p><strong>基于代价复杂度的剪枝</strong>:https://www.bilibili.com/read/cv11066239</p>
<p>采用一种<strong>“基于代价复杂度的剪枝</strong>”方法进行<strong>后剪枝</strong>，这种方法会生成一系列树，每<strong>个树都是通过将前面的树的某个或某些子树替换成一个叶节点而得到的，这一系列树中的最后一棵树仅含一个用来预测类别的叶节点</strong>。然后用一种成本复杂度的度量准则来判断哪棵子树应该被一个预测类别值的叶节点所代替。<strong>这种方法需要使用一个单独的测试数据集来评估所有的树，根据它们在测试数据集熵的分类性能选出最佳的树</strong>。</p>
<blockquote>
<p>从完整子树 <span class="math inline">\(T0\)</span> 开始， 通过在
<span class="math inline">\(Ti\)</span>
子树序列中裁剪真实误差最小【考虑叶子节点的个数】的子树，得到 <span class="math inline">\(Ti+1\)</span>。</p>
<p><img src="image-20220321203204744.png" alt="image-20220321203204744" style="zoom: 25%;">【剪枝之后的误差
- 剪枝前的误差 / 叶子节点数 - 1】</p>
<p>每次误差增加率最小的节点，得到一系列的子树，从中选择效果最好的【独立剪枝数据集】和【K折交叉验证】</p>
</blockquote>
<p><img src="image-20220320215056933.png" alt="image-20220320215056933" style="zoom:50%;"></p>
<p>我们来看具体看一下代价复杂度剪枝算法：</p>
<p>首先我们将最大树称为 <img src="https://www.zhihu.com/equation?tex=T_0" alt="[公式]">
，我们希望减少树的大小来防止过拟合，但又担心去掉节点后预测误差会增大，所以我们定义了一个损失函数来达到这两个变量之间的平衡。损失函数定义如下：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=C_%5Calpha%28T%29%3DC%28T%29%2B%5Calpha%7CT%7C++%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p><img src="https://www.zhihu.com/equation?tex=T" alt="[公式]">
为任意子树， <img src="https://www.zhihu.com/equation?tex=C%28T%29" alt="[公式]"> 为预测误差， <img src="https://www.zhihu.com/equation?tex=%7CT%7C" alt="[公式]"> 为子树
<img src="https://www.zhihu.com/equation?tex=T" alt="[公式]">
的叶子节点个数， <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> 是参数， <img src="https://www.zhihu.com/equation?tex=C%28T%29" alt="[公式]">
衡量训练数据的拟合程度， <img src="https://www.zhihu.com/equation?tex=%7CT%7C" alt="[公式]">
衡量树的复杂度， <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> <strong>权衡拟合程度与树的复杂度</strong>。</p>
<h3><span id="35-类别不平衡">3.5 类别不平衡</span></h3>
<p>CART
的一大优势在于：无论训练数据集有多失衡，它都可以将其子冻消除不需要建模人员采取其他操作。</p>
<p>CART
使用了一种先验机制，其作用相当于对类别进行加权。这种先验机制嵌入于 CART
算法判断分裂优劣的运算里，在 CART
默认的分类模式中，总是要计算每个节点关于根节点的类别频率的比值，这就相当于对数据自动重加权，对类别进行均衡。</p>
<p>对于一个二分类问题，节点 node 被分成类别 1 当且仅当：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cfrac%7BN_1%28node%29%7D%7BN_1%28root%29%7D+%3E+%5Cfrac%7BN_0%28node%29%7D%7BN_0%28root%29%7D++%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>比如二分类，根节点属于 1 类和 0 类的分别有 20 和 80 个。在子节点上有
30 个样本，其中属于 1 类和 0 类的分别是 10 和 20 个。如果
10/20&gt;20/80，该节点就属于 1 类。</p>
<p>通过这种计算方式就无需管理数据真实的类别分布。假设有 K
个目标类别，就可以确保根节点中每个类别的概率都是
1/K。这种默认的模式被称为“先验相等”。</p>
<p>先验设置和加权不同之处在于先验不影响每个节点中的各类别样本的数量或者份额。先验影响的是每个节点的类别赋值和树生长过程中分裂的选择。</p>
<h3><span id="36-连续值处理">3.6 连续值处理</span></h3>
<h4><span id="361-分类树">3.6.1 分类树</span></h4>
<ul>
<li><p><strong><font color="red">如果特征值是连续值：CART的处理思想与C4.5是相同的，即将连续特征值离散化。唯一不同的地方是度量的标准不一样，</font></strong>
<strong>CART采用基尼指数，而C4.5采用信息增益比</strong>。</p></li>
<li><p>如果当前节点为连续属性，<strong>CART树中该属性（剩余的属性值）后面还可以参与子节点的产生选择过程</strong>。</p></li>
</ul>
<h3><span id="37-回归树">3.7 回归树</span></h3>
<p><strong>CART（Classification and Regression
Tree，分类回归树），从名字就可以看出其不仅可以用于分类，也可以应用于回归</strong>。其回归树的建立算法上与分类树部分相似，这里简单介绍下不同之处。</p>
<h5><span id="连续值处理rss残差平方和"><strong>连续值处理</strong>：==RSS<strong>残差平方和</strong>==</span></h5>
<p>对于连续值的处理，<strong>CART
分类树采用基尼系数的大小来度量特征的各个划分点</strong>。<strong>在回归模型中，我们使用常见的和方差度量方式</strong>，对于任意划分特征
A，对应的任意划分点 s 两边划分成的数据集 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]"> ，求出使
<img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和
<img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]">
各自<strong>集合的均方差最小</strong>，同时 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]">
的均方差之和最小所对应的特征和特征值划分点。表达式为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=+%5Cmin%5Climits_%7Ba%2Cs%7D%5CBigg%5B%5Cmin%5Climits_%7Bc_1%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_1%7D%28y_i+-+c_1%29%5E2+%2B+%5Cmin%5Climits_%7Bc_2%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_2%7D%28y_i+-+c_2%29%5E2%5CBigg%5D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>其中， <img src="https://www.zhihu.com/equation?tex=c_1" alt="[公式]"> 为 <img src="https://www.zhihu.com/equation?tex=D_1" alt="[公式]"> 数据集的样本输出均值， <img src="https://www.zhihu.com/equation?tex=c_2" alt="[公式]"> 为 <img src="https://www.zhihu.com/equation?tex=D_2" alt="[公式]">
数据集的样本输出均值。</p>
<h5><span id="预测方式"><strong>预测方式</strong></span></h5>
<p>对于决策树建立后做预测的方式，上面讲到了 CART
分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。而回归树输出不是类别，它采用的是用最终叶子的均值或者中位数来预测输出结果。</p>
<h3><span id="37cart分类树建模时预测变量中存在连续和离散时会自动分别进行处理吗">3.7
CART分类树建模时，预测变量中存在连续和离散时，会自动分别进行处理吗？</span></h3>
<blockquote>
<p>在使用sklearn的决策树CART建模时，预测变量中存在连续和离散时，会自动分别进行处理吗？
- 月来客栈的回答 - 知乎
https://www.zhihu.com/question/472579561/answer/2002434993</p>
</blockquote>
<p><strong>对于这种连续型的特征变量，Sklearn中的具体做法（包括ID3、CART、随机森林等）是先对连续型特征变量进行排序处理</strong>，<strong><font color="red">
然后取所有连续两个值的均值来离散化整个连续型特征变量。</font></strong></p>
<p>假设现在某数据集其中一个特征维度为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5B0.5%2C+0.2%2C+0.8%2C+0.9%2C+1.2%2C+2.1%2C+3.2%2C+4.5%5D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>则首先需要对其进行排序处理，排序后的结果为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5B0.2%2C+0.5%2C+0.8%2C+0.9%2C+1.2%2C+2.1%2C+3.2%2C+4.5%5D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>接着再计算所有连续两个值之间的平均值：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5B0.35%2C+0.65%2C+0.85%2C+1.05%2C+1.65%2C+2.65%2C+3.85%5D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>这样，便得到了该特征离散化后的结果。最后在构造<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=决策树&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A%222002434993%22%7D">决策树</a>时，只需要使用式最后离散化后的特征进行划分指标的计算即可。同时，值得一说的地方是<strong>目前Sklearn在实际处理时，会把所有的特征均看作连续型变量进行处理</strong>。</p>
<p>下图所示为iris数据集根据sklearn中CART算法所建模的决策树的可视化结果：</p>
<p><img src="https://picx.zhimg.com/v2-9081bc3cd5f2ec069212b79d5c5ff7d3_b.jpg" alt="img" style="zoom:50%;"></p>
<p>从图中可以看到，<code>petal width</code>这个特征在前两次分类时的分割点分别为0.8和1.75。下面先来看看原始特征<code>petal width</code>的取值情况：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1.</span>  <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">1.4</span> <span class="number">2.5</span> <span class="number">1.3</span> <span class="number">2.1</span> <span class="number">1.5</span> <span class="number">0.2</span> <span class="number">2.</span>  <span class="number">1.</span>  <span class="number">0.2</span> <span class="number">0.3</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">0.2</span> <span class="number">0.5</span> <span class="number">1.3</span> <span class="number">0.2</span> <span class="number">1.2</span> <span class="number">2.2</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">2.</span>  <span class="number">0.2</span> <span class="number">1.8</span> <span class="number">1.9</span> <span class="number">1.</span>  <span class="number">1.5</span> <span class="number">2.3</span> <span class="number">1.3</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">1.9</span> <span class="number">0.2</span> <span class="number">0.2</span> <span class="number">1.1</span> <span class="number">1.7</span> <span class="number">0.2</span> <span class="number">2.4</span> <span class="number">0.2</span> <span class="number">0.6</span> <span class="number">1.8</span> <span class="number">1.1</span> <span class="number">2.3</span> <span class="number">1.6</span> <span class="number">1.4</span> <span class="number">2.3</span> <span class="number">1.3</span> <span class="number">0.2</span> <span class="number">0.1</span> <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">0.3</span> <span class="number">0.2</span> <span class="number">1.5</span> <span class="number">2.4</span> <span class="number">0.3</span> <span class="number">2.1</span> <span class="number">2.5</span> <span class="number">0.2</span> <span class="number">1.4</span> <span class="number">1.5</span> <span class="number">1.8</span> <span class="number">1.4</span> <span class="number">2.3</span> <span class="number">0.2</span> <span class="number">2.1</span> <span class="number">1.5</span> <span class="number">2.</span>  <span class="number">1.</span>  <span class="number">1.4</span> <span class="number">1.4</span> <span class="number">0.3</span> <span class="number">1.3</span> <span class="number">1.2</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">1.8</span> <span class="number">2.1</span> <span class="number">0.4</span> <span class="number">1.</span>  <span class="number">2.5</span> <span class="number">1.6</span> <span class="number">0.1</span> <span class="number">2.4</span> <span class="number">0.2</span> <span class="number">1.5</span> <span class="number">1.9</span> <span class="number">1.8</span> <span class="number">1.3</span> <span class="number">1.8</span> <span class="number">1.3</span> <span class="number">1.3</span> <span class="number">2.</span>  <span class="number">1.8</span> <span class="number">0.2</span> <span class="number">1.3</span> <span class="number">1.7</span> <span class="number">0.2</span> <span class="number">1.2</span> <span class="number">2.1</span>]</span><br></pre></td></tr></table></figure>
<p>可以发现上面并没有0.8和1.75这两个取值。接着按上面的方法先排序，再取相邻两个值的平均作为离散化的特征，其结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0.1</span>, <span class="number">0.15000000000000002</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, </span><br><span class="line"><span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.25</span>, <span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.35</span>, <span class="number">0.4</span>, <span class="number">0.4</span>,</span><br><span class="line"> <span class="number">0.45</span>, <span class="number">0.55</span>, <span class="number">0.8</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.05</span>, <span class="number">1.1</span>, <span class="number">1.15</span>, <span class="number">1.2</span>, <span class="number">1.2</span>, <span class="number">1.25</span>, <span class="number">1.3</span>,</span><br><span class="line"> <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.3</span>, <span class="number">1.35</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.4</span>, <span class="number">1.45</span>, <span class="number">1.5</span>, </span><br><span class="line"><span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.5</span>, <span class="number">1.55</span>, <span class="number">1.6</span>, <span class="number">1.65</span>, <span class="number">1.7</span>, <span class="number">1.75</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, </span><br><span class="line"><span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.8</span>, <span class="number">1.85</span>, <span class="number">1.9</span>, <span class="number">1.9</span>, <span class="number">1.95</span>, <span class="number">2.0</span>, <span class="number">2.0</span>, <span class="number">2.0</span>, <span class="number">2.05</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, <span class="number">2.1</span>, </span><br><span class="line"><span class="number">2.1500000000000004</span>, <span class="number">2.25</span>, <span class="number">2.3</span>, <span class="number">2.3</span>, <span class="number">2.3</span>, <span class="number">2.3499999999999996</span>, <span class="number">2.4</span>, <span class="number">2.4</span>, <span class="number">2.45</span>, <span class="number">2.5</span>, <span class="number">2.5</span>]</span><br></pre></td></tr></table></figure>
<h2><span id="4-总结">4. 总结</span></h2>
<p>最后通过总结的方式对比下 ID3、C4.5 和 CART 三者之间的差异。</p>
<p>除了之前列出来的划分标准、剪枝策略、连续值确实值处理方式等之外，我再介绍一些其他差异：</p>
<ul>
<li><strong>划分标准的差异：</strong>ID3
使用信息增益偏向特征值多的特征，C4.5
使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART
使用基尼指数克服 C4.5 需要求 log
的巨大计算量，偏向于特征值较多的特征。</li>
<li><strong>使用场景的差异：</strong>ID3 和 C4.5
都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5
是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li>
<li><strong>样本数据的差异：</strong>ID3
只能处理离散数据且缺失值敏感，C4.5 和 CART
可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议
C4.5、大样本建议 CART。C4.5
处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART
本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li>
<li><strong>样本特征的差异：</strong>ID3 和 C4.5
层级之间只使用一次特征，CART 可多次重复使用特征（连续型）；</li>
<li><strong>剪枝策略的差异：</strong>ID3 没有剪枝策略，C4.5
是通过悲观剪枝策略来修正树的准确性，而 CART 是通过代价复杂度剪枝。</li>
</ul>
<h2><span id="一-决策树">一、决策树</span></h2>
<h3><span id="11介绍决策树id2-c45-cart-3种决策树及其区别和适应场景">1.1
介绍决策树ID2、C4.5、CART, 3种决策树及其区别和适应场景？</span></h3>
<h3><span id="12-决策树处理连续值的方法">1.2 决策树处理连续值的方法?</span></h3>
<p><strong>ID3 只能离散型</strong>。<strong>C4.5
将连续特征离散化</strong>，假设 n 个样本的连续特征 A 有 m
个取值，<strong>C4.5 将其排序并取相邻两样本值的平均数共 m-1
个划分点</strong>，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点；</p>
<p><strong>CART分类树：离散化+基尼指数，</strong></p>
<p><strong>CART回归树：均方差之和度量方式</strong></p>
<figure>
<img src="https://www.zhihu.com/equation?tex=+%5Cmin%5Climits_%7Ba%2Cs%7D%5CBigg%5B%5Cmin%5Climits_%7Bc_1%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_1%7D%28y_i+-+c_1%29%5E2+%2B+%5Cmin%5Climits_%7Bc_2%7D%5Csum%5Climits_%7Bx_i+%5Cin+D_2%7D%28y_i+-+c_2%29%5E2%5CBigg%5D+%5C%5C" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h3><span id="13-决策树处理缺失值的方式">1.3 决策树处理缺失值的方式？</span></h3>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/84519568">ID3、c4.5、cart、rf到底是如何处理缺失值的？</a></p>
</blockquote>
<h4><span id="131在特征值缺失的情况下进行划分特征的选择">1.3.1
<strong>在特征值缺失的情况下进行划分特征的选择？</strong></span></h4>
<p><strong>ID3</strong> 没有缺失值处理；</p>
<p><strong>C4.5</strong>：对于具有缺失值特征，用没有缺失的<strong>样本子集所占比重来折算</strong>；</p>
<p><strong>CART</strong>：<strong>初期</strong>：分裂特征评估时只能使用在该特征上没有缺失值的那部分数据<strong>；后续</strong>：CART
算法使用了一种惩罚机制来抑制提升值，从而反映出缺失值的影响。</p>
<h4><span id="132选定该划分特征对于缺失该特征值的样本如何处理">1.3.2
<strong>选定该划分特征，对于缺失该特征值的样本如何处理？</strong></span></h4>
<p><strong>ID3</strong> 没有缺失值处理；</p>
<p><strong>C4.5</strong>：<strong>将样本同时划分到所有子节点</strong>，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</p>
<p>==<strong>CART</strong>：==sklearn中的cart的实现是没有对缺失值做任何处理的，也就是说sklearn的cart无法处理存在缺失值的特征。</p>
<h3><span id="14-决策树如何剪枝">1.4 决策树如何剪枝？</span></h3>
<ul>
<li><strong>预剪枝</strong>：在树的生成过程中，提前停止生长。简单，适合解决大规模问题。
<ul>
<li>深度</li>
<li>节点样本数</li>
<li>对测试集准确率的提升过小</li>
</ul></li>
<li><strong>后剪枝</strong>：生成一颗完全生长的二叉树，从低向上剪枝，将子树删除用叶子节点代替。【类别：多数投票】常见的剪枝方法：错误率降低剪枝（REP）、<strong>悲观剪枝（PEP）、代价复杂度剪枝（CCP）</strong>、最小误差剪枝（MEP）等。</li>
</ul>
<p><strong>代价复杂度剪枝（CCP）【CART树】</strong></p>
<p>从完整子树 <span class="math inline">\(T0\)</span> 开始， 通过在
<span class="math inline">\(Ti\)</span>
子树序列中裁剪真实误差最小【考虑叶子节点的个数】的子树，得到 <span class="math inline">\(Ti+1\)</span>。</p>
<p><img src="image-20220321203204744.png" alt="image-20220321203204744" style="zoom: 25%;">【剪枝之后的误差
- 剪枝前的误差 / 叶子节点数 - 1】</p>
<p>每次误差增加率最小的节点，得到一系列的子树，从中选择效果最好的【独立剪枝数据集】和【K折交叉验证】</p>
<h3><span id="15决策树特征选择特征重要性判断">1.5
决策树特征选择？特征重要性判断？</span></h3>
<p><strong>XGBoost</strong>：</p>
<ul>
<li><p>该特征在所有树中被用作分割样本的特征的总次数。</p></li>
<li><p>该特征在其出现过的所有树中产生的平均增益。</p></li>
<li><p>该特征在其出现过的所有树中的平均覆盖范围。</p>
<blockquote>
<p>注意：覆盖范围这里指的是一个特征用作分割点后，其影响的样本数量，即有多少样本经过该特征分割到两个子节点。</p>
</blockquote></li>
</ul>
<h3><span id="16-svm-lr-决策树的对比">1.6 SVM、LR、决策树的对比？</span></h3>
<blockquote>
<p>逻辑回归，决策树，支持向量机 选择方案:
https://cloud.tencent.com/developer/article/1435642</p>
<p>广义线性模型？</p>
<p>sigmod、softmax</p>
<p>为什么逻辑回归的连续值也需要离散化？</p>
<p>为什么逻辑回归要用交叉熵？</p>
<p>交叉熵和KL散度（相对熵）和GAN的损失函数的区别？</p>
</blockquote>
<table>
<colgroup>
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 27%">
<col style="width: 27%">
<col style="width: 6%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>线性回归</th>
<th>LR 逻辑回归</th>
<th>SVM</th>
<th>朴素贝叶斯</th>
<th>决策树</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>场景</td>
<td>【回归问题】</td>
<td>逻辑回归 = 线性回归 + Sigmoid
函数（非线形）【分类问题】==【参数模型】==【统计方法】</td>
<td>【分类问题】【几何方法】【非参数模型】</td>
<td>【生成式模型】</td>
<td>【分类问题】【回归问题】【非参数模型】</td>
</tr>
<tr class="even">
<td><strong>思想</strong></td>
<td></td>
<td><strong>思路：</strong>先拟合决策边界(不局限于线性，还可以是多项式)，再建立这个边界与分类的概率联系，从而得到了二分类情况下的概率。<strong>细节</strong>：通过<strong>非线性映射减小了离分类平面较远的点的权重</strong>，相对提升了与分类最相关的数据点的权重；</td>
<td><strong>思想</strong>：SVM
想要的就是找到各类样本点到超平面的距离最远，也就是找到最大间隔超平面。</td>
<td></td>
<td><strong>思想</strong>：用启发算法来度量特征选择，选择特征进行分裂。算法采用自顶向下的贪婪搜索遍历可能的决策树空间。</td>
</tr>
<tr class="odd">
<td><strong>关键样本</strong></td>
<td></td>
<td><strong>所有样本</strong>（通过非线性映射，大大减小了离分类平面较远的点的权重）</td>
<td><strong>支持向量</strong>（超平面到距离最近的不同标记样本集合）</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><strong>目标函数</strong></td>
<td></td>
<td><span class="math inline">\(y=\frac{1}{1+e^{-\left(w^{T}
x+b\right)}}\)</span> 【极大似然函数】</td>
<td><img src="image-20220322131856478.png" alt="image-20220322131856478" style="zoom:150%;">
<img src="https://pic2.zhimg.com/80/v2-0e87b3bf410cd798efd05a2837b83589_1440w.png" alt="img"></td>
<td></td>
<td>信息增益、信息增益率、Gini指数</td>
</tr>
<tr class="odd">
<td><strong>损失函数</strong></td>
<td></td>
<td><img src="https://pic3.zhimg.com/80/v2-ee1ddd22da5171fa44e079582cefe20a_1440w.png" alt="img" style="zoom:150%;"></td>
<td><strong><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/47746939">HingeLoss</a></strong>【合页损失函数】：<img src="https://www.zhihu.com/equation?tex=%5Csum_%7Bi%3D1%7D%5EN%5B1-y_i%28w%C2%B7x_i+%2B+b%29%5D_%2B+%2B+%5Clambda%7C%7Cw%7C%7C%5E2+%5C%5C+%5Bz%5D_%2B+%3D+%5Cbegin%7Bequation%7D+%5Cleft%5C%7B++++++++++++++%5Cbegin%7Barray%7D%7Blr%7D+++++++++++z%2C+z%3E0+%26++%5C%5C++++++++++++++0.z%5Cleq0+%26+++++++++++++++%5Cend%7Barray%7D++%5Cright.+%5Cend%7Bequation%7D+%5C%5C+" alt="[公式]" style="zoom:150%;"></td>
<td></td>
<td>信息增益、信息增益率、Gini指数【方差和】</td>
</tr>
<tr class="even">
<td>决策面</td>
<td></td>
<td>线性可分</td>
<td>【核函数映射】从而使得样本数据线性可分</td>
<td></td>
<td>矩形【非线性】</td>
</tr>
<tr class="odd">
<td>连续值处理</td>
<td></td>
<td>==离散化？==</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><strong>输出</strong></td>
<td></td>
<td>类别的概率</td>
<td>类别</td>
<td></td>
<td>类别、回归</td>
</tr>
<tr class="odd">
<td>过拟合</td>
<td></td>
<td><strong>正则化</strong> L1:
<img src="image-20220316144906846.png" alt="image-20220316144906846" style="zoom:50%;">
L2:
<img src="image-20220316145437180.png" alt="image-20220316145437180" style="zoom:50%;"></td>
<td>\</td>
<td></td>
<td>预剪枝和后剪枝</td>
</tr>
<tr class="even">
<td>优势</td>
<td></td>
<td><strong>本质其实是为了模型参数服从某一分布</strong>；1、对观测样本的概率值输出
2、实现简单高效3、<strong>多重共线性的问题可以通过L2正则化来应对</strong>。
4、大量的工业界解决方案5、支持online learning</td>
<td>1、可以处理<strong>高维特征</strong>
2、使用<strong>核函数</strong>轻松应对非线的性特征空间
3、分类面不依赖于所有数据4、关重要的<strong>关键样本</strong></td>
<td></td>
<td>1、直观的决策过程 2、能够处理非线性特征
3、考虑了<strong>特征相关性</strong></td>
</tr>
<tr class="odd">
<td>劣势</td>
<td></td>
<td>1、特征空间太大时表现不太好 2、对于大量的分类变量无能为力
3、对于非线性特征需要做特征变换 4、依赖所有的样本数据</td>
<td>1、<strong>对于大量的观测样本，效率会很低</strong>
2、找到一个“合适”的核函数还是很tricky的</td>
<td></td>
<td>1、极易过拟合 2、无法输出score，只能给出直接的分类结果</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong><a target="_blank" rel="noopener" href="https://blog.csdn.net/Alphonse_Huang/article/details/114278377">多重共线性问题</a></strong></p>
<p>多重共线性问题就是指一个解释变量的变化引起另一个解释变量地变化。多重共<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=线性&amp;spm=1001.2101.3001.7020">线性</a>是使用线性回归算法时经常要面对的一个问题。在其他算法中，例如决策树或者朴素贝叶斯，前者的建模过程时逐渐递进，每次都只有一个变量参与，这种机制含有抗多重共线性干扰的功能；后者假设变量之间是相互独立的。但对于回归算法来说，都要同时考虑多个预测因子，因此多重共线性不可避免。</p>
<ul>
<li>PCA等降维方法。因为在原始特征空间中变量之间相关性大，很容易想到通过降低维度的形式来去除这种共线性。</li>
<li>正则化。使用<strong>岭回归（L2</strong>）或者lasso回归（L1）或者elasticnet回归（L1+L2）</li>
<li>逐步回归法</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://blog.csdn.net/FrankieHello/article/details/94022594">机器学习中参数模型和非参数模型理解</a></strong></p>
<p>参数模型通常假设总体服从某个分布，这个分布可以由一些参数确定，如正态分布由均值和标准差确定，在此基础上构建的模型称为参数模型；非参数模型对于总体的分布不做任何假设或者说是数据分布假设自由，只知道其分布是存在的，所以就无法得到其分布的相关参数，只能通过非参数统计的方法进行推断。</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/2GBZRTM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/2GBZRTM/" class="post-title-link" itemprop="url">恶意软件检测（14）MALWARE综述</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-08-12 16:29:26" itemprop="dateCreated datePublished" datetime="2021-08-12T16:29:26+08:00">2021-08-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-19 16:31:01" itemprop="dateModified" datetime="2023-04-19T16:31:01+08:00">2023-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/" itemprop="url" rel="index"><span itemprop="name">学术前沿</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>26k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>47 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1><span id="malware">MALWARE</span></h1>
<p>[TOC]</p>
<h2><span id="0补充">0.补充</span></h2>
<blockquote>
<p>综述：</p>
<p>Malconv</p>
<p>数据集</p>
</blockquote>
<h2><span id="1-survey-overview">1. Survey Overview</span></h2>
<blockquote>
<p>Period :2014-2021</p>
</blockquote>
<ul>
<li><h5><span id="platform">Platform</span></h5>
<ul>
<li>Windows [13,32]</li>
<li>Android [1-3,11,14,16,18,23,25,33,35-37,40]</li>
<li>Linux</li>
</ul></li>
<li><h5><span id="direction">Direction</span></h5>
<ul>
<li>Malware features from various aspects [1,9,24,28,31,40]</li>
<li>Malware propagation(传播) [2,25]</li>
<li>System mechanisms or services against malware [3,37]</li>
<li>Malware behaviors [5,15]
<ul>
<li>Obfuscation [8,37]</li>
<li>Packing [8]</li>
<li>Stealth technologies [3,6]</li>
<li>Hook</li>
<li>Evasion from dynamic analysis [10,17,20,31,62]</li>
</ul></li>
<li>Dataset challenges, such as aging problem [21,23,41,51]</li>
<li>Performance metrics[14,23]</li>
<li>Specific malware：such as IoT malware[25,26,39], fileless[30] and
PDF malware[43,54]</li>
<li>Visualization [15]</li>
<li>Graph representation [22]</li>
<li><strong>Detection Methods</strong> [3-4,8,9,11,12,14,16,19,31,33,36]
<ul>
<li>ML based techniques [13,18,21,29,38,40]</li>
<li>DL based techniques [22,29,35]</li>
</ul></li>
<li><strong>APT</strong>(Advanced Persistent Threats) [20]</li>
<li><strong>Adversarial malware example generation</strong> [27,32]</li>
<li>ML/DL flaws [7,28]</li>
<li>ML/DL interpretability [34]</li>
</ul></li>
</ul>
<h2><span id="2-android-malware-detection">2. Android Malware detection</span></h2>
<h3><span id="21-behavior-detection-6364">2.1 Behavior detection [63,64]</span></h3>
<table>
<colgroup>
<col style="width: 27%">
<col style="width: 1%">
<col style="width: 26%">
<col style="width: 21%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Malton:Towards On-Device Non-Invasive Mobile Malware Analysis for
ART</td>
<td>2017</td>
<td>Toprovide a comprehensive view of malware’s behaviors</td>
<td>Detectingeffectively</td>
<td>multi-layermonitoring &amp; information flow tracking</td>
</tr>
<tr class="even">
<td>CopperDroid:Automatic Reconstruction of Android Malware
Behaviors</td>
<td>2015</td>
<td>Toidentify OS- and high-level Android-specific behaviors.</td>
<td>Toreconstruct the behaviors of Android malware</td>
<td>VMI-baseddynamic analysis</td>
</tr>
</tbody>
</table>
<h3><span id="22-signature-based-6566">2.2 Signature based [65,66]</span></h3>
<table>
<colgroup>
<col style="width: 27%">
<col style="width: 1%">
<col style="width: 20%">
<col style="width: 23%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>EnMobile: Entity-based Characterization and Analysis of Mobile</td>
<td>2018</td>
<td>Tocharacaterize malware comprehensively</td>
<td>Detectingeffectively</td>
<td>entity-based characterization and static analysis; signature based
approach</td>
</tr>
<tr class="even">
<td>Screening smartphone applications using malware family
signatures</td>
<td>2015</td>
<td>Toimprove the robustness of signature matching</td>
<td>Toautomaticly extract family signature and matching</td>
<td>family signature</td>
</tr>
</tbody>
</table>
<h3><span id="23-rule-based6768">2.3 Rule based[67,68]</span></h3>
<table>
<colgroup>
<col style="width: 37%">
<col style="width: 2%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Toward a more dependable hybrid analysis of android malware using
aspect-oriented programming</td>
<td>2018</td>
<td>None.</td>
<td>Detectingeffectively</td>
<td>dataflowanalysis, detection of resource abuse;rule based</td>
</tr>
<tr class="even">
<td>DroidNative: Automating and optimizing detection of Android native
code malware variants</td>
<td>2017</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>specific control flow patterns;rule based</td>
</tr>
</tbody>
</table>
<h3><span id="24-similarity-based">2.4 Similarity based</span></h3>
<h4><span id="241-model-similarity69-73">2.4.1 Model similarity[69-73]</span></h4>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 2%">
<col style="width: 21%">
<col style="width: 11%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>An HMM and structural entropy based detector for Android malware: An
empirical study</td>
<td>2016</td>
<td>Todefeat hiding</td>
<td>Detectingeffectively</td>
<td>HiddenMarkov Model, structural entropy.</td>
</tr>
<tr class="even">
<td>Scalable and robust unsupervised android malware fingerprinting
using community-based network partitioning</td>
<td>2020</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>maliciouscommunity</td>
</tr>
<tr class="odd">
<td>On the use of artificial malicious patterns for android malware
detection</td>
<td>2020</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>malwarepatterns; Genetic Algorithm (GA); Apriori algorithm</td>
</tr>
<tr class="even">
<td>Andro-Dumpsys: Anti-malware system based on the similarity of
malware creator and malware centric information</td>
<td>2016</td>
<td>Todefeat packing, dynamic loading etc.</td>
<td>Detectingeffectively</td>
<td>similarity matching of malware creator-centric</td>
</tr>
<tr class="odd">
<td>Bayesian Active Malware Analysis</td>
<td>2020</td>
<td>None.</td>
<td>Detectingeffectively</td>
<td>the Markov chain models</td>
</tr>
</tbody>
</table>
<h4><span id="242-graph-similarity74-79">2.4.2 Graph similarity[74-79]</span></h4>
<table>
<colgroup>
<col style="width: 30%">
<col style="width: 2%">
<col style="width: 23%">
<col style="width: 12%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PermPair: Android Malware Detection Using Permission Pairs</td>
<td>2020</td>
<td>Tomake use of permission information</td>
<td>Todetect Android malware</td>
<td>The comparasion of the graph of permission pairs.</td>
</tr>
<tr class="even">
<td>Apposcopy: Semantics-Based Detection of Android Malware through
Static Analysis</td>
<td>2014</td>
<td>Toimprove signature based methods</td>
<td>Detectingeffectively</td>
<td>combination of static taint analysis and program representation
called Inter-Component Call Graph</td>
</tr>
<tr class="odd">
<td>Profiling user-trigger dependence for Android malware detection</td>
<td>2015</td>
<td>Tocapture stealthily launch operation</td>
<td>Detectingeffectively</td>
<td>Graphcomparision</td>
</tr>
<tr class="even">
<td>Identifying Android Malware Using Network-Based Approaches</td>
<td>2019</td>
<td>Tomake use of network information</td>
<td>Detectingeffectively</td>
<td>aweighted network to compare closeness</td>
</tr>
<tr class="odd">
<td>Cypider: Building Community-Based Cyber-Defense Infrastructure for
Android Malware Detection</td>
<td>2016</td>
<td>Todeal with endless new malware</td>
<td>Detectingeffectively</td>
<td>scalablesimilarity network infrastructure;malicious community</td>
</tr>
<tr class="even">
<td>Semantics-Aware Android Malware Classification Using Weighted
Contextual API Dependency Graphs</td>
<td>2014</td>
<td>Tocharacaterize malware from program semantics</td>
<td>Detectingeffectively</td>
<td>a weighted contextual API dependency graph as program
semantics;graphsimilarity metrics</td>
</tr>
</tbody>
</table>
<h3><span id="25-ml-based-6080-101">2.5 ML based [60,80-101]</span></h3>
<table>
<colgroup>
<col style="width: 24%">
<col style="width: 1%">
<col style="width: 24%">
<col style="width: 24%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>MAMADROID:Detecting Android Malware by Building Markov
Chains of Behavioral Models</strong></td>
<td>2017</td>
<td>Todesign robust malware mitigation techniques</td>
<td>Constructinga classifier</td>
<td>BuildingMarkov Chains of Behavioral Models;Random Forests , Nearest
Neighbor (1-NN) ,3-Nearest Neighbor (3-NN) ,and Support Vector Machines
(SVM)</td>
</tr>
<tr class="even">
<td><strong>Drebin:Effective and Explainable Detection of Android
Malware in Your Pocket</strong></td>
<td>2014</td>
<td>Tomitigate the influence on limited resources in Android
platform</td>
<td>To propose a lightweight method to detect malware at run-time</td>
<td>Staticanalysis and SVM</td>
</tr>
<tr class="odd">
<td>MakeEvasion Harder: An Intelligent Android Malware Detection
System</td>
<td>2018</td>
<td>Todetect evolving Android malware</td>
<td>Higherdetection rate</td>
<td>APIcalls and higher-level semantics; SVM</td>
</tr>
<tr class="even">
<td>UsingLoops For Malware Classification Resilient to Feature-unaware
Perturbations</td>
<td>2018</td>
<td>Tosolve feature-unaware perturbation</td>
<td>Todetect malware resilient to feature-unaware perturbation</td>
<td>Looplocating and random forest</td>
</tr>
<tr class="odd">
<td>SemanticModelling of Android Malware for Effective Malware
Comprehension, Detection,and Classification</td>
<td>2016</td>
<td>Tomake use of semantic information</td>
<td>Todetect Android malware</td>
<td>Semanticmodel; Random forest</td>
</tr>
<tr class="even">
<td>Detecting Android Malware Leveraging Text Semantics of Network
Flows</td>
<td>2018</td>
<td>Tomake use of network information</td>
<td>Todetect Android malware</td>
<td>Usingthe text semantics of network traffic; SVM</td>
</tr>
<tr class="odd">
<td>Improving Accuracy of Android Malware Detection with Lightweight
Contextual Awareness</td>
<td>2018</td>
<td>Toreduce redundant metadata in modeling</td>
<td>ImprovingAccuracy of Android Malware Detection</td>
<td>KNN;RF;MLP</td>
</tr>
<tr class="even">
<td>MalScan: Fast Market-Wide Mobile Malware Scanning by Social-Network
Centrality Analysis</td>
<td>2019</td>
<td>Toreduce the cost of semantic analysis</td>
<td>To propose a lightweight method to detect malware</td>
<td>social-network-basedcentrality analysis; kNN and random forest</td>
</tr>
<tr class="odd">
<td>PIndroid: A novel Android malware detection system using ensemble
learning methods</td>
<td>2017</td>
<td>Tofight against covert technique of malware</td>
<td>Detectingeffectively</td>
<td>Permissionsand Intents based framework supplemented with Ensemble
methods:Nave Bayesian,Decision Tree, Decision Table, Random Forest,
Sequential Minimal Optimization and Multi Lateral Perceptron(MLP)</td>
</tr>
<tr class="even">
<td>A pragmatic android malware detection procedure</td>
<td>2017</td>
<td>Todesign a new ML model</td>
<td>Detectingeffectively</td>
<td>Atomic Naive Bayes classifiers used as inputs for the Support Vector
Machine ensemble.</td>
</tr>
<tr class="odd">
<td>ICCDetector: ICC-Based Malware Detection on Android</td>
<td>2016</td>
<td>Tocapture communication among components or cross boundaries to
supplymentfeatures</td>
<td>Detectingeffectively</td>
<td>SVM</td>
</tr>
<tr class="even">
<td>A Probabilistic Discriminative Model for Android Malware Detection
with Decompiled Source Code</td>
<td>2015</td>
<td>None.</td>
<td>Detectingeffectively</td>
<td>the 2-class Naive Bayes with Prior (2-PNB) and a discriminative
model,the regularized logistic regression</td>
</tr>
<tr class="odd">
<td>DroidCat: Effective Android Malware Detection and Categorization via
App-Level Profiling</td>
<td>2019</td>
<td>Tofight against systemcall obfuscation</td>
<td>Detectingeffectively</td>
<td>Dynamicanalysis based on method calls and inter-component
communication; RandomForest</td>
</tr>
<tr class="even">
<td>MADAM: Effective and Efficient Behavior-based Android Malware
Detection and Prevention</td>
<td>2018</td>
<td>None.</td>
<td>Detectingeffectively</td>
<td>KNN</td>
</tr>
<tr class="odd">
<td>==Android Malware Detection via (Somewhat) Robust Irreversible
Feature Transformations==</td>
<td>2020</td>
<td>Toavoid ML classifier evading</td>
<td>Transferingfeatures to a new feature domain</td>
<td>Classifiers used:(1) Bernoulli Naive Bayes, (2) Random Forest, (3)
NearestNeighbors, (4) Logistic Regression, (5) Gaussian Naive Bayes, (6)
AdaBoost Classifier, (7) Gradient Boosting Decision Tree, (8) XGB
Classifier and (9)SVM.</td>
</tr>
<tr class="even">
<td>Leveraging ontologies and machine-learning techniques for malware
analysis into Android permissions ecosystems</td>
<td>2018</td>
<td>None.</td>
<td>Detectingeffectively</td>
<td>ontology-basedframework;random forest</td>
</tr>
<tr class="odd">
<td>Lightweight, Obfuscation-Resilient Detection and Family
Identification of Android Malware</td>
<td>2018</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>familyidentification;linear SVM</td>
</tr>
<tr class="even">
<td>A multi-view context-aware approach to Android malware detection and
malicious code localization</td>
<td>2018</td>
<td>To characaterize malware comprehensively</td>
<td>Detectingeffectively</td>
<td>multipleviews of apps;SVM</td>
</tr>
<tr class="odd">
<td>DroidFusion: A Novel Multilevel Classifier Fusion Approach for
Android Malware Detection</td>
<td>2019</td>
<td>Toimprove classifier</td>
<td>Detectingeffectively</td>
<td>CLASSIFIER FUSION:J48, REPTree, voted perceptron, and random
tree</td>
</tr>
<tr class="even">
<td>DL-Droid: Deep learning based android malware detection using real
devices</td>
<td>2020</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>input generation;MLP</td>
</tr>
<tr class="odd">
<td>JOWMDroid: Android malware detection based on feature weighting with
joint optimization of weight-mapping and classifier parameters</td>
<td>2021</td>
<td>Tocharacaterize malware from feature importance</td>
<td>Detectingeffectively</td>
<td>featureweighting with the joint optimization of weight-mapping;SVM,
LR, MLP</td>
</tr>
<tr class="even">
<td>Towards using unstructured user input request for malware
detection</td>
<td>2020</td>
<td>Todefeat privacy analysis evading</td>
<td>Detectingeffectively</td>
<td>decision tree</td>
</tr>
</tbody>
</table>
<h3><span id="26-dl-based-102-109">2.6 DL based [102-109]</span></h3>
<table>
<colgroup>
<col style="width: 32%">
<col style="width: 2%">
<col style="width: 32%">
<col style="width: 11%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Motivation</th>
<th>Goal</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Toward s an interpretable deep learning model for mobile malware
detection and family identification</td>
<td>2021</td>
<td>Topropose a interpretable DL model</td>
<td>Detectingreasonablely</td>
<td>DL:Grad-CAM</td>
</tr>
<tr class="even">
<td>AMalNet: A deep learning framework based on graph convolutional
networks for malware detection</td>
<td>2020</td>
<td>Tohave a lower cost</td>
<td>Detectingeffectively</td>
<td>DL:GCNsand IndRNN</td>
</tr>
<tr class="odd">
<td>Disentangled Representation Learning in Heterogeneous Information
Network for Large-scale Android Malware Detection in the COVID-19 Era
and Beyond</td>
<td>2021</td>
<td>Tosolve the problem that society relys on the complex
cyberspace</td>
<td>Detectingeffectively</td>
<td>heterogeneousinformation network (HIN);DNN</td>
</tr>
<tr class="even">
<td>A Multimodal Deep Learning Method for Android Malware Detection
Using Various Features</td>
<td>2019</td>
<td>Tocharacaterize malware comprehensively</td>
<td>Detectingeffectively</td>
<td>multimodaldeep learning method;DNN</td>
</tr>
<tr class="odd">
<td>Android Fragmentation in Malware Detection</td>
<td>2019</td>
<td>Todeal with multiple Android version</td>
<td>Detectingeffectively</td>
<td>Deep Neural Network</td>
</tr>
<tr class="even">
<td>An Image-inspired and CNN-based Android Malware Detection
Approach</td>
<td>2019</td>
<td>Todefeat obfuscation</td>
<td>Detectingeffectively</td>
<td>CNN</td>
</tr>
<tr class="odd">
<td>A Performance-Sensitive Malware Detection System Using Deep Learning
on Mobile Devices</td>
<td>2021</td>
<td>Toreduce time cost of download and upload</td>
<td>Detectingfastly</td>
<td>customized DNN</td>
</tr>
<tr class="even">
<td>Byte-level malware classification based on markov images and deep
learning</td>
<td>2020</td>
<td>Toimprove the accuracy of gray image based methods</td>
<td>Detectingeffectively</td>
<td>deep convolutional neural network</td>
</tr>
</tbody>
</table>
<h2><span id="3-windows-malware-detection">3 Windows Malware detection</span></h2>
<h3><span id="31-behavior-detection-110111">3.1 Behavior detection [110,111]</span></h3>
<table style="width:100%;">
<colgroup>
<col style="width: 68%">
<col style="width: 4%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>API Chaser: Anti-analysis Resistant Malware Analyzer</td>
<td>2013</td>
<td>API call feature capture</td>
</tr>
<tr class="even">
<td>MalViz: An Interactive Visualization Tool for Tracing Malware</td>
<td>2018</td>
<td>Behavior visualization</td>
</tr>
</tbody>
</table>
<h3><span id="32-signature-based-112">3.2 Signature based [112]</span></h3>
<table>
<colgroup>
<col style="width: 76%">
<col style="width: 5%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CloudEyes: Cloud-based malware detection with reversible sketch for
resource-constrained internet of things (IoT) devices</td>
<td>2017</td>
<td>Based on cloud</td>
</tr>
</tbody>
</table>
<h3><span id="33-rule-based113">3.3 Rule based[113]</span></h3>
<table>
<colgroup>
<col style="width: 77%">
<col style="width: 5%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A fast malware detection algorithm based on objective-oriented
association mining</td>
<td>2013</td>
<td>API selection</td>
</tr>
</tbody>
</table>
<h3><span id="34-similarity-based">3.4 Similarity based</span></h3>
<h4><span id="341-model-similarity114-122">3.4.1 Model similarity[114-122]</span></h4>
<table>
<colgroup>
<col style="width: 48%">
<col style="width: 3%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>PoMMaDe: Pushdown Model-checking for Malware Detection</td>
<td>2013</td>
<td>model checking</td>
</tr>
<tr class="even">
<td>Growing Grapes in Your Computer to Defend Against Malware</td>
<td>2014</td>
<td>clustering and template matching</td>
</tr>
<tr class="odd">
<td>Hypervisor-based malware protection with AccessMiner</td>
<td>2015</td>
<td>system-centric behavioral detector</td>
</tr>
<tr class="even">
<td>Probabilistic Inference on Integrity for Access Behavior Based
Malware Detection</td>
<td>2015</td>
<td>probabilistic model of integrity</td>
</tr>
<tr class="odd">
<td>Probabilistic analysis of dynamic malware traces</td>
<td>2018</td>
<td>1.Features of system interaction 2. interpretability</td>
</tr>
<tr class="even">
<td>A malware detection method based on family behavior graph</td>
<td>2018</td>
<td>common behavior graph</td>
</tr>
<tr class="odd">
<td>Malware classification using self organising feature maps and
machine activity data</td>
<td>2018</td>
<td>1.The improvement of ML. to reduce over-fitting 2. Self Organizing
Feature Maps</td>
</tr>
<tr class="even">
<td>Volatile memory analysis using the MinHash method for efficient and
secured detection of malware in private cloud</td>
<td>2019</td>
<td>Based on memory features</td>
</tr>
<tr class="odd">
<td>A dynamic Windows malware detection and prediction method based on
contextual understanding of API call sequence</td>
<td>2020</td>
<td>1.Contextual relationship between API call features 2.
Marcovchain</td>
</tr>
</tbody>
</table>
<h4><span id="342-graph-similarity123-127">3.4.2 Graph similarity[123-127]</span></h4>
<table>
<colgroup>
<col style="width: 55%">
<col style="width: 3%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Deriving common malware behavior through graph clustering</td>
<td>2013</td>
<td>common behavior graph</td>
</tr>
<tr class="even">
<td>Enhancing the detection of metamorphic malware using call
graphs</td>
<td>2014</td>
<td>API call graph matching</td>
</tr>
<tr class="odd">
<td>Minimal contrast frequent pattern mining for malware detection</td>
<td>2016</td>
<td>Graph matching</td>
</tr>
<tr class="even">
<td><strong>Heterogeneous Graph Matching Networks for Unknown Malware
Detection</strong></td>
<td>2019</td>
<td>Graph matching similarity of benign software</td>
</tr>
<tr class="odd">
<td>Random CapsNet for est model for imbalanced malware type
classification task</td>
<td>2021</td>
<td>The improvement of the Model</td>
</tr>
</tbody>
</table>
<h3><span id="35-ml-based-128-143">3.5 ML based [128-143]</span></h3>
<table>
<colgroup>
<col style="width: 46%">
<col style="width: 6%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A Scalable Approach for Malware Detection through Bounded Feature
Space Behavior Modeling</td>
<td>2013</td>
<td>Scalable feature space</td>
</tr>
<tr class="even">
<td>SigMal: A Static Signal Processing Based Malware Triage</td>
<td>2013</td>
<td>noise-resistant similarity signatures</td>
</tr>
<tr class="odd">
<td>Unsupervised Anomaly-Based Malware Detection Using Hardware
Features</td>
<td>2014</td>
<td>hardware supported lower-level features</td>
</tr>
<tr class="even">
<td>Control flow-based opcode behavior analysis for Malware
detection</td>
<td>2014</td>
<td>Based on control flow method features</td>
</tr>
<tr class="odd">
<td>Employing Program Semantics for Malware Detection</td>
<td>20152021</td>
<td>Extracting information-rich call sequence based on AEPThe
improvement of the Model</td>
</tr>
<tr class="even">
<td>AMAL: High-fidelity, behavior-based automated malware analysis and
classification</td>
<td>2015</td>
<td>Based on behavior analysis</td>
</tr>
<tr class="odd">
<td>Optimized Invariant Representation of Network Traffic for Detecting
Unseen Malware Variants</td>
<td>2016</td>
<td>Network features</td>
</tr>
<tr class="even">
<td>DYNAMINER: Leveraging Offline Infection Analytics for On-the-Wire
Malware Detection</td>
<td>2017</td>
<td>Network features</td>
</tr>
<tr class="odd">
<td>Security importance assessment for system objects and malware
detection</td>
<td>2017</td>
<td>Based on importance of system objects</td>
</tr>
<tr class="even">
<td>From big data to knowledge: A spatiotemporal approach to malware
detection</td>
<td>2018</td>
<td>cloud based security service features</td>
</tr>
<tr class="odd">
<td>From big data to knowledge: A spatiotemporal approach to malware
detection</td>
<td>2018</td>
<td>cloud based security service features</td>
</tr>
<tr class="even">
<td>MalDAE: Detecting and explaining malware based on correlation and
fusion of static and dynamic characteristics</td>
<td>2019</td>
<td>fusion of static and dynamic API sequence features</td>
</tr>
<tr class="odd">
<td>Leveraging Compression-Based Graph Mining for Behavior-Based Malware
Detection</td>
<td>2019</td>
<td>Based on data flow graph</td>
</tr>
<tr class="even">
<td>Advanced Windows Methods on Malware Detection and
Classification</td>
<td>2020</td>
<td>API based Features extraction.</td>
</tr>
<tr class="odd">
<td>Sub-curve HMM: A malware detection approach based on partial
analysis of API call sequences</td>
<td>2020</td>
<td>1.Subset of API call feature 2. HMM</td>
</tr>
<tr class="even">
<td>Multiclass malware classification via first- and second-order
texture statistics</td>
<td>2020</td>
<td>visualization</td>
</tr>
<tr class="odd">
<td>Catch them alive: A malware detection approach through memory
forensics, manifoldlearning and computer vision</td>
<td>2021</td>
<td>Visualization</td>
</tr>
</tbody>
</table>
<h3><span id="36-dl-based-144-156">3.6 DL based [144-156]</span></h3>
<table>
<colgroup>
<col style="width: 57%">
<col style="width: 3%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Title</th>
<th>Year</th>
<th>Creativity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Auto-detection of sophisticated malware using lazy-binding control
flow graph and deep learning</td>
<td>2018</td>
<td>1.The improvement of CFG 2. Visualizaiton</td>
</tr>
<tr class="even">
<td>Malware identification using visualization images and deep
learning</td>
<td>2018</td>
<td>1.SimHash of features 2. Visualization</td>
</tr>
<tr class="odd">
<td>Classification of Malware by Using Structural Entropy on
Convolutional Neural Networks</td>
<td>2018</td>
<td>visual similarity</td>
</tr>
<tr class="even">
<td>Classifying Malware Represented as Control Flow Graphs using Deep
Graph Convolutional Neural Network</td>
<td>2019</td>
<td>The improvement of CFG</td>
</tr>
<tr class="odd">
<td><strong>Neurlux: Dynamic Malware Analysis Without Feature
Engineering</strong></td>
<td>2019</td>
<td>Based on dynamic analysis reports</td>
</tr>
<tr class="even">
<td>A feature-hybrid malware variants detection using CNN based opcode
embedding and BPNN based API embedding</td>
<td>2019</td>
<td>Hybrid features</td>
</tr>
<tr class="odd">
<td>Effective analysis of malware detection in cloud computing</td>
<td>2019</td>
<td>The improvement of the DL.</td>
</tr>
<tr class="even">
<td>Recurrent neural network for detecting malware</td>
<td>2020</td>
<td>The improvement of RNN</td>
</tr>
<tr class="odd">
<td><strong>Dynamic Malware Analysis with Feature Engineering and
Feature Learning</strong></td>
<td>2020</td>
<td>Feature hashing to encode API call info.</td>
</tr>
<tr class="even">
<td>An improved two-hidden-layer extreme learning machine for malware
hunting</td>
<td>2020</td>
<td>Improvement of the DL.</td>
</tr>
<tr class="odd">
<td>HYDRA: A multimodal deep learning framework for malware
classification</td>
<td>2020</td>
<td>Hybrid features</td>
</tr>
<tr class="even">
<td>A novel method for malware detection on ML-based visualization
technique</td>
<td>2020</td>
<td>visualization</td>
</tr>
<tr class="odd">
<td>Image-Based malware classification using ensemble of CNN
architectures (IMCEC)</td>
<td>2020</td>
<td>visualization</td>
</tr>
</tbody>
</table>
<h2><span id="4-mldl-flaws-overview">4. ML/DL flaws Overview</span></h2>
<ul>
<li>Ensemble classifier evasion [42]</li>
<li>Performance degradation [42,46,53,54]</li>
<li>Adversarial example generation [43,44,45,48,55,56,57,58]</li>
<li>Poisoning Attack [47]</li>
<li>Feature weights [49]</li>
<li>Cost analysis [50]</li>
<li>ML bias from dataset [51]</li>
<li>Influence of packing [52]</li>
<li>Methods reproduction [59]</li>
</ul>
<h2><span id="5-references">5. References</span></h2>
<ol type="1">
<li><p>2014 A Survey of Android Malware Characterisitics and Mitigation
Techniques</p></li>
<li><p>2014 Smartphone Malware and Its Propagation Modeling:A
Survey</p></li>
<li><p>2015 Android Security: A Survey of Issues, Malware Penetration,
and Defenses</p></li>
<li><p>2014 Evolution and Detection of Polymorphic and Metamorphic
Malwares: A Survey</p></li>
<li><p>2015 Kernel Malware Core Implementation: A Survey</p></li>
<li><p>2016 A Survey of Stealth Malware Attacks, Mitigation Measures,
and Steps Toward Autonomous Open World Solutions</p></li>
<li><p>2016 On the Security of Machine Learning in Malware C&amp;C
Detection: A Survey</p></li>
<li><p>2017 Malware Methodologies and Its Future: A Survey</p></li>
<li><p>2017 A Survey on Malware Detection Using Data Mining
Techniques</p></li>
<li><p>2018 Malware Dynamic Analysis Evasion Techniques: A
Survey</p></li>
<li><p>2018 Android Malware Detection: A Survey</p></li>
<li><p>2018 A Survey on Metamorphic Malware Detection based on Hidden
Markov Model</p></li>
<li><p>2018 Machine Learning Aided Static Malware Analysis: A Survey and
Tutorial</p></li>
<li><p>2018 A survey on dynamic mobile malware detection</p></li>
<li><p>2018 A survey of malware behavior description and
analysis</p></li>
<li><p>2019 A Survey on Android Malware Detection Techniques Using
Machine Learning Algorithms</p></li>
<li><p>2019 Dynamic Malware Analysis in the Modern Era—A State of the
Art Survey</p></li>
<li><p>2019 Data-Driven Android Malware Intelligence: A Survey</p></li>
<li><p>2019 A survey of zero-day malware attacks and itsdetection
methodology</p></li>
<li><p>2019 A Survey on malware analysis and mitigation
techniques</p></li>
<li><p><strong>2019 Survey of machine learning techniques for malware
analysis</strong></p></li>
<li><p>2020 Deep Learning and Open Set Malware Classification: A
Survey</p></li>
<li><p>2020 A Comprehensive Survey on Machine Learning Techniques for
Android Malware Detection</p></li>
<li><p>2015 A Survey on Mining Program-Graph Features for Malware
Analysis</p></li>
<li><p>2020 Stochastic Modeling of IoT Botnet Spread: A Short Survey on
Mobile Malware Spread Modeling</p></li>
<li><p>2020 A survey of IoT malware and detection methods based on
static features</p></li>
<li><p>2020 A survey on practical adversarial examples for malware
classifiers</p></li>
<li><p>2020 A Survey of Machine Learning Methods and Challenges for
Windows Malware Classification</p></li>
<li><p>2020 A Survey on Malware Detection with Deep Learning</p></li>
<li><p>2020 An emerging threat Fileless malware: a survey and research
challenges</p></li>
<li><p>2021 Malware classification and composition analysis: A survey of
recent developments</p></li>
<li><p><strong>2021 Adversarial EXEmples: A Survey and Experimental
Evaluation of Practical Attacks on Machine Learning for Windows Malware
Detection</strong></p></li>
<li><p>2020 A Survey on Mobile Malware Detection Techniques</p></li>
<li><p>2021 Towards interpreting ML-based automated malware detection
models: a survey</p></li>
<li><p>2021 A Survey of Android Malware Detection with Deep Neural
Models</p></li>
<li><p>2021 A survey of malware detection in Android apps:
Recommendations and perspectives for future research</p></li>
<li><p>2021 A survey of android application and malware
hardening</p></li>
<li><p>2021 A survey on machine learning-based malware detection in
executable files</p></li>
<li><p>2021 The evolution of IoT Malwares, from 2008 to 2019: Survey,
taxonomy, process simulator and perspectives</p></li>
<li><p>2021 A Survey of Android Malware Static Detection Technology
Based on Machine Learning</p></li>
<li><p>2016 Empirical assessment of machine learning-based malware
detectors for Android Measuring the gap between in-the-lab and
in-the-wild validation scenarios</p></li>
<li><p>2016 When a Tree Falls: Using Diversity in Ensemble Classifiers
to Identify Evasion in Malware Detectors</p></li>
<li><p><strong>2016 Automatically Evading Classifiers A Case Study on
PDF Malware Classifiers</strong></p></li>
<li><p>2017 SecureDroid: Enhancing Security of Machine Learning-based
Detection against Adversarial Android Malware Attacks</p></li>
<li><p>2017 How to defend against adversarial attack</p></li>
<li><p><strong>2017 Transcend: Detecting Concept Drift in Malware
Classification Models</strong></p></li>
<li><p><strong>2018 Automated poisoning attacks and defenses in malware
detection systems: An adversarial machine learning
approach</strong></p></li>
<li><p><strong>2018 Generic Black-Box End-to-End Attack Against State of
the Art API Call Based Malware Classifiers</strong></p></li>
<li><p><strong>==2019 Yes, Machine Learning Can Be More Secure! A Case
Study on Android Malware Detection==</strong></p></li>
<li><p>2019 A cost analysis of machine learning using dynamic runtime
opcodes for malware detection</p></li>
<li><p><strong>2019 TESSERACT: Eliminating Experimental Bias in Malware
Classification across Space and Time</strong></p></li>
<li><p>2020 When Malware is Packin’ Heat; Limits of Machine Learning
Classifiers Based on Static Analysis Features</p></li>
<li><p>2020 Assessing and Improving Malware Detection Sustainability
through App Evolution Studies</p></li>
<li><p>2020 On Training Robust PDF Malware Classifiers</p></li>
<li><p>2020 Adversarial Deep Ensemble: Evasion Attacks and Defenses for
Malware Detection</p></li>
<li><p>2020 Intriguing Properties of Adversarial ML Attacks in the
Problem Space Fabio</p></li>
<li><p>2020 Query-Efficient Black-Box Attack Against Sequence-Based
Malware Classifiers</p></li>
<li><p>2020 Enhancing State-of-the-art Classifiers with API Semantics to
Detect Evolved Android Malware</p></li>
<li><p>2021 Lessons Learnt on Reproducibility in Machine Learning Based
Android Malware Detection</p></li>
<li><p>2016 Semantics-Based Online Malware Detection: Towards Efficient
Real-Time Protection Against Malware</p></li>
<li><p>2018 Understanding Linux Malware</p></li>
<li><p>2017 Droid-AntiRM: Taming Control Flow Anti-analysis to Support
Automated Dynamic Analysis of Android Malware</p></li>
<li><p>2017 Malton: Towards On-Device Non-Invasive Mobile Malware
Analysis for ART</p></li>
<li><p>2015 CopperDroid: Automatic Reconstruction of Android Malware
Behaviors</p></li>
<li><p>2018 EnMobile: Entity-based Characterization and Analysis of
Mobile</p></li>
<li><p>2015 Screening smartphone applications using malware family
signatures</p></li>
<li><p>2018 Toward a more dependable hybrid analysis of android malware
using aspect-oriented programming</p></li>
<li><p>2017 DroidNative: Automating and optimizing detection of Android
native code malware variants</p></li>
<li><p>2016 An HMM and structural entropy based detector for Android
malware: An empirical study</p></li>
<li><p>2020 Scalable and robust unsupervised android malware
fingerprinting using community-based network partitioning</p></li>
<li><p>2020 On the use of artificial malicious patterns for android
malware detection</p></li>
<li><p>2016 Andro-Dumpsys: Anti-malware system based on the similarity
of malware creator and malware centric information</p></li>
<li><p>2020 Bayesian Active Malware Analysis</p></li>
<li><p>2020 PermPair: Android Malware Detection Using Permission
Pairs</p></li>
<li><p>2014 Apposcopy: Semantics-Based Detection of Android Malware
through Static Analysis</p></li>
<li><p>2015 Profiling user-trigger dependence for Android malware
detection</p></li>
<li><p>2019 Identifying Android Malware Using Network-Based
Approaches</p></li>
<li><p>2016 Cypider: Building Community-Based Cyber-Defense
Infrastructure for Android Malware Detection</p></li>
<li><p>2014 Semantics-Aware Android Malware Classification Using
Weighted Contextual API Dependency Graphs</p></li>
<li><p>2017 MAMADROID: Detecting Android Malware by Building Markov
Chains of Behavioral Models</p></li>
<li><p>2014 Drebin: Effective and Explainable Detection of Android
Malware in Your Pocket</p></li>
<li><p>2018 Make Evasion Harder: An Intelligent Android Malware
Detection System</p></li>
<li><p>2018 Using Loops For Malware Classification Resilient to
Feature-unaware Perturbations</p></li>
<li><p>2016 Semantic Modelling of Android Malware for Effective Malware
Comprehension, Detection, and Classification</p></li>
<li><p>2018 Detecting Android Malware Leveraging Text Semantics of
Network Flows</p></li>
<li><p>2018 Improving Accuracy of Android Malware Detection with
Lightweight Contextual Awareness</p></li>
<li><p>2019 MalScan: Fast Market-Wide Mobile Malware Scanning by
Social-Network Centrality Analysis</p></li>
<li><p>2017 PIndroid: A novel Android malware detection system using
ensemble learning methods</p></li>
<li><p>2017 A pragmatic android malware detection procedure</p></li>
<li><p>2016 ICCDetector: ICC-Based Malware Detection on Android</p></li>
<li><p>2015 A Probabilistic Discriminative Model for Android Malware
Detection with Decompiled Source Code</p></li>
<li><p>2019 DroidCat: Effective Android Malware Detection and
Categorization via App-Level Profiling</p></li>
<li><p>2018 MADAM: Effective and Efficient Behavior-based Android
Malware Detection and Prevention</p></li>
<li><p>2020 Android Malware Detection via (Somewhat) Robust Irreversible
Feature Transformations</p></li>
<li><p>2018 Leveraging ontologies and machine-learning techniques for
malware analysis into Android permissions ecosystems</p></li>
<li><p>2018 Lightweight, Obfuscation-Resilient Detection and Family
Identification of Android Malware</p></li>
<li><p>2018 A multi-view context-aware approach to Android malware
detection and malicious code localization</p></li>
<li><p>2019 DroidFusion: A Novel Multilevel Classifier Fusion Approach
for Android Malware Detection</p></li>
<li><p>2020 DL-Droid: Deep learning based android malware detection
using real devices</p></li>
<li><p>2021 JOWMDroid: Android malware detection based on feature
weighting with joint optimization of weight-mapping and classifier
parameters</p></li>
<li><p>2020 Towards using unstructured user input request for malware
detection</p></li>
<li><p>2021 Toward s an interpretable deep learning model for mobile
malware detection and family identification</p></li>
<li><p>2020 AMalNet: A deep learning framework based on graph
convolutional networks for malware detection</p></li>
<li><p>2021 Disentangled Representation Learning in Heterogeneous
Information Network for Large-scale Android Malware Detection in the
COVID-19 Era and Beyond</p></li>
<li><p>2019 A Multimodal Deep Learning Method for Android Malware
Detection Using Various Features</p></li>
<li><p>2019 Android Fragmentation in Malware Detection</p></li>
<li><p>2019 An Image-inspired and CNN-based Android Malware Detection
Approach</p></li>
<li><p>2021 A Performance-Sensitive Malware Detection System Using Deep
Learning on Mobile Devices</p></li>
<li><p>2020 Byte-level malware classification based on markov images and
deep learning</p></li>
<li><p>2013 API Chaser: Anti-analysis Resistant Malware
Analyzer</p></li>
<li><p>2018 MalViz: An Interactive Visualization Tool for Tracing
Malware</p></li>
<li><p>2017 CloudEyes: Cloud-based malware detection with reversible
sketch for resource-constrained internet of things (IoT)
devices</p></li>
<li><p>2013 A fast malware detection algorithm based on
objective-oriented association mining</p></li>
<li><p>2013 PoMMaDe: Pushdown Model-checking for Malware
Detection</p></li>
<li><p>2014 Growing Grapes in Your Computer to Defend Against
Malware</p></li>
<li><p>2015 Hypervisor-based malware protection with
AccessMiner</p></li>
<li><p>2015 Probabilistic Inference on Integrity for Access Behavior
Based Malware Detection</p></li>
<li><p>2018 Probabilistic analysis of dynamic malware traces</p></li>
<li><p>2018 A malware detection method based on family behavior
graph</p></li>
<li><p>2018 Malware classification using self organising feature maps
and machine activity data</p></li>
<li><p>2019 Volatile memory analysis using the MinHash method for
efficient and secured detection of malware in private cloud</p></li>
<li><p>2020 A dynamic Windows malware detection and prediction method
based on contextual understanding of API call sequence</p></li>
<li><p>2013 Deriving common malware behavior through graph
clustering</p></li>
<li><p>2014 Enhancing the detection of metamorphic malware using call
graphs</p></li>
<li><p>2016 Minimal contrast frequent pattern mining for malware
detection</p></li>
<li><p>2019 Heterogeneous Graph Matching Networks for Unknown Malware
Detection</p></li>
<li><p>2021 Random CapsNet for est model for imbalanced malware type
classification task</p></li>
<li><p>2013 A Scalable Approach for Malware Detection through Bounded
Feature Space Behavior Modeling</p></li>
<li><p>2013 SigMal: A Static Signal Processing Based Malware
Triage</p></li>
<li><p>2014 Unsupervised Anomaly-Based Malware Detection Using Hardware
Features</p></li>
<li><p>2014 Control flow-based opcode behavior analysis for Malware
detection</p></li>
<li><p>2015 Employing Program Semantics for Malware Detection</p></li>
<li><p>2015 AMAL: High-fidelity, behavior-based automated malware
analysis and classification</p></li>
<li><p>2016 Optimized Invariant Representation of Network Traffic for
Detecting Unseen Malware Variants</p></li>
<li><p>2017 DYNAMINER: Leveraging Offline Infection Analytics for
On-the-Wire Malware Detection</p></li>
<li><p>2017 Security importance assessment for system objects and
malware detection</p></li>
<li><p>2018 From big data to knowledge: A spatiotemporal approach to
malware detection</p></li>
<li><p>2019 MalDAE: Detecting and explaining malware based on
correlation and fusion of static and dynamic characteristics</p></li>
<li><p>2019 Leveraging Compression-Based Graph Mining for Behavior-Based
Malware Detection</p></li>
<li><p>2020 Advanced Windows Methods on Malware Detection and
Classification</p></li>
<li><p>2020 Sub-curve HMM: A malware detection approach based on partial
analysis of API call sequences</p></li>
<li><p>2020 Multiclass malware classification via first- and
second-order texture statistics</p></li>
<li><p>2021 Catch them alive: A malware detection approach through
memory forensics, manifold learning and computer vision</p></li>
<li><p>2018 Auto-detection of sophisticated malware using lazy-binding
control flow graph and deep learning</p></li>
<li><p>2018 Malware identification using visualization images and deep
learning</p></li>
<li><p>2018 Classification of Malware by Using Structural Entropy on
Convolutional Neural Networks</p></li>
<li><p>2019 Classifying Malware Represented as Control Flow Graphs using
Deep Graph Convolutional Neural Network</p></li>
<li><p>2019 Neurlux: Dynamic Malware Analysis Without Feature
Engineering</p></li>
<li><p>2019 A feature-hybrid malware variants detection using CNN based
opcode embedding and BPNN based API embedding</p></li>
<li><p>2019 Effective analysis of malware detection in cloud
computing</p></li>
<li><p>2020 Recurrent neural network for detecting malware</p></li>
<li><p>2020 Dynamic Malware Analysis with Feature Engineering and
Feature Learning</p></li>
<li><p>2020 An improved two-hidden-layer extreme learning machine for
malware hunting</p></li>
<li><p>2020 HYDRA: A multimodal deep learning framework for malware
classification</p></li>
<li><p>2020 A novel method for malware detection on ML-based
visualization technique</p></li>
<li><p>2020 Image-Based malware classification using ensemble of CNN
architectures (IMCEC)</p></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/1KY76QV/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/1KY76QV/" class="post-title-link" itemprop="url">恶意软件检测（5）BODMAS-An Open Dataset for Learning based Temporal Analysis of PE Malware</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-08-05 12:18:22" itemprop="dateCreated datePublished" datetime="2021-08-05T12:18:22+08:00">2021-08-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-19 15:49:51" itemprop="dateModified" datetime="2023-04-19T15:49:51+08:00">2023-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/" itemprop="url" rel="index"><span itemprop="name">学术前沿</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3><span id="bodmasan-open-dataset-for-learning-based-temporal-analysis-of-pe-malware">BODMAS:
An Open Dataset for Learning based Temporal Analysis of PE Malware</span></h3>
<blockquote>
<p>2021 <a target="_blank" rel="noopener" href="https://dblp.uni-trier.de/db/conf/sp/sp2021w.html#YangCLA021">SP
Workshops</a></p>
<p>On training robust PDF malware classifiers. (2020 USENIX)</p>
</blockquote>
<h3><span id="一-摘要">一、摘要</span></h3>
<p>我们描述并发布了一个名为BODMAS的开放PE恶意软件数据集，以促进基于机器学习的恶意软件分析的研究工作。通过仔细检查现有的open
PE恶意软件数据集，我们发现了两个缺失的功能（即<strong>最近/时间戳</strong>的恶意软件样本和精心策划的<strong>家族信息</strong>），这限制了研究人员研究<strong>概念漂移和恶意软件系列演化</strong>等紧迫问题的能力。出于这些原因，我们发布了一个新的数据集来填补空白。<strong>BODMAS数据集包含从2019年8月至2020年9月收集的57293个恶意软件样本和77142个良性样本，以及精心策划的家族信息（581个家族）</strong>。我们还进行了初步分析，以说明概念漂移的影响，并讨论该数据集如何有助于促进现有和未来的研究工作。</p>
<h3><span id="二-说明">二、说明</span></h3>
<p>如今，研究人员[30]、[5]、[11]、[6]和反病毒供应商[1]将机器学习模型（包括深度神经网络）广泛应用于恶意软件分析任务中。在这一工作领域，拥有公共数据集和开放基准是非常可取的。一方面，这些数据集将有助于促进解决开放性挑战的新工作（例如，对抗性机器学习、可解释技术[28]、[10]）。另一方面，公共基准和数据集可以帮助研究人员轻松地比较他们的模型，并跟踪整个社区的进展。然而，创建开放式恶意软件数据集是一项极具挑战性的工作。例如，[5]的作者讨论了许多此类挑战，包括<strong>法律限制、标记恶意软件样本的成本和难度，以及潜在的安全责任</strong>。除了这些因素外，另一个关键挑战是恶意软件（以及良性软件）的动态演化性质[20]。随着时间的推移，新的恶意软件系列和变种不断出现，它们不断地对底层数据分布进行更改。因此，随着时间的推移，不断需要发布新的数据集和基准。在过去的十年中，只有少数公开的PE恶意软件数据集发布到研究社区[30]。值得注意的例子包括Microsoft恶意软件分类挑战数据集[24]、Ember[5]、<strong>UCSB打包恶意软件数据集[2]</strong>和最近的SOREL-20M数据集[11]。我们在表一中总结了它们的主要特征。</p>
<blockquote>
<p>[30] Survey of machine learning techniques for malware analysis.
(2019 C&amp;S)</p>
<p>[5] Ember: an open dataset for training static pe malware machine
learning models</p>
<p>[11] SOREL-20M: A Large Scale Benchmark Dataset for Malicious PE
Detection</p>
<p><strong>[6] Scalable, behavior-based malware clustering (2009
NDSS)</strong></p>
<p><strong>[28] Exploring backdoor poisoning attacks against malware
classifiers</strong></p>
<p><strong>[10] Maldae: Detecting and explaining malware based on
correlation and fusion of static and dynamic characteristics. (2019
C&amp;S)</strong></p>
<p>[20]</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/2Y43CXR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/2Y43CXR/" class="post-title-link" itemprop="url">恶意软件检测（6）DeepReflect：通过二进制重构发现恶意行为</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-08-05 12:18:22" itemprop="dateCreated datePublished" datetime="2021-08-05T12:18:22+08:00">2021-08-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-19 15:50:27" itemprop="dateModified" datetime="2023-04-19T15:50:27+08:00">2023-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/" itemprop="url" rel="index"><span itemprop="name">学术前沿</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>17 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="usenixsec21deepreflect通过二进制重构发现恶意行为经典">USENIXSec21
DeepReflect：通过二进制重构发现恶意行为（经典）</span></h2>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg5MTM5ODU2Mg&amp;mid=2247495981&amp;idx=1&amp;sn=fa34f5211e67a7d6c144019424657d22&amp;chksm=cfcf41e0f8b8c8f6e91705e142147a6803ca1af45aa8173727e7858788b1473da5b00db25d7b&amp;scene=178&amp;cur_album_id=1776483007625822210#rd">参考材料</a></p>
<p>原文作者：Evan Downing, Yisroel Mirsky, Kyuhong Park, Wenke Lee
原文标题：DeepReflect: Discovering Malicious Functionality through
Binary Reconstruction
原文链接：https://www.usenix.org/conference/usenixsecurity21/presentation/downing
发表会议：USENIXSec 2021
<strong>代码地址</strong>：https://github.com/evandowning/deepreflect</p>
</blockquote>
<h3><span id="一-摘要">一、摘要</span></h3>
<p>深度学习已在恶意软件分类任务中表现出良好的结果。然而：</p>
<ul>
<li><strong>人工分析效率低</strong>：对于未知恶意软件的binary，分析人员仍要花大量时间来利用静态分析工具逆向整个binary，从而识别关键的恶意行为</li>
<li><strong>监督学习开销大</strong>：尽管机器学习可用来帮助识别二进制的重要部分，但由于获取足够大的标记数据集开销很大，因此监督学习方法是不切实际的</li>
</ul>
<p><strong>为了提高静态（或手动）逆向工程的生产力，我们提出了DeepReflect：一种用于定位（localize）和识别（identify）恶意二进制文件中恶意软件组件的工具。</strong></p>
<ul>
<li>为了定位恶意软件组件，我们以一种新型（novel）方式，即首先使用一个<strong>无监督的深度神经网络l来定位恶意软件中恶意组件（函数）的位置</strong></li>
<li><strong>其次，通过半监督聚类分析对恶意组件进行分类，根据恶意行为分类确定恶意函数的行为</strong>，其中分析人员在他们的日常工作流程中逐步提供标签</li>
<li>该工具是实用的，因为它不需要数据标记（require no data
labeling）来训练定位模型，也不需要最小/非侵入性标记来增量地训练分类器</li>
</ul>
<h4><span id="11-企业界对比capa">1.1 <strong>企业界对比：CAPA</strong></span></h4>
<p>我们通过5个恶意软件分析人员对超过26k个恶意软件样本进行评估。<strong>实验发现，DeepReflect让每个分析人员需要逆向工程的函数数量平均减少了85%</strong>。本文方法还可以检测到80%的恶意软件组件，而当使用基于签名的工具CAPA时，该值仅为43%。</p>
<h4><span id="12-学术界对比shap">1.2 <strong>学术界对比：Shap</strong></span></h4>
<p>此外，DeepReflect提出的自动编码器（autoencoder）比Shap（一种人工智能解释工具）表现得更好。这一点很重要，因为<strong>Shap是一种最先进（state-of-the-art）的方法，需要一个标记的数据集</strong>，而我们的自动编码器不需要。</p>
<h3><span id="二-引言">二、引言</span></h3>
<h4><span id="21-背景引出挑战">2.1 背景引出挑战</span></h4>
<p>静态逆向工程恶意软件可能是一个手动且乏味的过程。公司每周可以收到多达
500
万个PE样本。虽然大多数组织提前对这些样本进行分类（triage），以减少要分析的恶意软件数量（即，检查
VirusTotal来获取反病毒 (AV)
引擎结果、在受控沙箱中执行样本、提取静态和动态签名等）
，但最终仍然需要静态逆向工程的恶意软件样本。这是因为<strong>总会有新的恶意软件样本</strong>，没有被反病毒公司分析过，或者缺乏签名来识别这些新样本。最终，该样本有可能会拒绝在分析人员的动态沙箱（sandbox）中执行。</p>
<p>当前的解决方案以为恶意软件样本创建签名、分类和聚类的形式存在。然而，这些解决方案只能预测样本的类别（例如，良性与恶意，或特定的恶意软件家族）。<strong>他们无法定位或解释恶意软件样本本身内部的行为（定位恶意函数位置、解释恶意函数行为），而分析师需要执行（perform）这些行为来生成报告并改进他们公司的恶意软件检测产品</strong>。事实上，由于工作量过大，该领域已呈现了倦怠。</p>
<p>为了确定他们的需求，我们咨询了四名逆向工程恶意软件分析师（一名来自AV公司，三名来自政府部门）。本文发现，如果恶意软件分析师有一个工具可以：</p>
<ul>
<li><strong>识别恶意软件中恶意函数的位置</strong></li>
<li><strong>标记这些恶意函数的行为</strong></li>
</ul>
<p>那么，他们的工作将更有效率。开发这样一种工具的挑战在于：</p>
<ul>
<li><strong>需要能够区分什么是良性的（benign），什么是恶意的（malicious）</strong></li>
<li><strong>理解识别出的恶意行为的语义</strong></li>
</ul>
<p>对于第一个挑战，区分良性和恶意是困难的，因为恶意软件和良性软件的行为通常在高层次上重叠。对于第二个挑战，自动标记和验证这些行为是很困难的，因为没有单独标记的恶意软件函数的数据集（与使用反病毒标签的开放数据集的恶意软件检测和分类系统不同）。</p>
<h4><span id="22-如何解决挑战">2.2 如何解决挑战</span></h4>
<p>为了解决这些挑战，我们开发了DEEPREFLECT，它使用：</p>
<ul>
<li><font color="red"><strong>一个无监督的深度学习模型来定位二进制中的恶意函数【异常检测】</strong></font></li>
<li><font color="red"><strong>一个半监督聚类模型，它使用从分析人员的日常工作流程中获得的少量标签对识别的函数进行分类</strong></font></li>
</ul>
<p><strong>为了定位（locate）二进制文件中的恶意软件组件，我们使用自动编码器(autoencoder，AE)</strong>。AE是一种基于神经网络的机器学习模型，<strong>其任务是将其输入重构为输出（编码还原）</strong>。由于网络内层存在压缩，AE被迫学习训练分布中的关键概念。我们的直觉是，如果在良性二进制文件上训练AE，它将很难重建恶意二进制文件（即我们没有训练它的样本）。自然地，AE将无法重建（reconstruct）包含恶意行为的二进制数据区域（在良性样本中是不可见或罕见的）。<font color="red"><strong>因此（Thus），重构错误可以用来识别恶意软件中的恶意组件</strong></font>。此外，由于AE是以无监督的方式训练的，我们不需要数百万标记的样本，公司可以利用自己的恶意软件二进制数据集。</p>
<p><strong>为了对定位的恶意软件组件进行分类</strong>，我们：</p>
<ul>
<li>对恶意软件样本中所有已识别的函数进行聚类</li>
<li>使用分析人员在日常工作流程中所做的注释（即少量人工分析的函数行为标签）来标记聚类结果</li>
</ul>
<p><strong>这种方法是半监督的，因为每个类簇（cluster）只需要少数函数的行为标签（如三个）即可将大多数标签分配给整个集群</strong>。随着时间推移，我们可以将AE识别的函数映射到聚类模型来预测函数的类别（如，C&amp;C、特权升级等），即认为函数和最接近的类簇有相同的行为标签。这反过来又节省了分析人员的时间，因为他们不必一次又一次地对相同的代码进行逆向工程。</p>
<p>注意，无监督 AE
为恶意软件分析人员提供了即时实用程序，无需训练或使用半监督聚类模型。这是因为它：</p>
<ul>
<li><strong>通过对最相关的函数进行排序（重构误差）来吸引分析师的注意力</strong></li>
<li>过滤掉可能需要花费分析师数小时或数天时间来解释的函数</li>
</ul>
<blockquote>
<p>DEEPREFLECT根据我们是为恶意软件分析人员的反馈进行设计和修改的，并评估其有效性和实用性。</p>
<p><strong>我们评估了DEEPREFLECT的性能，包括五个工作：</strong></p>
<ul>
<li>识别恶意软件中的恶意活动</li>
<li>聚类相关的恶意软件组件</li>
<li>将分析人员的注意力集中在重要事情上</li>
<li>揭示不同恶意软件家族之间的共享行为</li>
<li>处理涉及混淆的对抗性攻击</li>
</ul>
</blockquote>
<h4><span id="23-创新contribution">2.3 创新（Contribution）</span></h4>
<p><strong>我们的贡献如下：</strong></p>
<ul>
<li><strong>提出了一个新颖的工具，它可以帮助恶意软件分析师：(1)
在静态恶意软件样本中自动定位和识别恶意行为，(2)
洞察分析不同恶意软件家族之间的功能关系。</strong></li>
<li><strong>提出一种在静态分析中使用机器学习的新颖实用方法</strong>：（1)
AE训练是在一种无监督方式下进行的，<strong>无需为系统标注任何样本</strong>，就可以产生突出显示恶意软件组件的实用程序，(2)
分类是以半监督方式完成，<strong>具有最小的干预</strong>：分析人员的常规工作流的注释用作标签，群集中的大多数标签用于对相关的恶意软件组件进行分类。</li>
<li>本文提出了一种解释框架（如我们提出的 AE 或
SHAP）定位恶意软件重要部分的方法，该方法可以<strong>映射回原始二进制或控制流图的特征</strong>。</li>
</ul>
<h3><span id="3-scope-amp-overview">3 <strong>Scope &amp; Overview</strong></span></h3>
<h4><span id="31-motivation">3.1 Motivation</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550446.png" alt="图片" style="zoom: 67%;"></p>
<p><font color="red"><strong>图1展示了一个典型的恶意软件分析师Molly的工作流程</strong>
</font>。当给定一个恶意软件样本，Molly的任务是了解该样本在做什么，以便她写一份技术报告并改进公司的检测系统，从而在未来识别该类样本。</p>
<ol type="1">
<li><strong>首先查询VT（virtotul）和其他组织</strong>，以确定他们以前是否见过这个特定的样本，然而并没有</li>
<li>在一个自定义的<strong>沙箱中执行样本以了解其动态行为</strong>，然而没有显示任何恶意行为或拒绝执行；运行一些内部工具，诱使恶意软件执行其隐藏的行为，但仍无效时；</li>
<li>尝试<strong>脱壳（unpacking）</strong>和<strong>静态逆向分析恶意样本</strong>，以了解其潜在行为</li>
<li><font color="red"><strong>在反汇编程序（IDA Pro 或
BinaryNinja）中打开脱壳后的样本，被数千个函数淹没，接着运行各种静态签名检测工具来识别恶意软件的某些特定恶意组件，但仍无效</strong></font></li>
<li>逐个<strong>查看每个函数（可能通过 API
调用和字符串过滤）以尝试了解它们的行为</strong></li>
<li><strong>在分析样本的行为后，撰写分析报告（包含基本信息、IOC、静态签名等）</strong></li>
</ol>
<p>然而，当新的样本出现时，Molly需要重复同样的任务。由于这种重复的体力劳动，这项工作对Molly来说变得单调乏味和耗时。<font color="red">
<strong>DEEPREFLECT旨在减轻恶意分析师的分析工作，能逆向一个未知的恶意软件样本，从而减轻他们繁重的任务，并为相似的函数标注行为标签。</strong></font></p>
<h4><span id="32-proposed-solution">3.2 Proposed Solution</span></h4>
<p>我们提出了<strong>DEEPREFLECT</strong>，该工具能：</p>
<ul>
<li><p><strong>定位恶意软件binary中的恶意函数</strong></p>
<blockquote>
<p>locates malicious functions within a malware binary</p>
</blockquote></li>
<li><p><strong>描述这些函数的行为</strong></p>
<blockquote>
<p>describes the behaviors of those functions</p>
</blockquote></li>
</ul>
<p>虽然分析人员可能首先尝试通过搜索特定的字符串和API调用来静态地识别行为，但这些行为很容易被分析人员混淆或隐藏（
obfuscated or
hidden）。<strong>DEEPREFLECT没有做出这样的假设，并试图通过控制流图(control-flow
graph，CFG)特性和API调用（API
calls）的组合来识别这些相同的行为</strong>。</p>
<p><font color="red">
<strong>DEEPREFLECT通过学习正常情况下良性的二进制函数来工作</strong></font>。因此，任何异常都表明这些函数不会出现在良性二进制文件中，而可能被用于恶意行为中。这些异常函数更可能是恶意函数，分析师可以只分析它们，从而缩小工作范围。如图5所示，DEEPREFLECT将分析师必须分析的函数数量平均减少了
85%。此外，实验表明我们的方法优于旨在实现相同目标的基于签名的技术。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550151.png" alt="图片" style="zoom:67%;"></p>
<h4><span id="33-research-goals">3.3 Research Goals</span></h4>
<p>本文有四个主要目标：</p>
<ul>
<li>准确地识别恶意软件样本中的恶意活动</li>
<li>帮助分析人员在静态分析恶意软件样本时集中注意力</li>
<li><strong>处理新的（不可见的）恶意软件家族</strong></li>
<li><strong>深入了解恶意软件家族的关系和趋势</strong></li>
</ul>
<h3><span id="4-模型设计">4、模型设计</span></h3>
<h4><span id="41-总体框架">4.1 总体框架</span></h4>
<p><strong>DEEPREFLECT的目标是识别恶意软件二进制中的恶意函数</strong>。在实践中，<font color="red"><strong>它通过定位异常基本块（感兴趣区域
regions of
interest，RoI)来识别可能是恶意的函数</strong></font>。然后，分析人员必须确定这些函数是恶意行为还是良性行为。DEEPREFLECT有两个主要步骤，如图2所示：</p>
<ul>
<li><strong>RoI检测（RoI
detection）</strong>：通过AE（AutoEncoder）来执行的</li>
<li><strong>RoI注释（RoI
annotation）</strong>：通过对每个函数的所有RoI聚类，并将标记聚类结果来执行注释。注意，一个函数可能有多个ROI，用每个函数自己的ROI的均值表示该函数，然后对函数聚类</li>
</ul>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550631.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h5><span id="1术语-terminology">（1）术语 Terminology</span></h5>
<p><strong>首先定义恶意行为（malicious
behaviors）的含义</strong>。我们根据识别恶意软件源代码的<strong>核心组件</strong>（例如，拒绝服务功能、垃圾邮件功能、键盘记录器功能、命令和控制C&amp;C功能、利用远程服务等）来生成真实情况（ground-truth）。<font color="red"><strong>通过MITRE
ATT&amp;CK框架描述</strong></font>，如表3所示。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550843.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p><strong>然而，当静态逆向工程评估恶意软件二进制文件时（即在野生恶意软件二进制
in-the-wild malware
binaries），我们有时无法肯定地将观察到的低级函数归因于更高级别的描述</strong>。</p>
<p>例如，恶意软件可能会因为许多不同的原因修改注册表项，但有时确定哪个注册表项因什么原因而被修改是很困难的，因此只能粗略地标记为“<font color="red"><code>防御逃避：修改注册表（Defense Evasion: Modify Registry）</code>”
</font>。即使是像CAPA这样的现代工具，也能识别出这些类型的模糊标签。<strong>因此，在我们的评估中，我们将“恶意行为”表示为可由MITRE
ATT&amp;CK框架描述的函数。</strong></p>
<h5><span id="2-roi-detection">（2） <strong>RoI Detection</strong></span></h5>
<p><strong>检测的目标是自动识别恶意软件二进制文件中的恶意区域</strong>。例如，我们希望检测C&amp;C逻辑的位置，而不是检测该逻辑的特定组件（例如，网络API调用connect()、send()
和
recv()）。<strong>RoI检测的优点是分析人员可以快速定位启动和操作恶意行为的特定代码区域</strong>。先前的工作只关注于创建临时签名，简单地将二进制文件标识为恶意软件或仅基于API调用的某些函数。这对于分析人员扩大他们的工作特别有用（即不仅仅依赖手动逆向工程和领域专业知识）。</p>
<h5><span id="3-roi-annotation"><strong>(3) RoI Annotation</strong></span></h5>
<p><strong>注释的目标是自动标记包含RoI的函数的行为，即识别恶意函数在做什么</strong>。由于分析人员为标记集群所执行的初始工作是一个长尾分布。也就是说，只需要前期做比较重要的工作，随着时间推移，工作量会减少。这个过程的优点很简单：它为分析人员提供了一种自动生成未知样本的报告及见解的方法。例如，如果恶意软件示例的变体包含与之前的恶意软件示例相似的逻辑（但对于分析人员来说看起来不同以至于不熟悉），我们的工具为他们提供了一种更快实现这一点的方法。</p>
<h4><span id="42-roi-detection">4.2 RoI Detection</span></h4>
<p>首先介绍了AutoEncode（AE）神经网络。此外，先前的工作已经证明，当自动编码器在良性分布上进行训练时，AE可以检测到恶意（异常）行为。我们的假设是，与良性二进制文件相比，恶意软件二进制文件将包含相似但独特的功能。</p>
<p>当使用大量良性样本训练AE后，给定一个随机的样本，可以利用公式(2)计算，超过<strong>MSE</strong>的即认为是恶意区域，突出显示ROI异常基本块。与先前识别整个样本为恶意区域的工作相比，我们识别了每个样本中的恶意区域。具体而言，我们计算的
<code>localized MSE</code> 定义如下： <span class="math display">\[
\operatorname{LMSE}(x, \hat{x})=\left(x^{(i)}-\hat{x}^{(i)}\right)^{2}
\]</span></p>
<h4><span id="1features"><font color="red">
（1）<strong>Features</strong></font></span></h4>
<p>为了在二进制样本中定位恶意行为的位置，编码使用的特征必须一对一的映射回原样本。<strong>因此，作者将每个二进制文件表示为一个
m×c
的矩阵，该矩阵使用c个静态特征捕获前m个基本块以总结样本的behavior</strong>。<strong>m设置为20k个基本块，是因为95%的数据集样本具有20k或者更少的基本块，
c设置为18个特征</strong>。<strong>基本块</strong>通常是以控制传输指令结尾的一系列指令。当然，根据反汇编程序的不同，基本块可能会有不同的表示，因此这种严格的定义可能不适用于所有静态恶意软件分析系统。</p>
<p>我们特征（c）的灵感来自于先前工作中发现的特征，即<strong>属性控制流图（attributed
control flow
graph，ACFG）</strong>特征<strong>[23,75]</strong>。在这些工作中，ACFG特征被选择来执行二进制相似性，因为它们假设这些特征(由结构和数字CFG特征组成)将在多个平台和编译器上是一致的。</p>
<blockquote>
<p><strong>[23] Scalable graph-based bug search for firmware images.
2016 CCS</strong></p>
<p><strong>[75] Neural Network-based Graph Embedding for Cross-Platform
Binary Code Similarity Detection. 2017 CCS</strong></p>
</blockquote>
<p>虽然可以说我们的目标是相似的（即识别二进制文件之间的异同），但我们专门为研究恶意软件定制了这些功能。特别是，我们选择了autoencoder要使用的功能，以捕获更高级别的行为。我们的特征包括每个<strong>基本块中的指令类型计数</strong>（为ACFG特征提取的指令类型的更详细形式）、<strong>CFG的结构特征</strong>和<strong>API调用类别</strong>（用于总结恶意软件程序行为[18]），将每个基本块总结如下：</p>
<h5><span id="astructural-characteristics"><font color="red">(a)
<strong>Structural Characteristics</strong> </font></span></h5>
<p><strong>结构特征2个</strong>，每个<strong>基本块的后代（offspring）数量</strong>和<strong>betweenness
score</strong>，可以描述不同功能的<strong>控制流结构</strong>，比如网络通信（connect,
send, recv）或文件加密（findfile, open, read, encrypt, write,
close）。如图所示:</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550517.png" alt="image-20220602164403223" style="zoom:67%;"></p>
<blockquote>
<p>该恶意软件通过InternetOpenUrlA() 访问URL，通过CreateFileA()
创建文件，并通过InternetReadFile() 和WriteFile()
将从连接接收的数据写入文件。</p>
</blockquote>
<p><strong>(b) Arithmetic Instructions</strong></p>
<p><strong>算术指令3个</strong>，每个<strong>基本块基本数学、逻辑运算、位移指令的数量</strong>（“basic
math”, “logic operation”, and “bit
shifting”）。这些算术指令特征可以用来表示如何对更高层次的行为执行数学运算，以及数字如何与函数交互。例如，加密函数可能包含大量的xor指令，混淆函数可能包含逻辑和位移操作的组合等。<strong>我们从《英特尔体系结构软件开发人员手册》[26]中检索到这些说明</strong>。此外，我们还提供了一个恶意软件示例，在图中展示了这些类型的功能。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550537.png" alt="image-20220602164519015" style="zoom:67%;"></p>
<blockquote>
<p>此函数对数据执行各种按位操作。类似这样的复杂逻辑可以解释为执行某种除臭或解码，以隐藏恶意软件解释或收集的数据。</p>
</blockquote>
<p><strong>(c) Transfer Instructions</strong></p>
<p><strong>转移指令</strong>3个，每个基本块<strong>内堆栈操作，寄存器操作和端口操作的数量</strong>（“stack
operation”, “register operation”, and “port
operation”）。这些底层特征可描述更高级别函数的<strong>传输操作</strong>，比如函数的参数和返回值是如何与函数内其余数据交互的，从而描述更复杂的逻辑和数据操作。<strong>例如去混淆、解密函数可能设计更多move-related指令，C&amp;C逻辑设计更多堆栈相关指令</strong>。因为它调用了更多的内部/外部函数。我们同样从《英特尔体系结构软件开发人员手册》中检索到了这些说明</p>
<p><strong>(d) API Call Categories</strong></p>
<p><strong>API类别10个</strong>，我们使用的API调用特性是每个基本块中与<strong>“文件系统”、“注册表”、“网络”、“DLL”、“对象”、“进程”、“服务”、“同步”、“系统信息”和“时间”相关的API调用的数量</strong>。这些类别的灵感来自<strong>priorwork
for malware
clustering</strong>[18]。这些特性可用于表示执行恶意活动（如网络通信和文件系统、注册表和进程操作）所需的高级库操作。由于这些直接表示高级行为，因此它们对于理解函数的总体行为至关重要。<strong>下图显示了利用这些不同调用类型执行不同行为的恶意软件功能的示例。</strong></p>
<blockquote>
<p><strong>[18] Scalable, Behavior-Based Malware Clustering. NDSS
2009.</strong></p>
</blockquote>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550690.png" alt="image-20220602164417162" style="zoom:67%;"></p>
<blockquote>
<p>此函数用于搜索具有特定扩展名（即doc、jpg等）的各种文件。然后将这些文件复制到单独的位置。此行为可能是针对其他恶意行为的设置，如数据外泄或勒索。</p>
</blockquote>
<p><strong>我们认为，与经典的ACFG功能相比，这些功能更适合恶意软件</strong>，因为（1）它们包括在priorwork中用于恶意软件检测的API调用（2）<strong>指令类别更细粒度，允许每个基本块中有更多的上下文</strong>（如前所述）以及（3）<font color="red"><strong>它们不依赖太容易规避攻击的字符串</strong></font>[77]。当然，如果有一个有动机的对手，任何机器学习模型都可能受到攻击和欺骗，从而产生错误和意外的输出。虽然我们的功能和模型也不例外，但我们认为它们足以产生可靠的模型（即，其行为符合预期），并使其变得足够困难，以至于对手必须广泛地工作以产生误导性的输入（如中所示 4.7).
有关对我们系统的潜在攻击的讨论，请参阅 5.</p>
<h4><span id="2模型">（2）模型</span></h4>
<p><strong>Autoencoder使用U-Net模型，U-Net的优点是其在编码器和解码器之间有跳过连接（skip
connections），对样本x可以跳过某些特征的压缩以在重构的x’中保持更高的保真度</strong>。</p>
<p>首先收集大量的良性样本，对每个binary抽取上述18个静态特征用于表示该binary。设有用feature表示的样本x，AE重构后得到x’，训练的目标是最小化重构损失，即输入x和输出x’之间的损失。</p>
<p><strong>RoI
Detection会在m个基本块中检测出一些异常基本块</strong>。这些基本块分别属于不同的函数，使用例如BinaryNinja的工具就可以确定ROI属于哪些函数，即认为这些函数可能是恶意函数，也就完成了恶意函数定位的任务。<strong>后续RoI
Annotation就是对这些函数聚类，完成恶意函数行为标记（分类）的任务。</strong></p>
<h4><span id="43-roi-annotation">4.3 RoI Annotation</span></h4>
<p><strong>给定一个新样本x，我们希望识别其每个函数的行为（类别），并将其报告给Molly</strong>。由于标记所有的函数都是不实用的，所以我们只注释了少量的函数，并使用聚类分析来传播结果。</p>
<h5><span id="1clusteringfeatures">（1）<strong>Clustering
Features</strong></span></h5>
<p>假设一组脱壳恶意软件，按上述特征提取方式（18种特征）得到每个binary的特征表示，其中一个binary为x。</p>
<p><strong>（2）Clustering Model</strong></p>
<p>使用PCA将特征数从18降维至5，然后使用HDBSCAN算法对5维特征聚类。</p>
<h3><span id="五-实现">五、实现</span></h3>
<p>接下来，我们将描述如何部署和使用它。</p>
<p><strong>(1) Initialization</strong></p>
<ul>
<li>首先对良性和恶意binaries脱壳</li>
<li>提取binary静态特征，形成20×18的矩阵</li>
<li><strong>用良性样本训练AutoEncoder</strong></li>
<li><strong>使用训练好的AE从恶意样本中提取ROIs，即恶意基本块位置</strong></li>
<li>计算恶意二进制中恶意函数的行为表示，加入聚类的训练集D</li>
<li>PCA降维并聚类生成C</li>
</ul>
<p>人工分析恶意软件手动打标，这些label注释到聚类训练集中，从而评估实验结果。换句话说，每个cluster只需要其中几个函数的label，就可确定整个cluster的label，即确定整个cluster中函数的恶意行为。</p>
<p><strong>(2) Execution</strong></p>
<p>当Molly收到一个新的样本x，DeepReflect会自动定位恶意函数并标注恶意行为。</p>
<ul>
<li><strong>对样本x执行脱壳（unpack）</strong></li>
<li>通过AutoEncoder获取ROIs</li>
<li>使用BinaryNinja以及ROIs确定恶意函数集合，然后计算恶意函数的行为表示</li>
<li>PCA模型降维</li>
<li>计算每个恶意函数最相近的集群，通过计算和聚类中心的距离实现</li>
<li>分配大数据集群注释给函数</li>
</ul>
<p>接下来，Molly分析highlighted functions，从而实现：</p>
<ul>
<li>obtains a better perspective on what the malware is doing</li>
<li>annotates any function labeled “unknown” with the corresponding
MITRE category (dynamically updating D)</li>
<li>observe shared relationships between other malware samples and
families by their shared
clusters（共享关系，分析恶意软件家族的相关性）</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/GW7NEC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/GW7NEC/" class="post-title-link" itemprop="url">恶意软件检测（13）Dynamic Malware Analysis</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-05-29 19:59:06" itemprop="dateCreated datePublished" datetime="2021-05-29T19:59:06+08:00">2021-05-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-19 16:24:26" itemprop="dateModified" datetime="2023-04-19T16:24:26+08:00">2023-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/" itemprop="url" rel="index"><span itemprop="name">学术前沿</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="dynamicmalware-analysis-in-the-modern-eraa-state-of-the-art-survey">Dynamic
Malware Analysis in the Modern Era—A State of the Art Survey</span></h2>
<p>​
本次调查的目的是对用于动态分析恶意软件的现有方法进行全面和最新的概述，其中包括对每种方法的<strong>描述</strong>、其<strong>优缺点</strong>以及对<strong>恶意软件规避技术的适应性</strong>。此外，我们还概述了利用机器学习方法来增强动态恶意软件分析能力的一些重要研究，这些研究旨在检测、分类和分类。</p>
<h4><span id="学习内容">学习内容：</span></h4>
<ul>
<li>分析方法：<strong>易失性内存取证（volatile memory
forensics）、侧通道分析（side-channel analysis）</strong></li>
</ul>
<h4><span id="动态分析的意义">动态分析的意义：</span></h4>
<ol type="1">
<li>虽然恶意软件编写者可以使用各种技术（如代码混淆、动态代码加载、加密和打包）来逃避静态分析（包括基于签名的防病毒工具）态分析对这些技术是健壮的，并且可以提供关于所分析文件的更多理解，因此可以导致更好的检测能力。</li>
</ol>
<h4><span id="动态分析的局限性">动态分析的局限性：</span></h4>
<ul>
<li>只有执行的代码是可观察的。这意味着，如果没有精确地满足所需的条件，那么某些代码可能无法执行，从而无法进行分析。<strong>Deeplocker</strong></li>
<li>动态分析还需要计算开销，这可能会降低执行速度。</li>
<li>分析必须在恶意软件针对的特定操作系统和/或硬件上执行。</li>
</ul>
<h4><span id="说明">说明：</span></h4>
<ul>
<li>物联网设备是另一个可以受益于内存分析的平台示例，因为基于软件的新检测机制的设计和安装并不简单。此外，由于物联网设备具有有限的计算资源，现有的动态分析技术对于此类设备可能不太相关或有效。</li>
</ul>
<h4><span id="恶意软件分类">恶意软件分类</span></h4>
<ul>
<li>Classification of Malware by Type</li>
<li>Classification of Malware by Malicious Behavior</li>
<li>Classification of Malware by Privilege</li>
<li>About Behavior and Privilege</li>
</ul>
<h4><span id="analyzing-malware-behavior">ANALYZING MALWARE BEHAVIOR</span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191623702.png" alt="image-20210529200406017">
<figcaption aria-hidden="true">image-20210529200406017</figcaption>
</figure>
<h4><span id="动态恶意软件分析框架描述">动态恶意软件分析框架描述</span></h4>
<h4><span id="分析技术和学术工具">分析技术和学术工具</span></h4>
<ul>
<li><h5><span id="函数功能分析">函数功能分析</span></h5>
<ul>
<li>每个进程都依赖函数调用来执行其职责，不管这些函数是进程内部的还是外部的（例如，由其他进程导出的函数、系统调用）。通过跟踪恶意软件调用的各种函数以及与这些函数相关的参数，可以更好地了解所分析恶意软件的行为。调用函数时获取通知可以通过将一段代码<strong>Hooking</strong>到该函数来实现。
<ul>
<li>hooking mechanism</li>
<li>code injection</li>
</ul></li>
<li><strong>TTAnalyze(LastLine)</strong>是一个分析工具，它用一个称为Inside
the
Matrix（insideetm）的客户机组件扩展了QEMU仿真器，该组件将虚拟地址转换为物理地址。</li>
<li><strong>CWSandbox</strong>基于将可信DLL的代码注入到分析的进程中，该进程通过覆盖导出地址表（EAT）中的条目并将执行重定向到CWSandbox来拦截函数调用。CWSandbox收集大量的信息（比如被调用函数的名称、参数、系统状态等），然后将这些信息呈现给用户。</li>
<li><strong>Capture</strong>使用三个监视器分析操作系统的状态：<strong>文件系统监视器</strong>（跟踪所有硬盘上的读/写事件）、<strong>注册表监视器</strong>（跟踪多个注册表事件，如OpenKey、CreateKey等）和<strong>进程监视器</strong>（跟踪进程的创建和终止）。所有监视器都提供其他数据，如触发事件的进程、完整路径和时间戳。使用内核驱动程序，捕获与上述每个监视器对应的内核事件。最终结果是恶意软件触发的事件列表，以及它们的时间戳和参数。</li>
<li><strong>MalTRAK</strong>是一个跟踪恶意软件行为并扭转其影响的框架。它使用内核模式组件并将自身与关键函数挂钩，以跟踪恶意软件的操作，同时提供撤消这些操作的机制。</li>
<li><strong>dAnubis</strong>是用来分析内核驱动程序和检测rootkit的。它使用一个in-guest组件来监视rootkit和系统其余部分之间的通信。触发器引擎调用各种windowsapi调用来显示<strong>rootkit（定义为一组在恶意软件中获得root访问权限、完全控制目标操作系统和其底层硬件的技术编码）</strong>的存在（例如，隐藏的进程或文件）。</li>
</ul></li>
<li><h5><span id="execution-control-执行控制">Execution Control 执行控制</span></h5>
<p>动态恶意软件分析应该包含一种机制，偶尔停止恶意软件的执行，并检查恶意进程和操作系统的状态。执行控制技术包括：</p>
<ul>
<li><strong>Debugging</strong>调试（也称为单步）是一种可靠的分析技术，最初是为了帮助程序员发现代码中的错误而开发的。使用CPU的陷阱标志在每个操作码指令后生成中断，调试器可以允许恶意软件在强制上下文切换回分析进程之前只运行一条操作码指令，然后分析进程可以检查恶意软件和操作系统的状态。</li>
<li>等</li>
</ul></li>
<li><p><strong>Flow Tracking 流量跟踪</strong></p>
<p>细粒度分析用于跟踪通过恶意软件执行代码的信息流（例如，当一个函数的结果用作调用另一个函数的参数时）。</p>
<ul>
<li><strong>Data Tainting</strong></li>
<li><strong>Vigilite</strong>是一种分析工具，它使用二进制工具实现数据污染。最初是为了检测和阻止蠕虫的传播而开发的，Vigilite寻找来自网络的受污染数据的执行。因此，污点源是网络，当指令指针（IP）指向污点数据时，污点接收器就到达了，这意味着一些来自网络的不可信代码正在被执行。</li>
<li><strong>Panorama</strong>最初是一个TEMU插件，用于对各种I/O设备（包括硬盘、键盘或鼠标）进行污染分析。后来成为一个独立的平台。全景图的输出是以图形的形式提供的，它允许用户跟踪进程和内存区域之间的数据流。</li>
<li><strong>Dytan</strong>是Pin仪器系统的一个扩展，为数据污染提供了一个易于使用的API。它的开发采用了灵活的设计，允许用户配置各种组件，如污染源、污染汇、数据流跟踪器和控制流跟踪器。Dytan可以配置为跟踪显式和隐式信息流。此外，它的功能可以通过使用回调函数来扩展，回调函数实现额外的污染源、标签、传播和接收器。</li>
<li><strong>TQana</strong>是一个构建在QEMU之上的框架，用于分析和检测安装在internetexplorer上的恶意浏览器扩展。它使用带有两个污点源的数据污点：（1）用户访问的页面的所有URL字符串和（2）浏览器收到的响应其请求的信息。污点接收器是文件系统、注册表和网络。当受污染的数据被写入文件或通过网络发送时，被分析的样本就被怀疑是间谍软件。</li>
</ul></li>
<li><p><strong>Tracing 追踪</strong></p>
<p>收集执行某些代码后留下的信息称为跟踪。网络连接和分配给恶意软件的内存会留下恶意软件行为的痕迹。分析这些痕迹可以提供有关恶意软件的见解，而无需使用客户端组件中的。</p>
<ul>
<li><strong>Volatile memory analysis
易失性内存分析分析</strong>从内存转储文件分析恶意软件的影响（见第6.5节）需要了解操作系统如何跟踪进程、文件、用户和配置。所有这些数据结构都以二进制形式存在于内存转储中。</li>
<li><strong>Network Tracing</strong>
网络跟踪由于恶意软件在大多数情况下需要连接Internet才能执行其操作，因此在没有Internet访问的情况下，可能无法显示恶意软件的确切性质。然而，允许恶意软件完全访问互联网有时是不可取或不可能的。通过恶意软件限制网络访问并分析网络连接可以揭示恶意软件的C&amp;C和从中收到的命令。恶意软件留下的网络痕迹有助于理解其呈现的通信模式。</li>
<li><strong>HookFinder</strong>是TEMU实现的另一部分，旨在通过分析易失性内存来检测和分析恶意钩子。在堆栈中找到的信息被转换为创建钩子图，这有助于识别钩子链。然后，HookFinder将属于恶意软件的内存段标记为污点接收器。为了验证钩子实际上是由恶意软件安装的，HookFinder调用各种函数调用，并通过检查指令指针（IP）来跟踪控制流。当IP指向受污染的内存时，恶意钩子就会被发现并验证。</li>
<li><strong>LiveDM</strong>利用QEMU来分析内核中新内存区域的分配。通过挂接操作系统实现的几个内存分配函数，它可以跟踪恶意软件的安装位置，并对恶意软件的二进制代码执行静态分析。使用模拟器对客户操作系统的控制，LiveDM能够获得客户操作系统的易失性内存并分析受感染的内核。</li>
<li>等</li>
</ul></li>
<li><p><strong>Side-channel Analysis</strong></p>
<ul>
<li>到目前为止提出的分析技术依赖于从操作系统、易失性存储器或仿真机器的状态中提取数据。然而，任何类型的计算设备都可能成为恶意软件的攻击目标。这些设备包括PCI卡、物联网设备、硬盘、医疗设备等。分析和检测这些设备上运行的恶意软件是困难的，因为大多数情况下，这些设备不包含一个操作系统，可以支持传统的分析技术。与从操作系统的角度（或二进制级别）跟踪系统的行为不同，<strong>可以通过物理组件的功耗、电磁辐射或内部CPU事件来分析它们的行为</strong>。获取的数据分为“正常行为”和“感染行为”。使用统计方法和机器学习算法，检测到偏离正常行为可能表明CPU行为异常（例如，存在cryptominer或rootkit）。侧通道分析无法提供有关操作系统、网络或正在修改的文件的内部事件的深入信息。没有向仅仅收到最终判决的用户提供报告（称为恶意或非恶意）。</li>
<li><strong>WattsUpDoc</strong>是一种分析工具，用于使用外部设备对医疗设备进行侧信道分析。它证明了侧通道分析可以用于分析没有操作系统的设备，而无需向分析的设备加载任何代码。</li>
</ul></li>
</ul>
<h4><span id="布局映射技术mappingtechniques-to-layouts">布局映射技术（MAPPING
TECHNIQUES TO LAYOUTS）</span></h4>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191624416.png" alt="image-20210531145449113">
<figcaption aria-hidden="true">image-20210531145449113</figcaption>
</figure>
<p>​
恶意软件和分析工具之间的战争是一场军备竞赛。攻击者不断开发新的方法来规避和检测分析框架，同时负责检测恶意软件的分析框架和工具的能力也在不断提高。创建图13是为了帮助读者理解这场军备竞赛以及<strong>攻击者和分析人员使用的不同方法</strong>。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191624015.png" alt="image-20210531150025715">
<figcaption aria-hidden="true">image-20210531150025715</figcaption>
</figure>
<h4><span id="综合比较研究">综合比较研究</span></h4>
<p>本部分比较了近年来动态恶意软件分析的研究，并讨论了与此相关的趋势和参数。进行此比较，我们可以发现一些重要的见解，我们也与读者分享。</p>
<ul>
<li><p>基于功能和实际方面的比较</p>
<ul>
<li><p>我们的比较基于以下几个关键方面：</p>
<p>（1）该工具的相关性（其对科学界的影响和贡献基于引文数量和是否开源），</p>
<p>（2）该工具提供的分析的多功能性，</p>
<p>（3）用于实现该工具的分析布局（见第6节），</p>
<p>（4）工具的限制（预分析要求、所依赖的附加软件、特殊要求的硬件）和</p>
<p>（5）工具提供的输出。请注意，这些工具是按分析技术分组的，在每种技术中，它们是按出版年份排序的。关于图14的详细说明如下：</p></li>
</ul></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/2WTQDCR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/2WTQDCR/" class="post-title-link" itemprop="url">算法长征-代码随想录</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-05-07 22:20:59" itemprop="dateCreated datePublished" datetime="2021-05-07T22:20:59+08:00">2021-05-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-05-19 14:08:37" itemprop="dateModified" datetime="2022-05-19T14:08:37+08:00">2022-05-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" itemprop="url" rel="index"><span itemprop="name">数据结构</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>12k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>22 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/">代码随想录</a></li>
<li><a href>labuladong</a></li>
</ul>
<h2><span id="一-树状数组">一、树状数组</span></h2>
<p>leecode 题目：<a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/shu-zu-zhong-de-ni-xu-dui-lcof/">数组中的逆序对</a></p>
<blockquote>
<p>在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组，求出这个数组中的逆序对的总数。</p>
<p>示例 1:</p>
<p>输入: [7,5,6,4] 输出: 5</p>
</blockquote>
<p><strong>「树状数组」</strong>是一种可以<strong>动态维护序列前缀和</strong>的数据结构，它的功能是：</p>
<ul>
<li><strong>单点更新<code>update(i, v)</code></strong>:把序列 <span class="math inline">\(i\)</span> 位置的数加上一个值<span class="math inline">\(v\)</span>，这题 v = 1</li>
<li><strong>区间查询 <code>query(i)</code>：</strong>
查询序列[1⋯<em>i</em>] 区间的区间和，即 <em>i</em> 位置的前缀和</li>
</ul>
<p>修改和查询的时间代价都是 <span class="math inline">\(O(\log
n)\)</span>，其中 <em>n</em> 为需要维护前缀和的序列的长度。</p>
<h2><span id="二-单调栈">二、单调栈</span></h2>
<p>通常是一维数组，要==寻找任一个元素的右边或者左边第一个比自己大或者小的元素的位置==，此时我们就要想到可以用<strong>单调栈</strong>了。</p>
<ul>
<li><p><strong>单调栈里存放的元素是什么？</strong></p>
<p>单调栈里只需要存放元素的下标i就可以了，如果需要使用对应的元素，直接T[i]就可以获取。</p></li>
<li><p><strong>单调栈里元素是递增呢？ 还是递减呢？</strong></p>
<p><strong>注意一下顺序为
从栈头到栈底的顺序</strong>，因为单纯的说从左到右或者从前到后，不说栈头朝哪个方向的话，大家一定会越看越懵。</p></li>
<li><p><strong>目标列表遍历顺序？</strong> 倒序？正序？</p></li>
</ul>
<h3><span id="21-下一个更大元素">2.1 下一个更大元素</span></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nextGreaterElement</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">    <span class="comment"># 下一个更大的元素：单调栈(不增的不要) + 哈希 </span></span><br><span class="line">    res = &#123;&#125;</span><br><span class="line">    stack = []</span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">reversed</span>(nums2): <span class="comment"># 倒序？</span></span><br><span class="line">        <span class="keyword">while</span> stack <span class="keyword">and</span> num &gt;= stack[-<span class="number">1</span>]:</span><br><span class="line">            stack.pop()</span><br><span class="line">        res[num] = stack[-<span class="number">1</span>] <span class="keyword">if</span> stack <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">        stack.append(num)</span><br><span class="line">    <span class="keyword">return</span> [res[num] <span class="keyword">for</span> num <span class="keyword">in</span> nums1]</span><br></pre></td></tr></table></figure>
<h3><span id="21下一个更大元素2循环数组又tm是循环">2.1
下一个更大元素2（循环数组）又TM是循环</span></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">def</span> <span class="title function_">nextGreaterElements</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="comment"># 三次逆转</span></span><br><span class="line">        s = <span class="built_in">list</span>(nums[::-<span class="number">1</span>])</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums[::-<span class="number">1</span>]:</span><br><span class="line">            <span class="keyword">while</span> s <span class="keyword">and</span> s[-<span class="number">1</span>] &lt;= num:</span><br><span class="line">                s.pop()</span><br><span class="line">            <span class="keyword">if</span> s:</span><br><span class="line">                res.append(s[-<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res.append(-<span class="number">1</span>)</span><br><span class="line">            s.append(num)</span><br><span class="line">        res.reverse()</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    def nextGreaterElements(self, nums: List[int]) -&gt; List[int]:</span></span><br><span class="line"><span class="string">        # 2n 遍历</span></span><br><span class="line"><span class="string">        n = len(nums)</span></span><br><span class="line"><span class="string">        ret = [-1] * n</span></span><br><span class="line"><span class="string">        stk = list()</span></span><br><span class="line"><span class="string">        for i in range(n * 2 - 1):</span></span><br><span class="line"><span class="string">            while stk and nums[stk[-1]] &lt; nums[i % n]:</span></span><br><span class="line"><span class="string">                ret[stk.pop()] = nums[i % n]</span></span><br><span class="line"><span class="string">            stk.append(i % n)</span></span><br><span class="line"><span class="string">        return ret</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    def nextGreaterElements(self, nums: List[int]) -&gt; List[int]:</span></span><br><span class="line"><span class="string">        # 栈留判断</span></span><br><span class="line"><span class="string">        n = len(nums)</span></span><br><span class="line"><span class="string">        ans = [-1 for _ in range(n)]</span></span><br><span class="line"><span class="string">        stack = [0]</span></span><br><span class="line"><span class="string">        stack2 = []</span></span><br><span class="line"><span class="string">        for i in range(1, n):</span></span><br><span class="line"><span class="string">            while stack and nums[i] &gt; nums[stack[-1]]: # ？</span></span><br><span class="line"><span class="string">                ans[stack[-1]] = nums[i]</span></span><br><span class="line"><span class="string">                stack.pop() </span></span><br><span class="line"><span class="string">            stack.append(i)</span></span><br><span class="line"><span class="string">        while len(stack) &gt; 1: # 栈顶是最大的保留</span></span><br><span class="line"><span class="string">            for num in nums: # 从头找？</span></span><br><span class="line"><span class="string">                if num &gt; nums[stack[-1]]:</span></span><br><span class="line"><span class="string">                    ans[stack[-1]] = num</span></span><br><span class="line"><span class="string">                    break</span></span><br><span class="line"><span class="string">            stack.pop()</span></span><br><span class="line"><span class="string">        return ans</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3><span id="23-每日温度">2.3 每日温度</span></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dailyTemperatures</span>(<span class="params">self, temperatures: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">    <span class="comment"># next Geater </span></span><br><span class="line">    n = <span class="built_in">len</span>(temperatures)</span><br><span class="line">    res = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)] </span><br><span class="line">    stack = [<span class="number">0</span>] <span class="comment"># 存的初始索引</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n): <span class="comment"># 正序</span></span><br><span class="line">        <span class="keyword">while</span> stack <span class="keyword">and</span> temperatures[i] &gt; temperatures[stack[-<span class="number">1</span>]]:</span><br><span class="line">            res[stack[-<span class="number">1</span>]] = i - stack[-<span class="number">1</span>]  <span class="comment"># stack[-1]</span></span><br><span class="line">            stack.pop() </span><br><span class="line">        stack.append(i)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h3><span id="24-接雨水">2.4 接雨水</span></h3>
<p>接雨水是找每个柱子<strong>左右两边第一个大于该柱子高度的柱子</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">trap</span>(<span class="params">self, height: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="comment"># 单调栈 左 弹出后 s.top() 中 s.pop()  右 height[i]</span></span><br><span class="line">    n = <span class="built_in">len</span>(height)</span><br><span class="line">    stack = [<span class="number">0</span>]</span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">while</span> stack <span class="keyword">and</span> height[i] &gt; height[stack[-<span class="number">1</span>]]:</span><br><span class="line">            mid = stack.pop() <span class="comment"># 弹一个左面还有的话就是有坑</span></span><br><span class="line">            <span class="keyword">if</span> stack:</span><br><span class="line">                high = <span class="built_in">min</span>(height[stack[-<span class="number">1</span>]], height[i]) - height[mid] </span><br><span class="line">                <span class="comment"># 高 = 左右最小 - 低</span></span><br><span class="line">                weith = i - stack[-<span class="number">1</span>] - <span class="number">1</span> <span class="comment"># 宽</span></span><br><span class="line">                res += weith * high </span><br><span class="line">        stack.append(i)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h3><span id="25-柱状图的最大矩形">2.5 柱状图的最大矩形</span></h3>
<p><strong>找每个柱子左右两边第一个小于该柱子的柱子。</strong>：==<strong>栈顶和栈顶的下一个元素以及要入栈的三个元素组成了我们要求最大面积的高度和宽度</strong>==</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">largestRectangleArea</span>(<span class="params">self, heights: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="comment"># 单调栈 左右两边都可以用</span></span><br><span class="line">    heights.insert(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">    heights.append(<span class="number">0</span>)</span><br><span class="line">    stack = [<span class="number">0</span>]</span><br><span class="line">    ans = heights[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(heights)):</span><br><span class="line">        <span class="keyword">while</span> stack <span class="keyword">and</span> heights[i] &lt; heights[stack[-<span class="number">1</span>]]:</span><br><span class="line">            mid = stack.pop()</span><br><span class="line">            <span class="keyword">if</span> stack: <span class="comment"># 存在左右最小</span></span><br><span class="line">                weith = i - stack[-<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">                <span class="comment"># high = max(heights[i], heights[stack[-1]])</span></span><br><span class="line">                ans = <span class="built_in">max</span>(ans, heights[mid] * weith)</span><br><span class="line">        stack.append(i)</span><br><span class="line">    <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h2><span id="三-单调队列">三、单调队列</span></h2>
<h2><span id="四-贪心算法"></span></h2>
<p><img src="https://code-thinking-1253855093.file.myqcloud.com/pics/20210917104315.png" alt="贪心算法大纲"></p>
<h3><span id="什么是贪心">什么是贪心</span></h3>
<p><strong>贪心的本质是选择每一阶段的局部最优，从而达到全局最优</strong>。</p>
<h3><span id="贪心一般解题步骤">贪心一般解题步骤</span></h3>
<p>贪心算法一般分为如下四步：</p>
<ul>
<li>将问题分解为若干个子问题</li>
<li>找出适合的贪心策略</li>
<li>求解每一个子问题的最优解</li>
<li>将局部最优解堆叠成全局最优解</li>
</ul>
<h2><span id="五-动态规划"></span></h2>
<figure>
<img src="https://images.zsxq.com/FvoG8qppuOWSNhXBbj27ShBAJw0G?imageMogr2/auto-orient/quality/100!/ignore-error/1&amp;e=1648742399&amp;token=kIxbL07-8jAj8w1n4s9zv64FuZZNEATmlU_Vm6zD:q36Nzw1NTcg-NvuvnNyOWSZ_mdI=" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>首先，动态规划问题的一般形式就是==求最值==</strong>。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，比如说让你求<strong>最长</strong>递增子序列呀，<strong>最小</strong>编辑距离呀等等。<strong>求解动态规划的核心问题是穷举</strong>。首先，动态规划的穷举有点特别，因为这类问题<strong>存在「重叠子问题」</strong>，如果暴力穷举的话效率会极其低下，所以需要「==备忘录」或者「DP
table」==来优化穷举过程，避免不必要的计算。而且，动态规划问题一定会<strong>具备「最优子结构」</strong>，才能通过子问题的最值得到原问题的最值。</p>
<p>另外，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，只有列出<strong>正确的「状态转移方程」</strong>，才能正确地穷举。</p>
<p>以上提到的<strong>重叠子问题、最优子结构、状态转移方程</strong>就是动态规划三要素。具体什么意思等会会举例详解，但是在实际的算法问题中，<strong>写出状态转移方程是最困难的</strong>，这也就是为什么很多朋友觉得动态规划问题困难的原因，我来提供我研究出来的一个思维框架，辅助你思考状态转移方程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化 base case</span></span><br><span class="line">dp[<span class="number">0</span>][<span class="number">0</span>][...] = base</span><br><span class="line"><span class="comment"># 进行状态转移</span></span><br><span class="line"><span class="keyword">for</span> 状态<span class="number">1</span> <span class="keyword">in</span> 状态<span class="number">1</span>的所有取值：</span><br><span class="line">    <span class="keyword">for</span> 状态<span class="number">2</span> <span class="keyword">in</span> 状态<span class="number">2</span>的所有取值：</span><br><span class="line">        <span class="keyword">for</span> ...</span><br><span class="line">            dp[状态<span class="number">1</span>][状态<span class="number">2</span>][...] = 求最值(选择<span class="number">1</span>，选择<span class="number">2.</span>..)</span><br></pre></td></tr></table></figure>
<h3><span id="51-背包问题"><strong>5.1 背包问题</strong></span></h3>
<p>https://leetcode-cn.com/problems/coin-change/solution/dai-ma-sui-xiang-lu-dai-ni-xue-tou-wan-q-80r7/</p>
<figure>
<img src="https://img-blog.csdnimg.cn/20210117171307407.png" alt="416.分割等和子集1">
<figcaption aria-hidden="true">416.分割等和子集1</figcaption>
</figure>
<blockquote>
<p><strong>1、确定dp数组以及下标的含义</strong></p>
<p><strong>2、确定递推公式</strong></p>
<p><strong>3、dp数组如何初始化</strong></p>
<ul>
<li><strong>最大长度</strong></li>
<li><strong>递推等号左侧要初始化</strong></li>
</ul>
<p><strong>4、确定遍历顺序</strong></p>
<ul>
<li><strong>滚动数组</strong></li>
</ul>
<p><strong>5、举例推导dp数组</strong></p>
</blockquote>
<h4><span id="511-背包递推公式">5.1.1 背包递推公式</span></h4>
<p><strong>问==能否装满背包==</strong>（或者<strong>最多装多少</strong>）：dp[j]
= max(dp[j], dp[j - nums[i]] + nums[i]); ，对应题目如下：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/0416.分割等和子集.html">动态规划：416.分割等和子集(opens
new window)</a></li>
<li><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/partition-to-k-equal-sum-subsets/">划分为k个相等的子集</a></li>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/1049.最后一块石头的重量II.html">动态规划：1049.最后一块石头的重量
II</a></li>
</ul>
<p><strong>==问装满背包有几种方法==</strong>：dp[j] += dp[j - nums[i]]
，对应题目如下：</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0494.目标和.html">动态规划：494.目标和(opens
new window)</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0518.零钱兑换II.html">动态规划：518.
零钱兑换 II(opens new window)</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0377.组合总和Ⅳ.html">动态规划：377.组合总和Ⅳ(opens
new window)</a></p>
<blockquote>
<p><strong>如果求组合数就是外层for循环遍历物品，内层for遍历背包</strong>。</p>
<p><strong>如果求排列数就是外层for遍历背包，内层for循环遍历物品</strong>。</p>
</blockquote></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0070.爬楼梯完全背包版本.html">动态规划：70.
爬楼梯进阶版（完全背包）</a></p></li>
</ul>
<p><strong>问背包装满==最大价值==</strong>：dp[j] = max(dp[j], dp[j -
weight[i]] + value[i]); ，对应题目如下：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/0474.一和零.html">动态规划：474.一和零</a></li>
</ul>
<p><strong>问装满背包所有物品的==最小个数==</strong>：dp[j] = min(dp[j -
coins[i]] + 1, dp[j]); ，对应题目如下：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/0322.零钱兑换.html">动态规划：322.零钱兑换(opens
new window)</a></li>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/0279.完全平方数.html">动态规划：279.完全平方数(opens
new window)</a></li>
</ul>
<h4><span id="512-遍历顺序">5.1.2 遍历顺序</span></h4>
<h5><span id="01背包">01背包</span></h5>
<p>在<a target="_blank" rel="noopener" href="https://programmercarl.com/背包理论基础01背包-1.html">动态规划：关于01背包问题，你该了解这些！
(opens new
window)</a>中我们讲解二维dp数组01背包先遍历物品还是先遍历背包都是可以的，且第二层for循环是从小到大遍历。</p>
<p>和<a target="_blank" rel="noopener" href="https://programmercarl.com/背包理论基础01背包-2.html">动态规划：关于01背包问题，你该了解这些！（滚动数组）
(opens new
window)</a>中，我们讲解一维dp数组01背包只能先遍历物品再遍历背包容量，且第二层for循环是从大到小遍历。</p>
<p><strong>一维dp数组的背包在遍历顺序上和二维dp数组实现的01背包其实是有很大差异的，大家需要注意！</strong></p>
<h5><span id="完全背包">完全背包</span></h5>
<p>说完01背包，再看看完全背包。</p>
<p>在<a target="_blank" rel="noopener" href="https://programmercarl.com/背包问题理论基础完全背包.html">动态规划：关于完全背包，你该了解这些！
(opens new
window)</a>中，讲解了纯完全背包的一维dp数组实现，先遍历物品还是先遍历背包都是可以的，且第二层for循环是从小到大遍历。</p>
<p>但是仅仅是纯完全背包的遍历顺序是这样的，题目稍有变化，两个for循环的先后顺序就不一样了。</p>
<p><strong>如果求==组合数==就是外层for循环遍历物品，内层for遍历背包</strong>。</p>
<p><strong>如果==求排列数==就是外层for遍历背包，内层for循环遍历物品</strong>。</p>
<p>相关题目如下：</p>
<ul>
<li>求组合数：<a target="_blank" rel="noopener" href="https://programmercarl.com/0518.零钱兑换II.html">动态规划：518.零钱兑换II(opens
new window)</a></li>
<li>求排列数：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Iixw0nahJWQgbqVNk8k6gA">动态规划：377.
组合总和 Ⅳ (opens new window)</a>、<a target="_blank" rel="noopener" href="https://programmercarl.com/0070.爬楼梯完全背包版本.html">动态规划：70.
爬楼梯进阶版（完全背包）(opens new window)</a></li>
</ul>
<p>如果求最小数，那么两层for循环的先后顺序就无所谓了，相关题目如下：</p>
<ul>
<li>求最小数：<a target="_blank" rel="noopener" href="https://programmercarl.com/0322.零钱兑换.html">动态规划：322.
零钱兑换 (opens new window)</a>、<a target="_blank" rel="noopener" href="https://programmercarl.com/0279.完全平方数.html">动态规划：279.完全平方数(opens
new window)</a></li>
</ul>
<p><strong>对于背包问题，其实递推公式算是容易的，难是难在遍历顺序上，如果把遍历顺序搞透，才算是真正理解了</strong>。</p>
<h3><span id="52-子序列问题">5.2 <strong>子序列问题</strong></span></h3>
<p><img src="https://code-thinking.cdn.bcebos.com/pics/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-%E5%AD%90%E5%BA%8F%E5%88%97%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.jpg" alt="img" style="zoom:50%;"></p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0300.最长上升子序列.html">动态规划：最长递增子序列</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 子序列 </span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">lengthOfLIS</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(nums)</span><br><span class="line">        dp = [<span class="number">1</span>] * <span class="built_in">len</span>(nums)</span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, i):</span><br><span class="line">                <span class="keyword">if</span> nums[i] &gt; nums[j]:</span><br><span class="line">                    dp[i] = <span class="built_in">max</span>(dp[i], dp[j] + <span class="number">1</span>)</span><br><span class="line">            result = <span class="built_in">max</span>(result, dp[i]) <span class="comment">#取长的子序列</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></li>
<li><h5><span id="动态规划最长斐波那契数列"></span></h5></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">lenLongestFibSubseq</span>(<span class="params">self, A: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="comment"># 基本顺序是 k，i，j 或者 A[k] = A[j] - A[i]</span></span><br><span class="line">    n = <span class="built_in">len</span>(A)</span><br><span class="line">    dic = &#123;&#125;</span><br><span class="line">    <span class="comment"># 创建索引字典，提速</span></span><br><span class="line">    <span class="keyword">for</span> ind,val <span class="keyword">in</span> <span class="built_in">enumerate</span>(A):</span><br><span class="line">        dic[val] = ind</span><br><span class="line">    <span class="comment"># 初始化，行代表的是i，不需要取到n-1，为了给j留出位置</span></span><br><span class="line">    <span class="comment"># 初始为2，只要包含了 j i 位置，则意味着已经有了2个数字。</span></span><br><span class="line">    dp = [[<span class="number">2</span>]*n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>)]</span><br><span class="line">    ret = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 因此i只能取到n-2，给j留出空间</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n-<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># j从i+1开始，毕竟j在i后面</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>,n):</span><br><span class="line">            diff = A[j] - A[i]</span><br><span class="line">            <span class="keyword">if</span> diff <span class="keyword">in</span> dic <span class="keyword">and</span> dic[diff] &lt; i:</span><br><span class="line">                k = dic[diff]</span><br><span class="line">                dp[i][j] = dp[k][i] + <span class="number">1</span> <span class="comment"># 这个1，代表着k位置数字</span></span><br><span class="line">                ret = <span class="built_in">max</span>(ret,dp[i][j])</span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0718.最长重复子数组.html">动态规划：最长重复子数组</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">findLength</span>(<span class="params">self, A: <span class="type">List</span>[<span class="built_in">int</span>], B: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        dp = [<span class="number">0</span>] * (<span class="built_in">len</span>(B) + <span class="number">1</span>)</span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(A)+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(B), <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> A[i-<span class="number">1</span>] == B[j-<span class="number">1</span>]:</span><br><span class="line">                    dp[j] = dp[j-<span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[j] = <span class="number">0</span> <span class="comment">#注意这里不相等的时候要有赋0的操作</span></span><br><span class="line">                result = <span class="built_in">max</span>(result, dp[j])</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/1143.最长公共子序列.html">动态规划：最长公共子序列</a>、
<a target="_blank" rel="noopener" href="https://programmercarl.com/1035.不相交的线.html">动态规划：不相交的线</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestCommonSubsequence</span>(<span class="params">self, text1: <span class="built_in">str</span>, text2: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 最长子序列 </span></span><br><span class="line">        m, n = <span class="built_in">len</span>(text1), <span class="built_in">len</span>(text2)</span><br><span class="line">        dp = [[<span class="number">0</span>] * (n+<span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m+<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> text2[j-<span class="number">1</span>] == text1[i-<span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = dp[i-<span class="number">1</span>][j-<span class="number">1</span>] +<span class="number">1</span> </span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>][j], dp[i][j-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0053.最大子序和（动态规划）.html">动态规划：最大子序和</a>
【贪心】【动态规划】</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">maxSubArray</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="comment"># 为什么dp[-1]不是最大？需要res</span></span><br><span class="line">    <span class="comment"># dp[i] 以i结尾的最大子数组和</span></span><br><span class="line">    n = <span class="built_in">len</span>(nums)</span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    dp = [<span class="number">0</span>] * (n)</span><br><span class="line">    dp[<span class="number">0</span>] = nums[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">        dp[i] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>]+nums[i], nums[i])</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(dp)</span><br></pre></td></tr></table></figure>
<ul>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/0392.判断子序列.html">动态规划：判断子序列</a>
【双指针】</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isSubsequence</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        n, m = <span class="built_in">len</span>(s), <span class="built_in">len</span>(t)</span><br><span class="line">        i = j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; n <span class="keyword">and</span> j &lt; m:</span><br><span class="line">            <span class="keyword">if</span> s[i] == t[j]:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> i == n</span><br></pre></td></tr></table></figure>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0115.不同的子序列.html">动态规划：不同的子序列</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0583.两个字符串的删除操作.html">动态规划：两个字符串的删除操作</a></p></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dp[i][j] : word1[i-1], word1[j-1] 最少步数</span></span><br><span class="line"><span class="comment"># word1[i - 1] 与 word2[j - 1]不相同的时候，有2种情况 *  min(dp[i-1][j], dp[i][j-1])+1  </span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">minDistance</span>(<span class="params">self, word1: <span class="built_in">str</span>, word2: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        m, n = <span class="built_in">len</span>(word1), <span class="built_in">len</span>(word2)</span><br><span class="line">        dp = [[<span class="number">0</span>] * (n+<span class="number">1</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m+<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n+<span class="number">1</span>):</span><br><span class="line">            dp[<span class="number">0</span>][i] = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m+<span class="number">1</span>):</span><br><span class="line">            dp[j][<span class="number">0</span>] = j</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> word1[i-<span class="number">1</span>] == word2[j-<span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = dp[i-<span class="number">1</span>][j-<span class="number">1</span>]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="built_in">min</span>(dp[i-<span class="number">1</span>][j], dp[i][j-<span class="number">1</span>])+<span class="number">1</span> <span class="comment"># , dp[i-1][j-1]+1</span></span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/0072.编辑距离.html">动态规划：编辑距离</a></li>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/为了绝杀编辑距离，卡尔做了三步铺垫.html">为了绝杀编辑距离，我做了三步铺垫，你都知道么？</a></li>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/0647.回文子串.html">动态规划：回文子串</a></li>
<li><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/longest-palindromic-substring/">最长回文子串</a>
==<a href="#manacher-算法">Manacher 算法</a>==</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 中心扩展法</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="comment"># 枚举+中心扩展法</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">extendCenter</span>(<span class="params">left, right</span>):</span><br><span class="line">            <span class="keyword">while</span> <span class="number">0</span> &lt;= left <span class="keyword">and</span> right &lt; <span class="built_in">len</span>(s) <span class="keyword">and</span> s[left] == s[right]:</span><br><span class="line">                left -= <span class="number">1</span></span><br><span class="line">                right += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 返回的为while不成立的值</span></span><br><span class="line">            <span class="keyword">return</span> left+<span class="number">1</span>, right-<span class="number">1</span> </span><br><span class="line">        start, end = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            left1, right1 = extendCenter(i,i)</span><br><span class="line">            left2, right2 = extendCenter(i,i+<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> right1 - left1 &gt; end - start:</span><br><span class="line">                start, end = left1, right1</span><br><span class="line">            <span class="keyword">if</span> right2 - left2 &gt; end - start:</span><br><span class="line">                start, end = left2, right2</span><br><span class="line">        <span class="keyword">return</span> s[start:end+<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">longestPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="comment"># dp[i][j]: 是否是回文 dp[i+1][j-1] -&gt; dp[i][j]</span></span><br><span class="line">    <span class="comment"># 返回的子串，不是数字 不能记录长度</span></span><br><span class="line">    n = <span class="built_in">len</span>(s)</span><br><span class="line">    dp = [[<span class="literal">False</span>] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="comment"># 右上为1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        dp[i][i] = <span class="literal">True</span></span><br><span class="line">    begin = <span class="number">0</span></span><br><span class="line">    maxlen = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 判断是否是回文子串中，如果是则记录begin and len</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>, -<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i,n):</span><br><span class="line">            <span class="keyword">if</span> s[i] == s[j]:</span><br><span class="line">                <span class="keyword">if</span> j - i &lt;=<span class="number">1</span>:</span><br><span class="line">                    dp[i][j] = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">elif</span> dp[i+<span class="number">1</span>][j-<span class="number">1</span>]:</span><br><span class="line">                    dp[i][j] = <span class="literal">True</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> dp[i][j] <span class="keyword">and</span> j - i + <span class="number">1</span> &gt; maxlen:</span><br><span class="line">                maxlen = j - i + <span class="number">1</span></span><br><span class="line">                begin = i</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> s[begin:begin+maxlen]</span><br></pre></td></tr></table></figure>
<h4><span id="manacher-算法">Manacher 算法</span></h4>
<p><strong>Manacher
算法是在线性时间内求解最长回文子串的算法</strong>。在本题中，我们要求解回文串的个数，为什么也能使用
Manacher 算法呢？这里我们就需要理解一下 Manacher 的基本原理。</p>
<ul>
<li><p>奇偶长度处理： abaaabaa 会被处理成
#a#b#a#a##<em>a</em>#<em>b</em>#<em>a</em>#<em>a</em>#</p></li>
<li><p>==<strong><span class="math inline">\(f(i)\)</span></strong>
来表示以 s 的第 i 位为回文中心，可以拓展出的<strong>最大回文半径 （包括
# ）</strong>==，那么$ f(i) - 1$就是以 i 为中心的最大回文串长度
。</p></li>
<li><p>利用已经计算出来的状态来更新 f(i）：<strong>回文右端点rm</strong>
：i + f(i) - 1</p></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0516.最长回文子序列.html">动态规划：最长回文子序列</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestPalindromeSubseq</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 动态规划 dp[i][j]: s[i:j] 最大回文长度</span></span><br><span class="line">        <span class="comment"># dp[i+1][j-1] -&gt; dp[i][j] 遍历顺序 and j - i &gt;=2</span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        dp = [[<span class="number">0</span>] * i +[<span class="number">1</span>] * (n-i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="comment"># 从定义出发 右上三角 = 1 有意义</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>,n): <span class="comment"># j - i &gt;=2</span></span><br><span class="line">                <span class="keyword">if</span> s[i] == s[j]:</span><br><span class="line">                    dp[i][j] = dp[i+<span class="number">1</span>][j-<span class="number">1</span>] + <span class="number">2</span> </span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    dp[i][j] = <span class="built_in">max</span>(dp[i+<span class="number">1</span>][j], dp[i][j-<span class="number">1</span>])                </span><br><span class="line">        <span class="keyword">return</span> dp[<span class="number">0</span>][n-<span class="number">1</span>]</span><br></pre></td></tr></table></figure></li>
<li><h5><span id="最少回文分割"></span></h5></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">minCut</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 动态规划1:判断回文</span></span><br><span class="line">        n = <span class="built_in">len</span>(s)</span><br><span class="line">        g = [[<span class="literal">True</span>] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, n):</span><br><span class="line">                g[i][j] = (s[i] == s[j]) <span class="keyword">and</span> g[i + <span class="number">1</span>][j - <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># </span></span><br><span class="line">        f = [<span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)] * n</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> g[<span class="number">0</span>][i]:</span><br><span class="line">                f[i] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">                    <span class="keyword">if</span> g[j + <span class="number">1</span>][i]:</span><br><span class="line">                        <span class="comment"># （0, j) + (j+1, i)</span></span><br><span class="line">                        f[i] = <span class="built_in">min</span>(f[i], f[j] + <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> f[n - <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li><h5><span id="最长连续序列"></span></h5></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">longestConsecutive</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        <span class="comment"># 动态规划</span></span><br><span class="line">        dic, res = <span class="built_in">dict</span>(), <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> num <span class="keyword">not</span> <span class="keyword">in</span> dic:</span><br><span class="line">                left, right = dic.get(num - <span class="number">1</span>, <span class="number">0</span>), dic.get(num + <span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">                cur = <span class="number">1</span> + left +right</span><br><span class="line">                <span class="keyword">if</span> res &lt; cur:</span><br><span class="line">                    res = cur</span><br><span class="line">                dic[num] = cur</span><br><span class="line">                dic[num - left] = cur</span><br><span class="line">                dic[num + right] = cur</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h3><span id="53-打家劫舍问题">5.3 打家劫舍问题</span></h3>
<ul>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/0198.打家劫舍.html">动态规划：开始打家劫舍</a></li>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/0213.打家劫舍II.html">动态规划：继续打家劫舍
环</a></li>
<li><a target="_blank" rel="noopener" href="https://programmercarl.com/0337.打家劫舍III.html">动态规划：还要打家劫舍
树状dp</a></li>
</ul>
<h3><span id="54-股票问题">5.4 股票问题</span></h3>
<figure>
<img src="https://code-thinking.cdn.bcebos.com/pics/%E8%82%A1%E7%A5%A8%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93.jpg" alt="股票问题总结">
<figcaption aria-hidden="true">股票问题总结</figcaption>
</figure>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0121.买卖股票的最佳时机.html">动态规划：121.买卖股票的最佳时机(opens
new window)</a> 股票只能买卖一次，问最大利润</p></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0122.买卖股票的最佳时机II（动态规划）.html">动态规划：122.买卖股票的最佳时机II(opens
new window)</a> 可以多次买卖股票，问最大收益。</p></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0123.买卖股票的最佳时机III.html">动态规划：123.买卖股票的最佳时机III(opens
new window)</a> 最多买卖两次，问最大收益。</p></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0188.买卖股票的最佳时机IV.html">动态规划：188.买卖股票的最佳时机IV(opens
new window)</a> 最多买卖k笔交易，问最大收益。</p></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0309.最佳买卖股票时机含冷冻期.html">动态规划：309.最佳买卖股票时机含冷冻期(opens
new window)</a> 可以多次买卖但每次卖出有冷冻期1天。</p></li>
<li><p><a target="_blank" rel="noopener" href="https://programmercarl.com/0714.买卖股票的最佳时机含手续费（动态规划）.html">动态规划：714.买卖股票的最佳时机含手续费(opens
new window)</a> 可以多次买卖，但每次有手续费。</p></li>
</ul>
<h3><span id="55-编辑距离问题">5.5 编辑距离问题</span></h3>
<h4><span id="判断子序列">判断子序列</span></h4>
<p><a target="_blank" rel="noopener" href="https://programmercarl.com/0392.判断子序列.html">动态规划：392.判断子序列
(opens new window)</a>给定字符串 s 和 t ，判断 s 是否为 t 的子序列。</p>
<p>这道题目
其实是可以用<strong>双指针</strong>或者<strong>贪心</strong>的的，但是我在开篇的时候就说了这是编辑距离的入门题目，因为从题意中我们也可以发现，只需要计算删除的情况，不用考虑增加和替换的情况。</p>
<ul>
<li>if (s[i - 1] == t[j - 1])
<ul>
<li>t中找到了一个字符在s中也出现了</li>
</ul></li>
<li>if (s[i - 1] != t[j - 1])
<ul>
<li>相当于t要删除元素，继续匹配</li>
</ul></li>
</ul>
<p>状态转移方程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (s[i - <span class="number">1</span>] == t[j - <span class="number">1</span>]) dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">else</span> dp[i][j] = dp[i][j - <span class="number">1</span>];</span><br></pre></td></tr></table></figure>
<h4><span id="不同的子序列">不同的子序列</span></h4>
<p><a target="_blank" rel="noopener" href="https://programmercarl.com/0115.不同的子序列.html">动态规划：115.不同的子序列
(opens new window)</a>给定一个字符串 s 和一个字符串 t ，计算在 s
的子序列中 t 出现的个数。</p>
<p>本题虽然也只有删除操作，不用考虑替换增加之类的，但相对于<a target="_blank" rel="noopener" href="https://programmercarl.com/0392.判断子序列.html">动态规划：392.判断子序列
(opens new window)</a>就有难度了，这道题目双指针法可就做不了。</p>
<p>当s[i - 1] 与 t[j - 1]相等时，dp[i][j]可以有两部分组成。</p>
<p>一部分是用s[i - 1]来匹配，那么个数为 dp[i - 1] [j - 1]</p>
<p>一部分是不用s[i - 1]来匹配，个数为 dp[i - 1] [j]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (s[i - <span class="number">1</span>] == t[j - <span class="number">1</span>]) &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + dp[i - <span class="number">1</span>][j];</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="两个字符串的删除操作">两个字符串的删除操作</span></h4>
<p><a target="_blank" rel="noopener" href="https://programmercarl.com/0583.两个字符串的删除操作.html">动态规划：583.两个字符串的删除操作
(opens new window)</a>给定两个单词 word1 和 word2，找到使得 word1 和
word2 相同所需的最小步数，每步可以删除任意一个字符串中的一个字符。</p>
<p>本题和<a target="_blank" rel="noopener" href="https://programmercarl.com/0115.不同的子序列.html">动态规划：115.不同的子序列
(opens new
window)</a>相比，其实就是两个字符串可以都可以删除了，情况虽说复杂一些，但整体思路是不变的。</p>
<ul>
<li>当word1[i - 1] 与 word2[j - 1]相同的时候</li>
<li>当word1[i - 1] 与 word2[j - 1]不相同的时候</li>
</ul>
<p>当word1[i - 1] 与 word2[j - 1]相同的时候，dp[i][j] = dp[i - 1] [j -
1];</p>
<p>当word1[i - 1] 与 word2[j - 1]不相同的时候，有2种情况：</p>
<p>情况一：删word1[i - 1]，最少操作次数为dp[i - 1] [j] + 1</p>
<p>情况二：删word2[j - 1]，最少操作次数为dp[i][j - 1] + 1</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (word1[i - <span class="number">1</span>] == word2[j - <span class="number">1</span>]) &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>];</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    dp[i][j] = <span class="built_in">min</span>(&#123;dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">2</span>, dp[i - <span class="number">1</span>][j] + <span class="number">1</span>, dp[i][j - <span class="number">1</span>] + <span class="number">1</span>&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="编辑距离">编辑距离</span></h4>
<p><a target="_blank" rel="noopener" href="https://programmercarl.com/0072.编辑距离.html">动态规划：72.编辑距离
(opens new window)</a>给你两个单词 word1 和 word2，请你计算出将 word1
转换成 word2 所使用的最少操作数 。</p>
<p>编辑距离终于来了，<strong>有了前面三道题目的铺垫，应该有思路了</strong>，本题是两个字符串可以增删改，比
<a target="_blank" rel="noopener" href="https://programmercarl.com/0392.判断子序列.html">动态规划：判断子序列
(opens new window)</a>，<a target="_blank" rel="noopener" href="https://programmercarl.com/0115.不同的子序列.html">动态规划：不同的子序列
(opens new window)</a>，<a target="_blank" rel="noopener" href="https://programmercarl.com/0583.两个字符串的删除操作.html">动态规划：两个字符串的删除操作
(opens new window)</a>都要复杂的多。</p>
<p>在确定递推公式的时候，首先要考虑清楚编辑的几种操作，整理如下：</p>
<ul>
<li>if (word1[i - 1] == word2[j - 1])
<ul>
<li>不操作</li>
</ul></li>
<li>if (word1[i - 1] != word2[j - 1])
<ul>
<li>增</li>
<li>删</li>
<li>换</li>
</ul></li>
</ul>
<p>也就是如上四种情况。</p>
<p>if (word1[i - 1] == word2[j - 1]) 那么说明不用任何编辑，dp[i][j]
就应该是 dp[i - 1] [j - 1]，即dp[i][j] = dp[i - 1] [j - 1];</p>
<p><strong>在整个动规的过程中，最为关键就是正确理解dp[i]
[j]的定义！</strong></p>
<p>if (word1[i - 1] != word2[j - 1])，此时就需要编辑了，如何编辑呢？</p>
<p>操作一：word1增加一个元素，使其word1[i - 1]与word2[j -
1]相同，那么就是以下标i-2为结尾的word1 与 i-1为结尾的word2的最近编辑距离
加上一个增加元素的操作。</p>
<p>即 dp[i][j] = dp[i - 1] [j] + 1;</p>
<p>操作二：word2添加一个元素，使其word1[i - 1]与word2[j -
1]相同，那么就是以下标i-1为结尾的word1 与 j-2为结尾的word2的最近编辑距离
加上一个增加元素的操作。</p>
<p>即 dp[i][j] = dp[i][j - 1] + 1;</p>
<p>这里有同学发现了，怎么都是添加元素，删除元素去哪了。</p>
<p><strong>word2添加一个元素，相当于word1删除一个元素</strong>，例如
word1 = "ad" ，word2 =
"a"，word2添加一个元素d，也就是相当于word1删除一个元素d，操作数是一样！</p>
<p>操作三：替换元素，word1替换word1[i - 1]，使其与word2[j -
1]相同，此时不用增加元素，那么以下标i-2为结尾的word1 与
j-2为结尾的word2的最近编辑距离 加上一个替换元素的操作。</p>
<p>即 dp[i][j] = dp[i - 1] [j - 1] + 1;</p>
<p>综上，当 if (word1[i - 1] != word2[j - 1]) 时取最小的，即：dp[i] [j]
= min({dp[i - 1] [j - 1], dp[i - 1] [j], dp[i][j - 1]}) + 1;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (word1[i - <span class="number">1</span>] == word2[j - <span class="number">1</span>]) &#123;</span><br><span class="line">    dp[i][j] = dp[i - <span class="number">1</span>][j - <span class="number">1</span>];</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    dp[i][j] = <span class="built_in">min</span>(&#123;dp[i - <span class="number">1</span>][j - <span class="number">1</span>], dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>]&#125;) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3><span id="让字符串成为最小回文">==让字符串成为最小回文==</span></h3>
<p>https://leetcode-cn.com/problems/minimum-insertion-steps-to-make-a-string-palindrome/</p>
<h2><span id="六-回溯法">六、回溯法</span></h2>
<p><strong>一个决策树的遍历过程（回溯法）</strong>：一种通过探索所有可能的候选解来找出所有的解的算法。如果候选解被确认不是一个解（或者至少不是最后一个解），回溯算法会通过在上一步进行一些变化抛弃该解，即回溯并且再次尝试。</p>
<p>回溯法，一般可以解决如下几种问题：</p>
<ul>
<li>组合问题：N个数里面按一定规则找出k个数的集合</li>
<li>切割问题：一个字符串按一定规则有几种切割方式</li>
<li>子集问题：一个N个数的集合里有多少符合条件的子集</li>
<li>排列问题：N个数按一定规则全排列，有几种排列方式</li>
<li><strong>棋盘问题</strong>：N皇后，解数独等等</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/11/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/13/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lzy</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>-->
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("03/01/2023 10:00:00"); //此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒.";
    }
setInterval("createtime()",250);
</script>

    </div>
  </footer>

  

  <a href="https://github.com/PowerLZY" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.4.3/mermaid.min.js","integrity":"sha256-e0o3JYsdjqKajf9eOe22FhioYSz9WofRY4dLKo3F6do="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>




        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        const hasAttr = (e,a) => a.some(_=> e.attr(_)!==undefined);
        $('a').each(function() {
          const $this = $(this);
          if(hasAttr($this,["data-fancybox","ignore-external-link"])) return;
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'powerlzy.github.io' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script></body>
</html>
