<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"powerlzy.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="相比到达的地方，同行的人更重要！">
<meta property="og:type" content="website">
<meta property="og:title" content="PowerLZY&#39;s Blog">
<meta property="og:url" content="https://powerlzy.github.io/page/14/index.html">
<meta property="og:site_name" content="PowerLZY&#39;s Blog">
<meta property="og:description" content="相比到达的地方，同行的人更重要！">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="lzy">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://powerlzy.github.io/page/14/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/14/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>PowerLZY's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">PowerLZY's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">本博客主要用于记录个人学习笔记（测试阶段）</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="lzy"
      src="/images/cat_mac.jpg">
  <p class="site-author-name" itemprop="name">lzy</p>
  <div class="site-description" itemprop="description">相比到达的地方，同行的人更重要！</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">239</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">43</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/PowerLZY" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;PowerLZY" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:3289218653@qq.com" title="E-Mail → mailto:3289218653@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/368N99B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/368N99B/" class="post-title-link" itemprop="url">安全场景（2）恶意加密流量检测*</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-13 12:49:05" itemprop="dateCreated datePublished" datetime="2022-05-13T12:49:05+08:00">2022-05-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-09-19 00:12:59" itemprop="dateModified" datetime="2022-09-19T00:12:59+08:00">2022-09-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" itemprop="url" rel="index"><span itemprop="name">应用场景</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>10 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="基于机器学习的恶意加密流量检测">基于机器学习的恶意加密流量检测</span></h2>
<p>[1] Anderson B, McGrew D. Identifying encrypted malware traffic with
contextual flow data[C]//Proceedings of the 2016 ACM workshop on
artificial intelligence and security. 2016: 35-46.</p>
<figure>
<img src="image-20220516100235456.png" alt="image-20220516100235456">
<figcaption aria-hidden="true">image-20220516100235456</figcaption>
</figure>
<h4><span id="在进行tls握手时会进行如下几个步骤">在进行TLS握手时，会进行如下几个步骤：</span></h4>
<ol type="1">
<li><strong>Client Hello</strong>，客户端提供支持的加密套件数组（cipher
suites）；</li>
<li><strong>Server
Hello</strong>，由服务器端选择一个加密套件，传回服务器端公钥，并进行认证和签名授权（<strong>Certificate</strong>
+ Signature）；</li>
<li>客户端传回客户端公钥（<strong>Client Key
Exchange</strong>），客户端确立连接；</li>
<li>服务器端确立连接，开始 HTTP 通信。</li>
</ol>
<p><img src="https://pic4.zhimg.com/80/v2-a10c338f4c3e283b3b29d0e5752f1beb_1440w.jpg" alt="img" style="zoom:50%;"></p>
<h3><span id="一-特征提取">一、特征提取</span></h3>
<h4><span id="11-可观察的数据元统计特征">1.1 可观察的数据元统计特征</span></h4>
<ul>
<li><strong>传统流数据</strong> (Flow Meta)
<ul>
<li>流入和流出的字节数和数据包数</li>
<li>源端口和目的端口</li>
</ul></li>
<li><strong>字节分布</strong> (BD, Byte Distribution)
<ul>
<li>数据包有效负载中遇到的每个字节值的计数</li>
<li>提供了大量<strong>数据编码</strong>和<strong>数据填充</strong>的信息</li>
<li>字节分布概率 ≈ 字节分布计数 / 分组有效载荷的总字节数</li>
<li>特征表示：1×256维字节分布概率序列</li>
</ul></li>
<li><strong>分组长度和分组到达间隔时间的序列 </strong>(SPLT, Sequence of
Packets Length and Times)
<ul>
<li><strong>==使用马尔可夫链模型建模==</strong></li>
</ul></li>
</ul>
<h4><span id="12-未加密的tls头部信息特征">1.2 未加密的TLS头部信息特征</span></h4>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220516101251514.png" alt="image-20220516101251514" style="zoom: 33%;"></p>
<blockquote>
<p><strong>TLS/SSL协议 过程</strong></p>
<ul>
<li>两层子协议：握手协议和记录协议</li>
<li>握手协议特点
<ul>
<li>加密明文但不加密握手过程</li>
<li>有多个版本但握手参数不变</li>
</ul></li>
</ul>
</blockquote>
<ul>
<li><strong>Client Hello</strong>
<ul>
<li>列出的密码套件列表(Cipher Suites)
<ul>
<li>密钥交换算法、加密算法</li>
<li>报文认证消息码(MAC)算法</li>
</ul></li>
<li>支持的扩展列表(Extensions)
<ul>
<li>提供额外功能或设定</li>
</ul></li>
</ul></li>
<li><strong>Server Hello</strong>：选定的密码套件和TLS扩展</li>
<li><strong>Certificate</strong>：服务器签发的证书信息</li>
<li><strong>Client Key Exchange</strong>：使用的密钥交换算法参数</li>
</ul>
<figure>
<img src="../../../../../../Library/Application%20Support/typora-user-images/image-20220516101639662.png" alt="image-20220516101639662">
<figcaption aria-hidden="true">image-20220516101639662</figcaption>
</figure>
<h4><span id="13-上下文数据">1.3 上下文数据</span></h4>
<ul>
<li><strong>DNS上下文流</strong>
<ul>
<li>基于目标IP地址与TLS相关的DNS响应
<ul>
<li>域名长度</li>
<li>DNS响应返回的IP地址数</li>
<li>DNS TTL值</li>
<li>域名在Alexa榜的排名</li>
</ul></li>
<li>补充了加密流中可能缺失的信息</li>
</ul></li>
<li><strong>HTTP上下文流</strong>
<ul>
<li>在TLS流5min窗口内的<strong>相同源IP地址的所有HTTP流</strong></li>
<li>恶意软件可能<strong>利用HTTP的头部字段</strong>来发起恶意活动
<ul>
<li>Content-Type、Server、Code</li>
</ul></li>
</ul></li>
</ul>
<h3><span id="二-工业落地">二、工业落地</span></h3>
<p>然而，AI技术如没有得到有效运用，也无法在实战中检测到加密的威胁行为。例如无监督学习可以定位未知威胁，但精准度待提升；有监督学习精确度高，却无法覆盖未知威胁。</p>
<h4><span id="21如何在实战中精准识别加密流量攻击">2.1
<strong>如何在实战中精准识别加密流量攻击？</strong></span></h4>
<p><strong>深信服安全团队经过7000+用户实践发现，只有将无监督学习和有监督学习智能化结合，才能最大限度提升加密流量攻击的识别率。</strong></p>
<figure>
<img src="https://mmbiz.qpic.cn/mmbiz_png/EJiaEo3Lq9kqe1fjo1Clib3ZyjiaxESYbUib3sYpbgKND3aB0b2gRURRDxECcT3mmFicMQdhdOaPDn2QVjyZ2rV8VrQ/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h4><span id="22有监督学习精准识别已知加密流量">2.2
<strong>有监督学习精准识别已知加密流量</strong></span></h4>
<p>有监督机器学习通过将已知、带标签的行为数据输入系统，学习分析数据行为，并根据数据标签来检测、识别特定的高级威胁。深信服NDR（全流量高级威胁检测系统）应用AI模型，基于有监督机器学习抓取所有上下行流量，<strong>提取1000+维度特征</strong>，同时增加了模型训练算法LightGBM学习特征的权重，对已知高级威胁的检测更为精准。传统的检测方式基于一个模型检测多个场景，不同场景的特征不尽相同，因此误报率很高。<strong><font color="red">
深信服NDR基于AI模型有监督学习进行场景化建模，一个模型对应一个场景，根据场景特征进行针对性检测</font></strong>，<strong>模型检测精准率能够达到98%</strong>。</p>
<h4><span id="23无监督学习提前发现未知加密流量">2.3
<strong>无监督学习提前发现未知加密流量</strong></span></h4>
<p>无监督的机器学习覆盖了聚类、神经网络等方法，不依赖任何标签值，通过自主学习，挖掘数据内在特征，实现自动化全面检测，更合理地利用资源，提升效率。</p>
<p>深信服NDR基于AI模型无监督学习方法，通过聚类学习、特征映射等智能分析技术建立设备加密流量动态行为基线，筛选出异常的、可疑的行为，同时结合行为聚合与关联分析，<strong>检测出未知威胁的早期迹象，最大程度地实现自动化检测</strong>，可以快速检测出如下异常，帮助网络安全团队主动预防威胁：</p>
<ul>
<li>异常的网络设备JA3</li>
<li>异常的访问时间和访问频率</li>
<li>异常的上下行数据包比率</li>
<li>异常的证书签发机构</li>
</ul>
<p><strong>以常见的“服务器权限获取手法webshell加密通信”为例</strong>，攻击者通过渗透系统或网络安装webshell
，在应用服务器上执行敏感命令、窃取数据、植入病毒，危害极大。‍webshell具有很强的隐蔽性，<strong>传统的、基于单向数据流的流量检测方案，无法实时更新数据，难以有效检测webshell</strong>。</p>
<p>深信服NDR基于AI模型无监督学习的<strong><font color="red">
孤立森林异常点</font></strong>检测算法，可以构建特征向量，精准检测“孤立离群”的webshell访问行为，<strong>具有更高检出率，更低误报率</strong>。除了webshell加密通信场景外，深信服NDR同样支持隧道检测、CS漏洞、加密挖矿、加密反弹shell等威胁检测，覆盖多种加密威胁场景。</p>
<h2><span id="三-算法比赛总结">三、算法比赛总结</span></h2>
<blockquote>
<p><a href="../算法比赛/恶意加密流量（1）DataCon2020-恶意加密流量检测.md">恶意加密流量（1）DataCon2020-恶意加密流量检测.md</a></p>
<p><a href="../算法比赛/恶意加密流量（2）Datacon2021恶意加密流量检测.md">恶意加密流量（2）Datacon2021恶意加密流量检测.md</a></p>
<p><a href="../算法比赛/恶意加密流量（3）西湖论剑AI大数据安全分析赛.md">恶意加密流量（3）西湖论剑AI大数据安全分析赛.md</a></p>
<p>#### 流量处理的工具</p>
<p>#### <strong>zeek</strong>:https://github.com/zeek/zeek</p>
<p><a target="_blank" rel="noopener" href="https://darkdefender.medium.com/https-medium-com-melanijan93-analysing-pcaps-with-bro-zeek-33340e710012">使用
Bro/Zeek 分析 PCAP</a></p>
<p><a target="_blank" rel="noopener" href="https://www.freebuf.com/sectool/235587.html">流量分析的瑞士军刀：Zeek</a></p>
<p>Zeek Analysis Tools (ZAT):</p>
<p>#### joy：</p>
</blockquote>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://github.com/ahlashkari/CICFlowMeter">CICFlowMeter</a>：</p>
</blockquote>
<h3><span id="21-数据包级">2.1 数据包级</span></h3>
<h4><span id="1长度分布">（1）长度分布</span></h4>
<p>根据Cisco的研究【17】，<strong>恶意软件和普通软件在正向流和反向流中的数据包长度分布不同</strong>。<strong><font color="red">
例如，当我们使用谷歌搜索时，客户端向服务器发送少量数据包，然后服务器返回大量数据包。然而，恶意软件的作用恰恰相反：恶意软件通常让客户端将数据传输到服务器，然后服务器定期返回调度命令。</font></strong>无论是否加密，数据包长度始终可见，因此它适合作为一种功能。我们将数据包长度和方向编码为一维独立特征。我们推测，感染恶意软件的客户端和服务器之间的一些控制消息的长度总是相似且频繁的，这具有很好的区分程度。<strong>我们考虑每个可能的数据包长度和方向元组。由于Internet上的最大传输单元（MTU）是1500字节，并且数据包的方向有两个发送或接收方向，因此我们的长度分布特征是3000维。</strong>为了提取这些特征，我们计算具有不同长度的所有数据包的数量，并进行规范化以确保概率分布。我们使用随机森林（RF）算法来处理这些特征。因为它能更好地处理高维特征，并且具有可解释性。</p>
<h4><span id="2长度序列">（2）长度序列</span></h4>
<p>第二部分，在不使用序列信息的情况下，我们只使用了数据包长度的统计特征，这可能会在时间上丢失一些信息，因此我们提取了数据包长度序列。<strong>我们在每个客户端的双向上取前1000个数据包长度</strong>，并将其放入TextCNN算法中以提取局部序列关系。因为该算法运行速度快，精度高。文本数据的卷积神经网络TextCNN【22】是一种用于句子分类任务的有用的深度学习算法。<strong>在这种情况下，我们将每个数据包的长度视为一个单词，长度序列相当于一个句子</strong>。</p>
<h4><span id="3服务器ip">（3）服务器IP</span></h4>
<p>在我们的数据集中，服务器IP地址是一个重要的标识符。<strong>我们假设，在同一地区，如果客户端感染了相同的恶意软件，则可能会导致其访问相同的服务器IP地址</strong>。因此，我们还考虑了对服务器IP地址的访问。<strong>值1或0表示是否访问了特定的服务器IP地址（一个热编码）</strong>。我们使用朴素贝叶斯（NB）算法来处理这些特征。由于朴素贝叶斯算法是一种非参数算法，其本质是寻找特征和标签之间的关系。因此，它可以被视为一个黑名单。</p>
<h4><span id="4词频分类器">（4）词频分类器</span></h4>
<p><strong>X509证书在Internet上广泛使用</strong>。它们用于验证实体之间的信任。证书颁发机构通常将X509证书链接在一起。如图2所示。[23]，<strong>X509证书提供URL、组织、签名等信息</strong>。我们从培训集中每个客户端的TLS流中提取X509证书链，并获取证书中<strong>主题</strong>和<strong>颁发者</strong>中包含的单词。我们将所有单词组合在一起，并将客户的流量视为由这些单词组成的句子。与B部分类似，我们计算每个单词的数量并将其用作特征。0我们使用朴素贝叶斯（NB）算法来处理这些特征。如果测试集样本证书中的所有单词从未出现在训练集中，我们将直接推断它是恶意的。因为训练集包含最流行的域名。</p>
<p><img src="image-20220621131035005.png" alt="image-20220621131035005" style="zoom: 67%;"></p>
<h4><span id="5tcp状态马尔可夫">==（5）TCP状态马尔可夫==</span></h4>
<p>我们发现<strong>恶意流量和正常流量之间TCP连接状态的分布是不同的</strong>。表一说明了可能的TCP连接状态[24]。我们按照流出现的时间对其进行排序，然后使用马尔可夫随机场转移矩阵（MRFTM）对该特征进行编码。MRFTM在建模连接状态序列时很有用。MRFTM[i，j]中的每个条目统计第i个和第j个状态之间的转换次数。最后，我们对MRFTM的行进行规范化，以确保适当的马尔可夫链。然后我们将其重塑为一维向量，也就是说，我们使用MRFTM的条目作为特征。我们使用随机森林（RF）算法来处理这些特征。</p>
<h3><span id="22-会话流级">2.2 会话流级</span></h3>
<h4><span id="6会话流量统计">（6）会话流量统计</span></h4>
<p>在加密流量中，上述5种分类器在主机级使用不同的特征提取方法和分类方法。此外，为了进一步提高准确率，防止恶意软件由于缺乏领域知识而欺骗分类器，我们还提取了TLS握手中的明文信息。在这个分类器中，我们首先考虑流级特征。我们仅选择TLS流，并分析每个流。一旦推断流是恶意的，就会推断相应的客户端被感染。我们对TCP和TLS协议进行了深入分析，<strong>提取了1000多个维度的流级特征</strong>，包括以下部分：</p>
<ul>
<li><strong>TCP连接状态特性</strong>：如F部分所述，我们对每个流的TCP连接状态进行一次热编码。</li>
<li><strong>统计特征</strong>：我们还提取常规统计特征，表II显示了相关特征名称和描述。</li>
</ul>
<p><img src="../../../../../../Library/Application Support/typora-user-images/image-20220621141516374.png" alt="image-20220621141516374" style="zoom: 33%;"></p>
<ul>
<li><strong>长度马尔可夫特征</strong>：数据包长度序列的操作类似于F部分中的TCP连接状态序列。长度值被离散为大小相等的容器。长度数据马尔可夫链有10个箱子，每个箱子150字节。假设一个1500字节的MTU，任何观察到的大小大于1350字节的数据包都被放入同一个bin中。</li>
<li><strong>TLS握手功能</strong>：我们发现客户端和服务器的TLS协议版本在恶意和良性TLS流之间有不同的分布，因此我们对客户端和服务器的TLS版本进行了一次热编码。此外，由于恶意软件可能使用旧的密码套件，我们在客户端和服务器上都对密码套件和扩展进行n-hot编码，即将所有密码套件和扩展扩展扩展为一维0向量，如果当前流使用某个密码套件或扩展，则相应的位置集值为1。</li>
<li><strong>TLS证书特性</strong>：我们发现，在恶意流中，很大一部分叶证书是自签名的，或者自签名证书出现在证书链中。恶意软件喜欢利用的自签名证书的成本很低。因此，我们分析从服务器发送的证书：<strong>证书链是否包含自签名证书、叶证书是否过期、证书版本、证书有效期、公钥长度、是否发生警报</strong>。同时，考虑到之前的词频分类器，我们发现一些词无法区分恶意和良性，因此我们还将流词频添加到流特征中。</li>
</ul>
<h3><span id="23-主机级特征">2.3 主机级特征</span></h3>
<h4><span id="7主机级荷载无关特征聚合流级统计信息">（7）<strong>主机级荷载无关特征聚合</strong>
(流级统计信息)</span></h4>
<p><strong>单独的看每条流可能漏掉了流之间的关联行为即主机级别的行为</strong>，比如恶意软件在发出正常的访问谷歌流量后可能就要开始进行恶意传输。再比如，有少量正常流也会出现自
签名，如果我们单独看流，可能就会误判，但是如果我们基于主机提取特征发现同一
IP
下有多条流都是自签名，则我们就会有很大的信心认为这是恶意的。因此，我们将上一小节中流级别
的特征进行聚合，并以流为基本单位提取主机级别特征。</p>
<p><strong>主机级特征聚合部分主要考虑了如下的特征:</strong></p>
<ul>
<li><strong>总包个数</strong>，<strong>每条流的平均包个数</strong>，<strong>时间间隔、包长的均值</strong>，以及上一个小节中证书部分的相关特
征，即<strong>自签名流数量，过期流数量，有效期过长（比如
100年）的流数量及其均值。</strong></li>
<li>TLS 半连接 和无连接</li>
</ul>
<h3><span id="24-上下文信息特征">2.4 上下文信息特征</span></h3>
<h4><span id="8其他应用协议">（8）其他应用协议</span></h4>
<p><strong><font color="red">HTTP头部信息</font></strong></p>
<ul>
<li><strong>Content-Type</strong>，正常流量 HTTP 头部信息汇总值多为
<code>image/*</code>，而恶意流量为
<code>text/*、text/html、charset=UTF-8</code> 或者
<code>text/html;charset=UTF-8</code>。</li>
<li><strong>User-Agent</strong></li>
<li><strong>Accept-Language</strong></li>
<li><strong>Server</strong></li>
<li><strong>HTTP响应码</strong></li>
</ul>
<p><strong><font color="red"> DNS响应信息</font></strong></p>
<ul>
<li><strong>==域名的长度==</strong>：正常流量的域名长度分布为均值为6或7的高斯分布（正态分布）；而恶意流量的域名（FQDN全称域名）长度多为6（10）。</li>
<li><strong>==数字字符及非字母数字(non-alphanumeric
character)的字符占比==</strong>：正常流量的DNS响应中全称域名的数字字符的占比和非字母数字字符的占比要大。</li>
<li><strong>DNS解析出的IP数量</strong>：大多数恶意流量和正常流量只返回一个IP地址；其它情况，大部分正常流量返回2-8个IP地址，恶意流量返回4或者11个IP地址。</li>
<li><strong>TTL值</strong>：正常流量的TTL值一般为60、300、20、30；而恶意流量多为300，大约22%的DNS响应汇总TTL为100，而这在正常流量中很罕见。</li>
<li><strong>域名是否收录在Alexa网站</strong>：恶意流量域名信息很少收录在Alexa
top-1,000,000中，而正常流量域名多收录在其中。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/KK562V/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/KK562V/" class="post-title-link" itemprop="url">安全场景（2）离地攻击检测</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-13 12:49:05" itemprop="dateCreated datePublished" datetime="2022-05-13T12:49:05+08:00">2022-05-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-05-27 21:24:45" itemprop="dateModified" datetime="2022-05-27T21:24:45+08:00">2022-05-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" itemprop="url" rel="index"><span itemprop="name">应用场景</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>11k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>20 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="living-off-the-land恶意软件系统分析">Living-Off-The-Land
恶意软件系统分析</span></h2>
<blockquote>
<p>[][AI安全论文] <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg5MTM5ODU2Mg==&amp;mid=2247496069&amp;idx=1&amp;sn=f5aecaae5494b900b29f12078a2d632e&amp;chksm=cfcf4148f8b8c85ee56fbab09252bb4dc90f936cfb6decaa860b5e91457c9838cfb35179041a&amp;scene=178&amp;cur_album_id=1776483007625822210#rd">21.S&amp;P21
Survivalism经典离地攻击（Living-Off-The-Land）恶意软件系统分析</a>:S&amp;P21的离地攻击（Living-Off-The-Land）系统分析，这是一篇非常经典的论文，并且系统性分析文章是另一种讲故事的方式。</p>
</blockquote>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuMu3z61w35bGkJLmiaMzSMlbhFgicVxHG54dmR1ic5oqLlwSSzT28qicT2Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:67%;"></p>
<blockquote>
<p>原文作者：Frederick Barr-Smith, Xabier Ugarte-Pedrero, et al.
<strong>原文标题</strong>：Survivalism: Systematic Analysis of Windows
Malware Living-Off-The-Land
<strong>原文链接</strong>：https://ieeexplore.ieee.org/document/9519480
<strong>发表会议</strong>：2021 IEEE Symposium on Security and Privacy
(SP)</p>
</blockquote>
<p><strong>文章目录：</strong></p>
<ul>
<li><p><strong>摘要</strong></p></li>
<li><p><strong>一.引言</strong></p>
<p>1.什么是离地攻击</p>
<p>2.APT中的离地攻击</p>
<p>3.提出五个关键问题</p>
<p>4.贡献（Contribution）</p></li>
<li><p><strong>二.背景和相关工作</strong></p>
<p>A.LotL Binaries</p>
<p>B.Scope of our Study</p>
<p>C.Related Work</p></li>
<li><p><strong>三.MOTIVATION: 杀毒软件产品 vs
离地攻击技术</strong></p></li>
<li><p><strong>四.离地攻击流行性评估</strong></p>
<p>A.Dataset Composition</p>
<p>B.Analysis Pipeline</p>
<p>C.LotL Technique Identification</p>
<p>D.Parameter Analysis to Identify Execution Purpose</p></li>
<li><p><strong>五.评估结果</strong></p>
<p>A.商用恶意软件中LotL技术的流行性（Prevalence）</p>
<p>B.Comparison of Benign and Malicious Samples</p>
<p>C.Prevalence of LotL techniques in APT Malware</p></li>
<li><p><strong>六.案例分析</strong></p></li>
<li><p><strong>七.要点和讨论</strong></p></li>
<li><p><strong>八.局限性和未来工作</strong></p></li>
<li><p><strong>九.个人感受</strong></p></li>
</ul>
<h3><span id="摘要">摘要</span></h3>
<p>随着恶意软件检测算法和方法变得越来越复杂（sophisticated），恶意软件作者也采用（adopt）同样复杂的逃避机制（evasion
mechansims）来对抗（defeat）它们。<strong>民间证据表明离地攻击技术（Living-Off-The-Land，LotL）是许多恶意软件攻击中最主要的逃避技术之一。这些技术利用（leverage）系统中已经存在的二进制文件来执行（conduct）恶意操作。</strong>基于此，我们首次对Windows系统上使用这些技术的恶意软件进行大规模系统地调查。</p>
<p>在本文中，我们分析了这些本地系统的二进制文件在多个恶意软件数据集上的使用情况，这些数据集共包含31,805,549个样本。我们发现平均流行率（prevalence）为9.41%。实验结果表明，LotL技术被大量的使用，特别是在高级持久性威胁（Advanced
Persistent Threat
，APT）恶意软件样本中，离地攻击占比为26.26%，是社区恶意软件的两倍多。</p>
<p><strong>为了验证（illustrate）LotL技术的逃逸潜力，我们在本地沙箱环境（sandboxed
environment）中对几个完全打补丁的Windows系统进行了离地攻击技术的测试，其结果表明在10个最流行的反病毒产品（anti-virus）中存在明显的gap。</strong></p>
<h3><span id="一-引言">一、引言</span></h3>
<h4><span id="11-什么是离地攻击">1.1 什么是离地攻击</span></h4>
<p>恶意软件开发和检测是猫和老鼠的游戏，恶意软件作者不断开发新技术来绕过（bypass）检测系统。像AV杀毒软件（anti-virus）这样的安全产品通过静态和启发式分析（heuristic
analysis）技术，以检测、分类和防止恶意软件有效执行。</p>
<p>在过去，许多解决方案严重依赖于基于签名的检测，但不幸的是，由于使用了<strong>多态性（polymorphism）和加壳程序（packers）</strong>，这些方法变得不再那么有效。相反，许多产品开始开发启发式分析解决方案，包括检测恶意行为的算法。这些算法已成为AV引擎的重要组成部分。随着时间的推移，这些算法越来越复杂，因此需要更多创新性的逃避技术。</p>
<p>恶意软件作者和红队经常研究和发现新方法来绕过安全解决方案。虽然它们的潜在目标本质上可能有所不同，但这两种类型的攻击者通常都利用（leverage）最先进（state-of-the-art）的逃避技术来实现目标。<strong>从防守者的角度来看，为了及时作出响应，了解这些攻击和研究它们的趋势是至关重要的（crucial）</strong>。其中，在红队和恶意软件作者中都流行的规避策略就是使用离地攻击（LotL）技术。</p>
<p>==<strong>离地攻击（LotL）技术是指使用系统中已经存在或易于安装的二进制文件（如已签名的合法管理工具）来执行后渗透活动（post-exploitation
activity）。</strong>==</p>
<ul>
<li>通过利用这些工具，攻击者可以<strong>实现注册表修改、持久化、网络或系统侦察，或执行其他恶意代码</strong>。它们甚至可以用来减少由恶意活动产生的事件日志，而不需要将其他文件下载到本地的系统中。</li>
</ul>
<h4><span id="12-apt中的离地攻击">1.2 APT中的离地攻击</span></h4>
<p>离地攻击并不是隐蔽的技术，它们在互联网上公开记录着。许多开源的攻击安全工具利用了LotL技术，并且经常被攻击者所使用，从合法的红队到业余的网络攻击者，以及有组织的APT团队。</p>
<ul>
<li><code>PoshSpy[15]</code>：是一个俄罗斯APT29攻击模块，它是第一个被检测到的APT组织使用的LotL技术，特别是在PowerShell和Windows
Management中。</li>
<li>伊朗威胁组织[1]、APT33、APT34和其他组织也以使用本地Windows二进制文件和其它签名工具而闻名，特别是PowerShell[8]。</li>
</ul>
<p>尽管“离地攻击”在信息安全界是一个相对知名的术语，但有时很难找到一个精确的定义。此外，据我们所知，没有任何研究包含了对LotL技术在恶意软件样本中的流行程度的系统分析。关于LotL技术的文档大多以博客的形式出现，并记录着某些恶意软件家族的在野发现，或者攻击者在远程访问受损系统中所使用技术的描述。</p>
<ul>
<li>例如，<code>Emotet</code> 和
<code>Trickbot</code>，两个最常见的远程访问木马（Remote Access
Trojans，RAT），据称是使用链接的LotL二进制文件来实现持久化。</li>
<li>作为一种对策，微软描述了对抗使用LotL技术商用RAT的基本步骤。高度逃逸的远程访问木马
<code>Astaroth</code>，<code>TA505</code>
组织的一些恶意软件库，<code>Dexphot cryptominer</code> 和
<code>Nodersok</code> 同期使用的多个LotL二进制文件。</li>
</ul>
<h4><span id="13-提出5个关键性问题">1.3 提出5个关键性问题</span></h4>
<p>在本文中，我们分析了LotL现象，即商用恶意软件中与离地攻击二进制文件利用相关的文件。我们首先描述了什么是LotL
binary以及它如何被恶意软件利用来实施恶意行为的。</p>
<p>本文的研究重点是以Windows为主导的操作系统下流行且恶意软件最常针对的目标。<strong>许多基于离地攻击的AV逃逸行为已被记录下来。因此（As
a
consequence），安全界很大程度上认为，LotL技术（如代理执行恶意软件）实际上对安全解决方案是有效的。</strong></p>
<p>首先，我们提出了第一个假设以及第一个研究问题：</p>
<blockquote>
<p>#### <strong>问题1：Can LotL techniques effectively evade commercial
AV?</strong></p>
<p>#### ==LotL技术能有效地逃避目前大部分安全厂商的杀毒软件检测吗？==</p>
</blockquote>
<p>为了回答这个问题，我们评估了一组具有代表性的安全产品，并展示了其中的一些技术，虽然这是攻击者和防御者所熟知的，但仍然是绕过安全解决方案的有效方法，因此对安全行业来说这仍是一个开放的挑战。</p>
<p><strong>事实上，LotL二进制文件经常被系统管理员和高级计算机用户使用来执行（perform）系统管理任务，这使得即使是对于训练有素的分析人员来说，区分（distinguish）合法行为和恶意行为也非常困难</strong>。我们负责任地向受影响的供应商披露了我们的发现并进行跟进，因此提高了他们的检测能力。</p>
<p>尽管现有的文档提供了这些技术使用的可靠证据，但仍然不清楚这种现象在恶意软件样本中有多普遍。因此（In
this way），我们就提出了第二个研究问题：</p>
<blockquote>
<p>#### <strong>问题2：How prevalent is the use of LotL binaries in
malware?</strong></p>
<p>#### ==在恶意软件中使用LotL二进制文件的情况有多普遍？==</p>
</blockquote>
<p>在此基础上，我们试图阐明当前威胁情景中的一些趋势，以确定（identify）：</p>
<blockquote>
<p>#### <strong>问题3：What purposes do malware binaries use LotL
techniques for?</strong></p>
<p>#### ==恶意软件的二进制文件使用LotL技术的目的是什么？==</p>
<p>#### <strong>问题4：Which malware families and types use LotL
binaries most prolifically and how does their usage differ?</strong></p>
<p>####
==哪些恶意软件家族和类型使用LotL二进制文件最多，它们的使用情况又有何不同？==</p>
</blockquote>
<p>此外，我们还调查（investigate）了为什么这些技术难以检测。部分杀毒软件公司参与了我们的披露，即将恶意攻击与系统管理员执行完全合法的管理任务区分开来是困难的。这就给我们带来了另一个问题：</p>
<blockquote>
<p><strong>问题5：What are the overlaps and differences in the behavior
of legitimate and malicious binaries with respect to the usage of LotL
binaries? How would this affect detection by heuristic AV
engines?</strong></p>
<p>####
==在使用LotL二进制文件方面，合法和恶意二进制文件的行为有哪些重叠和差异呢？这将如何影响启发式AV引擎的检测呢？==</p>
</blockquote>
<p>虽然恶意样本和良性样本之间的LotL二进制使用频率（prevalence）有一些明显的差异，但我们也注意到一些类别存在某些相似性，如<strong>代理执行（proxied
execution）</strong>。</p>
<p>最后，<strong>我们将注意力集中在高逃逸和高级持续威胁的恶意软件上，我们发现它利用离地攻击技术是商用恶意软件的两倍</strong>。在表1中列出了一些使用LotL技术进行攻击的APT组织。</p>
<h4><span id="14-贡献">1.4 贡献</span></h4>
<p>据我们所知，本文提出了迄今为止对商用和APT恶意软件使用LotL技术最大规模的系统分析。本文的核心（core
）贡献：</p>
<ul>
<li>我们通过测试一组最流行的AV引擎来对抗基于LotL技术部署的恶意载荷，以评估LotL技术的可行性，并展示了离地攻击检测的复杂性对行业仍是一个挑战。<strong>即使在披露9个月后，这些技术仍没有被发现</strong>。</li>
<li>我们对代表现代商用恶意软件的几个数据集进行了大规模的评估，并确定了LotL技术的流行程度，以及在不同恶意软件家族和类型之间的差异。我们还评估了LotL技术由于假阳性风险可能对行业产生的影响。</li>
<li>我们评估了一个APT恶意软件数据集，并将其公开以促进（facilitate）后续的研究，并确定它执行LotL技术的频率是商用恶意软件的两倍。此外，我们还确定了哪些APT组织最多地使用LotL技术。</li>
</ul>
<h3><span id="二-背景和相关工作">二、背景和相关工作</span></h3>
<p>我们首先定义LotL二进制文件，并枚举恶意软件使用这些二进制文件的目的。</p>
<h4><span id="21-lotl-binaries">2.1 LotL Binaries</span></h4>
<p>近年来，“<code>Living-Off-The-Land binary（LOLbin）</code>”已经成为一个常用词，用来指在网络攻击中广泛使用的二进制文件。历史上，“Living-Off-The-Land”一直被用来表示可以为农业或狩猎提供喂养土地或离地的概念。<strong>转换为恶意软件和入侵领域，攻击者可能利用那些已经可以使用的文件（即系统上已经存在或易于安装的）来发起攻击并躲避检测。</strong></p>
<p>在本文中，我们将LotL二进制定义为：</p>
<ul>
<li>==<strong>任何具有公认合法用途的二进制文件，在攻击期间利用它直接执行恶意行为，或间接协助一系列恶意行动，从而达到恶意结果。</strong>==</li>
</ul>
<blockquote>
<p>In this paper, we define a LotL binary as any binary with a
recognised legitimate use, that is leveraged during an attack to
directly perform a malicious action; or to assist indirectly, in a
sequence of actions that have a final malicious outcome.</p>
</blockquote>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuuKVSBxwXyah6oA8o8y4YIcSszS9wu9wTcMpoVLldVNGWEmTcXX8Slw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<h4><span id="举例">举例：</span></h4>
<ul>
<li>在Windows系统上默认安装的二进制文件（binaries installed），如
<code>Reg.exe</code> 、<code>Sc.exe</code> 和 <code>Wmic.exe</code>
是最常被恶意软件执行的文件。</li>
<li>大多数默认安装的二进制文件都是由微软认证码签名的。认证码签名证明二进制文件没有在编译中被篡改或修改，这些二进制文件甚至可能被列为白名单。<strong>利用可信的LotL二进制文件的恶意软件可能因此避开杀毒软件</strong>。在Windows系统上使用系统二进制文件可以作为恶意软件操作的一部分，更重要的是，许多LotL技术使用系统二进制文件来实现这些二进制文件的目的。</li>
<li>此外，可以使用外部签名二进制文件（external signed binaries），如
<code>PsExec.exe</code>
或其他系统内部二进制文件。虽然它们使用频率不高，但本文的分析也囊括了这些文件。<strong>如APT组织在
<code>SoftCell</code> 和 <code>Havex</code> 中都使用
<code>PsExec.exe</code>
来秘密执行远程命令，从而实现网络中的横向移动。</strong></li>
<li>某些罕见情况，脆弱的（已签名）驱动程序被用来升级系统上的权限。这是
<code>RobbinHood</code> 勒索软件和各种 <code>APT wiper</code>
恶意软件样本所使用的一种技术，针对 <code>Saudi Arabian</code> 系统，包括
<code>Dustman</code> 、<code>Shamoon</code> 和
<code>Zerocleare</code>。</li>
</ul>
<h4><span id="可追溯性traceability"><strong>可追溯性（Traceability）：</strong></span></h4>
<ul>
<li>某些LotL二进制文件可能会比其他文件留下更多的系统日志，安全工具或取证分析人员可以利用这些日志来检测恶意操作。<strong>例如，可以将Powershell配置为具有全面的日志记录</strong>。</li>
<li>微软甚至建议<strong>阻止在系统上执行一些本机的二进制文件</strong>，除非有充分的理由。</li>
</ul>
<h4><span id="22-scope-of-our-study">2.2 Scope of our Study</span></h4>
<p>在本文中，我们关注的是Windows恶意软件执行系统二进制文件的目的。这些目的通常包括沿着
<strong>kill
chain</strong>的进展或逃避AV的检测。所有这些技术都被部署在系统的用户空间中。</p>
<p><code>hollowing</code> 和 <code>injection（注入）</code>
不在我们的研究范围内，尽管这是无文件恶意软件部署的常见技术。因为根据我们早期的定义，它们不是LotL技术。</p>
<h4><span id="23-related-work">2.3 Related Work</span></h4>
<blockquote>
<p>离地攻击相关工作较少，并且都非常经典，因此下面罗列了详细的相关研究，仅供自己后续深入，也希望对您有所帮助。</p>
</blockquote>
<ul>
<li>LotL恶意软件及其别名，“advanced volatile
threat”或“无文件”恶意软件在当前的学术文献中很少被提及。这主要受限于介绍分析少或描述为一个新兴的高逃逸恶意软件变体。</li>
<li>Li等[31]对恶意PowerShell脚本进行了分析，其中有一个小节专门描述了LotL攻击和无文件攻击作为近年来网络攻击的趋势。（<strong>作者第17篇博客详细介绍过PS经典</strong>）</li>
<li>Wang等[72]最近发表的一篇关于数据来源分析的论文指出，Living-Off-The-Land
是一种新兴的、突出的逃避型恶意软件子类（evasive malware
subtype）。（<strong>经典的You Are What You
Do后续即将分享</strong>）</li>
<li>先前的工作[64]进行了介绍性分析，然而LotL恶意软件还没有受到详细的学术分析。（An
emerging threat Fileless malware: a survey and research
challenges）</li>
<li>==<strong>赛门铁克</strong>[73,66]和<strong>思科Talos</strong>的[65]白皮书介绍了这个主题，并对多个数据集的流行性进行了分析。目前，没有论文对包含多个使用LotL技术的Windows恶意软件数据集进行大规模地系统分析。（<strong>经典</strong>）==
<ul>
<li>https://www.symantec.com/content/dam/symantec/docs/security-center/white-papers/istr-living-off-the-land-and-fileless-attack-techniques-en.pdf</li>
<li>https://www.symantec.com/content/dam/symantec/docs/white-papers/living-off-the-land-turning-your-infrastructure-against-you-en.pdf</li>
<li>https://blog.talosintelligence.com/2019/11/hunting-for-lolbins.html</li>
</ul></li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuo3I9Tc2Y5ic4biaG6jqMn0XNQbwVBw1LBM5ibErWYib2DDXc2avCPt2iaXQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<p>在一些论文中提到了LotL技术，强调了高隐蔽（stealthiness）和APT恶意软件曾使用。</p>
<ul>
<li><p>在一篇关于恶意软件分析工具Yara的论文中，Cohen[9]将LotL描述 “ LotL
as a trend that has been recently observed in the tactics used by elite
threat actors”，我们的分析结果进一步证实了该说法。</p></li>
<li><p>Hassan等[21]的研究表明，APT恶意软件使用LotL攻击策略来实现持续攻击并分析了两个活动，他们的工作还利用了MITRE
ATT&amp;CK框架[45]，通过MITRE定义了一个描述和分类知名攻击的分类方法。<strong>许多LotL技术在MITRE
ATT&amp;CK框架内被索引</strong>。Mitre公司及其常见CVE漏洞是安全领域的既定权威，他们囊括并描述许多LotL技术，这样表明离地攻击是一个值得深入分析的课题。</p></li>
<li><ul>
<li><strong>==W. U. Hassan, A. Bates, and D. Marino, “Tactical
Provenance Analysis for Endpoint Detection and Response Systems,” IEEE
Symposium on Security and Privacy, 2020.==</strong></li>
</ul></li>
</ul>
<p>==<strong>强烈推荐一个包含LotL二进制和ATT&amp;CK功能映射的资源</strong>：==</p>
<ul>
<li>https://github.com/LOLBAS-Project/LOLBAS</li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuicYc1hL2AJtlQRoibrRvWzTQjdOsicdTsl0q5kzawT3MibrOM71uREq5wQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<p>与我们研究相关的是对基于脚本的恶意软件分析和去混淆。使用LotL技术的恶意软件经常使用恶意脚本作为有效负载。（<strong>下列论文在作者第16篇PowerShell总结博客中详细介绍过</strong>）</p>
<ul>
<li>Ugarte等[67]通过识别可疑行为模式，测试了经
<code>Powershell.exe</code> 二进制调用的恶意脚本。</li>
<li><strong>Rubin等[61]将机器学习应用于检测PowerShell恶意软件（微软团队）</strong>。</li>
<li>Curtsinger[11]等人提出了恶意Javascript攻击的检测机制——ZOZZLE。</li>
</ul>
<p><strong>虽然这些论文提出了有效的检测方法，但是他们都是为狭隘的恶意载荷（payload）所用，他们没有分析更广泛的恶意软件生态系统和这些有效载荷是如何被LotL二进制文件触发的。</strong></p>
<h3><span id="三-动机">三、动机</span></h3>
<p><strong>安全研究人员已经记录了许多使用LotL技术成功躲避安全产品的案例</strong>。在许多情况下，这些<strong>LotL二进制文件被用来代理恶意载荷的执行，使其在一个合法的进程上下文中执行，或者作为一个合法系统进程的子进程生成一个新进程</strong>。在某些情况下，这些有效载荷作为LotL二进制调用的副作用被执行，而在其他情况下，它只是其主要记录行为的结果。此外，许多杀毒产品未能正确检测到这些技术。</p>
<figure>
<img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuqG91IHaTia5YXypwibNOxcZymPMV5Ku4TjBhzZlOv1icJx9VnwDhZfVfw/640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p><strong>为了回答第一个问题，我们首先分析了当前AV产品是否将LotL技术作为恶意行为的指标。</strong></p>
<p>为此，我们首先选择了10个具有代表性的AV产品（详见附录C），并利用常见<strong>基于LotL的代理执行技术来实施反弹Shell的模拟攻击</strong>。此外，本研究的目的不是测试任何特定AV产品的检测能力或将它们相互比较，而是确定是否存在普遍的检测差距。</p>
<ul>
<li>实验在联网的Windows
10虚拟机执行，并将最新的本地AV产品连接到它们的云组件。</li>
<li>利用一个反弹Shell来评估AV系统在部署LotL技术的恶意软件中有多脆弱。本文认为能够允许远程执行命令的reverse
shell是成功执行代码的证明，这与许多远程访问木马（RAT）功能相同。</li>
<li>通过从不同LotL二进制文件中运行这个反弹shell来进行实验，以测试AV产品是否检测到离地攻击技术是恶意的。</li>
<li>我们在必要时混淆了反弹shell的有效载荷，并使用各种有效载荷类型来测试AV检测传递机制本身的能力，而不是通过静态签名传递的特定有效载荷（详见附录D）。</li>
</ul>
<h4><span id="实验结果如表2所示">实验结果如表2所示：</span></h4>
<ul>
<li><strong>可以发现大部分的AV引擎允许我们建立一个反弹Shell并执行命令，它们并没有检测出利用LotL技术的恶意软件，60个中只检测出4个。</strong></li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuoBzOPNqhU9ce1SlxeLjb0e6mb3RUz0rkP2wrKGjKibMMUltIvMvbUeA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<h4><span id="负责任的披露和回应">负责任的披露和回应：</span></h4>
<p>此后，我们向相关的AV供应商发布了一份文件，包含我们检查的结果并协助补救。9个月后，我们在Windows
10机器上重复了类似的测试，这允许我们测试AV供应商是否在他们的产品中包含了新的启发式规则来检测LotL二进制的使用。其结果如下：</p>
<ul>
<li><strong>可以发现在60个相同的有效载荷中检测到了25个</strong></li>
<li>在检测到的反弹shell测试中，我们修改了载荷（利用混淆或运行不同的载荷），同时为LotL二进制文件保持了完全相同的命令行参数，通过利用这些混淆和修改的有效载荷，我们成功地在这25个被拦截的实例中的19个执行了一个反向shell。</li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuHRbN87ZFfsyVAYjqDAoDicE27vuhSBiaLf4zlGotKd2yrNfxA7Z3h2icw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<p>==<strong>实验结果表明，LotL技术仍然是杀毒软件供应商面临的一个重大挑战。合法用户通常以不可预知的方式使用这些工具，而安全公司很难在没有误报的情况下部署有效的检测策略。</strong>==</p>
<p>接下来将展示这些技术如何在商用恶意软件中是普遍存在的，以及离地攻击是不应该被安全社区忽视的问题。</p>
<h3><span id="四-离地攻击流行性评估">四、离地攻击流行性评估</span></h3>
<p>在本节中，我们测量了恶意软件中LotL技术的流行程度，并试图回答所提出的研究问题。</p>
<h4><span id="41-数据集描述">4.1 数据集描述</span></h4>
<p>评估工作是在9个独立的子数据集上进行的。我们总共收集了31,805,549个样本，其中我们从VirusTotal（VT）中获得了16,048,202份行为报告。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXulUhTGQG5b3yfdmTq4NIo8YaKGvb39A0WOwvqUft2aUEB7MwGebkjGw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<p>==<strong>Public Datasets</strong>==</p>
<p>公共恶意软件数据集，包括商用恶意软件、VirusShare语料库的二进制文件、窗口恶意PE文件、佐治亚理工学院发布的可执行文件、VX-Mumbal和MalShare共享的样本（两个重点的共有数据集）。</p>
<ul>
<li>https://impactcybertrust.org/dataset{ }view?idDataset=1143</li>
<li>https://vx-underground.org/samples.html</li>
<li>https://malshare.com</li>
</ul>
<p><strong>VirusTotal Balanced Dataset</strong></p>
<p>从VT中收集了237,288个hash值，利用 <code>AVClass</code>
预处理代码和打标签（家族分类），并平衡数据集中每个族。</p>
<p><strong>APT Malware</strong></p>
<p>我们根据一种类似于数据集论文dAPTaset[59]的方法收集了一个APT恶意软件的数据集。我们处理了HTML页面和pdf文件（<code>APTnotes</code>），并提取了这些文件中包含的所有恶意软件的hash值。</p>
<ul>
<li>https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-rezaeirad.pdf</li>
<li>https://github.com/aptnotes/data</li>
</ul>
<p>==<strong>Yara Rule Match Malware</strong>==</p>
<p>部署3个Yara规则来检测LotL二进制文件，并使用Livehunte来识别上传到VT的新的恶意软件hash，并使用LotL技术匹配恶意软件的行为特征。</p>
<h4><span id="42-analysis-pipeline">4.2 Analysis Pipeline</span></h4>
<p>当收集了由Windows
PE二进制文件组成的不同数据集，我们就分析样本的行为。包括三个阶段：</p>
<ul>
<li>data collection</li>
<li>data augmentation</li>
<li>data analysis</li>
</ul>
<blockquote>
<p>First Seen：首次发现病毒样本的时间戳 AVClass
Family：某恶意软件样本所属家族 <strong>Behavioural
Report：恶意行为报告，由特定恶意软件样本执行的进程和Shell命令的列表</strong></p>
</blockquote>
<h4><span id="43-lotl-techniqueidentification">4.3 LotL Technique
Identification</span></h4>
<p><strong>数据准备就绪，那么如何识别是否使用了LotL技术呢？</strong></p>
<p>我们使用<strong>模式匹配</strong>来识别恶意软件执行过程中对LotL二进制文件调用的情况，从而处理所有收集到的行为报告（<code>behavioural reports</code>）。行为报告包括两个指标：</p>
<ul>
<li><p><strong>Shell Commands（Shell命令）</strong></p>
<p><strong>恶意二进制文件在主机操作系统中执行的Shell命令</strong>，Shell命令日志可以通过引用系统二进制文件的绝对路径来显示它的执行情况。<strong>同时，Windows的命令提示符还包括许多别名，例如Reg.exe的reg</strong>。</p></li>
<li><p><strong>Processes（进程）</strong></p>
<p><strong>进程日志明确由恶意软件样本执行的系统二进制文件</strong>。执行的参数也包含在行为报告中的进程日志中。</p></li>
</ul>
<p>在我们的分析中，如果一个样本的行为报告包含至少一个LotL二进制文件的执行，那么它使用了LotL技术。<strong>我们记录了每一个LotL的执行及其参数细节，并将它们插入到数据库中。然后，我们分析了这些恶意软件样本的参数，以确定每个数据集中最==常见的参数类型和执行目的==。</strong></p>
<p>具体而言，我们确定了这两种独立类型的二进制文件：</p>
<ul>
<li><strong>Default System Binaries</strong></li>
<li><strong>Installed Signed Binaries</strong></li>
</ul>
<p>模式匹配优化：模式匹配方法在不断改进，直到所有识别的LotL命令被正确分类和映射到执行目的，并进行了数据清洗处理。</p>
<ul>
<li>不带参数的二进制执行移除</li>
<li>沙箱产物删除（如Explorer.exe和sha256），Web访问不处理</li>
<li>删除Verclsid.exe的实例</li>
</ul>
<h4><span id="44parameter-analysis-to-identify-execution-purpose">==4.4
Parameter Analysis to Identify Execution Purpose==</span></h4>
<p>==<strong>为了确定LotL技术的执行目的，我们观察了恶意软件样本提供的参数。</strong>==</p>
<p>图1说明了四个进程执行的映射。该映射通过识别单独的执行目的来在所有数据集上实施，<strong>例如执行Net.exe时使用stop参数表示任务停止。在将单个命令映射到执行目的之后，我们将为该二进制文件选择所有匹配的执行</strong>。我们在所有系统二进制执行中重复该步骤，直到每次执行被分类为属于特定的执行目的或被错误分类。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/0RFmxdZEDROicMJKf6AXIujWAvOnAhjXuHicN1aicniaStH5EZY1y22UBUzsMYXomMtNgYwuQYr1AZ8vWfRTPJOFPg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:50%;"></p>
<p>按照这种方法，我们按目的将参数分为9个独立的类别。</p>
<p><strong>首先是三种与执行有关的类型：</strong></p>
<ul>
<li><strong>Proxied
Execution</strong>：代理执行，如Mshta.exe执行.hta文件，Rundll32.exe执行.dll文件</li>
<li><strong>Persistence</strong>：持久化：如果恶意代码配置或修改系统以在未来某个时间点执行命令或存储的作业，那么它就实现了持久性，比如Sc.exe带有创建参数的Bitsadmin.exe，或带有日期时间参数的Schtasks.exe/At.exe</li>
<li><strong>Delayed Execution</strong>：延迟执行，比如
Ping.exe执行-n</li>
</ul>
<p><strong>接着是三类与底层系统组件的修改有关。恶意软件通常从事这种行为，以便在机器上对目标进行==进一步的传播==或行动。</strong></p>
<ul>
<li><strong>Firewall Modification</strong>：防火墙修改，如Netsh.exe</li>
<li><strong>Registry Modification</strong>：注册表修改，如Reg.exe</li>
<li><strong>Permissions
Modification</strong>：权限修改，如Cacls.exe修改文件权限</li>
</ul>
<p><strong>最后是与执行或系统修改无关的三类。</strong></p>
<ul>
<li><strong>File Opening</strong>：打开文件，如Explorer.exe</li>
<li><strong>Reconnaissance</strong>：侦察，触发本地或远程配置的横向移动，如Net.exe</li>
<li><strong>Task
Stopping</strong>：使用LotL二进制文件秘密停止另一个进程或服务，如Taskkill.exe</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/2ZDHNTC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/2ZDHNTC/" class="post-title-link" itemprop="url">深度学习-NLP（1）词嵌入</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-13 11:14:54" itemprop="dateCreated datePublished" datetime="2022-05-13T11:14:54+08:00">2022-05-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-06-28 16:24:54" itemprop="dateModified" datetime="2022-06-28T16:24:54+08:00">2022-06-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>8 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="nlpword2vecglovefasttextelmogptbert">nlp：word2vec/glove/fastText/elmo/GPT/bert</span></h2>
<blockquote>
<p>本文以QA形式对自然语言处理中的词向量进行总结：包含word2vec/glove/fastText/elmo/bert。</p>
<ul>
<li>https://zhuanlan.zhihu.com/p/56382372</li>
<li><strong>Bert之后，RoBERTa、XLNET、ALBERT、ELECTRA改进对比</strong> -
虹膜小马甲的文章 - 知乎 https://zhuanlan.zhihu.com/p/486532878</li>
</ul>
</blockquote>
<h3><span id="一-文本表示和各词向量间的对比"><strong>一、文本表示和各词向量间的对比</strong></span></h3>
<h4><span id="1-文本表示和各词向量间的对比"><strong>1、文本表示和各词向量间的对比</strong></span></h4>
<ul>
<li><strong>词袋模型</strong>：<strong>one-hot、tf-idf</strong>、textrank等；</li>
<li>主题模型：LSA（SVD）、pLSA、LDA；</li>
<li><strong>基于词向量的固定表征</strong>：<strong>word2vec、fastText</strong>、glove</li>
<li><strong>基于词向量的动态表征</strong>：elmo、<strong>GPT、bert</strong></li>
</ul>
<h4><span id="2-怎么从语言模型理解词向量怎么理解分布式假设"><strong>2、怎么从语言模型理解词向量？怎么理解分布式假设？</strong></span></h4>
<p>上面给出的4个类型也是nlp领域最为常用的文本表示了，文本是由每个单词构成的，而谈起词向量，one-hot是可认为是最为简单的词向量，但存在维度灾难和语义鸿沟等问题；通过构建共现矩阵并利用<strong>SVD求解构建词向量</strong>，则计算复杂度高<strong>；而早期词向量的研究通常来源于语言模型，比如NNLM和RNNLM</strong>，其主要目的是语言模型，而词向量只是一个副产物。</p>
<p>所谓==分布式假设，用一句话可以表达：<strong>相同上下文语境的词有似含义</strong>==。而由此引申出了word2vec、fastText，在此类词向量中，虽然其本质仍然是语言模型，但是它的目标并不是语言模型本身，而是词向量，其所作的一系列优化，都是为了更快更好的得到词向量。<strong>glove则是基于全局语料库、并结合上下文语境构建词向量，结合了LSA和word2vec的优点。</strong></p>
<h4><span id="3-传统的词向量有什么问题怎么解决各种词向量的特点是什么"><strong>3、传统的词向量有什么问题？怎么解决？各种词向量的特点是什么？</strong></span></h4>
<p><strong>上述方法得到的词向量是固定表征的，无法解==决一词多义==等问题</strong>，如“川普”。为此引入基于语言模型的动态表征方法：elmo、GPT、bert。</p>
<p><img src="https://pic2.zhimg.com/80/v2-80e28f4375302454947c9c8431564ed9_1440w.jpg" alt="img" style="zoom:50%;"></p>
<p><strong>各种词向量的特点：</strong></p>
<p>One-hot 表示 ：维度灾难、语义鸿沟；</p>
<p><strong>分布式表示 (distributed representation)</strong> ：</p>
<ul>
<li>矩阵分解（LSA）：利用全局语料特征，但SVD求解计算复杂度大；</li>
<li>基于NNLM/RNNLM的词向量：词向量为副产物，存在效率不高等问题；</li>
<li><strong>word2vec、fastText</strong>：优化效率高，但是基于局部语料；</li>
<li>glove：基于全局预料，结合了LSA和word2vec的优点；</li>
<li>elmo、GPT、bert：动态特征；</li>
</ul>
<h4><span id="4-word2vec和nnlm对比有什么区别word2vecvs-nnlm"><strong>4、word2vec和NNLM对比有什么区别？（word2vec
vs NNLM）</strong></span></h4>
<p>1）其本质都可以看作是语言模型；</p>
<p>2）词向量只不过NNLM一个产物，word2vec虽然其本质也是语言模型，但是其专注于词向量本身，因此做了许多优化来提高计算效率：</p>
<ul>
<li>与NNLM相比，词向量直接sum，不再拼接，并舍弃隐层；</li>
<li>考虑到sofmax归一化需要遍历整个词汇表，采用<strong>hierarchical
softmax</strong> 和<strong>negative
sampling</strong>进行优化，<strong>hierarchical softmax
实质上生成一颗带权路径最小的哈夫曼树，让高频词搜索路劲变小；negative
sampling更为直接，实质上对每一个样本中每一个词都进行负例采样；</strong></li>
</ul>
<h4><span id="5-word2vec和fasttext对比有什么区别word2vecvs-fasttext">5、<strong>word2vec和fastText对比有什么区别？（word2vec
vs fastText）</strong></span></h4>
<ul>
<li>都可以无监督学习词向量，
<strong>fastText训练词向量时会考虑subword</strong>；</li>
<li>fastText还可以进行==有监督学习==进行文本分类，其主要特点：
<ul>
<li>结构与<strong>CBOW类似</strong>，但学习目标是<strong>人工标注的分类结果</strong>；</li>
<li>采用hierarchical
softmax对输出的分类标签建立哈夫曼树，样本中标签多的类别被分配短的搜寻路径；</li>
<li><strong>引入N-gram，考虑词序特征</strong>；</li>
<li><strong>引入subword来处理长词，处理未登陆词问题</strong>；</li>
</ul></li>
</ul>
<h4><span id="6-glove和word2vec-lsa对比有什么区别word2vec-vs-glove-vs-lsa"><strong>6、glove和word2vec、
LSA对比有什么区别？（word2vec vs glove vs LSA）</strong></span></h4>
<ul>
<li><p><strong>glove vs LSA</strong></p>
<ul>
<li><p>LSA（Latent Semantic Analysis）可以基于co-occurance
matrix构建词向量，实质上是基于全局语料采用SVD进行矩阵分解，然而SVD计算复杂度高；</p></li>
<li><p>glove可看作是对LSA一种优化的高效矩阵分解算法，采用Adagrad对最小平方损失进行优化；</p></li>
</ul></li>
<li><p>==<strong>word2vec vs glove</strong>==</p>
<ul>
<li><p><strong>word2vec是局部语料库训练的，其特征提取是基于滑窗的</strong>；而glove的滑窗是为了构建co-occurance
matrix，是基于全局语料的，可见glove需要事先统计共现概率；因此，word2vec可以进行在线学习，glove则需要统计固定语料信息。</p></li>
<li><p>word2vec是无监督学习，同样由于不需要人工标注；glove通常被认为是无监督学习，但实际上glove还是有label的，即共现次数<img src="https://www.zhihu.com/equation?tex=log%28X_%7Bij%7D%29" alt="[公式]">。</p></li>
<li><p><strong>word2vec损失函数实质上是带权重的交叉熵，权重固定</strong>；<strong>glove的损失函数是最小平方损失函数，权重可以做映射变换。</strong></p></li>
<li><p>总体来看，<strong>==glove可以被看作是更换了目标函数和权重函数的全局word2vec==</strong>。</p></li>
</ul></li>
</ul>
<h4><span id="7-elmo-gpt-bert三者之间有什么区别elmo-vs-gpt-vsbert"><strong><font color="red">
7、 elmo、GPT、bert三者之间有什么区别？（elmo vs GPT vs
bert）</font></strong></span></h4>
<p>之前介绍词向量均是静态的词向量，无法解决一次多义等问题。下面介绍三种elmo、GPT、bert词向量，它们都是基于语言模型的动态词向量。下面从几个方面对这三者进行对比：</p>
<ul>
<li><strong>特征提取器</strong>：elmo采用<strong>LSTM</strong>进行提取，GPT和bert则采用<strong>Transformer</strong>进行提取。很多任务表明<strong>Transformer特征提取能力强于LSTM</strong>，elmo采用1层静态向量+2层LSTM，多层提取能力有限，而GPT和bert中的==Transformer==可采用多层，并行计算能力强。</li>
<li><strong>单/双向语言模型</strong>：GPT采用单向语言模型，elmo和bert采用双向语言模型。但是elmo实际上是两个单向语言模型（方向相反）的拼接，这种融合特征的能力比bert一体化融合特征方式弱。<strong>GPT和bert都采用Transformer，Transformer是encoder-decoder结构，GPT的单向语言模型采用decoder部分，decoder的部分见到的都是不完整的句子；bert的双向语言模型则采用encoder部分，采用了完整句子。</strong></li>
</ul>
<h3><span id="二-深入解剖word2vec"><strong>二、深入解剖word2vec</strong></span></h3>
<h4><span id="1-word2vec的两种模型分别是什么"><strong>1、word2vec的两种模型分别是什么？</strong></span></h4>
<p><strong>word2Vec</strong> 有两种模型：<strong>CBOW</strong> 和
<strong>Skip-Gram：</strong></p>
<ul>
<li><strong>CBOW 在已知 <code>context(w)</code> 的情况下，预测
<code>w</code>；在CBOW中，投射层将词向量直接相加而不是拼接起来，并舍弃了隐层，这些牺牲都是为了减少计算量</strong>。</li>
<li>Skip-Gram在已知 <code>w</code> 的情况下预测 <code>context(w)</code>
；</li>
</ul>
<p><img src="https://pic4.zhimg.com/80/v2-f1194171ee403f95c4131137ea1b52b3_1440w.jpg" alt="img" style="zoom: 67%;"></p>
<h4><span id="2-word2vec的两种优化方法是什么它们的目标函数怎样确定的训练过程又是怎样的">2、<strong>word2vec的两种优化方法是什么？它们的目标函数怎样确定的？训练过程又是怎样的？</strong></span></h4>
<p><strong>不经过优化的CBOW和Skip-gram中
,在每个样本中每个词的训练过程都要遍历整个词汇表</strong>，也就是都需要经过softmax归一化，计算误差向量和梯度以更新两个词向量矩阵（这两个词向量矩阵实际上就是最终的词向量，可认为初始化不一样），当语料库规模变大、词汇表增长时，训练变得不切实际。为了解决这个问题，word2vec支持两种优化方法：<strong>hierarchical
softmax</strong> 和<strong>negative
sampling</strong>。此部分仅做关键介绍，数学推导请仔细阅读《<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/itplus/article/details/37969519">word2vec
中的数学原理详解</a>》。</p>
<ul>
<li><strong>hierarchical softmax</strong></li>
</ul>
<p><strong>hierarchical softmax</strong>
使用一颗二叉树表示词汇表中的单词，每个单词都作为二叉树的叶子节点。对于一个大小为V的词汇表，其对应的二叉树包含V-1非叶子节点。假如每个非叶子节点向左转标记为1，向右转标记为0，那么每个单词都具有唯一的从根节点到达该叶子节点的由｛0
1｝组成的代号（<strong>实际上为哈夫曼编码，为哈夫曼树，是带权路径长度最短的树，哈夫曼树保证了词频高的单词的路径短，词频相对低的单词的路径长，这种编码方式很大程度减少了计算量</strong>）。</p>
<ul>
<li><strong>negative sampling（拒绝采样）</strong></li>
</ul>
<p>negative sampling是一种不同于hierarchical
softmax的优化策略，相比于hierarchical softmax，negative
sampling的想法更直接——<strong>为每个训练实例都提供负例。</strong></p>
<p><strong><font color="red">
负采样算法实际上就是一个带权采样过程，负例的选择机制是和单词词频联系起来的。</font></strong>具体做法是以
<code>N+1</code> 个点对区间 <code>[0,1]</code>
做非等距切分，并引入的一个在区间 <code>[0,1]</code> 上的 <code>M</code>
等距切分，其中 <code>M &gt;&gt; N。</code>源码中取 M =
10^8。然后对两个切分做投影，得到映射关系：采样时，每次生成一个 [1, M-1]
之间的整数 i，则 Table(i)
就对应一个样本；当采样到正例时，跳过（<strong>拒绝采样</strong>）。</p>
<figure>
<img src="https://pic4.zhimg.com/80/v2-36547a4cd05365292830ad4b22ba4c93_1440w.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic3.zhimg.com/80/v2-a788595cc2611b0bfdac9e039a2e82fe_1440w.png" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<figure>
<img src="https://pic1.zhimg.com/80/v2-cfe67c913af37a9435f3331139abeab8_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<h3><span id="三-深入解剖glove详解"><strong>三、深入解剖Glove详解</strong></span></h3>
<p><strong>GloVe的全称叫Global Vectors for Word
Representation，它是一个基于全局词频统计（count-based &amp; overall
statistics）的词表征（word representation）工具。</strong></p>
<p><strong>1、GloVe构建过程是怎样的？</strong></p>
<p>（1）根据语料库构建一个共现矩阵，矩阵中的每一个元素 <img src="https://www.zhihu.com/equation?tex=X_%7Bij%7D" alt="[公式]">
代表单词 <img src="https://www.zhihu.com/equation?tex=i" alt="[公式]">
和上下文单词 <img src="https://www.zhihu.com/equation?tex=j" alt="[公式]"> 在特定大小的上下文窗口内共同出现的次数。</p>
<blockquote>
<p>共现矩阵:统计文本中两两词组之间共同出现的次数</p>
</blockquote>
<p>（2）构建词向量（Word
Vector）和共现矩阵之间的近似关系，其目标函数为：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=J+%3D+%5Csum_%7Bi%2Cj%3D1%7D%5EV+f%5CBig%28X_%7Bij%7D%5CBig%29%5CBig%28w_i%5ET%5Ctilde%7Bw_j%7D+%2B+b_i+%2B+b_j+-%5Clog%7BX_%7Bij%7D%7D+%5CBig%29%5E2" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>这个loss function的基本形式就是最简单的mean square
loss，只不过在此基础上加了一个权重函数 <img src="https://www.zhihu.com/equation?tex=f%28x_%7Bij%7D%29" alt="[公式]"> :</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=f%28x%29+%3D++%5Cbegin%7Bcases%7D+%28x%2Fx_%7B%5Cmax%7D%29%5E%5Calpha+%26+%5Ctext%7Bif+%7D+x%3Cx_%7B%5Cmax%7D+%5C%5C+1+%26+%5Ctext%7Botherwise.%7D+%5Cend%7Bcases%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>根据实验发现 <img src="https://www.zhihu.com/equation?tex=x_%7B%5Cmax%7D" alt="[公式]">
的值对结果的影响并不是很大，原作者采用了 <img src="https://www.zhihu.com/equation?tex=x_%7B%5Cmax%7D%3D100" alt="[公式]"> 。而 <img src="https://www.zhihu.com/equation?tex=%5Calpha%3D3%2F4" alt="[公式]"> 时的结果要比 <img src="https://www.zhihu.com/equation?tex=%5Calpha%3D1" alt="[公式]">
时要更好。下面是 <img src="https://www.zhihu.com/equation?tex=%5Calpha%3D3%2F4" alt="[公式]"> 时 <img src="https://www.zhihu.com/equation?tex=f%28x%29" alt="[公式]">
的函数图象，可以看出对于较小的 <img src="https://www.zhihu.com/equation?tex=X_%7Bij%7D" alt="[公式]">
，权值也较小。这个函数图像如下所示：</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-2e2b198b3b7a7c4ace45648ff18dd2ca_1440w.jpg" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<blockquote>
<ol type="1">
<li>实质上还是监督学习：虽然glove不需要人工标注为无监督学习，但实质还是有label就是
<img src="https://www.zhihu.com/equation?tex=log%28X_%7Bij%7D%29" alt="[公式]"> 。</li>
<li>向量 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]">
和 <img src="https://www.zhihu.com/equation?tex=%5Ctilde%7Bw%7D" alt="[公式]">为学习参数，本质上与监督学习的训练方法一样，采用了AdaGrad的梯度下降算法，对矩阵
<img src="https://www.zhihu.com/equation?tex=X" alt="[公式]">
中的所有非零元素进行随机采样，学习曲率（learning
rate）设为0.05，在vector
size小于300的情况下迭代了50次，其他大小的vectors上迭代了100次，直至收敛。</li>
<li>最终学习得到的是两个词向量是 <img src="https://www.zhihu.com/equation?tex=%5Ctilde%7Bw%7D" alt="[公式]">
和 <img src="https://www.zhihu.com/equation?tex=w+" alt="[公式]">
，因为 <img src="https://www.zhihu.com/equation?tex=X" alt="[公式]">
是对称的（symmetric），所以从原理上讲<img src="https://www.zhihu.com/equation?tex=%5Ctilde%7Bw%7D" alt="[公式]">
和 <img src="https://www.zhihu.com/equation?tex=w+" alt="[公式]">
，是也是对称的，他们唯一的区别是初始化的值不一样，而导致最终的值不一样。所以这两者其实是等价的，都可以当成最终的结果来使用。但是为了提高鲁棒性，我们最终会选择两者之和
<img src="https://www.zhihu.com/equation?tex=w%2B%5Ctilde%7Bw%7D" alt="[公式]">
作为最终的vector（两者的初始化不同相当于加了不同的随机噪声，所以能提高鲁棒性）。</li>
</ol>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/3VPSMN7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/3VPSMN7/" class="post-title-link" itemprop="url">python-正则表达式</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-12 18:22:55" itemprop="dateCreated datePublished" datetime="2022-05-12T18:22:55+08:00">2022-05-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-21 14:30:46" itemprop="dateModified" datetime="2023-04-21T14:30:46+08:00">2023-04-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B7%A5%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">工程</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B7%A5%E7%A8%8B/%E6%B5%81%E7%A8%8B%E7%9A%84Python/" itemprop="url" rel="index"><span itemprop="name">流程的Python</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>98</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1><span id="python3爬虫笔记-正则表达式">Python3爬虫笔记 --
正则表达式</span></h1>
<p>https://blog.csdn.net/Sc0fie1d/article/details/102724298?spm=1001.2014.3001.5502</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/M5Q53E/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/M5Q53E/" class="post-title-link" itemprop="url">高级威胁发现（3）SLEUTH: Real-time Attack Scenario Reconstruction from COTS Audit Data</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-12 18:10:54" itemprop="dateCreated datePublished" datetime="2022-05-12T18:10:54+08:00">2022-05-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-19 15:55:03" itemprop="dateModified" datetime="2023-04-19T15:55:03+08:00">2023-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/" itemprop="url" rel="index"><span itemprop="name">学术前沿</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>8.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>15 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="sleuthreal-time-attack-scenario-reconstruction-from-cots-audit-data">SLEUTH:
Real-time Attack Scenario Reconstruction from COTS Audit Data</span></h2>
<ul>
<li>https://blog.csdn.net/Sc0fie1d/article/details/104273798</li>
</ul>
<h3><span id="摘要">摘要</span></h3>
<p>本文提出了一种实时重构企业主机上攻击场景的方法和系统。为了满足问题的<strong>可伸缩性</strong>和<strong>实时需求</strong>，我们开发了一个平台中立的、基于主存的、审计日志数据的依赖图抽象方法。然后，我们提出了高效的、基于标签的攻击检测和重建技术，包括源识别和影响分析。我们还开发了一些方法，通过构建紧凑的攻击步骤的可视化图来揭示攻击的大局。我们的系统参与了由DARPA组织的红色团队评估，并能够成功地检测并重建了红色团队对运行Windows、FreeBSD和Linux的主机的攻击细节</p>
<h3><span id="一-说明">一、说明</span></h3>
<p>我们正在目睹由熟练的对手进行的有针对性的网络攻击(“企业高级和持续威胁(APTs))[1]的迅速升级。通过将社会工程技术（例如，鱼叉式网络钓鱼）与先进的开发技术相结合，这些对手通常会绕过广泛部署的软件保护系统，如ASLR、DEP和沙箱。因此，企业越来越依赖于二线防御，例如，<strong>入侵检测系统(IDS)、安全信息和事件管理(SIEM)工具、身份和访问管理工具，以及应用程序防火墙。虽然这些工具通常很有用，但它们通常会生成大量的信息，这使得安全分析师很难区分真正重要的攻击——众所周知的“大海捞针”——从背景噪音</strong>。此外，分析人员缺乏“连接这些点”的工具，即，将跨越多个应用程序或主机并在长时间扩展的攻击活动的碎片拼凑起来。相反，需要大量的手工努力和专业知识来整理由多个安全工具发出的众多警报。因此，许多攻击活动被错过了数周甚至数月的[7,40]。</p>
<p>为了有效地控制高级攻击活动，分析人员需要新一代的工具，不仅帮助检测，而且还生成一个总结攻击的因果链的紧凑总结。这样的摘要将使分析人员能够快速确定是否存在重大入侵，了解攻击者最初是如何违反安全规则的，并确定攻击的影响。</p>
<p>将导致攻击的事件的因果链拼接在一起的问题首先在反向跟踪器[25,26]中进行了探索。随后的研究[31,37]提高了由反向跟踪器构建的依赖链的精度。然而，这些工作在一个纯粹的法医环境中运行，因此不处理实时进行分析的挑战。相比之下，本文提出了侦探（<strong>SLEUTH</strong>），一个系统，该系统可以实时提醒分析师一个正在进行的活动，并在攻击后的几秒钟或几分钟内为他们提供一个紧凑的、直观的活动摘要。这将使在对受害者企业造成巨大损害之前及时作出反应。实时攻击检测和场景重构提出以下几点：</p>
<ul>
<li><strong>事件存储和分析</strong>：我们如何有效地存储来自事件流的数百万条记录，并让算法在几秒钟内筛选这些数据？</li>
<li><strong>确定分析实体的优先级</strong>：我们如何帮助被数据量淹没的分析师，优先排序并快速“放大”最有可能的攻击场景？</li>
<li><strong>场景重构</strong>：如何从攻击者的入口点开始，简洁地总结攻击场景，识别整个活动对系统的影响？</li>
<li><strong>处理常见的使用场景</strong>：如何应对正常的、良性的活动，这可能类似于在攻击期间观察到的常见活动，例如，软件下载？</li>
<li><strong>快速、交互式推理</strong>：我们如何为分析人员提供通过数据进行有效推理的能力，比如说，用另一种假设？</li>
</ul>
<p>下面，我们将简要介绍侦探调查，并总结我们的贡献。侦探假设攻击最初来自企业外部。例如，对手可以通过外部提供的恶意输入劫持web浏览器、插入受感染的u盘或向企业内运行的网络服务器提供零日攻击来启动攻击。我们假设对手在侦探开始监视系统之前并没有在主机上植入持续的恶意软件。我们还假设操作系统内核和审计系统是值得信赖的</p>
<h4><span id="11方法概述和贡献">1.1方法概述和贡献</span></h4>
<p>图1提供了我们的方法的概述。侦探是操作系统中立的，目前支持微软的Windows、Linux和FreeBSD。来自这些操作系统的审计数据被处理成平台中立的图形表示，其中顶点表示主题（<strong>进程</strong>）和对象（<strong>文件、套接字</strong>），边表示审计事件（例如，读、写、执行和连接等操作）。该图可作为攻击检测、因果关系分析和场景重建的基础。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191554457.png" alt="image-20220513135637994">
<figcaption aria-hidden="true">image-20220513135637994</figcaption>
</figure>
<ul>
<li><p>本文的第一个贡献是<strong>针对高效事件存储依赖图表示的开发和紧凑的事件存储和分析（第2节）的挑战</strong>。主存表示上的图形算法可以比磁盘上的表示快几个数量级，这是实现实时分析能力的一个重要因素。<strong>在我们的实验中，我们能够在14秒内处理来自FreeBSD系统的79小时的审计数据，主存使用量为84MB。这种性能表示的分析速率比生成数据的速率快2万倍。</strong></p></li>
<li><p>本文的第二个主要贡献是<strong>开发了一种基于标签的方法</strong>，<strong>用以识别最有可能参与攻击的主题、对象和事件</strong>。标签使我们能够确定分析的优先级和重点，从而解决上面提到的第二个挑战。标签编码对数据（即对象）以及过程（主题）的可信度和敏感性进行评估。此评估是基于来自审计日志的数据来源。从这个意义上说，<strong>从审计数据中衍生出的标签类似于粗粒度信息流标签</strong>。我们的分析也可以很自然地支持更细粒度的标记，例如，细粒度的污染标记[42,58]，如果它们可用的话。在第3节中更详细地描述了标签，以及它们在攻击检测中的应用。</p></li>
<li><p>本文的第三个贡献是<strong>开发了利用标签进行根源识别和影响分析的新算法</strong>（第5节）。从图1中所示的攻击检测组件产生的警报开始。我们的反向分析算法遵循图中的依赖关系来识别攻击的来源。从源代码开始，我们使用前向搜索对对手的行动进行全面的影响分析。我们提出了几个标准，以生成一个紧凑的图。我们还给出了一些转换，进一步简化了这个图，并生成了一个图，以一种简洁和语义上有意义的方式直观地捕获攻击，例如，图中的图。
4.实验表明，我们基于标记的方法是非常有效的：例如，侦探可以分析3850万个事件，并生成一个只有130个事件的攻击场景图，代表事件量减少了5个数量级。</p></li>
<li><p>本文的第四个贡献，旨在解决上面提到的最后两个挑战，是一个用于<strong>标记初始化和传播的可定制策略框架</strong>(第4节)。我们的框架提供了合理的默认值，但是可以覆盖它们以适应特定于操作系统或应用程序的行为。这使我们能够调整检测和分析技术，以避免在良性应用程序表现出类似攻击行为的情况下出现误报。(参见第6.6节了解的尾部。)策略还使分析人员能够测试攻击的“备选假设”，方法是重新对认为为可信或敏感的内容进行分类，并重新运行分析。如果分析人员怀疑某些行为是攻击的结果，他们还可以使用策略捕获这些行为，并重新运行分析以发现其原因和影响。由于我们处理和分析审计数据的速度比它生成的速度快数万倍，因此可以有效地、并行地、实时地测试alternate假设。</p></li>
</ul>
<p>本文的最后贡献是一个实验评估（第6节），主要基于由<strong>DARPA组织</strong>的一个红色团队评估，作为其透明计算项目的一部分。在这项评估中，<strong>在Windows、FreeBSD和Linux主机</strong>上进行了类似现代apt的攻击活动。在这项评估中，侦探能够：</p>
<ul>
<li>在几秒钟内处理包含参与期间产生的数千万事件的审计日志；</li>
<li>成功地检测和重建这些攻击的细节，包括它们的入口点、系统中的活动和过滤点；</li>
<li>过滤无关事件，实现数据中非常高的减少率(高达100K次)，从而提供这些攻击的清晰语义表示，其中几乎不包含系统中其他活动的噪声；</li>
<li>并实现较低的假阳性和假阴性率。</li>
</ul>
<p>我们的评估并不是为了表明我们发现了最复杂的对手；相反，我们的观点是，给定几种未知的可能性，我们系统的优先级结果可以实时到位，没有任何人类的帮助。因此，它确实填补了今天存在的一个空白，即法医分析似乎主要是手动启动的。</p>
<h3><span id="二-主内存依赖性图">二、 主内存依赖性图</span></h3>
<p>为了支持快速检测和实时分析，我们将依赖关系存储在图形数据结构中。存储此图的一个可能的选择是图形数据库。然而，诸如Neo4J[4]或Titan[6]等流行数据库的性能[39]在许多图形算法中都是有限的，除非主内存足够大，可以容纳大部分数据。此外，一般图数据库的内存使用太高，适合我们的问题。即使是毒刺[16]和NetworkX[5]，两个为主存性能而优化的图形数据库，每个图边[39]分别使用约250字节和3KB。<strong>在企业网络上报告的审计事件的数量每天很容易达到数十亿到数百亿亿美元之间，这将需要几tb范围内的主内存。相比之下，我们提出了一个更有效的空间依赖图设计，每条边只使用大约10个字节。在一个实验中，我们能够在329mb的主存中存储38m个事件</strong>。</p>
<p><strong>Subjects</strong>：</p>
<ul>
<li>表示进程；</li>
<li>属性值包括：process
id（pid）、命令行、所有者（owner）以及代码和数据的标签</li>
</ul>
<p><strong>Objects</strong>：</p>
<ul>
<li>表示实体，例如文件、pipes、网络连接</li>
<li>属性值包括：名称、类型（文件、pipe、socket等）、所有者和标签</li>
</ul>
<p><strong>事件</strong>：subjects和objects之间或者两个subjects之间带标签的边，用read
、connect、 execveread、connect、execveread、connect、execve来表示。
<strong>事件存储在subjects中</strong>，从而消除了subject-event的指针、事件标识符（event
id）的需求。他们的表示采用<strong>可变长编码</strong>，在通常情况下可以采用4
bytes，当需要时可以扩展到8、12或者16 bytes。</p>
<h3><span id="三-标签和攻击检测">三、 标签和攻击检测</span></h3>
<p>我们使用标签来描述<strong>objects和subjects的可信度和敏感度</strong>。对可信度和敏感度的评估基于以下三个因素：</p>
<ul>
<li><strong>起源（Provenance）</strong>：依赖图中，subject或object直接祖先的标记</li>
<li><strong>系统先验知识</strong>：我们对一些重要应用行为的了解，比如远程接入服务器、软件安装程序和重要的文件（/etc/passwd
和 /dev/audio）</li>
<li><strong>行为</strong>：观察subject的行为，并将其与预期行为进行比较</li>
</ul>
<p>一个默认的策略被用从从input到output传播标签：为output分配input的可信度标签中的最低值，以及机密性标签的最大值（也就是说，入口点的行为是危险的，出口点的行为也被标注为危险；入口点的数据是机密的，出口点的数据也被标注为是机密的）。这是一种保守的策略，该策略可能会导致一些良性事件被错误地识别为恶意事件（over-tainting），但绝不会漏掉攻击。</p>
<p><strong>标签在SLEUTH中扮演了核心角色</strong>。它为攻击检测提供了重要的上下文信息，每个事件都在这些标记组成的上下文中进行解释，以确定其导致攻击的可能性。此外，标签对我们的前向和回溯分析的速度也很有用。最后，标签为消除大量与攻击无关的审计数据也起到了关键作用。</p>
<h4><span id="31-标签设计">3.1 标签设计</span></h4>
<p>如下定义<strong>可信度标签（trustworthiness
tags，t-tags）</strong>，可信度依次降低：</p>
<ul>
<li><p><strong>良性可信标签（Benign authentic
tag）</strong>：为<strong>数据和代码</strong>分配该标签，其来源（source）为<strong>良性</strong>且可靠性<strong>可被验证</strong>的</p></li>
<li><p><strong>良性标签（Benign
tag）</strong>：为<strong>数据和代码</strong>分配该标签，其来源为<strong>良性</strong>，但是来源可靠性<strong>未被充分验证</strong></p></li>
<li><p><strong>未知标签（Unknown
tag）</strong>：为<strong>数据和代码</strong>分配该标签，但是其来源未知</p></li>
</ul>
<p><strong>策略（policy）定义了那些来源是良性的</strong>，哪些来源验证时充分的；策略的最简单情况是白名单。如果对于某个源，没有策略应用在它上面，那么这个源则被打上未知标签。如下定义<strong>机密性标签（confidentiality
tags，c-tags）</strong>，机密性依次降低：</p>
<ul>
<li><strong>Secret</strong>：高度敏感的信息，例如登陆凭证、私钥</li>
<li><strong>Sensitive</strong>：数据的披露可能会对安全产生重大影响，例如，披露了系统中的漏洞，但没有为攻击者提供访问系统的直接途径。</li>
<li><strong>Private</strong>：资料的披露涉及私隐，但未必构成安全威胁。</li>
<li><strong>Public</strong>：可以被公开的数据</li>
</ul>
<p>我们设计的一个重要方面是分离<strong>代码和数据的t-tag</strong>。具体而言，即一个subject给定两个t-tag，一个表示其代码可信度（code
trustworthiness，code t-tag），另一个表示其数据可信度（data
trustworthiness，data
t-tag）。这样的设计可以削减重建场景的规模，加快取证分析的速度。而机密性标签仅仅与数据相关联。</p>
<p>已经存在的objects和subjects使用<strong>标签初始化策略</strong>分配初始标签。在系统执行过程中还会产生新的objects和subjects，它们由<strong>标签传播策略</strong>分配标签。最后，<strong>基于行为的检测策略</strong>来检测攻击。</p>
<h4><span id="32-基于标签的攻击检测">3.2 基于标签的攻击检测</span></h4>
<p>检测方法不应该要求知晓特定应用的一些细节，因为这需要有关应用程序的专家知识，而在动态环境中，<strong>应用程序可能会频繁更新</strong>。</p>
<p>我们不把着眼点放在变化的应用行为上，而是着眼于攻击者的高级别目标，比如后门插入和信息窃取。具体而言，我们结合了攻击者的动机和手段的推理，注意到我们提出的标签就是用来捕获攻击者的手段：如果一段数据或代码有未
知 标 签 未知标签未知标签，那么它就是由不受信任的源产生的。</p>
<p>根据攻击者的攻击步骤，我们<strong>定义</strong>了下面包含<strong>攻击者目标和手段的策略</strong>（Detection
Policy）：</p>
<ul>
<li><p><strong>不受信任的代码执行</strong>：当一个拥有高code
t-tag的subject执行或<strong>加载拥有低t-tag的object</strong>时，便会引发警报</p></li>
<li><p><strong>被拥有低code t-tag的subject修改</strong>：当拥有低code
t-tag的subject修改一个拥有高t-tag的object时，便会引发警报。修改的可能是文件内容或者文件名、文件权限等。</p></li>
<li><p><strong>机密文件泄露</strong>：当不可信的subjects泄漏敏感数据时，将触发警报。具体地说，也就是具有sensitive
c-tag 和 unkonwn code
t-tag的subject在网络中执行写操作时会触发警报。</p></li>
<li><p><strong>为执行准备不可信的数据</strong>：该策略由一个拥有unknown
t-tag的subject的操作触发，该操作使一个object可执行。这样的操作会包含chmod和mprotect</p></li>
</ul>
<blockquote>
<p><strong>一点优势</strong>：值得注意的是，攻击者的手段并不会因为数据或代码经过了多个中间媒介之后而被“稀释”。啥意思呢？举个栗子：对于不受信任的代码执行策略来说，如果直接从未知网站加载数据的话，当然会触发警报。但是，当这些数据是被下载、提取、解压缩，甚至有可能是编译之后再加载的，在经过了重重转化之后，只要数据被加载，该策略仍然能够被触发。随后再进行回溯分析，就可以找到漏洞利用的第一步。</p>
<p>（与其它探测器合作的能力）另外，<strong>其它检测器的输入可以很容易地被集成到SLEUTH中</strong>。比如说，某个外部的检测器将一个subject标为可疑，这个时候再SLEUTH中可以将该subject的code
t-tag标为unknown，从而后面的分析都会受益。此外该操作也会保留图节点之间的依赖关系。</p>
</blockquote>
<p>被不受信的代码执行所触发的策略，不应该被认为工作在静态环境中（需要动态匹配策略），静态环境意味着不允许新代码产生。实际上，我们期望可以连续地更新和升级，但在企业环境中，我们不希望用户下载未知代码。因此，下面会叙述如何支持标准化的软件更新机制。</p>
<h3><span id="四-策略框架">四、策略框架</span></h3>
<p>本文开发了一个灵活的<strong>策略框架（policy
framework）</strong>，用于标签的分配、传播和攻击检测。我们使用<strong>基于规则</strong>的记法来描述策略，例如：</p>
<p><code>exec(s,o):o.ttag&lt;benign→alert("UntrustedExec")</code></p>
<p>这条规则被触发的条件是：当一个subject s 执行了一个object
o(比如文件），而o的t-tag要小于良性。
在该策略框架中，<strong>规则通常与事件关联</strong>，并且包含objects或subjects的<strong>属性的一些条件</strong>，这些属性包括：</p>
<ul>
<li><p><strong>name</strong>：使用Perl正则表达式来匹配<strong>object
name</strong>和<strong>subject命令行</strong></p></li>
<li><p><strong>tags</strong>:
条件中可以放置objects或subjects的t-tags或者c-tags。对于subjects来说，代码和数据的t-tag可以分别使用</p></li>
<li><p><strong>所有权和权限</strong>：条件中可以放置objects和subjects的所有权，或者objects和事件权限</p></li>
</ul>
<p>不同类型的策略有不同的作用：</p>
<ul>
<li>检测策略：引发警报</li>
<li>标签初始化和传播策略：修改标签</li>
</ul>
<p><strong>触发点（trigger
points）</strong>：为了更好地控制不同类型策略的匹配，我们将策略与触发点联系起来。此外，触发点允许有相似目的的不同事件共享策略。</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191554914.png" alt="在这里插入图片描述">
<figcaption aria-hidden="true">在这里插入图片描述</figcaption>
</figure>
<p>上图展示了策略框架中定义的触发点，define表示一个新的object，比如一个新网络连接的建立、首次提及一个已经存在的文件、新文件的创建等。
（检测策略匹配过程）当事件出现时，检测策略就会被执行。后面，除非手动配置，否则仅当<strong>目标subject或object</strong>（某个信息流的终点，Target）发生变化时，检测策略才会被再次执行。</p>
<p>（标签策略）然后，标签策略按照指定的顺序进行尝试，一旦规则匹配，被规则指定的标签将会被分配给<strong>目标事件（Target，也就是subject/object）</strong></p>
<h3><span id="五-基于标签的双向分析">五、基于标签的双向分析</span></h3>
<h4><span id="51-回溯分析">5.1 回溯分析</span></h4>
<p>回溯分析的目标是识别攻击的入口点，入口点是图中入度为0的节点，并且被标记为untrusted。通常是网络连接，但有时也会是其他形式，比如U盘中的文件。</p>
<p><strong>回溯分析的起点是检测策略产生警报的地方</strong>。每个警报都与一个或多个实体相关，这些实体在图中被标记为可疑节点。反向搜索涉及对图的反向遍历，从而识别由可疑节点连接到入口点的路径。我们注意到，在这样的遍历和接下来的讨论中，依赖关系边的方向是相反的。反向搜索带来了几个重大<strong>挑战</strong>:</p>
<ul>
<li><p><strong>性能</strong>：依赖图可能包含数亿条边。警报数可以达到数千。在这么大的图上执行反向搜索，会消耗大量的计算资源。</p></li>
<li><p><strong>多路径</strong>：通常，从可疑节点向后可访问多个入口点。然而，在APT攻击中，通常只有一个真正的入口点。因此，简单的反向搜索可能会导致大量的误报</p></li>
</ul>
<p>标签可以用来解决这两个挑战。一方面，标签的计算和传播本来就是一种简洁的路径计算。另一方面，如果节点的标签值是unknown，那么该节点很有可能会构成攻击路径。如果节点A的标签是unknown，这意味着至少存在一条路径，从不受信任的入口点指向节点A，这样节点A就比其他拥有良性标签的邻居节点更有可能是攻击的一部分。使用标签来进行反向搜索，消除许多无关节点，极大地减少了搜索空间。</p>
<p>基于此，我们将反向分析当作<strong>最短路径问题</strong>的一个实例，<strong>标签</strong>被用来定义边的代价<strong>（cost）</strong>。一方面，标签能够“引导”搜索沿着攻击相关的路径，并远离不相关的路径。这使得搜索可以在不必遍历整个图的情况下完成，从而解决了性能方面的挑战。另一方面，最短路径算法通过选择最接近可疑节点的入口点（以路径成本衡量）来解决多个路径的挑战。
计算最短路径使用<strong>Dijkstra算法</strong>，当入口点被加入到路径中时，算法就停止。</p>
<p><strong>代价函数设计</strong>：对于那些表示节点依赖关系的<strong>边</strong>，如果其标签是<strong>“未知”</strong>，则为其分配<strong>较低的开销</strong>；其它节点分配较高的开胶，<strong>具体地说：</strong></p>
<ul>
<li>从一个“未知”数据/代码 t-tag 的节点，到一个“良性”代码/数据 t-tag
节点的边，为其分配<strong>代价为0</strong></li>
<li>从一个“良性”代码/数据 t-tag
的节点引出的边，为其分配一个<strong>较高的代价</strong></li>
<li>从已有“未知” tag
的节点之间引入边，为其分配<strong>代价为1</strong></li>
</ul>
<p>与未知 subject/object 直接相关的良性 subject/object
表示图中恶意和良性部分之间的边界。因此，它们必须包含在搜索中，因此这些边的代价是0。</p>
<p>良性实体之间的信息流动不是攻击的一部分，因此我们将它们的代价设置得非常高，以便将它们排除在搜索之外。</p>
<p>不可信节点之间的信息流可能是攻击的一部分，因此我们将它们的代价设置为一个较低的值。它们将被包括在搜索结果中，除非由较少边组成的可选路径可用。</p>
<h4><span id="52-向前分析">5.2 向前分析</span></h4>
<p>前向分析的目的是为了评估攻击的影响。通过从一个入口点开始，发现所有依赖于入口点的可能影响。与反向分析类似，主要的挑战是图的大小。一种简单的方法是，标记所有从入口点可到达的
subject/object，这些 subject/object
是通过反向分析得到的。不幸的是，这种方法将导致影响图太大。
在实验中，利用这种方法得到的影响图包含数百万条边，利用我们的简化算法可以降低100到500倍。</p>
<p>一个降低其大小的方法是使用距离阈值dth
，来排除那些距离可疑节点太远的点，分析人员可以调节该阈值。我们使用在回溯分析时使用到的
cost 。</p>
<p>（为什么回溯分析不考虑？？）不同于回溯分析的是，我们考虑机密性。特别的，一条边两端的节点，一个由高机密性标签，另外一个具有低代码
integrity（可信度？？） 标签（如未知进程）或者低数据 integrity
标签（如未知socket），那么为这条边分配代价为0；而当另一个节点由良性标签时，为其分配较高代价值。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/3593RMP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/3593RMP/" class="post-title-link" itemprop="url">高级威胁发现（2）溯源图技术在入侵检测与威胁分析中的应用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-12 10:59:21" itemprop="dateCreated datePublished" datetime="2022-05-12T10:59:21+08:00">2022-05-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-19 15:54:02" itemprop="dateModified" datetime="2023-04-19T15:54:02+08:00">2023-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/" itemprop="url" rel="index"><span itemprop="name">应用场景</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1><span id="溯源图技术在入侵检测与威胁分析中的应用">溯源图技术在入侵检测与威胁分析中的应用</span></h1>
<p>现代信息系统中存在的众多漏洞一直是攻击者进行攻击的“关键”突破点，因此漏洞检测已经成为防守方的一门必修课。但常见的漏洞检测方法中，模糊测试覆盖率不足，基于符号执行程序的验证方法又对检测设备的性能有较高要求，此外漏洞发现后的补洞过程也极为耗时。</p>
<p>入侵检测与威胁分析系统的研发为对抗攻击提供了更直接、更快速的新方法,
能很大程度缓解上述问题。然而，现有的入侵检测系统大多依赖于提取自已有攻击的攻击特征，如<strong>入侵指标（Indicator
of
Compromise，IoC）</strong>等，其作为检测依据并未真正把握到攻击的要点，使得防御者总是落后一步。攻击者总是可以通过找到新的攻击面，构造多阶段多变的复杂攻击来绕此类检测。因此，安全研究人员和从业人员亟需重新考虑传统的入侵检测方案，设计出新一代更加通用和鲁棒的入侵检测机制来检测各种不断变化的入侵方式。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553344.png" alt="图片" style="zoom: 67%;"></p>
<p>David Bianco很早便提出了入侵检测的 “痛苦金字塔模型”(如图1所示)
，研究指出相对于 “Hash 值”、“IP 地址”等底层入侵指标，<strong>“攻击工具”
和 “攻击策略、技术、流程（TTPs）”
等高层特征在入侵检测中有更大的价值</strong>，也更难以分析和改变。这是因为底层的入侵指标的出现更具偶然性，因此攻击者很容易改变这些指标来逃避检测。<strong>此外，无文件攻击和
“Live-off-the-Land”
攻击等攻击技术的出现，使得攻击行为涉及的底层特征与正常行为完全无法区分</strong>。而高层次特征中带有丰富的语义信息（包括攻击的方法、目标、利用的技术等），更具鲁棒性。<strong>对于攻击者而言，攻击策略、技术、流程（TTPs）与其最终的攻击目标直接相关</strong>，很难被真正的改变，因此对入侵检测更有意义。同时，语义信息可以很好的帮助安全分析人员理解攻击，包括入侵的途径、可能的损失等，从而针对性地做出对应的止损和弥补措施。</p>
<h3><span id="一-系统溯源图介绍">一、<strong>系统溯源图介绍</strong></span></h3>
<p>2015
年，<strong>美国国防部高级研究计划署（DARPA）</strong>启动的一项名为
“<strong>透明计算（Transparent Computing）</strong>”
的科研项目为上述问题的解决提供了可能性。该项目旨在通过将目前不透明的计算系统变得透明，辅助海量的系统日志建模，从而为后续的高层次程序行为分析和高效地入侵检测提供支持。具体来说，该项目<strong>将开发一套数据收集与建模系统来记录和建模所有系统和网络实体</strong>（包括<strong>进程、文件、网络端口</strong>等）及其之间的互动和因果关系（Causal
Dependency）。这些实体和关系可以以图的形式表示，如图2所示，一般被称为
“<strong>溯源图（Provenance Graph）</strong>” 或者 “因果图（Causality
Graph）”。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553405.png" alt="图片" style="zoom:67%;"></p>
<p>上图是一个利用Firefox漏洞进行入侵的溯源图例子：</p>
<ul>
<li>攻击者从x.x.x.x:80发起攻击</li>
<li>利用Firefox的漏洞创建并启动了mozillanightly浏览器插件</li>
<li>该插件通过cmd执行环境信息获取命令获取敏感信息后回传到x.x.x.x:443</li>
<li>最后创建burnout.bat清除所有入侵痕迹。（箭头方向代表数据流或者控制流方向）</li>
</ul>
<p><strong><font color="red">
溯源图是一个带有时间信息的有向图，两个节点之间可能有多条不同属性（包括时间和具体操作等）的边。该图准确的记录了系统实体间的交互关系，包含丰富的信息。</font></strong>前文提到的攻击图可以看作溯源图中提取并抽象后的，与攻击直接相关的部分子图。但需要指出的是，溯源图记录的并不是细粒度的数据流和控制流，而是可能的因果控制关系，因此在<strong>进行多跳的分析时会引入错误的依赖</strong>，导致核心的依赖爆炸问题，这也是基于溯源图入侵检测的核心问题。【难点】</p>
<h3><span id="二-基于系统溯源图的入侵检测框架"><strong>二、基于系统溯源图的入侵检测框架</strong></span></h3>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553006.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p><strong>溯源图能很好地还原系统中的各种行为，使其成为了近年来入侵检测领域热门有潜力的研究方向</strong>。安全研究者在其基础上设计了多种模型来进行系统中恶意行为地检测与分析，包括
“数据采集、解析和压缩”，“数据存储与压缩”，和 “入侵检测和溯源分析”
在内的许多具体研究问题。我们整理了威胁分析与检测系统的整体框架，如图3所示。以下，我们将具体讨论框架的三个模块并对其中技术进行分析：</p>
<h4><span id="21-数据收集模块">2.1 <strong>数据收集模块</strong></span></h4>
<p>数据收集是所有检测和分析系统的基础。一般而言，基于溯源图的威胁检测系统会收集<strong>系统日志</strong>作为数据源，包括
<strong>Windows 的内置日志系统 Event Tracing for
Windows（ETW）</strong>、<strong>Linux 的日志系统
Auditd</strong>等。基于依赖分析的方法的一个普遍的挑战是
“依赖爆炸问题”。错误的依赖会导致后续分析的开销与误报指数型增长，导致分析的失败，而细粒度的数据收集可以从根本上缓解这一问题。</p>
<blockquote>
<p>ETW（Event Tracing for
Windows）:https://cloud.tencent.com/developer/article/1020029</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191553107.png" alt="image-20220614224748594" style="zoom: 50%;"></p>
</blockquote>
<h4><span id="22-数据管理模块"><strong>2.2 数据管理模块</strong></span></h4>
<p>系统日志为威胁分析提供了大量有价值的信息，然而其巨大的数据量给数据的<strong>存储和分析</strong>带来了很大的压力。因此在数据管理模块中，我们一方面需要提供<strong><font color="red">
合理的数据存储模型来存储海量的数据并提供高效的查询分析接口</font></strong>，另一方面要尝试通过<strong><font color="red">
压缩和剪枝去除冗余的数据</font></strong>。</p>
<blockquote>
<p><strong>数据存储模型</strong>
利用图结构存储溯源图是一种解决思路，但受溯源图规模限制，将图完全存储在内容内存中是不现实的，只能在小规模的实验中使用，无法大规模部署。因此，研究者们提出了将图中所有边视为数据流，每个边只处理一次，并利用节点上标签记录计算过程的方案。为了加以区分，我们将用图数据存储图的方案称为
“缓存图”，流式处理的方案为“流式图”。流式图方案存在优势的原因在于溯源图中边的数量远远大于节点数量，因此查询节点的属性效率比查询边的效率高得多。类似地，一些研究以节点作为键，边为值，将溯源图存储在查询效率更高的关系型数据库中，我们称之为
“节点数据库”。</p>
</blockquote>
<p>数据压缩算法
溯源图上的数据压缩算法可以大致分为两类：<strong>一类是通用的压缩算法，尽可能地保持了溯源图的信息</strong>；另一类与检测和分析算法耦合，使用有较大的局限性，而本文主要分析前者。</p>
<h4><span id="23-威胁检测与分析模块">2.3 <strong>威胁检测与分析模块</strong></span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191554502.png" alt="图片" style="zoom:60%;"></p>
<p>溯源图提供了丰富的语义信息，支持多种检测分析方案，如表1所示。这些检测方案考虑了不同的攻击模型，针对不同攻击模型提出来不同的检测模型，大致可以分为几类：</p>
<ul>
<li><strong>子图匹配</strong>:
在<strong>溯源图中定位攻击行为抽象出的攻击图</strong>。准确的图匹配的开销过大，因此研究者提出了几种<strong>模糊匹配</strong>方法，包括：<strong>基于威胁情报的图对齐、基于图嵌入的机器学习匹配</strong>等。</li>
<li><strong>节点标签传播计算结</strong>:
并用标签的传递代替复杂的图计算的
“标签传播（TagPropagation）算法”。这类算法一般使用<strong>流式图</strong>作为数据模型，避免了大量的数据读写操作，因此整体效率最高,
但也对检测和分析算法作出了更多的限制。</li>
<li><strong>异常检测模型</strong>:
已有的溯源图上的异常检测模型一般先寻找局部的异常点，并通过依赖分析关联异常点，从而作出全局的判断。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/JFCMNX/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/JFCMNX/" class="post-title-link" itemprop="url">恶意软件检测（1）SeqNet: An Efficient Neural Network for Automatic Malware Detection</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-10 11:04:47" itemprop="dateCreated datePublished" datetime="2022-05-10T11:04:47+08:00">2022-05-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-19 15:47:27" itemprop="dateModified" datetime="2023-04-19T15:47:27+08:00">2023-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/" itemprop="url" rel="index"><span itemprop="name">学术前沿</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>13k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>23 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="seqnetan-efficient-neural-network-for-automatic-malware-detection">SeqNet:
An Efficient Neural Network for Automatic Malware Detection</span></h2>
<ul>
<li>https://github.com/Darren-8/SeqNet.git.</li>
</ul>
<h3><span id="摘要">摘要</span></h3>
<p>恶意软件继续快速发展，每天捕获超过45万个新样本，这使得手动恶意软件分析变得不切实际。然而，现有的深度学习检测模型需要人工特征工程，或者需要很高的计算开销来进行长时间的训练，这可能会很难选择特征空间，并且很难再训练来缓解模型老化。因此，对探测器的一个关键要求是实现自动、高效的检测。在本文中，我们<strong>提出了一种轻量级的恶意软件检测模型SeqNet</strong>，该模型可以在原始二进制文件上以低内存进行高速训练。通过避免上下文混淆和减少语义丢失，SeqNet在将参数数量减少到仅136K时保持了检测精度。在我们的实验中，我们证明了我们的方法的有效性和SeqNet的低训练成本要求。此外，我们还公开了我们的数据集和代码，以促进进一步的学术研究。</p>
<h3><span id="一-说明">一、说明</span></h3>
<p>恶意软件是一种严重的网络安全威胁，可能会对个人和公司系统造成严重损害，例如，急剧减速或崩溃、严重数据丢失或泄漏，以及灾难性的硬件故障。<strong>AVTest报告称，平均每天检测到超过45万个新的恶意程序和可能不需要的应用程序</strong>。[1].
大量新的恶意软件变体使得手动恶意软件分析效率低下且耗时。为了更有效地检测恶意软件，许多研究人员提出了用于恶意软件分析和检测的高级工具[2,5,9,14]。这些工具通过对分析员的行为进行部分工作，帮助他们更高效地完成任务。然而，在处理如此大量的恶意软件时，这些解决方案无法从根本上减少工作量。为了解决这个问题，许多专家和学者将机器学习算法，尤其是深度学习应用于恶意软件检测和分类[7,12,15,16,18,22,26,28,34,37,45,50,51,53,55,58-60,62,63]。他们的努力为恶意软件分析神经网络的研究和实用的恶意软件自动检测做出了很大贡献。</p>
<p>然而，这些模型通常需要各种特征工程来帮助神经网络做出判断，这可能很费劲，并且容易丢失一些关键信息。为了实现更加友好和自动的检测，提出了基于二进制的方法[31,37,41,42]。两种流行的原始二进制处理方法是文件剪切和二进制图像转换。然而，这两种方法可能会遇到<strong>语境混乱和语义丢失</strong>，这将在后面讨论。</p>
<p><strong>此外，模型老化是神经网络的一个关键问题</strong>[25,40]。与计算机视觉和自然语言处理不同，恶意软件正在不断快速发展。恶意软件检测是攻击者和检测器之间的斗争。随着恶意软件的不断发展，深度学习模型可能已经过时。例如，五年前训练的模型在今天的恶意软件检测中可能非常薄弱。神经网络很难识别看不见的恶意行为，这可能会导致较低的检测精度和更容易的规避。模型不可能预测未来恶意软件的特征，但快速学习检测新恶意软件的知识是可行的。因此，再培训模式成为缓解老龄化问题的少数方法之一。我们可以让神经网络快速重新训练，学习新恶意软件的新特征，以便识别新的攻击方法。</p>
<p><strong>由于模型的结构和规模，再培训可能会耗费时间和计算量，而且如此高的成本可能会导致模型更新困难</strong>。此外，恶意软件检测是几乎所有电子系统中的常见操作，对于计算能力较低的设备来说，进行检测是必要的。例如，笔记本电脑或其他移动设备很难运行一个庞大的模型来扫描所有文件以检测恶意软件。这些要求表明，检测模型应该足够小和有效，使其更实用，以便我们能够快速重新培训或执行检测。此外，无需复杂特征工程的自动检测对于各种场景中使用的模型至关重要。</p>
<p>总的来说，我们的工作面临两个挑战：<strong>自动化和高效</strong>。检测模型应该足够自动化，并且几乎不需要人工特征工程。该模型的规模应足够小，以降低训练和检测成本。</p>
<p>在本文中，我们提出了一个有效的恶意软件自动检测模型，该模型只有大约136K个参数，我们称之为SeqNet。在没有人工特征选择的情况下，SeqNet可以仅基于原始二进制文件自动分析样本并找出恶意程序和良性程序之间的差异。较小的神经网络通常具有较少的参数，这可能会导致较低的学习能力。这可能是因为较小的模型往往更难适应从原始二进制文件到恶意域的复杂映射。这个问题可能会导致小型深度学习模型中恶意软件检测的准确性较低。</p>
<p>为了在减少参数数量时保持准确性，我们<strong>提出了一种新的二进制代码表示方法</strong>，以减少语义损失并避免上下文混淆。根据我们的方法，我们使SeqNet在无需特征工程的情况下，在可移植可执行（PE）恶意软件检测方面表现良好。基于这种表示方法，我们创建了一种新的卷积方法，称为<strong>序列深度可分离卷积（SDSC）</strong>，以进一步压缩检测模型的规模。我们在一个大型PE数据集上对SeqNet进行训练，发现与许多现有的基于二进制的方法和模型相比，它具有很好的性能。我们还在进一步的实验中证明了我们的模型收缩方法的有效性。此外，我们还公开了我们的代码和数据集以供进一步研究，我们希望深度学习算法能够更好地应用于恶意软件检测。</p>
<p>我们在一个大型PE数据集上对SeqNet进行训练，发现与许多现有的基于二进制的方法和模型相比，它具有很好的性能。我们还在进一步的实验中证明了我们的模型收缩方法的有效性。此外，我们还公开了我们的代码和数据集以供进一步研究，我们希望深度学习算法能够更好地应用于恶意软件检测。</p>
<h4><span id="本文的主要贡献包括">本文的主要贡献包括：</span></h4>
<ul>
<li>我们提出了一种<strong>新的方法来表示二进制代码</strong>，同时减少语义损失，避免上下文混淆。</li>
<li>基于上述新的表示方法，我们提出了一种<strong>新的卷积压缩恶意软件检测模型的方法SDSC</strong>。</li>
<li>我们<strong>设计了一个深度卷积神经网络（CNN），称为SeqNet</strong>，它具有更小的规模和更短的训练过程。</li>
<li>我们将数据集和代码公开以供进一步研究。</li>
</ul>
<p>这是本文的布局。第2节介绍了深层恶意软件检测的主要方法和几个问题。第3节描述了我们应用于SeqNet的主要方法。第四部分阐述了我们的实验和相应的结果。</p>
<h3><span id="二-背景">二、背景</span></h3>
<p>在本节中，我们将介绍使用深度学习进行恶意软件检测的背景。首先，我们列举了这方面的两种主要方法。然后进一步讨论了目前流行的二进制表示方法的几个问题。最后，我们解释了其中一种方法所基于的深度可分离卷积。</p>
<h4><span id="21-深度恶意软件检测">2.1 深度恶意软件检测</span></h4>
<p>神经网络具有强大的学习能力，在计算机视觉和自然语言处理中得到了广泛的应用。深度学习算法已经被许多研究人员应用于恶意软件检测。据我们所知，我们认为有两种主流思想，类似于[47]。</p>
<p><strong>基于特征的方法</strong>。在早期作品中，深度学习模型是从精心制作的恶意软件功能中训练出来的[7、15、16、18、26、28、34、58、63]。在检查可疑样本时，模型需要提取特定特征，以特定方式处理它们，然后检测恶意代码以给出结果。所选功能可以是API调用、控制流图（CFG）或任何其他能够反映程序操作的信息。的确，人工特征学习是神经网络识别恶意样本和良性样本之间主要差异的有效方法。然而，特定的领域特征只能从一个角度很好地描述样本的关键信息。它不能完全覆盖二进制代码的语义，甚至会引发严重的信息丢失。例如，仅使用API调用作为特性会导致模型忽略控制流。此外，精心设计的功能需要足够的先验知识，这需要专家仔细选择。因此，耗时的手动特征提取可能会限制基于特征的模型的使用，并使其难以对抗恶意软件的持续演化。</p>
<p><strong>基于二进制的方法</strong>。与传统的特征工程相比，自动特征提取是神经网络的发展趋势之一，人工干预更少，性能更好。我们读取文件的二进制文件，直接将其发送到检测模型，无需或几乎不需要预处理。该模型将自动找到可疑部分，并将二进制文件识别为恶意或良性。这种方法可以更有效地避免人们分析恶意软件的需要，并更好地减少分析人员的工作量。<strong>此外，通过减少手动特征工程造成的损失，直接从原始二进制文件学习可能会更好地保留语义和上下文信息。</strong></p>
<p>为了使我们的模型更加自动化，避免信息丢失，<strong>我们将重点放在基于二进制的模型上</strong>，SeqNet将原始二进制文件用作输入。此外，较低的计算开销可以使模型更好地适应恶意软件的演变，并扩展应用场景，例如在物联网环境中。我们将一种新颖但简单的二进制代码表示方法应用于SeqNet，并在减少参数时保持其性能。</p>
<h4><span id="22-二进制代码表示法">2.2 二进制代码表示法</span></h4>
<p>在这一部分中，我们将介绍几种主要的二进制代码表示方法，它们适用于基于二进制的模型。将样本转换为神经网络的输入会显著影响模型的性能。因此，<strong>正确的二进制代码表示方法是基于二进制的恶意软件检测神经网络的重要组成部分</strong>。目前，人们提出了两种主要的方法来完全表示原始二进制码。</p>
<p><strong>文件剪切</strong>。<strong>由于内存限制的限制，许多作品对最大文件大小设置了人为限制，这种方法是从二进制程序的开头提取一段固定长度的代码片段</strong>。如果二进制程序的长度小于所需代码段的长度，则该代码段的末尾将填充零。文件剪切会导致语义信息丢失，因为如果二进制文件的结尾比固定长度长得多，就会忽略它。然而，恶意代码通常位于二进制文件的末尾。例如，嵌入的病毒通常嵌入在受感染文件的尾部，这可能有助于它们逃避基于这种方法的模型的检测。<strong>为了缓解这个问题，Mal-ConvGCT[42]通过扩展代码段大小限制来提高MalConv[41]的性能。</strong></p>
<p><strong>二值图像转换</strong>。第二种方法将所有二进制代码转换为图像，并利用图像分类解决方案执行恶意软件检测。所有<strong>图像都可以使用双线性插值算法重新采样到相同的大小</strong>。然而，图像与序列不同，这可能会导致几个问题。我们认为这种方法会导致上下文信息混乱，下面列举了三个例子。</p>
<ul>
<li><strong>边缘丢失</strong>：如果二进制指令位于图像边缘，换行符可能会将指令分成两部分，如图1（a）所示。此问题可能会导致模型难以识别多条长指令。此外，由于<strong>强相关指令的中断，上下文信息可能在边缘被破坏</strong>。</li>
<li><strong>重采样噪声</strong>：如果我们重塑图像大小，不同行中不相关的指令会导致上下文信息混淆，如图1（b）所示。这个问题很容易使原始序列中的指令彼此相距很远，而被迫集成到相应的图像中，这可能会混淆神经网络。</li>
<li><strong>填充问题</strong>：填充操作可能会使模型难以识别原始序列的开始和结束，如图1（c）所示。为了确保卷积层输入和输出的一致性，我们通常在输入的边缘填充一些零，神经网络可能会根据填充得到空间信息[27]。与图像处理不同，识别出的空间信息可能会误导模型。</li>
</ul>
<p><strong>文件剪切导致的语义丢失</strong>和<strong>二值图像转换导致的上下文混乱</strong>阻碍了恶意软件检测模型的性能。这些问题可能会混淆神经网络，甚至误导它们做出截然相反的决定。通过缓解这些问题，我们可以帮助我们的模型在减少参数时保持其性能。</p>
<h4><span id="23-卷积法">2.3 卷积法</span></h4>
<p>传统的卷积算法模拟动物视觉，在计算机视觉中具有很好的性能。这个简单的操作可以有效地提取图像中的视觉特征。低级卷积层检测图像中的纹理和简单特征，高级卷积层可以识别内容和整体语义[61]。这就是为什么计算机可以通过多个卷积层的叠加来识别复杂的物体。</p>
<p>然而，传统卷积所需的参数数量往往使得深度学习模型太大，无法应用于计算能力较低的设备。此外，参数过多的模型可能需要很长的训练过程。例如，VGG有超过1.3亿个参数，已经接受了2年的培训 
3周[49]。如此庞大的模型不适合在普通设备上运行。</p>
<p>因此，我们将CNN架构应用于SeqNet，并将DSC的输入形式从2D调整为1D，从而更好地减少了训练参数的数量。因此，训练时间成本和新生成的模型的大小都进一步减小。我们的方法的细节在第3节中描述。</p>
<h3><span id="三-方法">三、 方法</span></h3>
<p>在本节中，我们将介绍SeqNet的详细信息。首先，我们概述了我们的方法。其次，我们引入了可以减少语义损失和避免语境混淆的序列表征。第三部分描述了SDSC如何压缩模型的规模。最后，我们详细介绍了SeqNet的体系结构。</p>
<h4><span id="31概述">3.1概述</span></h4>
<p>SeqNet的目标是以较低的培训成本实现高效、自动的恶意软件检测。在整个培训和检测过程中，操作员不需要专业的恶意软件分析知识来执行手动领域特定的功能工程。实际上，我们直接将原始二进制文件输入SeqNet，SeqNet将自动分析序列并提取特征。SeqNet的输出是可疑样本的恶意可能性，输入样本是否为恶意软件取决于模型给出的可能性。</p>
<p>准确检测是恶意软件检测模型的基本要求。我们认为恶意软件检测不同于图像分类。恶意软件检测可能需要更多地关注几个<strong>关键的恶意代码</strong>，而图像分类可能更关注整体。根据这一理论，我们对SeqNet的主要设计要点之一是减少上下文混淆和语义丢失。我们使用<strong>原始二进制序列作为SeqNet的输入</strong>，这样可以避免上下文混淆，减少语义损失。</p>
<p>轻量级模型通常具有更广泛的应用场景和更快的检测性能。显然，小型模型的培训成本也很低。因此，压缩SeqNet的规模是必要的。新的卷积方法，称为序列深度可分离卷积（SDSC），有助于SeqNet满足这一要求。</p>
<h4><span id="32-序列表征">3.2 序列表征</span></h4>
<p>输入格式对神经网络性能和模型大小至关重要。较大的输入往往导致较大的模型，适当的输入格式可以有效地提高神经网络的学习效果。SeqNet的输入是原始二进制序列，这些序列通过线性插值算法调整到相同的长度。原始二进制序列输入几乎不需要人工干预。在不转换为图像的情况下，很明显，我们可以避免上下文信息混淆，减少语义损失，如图所示</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182201637.png" alt="image-20220510151305157">
<figcaption aria-hidden="true">image-20220510151305157</figcaption>
</figure>
<blockquote>
<p>一个例子表明，序列表征可以解决上下文混淆和语义丢失的问题。在图像中，二进制指令“BF
01
00”在边缘被切断，但它仍保留序列中的形状。插值后，我们可以看到，图像强制加强了“56”与“00”之间的关系，其中“56”表示“推esi”，而“00”在“0F
85 93 00 00 00 00 00”中表示“jnz loc
1000DF90”，但它忽略了具有更强关系的指令，例如“推edi”和“mov
edi，1”。在序列中，指令“56”与前端结合，而不是“00”，并且在物理上与“57”保持接近，后者表示“推edi”。在图像中，输入到卷积层之前添加的填充提供了不正确的位置信息，但在序列中，它标记了开始和结束。</p>
</blockquote>
<ul>
<li><strong>避免边缘丢失</strong>。由于序列只有两条边，即开始和结束，因此可以避免边缘丢失。序列格式符合代码的空间结构，因此任何指令都没有中断，这使得所有指令在输入模型时都完好无损。中断的消失也有效地保护了原始二进制序列的语义，因为相邻的指令是不分离的。</li>
<li><strong>重采样降噪</strong>。当我们调整序列的大小时，元素只会受到前向和后向上下文的影响，因此重采样噪声可以减少。此外，图像中两条无关指令之间的强制关系消失。通过使用序列特征，远程指令不能相互影响，这使得模型能够更清楚地识别指令之间的关系。此外，通过使用线性插值算法，我们可以确保输入序列的长度是相同的。</li>
<li><strong>避免问题</strong>。填充问题可以解决，因为在卷积之前，我们只需要在序列的两端填充。此外，与向图像中添加不正确的信息相比，序列中的填充将有效地标记相应程序的开始和结束。因此，该模型可以根据填充来识别指令的正确位置。</li>
<li><strong>语义损失减少</strong>。由于我们输入的是整个二进制文件，而不仅仅是一个片段，因此语义损失可能会减少。通过线性插值算法，我们可以压缩语义，而不是忽略它。在这种情况下，嵌入式病毒也可能包括在内，因为程序中的所有指令都被输入到模型中。</li>
</ul>
<p>在缩放到相同的长度之前，我们首先规范化整个序列，使元素的值介于-1和1之间，并以浮点格式存储。由于实数字段的连续性，浮点格式可以比整数格式代表更多的信息。因此，这个操作对于减少线性插值算法造成的语义损失是必要的，如图4所示。通过对数据集进行统计，<strong>我们发现大多数文件的大小约为256KB。因此，我们将所有输入序列扩展到2^18字节。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191547964.png" alt="image-20220510152040055" style="zoom:50%;"></p>
<blockquote>
<p>图4：如果我们在规范化之前调整序列的大小，结果不能代表原始二进制代码（a）中的所有信息。<strong>相反，如果我们在规范化后调整以浮点格式存储的序列的大小，我们可以有效地减少语义损失</strong>（b）。</p>
</blockquote>
<p>在序列格式中，指令之间的所有信息都将得到正确和更好的保留。两条指令之间的物理距离反映了关系的真实强度。这种表示方法还利用了代码中的空间局部性，因为模型将更多地关注附近的指令，而不是那些相关性较弱的指令。因此，该模型在学习和检测时接收到的干扰较小。</p>
<p><strong>使用序列特征而不是二进制图像转换的另一个原因是，可执行文件的前后相关性比平面相关性更明显。这就是为什么序列可以更好地代表程序。</strong></p>
<h4><span id="33-序列深度可分离卷积">3.3 序列深度可分离卷积</span></h4>
<p><strong>序列输入格式不仅解决了语义丢失和上下文混淆的问题，还压缩了SeqNet的规模</strong>。SeqNet的卷积核只需要在只有一维的序列上提取特征。与处理一维输入相比，提取二维特征需要更大的卷积核和更多的计算。例如，如图2（c）所示，a
3 3用于图像的内核至少需要10个参数（包括偏差），而3 1序列中使用的内核只需要至少四个参数（包括偏差）。</p>
<p><strong>基于序列输入和深度可分离卷积</strong>[21]，我们提出了一种称为序列深度可分离卷积（SDSC）的方法，它需要更少的参数和更少的计算。在SDSC中，我们使用3 1个内核替换DSC中的2D深度卷积内核。通过使用SDSC层，SeqNet的尺寸比现有模型小得多。<strong>在下文中，我们分析了与DSC相比计算量的减少</strong>。</p>
<p>此外，SDSC的输入是一维数据，因此与DSC相比，它不太容易受到无关指令的影响。在实验中，我们发现SDSC具有良好的性能，并成功地保持了SeqNet的性能。基于SDSC，我们在SeqNet中使用了以下两种主要的卷积块架构。</p>
<ul>
<li><strong>标准SDSC块</strong>。如图5（a）所示，标准SDSC块由三部分组成。我们使用批量归一化层[23]来帮助模型更好地了解训练样本的概率分布。ReLU[38]激活函数可以通过使模型快速收敛来加速训练过程</li>
<li><strong>残差SDSC块</strong>。如图5（b）所示，剩余SDSC块结合了ResNet[19]中使用的方法。通过跳过SDSC块，我们可以有效地防止梯度消失，并构建更深层的架构。</li>
</ul>
<h4><span id="34-模型架构">3.4 模型架构</span></h4>
<p>SeqNet的构建主要基于SDSC，图6解释了该架构。为了减少参数的数量，我们使用<strong>更小的核和更深的结构</strong>，这也可以扩大感受野。标准SDSC块用于在对序列进行下采样时提取特征。对于第一个卷积层，我们使用单个公共卷积层嵌入原始输入，内核大小为3*1.我们<strong>设置大小是因为经常使用的CPU指令的长度通常是三个字节</strong>。对于高层特征，我们使用五个剩余的SDSC块进行分析，与完全连接的层相比，这也可以更好地保留上下文和空间信息。此外，<strong>残差SDSC块可以防止梯度消失，使模型快速收敛</strong>。最后两层是完全连接层和softmax层。全连通层用于对模型前端给出的分析结果进行分类。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191547603.png" alt="image-20220510152817964" style="zoom:50%;"></p>
<p>在这个公式中，P表示转换后的结果，x表示softmax层的输入。对于池层，我们使用平均池。<strong>在我们的实验中，我们发现当剩余SDSC块的数量为5个，输入128个通道，并且完全连接的层的数量仅为1个时，该模型的性能最好</strong>。SeqNet输出样本的恶意可能性，如果可能性超过50%，模型将视其为恶意软件。根据输出，对于损失函数，我们使用交叉熵函数。SeqNet总共只有大约136K个参数，几乎是MalConv的十分之一，我们将在第4节中讨论。</p>
<h3><span id="四-实验">四、实验</span></h3>
<h4><span id="41培训数据集">4.1培训数据集</span></h4>
<p>建立良好的培训数据集对于评估SeqNet的性能至关重要。正确的标签和足够的样本是展示SeqNet学习能力的必要条件。对于样本类型，我们认为PE恶意软件是电子系统的主要威胁之一。此外，有很多PE恶意样本，很容易获得足够的PE样本。</p>
<p>因此，以下实验适用于一组PE文件，因为它们很普遍。在这项工作中，所有恶意样本都来自VirusShare[4]。<strong>齐安信公司提供了约10000份良性样本。我们还从真实的个人电脑中收集了许多良性样本，以模拟我们日常生活中的真实环境。为了确保良性样本中没有混合病毒，我们使用VirusTotal[6]检测所有文件。如果在VirusTotal报告中没有AV引擎将其视为恶意软件，我们将其视为良性样本。操作系统文件和恶意软件通常具有类似的行为，这可能会混淆检测模型，甚至会混淆训练有素的分析师[8]</strong>。因此，为了帮助SeqNet观察恶意程序和良性程序之间的一般差异，并使SeqNet更加健壮，<strong>我们添加了大约10000个系统文件作为良性数据。</strong>VirusTotal[6]也会检查系统文件，以确保它们是良性的。我们总共获得了72329个二进制文件的训练数据集，其中37501个恶意文件和34828个良性文件，以及24110个二进制文件的验证数据集，其中12501个恶意文件和11609个良性文件。</p>
<p>数据集中的所有文件都是PE文件，我们<strong>通过比较SHA256值来消除重复</strong>。我们将恶意和良性样本的比例设置为1左右，以确保结果可靠。例如，如果数据集只有恶意样本，模型可能会通过识别“4D
5A”来检测所有恶意软件。相反，如果我们向数据集中添加足够多的良性样本，模型就可以了解恶意样本和良性样本之间的真正区别。</p>
<h4><span id="42-测量">4.2 测量</span></h4>
<p>在我们的实验中，我们从训练成本和准确性两个方面测量SeqNet。对于培训成本测量，我们使用参数的数量来表示模型的规模。更大的模型包含更多的神经元，需要更多的参数来构建。在训练和预测过程中，每个参数都会占用恒定的内存。因此，参数的数量显著影响模型训练和预测所需的记忆。为了准确测量模型推理的计算开销，我们通过输入一个随机二进制来计算每个模型上的浮点运算（Flops）。我们还通过记录一个历元所需的时间来测量模型的速度，包括训练和验证过程。</p>
<h4><span id="43-培训">4.3 培训</span></h4>
<p>设置模型和培训设置会显著影响培训过程和结果。所有模型都经过70个阶段的训练，我们选择了过去30个阶段的验证结果，以获得平均精度和其他指标。<strong>我们将批量大小设置为32，并选择Adam[29]作为所有模型的优化器。为了保证训练的公平性，我们将交叉熵损失应用于所有模型。</strong></p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191547084.png" alt="image-20220510153236041" style="zoom:50%;"></p>
<h4><span id="44-模型评估">4.4 模型评估</span></h4>
<p>我们选择几种最先进的基于二进制的方法作为基线。<strong>为了反映基于图像转换的模型的总体性能，我们选择著名的MobileNet[21]作为代表性模型</strong>。我们将程序转换为RGB图像作为MobileNet的输入。在转换过程中，一个字节映射一个通道中的一个像素。<strong>对于基于文件剪切的模型，我们选择MalConv[41]和MalConvGCT[42]</strong>。<strong>ResNet和MobileNet都是由Pytorh[39]实现的，我们使用ResNet18作为ResNet，而MobileNet
v2作为MobileNet</strong>。我们使用MalConv和MalConvGCT作者提供的源代码，并将它们应用到我们的实验中。我们在每个模型的末尾添加一个softmax层，以便在验证时将结果转换为可能性格式。根据表1中的参数数量，我们可以发现SeqNet的最小参数仅为MalConv和Mal-ConvGCT的十分之一。此外，SeqNet在恶意软件检测方面保持了良好的性能。图7是精度和模型尺寸对比图，左上角的模型位置表明模型尺寸较小，精度较高。</p>
<p>精度还表明，SeqNet误解良性样本的可能性很低。此次召回意味着SeqNet可能有能力防止逃税。在训练过程中，我们发现大多数模型在第一个历元后达到90%的准确率。在我们的训练中，我们发现SeqNet只需要大约两分钟半就可以完成一个历元，而Mal-Conv大约需要一个小时。因此，我们可以看到，SeqNet的微小尺寸导致了较低的计算开销，基于卷积的体系结构加速了训练和推理。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191547005.png" alt="image-20220510153439695" style="zoom:50%;"></p>
<h4><span id="45-进一步评估和消融研究">4.5 进一步评估和消融研究</span></h4>
<p>接下来，我们将描述进一步的实验，以讨论SeqNet中的上下文混淆避免、模型收缩和架构设计。我们对SeqNet进行了几个简单的更改，以测试我们的假设。</p>
<ul>
<li><strong>语境混乱</strong>。为了证明上下文混淆的存在，我们将SeqNet更改为SeqNet2D，可以输入512
* 512张图片。我们将图像大小设置为512 *
512，因为它可以提供与序列相同的信息量。<strong>SeqNet2D使用深度可分离卷积层的架构与SeqNet非常相似</strong>。表2确保了图像转换方法会导致混淆，在从程序学习功能时可能会混淆网络。MobileNet使用图像作为输入，因此表1还通过SeqNet和ResNet之间的比较反映了上下文混淆的存在。</li>
<li><strong>模型收缩</strong>。SDSC层通过降低输入维数和分解卷积来减少参数量。我们用SeqNet中的公共卷积层替换所有SDSC层，并将新模型命名为SeqNetConv，以反映因子分解卷积的效果。为了验证尺寸减小在模型收缩中的作用，我们使用SeqNet2D作为实验对象。我们还将公共卷积层应用于SeqNet2D，并调用新模型SeqNet2DConv来展示这两种方法的缩减效果。如表2所示，我们可以看到维数的有效降低减少了参数的数量，卷积分解进一步减少。通过结果可以看出，SDSC层在保持性能的情况下有效地缩小了模型。我们还发现，参数越少，模型在训练时收敛速度越快。</li>
<li><strong>结构设计</strong>。在我们的实验中，我们还发现，更深层次的结构可能不会表现得更好。我们调整SeqNet的深度。具有更深层次架构的模型称为SeqNetDeep，而更浅层次的架构称为SeqNetShal。与我们的直觉类似，较浅的体系结构会显著降低模型的性能。然而，表2中的结果表明，更深层次的体系结构并不能明显提高性能，而是扩大了模型的规模。<strong>我们假设这种现象可能是因为从二进制到恶意软件的简单映射关系，而不需要复杂的神经网络来拟合。</strong>另一个可能的原因是，更深层次的结构使网络难以训练，这可能会导致精确度较低。我们发现的另一个现象是，扩张卷积不能有效地提高性能。我们认为这是因为与输入的长度相比，使用或不使用扩张卷积对模型的感受野没有太大影响。</li>
</ul>
<h4><span id="46-稳健性评估">4.6 稳健性评估</span></h4>
<p>我们还检查了SeqNet的健壮性，并将其与MalConv进行了比较。关于攻击深度模型有大量的研究[24,32,36,44,48,54,56]。<strong>然而，与针对图像相关任务的神经网络的传统攻击不同，我们不能直接在二进制文件上添加扰动，因为这可能会使二进制文件不可执行</strong>。此外，我们很难根据提取的特征[47]调整攻击策略以适应原始的二进制模型。因此，对于攻击策略，我们采用[30]中的方法，在输入端的填充部分注入一个短的有毒二进制文件。</p>
<p>由于Mal-Conv和SeqNet之间的输入格式不同，我们等效地采用了有毒二进制生成方法。与沿梯度选择最近的嵌入向量相比，SeqNet的毒药生成过程如下所示。</p>
<p>为了使攻击策略在有限的二进制长度下有效，我们从验证恶意数据集中随机选择了500个可用样本。我们将毒药的长度设置为32000字节，MalConv的整个二进制文件固定为16000000字节，并逐步增加毒药生成迭代次数。我们测试了SeqNet和MalConv错误分类的样本数量。结果如图9所示。我们看到SeqNet对有毒二进制攻击有很强的防御能力。我们假设这种现象是由于文件剪切方法中的填充部分造成的漏洞。<strong>基于文件剪切的模型在训练时经常会看到不完整的二进制文件。</strong>因此，文件剪切中的填充使攻击者有机会混淆模型，而模型不确定有毒二进制文件是否是样本的一部分。与文件剪切相比，我们的方法可以通过输入整个二进制文件来缓解这个问题。然而，我们认为这一理论仍需进一步验证，我们可能会在未来的工作中对其进行研究。</p>
<h4><span id="47-案例研究">4.7 案例研究</span></h4>
<p>为了更好地理解SeqNet所学到的知识，我们随机选择了四个样本，并使用Grad
<strong>CAM</strong>[46]解释技术生成热图，以便我们能够可视化哪个部分对结果影响最大。此外，我们还手动分析相应的样本，以验证SeqNet是否找到了正确的恶意代码。在手动分析中，我们通过IDA
Pro[3]分解样本，精确定位恶意功能或代码。为了更好地绘制结果，我们提取了热图的关键部分，并对片段应用以下归一化公式。</p>
<p>其中X表示代码段。用于热图的激活图是由SeqNet的最后一个卷积层和ReLU层生成的，因为剩余的空间信息由卷积层编码。我们还在原始二进制文件上标记手动定位结果，以便更好地进行比较。图10显示了手动定位和基于梯度凸轮的解释之间的比较。我们看到，本地激活位置与分析人员定位的恶意部件接近，这反映了SeqNet可能会发现恶意代码并进行可靠的检测。在我们的解释中，我们发现在整个热图中有许多噪音。我们认为这可能是因为数据集中可能存在潜在的异常统计[10]和一些错误标签[43]。然而，遗憾的是，由于学术界对良性档案的忽视，我们很难收集到更多的良性样本。我们希望在未来的工作中能够探索这一现象。此外，我们还发现PE头通常会对SeqNet产生很大影响。这可能意味着PE头包含恶意软件中的恶意信息。更多细节见附录。</p>
<h3><span id="5讨论">5.讨论</span></h3>
<p>在这一部分中，我们将讨论我们的工作的局限性，并提出一些未来需要进一步研究的工作。</p>
<h4><span id="51局限性">5.1局限性</span></h4>
<p>尽管SeqNet表现良好，但我们的工作仍有一些局限性。仍然是<strong>语义缺失</strong>。虽然我们有效地减少了语义损失，但SeqNet的输入仍然不能包含所有语义。如果序列太长，在插值过程中会对序列进行压缩，压缩后的序列不能代表所有原始信息。此外，如果序列太短，序列将被扩展，这可能会混淆SeqNet。SeqNet的体系结构决定了输入必须具有相同的大小，这是SeqNet的一个限制。</p>
<p><strong>缺乏良性样本</strong>。我们面临的主要困难是缺乏良性样本。我们可以获得大量恶意软件收集网站，但很难找到权威的良性样本提供商。为了均匀采样，仅通过添加恶意样本来扩展训练数据集是不合适的，这可能会降低SeqNet的性能，并使实验结果不可靠。因此，很难在具有足够样本的更大数据集上训练神经网络。</p>
<p><strong>标签的质量</strong>。除了缺乏良性样本，标签的质量可能是一个潜在问题。由于权威供应商寥寥无几，我们无法保证培训和验证数据集中的所有良性样本都正确标记。我们数据集中的所有恶意样本都是从VirusShare收集的，无需人工确认。几家报纸检查了恶意软件标签的质量，发现它可能达不到我们的预期[43]。虽然这些限制可能会对SeqNet的训练过程产生一些影响，但我们假设，几个不正确的标记样本不会显著影响整体性能。</p>
<p><strong>可能存在的漏洞</strong>。对抗性攻击是大多数神经网络的风险，我们也不例外。有动机的对手可能会污染训练数据集，并逃避SeqNet的检测。<strong>此外，基于梯度的攻击是混淆深度学习模型的有效方法[17,30,32]。相反，这个问题也有很多解决方案[7,12,20,33,57]。</strong>虽然SeqNet可以抵御多次攻击，但我们仍然无法完全保证SeqNet的安全。此外，SeqNet的健壮性原则需要我们进一步探索。</p>
<h4><span id="52-未来工作">5.2 未来工作</span></h4>
<p>我们提出了一种高效的恶意软件自动检测神经网络SeqNet。SeqNet的主要目标是实现自动、高效的检测，可以以较低的原始二进制文件培训成本快速进行培训。尽管如此，未来仍有许多工作需要完成。基于深度学习的恶意软件检测研究的最大障碍之一是<strong>缺乏工业规模的公共可用数据集</strong>。研究人员需要权威可靠的数据集，这些数据集不仅包含恶意特征，还包含原始二进制序列。我们将建立一个更大的数据集，以进一步评估SeqNet的性能。此外，还需要足够的良性样本进行进一步研究。<strong>我们认为，当使用深度学习模型进行检测时，恶意软件分析不仅应该关注恶意样本，还应该关注良性样本</strong>。由于神经网络是黑盒模型，恶意软件检测神经网络的可靠性可能会受到怀疑。虽然SeqNet给了我们很好的结果，但我们仍然无法完全解释原因。因此，在实践中使用深度学习算法检测恶意软件仍需进一步研究。通过我们的实验，<strong>我们认为神经网络在恶意软件检测方面可能具有巨大的潜力</strong>，我们期待着神经网络在这一领域取得重大突破。SeqNet的健壮性仍需进一步研究。我们仍然缺乏这方面的实验和研究。在未来的工作中，我们将更深入地探索该模型的稳健性，并对其进行更多的改进和分析。</p>
<blockquote>
<p>基于二进制的模型。与传统的特征工程相比，自动特征提取是神经网络的发展趋势之一，人工干预更少，性能更好。Raff等人设计了一种称为MalConv的架构，它可以直接从原始PE二进制样本中学习，而无需手动选择特征[41,42]。Krc al等人设计了一个简单的CNN，可以从PE原始字节序列中学习，而无需特定领域的特征选择，这项工作获得了较高的AUC分数，尤其是在小型PE恶意软件样本上[31]。</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/7C1A6K/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/7C1A6K/" class="post-title-link" itemprop="url">文本分类（1）搜狐文本情感分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-09 12:46:40" itemprop="dateCreated datePublished" datetime="2022-05-09T12:46:40+08:00">2022-05-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-18 20:41:07" itemprop="dateModified" datetime="2023-04-18T20:41:07+08:00">2023-04-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E7%AE%97%E6%B3%95%E6%AF%94%E8%B5%9B/" itemprop="url" rel="index"><span itemprop="name">算法比赛</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BA%94%E7%94%A8/%E7%AE%97%E6%B3%95%E6%AF%94%E8%B5%9B/%E4%B8%9A%E5%8A%A1%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">业务安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>16 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="搜狐情感分析-推荐排序算法大赛-baseline">搜狐情感分析 ×
推荐排序算法大赛 baseline</span></h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzAxOTU5NTU4MQ==&amp;mid=2247490226&amp;idx=1&amp;sn=b080925450eb0fa2f8215a33e297214e&amp;chksm=9bc5f2e0acb27bf60296480678b8a8d20ddc0ca1e7e086fd7894fd70372cdd75d0260a915aa6&amp;mpshare=1&amp;scene=23&amp;srcid=0506hKi6p6tQeYmhSvBsgKQT&amp;sharer_sharetime=1651827176665&amp;sharer_shareid=984256fd6ff6c7f7ab7ae447f9006552%23rd">搜狐情感分析
× 推荐排序算法大赛 baseline</a></li>
<li><strong>比赛官网</strong>：https://www.biendata.xyz/competition/sohu_2022/</li>
</ul>
<h3><span id="赛题背景"><strong>赛题背景</strong></span></h3>
<p>在工业界，推荐算法和自然语言处理是结合非常紧密的两个技术环节。本次大赛我们推出创新赛制——NLP
和推荐算法双赛道：探究文本情感对推荐转化的影响。情感分析是NLP领域的经典任务，本次赛事在经典任务上再度加码，研究文本对指定对象的情感极性及色彩强度，难度升级，挑战加倍。同时拥有将算法成果研究落地实际场景的绝佳机会，接触在校园难以体验到的工业实践，体验与用户博弈的真实推荐场景。</p>
<h3><span id="比赛任务"><strong>比赛任务</strong></span></h3>
<p><strong>比赛分为两部分：</strong></p>
<ul>
<li><strong>第一部分：==面向实体对象的文本描述情感极性及色彩强度分析==。情感极性和强度分为五种情况：极正向、正向、中立、负向、极负向。选手需要针对给定的每一个实体对象，从文本描述的角度，分析出对该实体的情感极性和强度。</strong></li>
<li><strong>第二部分：利用给出的用户文章点击序列数据及用户相关特征，结合第一部分做出的情感分析模型，对给定的文章做出是否会形成点击转化的预测判别。用户点击序列中涉及的文章，及待预测的文章，我们都会给出其详细内容。</strong></li>
</ul>
<h3><span id="一-任务1面向实体对象的文本情感分类">一、
<strong>任务1：面向实体对象的文本情感分类</strong></span></h3>
<h4><span id="21-数据加载">2.1 <strong>数据加载</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train_file = <span class="string">&#x27;data/Sohu2022_data/nlp_data/train.txt&#x27;</span></span><br><span class="line">test_file = <span class="string">&#x27;data/Sohu2022_data/nlp_data/test.txt&#x27;</span></span><br><span class="line">sub_file = <span class="string">&#x27;data/submission/section1.txt&#x27;</span></span><br><span class="line"></span><br><span class="line">train = pd.read_json(train_file, lines=<span class="literal">True</span>)</span><br><span class="line">test = pd.read_json(test_file, lines=<span class="literal">True</span>)</span><br><span class="line">sub= pd.read_table(sub_file)</span><br></pre></td></tr></table></figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040555.png" alt="图片"></p>
<h4><span id="22-文本长度统计">2.2 <strong>文本长度统计</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;text_len&#x27;</span>].quantile([<span class="number">0.5</span>,<span class="number">0.8</span>,<span class="number">0.9</span>,<span class="number">0.96</span>])</span><br></pre></td></tr></table></figure>
<p><strong>大部分文本长度在562以内</strong>，在迭代过程中发现，输入到模型的文本越完整效果越好，所以可以尝试<strong>文档级的模型</strong>，比如<strong>ernie-doc</strong>或者<strong>xlnet</strong>等。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040982.png" alt="图片" style="zoom:50%;"></p>
<h4><span id="23-实体情感标签统计">2.3 <strong>实体情感标签统计</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(sentiment_df.sentiment)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sentiment value count&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040704.png" alt="图片" style="zoom:50%;"></p>
<p>可以看出中性情感占到了绝大部分，极端情感最少。因为数据量比较大，大家可以使用一些<strong>采样策略</strong>：</p>
<ul>
<li><strong>中立情感负采样 ，但是有过拟合风险</strong></li>
<li><strong>保证情感比例采样：加快模型迭代速度</strong></li>
<li><strong>对同一个样本的重复情感可以负采样，ent1和ent2：1
text|ent1+ent2</strong></li>
</ul>
<h4><span id="24-数据预处理">2.4 <strong>数据预处理</strong></span></h4>
<p><strong>重复标签</strong>：同一样本的标签有多个，然后按照多个实体情感对样本进行复制，得到每个文本以及标签，处理代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lst_col = <span class="string">&#x27;sentiment&#x27;</span></span><br><span class="line">train = pd.DataFrame(&#123;</span><br><span class="line">    col: np.repeat(train[col].values, train[lst_col].<span class="built_in">str</span>.<span class="built_in">len</span>())</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> train.columns.difference([lst_col])</span><br><span class="line">&#125;).assign(**&#123;lst_col: np.concatenate(train[lst_col].values)&#125;)[train.columns.tolist()]</span><br></pre></td></tr></table></figure>
<h4><span id="模型定义"><strong>模型定义</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LastHiddenModel</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_name, n_classes</span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        config = AutoConfig.from_pretrained(model_name)</span><br><span class="line">        self.model = AutoModel.from_pretrained(model_name, config=config)</span><br><span class="line">        self.linear = nn.Linear(config.hidden_size, n_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_ids, attention_mask, token_type_ids</span>):</span><br><span class="line">        outputs = self.model(input_ids, attention_mask, token_type_ids)<span class="comment"># last_hidden_state和pooler out</span></span><br><span class="line">        last_hidden_state = outputs[<span class="number">0</span>] <span class="comment"># 所有字符最后一层hidden state # 32 400 768 ，但是PAD PAD</span></span><br><span class="line">        input_mask_expanded = attention_mask.unsqueeze(-<span class="number">1</span>).expand(last_hidden_state.size()).<span class="built_in">float</span>()</span><br><span class="line">        sum_embeddings = torch.<span class="built_in">sum</span>(last_hidden_state * input_mask_expanded, <span class="number">1</span>)</span><br><span class="line">        sum_mask = input_mask_expanded.<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line">        sum_mask = torch.clamp(sum_mask, <span class="built_in">min</span>=<span class="number">1e-9</span>)</span><br><span class="line">        mean_embeddings = sum_embeddings / sum_mask</span><br><span class="line">        logits = self.linear(mean_embeddings)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure>
<h4><span id="扩展思路"><strong>扩展思路：</strong></span></h4>
<ul>
<li><strong>长文本处理：模型输入/模型预测:TTA</strong></li>
<li><strong>doc级文本模型：longformer</strong></li>
</ul>
<blockquote>
<p>（<strong>xlnet</strong>）
https://huggingface.co/hfl/chinese-xlnet-base</p>
<p>(<strong>longformer_zh</strong>)
https://huggingface.co/ValkyriaLenneth/longformer_zh</p>
<p>(longformer-chinese-base-4096)
https://huggingface.co/schen/longformer-chinese-base-4096</p>
</blockquote>
<ul>
<li><strong>轻量级模型：LSTM、GRU/Transformer等网络 600 word
300</strong></li>
<li><strong>选择使用不同预训练模型进行微调，chinese-roberta-wwm/nezha/xlnet/ernie/ernie-gram,其中ernie或者ernie-gram效果可能会好些</strong></li>
<li><strong>预训练模型输出的利用：CLS/PoolerOut/LastHiddenState/+(Bi)LSTM/LastFourConcat/etc...</strong></li>
<li><strong>训练优化：对抗训练(FGM/PGD/AWP)/EMA/MultiDropout/Rdrop</strong></li>
<li><strong>文本分类上分微调技巧实战</strong>
<ul>
<li>改进1 Last 4 Layers Concatenating</li>
<li>改进2 模型层间差分学习率:
对不同的网络层数使用不同的学习率，这样可以防止过拟合，有利于加速学习。</li>
</ul></li>
<li>==<strong>BERT长文本处理：《CogLTX: Applying BERT to Long
Texts》</strong>==
<ul>
<li>https://github.com/Sleepychord/CogLTX</li>
<li><strong>分类实例</strong>：https://github.com/Sleepychord/CogLTX/blob/main/run_20news.py</li>
<li>COGLTX采用的策略是将每个子句从原句中移除判断其是否是必不可少的(t是一个阈值)：</li>
</ul></li>
</ul>
<p>​
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040195.png" alt="图片" style="zoom: 67%;"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzkzOTI4ODc2Ng==&amp;mid=2247484174&amp;idx=1&amp;sn=cd2d5d51d9874bbc03d50b0bca9f17f3&amp;scene=21#wechat_redirect"><strong>CogLTX
: bert处理长文本代码解析</strong></a></p>
<ul>
<li><strong>XLNET分类模型</strong></li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> XLNetModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyXLNet</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">35</span>, alpha=<span class="number">0.5</span></span>):</span><br><span class="line"></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="built_in">super</span>(MyXLNet, self).__init__()</span><br><span class="line">        self.net = XLNetModel.from_pretrained(xlnet_cfg.xlnet_path).cuda()</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> self.net.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;layer.11&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;layer.10&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;layer.9&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;layer.8&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;pooler.dense&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">                param.requires_grad = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                param.requires_grad = <span class="literal">False</span></span><br><span class="line">        self.MLP = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">768</span>, num_classes, bias=<span class="literal">True</span>),</span><br><span class="line">        ).cuda()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line"></span><br><span class="line">        x = x.long()</span><br><span class="line">        x = self.net(x, output_all_encoded_layers=<span class="literal">False</span>).last_hidden_state</span><br><span class="line">        x = F.dropout(x, self.alpha, training=self.training)</span><br><span class="line">        x = torch.<span class="built_in">max</span>(x, dim=<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">        x = self.MLP(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(x)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<ul>
<li><strong>长文本理解模型 ERNIE-Doc</strong>
<ul>
<li>ERNIE-DOC，是一个基于Recurrence Transformers(Dai et al., 2019)
的文档级语言预训练模型。
本模型用了两种技术：<strong>回溯式feed机制和增强的循环机制</strong>，<strong>使模型具有更长的有效上下文长度，以获取整个文档的相关信息。</strong></li>
<li>https://github.com/PaddlePaddle/ERNIE</li>
</ul></li>
</ul>
<h3><span id="二-任务2文章点击预测"><strong>二、任务2：文章点击预测</strong></span></h3>
<p>第二部分：利用给出的<strong>用户文章点击序列数据</strong>及<strong>用户相关特征</strong>，结合第一部分做出的情感分析模型，对给定的文章做出是否会形成点击转化的预测判别。用户点击序列中涉及的文章，及待预测的文章，我们都会给出其详细内容。</p>
<h4><span id="21-数据加载">2.1 <strong>数据加载</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train = pd.read_csv(<span class="string">&#x27;data/Sohu2022_data/rec_data/train-dataset.csv&#x27;</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;data/Sohu2022_data/rec_data/test-dataset.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train_data.shape&quot;</span>,train.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test_data.shape&quot;</span>,test.shape)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040116.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>训练集中每条样本包含pvId，用户id，点击序列（序列中的每次点击都包含文章id和浏览时间），用户特征（包含但不限于操作系统、浏览器、设备、运营商、省份、城市等），待预测文章id和当前时间戳，以及用户的行为(1为有点击，0为未点击)。</p>
<blockquote>
<p><strong>smapleId:样本的唯一id</strong></p>
<p><strong>label：点击标签</strong></p>
<p><strong>pvId：将每次曝光给用户的展示结果列表称为一个Group(每个Group都有唯一的pvId)</strong></p>
<p><strong>suv:用户id</strong></p>
<p><strong>itemId：文章id</strong></p>
<p><strong>userSeq:点击序列</strong></p>
<p><strong>logTs：当前时间戳</strong></p>
<p><strong>operator：操作系统</strong></p>
<p><strong>browserType：浏览器</strong></p>
<p><strong>deviceType:设备</strong></p>
<p><strong>osType：运营商</strong></p>
<p><strong>province：省份</strong></p>
<p><strong>city：城市</strong></p>
</blockquote>
<h4><span id="22-数据分析">2.2 数据分析</span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">statics</span>(<span class="params">data</span>):</span><br><span class="line">    stats = []</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> data.columns:</span><br><span class="line">        stats.append((col, data[col].nunique(), data[col].isnull().<span class="built_in">sum</span>() * <span class="number">100</span> / data.shape[<span class="number">0</span>],data[col].value_counts(normalize=<span class="literal">True</span>, dropna=<span class="literal">False</span>).values[<span class="number">0</span>] * <span class="number">100</span>, data[col].dtype))</span><br><span class="line">    stats_df = pd.DataFrame(stats, columns=[<span class="string">&#x27;Feature&#x27;</span>, <span class="string">&#x27;Unique_values&#x27;</span>, <span class="string">&#x27;Percentage_of_missing_values&#x27;</span>,<span class="string">&#x27;Percentage_of_values_in_the_biggest category&#x27;</span>, <span class="string">&#x27;type&#x27;</span>])</span><br><span class="line">    stats_df.sort_values(<span class="string">&#x27;Percentage_of_missing_values&#x27;</span>, ascending=<span class="literal">False</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> stats_df  </span><br><span class="line">stats_df=statics(train)</span><br><span class="line">stats_df</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040147.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h5><span id="标签分布如下">标签分布如下:</span></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train.label)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;train label count&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182041629.png" alt="图片" style="zoom:67%;"></p>
<h4><span id="23-初步特征工程"><strong>2.3 初步特征工程</strong></span></h4>
<ul>
<li><strong>情感特征</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">amount_feas = [<span class="string">&#x27;prob_0&#x27;</span>, <span class="string">&#x27;prob_1&#x27;</span>, <span class="string">&#x27;prob_2&#x27;</span>, <span class="string">&#x27;prob_3&#x27;</span>,<span class="string">&#x27;prob_4&#x27;</span> ]</span><br><span class="line">category_fea = [<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> tqdm(amount_feas, desc=<span class="string">&quot;amount_feas 基本聚合特征&quot;</span>):</span><br><span class="line">    <span class="keyword">for</span> cate <span class="keyword">in</span> category_fea:</span><br><span class="line">        <span class="keyword">if</span> f != cate:</span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_medi&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;median&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_mean&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_max&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_min&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;min&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_std&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;std&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h5><span id="类别特征count特征">类别特征count特征：</span></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># count特征</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm(sparse_features):</span><br><span class="line">    data[col + <span class="string">&#x27;_count&#x27;</span>] = data.groupby(col)[<span class="string">&#x27;sampleId&#x27;</span>].transform(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">    dense_features.append(col + <span class="string">&#x27;_count&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h5><span id="用户特征">用户特征：</span></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># count特征</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm([<span class="string">&#x27;pvId&#x27;</span>,<span class="string">&#x27;itemId&#x27;</span> ]):</span><br><span class="line">    data[<span class="string">f&#x27;group_suv_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>] = data[[<span class="string">&#x27;suv&#x27;</span>, col]].groupby(<span class="string">&#x27;suv&#x27;</span>)[col].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">    dense_features.append(<span class="string">f&#x27;group_suv_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>)  </span><br></pre></td></tr></table></figure>
<h5><span id="物料特征">物料特征：</span></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pvId nunique特征</span></span><br><span class="line">select_cols = [<span class="string">&#x27;suv&#x27;</span>, <span class="string">&#x27;itemId&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm(select_cols):</span><br><span class="line"></span><br><span class="line">    data[<span class="string">f&#x27;group_pvId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>] = data[[<span class="string">&#x27;pvId&#x27;</span>, col]].groupby(<span class="string">&#x27;pvId&#x27;</span>)[col].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">    dense_features.append(<span class="string">f&#x27;group_pvId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>)      </span><br><span class="line"><span class="comment"># itemId nunique特征</span></span><br><span class="line">select_cols = [<span class="string">&#x27;pvId&#x27;</span>, <span class="string">&#x27;suv&#x27;</span>, <span class="string">&#x27;operator&#x27;</span>, <span class="string">&#x27;browserType&#x27;</span>, <span class="string">&#x27;deviceType&#x27;</span>, <span class="string">&#x27;osType&#x27;</span>, <span class="string">&#x27;province&#x27;</span>, <span class="string">&#x27;city&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm(select_cols):</span><br><span class="line">    data[<span class="string">f&#x27;group_itemId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>] = \</span><br><span class="line">        data[[<span class="string">&#x27;itemId&#x27;</span>, col]].groupby(<span class="string">&#x27;itemId&#x27;</span>)[col].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">    dense_features.append(<span class="string">f&#x27;group_itemId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>) </span><br></pre></td></tr></table></figure>
<h4><span id="nn模型-deepfm"><strong>NN模型-DeepFM</strong></span></h4>
<p>基于deepctr实现DeepFM训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">train_model_input = &#123;name: train[name] <span class="keyword">for</span> name <span class="keyword">in</span> feature_names&#125;</span><br><span class="line">valid_model_input = &#123;name: valid[name] <span class="keyword">for</span> name <span class="keyword">in</span> feature_names&#125;</span><br><span class="line">test_model_input = &#123;name: test[name] <span class="keyword">for</span> name <span class="keyword">in</span> feature_names&#125;</span><br><span class="line">model = DeepFM(linear_feature_columns, dnn_feature_columns, task=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(<span class="string">&quot;adam&quot;</span>, <span class="string">&quot;binary_crossentropy&quot;</span>, metrics=[<span class="string">&#x27;binary_crossentropy&#x27;</span>, <span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(train_model_input, train[target].values,</span><br><span class="line">                    batch_size=<span class="number">1024</span>, epochs=<span class="number">3</span>, verbose=<span class="number">1</span>, </span><br><span class="line">                    validation_data=(valid_model_input, valid[target].values))</span><br><span class="line"></span><br><span class="line">pred_ans = model.predict(valid_model_input, batch_size=<span class="number">1024</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;valid AUC&quot;</span>, <span class="built_in">round</span>(roc_auc_score(valid[target].values, pred_ans), <span class="number">4</span>))</span><br><span class="line">pred_ans = model.predict(test_model_input, batch_size=<span class="number">1024</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="树模型-catboost"><strong>树模型-Catboost</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_model = CatBoostClassifier(iterations=<span class="number">15000</span>, depth=<span class="number">5</span>, learning_rate=<span class="number">0.05</span>, loss_function=<span class="string">&#x27;Logloss&#x27;</span>, logging_level=<span class="string">&#x27;Verbose&#x27;</span>, eval_metric=<span class="string">&#x27;AUC&#x27;</span>, task_type=<span class="string">&quot;GPU&quot;</span>, devices=<span class="string">&#x27;0:1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">train_model.fit(train_dataset, eval_set=eval_dataset, early_stopping_rounds=<span class="number">30</span>, verbose=<span class="number">40</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="特征工程思路扩展"><strong>特征工程思路扩展</strong></span></h4>
<ul>
<li><strong>高阶特征：类别特征组合、高阶聚合特征，比例特征</strong></li>
<li><strong>点击序列统计特征：当前用户|全局： item
众数当做类别特征；统计量 count或者nunique</strong></li>
<li><strong>序列 Embedding特征：word2vec，tfidf(词袋)+SVD、graph
embedding(deepwalk)</strong></li>
<li><strong>点击转化率特征：itemid、pvId,类别组合 ..(提分)
Kfold</strong></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/3ZEPE93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/3ZEPE93/" class="post-title-link" itemprop="url">机器学习-模型融合</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-07 13:51:03" itemprop="dateCreated datePublished" datetime="2022-05-07T13:51:03+08:00">2022-05-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-17 21:20:45" itemprop="dateModified" datetime="2023-04-17T21:20:45+08:00">2023-04-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">理论基础</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="融合机器学习模型一种提升预测能力的方法"><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/33589222">「融合」机器学习模型：一种提升预测能力的方法</a></h2>
<p>没有哪个机器学习模型可以常胜，如何找到当前问题的最优解是一个永恒的问题。</p>
<p>幸运的是，<strong>结合/融合/整合 (integration/ combination/
fusion)多个机器学习模型往往可以提高整体的预测能力。</strong>这是一种非常有效的提升手段，在多分类器系统(multi-classifier
system)和集成学习(ensemble learning)中，融合都是最重要的一个步骤。</p>
<p>一般来说，<strong>模型融合或多或少都能提高的最终的预测能力，且一般不会比最优子模型差</strong>。举个实用的例子，Kaggle比赛中常用的stacking方法就是模型融合，通过结合多个各有所长的子学习器，我们实现了更好的预测结果。基本的理论假设是：<strong>不同的子模型在不同的数据上有不同的表达能力，我们可以结合他们擅长的部分，得到一个在各个方面都很“准确”的模型</strong>。当然，最基本的假设是子模型的误差是互相独立的，这个一般是不现实的。但即使子模型间的误差有相关性，适当的结合方法依然可以各取其长，从而达到提升效果。</p>
<p>我们今天介绍几种简单、有效的模型结合方法。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/posts/3ZEPE93/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/R9HZV9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/R9HZV9/" class="post-title-link" itemprop="url">局部敏感哈希LSH</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-05-06 10:05:54 / 修改时间：10:56:38" itemprop="dateCreated datePublished" datetime="2022-05-06T10:05:54+08:00">2022-05-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B7%A5%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">工程</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B7%A5%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">大数据处理</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="一-局部敏感哈希函数">一、局部敏感哈希函数</span></h2>
<blockquote>
<p>python_mmdt:ssdeep、tlsh、vhash、mmdthash对比 :
https://www.freebuf.com/sectool/321011.html</p>
<p>局部敏感哈希(Locality Sensitive
Hashing，LSH)总结：http://yangyi-bupt.github.io/ml/2015/08/28/lsh.html</p>
</blockquote>
<h3><span id="11-局部敏感哈希的基本概念">1.1 局部敏感哈希的基本概念</span></h3>
<p>局部敏感哈希(Locality Sensitive
Hashing，LSH)的基本思想类似于一种空间域转换思想，LSH算法基于一个假设，<strong>如果两个文本在原有的数据空间是相似的，那么分别经过哈希函数转换以后的它们也具有很高的相似度</strong>；相反，如果它们本身是不相似的，那么经过转换后它们应仍不具有相似性。</p>
<h3><span id="12-hash方法">1.2 hash方法</span></h3>
<p><strong><a target="_blank" rel="noopener" href="https://ssdeep-project.github.io/ssdeep/index.html">CTPH(ssdeep)</a>：Context
Triggered Piecewise Hashes(CTPH)</strong>，又叫模糊哈希，最早由Jesse
Kornblum博士在2006年提出，论文地址点击<a target="_blank" rel="noopener" href="https://ssdeep-project.github.io/ssdeep/index.html">这里</a>。CTPH可用于文件/数据的<strong>同源性判定</strong>。据官方文档介绍，其计算速度是<code>tlsh</code>的两倍（测试了一下，好像并没有）。</p>
<blockquote>
<p>当使用传统的加密散列时，会为整个文件创建一个散列。单个位的变化会对输出哈希值产生雪崩效应。另一方面，CTPH
为文件的多个固定大小段计算多个传统加密哈希。它使用<em>滚动哈希</em>。</p>
</blockquote>
<p><strong><a target="_blank" rel="noopener" href="https://tlsh.org/index.html">tlsh</a>：是趋势科技开源的一款模糊哈希计算工具</strong>，将50字节以上的数据计算生成一个哈希值，通过计算哈希值之间的相似度，从而得到原始文件之间的同源性关联。据官方文档介绍，<code>tlsh</code>比<code>ssdeep</code>和<code>sdhash</code>等其他模糊哈希算法更难攻击和绕过。</p>
<p><a target="_blank" rel="noopener" href="https://developers.virustotal.com/reference/files">vhash</a>：（翻遍了整个virustotal的文档，就找到这么一句话）“an
in-house similarity clustering algorithm value, based on a simple
structural feature hash allows you to find similar
files”，大概就是说是个内部相似性聚类算法，允许你通过这个简单的值，找到相似的样本。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/a232319779/python_mmdt">mmdthash</a>：是开源的一款模糊哈希计算工具，将任意数据计算生成一个模糊哈希值，通过计算模糊哈希值之间的相似度，从而判断两个数据之间的关联性。详情前文1-5篇。</p>
<blockquote>
<p>#### mmdthash：</p>
<p>通过重采样之后的数据，我们假设其满足独立同分布。同时，我们将重采样的数据，平均分成N块，每块之间的数据进行累计求和，和值分布近似服从正态分布，我们取和值高x位的一个byte做为本块数据的敏感哈希值。</p>
<p>51030000:D6E26822530202020202020202020202：</p>
<ul>
<li><code>51030000</code>是4字节<strong>索引</strong>敏感哈希</li>
<li><code>D6E26822530202020202020202020202</code>是16字节敏感哈希</li>
</ul>
</blockquote>
<h3><span id="13-应用">1.3 应用</span></h3>
<p>简单应用如，索引敏感哈希可以转成一个int32的数字，当<strong>索引敏感哈希相等</strong>时，<strong>再比较敏感哈希的距离</strong>（如曼哈顿距离，将敏感哈希转成N个<code>unsigned char</code>类型计算敏感哈希，此时<code>00</code>和<code>FF</code>之间的距离可算作1，也可算作255，具体看实现）。</p>
<p>由于特征向量的维度是固定的，因此可以很方便的使用其他数学方法，进行大规模计算。</p>
<ul>
<li>如结合矩阵运算，快速得到上万特征向量（样本）的相似度矩阵，</li>
<li>如用于机器学习的分类（KNN）、聚类（Kmeans）等</li>
</ul>
<h3><span id></span></h3>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/13/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span><a class="page-number" href="/page/15/">15</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/15/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lzy</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>-->
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("03/01/2023 10:00:00"); //此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒.";
    }
setInterval("createtime()",250);
</script>

    </div>
  </footer>

  

  <a href="https://github.com/PowerLZY" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.4.3/mermaid.min.js","integrity":"sha256-e0o3JYsdjqKajf9eOe22FhioYSz9WofRY4dLKo3F6do="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>




        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        const hasAttr = (e,a) => a.some(_=> e.attr(_)!==undefined);
        $('a').each(function() {
          const $this = $(this);
          if(hasAttr($this,["data-fancybox","ignore-external-link"])) return;
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'powerlzy.github.io' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script></body>
</html>
