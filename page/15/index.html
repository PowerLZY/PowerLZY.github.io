<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-bounce.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"powerlzy.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="相比到达的地方，同行的人更重要！">
<meta property="og:type" content="website">
<meta property="og:title" content="PowerLZY&#39;s Blog">
<meta property="og:url" content="https://powerlzy.github.io/page/15/index.html">
<meta property="og:site_name" content="PowerLZY&#39;s Blog">
<meta property="og:description" content="相比到达的地方，同行的人更重要！">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="lzy">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://powerlzy.github.io/page/15/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/15/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>PowerLZY's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">PowerLZY's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">本博客主要用于记录个人学习笔记（测试阶段）</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="lzy"
      src="/images/cat_mac.jpg">
  <p class="site-author-name" itemprop="name">lzy</p>
  <div class="site-description" itemprop="description">相比到达的地方，同行的人更重要！</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">251</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">38</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/PowerLZY" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;PowerLZY" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:3289218653@qq.com" title="E-Mail → mailto:3289218653@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/7C1A6K/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/7C1A6K/" class="post-title-link" itemprop="url">文本分类（1）搜狐文本情感分类</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-09 12:46:40" itemprop="dateCreated datePublished" datetime="2022-05-09T12:46:40+08:00">2022-05-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-18 20:41:07" itemprop="dateModified" datetime="2023-04-18T20:41:07+08:00">2023-04-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">【draft】应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E7%AE%97%E6%B3%95%E6%AF%94%E8%B5%9B/" itemprop="url" rel="index"><span itemprop="name">算法比赛</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E7%AE%97%E6%B3%95%E6%AF%94%E8%B5%9B/%E4%B8%9A%E5%8A%A1%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">业务安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>16 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="搜狐情感分析-推荐排序算法大赛-baseline">搜狐情感分析 ×
推荐排序算法大赛 baseline</span></h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzAxOTU5NTU4MQ==&amp;mid=2247490226&amp;idx=1&amp;sn=b080925450eb0fa2f8215a33e297214e&amp;chksm=9bc5f2e0acb27bf60296480678b8a8d20ddc0ca1e7e086fd7894fd70372cdd75d0260a915aa6&amp;mpshare=1&amp;scene=23&amp;srcid=0506hKi6p6tQeYmhSvBsgKQT&amp;sharer_sharetime=1651827176665&amp;sharer_shareid=984256fd6ff6c7f7ab7ae447f9006552%23rd">搜狐情感分析
× 推荐排序算法大赛 baseline</a></li>
<li><strong>比赛官网</strong>：https://www.biendata.xyz/competition/sohu_2022/</li>
</ul>
<h3><span id="赛题背景"><strong>赛题背景</strong></span></h3>
<p>在工业界，推荐算法和自然语言处理是结合非常紧密的两个技术环节。本次大赛我们推出创新赛制——NLP
和推荐算法双赛道：探究文本情感对推荐转化的影响。情感分析是NLP领域的经典任务，本次赛事在经典任务上再度加码，研究文本对指定对象的情感极性及色彩强度，难度升级，挑战加倍。同时拥有将算法成果研究落地实际场景的绝佳机会，接触在校园难以体验到的工业实践，体验与用户博弈的真实推荐场景。</p>
<h3><span id="比赛任务"><strong>比赛任务</strong></span></h3>
<p><strong>比赛分为两部分：</strong></p>
<ul>
<li><strong>第一部分：==面向实体对象的文本描述情感极性及色彩强度分析==。情感极性和强度分为五种情况：极正向、正向、中立、负向、极负向。选手需要针对给定的每一个实体对象，从文本描述的角度，分析出对该实体的情感极性和强度。</strong></li>
<li><strong>第二部分：利用给出的用户文章点击序列数据及用户相关特征，结合第一部分做出的情感分析模型，对给定的文章做出是否会形成点击转化的预测判别。用户点击序列中涉及的文章，及待预测的文章，我们都会给出其详细内容。</strong></li>
</ul>
<h3><span id="一-任务1面向实体对象的文本情感分类">一、
<strong>任务1：面向实体对象的文本情感分类</strong></span></h3>
<h4><span id="21-数据加载">2.1 <strong>数据加载</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">train_file = <span class="string">&#x27;data/Sohu2022_data/nlp_data/train.txt&#x27;</span></span><br><span class="line">test_file = <span class="string">&#x27;data/Sohu2022_data/nlp_data/test.txt&#x27;</span></span><br><span class="line">sub_file = <span class="string">&#x27;data/submission/section1.txt&#x27;</span></span><br><span class="line"></span><br><span class="line">train = pd.read_json(train_file, lines=<span class="literal">True</span>)</span><br><span class="line">test = pd.read_json(test_file, lines=<span class="literal">True</span>)</span><br><span class="line">sub= pd.read_table(sub_file)</span><br></pre></td></tr></table></figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040555.png" alt="图片"></p>
<h4><span id="22-文本长度统计">2.2 <strong>文本长度统计</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&#x27;text_len&#x27;</span>].quantile([<span class="number">0.5</span>,<span class="number">0.8</span>,<span class="number">0.9</span>,<span class="number">0.96</span>])</span><br></pre></td></tr></table></figure>
<p><strong>大部分文本长度在562以内</strong>，在迭代过程中发现，输入到模型的文本越完整效果越好，所以可以尝试<strong>文档级的模型</strong>，比如<strong>ernie-doc</strong>或者<strong>xlnet</strong>等。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040982.png" alt="图片" style="zoom:50%;"></p>
<h4><span id="23-实体情感标签统计">2.3 <strong>实体情感标签统计</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(sentiment_df.sentiment)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;sentiment value count&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040704.png" alt="图片" style="zoom:50%;"></p>
<p>可以看出中性情感占到了绝大部分，极端情感最少。因为数据量比较大，大家可以使用一些<strong>采样策略</strong>：</p>
<ul>
<li><strong>中立情感负采样 ，但是有过拟合风险</strong></li>
<li><strong>保证情感比例采样：加快模型迭代速度</strong></li>
<li><strong>对同一个样本的重复情感可以负采样，ent1和ent2：1
text|ent1+ent2</strong></li>
</ul>
<h4><span id="24-数据预处理">2.4 <strong>数据预处理</strong></span></h4>
<p><strong>重复标签</strong>：同一样本的标签有多个，然后按照多个实体情感对样本进行复制，得到每个文本以及标签，处理代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lst_col = <span class="string">&#x27;sentiment&#x27;</span></span><br><span class="line">train = pd.DataFrame(&#123;</span><br><span class="line">    col: np.repeat(train[col].values, train[lst_col].<span class="built_in">str</span>.<span class="built_in">len</span>())</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> train.columns.difference([lst_col])</span><br><span class="line">&#125;).assign(**&#123;lst_col: np.concatenate(train[lst_col].values)&#125;)[train.columns.tolist()]</span><br></pre></td></tr></table></figure>
<h4><span id="模型定义"><strong>模型定义</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LastHiddenModel</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_name, n_classes</span>):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        config = AutoConfig.from_pretrained(model_name)</span><br><span class="line">        self.model = AutoModel.from_pretrained(model_name, config=config)</span><br><span class="line">        self.linear = nn.Linear(config.hidden_size, n_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_ids, attention_mask, token_type_ids</span>):</span><br><span class="line">        outputs = self.model(input_ids, attention_mask, token_type_ids)<span class="comment"># last_hidden_state和pooler out</span></span><br><span class="line">        last_hidden_state = outputs[<span class="number">0</span>] <span class="comment"># 所有字符最后一层hidden state # 32 400 768 ，但是PAD PAD</span></span><br><span class="line">        input_mask_expanded = attention_mask.unsqueeze(-<span class="number">1</span>).expand(last_hidden_state.size()).<span class="built_in">float</span>()</span><br><span class="line">        sum_embeddings = torch.<span class="built_in">sum</span>(last_hidden_state * input_mask_expanded, <span class="number">1</span>)</span><br><span class="line">        sum_mask = input_mask_expanded.<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line">        sum_mask = torch.clamp(sum_mask, <span class="built_in">min</span>=<span class="number">1e-9</span>)</span><br><span class="line">        mean_embeddings = sum_embeddings / sum_mask</span><br><span class="line">        logits = self.linear(mean_embeddings)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure>
<h4><span id="扩展思路"><strong>扩展思路：</strong></span></h4>
<ul>
<li><strong>长文本处理：模型输入/模型预测:TTA</strong></li>
<li><strong>doc级文本模型：longformer</strong></li>
</ul>
<blockquote>
<p>（<strong>xlnet</strong>）
https://huggingface.co/hfl/chinese-xlnet-base</p>
<p>(<strong>longformer_zh</strong>)
https://huggingface.co/ValkyriaLenneth/longformer_zh</p>
<p>(longformer-chinese-base-4096)
https://huggingface.co/schen/longformer-chinese-base-4096</p>
</blockquote>
<ul>
<li><strong>轻量级模型：LSTM、GRU/Transformer等网络 600 word
300</strong></li>
<li><strong>选择使用不同预训练模型进行微调，chinese-roberta-wwm/nezha/xlnet/ernie/ernie-gram,其中ernie或者ernie-gram效果可能会好些</strong></li>
<li><strong>预训练模型输出的利用：CLS/PoolerOut/LastHiddenState/+(Bi)LSTM/LastFourConcat/etc...</strong></li>
<li><strong>训练优化：对抗训练(FGM/PGD/AWP)/EMA/MultiDropout/Rdrop</strong></li>
<li><strong>文本分类上分微调技巧实战</strong>
<ul>
<li>改进1 Last 4 Layers Concatenating</li>
<li>改进2 模型层间差分学习率:
对不同的网络层数使用不同的学习率，这样可以防止过拟合，有利于加速学习。</li>
</ul></li>
<li>==<strong>BERT长文本处理：《CogLTX: Applying BERT to Long
Texts》</strong>==
<ul>
<li>https://github.com/Sleepychord/CogLTX</li>
<li><strong>分类实例</strong>：https://github.com/Sleepychord/CogLTX/blob/main/run_20news.py</li>
<li>COGLTX采用的策略是将每个子句从原句中移除判断其是否是必不可少的(t是一个阈值)：</li>
</ul></li>
</ul>
<p>​
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040195.png" alt="图片" style="zoom: 67%;"></p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzkzOTI4ODc2Ng==&amp;mid=2247484174&amp;idx=1&amp;sn=cd2d5d51d9874bbc03d50b0bca9f17f3&amp;scene=21#wechat_redirect"><strong>CogLTX
: bert处理长文本代码解析</strong></a></p>
<ul>
<li><strong>XLNET分类模型</strong></li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> XLNetModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyXLNet</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">35</span>, alpha=<span class="number">0.5</span></span>):</span><br><span class="line"></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        <span class="built_in">super</span>(MyXLNet, self).__init__()</span><br><span class="line">        self.net = XLNetModel.from_pretrained(xlnet_cfg.xlnet_path).cuda()</span><br><span class="line">        <span class="keyword">for</span> name, param <span class="keyword">in</span> self.net.named_parameters():</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;layer.11&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;layer.10&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;layer.9&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;layer.8&#x27;</span> <span class="keyword">in</span> name <span class="keyword">or</span> <span class="string">&#x27;pooler.dense&#x27;</span> <span class="keyword">in</span> name:</span><br><span class="line">                param.requires_grad = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                param.requires_grad = <span class="literal">False</span></span><br><span class="line">        self.MLP = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">768</span>, num_classes, bias=<span class="literal">True</span>),</span><br><span class="line">        ).cuda()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line"></span><br><span class="line">        x = x.long()</span><br><span class="line">        x = self.net(x, output_all_encoded_layers=<span class="literal">False</span>).last_hidden_state</span><br><span class="line">        x = F.dropout(x, self.alpha, training=self.training)</span><br><span class="line">        x = torch.<span class="built_in">max</span>(x, dim=<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">        x = self.MLP(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(x)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<ul>
<li><strong>长文本理解模型 ERNIE-Doc</strong>
<ul>
<li>ERNIE-DOC，是一个基于Recurrence Transformers(Dai et al., 2019)
的文档级语言预训练模型。
本模型用了两种技术：<strong>回溯式feed机制和增强的循环机制</strong>，<strong>使模型具有更长的有效上下文长度，以获取整个文档的相关信息。</strong></li>
<li>https://github.com/PaddlePaddle/ERNIE</li>
</ul></li>
</ul>
<h3><span id="二-任务2文章点击预测"><strong>二、任务2：文章点击预测</strong></span></h3>
<p>第二部分：利用给出的<strong>用户文章点击序列数据</strong>及<strong>用户相关特征</strong>，结合第一部分做出的情感分析模型，对给定的文章做出是否会形成点击转化的预测判别。用户点击序列中涉及的文章，及待预测的文章，我们都会给出其详细内容。</p>
<h4><span id="21-数据加载">2.1 <strong>数据加载</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train = pd.read_csv(<span class="string">&#x27;data/Sohu2022_data/rec_data/train-dataset.csv&#x27;</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">&#x27;data/Sohu2022_data/rec_data/test-dataset.csv&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train_data.shape&quot;</span>,train.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test_data.shape&quot;</span>,test.shape)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040116.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<p>训练集中每条样本包含pvId，用户id，点击序列（序列中的每次点击都包含文章id和浏览时间），用户特征（包含但不限于操作系统、浏览器、设备、运营商、省份、城市等），待预测文章id和当前时间戳，以及用户的行为(1为有点击，0为未点击)。</p>
<blockquote>
<p><strong>smapleId:样本的唯一id</strong></p>
<p><strong>label：点击标签</strong></p>
<p><strong>pvId：将每次曝光给用户的展示结果列表称为一个Group(每个Group都有唯一的pvId)</strong></p>
<p><strong>suv:用户id</strong></p>
<p><strong>itemId：文章id</strong></p>
<p><strong>userSeq:点击序列</strong></p>
<p><strong>logTs：当前时间戳</strong></p>
<p><strong>operator：操作系统</strong></p>
<p><strong>browserType：浏览器</strong></p>
<p><strong>deviceType:设备</strong></p>
<p><strong>osType：运营商</strong></p>
<p><strong>province：省份</strong></p>
<p><strong>city：城市</strong></p>
</blockquote>
<h4><span id="22-数据分析">2.2 数据分析</span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">statics</span>(<span class="params">data</span>):</span><br><span class="line">    stats = []</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> data.columns:</span><br><span class="line">        stats.append((col, data[col].nunique(), data[col].isnull().<span class="built_in">sum</span>() * <span class="number">100</span> / data.shape[<span class="number">0</span>],data[col].value_counts(normalize=<span class="literal">True</span>, dropna=<span class="literal">False</span>).values[<span class="number">0</span>] * <span class="number">100</span>, data[col].dtype))</span><br><span class="line">    stats_df = pd.DataFrame(stats, columns=[<span class="string">&#x27;Feature&#x27;</span>, <span class="string">&#x27;Unique_values&#x27;</span>, <span class="string">&#x27;Percentage_of_missing_values&#x27;</span>,<span class="string">&#x27;Percentage_of_values_in_the_biggest category&#x27;</span>, <span class="string">&#x27;type&#x27;</span>])</span><br><span class="line">    stats_df.sort_values(<span class="string">&#x27;Percentage_of_missing_values&#x27;</span>, ascending=<span class="literal">False</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> stats_df  </span><br><span class="line">stats_df=statics(train)</span><br><span class="line">stats_df</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182040147.png" alt="图片">
<figcaption aria-hidden="true">图片</figcaption>
</figure>
<h5><span id="标签分布如下">标签分布如下:</span></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train.label)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;train label count&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182041629.png" alt="图片" style="zoom:67%;"></p>
<h4><span id="23-初步特征工程"><strong>2.3 初步特征工程</strong></span></h4>
<ul>
<li><strong>情感特征</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">amount_feas = [<span class="string">&#x27;prob_0&#x27;</span>, <span class="string">&#x27;prob_1&#x27;</span>, <span class="string">&#x27;prob_2&#x27;</span>, <span class="string">&#x27;prob_3&#x27;</span>,<span class="string">&#x27;prob_4&#x27;</span> ]</span><br><span class="line">category_fea = [<span class="string">&#x27;id&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> tqdm(amount_feas, desc=<span class="string">&quot;amount_feas 基本聚合特征&quot;</span>):</span><br><span class="line">    <span class="keyword">for</span> cate <span class="keyword">in</span> category_fea:</span><br><span class="line">        <span class="keyword">if</span> f != cate:</span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_medi&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;median&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_mean&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_max&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_min&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;min&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            rec_item_sentiment[<span class="string">&#x27;&#123;&#125;_&#123;&#125;_std&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;senti&#x27;</span>, f)] = rec_item_sentiment.groupby(cate)[f].transform(<span class="string">&#x27;std&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h5><span id="类别特征count特征">类别特征count特征：</span></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># count特征</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm(sparse_features):</span><br><span class="line">    data[col + <span class="string">&#x27;_count&#x27;</span>] = data.groupby(col)[<span class="string">&#x27;sampleId&#x27;</span>].transform(<span class="string">&#x27;count&#x27;</span>)</span><br><span class="line">    dense_features.append(col + <span class="string">&#x27;_count&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h5><span id="用户特征">用户特征：</span></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># count特征</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm([<span class="string">&#x27;pvId&#x27;</span>,<span class="string">&#x27;itemId&#x27;</span> ]):</span><br><span class="line">    data[<span class="string">f&#x27;group_suv_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>] = data[[<span class="string">&#x27;suv&#x27;</span>, col]].groupby(<span class="string">&#x27;suv&#x27;</span>)[col].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">    dense_features.append(<span class="string">f&#x27;group_suv_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>)  </span><br></pre></td></tr></table></figure>
<h5><span id="物料特征">物料特征：</span></h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pvId nunique特征</span></span><br><span class="line">select_cols = [<span class="string">&#x27;suv&#x27;</span>, <span class="string">&#x27;itemId&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm(select_cols):</span><br><span class="line"></span><br><span class="line">    data[<span class="string">f&#x27;group_pvId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>] = data[[<span class="string">&#x27;pvId&#x27;</span>, col]].groupby(<span class="string">&#x27;pvId&#x27;</span>)[col].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">    dense_features.append(<span class="string">f&#x27;group_pvId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>)      </span><br><span class="line"><span class="comment"># itemId nunique特征</span></span><br><span class="line">select_cols = [<span class="string">&#x27;pvId&#x27;</span>, <span class="string">&#x27;suv&#x27;</span>, <span class="string">&#x27;operator&#x27;</span>, <span class="string">&#x27;browserType&#x27;</span>, <span class="string">&#x27;deviceType&#x27;</span>, <span class="string">&#x27;osType&#x27;</span>, <span class="string">&#x27;province&#x27;</span>, <span class="string">&#x27;city&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> tqdm(select_cols):</span><br><span class="line">    data[<span class="string">f&#x27;group_itemId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>] = \</span><br><span class="line">        data[[<span class="string">&#x27;itemId&#x27;</span>, col]].groupby(<span class="string">&#x27;itemId&#x27;</span>)[col].transform(<span class="string">&#x27;nunique&#x27;</span>)</span><br><span class="line">    dense_features.append(<span class="string">f&#x27;group_itemId_<span class="subst">&#123;col&#125;</span>_nunique&#x27;</span>) </span><br></pre></td></tr></table></figure>
<h4><span id="nn模型-deepfm"><strong>NN模型-DeepFM</strong></span></h4>
<p>基于deepctr实现DeepFM训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">train_model_input = &#123;name: train[name] <span class="keyword">for</span> name <span class="keyword">in</span> feature_names&#125;</span><br><span class="line">valid_model_input = &#123;name: valid[name] <span class="keyword">for</span> name <span class="keyword">in</span> feature_names&#125;</span><br><span class="line">test_model_input = &#123;name: test[name] <span class="keyword">for</span> name <span class="keyword">in</span> feature_names&#125;</span><br><span class="line">model = DeepFM(linear_feature_columns, dnn_feature_columns, task=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(<span class="string">&quot;adam&quot;</span>, <span class="string">&quot;binary_crossentropy&quot;</span>, metrics=[<span class="string">&#x27;binary_crossentropy&#x27;</span>, <span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">history = model.fit(train_model_input, train[target].values,</span><br><span class="line">                    batch_size=<span class="number">1024</span>, epochs=<span class="number">3</span>, verbose=<span class="number">1</span>, </span><br><span class="line">                    validation_data=(valid_model_input, valid[target].values))</span><br><span class="line"></span><br><span class="line">pred_ans = model.predict(valid_model_input, batch_size=<span class="number">1024</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;valid AUC&quot;</span>, <span class="built_in">round</span>(roc_auc_score(valid[target].values, pred_ans), <span class="number">4</span>))</span><br><span class="line">pred_ans = model.predict(test_model_input, batch_size=<span class="number">1024</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="树模型-catboost"><strong>树模型-Catboost</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_model = CatBoostClassifier(iterations=<span class="number">15000</span>, depth=<span class="number">5</span>, learning_rate=<span class="number">0.05</span>, loss_function=<span class="string">&#x27;Logloss&#x27;</span>, logging_level=<span class="string">&#x27;Verbose&#x27;</span>, eval_metric=<span class="string">&#x27;AUC&#x27;</span>, task_type=<span class="string">&quot;GPU&quot;</span>, devices=<span class="string">&#x27;0:1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">train_model.fit(train_dataset, eval_set=eval_dataset, early_stopping_rounds=<span class="number">30</span>, verbose=<span class="number">40</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="特征工程思路扩展"><strong>特征工程思路扩展</strong></span></h4>
<ul>
<li><strong>高阶特征：类别特征组合、高阶聚合特征，比例特征</strong></li>
<li><strong>点击序列统计特征：当前用户|全局： item
众数当做类别特征；统计量 count或者nunique</strong></li>
<li><strong>序列 Embedding特征：word2vec，tfidf(词袋)+SVD、graph
embedding(deepwalk)</strong></li>
<li><strong>点击转化率特征：itemid、pvId,类别组合 ..(提分)
Kfold</strong></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/1A55BTN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/1A55BTN/" class="post-title-link" itemprop="url">理论基础（6）模型融合</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-07 13:51:03" itemprop="dateCreated datePublished" datetime="2022-05-07T13:51:03+08:00">2022-05-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-25 21:24:15" itemprop="dateModified" datetime="2023-04-25T21:24:15+08:00">2023-04-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/" itemprop="url" rel="index"><span itemprop="name">理论基础</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3><span id="模型融合">模型融合</span></h3>
<p>没有哪个机器学习模型可以常胜，如何找到当前问题的最优解是一个永恒的问题。</p>
<p>幸运的是，<strong>结合/融合/整合 (integration/ combination/
fusion)多个机器学习模型往往可以提高整体的预测能力。</strong>这是一种非常有效的提升手段，在多分类器系统(multi-classifier
system)和集成学习(ensemble learning)中，融合都是最重要的一个步骤。</p>
<p>一般来说，<strong>模型融合或多或少都能提高的最终的预测能力，且一般不会比最优子模型差</strong>。举个实用的例子，Kaggle比赛中常用的stacking方法就是模型融合，通过结合多个各有所长的子学习器，我们实现了更好的预测结果。基本的理论假设是：<strong>不同的子模型在不同的数据上有不同的表达能力，我们可以结合他们擅长的部分，得到一个在各个方面都很“准确”的模型</strong>。当然，最基本的假设是子模型的误差是互相独立的，这个一般是不现实的。但即使子模型间的误差有相关性，适当的结合方法依然可以各取其长，从而达到提升效果。</p>
<p>我们今天介绍几种简单、有效的模型结合方法。</p>
<h3><span id="一-案例分析">一、案例分析</span></h3>
<p>让我们给出一个简单的分析。假设我们有天气数据X和对应的标签 <span class="math inline">\(\mathrm{y}\)</span>,
现在希望实现一个可以预测明天天气的模型 <span class="math inline">\(\psi\)</span> 。但我们并不知道用什么算法效果最好,
于是尝试了十种算法, 包括</p>
<ul>
<li>算法1: 逻辑回归- <span class="math inline">\(C_1\)</span></li>
<li>算法2: 支持向量机 (SVM) - <span class="math inline">\(C_2\)</span></li>
<li>...</li>
<li>算法10: 随机森林 - <span class="math inline">\(C_{10}\)</span></li>
</ul>
<p>结果发现他们表现都一般，在验证集上的误分率比较高。我们现在期待找到一种方法，可以有效提高最终预测结果。</p>
<h3><span id="二-平均法投票法"><strong>二、 平均法/投票法</strong></span></h3>
<p>一种比较直白的方法就是对让 10 个算法模型同时对需要预测的数据进行预测,
并对结果取平均数/众数。假设 10 个 分类器对于测试数据 <span class="math inline">\(X_t\)</span> 的预测结果是 <span class="math inline">\(\left[C_1\left(X_t\right), C_2\left(X_t\right),
\ldots, C_{10}\left(X_t\right)\right]=[0,1,1,1,1,1,0,1,1,0]\)</span>
，那很显然少数服 从多数, 我们应该选择1作为 <span class="math inline">\(X_t\)</span>
的预测结果。如果取平均值的话也可以那么会得到 0.7 , 高于阈值 0.5 ,
因此是等 价的。</p>
<p>但这个时候需要有几个注意的地方：</p>
<p><strong>首先，不同分类器的输出结果取值范围不同</strong>，不一定是[0,1]，而可以是无限定范围的值。举例，逻辑回归的输出范围是0-1（概率），而k-近邻的输出结果可以是大于0的任意实数，其他算法的输出范围可能是负数。<strong>因此整合多个分类器时，需要注意不同分类器的输出范围，并统一这个取值范围</strong>。</p>
<ul>
<li>比如可以先转化为如<strong>二分类结果</strong>，把输出的范围统一后再进行整合。但这种方法的问题在于我们丢失了很多信息，0.5和0.99都会被转化为1，但明显其可靠程度差别很大。</li>
<li>也可以转化为排序（ranking），再对不同的ranking进行求平均。</li>
<li>更加稳妥的方法是对每个分类器的输出结果做标准化，也就是调整到正态分布上去。之后就可以对多个调整后的结果进行整合。同理，用归一化也可以有类似的效果。</li>
</ul>
<p><strong>其次，就是整合稳定性的问题</strong>。采用平均法的另一个风险在于可能被极值所影响。正态分布的取值是
<span class="math inline">\([-\infty,+\infty]\)</span>
，在少数情况下平均值会受到少数极值的影响。一个常见的解决方法是，用中位数（median)来代替平均数进行整合。</p>
<p><strong>同时，模型整合面临的另一个问题是子模型良莠不齐</strong>。如果10个模型中有1个表现非常差，那么会拖累最终的效果，适得其反。<font color="red">因此，简单、粗暴的把所有子模型通过平均法整合起来效果往往一般。</font></p>
<h3><span id="三-寻找优秀的子模型准而不同">三、寻找优秀的子模型准而不同</span></h3>
<p>不难看出，一个较差的子模型会拖累整体的集成表现，那么这就涉及到另一个问题？什么样的子模型是优秀的。</p>
<p>一般来说，我们希望子模型：<strong>准而不同 -&gt; accurate but
diversified</strong>。好的子模型应该首先是准确的，这样才会有所帮助。其次不同子模型间应该有差别，比如独立的误差，这样作为一个整体才能起到<strong>互补作用</strong>。</p>
<p>因此，如果想实现良好的结合效果，就必须对子模型进行筛选，去粗取精。在这里我们需要做出一点解释，我们今天说的融合方法和bagging还有boosting中的思路不大相同。<font color="red">bagging和boosting中的子模型都是<strong>很简单的且基数庞大</strong>，而我们今天的模型融合是<strong>结合少量但较为复杂的模型</strong>。</font></p>
<h3><span id="四-筛选方法赋予不同子模型不同的权重"><strong>四、筛选方法：赋予不同子模型不同的权重</strong></span></h3>
<p>因此我们不能再简单的取平均了,
而应该给优秀的子模型更大的权重。在这种前提下, 一个比较直白的方法就是根
据子<strong>模型的准确率给出一个参考权重</strong> <span class="math inline">\(w\)</span> ，子模型越准确那么它的权重就更大,
对于最终预测的影响就更强: <span class="math inline">\(w_i=\frac{A c
c\left(C_i\right)}{\sum_1^{10} A c c\left(C_j\right)}\)</span>
。简单取平均是这个方法的一个特例, 即假设子模型准确率一致。</p>
<h3><span id="五-更进一步学习分类器权重"><strong>五、更进一步：学习分类器权重</strong></span></h3>
<p>在4中提到的方法在一定程度上可以缓解问题，但效果有限。那么另一个思路是，我们是否可以学习每个分类器的权重呢？</p>
<p>答案是肯定，这也就是Stacking的核心思路。通过增加一层来学习子模型的权重。</p>
<figure>
<img src="https://pic3.zhimg.com/v2-13396e65c2bcc1c270ca536310686d07_720w.jpg?source=d16d100b" alt="img">
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>图片来源</strong>：https://www.quora.com/What-is-stacking-in-machine-learning</p>
<p>更多有关于stacking的讨论可以参考我最近的文章：<font color="blue">集成学习总结-Stacking和神经网络</font>。简单来说，就是加一层逻辑回归或者SVM，把子模型的输出结果当做训练数据，来自动赋予不同子模型不同的权重。</p>
<p><font color="red"><strong>一般来看，这种方法只要使用得当，效果应该比简单取平均值、或者根据准确度计算权重的效果会更好。</strong></font></p>
<h3><span id="参考文献">参考文献</span></h3>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/33589222">「融合」机器学习模型：一种提升预测能力的方法</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/R9HZV9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/R9HZV9/" class="post-title-link" itemprop="url">局部敏感哈希LSH</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-05-06 10:05:54 / 修改时间：10:56:38" itemprop="dateCreated datePublished" datetime="2022-05-06T10:05:54+08:00">2022-05-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%B7%A5%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">【draft】工程</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%B7%A5%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">大数据处理</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="一-局部敏感哈希函数">一、局部敏感哈希函数</span></h2>
<blockquote>
<p>python_mmdt:ssdeep、tlsh、vhash、mmdthash对比 :
https://www.freebuf.com/sectool/321011.html</p>
<p>局部敏感哈希(Locality Sensitive
Hashing，LSH)总结：http://yangyi-bupt.github.io/ml/2015/08/28/lsh.html</p>
</blockquote>
<h3><span id="11-局部敏感哈希的基本概念">1.1 局部敏感哈希的基本概念</span></h3>
<p>局部敏感哈希(Locality Sensitive
Hashing，LSH)的基本思想类似于一种空间域转换思想，LSH算法基于一个假设，<strong>如果两个文本在原有的数据空间是相似的，那么分别经过哈希函数转换以后的它们也具有很高的相似度</strong>；相反，如果它们本身是不相似的，那么经过转换后它们应仍不具有相似性。</p>
<h3><span id="12-hash方法">1.2 hash方法</span></h3>
<p><strong><a target="_blank" rel="noopener" href="https://ssdeep-project.github.io/ssdeep/index.html">CTPH(ssdeep)</a>：Context
Triggered Piecewise Hashes(CTPH)</strong>，又叫模糊哈希，最早由Jesse
Kornblum博士在2006年提出，论文地址点击<a target="_blank" rel="noopener" href="https://ssdeep-project.github.io/ssdeep/index.html">这里</a>。CTPH可用于文件/数据的<strong>同源性判定</strong>。据官方文档介绍，其计算速度是<code>tlsh</code>的两倍（测试了一下，好像并没有）。</p>
<blockquote>
<p>当使用传统的加密散列时，会为整个文件创建一个散列。单个位的变化会对输出哈希值产生雪崩效应。另一方面，CTPH
为文件的多个固定大小段计算多个传统加密哈希。它使用<em>滚动哈希</em>。</p>
</blockquote>
<p><strong><a target="_blank" rel="noopener" href="https://tlsh.org/index.html">tlsh</a>：是趋势科技开源的一款模糊哈希计算工具</strong>，将50字节以上的数据计算生成一个哈希值，通过计算哈希值之间的相似度，从而得到原始文件之间的同源性关联。据官方文档介绍，<code>tlsh</code>比<code>ssdeep</code>和<code>sdhash</code>等其他模糊哈希算法更难攻击和绕过。</p>
<p><a target="_blank" rel="noopener" href="https://developers.virustotal.com/reference/files">vhash</a>：（翻遍了整个virustotal的文档，就找到这么一句话）“an
in-house similarity clustering algorithm value, based on a simple
structural feature hash allows you to find similar
files”，大概就是说是个内部相似性聚类算法，允许你通过这个简单的值，找到相似的样本。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/a232319779/python_mmdt">mmdthash</a>：是开源的一款模糊哈希计算工具，将任意数据计算生成一个模糊哈希值，通过计算模糊哈希值之间的相似度，从而判断两个数据之间的关联性。详情前文1-5篇。</p>
<blockquote>
<p>#### mmdthash：</p>
<p>通过重采样之后的数据，我们假设其满足独立同分布。同时，我们将重采样的数据，平均分成N块，每块之间的数据进行累计求和，和值分布近似服从正态分布，我们取和值高x位的一个byte做为本块数据的敏感哈希值。</p>
<p>51030000:D6E26822530202020202020202020202：</p>
<ul>
<li><code>51030000</code>是4字节<strong>索引</strong>敏感哈希</li>
<li><code>D6E26822530202020202020202020202</code>是16字节敏感哈希</li>
</ul>
</blockquote>
<h3><span id="13-应用">1.3 应用</span></h3>
<p>简单应用如，索引敏感哈希可以转成一个int32的数字，当<strong>索引敏感哈希相等</strong>时，<strong>再比较敏感哈希的距离</strong>（如曼哈顿距离，将敏感哈希转成N个<code>unsigned char</code>类型计算敏感哈希，此时<code>00</code>和<code>FF</code>之间的距离可算作1，也可算作255，具体看实现）。</p>
<p>由于特征向量的维度是固定的，因此可以很方便的使用其他数学方法，进行大规模计算。</p>
<ul>
<li>如结合矩阵运算，快速得到上万特征向量（样本）的相似度矩阵，</li>
<li>如用于机器学习的分类（KNN）、聚类（Kmeans）等</li>
</ul>
<h3><span id></span></h3>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/1G5MF0A/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/1G5MF0A/" class="post-title-link" itemprop="url">风控算法（1）字节-色情导流用户识别</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-04 11:28:30" itemprop="dateCreated datePublished" datetime="2022-05-04T11:28:30+08:00">2022-05-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-18 20:38:59" itemprop="dateModified" datetime="2023-04-18T20:38:59+08:00">2023-04-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">【draft】应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E7%AE%97%E6%B3%95%E6%AF%94%E8%B5%9B/" itemprop="url" rel="index"><span itemprop="name">算法比赛</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E7%AE%97%E6%B3%95%E6%AF%94%E8%B5%9B/%E4%B8%9A%E5%8A%A1%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">业务安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>1.4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1><span id="字节跳动安全ai挑战赛-大佬等等我">字节跳动安全AI挑战赛-大佬等等我</span></h1>
<ul>
<li><strong>比赛链接</strong>：https://security.bytedance.com/fe/ai-challenge#/challenge
<ul>
<li>基于文本和多模态数据的风险识别
<ul>
<li>电商黄牛地址识别</li>
<li><strong>色情导流用户识别</strong></li>
</ul></li>
<li>小样本半监督风险识别
<ul>
<li>人机识别</li>
<li>少样本作弊样本检测任务</li>
</ul></li>
</ul></li>
</ul>
<h2><span id="色情导流用户识别">色情导流用户识别</span></h2>
<blockquote>
<p>色情导流赛道 2ndSolution
https://github.com/rooki3ray/2021BytedanceSecurityAICompetition_track1</p>
</blockquote>
<h3><span id="一-赛题描述">一、赛题描述</span></h3>
<p>随着互联网的快速发展，网络黑产特别是色情导流也日益增多，给用户带来了极大的伤害。色情导流用户发布色情/低俗内容吸引用户，并且通过二维码、联系方式、短网址等完成导流。本赛题旨在通过提供用户相关数据，运用机器学习等方法对色情导流用户进行识别，提高模型检测的效果。</p>
<ul>
<li>输入：<strong>用户的特征，包括基础信息、投稿信息、行为信息</strong>。</li>
<li>输出：用户的标签（1表示色情导流用户，0表示正常用户）</li>
<li><strong>评价指标</strong>采用fβ（取β=0.3） <span class="math display">\[ f_{\beta} = (1 + \beta^2)\frac{p*r}{\beta^2*p+r}
\]</span></li>
</ul>
<h4><span id="基础信息">基础信息</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182038415.png" alt="image-20220629211352351" style="zoom:50%;"></p>
<h4><span id="投稿信息">投稿信息</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182038486.png" alt="image-20220629211559660" style="zoom:50%;"></p>
<h4><span id="行为信息">行为信息</span></h4>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182038131.png" alt="image-20220629211703172" style="zoom:50%;"></p>
<h3><span id="二-数据构成">二、数据构成</span></h3>
<ul>
<li>用户基础信息
<ul>
<li>性别、粉丝数、个签、关注人数……</li>
</ul></li>
<li>用户投稿信息
<ul>
<li>视频标题、poi、省份、投稿时间</li>
</ul></li>
<li>用户行为信息
<ul>
<li>播放次数、点赞数、分享数……</li>
</ul></li>
</ul>
<h3><span id="三-方案说明">三、方案说明</span></h3>
<ul>
<li><strong>特征工程</strong>
<ul>
<li><strong>log1p 数据平滑</strong></li>
<li>类别特征（<strong>LabelEncoder</strong>）</li>
<li>时间特征（<strong>min-max 归一化</strong>）</li>
<li>文本特征（长度、WordVec）</li>
<li>交叉特征</li>
</ul></li>
<li><strong>模型训练</strong>
<ul>
<li>10折lgb交叉验证，均值作为预测结果</li>
<li>伪标签</li>
</ul></li>
<li>最终分数线上第二（0.9906）。</li>
</ul>
<h3><span id="四-代码结构">四、代码结构</span></h3>
<blockquote>
<p>from config import Config</p>
<p>import argparse</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── 1_word2vec.py</span><br><span class="line">├── 2_merge_data.py</span><br><span class="line">├── 3_5_train_kfold.py</span><br><span class="line">├── 4_pseudo_label.py</span><br><span class="line">├── config.py</span><br><span class="line">├── data</span><br><span class="line">│   ├── pseudo.csv</span><br><span class="line">│   ├── raw</span><br><span class="line">│   │   ├── 测试数据</span><br><span class="line">│   │   └── 训练数据</span><br><span class="line">│   ├── sentence</span><br><span class="line">│   │   └── signature</span><br><span class="line">│   ├── test.csv</span><br><span class="line">│   ├── train.csv</span><br><span class="line">│   └── ...</span><br><span class="line">├── evaluate_kfold.py</span><br><span class="line">├── __pycache__</span><br><span class="line">├── readme.md</span><br><span class="line">├── requirements.txt</span><br><span class="line">├── run.sh</span><br><span class="line">├── saved</span><br><span class="line">│   ├── <span class="number">1112_1315_0.985_0</span><span class="number">.9934</span></span><br><span class="line">│   │   └── ...</span><br><span class="line">│   ├── <span class="number">1112_1320_0.985</span>_pseudo_0<span class="number">.9934</span></span><br><span class="line">│   │   └── ...</span><br><span class="line">│   ├── 1112_1321_pseudo_0<span class="number">.985_0</span><span class="number">.9942</span></span><br><span class="line">│   │   ├── <span class="number">1112_1321_0.985</span>_results_kfold_0<span class="number">.9942</span>.csv</span><br><span class="line">│   │   ├── log.log</span><br><span class="line">│   │   └── ...</span><br><span class="line">└── utils.py</span><br></pre></td></tr></table></figure>
<h4><span id="41-runsh">4.1 run.sh</span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> -x</span><br><span class="line">python 1_word2vec.py</span><br><span class="line">python 2_merge_data.py</span><br><span class="line">python 3_5_train_kfold.py</span><br><span class="line">python 4_pseudo_label.py</span><br><span class="line">python 3_5_train_kfold.py --pseudo</span><br></pre></td></tr></table></figure>
<h4><span id="42-1_word2vecpy">4.2 1_word2vec.py</span></h4>
<h4><span id="43-5_train_kfoldpy">4.3 <strong>5_train_kfold.py</strong></span></h4>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/1CE2BYX/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/1CE2BYX/" class="post-title-link" itemprop="url">风控算法（2）字节-小样本半监督风险识别</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-04 11:28:30" itemprop="dateCreated datePublished" datetime="2022-05-04T11:28:30+08:00">2022-05-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-18 20:39:52" itemprop="dateModified" datetime="2023-04-18T20:39:52+08:00">2023-04-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">【draft】应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E7%AE%97%E6%B3%95%E6%AF%94%E8%B5%9B/" itemprop="url" rel="index"><span itemprop="name">算法比赛</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E7%AE%97%E6%B3%95%E6%AF%94%E8%B5%9B/%E4%B8%9A%E5%8A%A1%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">业务安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>15k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>28 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="字节跳动安全ai挑战赛-大佬等等我">字节跳动安全AI挑战赛-大佬等等我</span></h2>
<ul>
<li><strong>比赛链接</strong>：https://security.bytedance.com/fe/ai-challenge#/challenge
<ul>
<li>基于文本和多模态数据的风险识别
<ul>
<li>电商黄牛地址识别</li>
<li><strong>色情导流用户识别</strong></li>
</ul></li>
<li>小样本半监督风险识别
<ul>
<li>人机识别</li>
<li>少样本作弊样本检测任务</li>
</ul></li>
</ul></li>
<li><strong>人工智能竞赛复盘：2021安全AI挑战赛</strong>
:https://www.bilibili.com/video/BV1PL4y1n7SN?spm_id_from=333.337.search-card.all.click&amp;vd_source=29387dc08d18f642078183a6816e93e8</li>
<li><strong>炼丹术士Zoro</strong>:https://www.zhihu.com/people/AIMuseum/posts</li>
<li><strong>字节跳动安全AI挑战赛直播笔记</strong> - 知乎
https://zhuanlan.zhihu.com/p/435018506</li>
</ul>
<h2><span id="小样本半监督风险识别">小样本半监督风险识别</span></h2>
<h3><span id="一-赛题描述">一、赛题描述</span></h3>
<p>在真实的社交网络中，存在的作弊用户会影响社交网络平台。在真实场景中，会受到多方面的约束，我们仅能获取到少部分的作弊样本和一部分正常用户样本，<strong>现需利用已有的少量带标签的样本，去挖掘大量未知样本中的剩余作弊样本</strong>。给定一段时间内的样本，其中包含少量作弊样本，部分正常样本以及标签未知的样本。参赛者应该利用这段时间内已有的数据，提出自己的解决方案，以预测标签未知的样本是否为作弊样本。数据处理方法和算法不限，但是参赛者需要综合考虑算法的效果和复杂度，从而构建合理的解决方案。</p>
<h4><span id="11-赛题数据与评价指标">1.1 赛题数据与评价指标</span></h4>
<p><strong>赛题数据</strong>：本次比赛给出的数据是T～T+N
时刻内点赞、关注事件下按比例抽样数据以及其对应账号的基础特征数据。</p>
<p><strong>评价指标</strong>：本赛题使用F1-score来评估模型的准召程度</p>
<h3><span id="二-解决方案一">二、 解决方案一</span></h3>
<p>首先明确本赛题实质上仍然是一个二分类的问题，我们也可以完全从此角度出来先构建出一个基础分类模型，然后再<strong>利用大量无标签的数据进行半监督学习来提升模型性能</strong>。</p>
<blockquote>
<p><strong>风险识别：第二名源代码</strong>
https://github.com/Ljwccc/ByteDanceSecurityAI</p>
<ul>
<li>用户侧特征：
<ul>
<li>账户本身的基础特征</li>
<li>账户本身的特征计数统计</li>
<li>粉丝量、关注量、发帖量、被点赞量、最后登陆时间-注册时间
乘除交叉</li>
<li>从请求数据中提取出来的device_type, app_version,
app_channel类别特征，直接作为静态画像使用</li>
<li>类别特征下的数值统计特征 min/sum/max/std</li>
</ul></li>
<li>请求侧特征：
<ul>
<li>用户请求的时间序列特征, 时间差序列特征 min/sum/max/std</li>
<li>w2v特征， 每个用户的请求ip序列建模</li>
</ul></li>
</ul>
</blockquote>
<h3><span id="21-特征工程">2.1 特征工程</span></h3>
<p>从序列特征中提取用户的设备信息、channel信息和app_version信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先 group</span></span><br><span class="line">user_request_cat_group = user_request.groupby([<span class="string">&#x27;request_user&#x27;</span>],as_index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">user_request_device_type = user_request_cat_group[<span class="string">&#x27;request_device_type&#x27;</span>].agg(&#123;<span class="string">&#x27;device_type_list&#x27;</span>:<span class="built_in">list</span>&#125;)</span><br><span class="line">user_request_channel = user_request_cat_group[<span class="string">&#x27;request_app_channel&#x27;</span>].agg(&#123;<span class="string">&#x27;channel_list&#x27;</span>:<span class="built_in">list</span>&#125;)</span><br><span class="line">user_request_app_version = user_request_cat_group[<span class="string">&#x27;request_app_version&#x27;</span>].agg(&#123;<span class="string">&#x27;app_version_list&#x27;</span>:<span class="built_in">list</span>&#125;)</span><br><span class="line"></span><br><span class="line">user_request_device_type[<span class="string">&#x27;device_type&#x27;</span>] = user_request_device_type[<span class="string">&#x27;device_type_list&#x27;</span>].apply(<span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line">user_request_channel[<span class="string">&#x27;channel&#x27;</span>] = user_request_channel[<span class="string">&#x27;channel_list&#x27;</span>].apply(<span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line">user_request_app_version[<span class="string">&#x27;app_version&#x27;</span>] = user_request_app_version[<span class="string">&#x27;app_version_list&#x27;</span>].apply(<span class="keyword">lambda</span> x:x[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">user_feat_from_action = pd.concat([user_request_device_type[[<span class="string">&#x27;request_user&#x27;</span>,<span class="string">&#x27;device_type&#x27;</span>]],user_request_channel[[<span class="string">&#x27;channel&#x27;</span>]], user_request_app_version[[<span class="string">&#x27;app_version&#x27;</span>]]],axis=<span class="number">1</span>).rename(columns=&#123;<span class="string">&#x27;request_user&#x27;</span>:<span class="string">&#x27;user&#x27;</span>&#125;)</span><br></pre></td></tr></table></figure>
<h4><span id="211-用户基础特征">2.1.1 用户基础特征</span></h4>
<p>类别特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 类别特征</span></span><br><span class="line">cat_cols = [<span class="string">&#x27;user_name&#x27;</span>,<span class="string">&#x27;user_profile&#x27;</span>,<span class="string">&#x27;user_register_type&#x27;</span>,<span class="string">&#x27;user_register_app&#x27;</span>,<span class="string">&#x27;user_least_login_app&#x27;</span>,<span class="string">&#x27;user_freq_ip&#x27;</span>,<span class="string">&#x27;user_freq_ip_3&#x27;</span>,<span class="string">&#x27;device_type&#x27;</span>,<span class="string">&#x27;channel&#x27;</span>,<span class="string">&#x27;app_version&#x27;</span>,<span class="string">&#x27;user_freq_ip_2&#x27;</span>,<span class="string">&#x27;user_freq_ip_1&#x27;</span>,]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手工类别特征</span></span><br><span class="line">user_info[<span class="string">&#x27;user_freq_ip_3&#x27;</span>] = user_info[<span class="string">&#x27;user_freq_ip&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="string">&#x27;.&#x27;</span>.join(<span class="built_in">str</span>(x).split(<span class="string">&#x27;.&#x27;</span>)[:<span class="number">3</span>])) <span class="comment"># 常用ip取前3位</span></span><br><span class="line">user_info[<span class="string">&#x27;user_freq_ip_2&#x27;</span>] = user_info[<span class="string">&#x27;user_freq_ip&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="string">&#x27;.&#x27;</span>.join(<span class="built_in">str</span>(x).split(<span class="string">&#x27;.&#x27;</span>)[:<span class="number">2</span>])) <span class="comment"># 常用ip取前2位</span></span><br><span class="line">user_info[<span class="string">&#x27;user_freq_ip_1&#x27;</span>] = user_info[<span class="string">&#x27;user_freq_ip&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="string">&#x27;.&#x27;</span>.join(<span class="built_in">str</span>(x).split(<span class="string">&#x27;.&#x27;</span>)[:<span class="number">1</span>])) <span class="comment"># 常用ip取前1位</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并从request中提取的基础特征</span></span><br><span class="line">user_info = user_info.merge(user_feat_from_action,on=<span class="string">&#x27;user&#x27;</span>,how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line"><span class="keyword">del</span> user_feat_from_action</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类别特征的频次</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cat_cols:</span><br><span class="line">    user_info = freq_enc(user_info,col)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 对所有类别特征做label_encoder</span></span><br><span class="line">user_info = label_enc(user_info,cat_cols)</span><br></pre></td></tr></table></figure>
<p>点赞量，关注量等交叉特征，直接梭哈所有乘除法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">num_cols = [<span class="string">&#x27;user_fans_num&#x27;</span>,<span class="string">&#x27;user_follow_num&#x27;</span>,<span class="string">&#x27;user_post_num&#x27;</span>,<span class="string">&#x27;user_post_like_num&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col1 <span class="keyword">in</span> num_cols:</span><br><span class="line">    <span class="keyword">for</span> col2 <span class="keyword">in</span> [col <span class="keyword">for</span> col <span class="keyword">in</span> num_cols <span class="keyword">if</span> col!=col1]:</span><br><span class="line">        user_info[<span class="string">f&#x27;<span class="subst">&#123;col1&#125;</span>_<span class="subst">&#123;col2&#125;</span>_mul&#x27;</span>] = user_info[col1]*user_info[col2]</span><br><span class="line">        user_info[<span class="string">f&#x27;<span class="subst">&#123;col1&#125;</span>_<span class="subst">&#123;col2&#125;</span>_div&#x27;</span>] = user_info[col1]/(user_info[col2]+<span class="number">1e-3</span>)</span><br></pre></td></tr></table></figure>
<p>类别特征下粉丝量、关注量、发帖量、被点赞量、请求数量的统计值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">num_cols = [<span class="string">&#x27;user_fans_num&#x27;</span>,<span class="string">&#x27;user_follow_num&#x27;</span>,<span class="string">&#x27;user_post_num&#x27;</span>,<span class="string">&#x27;user_post_like_num&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> cat_col <span class="keyword">in</span> cat_cols:</span><br><span class="line">    cat_group = user_info.groupby(cat_col)[num_cols]</span><br><span class="line">    <span class="comment"># 平均值</span></span><br><span class="line">    cat_col_stat = cat_group.transform(np.mean)</span><br><span class="line">    cat_col_stat.rename(columns=&#123;name:<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span>_<span class="subst">&#123;cat_col&#125;</span>_mean&#x27;</span> <span class="keyword">for</span> name <span class="keyword">in</span> cat_col_stat.columns&#125;,inplace=<span class="literal">True</span>)</span><br><span class="line">    user_info = pd.concat([user_info,cat_col_stat],axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 和</span></span><br><span class="line">    cat_col_stat = cat_group.transform(np.<span class="built_in">sum</span>)</span><br><span class="line">    cat_col_stat.rename(columns=&#123;name:<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span>_<span class="subst">&#123;cat_col&#125;</span>_sum&#x27;</span> <span class="keyword">for</span> name <span class="keyword">in</span> cat_col_stat.columns&#125;,inplace=<span class="literal">True</span>)</span><br><span class="line">    user_info = pd.concat([user_info,cat_col_stat],axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 方差</span></span><br><span class="line">    cat_col_stat = cat_group.transform(np.std)</span><br><span class="line">    cat_col_stat.rename(columns=&#123;name:<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span>_<span class="subst">&#123;cat_col&#125;</span>_std&#x27;</span> <span class="keyword">for</span> name <span class="keyword">in</span> cat_col_stat.columns&#125;,inplace=<span class="literal">True</span>)</span><br><span class="line">    user_info = pd.concat([user_info,cat_col_stat],axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">del</span> cat_col_stat</span><br></pre></td></tr></table></figure>
<h4><span id="212-序列特征">2.1.2 序列特征</span></h4>
<p><strong>用户请求序列特征</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">user_request_list = user_request.groupby([<span class="string">&#x27;request_user&#x27;</span>],as_index=<span class="literal">False</span>)[<span class="string">&#x27;request_target&#x27;</span>].agg(&#123;<span class="string">&#x27;request_list&#x27;</span>:<span class="built_in">list</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 先按照时间进行排序</span></span><br><span class="line">user_request = user_request.sort_values(by=<span class="string">&#x27;request_time&#x27;</span>,)</span><br><span class="line"><span class="comment"># 请求的数量</span></span><br><span class="line">user_action_feat = user_request.groupby([<span class="string">&#x27;request_user&#x27;</span>],as_index=<span class="literal">False</span>)[<span class="string">&#x27;request_user&#x27;</span>].agg(&#123;<span class="string">&#x27;request_num&#x27;</span>:<span class="string">&#x27;count&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户请求的时间统计量，但是80%的用户只有一次请求行为</span></span><br><span class="line">user_action_feat_temp = user_request.groupby([<span class="string">&#x27;request_user&#x27;</span>],as_index=<span class="literal">False</span>)[<span class="string">&#x27;request_time&#x27;</span>].agg(&#123;<span class="string">&#x27;time_list&#x27;</span>:<span class="built_in">list</span>&#125;)</span><br><span class="line">user_action_feat = user_action_feat.merge(user_action_feat_temp,on=<span class="string">&#x27;request_user&#x27;</span>,how=<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">user_action_feat[<span class="string">&#x27;time_min&#x27;</span>] = user_action_feat[<span class="string">&#x27;time_list&#x27;</span>].apply(<span class="built_in">min</span>)</span><br><span class="line">user_action_feat[<span class="string">&#x27;time_max&#x27;</span>] = user_action_feat[<span class="string">&#x27;time_list&#x27;</span>].apply(<span class="built_in">max</span>)</span><br><span class="line">user_action_feat[<span class="string">&#x27;time_var&#x27;</span>] = user_action_feat[<span class="string">&#x27;time_list&#x27;</span>].apply(np.var)</span><br><span class="line">user_action_feat[<span class="string">&#x27;time_max-min&#x27;</span>] = user_action_feat[<span class="string">&#x27;time_list&#x27;</span>].apply(<span class="keyword">lambda</span> x:np.<span class="built_in">max</span>(x)-np.<span class="built_in">min</span>(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 时间间隔的平均值，最大值，最小值，方差</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">diff_value</span>(<span class="params">time</span>):</span><br><span class="line">    time_shift = <span class="built_in">list</span>(time[<span class="number">1</span>:])</span><br><span class="line">    time_shift.append(time[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    diff_time = time_shift-time</span><br><span class="line">    <span class="keyword">return</span> diff_time</span><br><span class="line">user_action_feat[<span class="string">&#x27;diff_time&#x27;</span>] = user_action_feat[<span class="string">&#x27;time_list&#x27;</span>].apply(<span class="keyword">lambda</span> x: diff_value(np.array(x)))</span><br><span class="line">user_action_feat[<span class="string">&#x27;diff_time_max&#x27;</span>] = user_action_feat[<span class="string">&#x27;diff_time&#x27;</span>].apply(<span class="built_in">max</span>)</span><br><span class="line">user_action_feat[<span class="string">&#x27;diff_time_var&#x27;</span>] = user_action_feat[<span class="string">&#x27;diff_time&#x27;</span>].apply(np.var)</span><br><span class="line">user_action_feat[<span class="string">&#x27;diff_time_mean&#x27;</span>] = user_action_feat[<span class="string">&#x27;diff_time&#x27;</span>].apply(np.mean)</span><br><span class="line">user_action_feat[<span class="string">&#x27;diff_time_min&#x27;</span>] = user_action_feat[<span class="string">&#x27;diff_time&#x27;</span>].apply(<span class="built_in">min</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>用户请求序列做一个embedding</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">sentences = user_request_list[<span class="string">&#x27;request_list&#x27;</span>].values.tolist()</span><br><span class="line">emb_size = <span class="number">64</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sentences)):</span><br><span class="line">    sentences[i] = [<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> sentences[i]]  <span class="comment"># 数字转化为字符串用于训练w2v</span></span><br><span class="line"></span><br><span class="line">model = Word2Vec(sentences, size=emb_size, window=<span class="number">5</span>, min_count=<span class="number">5</span>, sg=<span class="number">0</span>, hs=<span class="number">0</span>, seed=<span class="number">1</span>, <span class="built_in">iter</span>=<span class="number">5</span>, workers=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">emb_matrix = []</span><br><span class="line"><span class="keyword">for</span> seq <span class="keyword">in</span> sentences:</span><br><span class="line">    vec = []</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> seq:</span><br><span class="line">        <span class="keyword">if</span> w <span class="keyword">in</span> model.wv.vocab:</span><br><span class="line">            vec.append(model.wv[w])</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(vec) &gt; <span class="number">0</span>:</span><br><span class="line">        emb_matrix.append(np.mean(vec, axis=<span class="number">0</span>))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        emb_matrix.append([<span class="number">0</span>] * emb_size)</span><br><span class="line">emb_matrix = np.array(emb_matrix)</span><br><span class="line"></span><br><span class="line">emb_size = <span class="number">64</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(emb_size):</span><br><span class="line">    user_request_list[<span class="string">&#x27;action_emb_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i)] = emb_matrix[:, i]</span><br><span class="line"></span><br><span class="line">user_request_list = user_request_list.drop([<span class="string">&#x27;request_list&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">user_action_feat = user_action_feat.merge(user_request_list,how=<span class="string">&#x27;left&#x27;</span>,on=<span class="string">&#x27;request_user&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>合并基础特征和序列特征</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">user_info = user_info.merge(user_action_feat,how=<span class="string">&#x27;left&#x27;</span>,on=<span class="string">&#x27;user&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3><span id="22-模型训练">2.2 模型训练</span></h3>
<h4><span id="221-交叉验证">2.2.1 交叉验证</span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">folds = KFold(n_splits=<span class="number">10</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">546789</span>)</span><br><span class="line">oof_preds, test_preds, importances = train_model_cat(train, test, y, folds, cat_cols)</span><br><span class="line"></span><br><span class="line">test_preds[<span class="string">&#x27;label&#x27;</span>] = test_preds[<span class="string">&#x27;label&#x27;</span>].apply(<span class="keyword">lambda</span> x:<span class="number">0</span> <span class="keyword">if</span> x&lt;<span class="number">0.4</span> <span class="keyword">else</span> <span class="number">1</span>)</span><br><span class="line">test_preds = test_preds.drop_duplicates(subset=[<span class="string">&#x27;user&#x27;</span>])   <span class="comment"># 去除相同的user</span></span><br><span class="line"><span class="comment"># 生成结果</span></span><br><span class="line">test_preds[[<span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]].to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>, header=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="222-模型训练">2.2.2 模型训练</span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">useless_cols = [<span class="string">&#x27;user&#x27;</span>,<span class="string">&#x27;user_status&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model_cat</span>(<span class="params">data_, test_, y_, folds_, cat_cols, semi_data_=<span class="literal">None</span></span>):</span><br><span class="line">    oof_preds = np.zeros(data_.shape[<span class="number">0</span>])  <span class="comment"># 验证集预测结果</span></span><br><span class="line">    sub_preds = np.zeros(test_.shape[<span class="number">0</span>])  <span class="comment"># 测试集预测结果</span></span><br><span class="line">    feature_importance_df = pd.DataFrame()</span><br><span class="line">    feats = [f <span class="keyword">for</span> f <span class="keyword">in</span> data_.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> useless_cols]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 半监督每批训练数据</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> semi_data_ <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        semi_num = semi_data_.shape[<span class="number">0</span>]/<span class="number">5</span></span><br><span class="line">        semi_y = semi_data_[<span class="string">&#x27;user_status&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> n_fold, (trn_idx, val_idx) <span class="keyword">in</span> <span class="built_in">enumerate</span>(folds_.split(data_)):</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> semi_data_ <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            semi_data_batch = semi_data_[feats].iloc[<span class="built_in">int</span>(n_fold*semi_num):<span class="built_in">int</span>((n_fold+<span class="number">1</span>)*semi_num)]</span><br><span class="line">            semi_y_batch = semi_y.iloc[<span class="built_in">int</span>(n_fold*semi_num):<span class="built_in">int</span>((n_fold+<span class="number">1</span>)*semi_num)]</span><br><span class="line">        </span><br><span class="line">            trn_x, trn_y = pd.concat([data_[feats].iloc[trn_idx],semi_data_batch]), pd.concat([y_.iloc[trn_idx],semi_y_batch])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]   <span class="comment"># 训练集数据</span></span><br><span class="line">            </span><br><span class="line">        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]   <span class="comment"># 验证集数据</span></span><br><span class="line">       </span><br><span class="line">        clf = CatBoostClassifier(</span><br><span class="line">            iterations=<span class="number">6000</span>,</span><br><span class="line">            learning_rate=<span class="number">0.08</span>,  <span class="comment"># 0.08</span></span><br><span class="line">            <span class="comment"># num_leaves=2**5,</span></span><br><span class="line">            eval_metric=<span class="string">&#x27;AUC&#x27;</span>,</span><br><span class="line">            task_type=<span class="string">&quot;CPU&quot;</span>,</span><br><span class="line">            loss_function=<span class="string">&#x27;Logloss&#x27;</span>,</span><br><span class="line">            colsample_bylevel = <span class="number">0.8</span>,</span><br><span class="line">            </span><br><span class="line">            subsample=<span class="number">0.9</span>,   <span class="comment"># 0.9</span></span><br><span class="line">            max_depth=<span class="number">7</span>,</span><br><span class="line">            reg_lambda = <span class="number">0.3</span>,</span><br><span class="line">            verbose=-<span class="number">1</span>,</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        clf.fit(trn_x, trn_y, </span><br><span class="line">                eval_set= [(trn_x, trn_y), (val_x, val_y)], </span><br><span class="line">                verbose_eval=<span class="number">300</span>, early_stopping_rounds=<span class="number">100</span>,  <span class="comment"># 这个参数有点小，可以再大一点</span></span><br><span class="line">                cat_features = cat_cols</span><br><span class="line">               )</span><br><span class="line">        oof_preds[val_idx] = clf.predict_proba(val_x)[:, <span class="number">1</span>]   <span class="comment"># 验证集结果</span></span><br><span class="line">        </span><br><span class="line">        sub_preds += clf.predict_proba(test_[feats])[:, <span class="number">1</span>] / folds_.n_splits  <span class="comment"># 测试集结果</span></span><br><span class="line">        </span><br><span class="line">        fold_importance_df = pd.DataFrame()</span><br><span class="line">        fold_importance_df[<span class="string">&quot;feature&quot;</span>] = feats</span><br><span class="line">        fold_importance_df[<span class="string">&quot;importance&quot;</span>] = clf.feature_importances_</span><br><span class="line">        fold_importance_df[<span class="string">&quot;fold&quot;</span>] = n_fold + <span class="number">1</span></span><br><span class="line">        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Fold %2d AUC : %.6f&#x27;</span> % (n_fold + <span class="number">1</span>, roc_auc_score(val_y, oof_preds[val_idx])))</span><br><span class="line">        <span class="keyword">del</span> clf, trn_x, trn_y, val_x, val_y</span><br><span class="line">        gc.collect()</span><br><span class="line">    </span><br><span class="line">    oof_preds = [<span class="number">1</span> <span class="keyword">if</span> i &gt;= <span class="number">0.4</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> oof_preds]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Full F1 score %.6f&#x27;</span> % f1_score(y_, oof_preds))</span><br><span class="line">    test_[<span class="string">&#x27;label&#x27;</span>] = sub_preds</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> oof_preds, test_[[<span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;label&#x27;</span>]], feature_importance_df</span><br></pre></td></tr></table></figure>
<h2><span id="三-解决方案二">三、<strong>解决方案二</strong></span></h2>
<ul>
<li><strong>基于账户本身基础特征</strong>，可以做这些类别特征的计数统计、对于粉丝量等数值特征可以做除法的交叉、登录时间和注册时间特征可以做减法交叉，基于请求行为，我们可以对机型、ip、app_version、app_channel做频数统计</li>
<li><strong>基于用户的请求行为序列</strong>，我们可以构建w2v特征(把用户请求行为序列看成句子，行为看作词，训练Word2Vec模型得到每个行为的表征</li>
<li><strong>基于用户的请求时间</strong>，我们可以计算请求时间的均值方差、请求时间间隔的统计特征等等。</li>
</ul>
<h2><span id="四-anovel-framework-for-social-bots-detection-in-online-social-networksbased-on-graph-embedding-and-community-detection">四、A
Novel Framework for Social Bots Detection in Online Social Networks
Based on Graph Embedding and Community Detection</span></h2>
<h3><span id="摘要">摘要</span></h3>
<p>随着在线社交网络的广泛普及，近年来用户数量也呈指数级增长。与此同时，社交机器人，即由程序控制的账户，也在上升。OSN的服务提供商经常使用它们来保持社交网络的活跃。与此同时，一些社交机器人也出于恶意目的注册。有必要检测这些恶意社交机器人，以呈现真实的舆论环境。我们提出了BotFinder，一个在OSN中检测恶意社交机器人的框架。具体来说，<strong>它将机器学习和图方法相结合</strong>，以便有效地提取社交机器人的潜在特征。关于特征工程，我们生成二阶特征，并使用编码方法对具有高基数的变量进行编码。这些特征充分利用了标记和未标记的样本。对于图，我们首先通过嵌入方法生成节点向量，然后进一步计算人类和机器人向量之间的相似性；然后，我们使用无监督的方法扩散标签，从而再次提高性能。为了验证该方法的性能，我们在由800多万条用户记录组成的人工竞赛提供的数据集上进行了广泛的实验。结果表明，我们的方法达到了0.8850的F1分数，这比最先进的方法要好得多</p>
<h3><span id="说明">说明</span></h3>
<p>与报纸等传统媒体相比。社交机器人，即由程序控制的帐户，可用于保持社交网络的活跃。虽然OSN中存在有益的社交机器人，但一些恶意社交机器人的出现会产生有害影响。例如，一些人可以出于各种目的注册大量帐户，例如增加粉丝数量或恶意喜欢。这些恶意行为已成为威胁社交网络平台健康发展的重要信息安全问题[1-2]。因此，有必要检测那些恶意的社交机器人，也称为社交机器人检测。特别是，当前的大多数研究涉及Twitter和其他国外平台，而很少有研究调查中国的OSN。因此，众多学者致力于研究社交机器人的检测问题。当前与社交机器人检测相关的工作主要分为两类，即机器学习方法和基于图的方法。然而，这一主题仍然存在一些挑战：</p>
<p>1）
一般来说，大多数方法依赖于单个算法来识别社交机器人，由于数据集的多样性，这可能不是理想的选择。</p>
<p>2）
实际上，大多数数据都是未标记的，这表明标签的数量通常很小。因此，<strong>有效利用未标记数据是一个巨大的挑战</strong>。</p>
<p>为了应对上述挑战，我们在此共同考虑用户的配置文件、行为以及它们之间的关系。此外，我们将特征工程和图方法相结合，提出了一种检测社交机器人的集成机制BotFinder。首先，在数据集上进行特征工程以提取全局信息。然后，通过嵌入方法生成节点向量。然后，我们计算人类和机器人的向量之间的相似性。最后，为了进一步提高性能，我们采用了无监督方法（这里考虑了社区检测算法）。使用所提出的算法，我们可以轻松地检测这些机器帐户。</p>
<p><strong>本文的贡献总结如下：</strong></p>
<p>1）
首先，在节点数较多、边数较少的情况下，在绘制过程中可能会忽略一些单个节点。然而，机器学习方法无法学习拓扑结构。因此，我们结合机器学习方法和图方法来克服这些问题。</p>
<p>2）
其次，在特征工程中，我们试图获得二阶特征，并采用编码方法对具有高基数的变量进行编码，或者换句话说，包含大量不同值的变量进行编码。对于图，我们通过嵌入方法生成节点向量。然后，我们利用无监督方法扩散标签以提高性能。这些方法充分利用了标记和未标记的样本。</p>
<p>本文的其余部分组织如下。在第二节中，我们回顾了一些相关的工作。在第3节中，我们介绍了拟议的框架BotFinder。然后，在第4节中，我们详细描述了所研究的数据集，并在充分分析的基础上进行了实验。最后，我们在第5节总结了我们的研究。</p>
<h3><span id="二-related-works"><strong>二、Related works</strong></span></h3>
<h4><span id="21-机器学习方法">2.1 机器学习方法</span></h4>
<p>在机器学习方法中，监督学习方法得到了广泛的研究。早期的反作弊算法仅利用用户配置文件或用户行为来构建模型。Breno等人[3]提出了一种使用人工神经网络进行数据预处理和挖掘的方法。Chang等人[4]提出了一种特征选择方法，然后使用决策树来检测机器人。Ganji等人[5]将K-最近邻（KNN）应用于信用卡欺诈检测。Ferrara等人[6-7]利用机器学习和认知行为建模技术分析了2017年法国总统选举和2017年加泰罗尼亚独立公投中的社交机器人。<strong>Denis等人[8]提出了一种用于检测Twitter上机器人的集成学习方法。</strong>
随着深度学习方法（LSTM、CNN等）的发展，研究人员也尝试开发新的方法来检测社交机器人，以进一步提高检测精度。通过将用户内容视为时间文本数据，Cai等人[9]提出了BeDM方法用于机器人检测。Kudugunta等人[10]提取了用户元数据和推文文本，这些数据被视为LSTM深度网络的输入。在实践中，大多数真实世界的数据都是未标记的，而无监督学习方法被广泛研究，这通常依赖于社交机器人的共同特征。Cresci等人[11-12]提出了一种基于DNA启发技术的改进方法，以模拟在线用户行为。陈等人[13]提出了一种无监督的方法来实时检测推特垃圾邮件活动。姜等人[14]提出了CATCHSYNC，仅使用没有标签的拓扑来检测可疑节点。Su等人[15]提出了物联网RU。Mazza等人[16]将转发的时间序列转换为特征向量，然后进行聚类。</p>
<h4><span id="22-图算法">2.2 图算法</span></h4>
<p>机器学习方法只考虑节点的特征。然而，节点之间的关系也包含有价值和有用的信息。随着深度学习和图算法的发展，需要考虑图的拓扑信息以进一步改进。<strong>社交机器人具有图形聚合的特点</strong>。而社区检测用于发现网络中的社区结构，也可以看作是一种广义聚类算法。因此，社区检测算法可能适用于检测社交机器人。许多研究者对这一课题进行了不懈的研究。Guillaume等人[17]提出了一种基于模块化优化的启发式方法。李等人[18]提出了基于深度稀疏自动编码器的WCD算法。对于特征丰富的样本，很难充分挖掘特征中存在的信息。然后，提出了新的方法，首先将节点的拓扑信息转换为特征向量，然后使用机器学习算法进行训练和推理。例如，Lerer等人[19]提出的Pytorch
BigGraph，<strong>Yu等人[20]提出的NetWalk</strong>，<strong>Grover等人[21]提出的Node2Vec</strong>，P<strong>ham等人[22]提出的Bot2Vec</strong>。此外，Kipf等人[23]提出了图卷积网络（GCN），对节点和网络拓扑的特征进行建模，<strong>Aljohani等人[24]将GCN应用于检测Twitter上的机器人</strong>。李等人[25]提出了用于网络免疫的BPD-DMP算法。聂等人[26]考虑了社交网络和发布内容；然后，他们提出了DCIM算法。高等人[27]对动态行为进行了表征，并提出了一种基于网络的模型。朱等人[28]研究了流行病在多层网络上的传播过程。Su等人[29]提出了检测车载网络中恶意节点的IDE。
大多数方法依赖于单个算法来识别社交机器人。在准确性和其他相关评估指标方面，以前的识别方法仍然有很大的局限性。</p>
<h3><span id="三-botfinder"><strong>三、BotFinder</strong></span></h3>
<p>在本节中，我们主要介绍BotFinder，它主要包括三个步骤：1）我们在表格数据上表示特征工程技术；2）
我们推导节点嵌入，然后测量人类和机器人之间的相似性；3）
我们应用社区检测算法来进一步提高性能</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182039206.png" alt="image-20220719205923660">
<figcaption aria-hidden="true">image-20220719205923660</figcaption>
</figure>
<p>图1详细说明了这些步骤。第一步，利用特征工程技术生成特征矩阵。第二步，我们使用图嵌入方法生成相似矩阵，然后合并这两个矩阵。然后，我们采用LightGBM[30]来训练合并矩阵并推断临时结果。第三步，我们应用社区检测方法生成部分结果，并使用这些结果校正LightGBM的结果。</p>
<h4><span id="31-featureengineering">3.1 <strong>Feature
Engineering</strong></span></h4>
<p>在这里，我们试图获得<strong>二阶特征、时间间隔特征、计数编码和k倍目标编码</strong>。然后，我们应用LightGBM来训练获得的特征并推断临时结果。</p>
<p><strong><font color="red">
二阶特征：为了表示表中分类变量的组合，我们假设二阶特征表示为
COUNT、NUNIQUE、RATIO</font></strong></p>
<ul>
<li><p><strong>COUNT 反映了活动程度。具体来说，我们选择一对变量（即 V1和
V2），并预计记录这对变量在数据集中出现的次数。我们将其缩写为 COUNT(v1,
v2)。</strong>例如，用户向使用设备类型（ V1）iPhone12,1和应用程序版本（
V2）126.7.0组合的人thump-up，这种组合在数据集中出现了k次。然后，使用iPhone12、1和126.7.0的用户将获得k的
COUNT值。【记录元组出现的次数】【并行化】</p></li>
<li><p><strong>UNIQUE表明了给定范围内的多样性。我们使用一个变量（
V1）作为主键，并在另一个变量（V2）中记录唯一类别的数量。我们将其缩写为
UNIQUE(V1)[V2] 。</strong>例如，对于使用device type（
V1）iPhone12,1的用户，数据集中有k个不同的应用程序版本。然后，使用iPhone12,1的用户将获得
UNIQUE 值k。</p></li>
<li><p><strong>RATIO描述计数比例。它计算为 COUNT(v1, v2) /
COUNT(v1)</strong>。例如，device type（V1）iPhone12,1 和 app version（
V2）126.7.0的组合在数据集中出现k次，device
type（V1）iPhone12在数据集中出现V次。然后，所有使用iPhone12、1和126.7.0的用户将获得
k/v 的 RATIO 值。</p></li>
</ul>
<p><strong>时间间隔特性：请求时间间隔因用户而异。这里，我们主要考虑时间间隔的最大值、最小值、中值和和。</strong></p>
<p><strong>计数编码：计数编码是通过将类别替换为在数据集上计算的类别计数来进行的</strong>。然而，某些变量的计数可能相同，这可能导致两个类别可能编码为相同值的冲突。这将导致模型性能下降。因此，我们在此介绍一种目标编码技术。</p>
<p><strong>K-折叠目标编码（或似然编码、影响编码、平均编码）</strong>：目标编码是通过目标（标签）对分类变量进行计数。在这里，我们用目标的相应概率替换分类变量的每一类。为了减少目标泄漏，我们采用k倍目标编码。具体实现如下：</p>
<ul>
<li>将训练数据分成10折。</li>
<li>将折#2-10<strong>目标的平均值</strong>作为折#1的编码值，并类似地计算#2-10的编码值。</li>
<li>使用训练数据的目标来确定测试数据的编码值。</li>
</ul>
<h4><span id="32-similaritycalculation"><strong>3.2 Similarity
Calculation</strong></span></h4>
<p><strong>在这里，我们采用Node2vec[21]来获得用户的节点嵌入（向量），然后计算用户和标记用户之间嵌入的余弦相似性</strong>。相似度值表示两个用户具有相同标签的概率；例如，如果user1和user2之间的余弦相似性相对较大，则它们很可能具有高概率的相同标签。</p>
<p>然后，对于训练集和测试集中的每个节点向量C，我们计算机器人和人类之间的最大和平均余弦相似度，该相似度表示为一个向量。【Smax1、Smean1，Smax0，Smean0】</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304182039522.png" alt="image-20220719212846481" style="zoom:50%;"></p>
<h3><span id="33-communitydetection">3.3 <strong>community
detection</strong></span></h3>
<p><strong>对于社区检测，我们采用典型的Louvain方法</strong>[17]，将构建的图划分为社区。之后，我们将用以下规则标记社区：</p>
<blockquote>
<p>[1] Guillaume L. Fast unfolding of communities in large networks[J].
Journal Statistical Mechanics: Theory and Experiment, 2008, 10:
P1008.</p>
</blockquote>
<p>1）
如果具有标签的用户属于同一社区，则社区中的所有用户都应该具有相同的标签。</p>
<p>2）
如果社区中的用户没有任何标签，或者用户具有不同的标签，我们将不会进行预测。</p>
<p><strong>然而，预测可能不会覆盖所有用户。因此，该规则的性能是有限的。但该规则的结果比LightGBM更准确。通过将上述两个步骤结合起来，可以进一步提高性能。</strong></p>
<h3><span id="四-实验">四、实验</span></h3>
<p>为了评估该机制的性能，我们从一个大型社交网络平台的数据中心收集了一个数据集(https://security.bytedance.com/fe/ai-challenge#/sec-project?id=2&amp;active=1）。它包含超过800万条记录，包括<strong>用户配置文件</strong>和<strong>用户请求</strong>（关注或喜欢某人）。数据集的基本信息如表1和表2所示：表1显示了用户的个人信息（配置文件），而表2说明了用户的行为（请求），包括当时用于启动请求的设备和应用程序版本。</p>
<p><strong><font color="red">
任务描述如下：给定用户配置文件及其请求。只有一小部分用户被标记。因此，我们必须建立一个合理、解释性和有效的模型来检测来自用户的恶意机器人。</font></strong></p>
<h3><span id="五-结论">五、结论</span></h3>
<p>本文提出了一种社交机器人检测方法BotFinder。为了验证所开发方法的性能，我们收集了一个包含800多万条用户记录的数据集。同时，应用机器学习和图方法从此类数据集中提取社交机器人的潜在特征。<strong>特别是，对于特征工程，我们生成二阶特征，并使用编码方法对高基数变量进行编码。</strong>在图方面，我们为账户生成节点向量，然后利用无监督方法（这里我们利用社区检测）扩散标签，以进一步提高性能。通过在收集的数据集上进行的实验，所提出的集成机制的有效性得到了相对较大的F1分数0.8850的保证。与现有方法相比，该方法的性能优越。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/3FC64SH/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/3FC64SH/" class="post-title-link" itemprop="url">工业落地-阿里云-郑翰-安全智能应用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-03 17:42:52" itemprop="dateCreated datePublished" datetime="2022-05-03T17:42:52+08:00">2022-05-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-07-05 23:07:44" itemprop="dateModified" datetime="2022-07-05T23:07:44+08:00">2022-07-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">【draft】应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E5%B7%A5%E4%B8%9A%E8%90%BD%E5%9C%B0/" itemprop="url" rel="index"><span itemprop="name">工业落地</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E5%B7%A5%E4%B8%9A%E8%90%BD%E5%9C%B0/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="安全智能应用的一些迷思"></span></h2>
<h4><span id="1-文章主旨">1、文章主旨</span></h4>
<p>本文是一个面向安全学术圈和工业界同行的介绍性和探讨性议题，议题的前半部分会介绍一些工业实践中被证明有效的落地实践，后半部分更多地是希望抛砖引玉，通过抽象和定义最新的问题，吸引更多学术研究员的关注和合作。</p>
<h4><span id="2-目前可以做到哪些">2、目前可以做到哪些</span></h4>
<p>第一部分，本次演讲从目前工业界中智能算法的一些落地实践情况切入说起，总结目前智能安全从概念到落地的应用情况，主要目的是希望阐述，有哪些问题是已经得到解决，或者部分解决的，包括:</p>
<ol type="1">
<li><strong>在海量、富类型的样本集支持下，现有的深度学习和机器学习框架已经可以很好的实现有监督学习和预测的目标</strong>，复杂模型结构层面的调整对最终结果的提升非常有限，更多的瓶颈是在如何发现更多的打标数据上，即<strong>样本集概率空间覆盖度问题</strong>。</li>
<li><strong>文本内容检测</strong>是现在落地应用最多的场景之一(例如<strong>WAF</strong>、<strong>Webshell检测</strong>、<strong>二进制病毒检测</strong>、<strong>网页敏感内容检测</strong>、<strong>明码流量检测</strong>等)，<strong>传统的NLP和图形领域的特征工程和建模方法可以较好发挥作用</strong>。</li>
<li>针对<strong>简单场景问题</strong>(例如<strong>暴力破解攻击检测</strong>、<strong>异地登录检测</strong>、<strong>真实入侵证据发现</strong>)，<strong>简单统计</strong>和<strong>假设检验</strong>可以发挥较好作用。</li>
<li><strong>时序建模</strong>和<strong>时序异常检测算法</strong>在<strong>ddos、cc、定点API接口爆破检测</strong>上可以发挥较好效果，但受限于安全领域中存在较多的突然性、偶然性事件，时序周期性假设常常无法成立，这点极大限制了时序异常检测算法在安全领域内的应用。</li>
<li><strong>相似性匹配算法</strong>(例如<strong>simhash、ssdeep、kmeans</strong>)目前的主要落地场景主要是，扩展原有规则模型的泛化能力。纯粹无监督的相似性聚类由于缺乏可解释性，目前更多用于辅助专家决策。</li>
</ol>
<p>总结来说，当前工业界和学术界智能算法的应用可以综合概括为，"<strong>基于历史经验样本下的的拟合学习</strong>"，即”<strong>基于知识的对抗</strong>“，机器学习在其中充当的角色更多地是一种记忆学习，缺点是难以提供更多的泛化检测和0day发现能力。</p>
<h4><span id="3-还未解决的难题">3、还未解决的难题</span></h4>
<p>第二部分，笔者希望将我们在企业一线工作的经历进行总结和抽象，将目前智能安全中的一些未解决问题，用学术课题的方式明确地定义出来，将智能安全中的问题转化为学术研究课题，目标是争取更广大的国内科研高效和机构的研究力量，将更多的研究重点投入在实际的问题上，避免对历史老问题的重复研究和建设，包括:</p>
<ol type="1">
<li><strong>安全风险定量评估函数建模</strong>:
以恶意样本检测为例，恶意样本检测0day发现能力(对未知的未知发现能力)本质上是一个搜索优化问题，如何对每一个样本的威胁性(值越大表示恶意性越大，0或负值表示是正常样本)进行定量的定义和分析，是问题的关键。<strong>定义了明确的量化损失函数，恶意样本的检测就会从有监督学习问题转化为搜索优化问题。</strong></li>
<li><strong>基于威胁性定量评估损失函数下的随机搜索问题</strong>:
在基于对各个场景建立了明确的损失函数(例如某个ttp的风险分值、某个http
payload的恶意分值、某个文本文件的恶意分值)之后。接下来的工作就是结合安全问题的特点，开发针对性的优化搜索算法，例如<strong>蒙特卡洛搜索</strong>、<strong>随机梯度下降搜索</strong>。</li>
<li>非完整观测下的复杂事件动态推理过程:
入侵检测是安全攻防领域一个很重要的问题，这个问题本质上是一个<strong>复杂事件马尔科夫推理过程</strong>，各种日志采集点代表了可观测量，但实际情况是，我们永远不可能获得一个安全事件的完整观测视角(受限于日志采集的种类和完整性)。所以安全研究员要解决的问题是，<strong>如果在不完整观测的条件下，进行贝叶斯信念网络的建模，并基于该信念网络进行复杂事件推理</strong>。</li>
<li><strong>模型衰减对抗问题</strong>:
类似于自然界所有物理都在朝着熵增的方向演进，安全攻防中的所有模型都存在”性能衰退“的问题，在开发测试阶段完美适配了当前问题场景的模型在上线运行一段时间后，面临误报和漏报的风险会不断提高。</li>
<li>针对攻击入侵链路回溯的有向无环图推理问题:
入侵回溯场景中面对的主要问题有如下几不同事件节点之间的因果依赖推导:
因为攻击在逻辑上是存在逻辑先后关系的多条路径(攻击事件链路)的合并:
一台机器可能不只遭到一次和一个攻击者的攻击异构节点的融合:
一次成功的入侵回溯包括对已知告警节点的因果串联，以及融合其他可以提供更多线索证据的日志节点这两项工作子图融合:
从不同的日志视角可能获得多条攻击链路，入侵回溯师需要能够识别出其中的底层联系，将多条攻击链路合成到一个大的攻击视角中，为后续的决策提供更丰富的攻击者和攻击面信息。</li>
</ol>
<h4><span id="4-我们目前在尝试的项目">4、我们目前在尝试的项目</span></h4>
<p>第三部分，笔者会介绍一些目前我们公司团队在进行的课题研究方向，包括，</p>
<ol type="1">
<li>通过LSTM自动生成webshell黑样本</li>
<li>基于<strong>GAN网络绕过</strong>现有深度学习AV检测模型</li>
<li>基于<strong>遗传优化算法</strong>的的自动化0day样本生成</li>
<li><strong>基于贝叶斯信念网络的入侵回溯推理</strong></li>
<li><strong>==通过攻击链路中已回溯出来的信息（进程、网络、文件）横向关联其他被这个团伙入侵的机器，然后继承他们的入侵原因==</strong></li>
</ol>
<h4><span id="5-历史外部演讲">5、历史外部演讲</span></h4>
<ul>
<li>《云环境自动化入侵溯源实战》, KCon 2019 [<a href="http://link.zhihu.com/?target=https%3A//static.cdxy.me/201908-%E4%BA%91%E7%8E%AF%E5%A2%83%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E4%BE%B5%E6%BA%AF%E6%BA%90%E5%AE%9E%E6%88%98-KCon.pdf">slides]</a></li>
<li>"Hunting zero-days for millions of websites on Alibaba Cloud", XCon
2019 [<a href="http://link.zhihu.com/?target=https%3A//static.cdxy.me/XCON-2019-EN.pdf">slides]</a></li>
<li>"Webshell Detection via Attention-Based Opcode Sequence
Classification", Artificial Intelligence for Business Security Workshop
(AIBS @ IJCAI-19). Macao, CN. 10-12 Aug 2019. [<a href="http://link.zhihu.com/?target=https%3A//static.cdxy.me/AIBS_2019_paper_3.pdf">paper]</a></li>
<li>"Enhance Security Awareness with Data Mining", BlueHat Shanghai
2019</li>
<li>[<a href="http://link.zhihu.com/?target=https%3A//www.butian.net/datacon">DataCon
2019]</a> 1st place solution of malicious DNS traffic &amp; DGA
analysis. [<a href="http://link.zhihu.com/?target=https%3A//www.cdxy.me/%3Fp%3D806">writeup]</a></li>
<li>《企业安全数据分析思考与实践》, FreeBuf公开课 [<a href="http://link.zhihu.com/?target=http%3A//static.cdxy.me/data-knowledge-action_cdxy.pdf">slides]</a></li>
<li>《从数据视角探索安全威胁》, 先知白帽大会2018 [<a href="http://link.zhihu.com/?target=https%3A//xzfile.aliyuncs.com/upload/zcon/2018/10_%E4%BB%8E%E6%95%B0%E6%8D%AE%E8%A7%86%E8%A7%92%E6%8E%A2%E7%B4%A2%E5%AE%89%E5%85%A8%E5%A8%81%E8%83%81_cdxy.pdf">slides]</a></li>
</ul>
<h2><span id="企业安全数据分析实践与思考">企业安全数据分析实践与思考</span></h2>
<p>https://live.freebuf.com/detail/c5e504cf96a4e1826a609553bf6054f9</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/2ZYZKWX/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/2ZYZKWX/" class="post-title-link" itemprop="url">【Nan】Hunting Stealthy Malware</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-05-02 22:07:29 / 修改时间：22:08:37" itemprop="dateCreated datePublished" datetime="2022-05-02T22:07:29+08:00">2022-05-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">【draft】应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/" itemprop="url" rel="index"><span itemprop="name">学术前沿</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>53</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>https://mzgao.blog.csdn.net/article/details/118355956</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/95QGZ5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/95QGZ5/" class="post-title-link" itemprop="url">【Nan】Soghos-家族语义标签问题</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-05-02 21:37:47 / 修改时间：21:38:54" itemprop="dateCreated datePublished" datetime="2022-05-02T21:37:47+08:00">2022-05-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">【draft】应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/" itemprop="url" rel="index"><span itemprop="name">学术前沿</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>53</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>https://mzgao.blog.csdn.net/article/details/118943477</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/21HN90E/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/21HN90E/" class="post-title-link" itemprop="url">恶意软件检测（10）Dos and Don'ts of Machine Learning in Computer Security</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-02 21:29:45" itemprop="dateCreated datePublished" datetime="2022-05-02T21:29:45+08:00">2022-05-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-04-19 15:51:57" itemprop="dateModified" datetime="2023-04-19T15:51:57+08:00">2023-04-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/" itemprop="url" rel="index"><span itemprop="name">【draft】应用</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/" itemprop="url" rel="index"><span itemprop="name">学术前沿</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%BA%94%E7%94%A8/%E5%AD%A6%E6%9C%AF%E5%89%8D%E6%B2%BF/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">网络安全</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>30k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>54 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="dos-anddonts-of-machine-learning-in-computer-security">Dos and
Don'ts of Machine Learning in Computer Security</span></h2>
<blockquote>
<p>改github的主页信息</p>
<p>USENIX Security
'22：https://www.usenix.org/conference/usenixsecurity22/presentation/arp</p>
<p><strong>Why not（ ? ）Use AI in Cyber Security</strong></p>
</blockquote>
<h3><span id="摘要">摘要</span></h3>
<p><strong>随着计算系统处理能力的不断增强和海量数据集的日益可用，机器学习算法在许多不同领域取得了重大突破</strong>。这一发展影响了计算机安全，催生了一系列基于机器学习的安全系统的工作，例如<strong>恶意软件检测、漏洞发现和二进制代码分析</strong>。尽管机器学习在安全领域有着巨大的潜力，但它容易出现一些微妙的缺陷，这些缺陷会破坏其性能，并使基于学习的系统可能不适合安全任务和实际部署。</p>
<p>在本文中，我们用批判的眼光看待这个问题。首先，我们确定了基于学习的安全系统的设计、实现和评估中的常见陷阱。我们对过去10年中顶级安全会议上的30篇论文进行了研究，确认这些缺陷在当前安全文献中普遍存在。在实证分析中，我们进一步证明了个别陷阱如何导致不切实际的表现和解释，阻碍对当前安全问题的理解。作为补救措施，我们提出了可行的建议，以支持研究人员在可能的情况下避免或减轻陷阱。此外，我们发现了将机器学习应用于安全时存在的问题，并为进一步的研究提供了方向。</p>
<h3><span id="一-说明">一、说明</span></h3>
<p><strong>没有一天不阅读机器学习的成功故事</strong>。对专业计算资源和大型数据集的广泛访问，以及用于深度学习的新概念和架构，为机器学习在几个领域的突破铺平了道路，例如自然语言的翻译[13，31，125]和图像内容的识别[62，78，117]。这一发展自然影响了安全研究：虽然过去主要局限于特定应用[53、54、132]，但机器学习现在已成为研究和解决多个应用领域中普遍存在的安全相关问题的关键促成因素之一，包括<strong>入侵检测</strong>[43、93]、<strong>恶意软件分析</strong>[69、88]、<strong>漏洞发现</strong>[83、142]，和<strong>二进制代码分析</strong>[42、114、140]。</p>
<p>然而，机器学习没有洞察力，需要在相当精细的工作流程中对数据的统计特性进行推理：错误的假设和实验偏见可能会对这一过程产生怀疑，以至于不清楚我们是否可以信任使用学习算法得出的科学发现[56]。<strong>二十年前[11、119、126]开始尝试识别特定安全领域（如网络入侵检测）中的挑战和限制，最近扩展到其他领域，如恶意软件分析和网站指纹识别[3、72、104、112]</strong>。然而，与这项工作垂直的是，我们认为存在与机器学习相关的一般陷阱，这些陷阱影响所有安全领域，迄今为止几乎没有受到关注。<strong>这些缺陷可能导致结果过于乐观，甚至影响整个机器学习工作流，削弱假设、结论和经验教训</strong>。因此，人们感觉到一种虚假的成就感，阻碍了学术界和工业界采用研究进展。健全的科学方法是支持直觉和得出结论的基础。我们认为，这一需求在安全性方面尤其重要，在安全性领域，过程往往受到积极绕过分析并破坏系统的对手的破坏。</p>
<p><strong>在本文中，我们确定了十个常见但微妙的陷阱，这些陷阱对研究结果的有效性构成威胁，并阻碍了对其的解释。</strong>为了支持这一说法，我们分析了过去十年中30篇依靠机器学习解决不同问题的顶级安全论文中这些陷阱的普遍性。令我们惊讶的是，每篇论文至少有三个陷阱；更糟糕的是，有几个陷阱影响了大多数论文，这表明这个问题是多么普遍和微妙。尽管这些陷阱很普遍，但了解它们在多大程度上削弱了结果并导致过于乐观的结论可能更为重要。最后我们对四个不同安全领域中的陷阱进行了影响分析。这些发现支持了我们的假设，回应了社区更广泛的关注。</p>
<h4><span id="贡献">贡献：</span></h4>
<ul>
<li><strong>陷阱识别</strong>。我们确定了机器学习在安全性方面的十个陷阱，并提出了可行的建议，以支持研究人员尽可能避免这些陷阱。此外，要确定无法轻松缓解的开放性问题，需要进一步研究。</li>
<li><strong>流行率分析</strong>。我们分析了在过去十年中发表的30份具有代表性的顶级证券报纸中发现的陷阱的普遍性。此外，我们进行了一项广泛的调查，其中我们获得并评估了这些论文作者关于已识别缺陷的反馈。</li>
<li><strong>影响分析</strong>。在四个不同的安全领域，我们通过实验分析了此类缺陷在多大程度上导致了实验偏差，以及我们如何通过应用建议的建议来有效克服这些问题。</li>
</ul>
<blockquote>
<p><strong>评论</strong> :
这项工作不应被解释为指手画脚的练习。相反，这是一种反思性的努力，表明了微妙的陷阱会对安全研究的进展产生多大的负面影响，以及我们作为一个社区如何充分缓解它们。</p>
</blockquote>
<h3><span id="二-机器学习中的陷阱">二、机器学习中的陷阱</span></h3>
<p>尽管机器学习取得了巨大的成功，但在实践中应用机器学习通常并不简单，而且容易出现一些缺陷，从明显的缺陷到微小的瑕疵。<strong>忽视这些问题可能会导致实验偏差或错误结论，尤其是在计算机安全方面。</strong>在本节中，我们介绍了在security
research中经常出现的十个常见陷阱。虽然这些陷阱乍一看似乎显而易见，但它们根源于安全研究中普遍存在的细微缺陷，甚至在ATOP会议上发表的论文中也是如此。</p>
<p>我们根据典型机器学习工作流的各个阶段对这些缺陷进行分类，如图1所示。对于每个缺陷，我们提供了简短的描述，讨论了其对安全领域的影响，并提出了建议。此外，彩色条显示了我们分析中遭受陷阱的论文比例，较暖的颜色表示存在陷阱（见图3）</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191550030.png" alt="image-20220804131643885">
<figcaption aria-hidden="true">image-20220804131643885</figcaption>
</figure>
<h3><span id="21-数据收集与标记">2.1 数据收集与标记</span></h3>
<p>基于学习的系统的设计和开发通常从获取代表性数据集开始。显然，使用不切实际的数据进行实验会导致错误估计方法的能力。以下两个陷阱经常导致这个问题，因此在开发基于学习的计算机安全系统时需要特别注意。</p>
<h4><span id="221-sampling-bias-样本偏差1">2.2.1 Sampling Bias ：
样本偏差（1）</span></h4>
<p>收集的数据不足以代表潜在安全问题的真实数据分布。</p>
<p><strong>描述</strong>：除了少数例外，研究人员开发基于学习的方法时没有确切了解输入空间的真实潜在分布。相反，他们需要依赖于包含固定数量样本的数据集，这些样本旨在与实际分布相似。虽然在大多数情况下不可避免地存在一些偏见，但理解特定问题固有的特定偏见对于限制其在实践中的影响至关重要。如果数据不能有效地表示输入空间，甚至不能遵循不同的分布，那么从训练数据中得出有意义的结论就变得很有挑战性。</p>
<p><strong>安全影响</strong>：<strong>采样偏差与安全高度相关，因为数据采集尤其具有挑战性</strong>，通常需要使用多个质量不同的源。例如，对于用于Android恶意软件检测的合适数据集的收集，只有少数公共来源可用于获取此类数据[6,
134]。因此，依赖合成数据或组合来自不同来源的数据是常见的做法，正如我们在第4节中通过最先进的入侵和恶意软件检测方法的例子所证明的那样，这两种方法都会引入偏差。</p>
<p><strong>建议</strong>：在许多安全应用程序中，从真实分布中采样极其困难，有时甚至不可能。因此，这种偏差通常只能得到缓解，但不能完全消除。在§4中，我们表明，<strong>在某些情况下，一个合理的策略是构造真实分布的差分集并对其进行单独分析。进一步的策略包括使用合成数据扩展数据集</strong>[例如，28，60，137]或使用转移学习[See99，135，145，147]。然而，应避免来自不兼容源的数据混合，因为这是额外偏差的常见原因。无论如何，应该公开讨论所用数据集的局限性，让其他研究人员更好地理解潜在采样偏差的安全含义。</p>
<h4><span id="221-labelinaccuracy标签不准确2">2.2.1 Label
Inaccuracy：标签不准确（2）</span></h4>
<p>分类任务所需的地面真实值标签不准确、不稳定或错误，影响基于学习的系统的整体性能[85，144]</p>
<p><strong>描述</strong>：许多基于AI的安全系统是为分类任务而构建的。为了训练这些系统，每次观测都需要一个
<strong>ground-truth</strong>
label。不幸的是，这种标记很少是完美的，研究人员必须考虑不确定性和噪声，以防止他们的模型受到固有偏差的影响。</p>
<p><strong>安全影响</strong>：对于许多相关的安全问题，如检测网络攻击或恶意软件，通常无法获得可靠的标签，从而导致鸡和蛋的问题。作为补救措施，研究人员通常采用启发式方法，例如使用无法提供可靠基础真相的外部来源。例如，像
virustotal
这样的服务通常用于获取恶意软件的标签信息，但这些服务并不总是一致的[144]。此外，随着时间的推移，对手行为的改变可能会改变不同等级之间的比例[3,92，144]，引入一种称为<strong>标签偏移的偏差</strong>[85]。无法适应这些变化的系统一旦部署，性能将下降。</p>
<p><strong>建议</strong>：通常，应尽可能验证标签，例如，通过手动调查假阳性或随机样本[例如，122]。如果不排除噪声，则可以通过（i）使用稳健模型或损失函数，（ii）<strong>在学习过程中积极建模标签噪声</strong>，或（iii）清除训练数据中的噪声标签来减少其对学习模型的影响[见55,67,84]。为了证明这些方法的适用性，我们主要采用附录a中的清理方法。请注意，标签不确定的实例不得从测试数据中删除。这代表了采样偏差（P1）和数据窥探（P3）的变化，这是我们在§2.2中详细讨论的一个陷阱。由于标签可能会随时间变化，因此有必要采取预防措施，防止标签移动[85]，例如延迟标签，直到获得稳定的地面真相为止[见144]。</p>
<h3><span id="22-系统设计和学习">2.2 系统设计和学习</span></h3>
<p>一旦收集到足够的数据，就可以训练基于学习的安全系统。<strong>这个过程包括从数据预处理到提取有意义的特征和建立有效的学习模型</strong>。不幸的是，这些步骤中的每一步都可能引入缺陷和弱点。</p>
<h4><span id="221-data-snooping数据窥探3">2.2.1 Data Snooping：数据窥探（3）</span></h4>
<p><strong>学习模型是用实践中通常不可用的数据训练的。数据窥探可以以多种方式发生，其中一些非常细微，难以识别[1]。</strong></p>
<p><strong>描述</strong>：在生成学习模型之前，通常将收集的数据拆分为单独的训练集和测试集。虽然分割数据似乎很简单，但测试数据或其他通常不可用的背景信息有许多微妙的方式可以影响训练过程，从而导致数据窥探。<strong>虽然附录中提供了数据监听示例的详细列表（见表8</strong>），但我们大致区分了三种类型的数据监听：测试、临时和选择性监听。<strong>当测试集用于最终评估之前的实验时，会发生测试窥探</strong>。这包括识别有用特征、参数和学习算法的准备工作。<strong>如果忽略数据中的时间依赖性，则会发生时间监听</strong>。这是一个常见的陷阱，<strong>因为许多与安全相关的问题的潜在分布都处于不断变化的状态</strong>[例如，87，104]。最后，选择性监听描述了基于实践中不可用的信息清理数据。一个例子是基于完整数据集（即，训练和测试）的统计数据删除外部LIER，这些数据集通常在训练时不可用。</p>
<p><strong>安全影响</strong>：在安全方面，由于新的攻击或技术，数据分布是非平稳的，并且不断变化。因此，窥探未来或外部数据源的数据是一种普遍现象，导致结果过于乐观。例如，一些研究人员已经在基于学习的恶意软件检测系统中发现了时间窥探[4,8,104]。在所有这些情况下，由于混合了过去和现在的样本，这些方法的能力被高估。同样，在安全研究中也存在测试和选择性窥探事件，导致结果出现无意偏差（见§3）。</p>
<p><strong>建议</strong>：虽然训练、验证和测试数据应该严格分开似乎很明显，但在预处理阶段，这种数据隔离往往会被无意中违反。<strong>例如，我们观察到，在整个数据集上计算tf-idf权重或神经嵌入是一个常见错误</strong>（见§3）。为了避免这个问题，测试数据应该在数据收集期间尽早分割，并单独存储，直到最终评估。<strong>此外，在创建数据时，应考虑数据内的时间依赖性,数据集被拆分</strong>[4，87，104]。然而，其他类型的数据窥探很难解决。例如，随着公开数据集的特征日益暴露，使用该数据开发的方法隐含地从测试数据中获取年龄知识[见1，90]。<strong>因此，对知名数据集的实验应与对来自考虑适应应用领域的较新数据的实验相补充。</strong></p>
<h4><span id="222-spuriouscorrelations假相关性4">2.2.2 Spurious
Correlations：假相关性（4）</span></h4>
<p><strong>与安全问题无关的工件创建了用于分类的快捷模式。因此，学习模型适应这些工件，而不是解决实际任务</strong>；</p>
<p><strong>描述</strong>：伪相关性是由与要解决的任务相关但实际上与之无关的产生的，从而导致错误关联。考虑一个网络入侵检测系统的例子，其中数据集中的大部分攻击来自某个网络区域。该模型可以学习检测特定IP范围而不是一般攻击模式。请注意，虽然抽样偏差是产生虚假相关性的常见原因，但这些偏差也是由其他因素造成的，我们在附录a.对此进行了更详细的讨论</p>
<p><strong>安全影响</strong>：<strong>机器学习通常应用于安全领域的黑盒。因此，虚假的相关性往往无法确定。一旦结果被解释并用于得出一般结论，这些相关性就会带来问题</strong>。如果不知道虚假相关性，则存在高估方法能力和误判其实际局限性的高风险。例如，§4.2报告了我们对漏洞发现系统的分析，表明基础数据中存在明显的虚假相关性。</p>
<p><strong>建议</strong>：<strong>为了更好地了解基于学习的系统的能力，我们通常建议应用机器学习的解释技术</strong>[见59、79、133]。尽管存在一些限制[例如，66，75127]，这些技术可以揭示虚假的相关性，并允许从业者评估其对系统能力的影响。作为一个例子，我们在§4中展示了不同安全相关问题的可解释学习如何有助于识别该问题。请注意，根据基于学习的系统的目标，一种设置中的虚假相关性可能被视为另一种设置的有效信号。因此，我们建议提前明确定义该目标，并验证系统学习的相关性是否符合该目标。例如，一个强大的恶意软件检测系统应该检测与恶意活动相关的特征，而不是数据中存在的其他无关信息</p>
<h4><span id="223-biased-parameterselection-有偏参数选择5">2.2.3 Biased Parameter
Selection ：有偏参数选择（5）</span></h4>
<p><strong>基于学习的方法的最终参数在训练时并不完全固定。相反，它们间接依赖于测试集</strong>。</p>
<p><strong>描述</strong>：在整个学习过程中，通常通过改变参数生成不同的模型。选择性能最佳的模型，并给出其在测试集上的性能。虽然这种设置通常是合理的，但它仍然会受到参数选择偏差的影响。<strong>例如，通过调整超参数或校准测试数据（而不是训练数据）上的阈值，可以很容易产生过于乐观的结果。</strong></p>
<p><strong>安全影响</strong>：参数在训练时未完全校准的安全系统在现实环境中的性能可能会有所不同。<strong>虽然网络入侵检测系统的检测阈值可以使用测试集上获得的ROC曲线来确定，但由于现实世界流量的多样性，在实践中很难选择相同的操作点</strong>[119]。与原始实验设置相比，这可能导致系统性能下降。请注意，此陷阱与数据窥探（P3）有关，但应明确考虑，因为它很容易导致夸大的结果。</p>
<p><strong>建议</strong>：这种陷阱构成了数据窥探的一种特殊情况，因此适用相同的对策。然而，在实践中，通过使用分离的评估集进行模型选择和参数调整，可以很容易地固定有偏差的参数选择。与通常难以缓解的一般数据窥探相比，严格的数据隔离已经足以排除确定超参数和阈值时的问题。</p>
<h3><span id="23-performance-evaluation">2.3 Performance Evaluation</span></h3>
<p><strong>性能评估典</strong>型机器学习工作流的下一个阶段是系统性能评估。在下文中，我们将展示不同的陷阱如何在评估此类系统时导致不公平的比较和有偏见的结果。</p>
<h4><span id="231-inappropriatebaseline-不适当的基线6">2.3.1 Inappropriate
Baseline: 不适当的基线（6）</span></h4>
<p>评估不使用或使用有限的基线方法进行。结果是，不可能证明对现有技术和其他安全机制的改进;</p>
<p><strong>描述</strong>:为了说明一种新方法在多大程度上提高了技术水平，将其与先前提出的方法进行比较至关重要。在选择基线时，重要的是要记住，不存在优于一般[136]中所有其他方法的通用学习算法。因此，仅提供所提出方法的结果或与基本相同的学习模型进行比较，并没有提供足够的背景来评估其影响。</p>
<p><strong>安全影响</strong>：<strong>过于复杂的学习方法会增加过度拟合的可能性，还会增加运行时开销、攻击面以及部署的时间和成本</strong>。为了证明与传统方法相比，机器学习技术提供了显著的改进，因此有必要对这些系统进行并排比较。</p>
<p><strong>推荐</strong>：在整个评估过程中，应考虑简单模型，而不是仅仅关注复杂模型进行比较。<strong>这些方法易于解释，计算要求较低，并且在实践中证明是有效的和可扩展的</strong>。在第4节中，我们演示了如何使用易于理解的简单模型作为基线来解释不必要的复杂学习模型。类似地，我们表明自动机器学习（AutoML）框架工作[例如，48,70]有助于找到合适的基线。虽然这些自动化方法肯定不能取代经验丰富的数据分析师，但它们可以用来设定所提出方法应达到的下限。最后，检查非学习方法是否也适用于应用场景是至关重要的。<strong>例如，对于入侵和恶意软件检测，存在多种使用其他检测策略的方法[例如，45、102、111]</strong>。</p>
<h4><span id="232inappropriate-performance-measures不适当的性能衡量标准7">2.3.2
Inappropriate Performance Measures：不适当的性能衡量标准（7）</span></h4>
<p><strong>精选的性能度量没有考虑到应用场景的限制，例如数据不平衡或需要保持较低的误报率。</strong></p>
<p><strong>描述</strong>：可提供范围广泛的性能指标，但并非所有这些指标都适用于安全环境。例如，在评估检测系统时，仅报告一个性能值（如精度）通常是不够的，因为真阳性和假阳性判断是不可观察的。然而，更先进的测量方法，如ROC曲线，在某些应用环境中可能会模糊实验结果。图2显示了不平衡数据集上的ROC曲线和精度召回曲线（分类比率1:100）。仅考虑ROC曲线，性能看起来非常出色，但低精度揭示了分类器的真实性能，这对于许多安全应用来说是不切实际的；此外，各种与安全相关的问题涉及两个以上的类，需要多类度量。这一套可能会引入更多的微妙陷阱。众所周知，常用的策略，如”macro-averagingormicro-averaging
“会过度估计和低估小类[51]。</p>
<p><strong>安全影响</strong>：不适当的性能度量是安全研究中的一个长期问题，特别是在检测任务中。例如，虽然真阳性和假阳性可以更详细地描述系统的性能，但当攻击发生率较低时，它们也可以掩盖实际精度。在机器学习中，性能指标的选择非常具体。因此，我们无法提供一般指南。相反，我们建议考虑基于学习的系统的实际部署，并确定有助于实践评估其性能的措施。请注意，这些度量通常与标准度量（如精度或误差）不同，因为它们更符合系统的日常操作。为了给读者一种直觉，在§4.1中，我们展示了Android恶意软件检测器的不同性能测量如何导致对其性能的矛盾解释。</p>
<h4><span id="233-base-ratefallacy基本利率谬误8">2.3.3 Base Rate
Fallacy：基本利率谬误（8）</span></h4>
<p><strong>在解释性能指标时，忽略了较大的类别不平衡，导致对绩效的高估。</strong></p>
<p><strong>描述</strong>：如果不考虑负类的基本速率，类不平衡很容易导致对性能的错误预测。如果这一类占主导地位，即使是极低的假阳性率也会导致意外的高假阳性率。请注意与先前陷阱的不同之处：P7指的是对绩效的不恰当描述，而基本利率谬误则是对结果的错误解释。这种特殊情况在实践中很容易被忽视（见§3）。考虑图2中的示例，其中99%的真阳性可能为1%的假阳性。然而，如果我们考虑1:100的分类比率，这实际上对应于每99个真阳性对应100个假阳性。</p>
<p><strong>安全影响</strong>：基本速率谬误与各种安全问题有关，例如入侵检测和网站指纹识别[11,
72,
100]。<strong>因此，现实地量化攻击者构成的安全和先验威胁是一项挑战。类似地，安装恶意软件的概率通常远低于恶意软件检测实验[104]</strong>。</p>
<p><strong>建议</strong>：安全方面的几个问题围绕着检测罕见事件，如威胁和攻击。对于这些问题，我们提倡使用精度和召回以及相关措施，如精度召回曲线。与其他衡量标准不同，这些功能考虑了分类平衡，因此类似于可靠的性能指标,对于关注少数类的检测任务[38118]。然而，请注意，如果少数群体的流行率被夸大，例如，由于抽样偏差[104]，精确度和召回率可能会产生误导。在这些情况下，马修相关系数（MCC）等其他度量更适合评估分类器的性能[29]（见§4）。此外，ROC曲线及其AUC值是比较检测和分类方法的有用指标。为了更加关注实际约束，我们建议考虑仅将曲线调整到可处理的假阳性率，并计算有界AUC值。<strong>最后，我们还建议讨论与负类（白样本）的基本比率相关的误报类，这使读者能够了解误报决策导致的工作量。</strong></p>
<h3><span id="24-部署和操作">2.4 部署和操作</span></h3>
<p>在典型机器学习工作流的最后一个阶段，部署了开发的系统来解决实践中潜在的安全问题。</p>
<h4><span id="241-lab-onlyevaluation仅实验室评估9">2.4.1 Lab-Only
Evaluation：仅实验室评估（9）</span></h4>
<p>基于学习的系统在实验室环境中进行了简单的评估，没有讨论其实际局限性</p>
<p><strong>描述</strong>：与所有经验学科一样，在某些假设下进行实验以证明方法的有效性是很常见的。虽然执行受控实验是检验某一方法特定方面的合法方法，但应在现实环境中进行评估，以透明地评估其能力，并展示将促进进一步研究的开放挑战。</p>
<p><strong>安全影响</strong>：许多基于学习的安全系统仅在实验室环境中评估，夸大了其实际影响。<strong>一个常见的例子是仅在封闭世界设置中评估的检测方法，具有有限的多样性，不考虑非平稳性[15,71]</strong>。例如，大量网站指纹攻击仅在有限时间内的封闭环境中评估[72]。类似地，一些基于学习的恶意软件检测系统在现实环境中没有得到充分的研究[见5，104]</p>
<p><strong>建议</strong>：<strong>重要的是要尽可能准确地远离实验室设置和近似的真实世界设置</strong>。例如，应考虑数据的时间和空间关系，以解释野外遇到的典型动态[见104]。类似地，运行时和存储约束应在实际条件下进行分析[See
15，112，130]。理想情况下，所提议的系统应该被部署来发现在纯实验室环境中无法观察到的问题，例如真实世界网络流量的多样性[see119]，尽管由于道德和隐私限制，这并非总是可能的。</p>
<h4><span id="242inappropriate-threat-model不恰当的威胁模型10">2.4.2
Inappropriate Threat Model：不恰当的威胁模型（10）</span></h4>
<p>没有考虑机器学习的安全性，使系统面临各种攻击，如中毒和逃避攻击；</p>
<p><strong>描述</strong>：基于学习的安全系统在一个恶劣环境中运行，在设计这些系统时应考虑到这一点。<strong>先前在对抗式学习方面的工作表明，在工作流程的各个阶段，机器学习本身都引入了相当大的攻击面</strong>[见18，101]。其广泛的攻击面使这些算法容易受到各种类型的攻击，例如对抗性预处理、中毒和逃避[19、20、25、105、108]。</p>
<p><strong>安全影响</strong>：在威胁模型和评估中包括对抗性影响通常至关重要，因为攻击的系统不能保证输出可信和有意义的结果。因此，除了传统的安全问题外，还必须考虑与机器学习相关的攻击。例如，与考虑到安全因素而设计的适当规范化模型相比，攻击者可能更容易避开仅依赖少数功能的模型[40]，尽管还应考虑特定领域的影响[105]。此外，机器学习工作流程中的语义漏洞可能会造成攻击盲点。例如，不精确的解析和特征提取可能会使对手隐藏恶意内容[131]。</p>
<p><strong>建议</strong>：在使用基于学习的系统的大多数安全领域中，我们在一个动态的环境中操作。因此，应准确定义威胁模型，并根据这些模型评估系统。在大多数情况下，有必要假设一个适应性强的对手专门针对拟议的系统，并将搜索和利用弱点进行规避或操纵。类似地，考虑机器学习工作流的所有阶段并调查可能的漏洞也是至关重要的[见18、26、39、101]。对于该分析，我们建议尽可能关注白盒策略，遵循Kerckhoff的原则[73]和安全最佳实践。最后，我们要强调的是，对对抗性方面的评估不是附加内容，而是安全研究中的一个强制性组成部分。</p>
<h3><span id="三-流行性分析">三、流行性分析</span></h3>
<p>一旦我们了解了基于学习的安全系统所面临的陷阱，就有必要评估其普遍性并调查其对科学进步的影响。为此，我们对过去十年在ACM
CCS、IEEE S&amp;P、USENIX
Security和NDSS上发表的30篇论文进行了研究，这是我们社区中与安全相关研究的四大会议。这些论文被选为我们研究的代表性例子，因为它们涉及大量不同的安全主题，并成功地将机器学习应用于相应的研究问题。</p>
<p>特别是，我们选择的顶级论文涵盖以下主题：</p>
<ul>
<li>恶意软件检测[9，34，88，104，121，138]；</li>
<li>网络入侵检测[43，93，113，115]；</li>
<li>漏洞发现[42、49、50、83]；</li>
<li>tacks网站指纹识别[44100110116]；</li>
<li>社交网络滥用[22,95,120]；</li>
<li>二进制代码分析[14，32，114]；</li>
<li>代码归属[2,23]；</li>
<li>隐写术[17]；</li>
<li>网上诈骗[74]；</li>
<li>游戏机器人[80]；</li>
<li>[68]</li>
</ul>
<p><strong>评估标准</strong>：对于每一篇论文，<strong>陷阱大致分为存在、不存在、文本不清楚或不适用</strong>。在没有补救（存在）的实验中，陷阱可能完全存在，也可能不存在。如果作者纠正了任何偏见或缩小了他们的主张范围以适应陷阱，这也被视为不存在。此外，我们还介绍了一个类别，以说明确实存在陷阱的实验，但其影响已经得到了特别处理。如果目前或部分出现了一个陷阱，但在文本中得到了承认，我们将按照讨论的方式对分类进行调整。如果审稿人无法排除由于信息缺失而出现的陷阱，我们会将出版物与文本区分开来。最后，在P10的特殊情况下，如果陷阱不适用于纸张的设置，则将其视为单独的类别；</p>
<p><strong>观察</strong>：<strong>普适性分析的汇总结果如图3所示。条形图的颜色表示存在陷阱的程度，其宽度表示具有该分类的论文的比例。受影响纸张的数量记录在条形图的中心</strong>。最普遍的缺陷是<strong>抽样偏差</strong>（P1）和<strong>数据窥探</strong>（P3），这两种情况至少部分出现在90%和73%的论文中。在超过50%的论文中，我们发现至少部分存在不适当的威胁模型（第10页）、仅实验室评估（第9页）和不适当的性能度量（第7页）。每一份报纸都会受到至少三个陷阱的影响，这突出了这些问题在最近的计算机安全研究中的普遍性。特别是，我们发现数据集的收集仍然非常具有挑战性：我们作为社区开发的一些最具权威性和扩展性的开放数据集仍然不完善（见§4.1）</p>
<p>&lt;img src="pic/Dos and Don'ts of Machine Learning in Computer
Security</p>
<blockquote>
<p>改github的主页信息</p>
<p>USENIX Security
'22：https://www.usenix.org/conference/usenixsecurity22/presentation/arp</p>
<p><strong>Why not（ ? ）Use AI in Cyber Security</strong></p>
</blockquote>
<h3><span id="摘要">摘要</span></h3>
<p><strong>随着计算系统处理能力的不断增强和海量数据集的日益可用，机器学习算法在许多不同领域取得了重大突破</strong>。这一发展影响了计算机安全，催生了一系列基于机器学习的安全系统的工作，例如<strong>恶意软件检测、漏洞发现和二进制代码分析</strong>。尽管机器学习在安全领域有着巨大的潜力，但它容易出现一些微妙的缺陷，这些缺陷会破坏其性能，并使基于学习的系统可能不适合安全任务和实际部署。</p>
<p>在本文中，我们用批判的眼光看待这个问题。首先，我们确定了基于学习的安全系统的设计、实现和评估中的常见陷阱。我们对过去10年中顶级安全会议上的30篇论文进行了研究，确认这些缺陷在当前安全文献中普遍存在。在实证分析中，我们进一步证明了个别陷阱如何导致不切实际的表现和解释，阻碍对当前安全问题的理解。作为补救措施，我们提出了可行的建议，以支持研究人员在可能的情况下避免或减轻陷阱。此外，我们发现了将机器学习应用于安全时存在的问题，并为进一步的研究提供了方向。</p>
<h3><span id="一-说明">一、说明</span></h3>
<p><strong>没有一天不阅读机器学习的成功故事</strong>。对专业计算资源和大型数据集的广泛访问，以及用于深度学习的新概念和架构，为机器学习在几个领域的突破铺平了道路，例如自然语言的翻译[13，31，125]和图像内容的识别[62，78，117]。这一发展自然影响了安全研究：虽然过去主要局限于特定应用[53、54、132]，但机器学习现在已成为研究和解决多个应用领域中普遍存在的安全相关问题的关键促成因素之一，包括<strong>入侵检测</strong>[43、93]、<strong>恶意软件分析</strong>[69、88]、<strong>漏洞发现</strong>[83、142]，和<strong>二进制代码分析</strong>[42、114、140]。</p>
<p>然而，机器学习没有洞察力，需要在相当精细的工作流程中对数据的统计特性进行推理：错误的假设和实验偏见可能会对这一过程产生怀疑，以至于不清楚我们是否可以信任使用学习算法得出的科学发现[56]。<strong>二十年前[11、119、126]开始尝试识别特定安全领域（如网络入侵检测）中的挑战和限制，最近扩展到其他领域，如恶意软件分析和网站指纹识别[3、72、104、112]</strong>。然而，与这项工作垂直的是，我们认为存在与机器学习相关的一般陷阱，这些陷阱影响所有安全领域，迄今为止几乎没有受到关注。<strong>这些缺陷可能导致结果过于乐观，甚至影响整个机器学习工作流，削弱假设、结论和经验教训</strong>。因此，人们感觉到一种虚假的成就感，阻碍了学术界和工业界采用研究进展。健全的科学方法是支持直觉和得出结论的基础。我们认为，这一需求在安全性方面尤其重要，在安全性领域，过程往往受到积极绕过分析并破坏系统的对手的破坏。</p>
<p><strong>在本文中，我们确定了十个常见但微妙的陷阱，这些陷阱对研究结果的有效性构成威胁，并阻碍了对其的解释。</strong>为了支持这一说法，我们分析了过去十年中30篇依靠机器学习解决不同问题的顶级安全论文中这些陷阱的普遍性。令我们惊讶的是，每篇论文至少有三个陷阱；更糟糕的是，有几个陷阱影响了大多数论文，这表明这个问题是多么普遍和微妙。尽管这些陷阱很普遍，但了解它们在多大程度上削弱了结果并导致过于乐观的结论可能更为重要。最后我们对四个不同安全领域中的陷阱进行了影响分析。这些发现支持了我们的假设，回应了社区更广泛的关注。</p>
<h4><span id="贡献">贡献：</span></h4>
<ul>
<li><strong>陷阱识别</strong>。我们确定了机器学习在安全性方面的十个陷阱，并提出了可行的建议，以支持研究人员尽可能避免这些陷阱。此外，要确定无法轻松缓解的开放性问题，需要进一步研究。</li>
<li><strong>流行率分析</strong>。我们分析了在过去十年中发表的30份具有代表性的顶级证券报纸中发现的陷阱的普遍性。此外，我们进行了一项广泛的调查，其中我们获得并评估了这些论文作者关于已识别缺陷的反馈。</li>
<li><strong>影响分析</strong>。在四个不同的安全领域，我们通过实验分析了此类缺陷在多大程度上导致了实验偏差，以及我们如何通过应用建议的建议来有效克服这些问题。</li>
</ul>
<blockquote>
<p><strong>评论</strong> :
这项工作不应被解释为指手画脚的练习。相反，这是一种反思性的努力，表明了微妙的陷阱会对安全研究的进展产生多大的负面影响，以及我们作为一个社区如何充分缓解它们。</p>
</blockquote>
<h3><span id="二-机器学习中的陷阱">二、机器学习中的陷阱</span></h3>
<p>尽管机器学习取得了巨大的成功，但在实践中应用机器学习通常并不简单，而且容易出现一些缺陷，从明显的缺陷到微小的瑕疵。<strong>忽视这些问题可能会导致实验偏差或错误结论，尤其是在计算机安全方面。</strong>在本节中，我们介绍了在security
research中经常出现的十个常见陷阱。虽然这些陷阱乍一看似乎显而易见，但它们根源于安全研究中普遍存在的细微缺陷，甚至在ATOP会议上发表的论文中也是如此。</p>
<p>我们根据典型机器学习工作流的各个阶段对这些缺陷进行分类，如图1所示。对于每个缺陷，我们提供了简短的描述，讨论了其对安全领域的影响，并提出了建议。此外，彩色条显示了我们分析中遭受陷阱的论文比例，较暖的颜色表示存在陷阱（见图3）</p>
<figure>
<img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551371.png" alt="image-20220804131643885">
<figcaption aria-hidden="true">image-20220804131643885</figcaption>
</figure>
<h3><span id="21-数据收集与标记">2.1 数据收集与标记</span></h3>
<p>基于学习的系统的设计和开发通常从获取代表性数据集开始。显然，使用不切实际的数据进行实验会导致错误估计方法的能力。以下两个陷阱经常导致这个问题，因此在开发基于学习的计算机安全系统时需要特别注意。</p>
<h4><span id="221-sampling-bias-样本偏差1">2.2.1 Sampling Bias ：
样本偏差（1）</span></h4>
<p>收集的数据不足以代表潜在安全问题的真实数据分布。</p>
<p><strong>描述</strong>：除了少数例外，研究人员开发基于学习的方法时没有确切了解输入空间的真实潜在分布。相反，他们需要依赖于包含固定数量样本的数据集，这些样本旨在与实际分布相似。虽然在大多数情况下不可避免地存在一些偏见，但理解特定问题固有的特定偏见对于限制其在实践中的影响至关重要。如果数据不能有效地表示输入空间，甚至不能遵循不同的分布，那么从训练数据中得出有意义的结论就变得很有挑战性。</p>
<p><strong>安全影响</strong>：<strong>采样偏差与安全高度相关，因为数据采集尤其具有挑战性</strong>，通常需要使用多个质量不同的源。例如，对于用于Android恶意软件检测的合适数据集的收集，只有少数公共来源可用于获取此类数据[6,
134]。因此，依赖合成数据或组合来自不同来源的数据是常见的做法，正如我们在第4节中通过最先进的入侵和恶意软件检测方法的例子所证明的那样，这两种方法都会引入偏差。</p>
<p><strong>建议</strong>：在许多安全应用程序中，从真实分布中采样极其困难，有时甚至不可能。因此，这种偏差通常只能得到缓解，但不能完全消除。在§4中，我们表明，<strong>在某些情况下，一个合理的策略是构造真实分布的差分集并对其进行单独分析。进一步的策略包括使用合成数据扩展数据集</strong>[例如，28，60，137]或使用转移学习[See99，135，145，147]。然而，应避免来自不兼容源的数据混合，因为这是额外偏差的常见原因。无论如何，应该公开讨论所用数据集的局限性，让其他研究人员更好地理解潜在采样偏差的安全含义。</p>
<h4><span id="221-labelinaccuracy标签不准确2">2.2.1 Label
Inaccuracy：标签不准确（2）</span></h4>
<p>分类任务所需的地面真实值标签不准确、不稳定或错误，影响基于学习的系统的整体性能[85，144]</p>
<p><strong>描述</strong>：许多基于AI的安全系统是为分类任务而构建的。为了训练这些系统，每次观测都需要一个
<strong>ground-truth</strong>
label。不幸的是，这种标记很少是完美的，研究人员必须考虑不确定性和噪声，以防止他们的模型受到固有偏差的影响。</p>
<p><strong>安全影响</strong>：对于许多相关的安全问题，如检测网络攻击或恶意软件，通常无法获得可靠的标签，从而导致鸡和蛋的问题。作为补救措施，研究人员通常采用启发式方法，例如使用无法提供可靠基础真相的外部来源。例如，像
virustotal
这样的服务通常用于获取恶意软件的标签信息，但这些服务并不总是一致的[144]。此外，随着时间的推移，对手行为的改变可能会改变不同等级之间的比例[3,92，144]，引入一种称为<strong>标签偏移的偏差</strong>[85]。无法适应这些变化的系统一旦部署，性能将下降。</p>
<p><strong>建议</strong>：通常，应尽可能验证标签，例如，通过手动调查假阳性或随机样本[例如，122]。如果不排除噪声，则可以通过（i）使用稳健模型或损失函数，（ii）<strong>在学习过程中积极建模标签噪声</strong>，或（iii）清除训练数据中的噪声标签来减少其对学习模型的影响[见55,67,84]。为了证明这些方法的适用性，我们主要采用附录a中的清理方法。请注意，标签不确定的实例不得从测试数据中删除。这代表了采样偏差（P1）和数据窥探（P3）的变化，这是我们在§2.2中详细讨论的一个陷阱。由于标签可能会随时间变化，因此有必要采取预防措施，防止标签移动[85]，例如延迟标签，直到获得稳定的地面真相为止[见144]。</p>
<h3><span id="22-系统设计和学习">2.2 系统设计和学习</span></h3>
<p>一旦收集到足够的数据，就可以训练基于学习的安全系统。<strong>这个过程包括从数据预处理到提取有意义的特征和建立有效的学习模型</strong>。不幸的是，这些步骤中的每一步都可能引入缺陷和弱点。</p>
<h4><span id="221-datasnooping数据窥探3">2.2.1 Data
Snooping：数据窥探（3）</span></h4>
<p><strong>学习模型是用实践中通常不可用的数据训练的。数据窥探可以以多种方式发生，其中一些非常细微，难以识别[1]。</strong></p>
<p><strong>描述</strong>：在生成学习模型之前，通常将收集的数据拆分为单独的训练集和测试集。虽然分割数据似乎很简单，但测试数据或其他通常不可用的背景信息有许多微妙的方式可以影响训练过程，从而导致数据窥探。<strong>虽然附录中提供了数据监听示例的详细列表（见表8</strong>），但我们大致区分了三种类型的数据监听：测试、临时和选择性监听。<strong>当测试集用于最终评估之前的实验时，会发生测试窥探</strong>。这包括识别有用特征、参数和学习算法的准备工作。<strong>如果忽略数据中的时间依赖性，则会发生时间监听</strong>。这是一个常见的陷阱，<strong>因为许多与安全相关的问题的潜在分布都处于不断变化的状态</strong>[例如，87，104]。最后，选择性监听描述了基于实践中不可用的信息清理数据。一个例子是基于完整数据集（即，训练和测试）的统计数据删除外部LIER，这些数据集通常在训练时不可用。</p>
<p><strong>安全影响</strong>：在安全方面，由于新的攻击或技术，数据分布是非平稳的，并且不断变化。因此，窥探未来或外部数据源的数据是一种普遍现象，导致结果过于乐观。例如，一些研究人员已经在基于学习的恶意软件检测系统中发现了时间窥探[4,8,104]。在所有这些情况下，由于混合了过去和现在的样本，这些方法的能力被高估。同样，在安全研究中也存在测试和选择性窥探事件，导致结果出现无意偏差（见§3）。</p>
<p><strong>建议</strong>：虽然训练、验证和测试数据应该严格分开似乎很明显，但在预处理阶段，这种数据隔离往往会被无意中违反。<strong>例如，我们观察到，在整个数据集上计算tf-idf权重或神经嵌入是一个常见错误</strong>（见§3）。为了避免这个问题，测试数据应该在数据收集期间尽早分割，并单独存储，直到最终评估。<strong>此外，在创建数据时，应考虑数据内的时间依赖性,数据集被拆分</strong>[4，87，104]。然而，其他类型的数据窥探很难解决。例如，随着公开数据集的特征日益暴露，使用该数据开发的方法隐含地从测试数据中获取年龄知识[见1，90]。<strong>因此，对知名数据集的实验应与对来自考虑适应应用领域的较新数据的实验相补充。</strong></p>
<h4><span id="222-spuriouscorrelations假相关性4">2.2.2 Spurious
Correlations：假相关性（4）</span></h4>
<p><strong>与安全问题无关的工件创建了用于分类的快捷模式。因此，学习模型适应这些工件，而不是解决实际任务</strong>；</p>
<p><strong>描述</strong>：伪相关性是由与要解决的任务相关但实际上与之无关的产生的，从而导致错误关联。考虑一个网络入侵检测系统的例子，其中数据集中的大部分攻击来自某个网络区域。该模型可以学习检测特定IP范围而不是一般攻击模式。请注意，虽然抽样偏差是产生虚假相关性的常见原因，但这些偏差也是由其他因素造成的，我们在附录a.对此进行了更详细的讨论</p>
<p><strong>安全影响</strong>：<strong>机器学习通常应用于安全领域的黑盒。因此，虚假的相关性往往无法确定。一旦结果被解释并用于得出一般结论，这些相关性就会带来问题</strong>。如果不知道虚假相关性，则存在高估方法能力和误判其实际局限性的高风险。例如，§4.2报告了我们对漏洞发现系统的分析，表明基础数据中存在明显的虚假相关性。</p>
<p><strong>建议</strong>：<strong>为了更好地了解基于学习的系统的能力，我们通常建议应用机器学习的解释技术</strong>[见59、79、133]。尽管存在一些限制[例如，66，75127]，这些技术可以揭示虚假的相关性，并允许从业者评估其对系统能力的影响。作为一个例子，我们在§4中展示了不同安全相关问题的可解释学习如何有助于识别该问题。请注意，根据基于学习的系统的目标，一种设置中的虚假相关性可能被视为另一种设置的有效信号。因此，我们建议提前明确定义该目标，并验证系统学习的相关性是否符合该目标。例如，一个强大的恶意软件检测系统应该检测与恶意活动相关的特征，而不是数据中存在的其他无关信息</p>
<h4><span id="223-biasedparameter-selection-有偏参数选择5">2.2.3 Biased
Parameter Selection ：有偏参数选择（5）</span></h4>
<p><strong>基于学习的方法的最终参数在训练时并不完全固定。相反，它们间接依赖于测试集</strong>。</p>
<p><strong>描述</strong>：在整个学习过程中，通常通过改变参数生成不同的模型。选择性能最佳的模型，并给出其在测试集上的性能。虽然这种设置通常是合理的，但它仍然会受到参数选择偏差的影响。<strong>例如，通过调整超参数或校准测试数据（而不是训练数据）上的阈值，可以很容易产生过于乐观的结果。</strong></p>
<p><strong>安全影响</strong>：参数在训练时未完全校准的安全系统在现实环境中的性能可能会有所不同。<strong>虽然网络入侵检测系统的检测阈值可以使用测试集上获得的ROC曲线来确定，但由于现实世界流量的多样性，在实践中很难选择相同的操作点</strong>[119]。与原始实验设置相比，这可能导致系统性能下降。请注意，此陷阱与数据窥探（P3）有关，但应明确考虑，因为它很容易导致夸大的结果。</p>
<p><strong>建议</strong>：这种陷阱构成了数据窥探的一种特殊情况，因此适用相同的对策。然而，在实践中，通过使用分离的评估集进行模型选择和参数调整，可以很容易地固定有偏差的参数选择。与通常难以缓解的一般数据窥探相比，严格的数据隔离已经足以排除确定超参数和阈值时的问题。</p>
<h3><span id="23-performance-evaluation">2.3 Performance Evaluation</span></h3>
<p><strong>性能评估典</strong>型机器学习工作流的下一个阶段是系统性能评估。在下文中，我们将展示不同的陷阱如何在评估此类系统时导致不公平的比较和有偏见的结果。</p>
<h4><span id="231-inappropriatebaseline-不适当的基线6">2.3.1 Inappropriate
Baseline: 不适当的基线（6）</span></h4>
<p>评估不使用或使用有限的基线方法进行。结果是，不可能证明对现有技术和其他安全机制的改进;</p>
<p><strong>描述</strong>:为了说明一种新方法在多大程度上提高了技术水平，将其与先前提出的方法进行比较至关重要。在选择基线时，重要的是要记住，不存在优于一般[136]中所有其他方法的通用学习算法。因此，仅提供所提出方法的结果或与基本相同的学习模型进行比较，并没有提供足够的背景来评估其影响。</p>
<p><strong>安全影响</strong>：<strong>过于复杂的学习方法会增加过度拟合的可能性，还会增加运行时开销、攻击面以及部署的时间和成本</strong>。为了证明与传统方法相比，机器学习技术提供了显著的改进，因此有必要对这些系统进行并排比较。</p>
<p><strong>推荐</strong>：在整个评估过程中，应考虑简单模型，而不是仅仅关注复杂模型进行比较。<strong>这些方法易于解释，计算要求较低，并且在实践中证明是有效的和可扩展的</strong>。在第4节中，我们演示了如何使用易于理解的简单模型作为基线来解释不必要的复杂学习模型。类似地，我们表明自动机器学习（AutoML）框架工作[例如，48,70]有助于找到合适的基线。虽然这些自动化方法肯定不能取代经验丰富的数据分析师，但它们可以用来设定所提出方法应达到的下限。最后，检查非学习方法是否也适用于应用场景是至关重要的。<strong>例如，对于入侵和恶意软件检测，存在多种使用其他检测策略的方法[例如，45、102、111]</strong>。</p>
<h4><span id="232inappropriate-performance-measures不适当的性能衡量标准7">2.3.2
Inappropriate Performance Measures：不适当的性能衡量标准（7）</span></h4>
<p><strong>精选的性能度量没有考虑到应用场景的限制，例如数据不平衡或需要保持较低的误报率。</strong></p>
<p><strong>描述</strong>：可提供范围广泛的性能指标，但并非所有这些指标都适用于安全环境。例如，在评估检测系统时，仅报告一个性能值（如精度）通常是不够的，因为真阳性和假阳性判断是不可观察的。然而，更先进的测量方法，如ROC曲线，在某些应用环境中可能会模糊实验结果。图2显示了不平衡数据集上的ROC曲线和精度召回曲线（分类比率1:100）。仅考虑ROC曲线，性能看起来非常出色，但低精度揭示了分类器的真实性能，这对于许多安全应用来说是不切实际的；此外，各种与安全相关的问题涉及两个以上的类，需要多类度量。这一套可能会引入更多的微妙陷阱。众所周知，常用的策略，如”macro-averagingormicro-averaging
“会过度估计和低估小类[51]。</p>
<p><strong>安全影响</strong>：不适当的性能度量是安全研究中的一个长期问题，特别是在检测任务中。例如，虽然真阳性和假阳性可以更详细地描述系统的性能，但当攻击发生率较低时，它们也可以掩盖实际精度。在机器学习中，性能指标的选择非常具体。因此，我们无法提供一般指南。相反，我们建议考虑基于学习的系统的实际部署，并确定有助于实践评估其性能的措施。请注意，这些度量通常与标准度量（如精度或误差）不同，因为它们更符合系统的日常操作。为了给读者一种直觉，在§4.1中，我们展示了Android恶意软件检测器的不同性能测量如何导致对其性能的矛盾解释。</p>
<h4><span id="233-base-ratefallacy基本利率谬误8">2.3.3 Base Rate
Fallacy：基本利率谬误（8）</span></h4>
<p><strong>在解释性能指标时，忽略了较大的类别不平衡，导致对绩效的高估。</strong></p>
<p><strong>描述</strong>：如果不考虑负类的基本速率，类不平衡很容易导致对性能的错误预测。如果这一类占主导地位，即使是极低的假阳性率也会导致意外的高假阳性率。请注意与先前陷阱的不同之处：P7指的是对绩效的不恰当描述，而基本利率谬误则是对结果的错误解释。这种特殊情况在实践中很容易被忽视（见§3）。考虑图2中的示例，其中99%的真阳性可能为1%的假阳性。然而，如果我们考虑1:100的分类比率，这实际上对应于每99个真阳性对应100个假阳性。</p>
<p><strong>安全影响</strong>：基本速率谬误与各种安全问题有关，例如入侵检测和网站指纹识别[11,
72,
100]。<strong>因此，现实地量化攻击者构成的安全和先验威胁是一项挑战。类似地，安装恶意软件的概率通常远低于恶意软件检测实验[104]</strong>。</p>
<p><strong>建议</strong>：安全方面的几个问题围绕着检测罕见事件，如威胁和攻击。对于这些问题，我们提倡使用精度和召回以及相关措施，如精度召回曲线。与其他衡量标准不同，这些功能考虑了分类平衡，因此类似于可靠的性能指标,对于关注少数类的检测任务[38118]。然而，请注意，如果少数群体的流行率被夸大，例如，由于抽样偏差[104]，精确度和召回率可能会产生误导。在这些情况下，马修相关系数（MCC）等其他度量更适合评估分类器的性能[29]（见§4）。此外，ROC曲线及其AUC值是比较检测和分类方法的有用指标。为了更加关注实际约束，我们建议考虑仅将曲线调整到可处理的假阳性率，并计算有界AUC值。<strong>最后，我们还建议讨论与负类（白样本）的基本比率相关的误报类，这使读者能够了解误报决策导致的工作量。</strong></p>
<h3><span id="24-部署和操作">2.4 部署和操作</span></h3>
<p>在典型机器学习工作流的最后一个阶段，部署了开发的系统来解决实践中潜在的安全问题。</p>
<h4><span id="241-lab-onlyevaluation仅实验室评估9">2.4.1 Lab-Only
Evaluation：仅实验室评估（9）</span></h4>
<p>基于学习的系统在实验室环境中进行了简单的评估，没有讨论其实际局限性</p>
<p><strong>描述</strong>：与所有经验学科一样，在某些假设下进行实验以证明方法的有效性是很常见的。虽然执行受控实验是检验某一方法特定方面的合法方法，但应在现实环境中进行评估，以透明地评估其能力，并展示将促进进一步研究的开放挑战。</p>
<p><strong>安全影响</strong>：许多基于学习的安全系统仅在实验室环境中评估，夸大了其实际影响。<strong>一个常见的例子是仅在封闭世界设置中评估的检测方法，具有有限的多样性，不考虑非平稳性[15,71]</strong>。例如，大量网站指纹攻击仅在有限时间内的封闭环境中评估[72]。类似地，一些基于学习的恶意软件检测系统在现实环境中没有得到充分的研究[见5，104]</p>
<p><strong>建议</strong>：<strong>重要的是要尽可能准确地远离实验室设置和近似的真实世界设置</strong>。例如，应考虑数据的时间和空间关系，以解释野外遇到的典型动态[见104]。类似地，运行时和存储约束应在实际条件下进行分析[See
15，112，130]。理想情况下，所提议的系统应该被部署来发现在纯实验室环境中无法观察到的问题，例如真实世界网络流量的多样性[see119]，尽管由于道德和隐私限制，这并非总是可能的。</p>
<h4><span id="242inappropriate-threat-model不恰当的威胁模型10">2.4.2
Inappropriate Threat Model：不恰当的威胁模型（10）</span></h4>
<p>没有考虑机器学习的安全性，使系统面临各种攻击，如中毒和逃避攻击；</p>
<p><strong>描述</strong>：基于学习的安全系统在一个恶劣环境中运行，在设计这些系统时应考虑到这一点。<strong>先前在对抗式学习方面的工作表明，在工作流程的各个阶段，机器学习本身都引入了相当大的攻击面</strong>[见18，101]。其广泛的攻击面使这些算法容易受到各种类型的攻击，例如对抗性预处理、中毒和逃避[19、20、25、105、108]。</p>
<p><strong>安全影响</strong>：在威胁模型和评估中包括对抗性影响通常至关重要，因为攻击的系统不能保证输出可信和有意义的结果。因此，除了传统的安全问题外，还必须考虑与机器学习相关的攻击。例如，与考虑到安全因素而设计的适当规范化模型相比，攻击者可能更容易避开仅依赖少数功能的模型[40]，尽管还应考虑特定领域的影响[105]。此外，机器学习工作流程中的语义漏洞可能会造成攻击盲点。例如，不精确的解析和特征提取可能会使对手隐藏恶意内容[131]。</p>
<p><strong>建议</strong>：在使用基于学习的系统的大多数安全领域中，我们在一个动态的环境中操作。因此，应准确定义威胁模型，并根据这些模型评估系统。在大多数情况下，有必要假设一个适应性强的对手专门针对拟议的系统，并将搜索和利用弱点进行规避或操纵。类似地，考虑机器学习工作流的所有阶段并调查可能的漏洞也是至关重要的[见18、26、39、101]。对于该分析，我们建议尽可能关注白盒策略，遵循Kerckhoff的原则[73]和安全最佳实践。最后，我们要强调的是，对对抗性方面的评估不是附加内容，而是安全研究中的一个强制性组成部分。</p>
<h3><span id="三-流行性分析">三、流行性分析</span></h3>
<p>一旦我们了解了基于学习的安全系统所面临的陷阱，就有必要评估其普遍性并调查其对科学进步的影响。为此，我们对过去十年在ACM
CCS、IEEE S&amp;P、USENIX
Security和NDSS上发表的30篇论文进行了研究，这是我们社区中与安全相关研究的四大会议。这些论文被选为我们研究的代表性例子，因为它们涉及大量不同的安全主题，并成功地将机器学习应用于相应的研究问题。</p>
<p>特别是，我们选择的顶级论文涵盖以下主题：</p>
<ul>
<li>恶意软件检测[9，34，88，104，121，138]；</li>
<li>网络入侵检测[43，93，113，115]；</li>
<li>漏洞发现[42、49、50、83]；</li>
<li>tacks网站指纹识别[44100110116]；</li>
<li>社交网络滥用[22,95,120]；</li>
<li>二进制代码分析[14，32，114]；</li>
<li>代码归属[2,23]；</li>
<li>隐写术[17]；</li>
<li>网上诈骗[74]；</li>
<li>游戏机器人[80]；</li>
<li>[68]</li>
</ul>
<p><strong>评估标准</strong>：对于每一篇论文，<strong>陷阱大致分为存在、不存在、文本不清楚或不适用</strong>。在没有补救（存在）的实验中，陷阱可能完全存在，也可能不存在。如果作者纠正了任何偏见或缩小了他们的主张范围以适应陷阱，这也被视为不存在。此外，我们还介绍了一个类别，以说明确实存在陷阱的实验，但其影响已经得到了特别处理。如果目前或部分出现了一个陷阱，但在文本中得到了承认，我们将按照讨论的方式对分类进行调整。如果审稿人无法排除由于信息缺失而出现的陷阱，我们会将出版物与文本区分开来。最后，在P10的特殊情况下，如果陷阱不适用于纸张的设置，则将其视为单独的类别；</p>
<p><strong>观察</strong>：<strong>普适性分析的汇总结果如图3所示。条形图的颜色表示存在陷阱的程度，其宽度表示具有该分类的论文的比例。受影响纸张的数量记录在条形图的中心</strong>。最普遍的缺陷是<strong>抽样偏差</strong>（P1）和<strong>数据窥探</strong>（P3），这两种情况至少部分出现在90%和73%的论文中。在超过50%的论文中，我们发现至少部分存在不适当的威胁模型（第10页）、仅实验室评估（第9页）和不适当的性能度量（第7页）。每一份报纸都会受到至少三个陷阱的影响，这突出了这些问题在最近的计算机安全研究中的普遍性。特别是，我们发现数据集的收集仍然非常具有挑战性：我们作为社区开发的一些最具权威性和扩展性的开放数据集仍然不完善（见§4.1）</p>
<p>此外，文本中存在的一些陷阱比其他陷阱更容易被忽略。我们观察到，当没有对参数的描述时，这种有偏参数选择（P5）,给出了超参数或调谐过程；对于伪相关（P4），当没有试图解释模型的决定时；以及当文本中未明确描述数据集分割或归一化过程时的数据窥探（P3）。这些问题还表明，由于缺乏信息，实验设置更难复现；</p>
<p><strong>作者的反馈</strong>：为了促进我们社区内的讨论，我们联系了所选论文的作者，并收集了对我们研究结果的反馈。我们对135位有联系方式的作者进行了调查。为了保护作者的隐私并鼓励公开讨论，所有回复均匿名。调查包括一系列关于已识别缺陷的一般和具体问题。首先，我们询问作者是否阅读过我们的作品，并认为它对社区有帮助。其次，对于每一个陷阱，我们收集反馈信息，说明他们是否同意（a）他们的出版可能受到影响，（b）安全文件中经常出现陷阱，以及（c）在大多数情况下很容易避免。为了量化评估回答，我们对每个问题使用五点Likert量表，范围从强烈不同意到强烈同意。此外，我们提供了一个不回答的选项，并允许作者省略问题。我们收到了49位作者的反馈，回复率为36%。这些作者对应于30篇选定论文中的13篇，因此占考虑研究的43%。关于一般性问题，46（95%）的作者阅读了我们的论文，48（98%）同意这有助于提高对已识别缺陷的认识。对于具体的陷阱问题，作者和我们的发现之间的总体一致性平均为63%，这取决于安全区域和陷阱。所有的作者都认为他们的论文至少有一个缺陷。平均而言，他们指出他们的工作中存在2.77个陷阱，标准偏差为1.53，涵盖了所有十个陷阱。在评估总体缺陷时，作者特别同意，仅<strong>实验室评估（92%）、基本比率谬误（77%）、不适当的绩效衡量（69%）和抽样偏差（69%）经常发生在安全人员中</strong>。此外，他们指出，<strong>不适当的性能测量（62%）、不适当的参数选择（62%）和基准利率谬误（46%）在实践中可以很容易地避免</strong>，而其他陷阱需要更多的努力。我们在附录B中提供了关于该调查的更多信息。总之，我们从该调查中得出了三个中心观察结果。首先，大多数作者都同意，我们的社区缺乏对已识别缺陷的意识。第二，他们确认，这些陷阱在安全文献中很普遍，有必要减轻它们。第三，仍然缺乏对已识别缺陷的一致理解。例如，几位作者（44%）既不同意也不反对数据窥探是否容易避免，强调了明确定义和建议的重要性。我们发现§2中引入的所有陷阱在安全研究中都很普遍，影响了17%到90%的选定论文。每篇论文至少有三个陷阱，只有22%的实例与本文中的讨论相关。虽然作者在某些情况下甚至可能故意省略了对陷阱的讨论，但我们的患病率分析结果总体上表明，我们的社区缺乏认识。虽然这些发现指出了研究中的一个严重问题，<strong>但我们想指出，所有分析的论文都提供了出色的贡献和宝贵的见解。我们的目标不是责怪研究人员陷入陷阱，而是提高安全领域机器学习研究的意识和实验质量。</strong></p>
<h3><span id="四-影响分析">四、影响分析</span></h3>
<p>在前几节中，我们介绍了计算机安全文献中普遍存在的缺陷。然而，到目前为止，尚不清楚单个陷阱会在多大程度上影响实验结果及其结论。在本节中，我们估计了机器学习在安全领域的流行应用中的一些缺陷的实验影响。同时，我们展示了§2中讨论的建议如何帮助识别和解决这些问题。在我们的讨论中，我们考虑了计算机安全领域的四个热门研究主题：</p>
<ul>
<li><strong>移动恶意软件检测</strong>： (P1, P4, and P7)</li>
<li>漏洞发现： (P2, P4, and P6)</li>
<li>源代码作者归属：（P1和P4）</li>
<li><strong>网络入侵检测</strong>：（P6和P9）</li>
</ul>
<blockquote>
<p><strong>评论对于该分析，我们考虑了每个安全域的最先进方法</strong>。我们注意到，本节中的结果并不意味着具体批评这些方法；我们选择它们是因为它们代表了陷阱如何影响不同领域。值得注意的是，我们能够复制这些方法的事实高度赞扬了他们的学术水平;</p>
</blockquote>
<h4><span id="41-移动恶意软件检测">4.1 移动恶意软件检测</span></h4>
<p>使用机器学习自动检测Android恶意软件是一个特别活跃的研究领域。这种方法的设计和评估是微妙的，可能会显示出一些先前讨论的缺陷。在下文中，我们<strong>讨论了采样偏差（P1）、伪相关性（P4）和不适当的性能度量（P7）对基于学习的检测的影响</strong>；</p>
<p><strong>数据集集合</strong>：最近移动数据的一个常见来源是AndroZoop项目[6]，该项目从各种来源收集Android应用程序，包括Official
谷歌市场和几个中国app软件市场。在撰写本文时，它包括来自18个不同来源的超过1100万个Android应用程序。<strong>除了样本本身，它还包括元信息，如抗病毒检测的数量</strong>。虽然AndroZoo是获取移动应用的优秀来源，但我们证明，如果不考虑数据集的特性，实验可能会出现严重的抽样偏差（P1）。请注意，以下讨论不限于AndroZoo数据，而是与Android数据集的组成相关。</p>
<p><strong>数据集分析</strong>：在第一步中，我们通过考虑应用程序的来源和Android应用程序的防病毒检测数量来分析AndroZoo的数据分布。为了进行分析，我们将各个市场大致分为四个不同的来源：谷歌游戏、中国市场、VirusShare和所有其他市场。图4显示了从特定来源随机采样的概率，这取决于应用程序的防病毒检测数量。例如，当选择一个对检测次数没有限制的样本时，从谷歌游戏中采样的概率大约为80%。如果我们考虑10次检测的结果，我们从中国市场随机选择应用的概率是70%。如果我们忽略数据分布，数据集中的大部分良性应用很可能来自GooglePlay，而大多数恶意应用来自中国市场。请注意，此采样偏差不限于Andro
Zoo。我们确定了DredeBin数据集[9]的类似抽样偏差，该偏差通常用于评估基于学习的Android恶意软件检测方法的性能[9、58、146]。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551654.png" alt="image-20220807135625094" style="zoom: 67%;"></p>
<p><strong>实验装置</strong>：为了更好地理解这一发现，我们使用两个数据集进行了实验：</p>
<ul>
<li>对于第一个数据集（D1），我们将来自Google
Play的10000个良性应用程序与来自中国市场的1000个恶性应用程序（安齐安达应用程序中国）合并。</li>
<li>然后，我们使用相同的10000个良性应用程序创建第二个数据集（D2），但将它们与Google
Play独家提供的1000个软件样本相结合。所有合法的应用程序都至少被10个病毒扫描程序检测到。接下来，我们使用来自最先进分类器的两个特征集（DREBIN[9]和OPSEQS[91]），在这些数据集上训练线性支持向量机[47]。</li>
</ul>
<p><strong>实验结果</strong>：在数据集D1和D2之间，DREBIN 和
OPSDEQS的召回率（真阳性率）分别超过10%和15%，而准确性仅受到轻微影响（见表1）。因此，性能度量的选择至关重要（P7）。有趣的是，URLplay.google.Com
被证明是良性类的五个最具歧视性的特征之一，这表明分类者已经学会区分Android
apps的起源，而不是恶意软件和benign apps
之间的区别（P4）。<strong>虽然我们的实验装置通过故意忽略时间相关性（P3）高估了分类器的性能，但我们仍然可以清楚地观察到陷阱的影响</strong>。请注意，在以前的工作[4,
104]中已经证明了在这种情况下时间窥探的效果。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551720.png" alt="image-20220807211200980" style="zoom: 67%;"></p>
<h3><span id="42-漏洞发现">4.2 漏洞发现</span></h3>
<p>源代码中的漏洞可能导致权限提升和远程代码执行，使其成为主要威胁。由于手动搜索漏洞复杂且耗时，近年来提出了基于机器学习的检测方法[57，83，141]。在下面的内容中，我们展示了用于漏洞检测的数据集包含仅在一个类（P4）中发生的事件。我们还发现，用于检测脆弱性的神经网络Vuldeepecker[83]使用伪影进行分类，并且简单的线性分类器在相同的数据集上获得更好的结果（P6）。最后，我们讨论了forVulDeePecker提出的预处理步骤如何使我们无法确定某些代码片段是否包含漏洞（P2）</p>
<p><strong>数据集集合</strong>：在我们的分析中，我们使用了Li等人[83]发布的数据集，其中包含来自国家漏洞数据库[36]和SARD项目[37]的源代码。我们关注与缓冲区（CWE-119）相关的漏洞，并获得了39757个源代码片段，其中10444（26%）被标记为包含漏洞。</p>
<h3><span id="43-源代码作者归属">4.3 源代码作者归属</span></h3>
<p>基于源代码识别开发人员的任务称为作者归属[23]。编程习惯具有多种风格模式，因此</p>
<h4><span id="44-网络入侵检测检测">4.4 网络入侵检测检测</span></h4>
<p>网络入侵是安全[41]中最古老的问题之一，毫不奇怪，异常网络流量的检测严重依赖于基于学习的方法[27,81,82,93]。<strong>然而，收集真实攻击数据的挑战[46]常常导致研究人员生成合成数据，用于实验室评估</strong>（P9）。在这里，我们演示了这些数据如何不足以证明使用复杂模型（如神经网络）的合理性，以及将一个更简单的模型作为基线将如何揭示这些缺点（P6）。</p>
<p><strong>数据集集合</strong>：我们考虑Mirsky等人<a href>93</a>发布的数据集，其中包含物联网（IoT）网络流量的捕获，模拟Mirai僵尸网络恶意软件的初始激活和传播。该数据包覆盖了三台个人电脑和九台物联网设备的Wi-Fi网络上119分钟的流量.</p>
<p><strong>数据集分析</strong>：首先，我们分析捕获的网络流量的传输量。图8显示了捕获过程中良性和恶意数据包的频率，划分为10秒。这表明在分组频率中有一个强信号，这高度指示了一个持续攻击。<strong>此外，所有良性活动似乎都随着袭击的开始而停止。74分钟后，尽管网络上有很多设备。这表明个体观测可能已经合并，并可能进一步导致系统受益于虚假相关性</strong>（P4）</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551694.png" alt="image-20220807213124529" style="zoom:50%;"></p>
<blockquote>
<p>图:Mirai数据集中良性与恶意数据包的频率<a href>93</a>。灰色虚线显示了定义使用简单基线计算的正常流量的阈值（箱线图法[129]）。用于校准的数据范围由浅蓝色阴影区域突出显示.</p>
</blockquote>
<p><strong>实验设置</strong>：为了说明这些缺陷的严重程度，我们考虑了<strong>Kitsune<a href>93</a></strong>，这是一种基于深度学习的最先进入侵检测器，构建在一组au-toencoders上。对于每个数据包，提取115个特征，输入到12个自动编码器，这些自动编码器本身反馈到另一个作为异常检测器运行的最终自动编码器。</p>
<blockquote>

</blockquote>
<p><strong>作为与Kitsune进行比较的简单基线，我们选择了箱线图法[129]</strong>，这是一种识别异常值的常用方法。我们使用10秒滑动窗口处理分组，并使用每个窗口的分组频率作为唯一特征。接下来，我们从干净的校准分布推导出一个上下阈值：τlow=Q1−1.5·IQRand
，τ高＝Q3+1.5·IQR。<strong>在测试期间，如果滑动窗口的数据包频率在τ低和τ高之间，则数据包被标记为良性，否则为恶意。在图8中，这些阈值用灰色虚线表示。</strong></p>
<p><strong>后果</strong>：表5显示了与箱线图方法相比，自动编码器集成的分类性能。虽然两种方法在ROC
AUC方面表现相似，但简单箱线图法在低误报率（FPR）下优于自动编码器集成。<strong>除了其优越的性能外，箱线图方法与集成的特征提取和测试程序相比，重量非常轻</strong>。这一点尤其重要，因为集成设计用于在低延迟的资源受限设备（如物联网设备）上运行。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551172.png" alt="image-20220807220205015" style="zoom:50%;"></p>
<blockquote>
<p>表5：比较Kitsune<a href>93</a>，一种自动编码器集成NIDS，相比于一个简单基线，箱线图法[129]，用于检测Mirai感染。</p>
</blockquote>
<p><strong>注意</strong>：<strong>本实验的目的不是证明箱图法可以检测到野外操作的Mirai实例，也不是证明Kitsuneis无法检测到其他攻击，而是证明没有适当基线（P6）的实验不足以证明集成的复杂性和过度性</strong>。箱线图法的成功还表明，简单的方法可以揭示仅用于实验室评估的数据产生的问题（第9页）。在Mirai数据集中，感染过于明显；在野外进行的攻击很可能只占网络流量的一小部分。</p>
<h3><span id="五-总结">五、总结</span></h3>
<p>我们识别并系统地评估了机器学习在安全领域的应用中的十个细微缺陷。这些问题会影响研究的有效性，并导致高估安全系统的性能。我们发现这些陷阱在安全研究中非常普遍，并展示了这些陷阱在不同安全应用中的影响。为了支持研究人员避免这些问题，我们提供了适用于所有安全领域的建议，从入侵和恶意软件检测到漏洞发现。最终，我们努力提高安全领域机器学习实验工作的科学质量。在Sommer和Paxson[119]的开创性研究十年后，weagain鼓励社区深入封闭的世界，探索将机器学习嵌入现实世界安全系统的挑战和机遇。AI安全的十大缺陷/image-20220806171411086.png"
alt="image-20220806171411086" style="zoom:50%;" /&gt;</p>
<p>此外，文本中存在的一些陷阱比其他陷阱更容易被忽略。我们观察到，当没有对参数的描述时，这种有偏参数选择（P5）,给出了超参数或调谐过程；对于伪相关（P4），当没有试图解释模型的决定时；以及当文本中未明确描述数据集分割或归一化过程时的数据窥探（P3）。这些问题还表明，由于缺乏信息，实验设置更难复现；</p>
<p><strong>作者的反馈</strong>：为了促进我们社区内的讨论，我们联系了所选论文的作者，并收集了对我们研究结果的反馈。我们对135位有联系方式的作者进行了调查。为了保护作者的隐私并鼓励公开讨论，所有回复均匿名。调查包括一系列关于已识别缺陷的一般和具体问题。首先，我们询问作者是否阅读过我们的作品，并认为它对社区有帮助。其次，对于每一个陷阱，我们收集反馈信息，说明他们是否同意（a）他们的出版可能受到影响，（b）安全文件中经常出现陷阱，以及（c）在大多数情况下很容易避免。为了量化评估回答，我们对每个问题使用五点Likert量表，范围从强烈不同意到强烈同意。此外，我们提供了一个不回答的选项，并允许作者省略问题。我们收到了49位作者的反馈，回复率为36%。这些作者对应于30篇选定论文中的13篇，因此占考虑研究的43%。关于一般性问题，46（95%）的作者阅读了我们的论文，48（98%）同意这有助于提高对已识别缺陷的认识。对于具体的陷阱问题，作者和我们的发现之间的总体一致性平均为63%，这取决于安全区域和陷阱。所有的作者都认为他们的论文至少有一个缺陷。平均而言，他们指出他们的工作中存在2.77个陷阱，标准偏差为1.53，涵盖了所有十个陷阱。在评估总体缺陷时，作者特别同意，仅<strong>实验室评估（92%）、基本比率谬误（77%）、不适当的绩效衡量（69%）和抽样偏差（69%）经常发生在安全人员中</strong>。此外，他们指出，<strong>不适当的性能测量（62%）、不适当的参数选择（62%）和基准利率谬误（46%）在实践中可以很容易地避免</strong>，而其他陷阱需要更多的努力。我们在附录B中提供了关于该调查的更多信息。总之，我们从该调查中得出了三个中心观察结果。首先，大多数作者都同意，我们的社区缺乏对已识别缺陷的意识。第二，他们确认，这些陷阱在安全文献中很普遍，有必要减轻它们。第三，仍然缺乏对已识别缺陷的一致理解。例如，几位作者（44%）既不同意也不反对数据窥探是否容易避免，强调了明确定义和建议的重要性。我们发现§2中引入的所有陷阱在安全研究中都很普遍，影响了17%到90%的选定论文。每篇论文至少有三个陷阱，只有22%的实例与本文中的讨论相关。虽然作者在某些情况下甚至可能故意省略了对陷阱的讨论，但我们的患病率分析结果总体上表明，我们的社区缺乏认识。虽然这些发现指出了研究中的一个严重问题，<strong>但我们想指出，所有分析的论文都提供了出色的贡献和宝贵的见解。我们的目标不是责怪研究人员陷入陷阱，而是提高安全领域机器学习研究的意识和实验质量。</strong></p>
<h3><span id="四-影响分析">四、影响分析</span></h3>
<p>在前几节中，我们介绍了计算机安全文献中普遍存在的缺陷。然而，到目前为止，尚不清楚单个陷阱会在多大程度上影响实验结果及其结论。在本节中，我们估计了机器学习在安全领域的流行应用中的一些缺陷的实验影响。同时，我们展示了§2中讨论的建议如何帮助识别和解决这些问题。在我们的讨论中，我们考虑了计算机安全领域的四个热门研究主题：</p>
<ul>
<li><strong>移动恶意软件检测</strong>： (P1, P4, and P7)</li>
<li>漏洞发现： (P2, P4, and P6)</li>
<li>源代码作者归属：（P1和P4）</li>
<li><strong>网络入侵检测</strong>：（P6和P9）</li>
</ul>
<blockquote>
<p><strong>评论对于该分析，我们考虑了每个安全域的最先进方法</strong>。我们注意到，本节中的结果并不意味着具体批评这些方法；我们选择它们是因为它们代表了陷阱如何影响不同领域。值得注意的是，我们能够复制这些方法的事实高度赞扬了他们的学术水平;</p>
</blockquote>
<h4><span id="41-移动恶意软件检测">4.1 移动恶意软件检测</span></h4>
<p>使用机器学习自动检测Android恶意软件是一个特别活跃的研究领域。这种方法的设计和评估是微妙的，可能会显示出一些先前讨论的缺陷。在下文中，我们<strong>讨论了采样偏差（P1）、伪相关性（P4）和不适当的性能度量（P7）对基于学习的检测的影响</strong>；</p>
<p><strong>数据集集合</strong>：最近移动数据的一个常见来源是AndroZoop项目[6]，该项目从各种来源收集Android应用程序，包括Official
谷歌市场和几个中国app软件市场。在撰写本文时，它包括来自18个不同来源的超过1100万个Android应用程序。<strong>除了样本本身，它还包括元信息，如抗病毒检测的数量</strong>。虽然AndroZoo是获取移动应用的优秀来源，但我们证明，如果不考虑数据集的特性，实验可能会出现严重的抽样偏差（P1）。请注意，以下讨论不限于AndroZoo数据，而是与Android数据集的组成相关。</p>
<p><strong>数据集分析</strong>：在第一步中，我们通过考虑应用程序的来源和Android应用程序的防病毒检测数量来分析AndroZoo的数据分布。为了进行分析，我们将各个市场大致分为四个不同的来源：谷歌游戏、中国市场、VirusShare和所有其他市场。图4显示了从特定来源随机采样的概率，这取决于应用程序的防病毒检测数量。例如，当选择一个对检测次数没有限制的样本时，从谷歌游戏中采样的概率大约为80%。如果我们考虑10次检测的结果，我们从中国市场随机选择应用的概率是70%。如果我们忽略数据分布，数据集中的大部分良性应用很可能来自GooglePlay，而大多数恶意应用来自中国市场。请注意，此采样偏差不限于Andro
Zoo。我们确定了DredeBin数据集[9]的类似抽样偏差，该偏差通常用于评估基于学习的Android恶意软件检测方法的性能[9、58、146]。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551441.png" alt="image-20220807135625094" style="zoom: 67%;"></p>
<p><strong>实验装置</strong>：为了更好地理解这一发现，我们使用两个数据集进行了实验：</p>
<ul>
<li>对于第一个数据集（D1），我们将来自Google
Play的10000个良性应用程序与来自中国市场的1000个恶性应用程序（安齐安达应用程序中国）合并。</li>
<li>然后，我们使用相同的10000个良性应用程序创建第二个数据集（D2），但将它们与Google
Play独家提供的1000个软件样本相结合。所有合法的应用程序都至少被10个病毒扫描程序检测到。接下来，我们使用来自最先进分类器的两个特征集（DREBIN[9]和OPSEQS[91]），在这些数据集上训练线性支持向量机[47]。</li>
</ul>
<p><strong>实验结果</strong>：在数据集D1和D2之间，DREBIN 和
OPSDEQS的召回率（真阳性率）分别超过10%和15%，而准确性仅受到轻微影响（见表1）。因此，性能度量的选择至关重要（P7）。有趣的是，URLplay.google.Com
被证明是良性类的五个最具歧视性的特征之一，这表明分类者已经学会区分Android
apps的起源，而不是恶意软件和benign apps
之间的区别（P4）。<strong>虽然我们的实验装置通过故意忽略时间相关性（P3）高估了分类器的性能，但我们仍然可以清楚地观察到陷阱的影响</strong>。请注意，在以前的工作[4,
104]中已经证明了在这种情况下时间窥探的效果。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551324.png" alt="image-20220807211200980" style="zoom: 67%;"></p>
<h3><span id="42-漏洞发现">4.2 漏洞发现</span></h3>
<p>源代码中的漏洞可能导致权限提升和远程代码执行，使其成为主要威胁。由于手动搜索漏洞复杂且耗时，近年来提出了基于机器学习的检测方法[57，83，141]。在下面的内容中，我们展示了用于漏洞检测的数据集包含仅在一个类（P4）中发生的事件。我们还发现，用于检测脆弱性的神经网络Vuldeepecker[83]使用伪影进行分类，并且简单的线性分类器在相同的数据集上获得更好的结果（P6）。最后，我们讨论了forVulDeePecker提出的预处理步骤如何使我们无法确定某些代码片段是否包含漏洞（P2）</p>
<p><strong>数据集集合</strong>：在我们的分析中，我们使用了Li等人[83]发布的数据集，其中包含来自国家漏洞数据库[36]和SARD项目[37]的源代码。我们关注与缓冲区（CWE-119）相关的漏洞，并获得了39757个源代码片段，其中10444（26%）被标记为包含漏洞。</p>
<h3><span id="43-源代码作者归属">4.3 源代码作者归属</span></h3>
<p>基于源代码识别开发人员的任务称为作者归属[23]。编程习惯具有多种风格模式，因此</p>
<h4><span id="44-网络入侵检测检测">4.4 网络入侵检测检测</span></h4>
<p>网络入侵是安全[41]中最古老的问题之一，毫不奇怪，异常网络流量的检测严重依赖于基于学习的方法[27,81,82,93]。<strong>然而，收集真实攻击数据的挑战[46]常常导致研究人员生成合成数据，用于实验室评估</strong>（P9）。在这里，我们演示了这些数据如何不足以证明使用复杂模型（如神经网络）的合理性，以及将一个更简单的模型作为基线将如何揭示这些缺点（P6）。</p>
<p><strong>数据集集合</strong>：我们考虑Mirsky等人<a href>93</a>发布的数据集，其中包含物联网（IoT）网络流量的捕获，模拟Mirai僵尸网络恶意软件的初始激活和传播。该数据包覆盖了三台个人电脑和九台物联网设备的Wi-Fi网络上119分钟的流量.</p>
<p><strong>数据集分析</strong>：首先，我们分析捕获的网络流量的传输量。图8显示了捕获过程中良性和恶意数据包的频率，划分为10秒。这表明在分组频率中有一个强信号，这高度指示了一个持续攻击。<strong>此外，所有良性活动似乎都随着袭击的开始而停止。74分钟后，尽管网络上有很多设备。这表明个体观测可能已经合并，并可能进一步导致系统受益于虚假相关性</strong>（P4）</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551606.png" alt="image-20220807213124529" style="zoom:50%;"></p>
<blockquote>
<p>图:Mirai数据集中良性与恶意数据包的频率<a href>93</a>。灰色虚线显示了定义使用简单基线计算的正常流量的阈值（箱线图法[129]）。用于校准的数据范围由浅蓝色阴影区域突出显示.</p>
</blockquote>
<p><strong>实验设置</strong>：为了说明这些缺陷的严重程度，我们考虑了<strong>Kitsune<a href>93</a></strong>，这是一种基于深度学习的最先进入侵检测器，构建在一组au-toencoders上。对于每个数据包，提取115个特征，输入到12个自动编码器，这些自动编码器本身反馈到另一个作为异常检测器运行的最终自动编码器。</p>
<blockquote>

</blockquote>
<p><strong>作为与Kitsune进行比较的简单基线，我们选择了箱线图法[129]</strong>，这是一种识别异常值的常用方法。我们使用10秒滑动窗口处理分组，并使用每个窗口的分组频率作为唯一特征。接下来，我们从干净的校准分布推导出一个上下阈值：τlow=Q1−1.5·IQRand
，τ高＝Q3+1.5·IQR。<strong>在测试期间，如果滑动窗口的数据包频率在τ低和τ高之间，则数据包被标记为良性，否则为恶意。在图8中，这些阈值用灰色虚线表示。</strong></p>
<p><strong>后果</strong>：表5显示了与箱线图方法相比，自动编码器集成的分类性能。虽然两种方法在ROC
AUC方面表现相似，但简单箱线图法在低误报率（FPR）下优于自动编码器集成。<strong>除了其优越的性能外，箱线图方法与集成的特征提取和测试程序相比，重量非常轻</strong>。这一点尤其重要，因为集成设计用于在低延迟的资源受限设备（如物联网设备）上运行。</p>
<p><img src="https://lzy-picture.oss-cn-beijing.aliyuncs.com/img/202304191551961.png" alt="image-20220807220205015" style="zoom:50%;"></p>
<blockquote>
<p>表5：比较Kitsune<a href>93</a>，一种自动编码器集成NIDS，相比于一个简单基线，箱线图法[129]，用于检测Mirai感染。</p>
</blockquote>
<p><strong>注意</strong>：<strong>本实验的目的不是证明箱图法可以检测到野外操作的Mirai实例，也不是证明Kitsuneis无法检测到其他攻击，而是证明没有适当基线（P6）的实验不足以证明集成的复杂性和过度性</strong>。箱线图法的成功还表明，简单的方法可以揭示仅用于实验室评估的数据产生的问题（第9页）。在Mirai数据集中，感染过于明显；在野外进行的攻击很可能只占网络流量的一小部分。</p>
<h3><span id="五-总结">五、总结</span></h3>
<p>我们识别并系统地评估了机器学习在安全领域的应用中的十个细微缺陷。这些问题会影响研究的有效性，并导致高估安全系统的性能。我们发现这些陷阱在安全研究中非常普遍，并展示了这些陷阱在不同安全应用中的影响。为了支持研究人员避免这些问题，我们提供了适用于所有安全领域的建议，从入侵和恶意软件检测到漏洞发现。最终，我们努力提高安全领域机器学习实验工作的科学质量。在Sommer和Paxson[119]的开创性研究十年后，weagain鼓励社区深入封闭的世界，探索将机器学习嵌入现实世界安全系统的挑战和机遇。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://powerlzy.github.io/posts/1TPZG47/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cat_mac.jpg">
      <meta itemprop="name" content="lzy">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PowerLZY's Blog">
      <meta itemprop="description" content="相比到达的地方，同行的人更重要！">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | PowerLZY's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/posts/1TPZG47/" class="post-title-link" itemprop="url">Pytorch（10）模型训练-损失函数</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-02 19:04:03" itemprop="dateCreated datePublished" datetime="2022-05-02T19:04:03+08:00">2022-05-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-06-30 16:27:07" itemprop="dateModified" datetime="2022-06-30T16:27:07+08:00">2022-06-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%B7%A5%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">【draft】工程</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%B7%A5%E7%A8%8B/%E5%BC%80%E6%BA%90%E5%B7%A5%E5%85%B7/" itemprop="url" rel="index"><span itemprop="name">开源工具</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E3%80%90draft%E3%80%91%E5%B7%A5%E7%A8%8B/%E5%BC%80%E6%BA%90%E5%B7%A5%E5%85%B7/Pytorch%E6%A1%86%E6%9E%B6/" itemprop="url" rel="index"><span itemprop="name">Pytorch框架</span></a>
        </span>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>12 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2><span id="pytorch-学习笔记-损失函数">[PyTorch 学习笔记] 损失函数</span></h2>
<h3><span id="一-损失函数">一、损失函数</span></h3>
<p><strong>损失函数是衡量模型输出与真实标签之间的差异</strong>。我们还经常听到<strong>代价函数</strong>和<strong>目标函数</strong>，它们之间差异如下：</p>
<ul>
<li><p><strong>损失函数</strong>(Loss
Function)是计算<strong>一个样本</strong>的模型输出与真实标签的差异 Loss
<img src="https://www.zhihu.com/equation?tex=%3Df%5Cleft%28y%5E%7B%5Cwedge%7D%2C+y%5Cright%29" alt="[公式]"></p></li>
<li><p><strong>代价函数</strong>(Cost
Function)是计算整个<strong>样本集</strong>的模型输出与真实标签的差异，是所有样本损失函数的平均值
<img src="https://www.zhihu.com/equation?tex=%5Ccos+t%3D%5Cfrac%7B1%7D%7BN%7D+%5Csum_%7Bi%7D%5E%7BN%7D+f%5Cleft%28y_%7Bi%7D%5E%7B%5Cwedge%7D%2C+y_%7Bi%7D%5Cright%29" alt="[公式]"></p></li>
<li><p><strong>目标函数</strong>(Objective
Function)就是代价函数加上正则项</p></li>
</ul>
<p><strong>在 PyTorch
中的损失函数也是继承于<code>nn.Module</code>，所以损失函数也可以看作网络层。</strong></p>
<p>在逻辑回归的实验中，我使用了交叉熵损失函数<code>loss_fn = nn.BCELoss()</code>，<img src="https://www.zhihu.com/equation?tex=BCELoss" alt="[公式]">
的继承关系：<code>nn.BCELoss() -&gt; _WeightedLoss -&gt; _Loss -&gt; Module</code>。在计算具体的损失时<code>loss = loss_fn(y_pred.squeeze(), train_y)</code>，这里实际上在
Loss
中进行一次前向传播，<strong>最终调用<code>BCELoss()</code>的<code>forward()</code>函数<code>F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)</code>。</strong></p>
<h4><span id="11nncrossentropyloss-softmaxxlogxnnnllloss">1.1
<strong>nn.CrossEntropyLoss</strong> = softmax(x)+log(x)+nn.NLLLoss</span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.CrossEntropyLoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, ignore_index=-<span class="number">100</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：把<code>nn.LogSoftmax()</code>和<code>nn.NLLLoss()</code>结合，计算交叉熵。<code>nn.LogSoftmax()</code>的作用是把输出值归一化到了
[0,1] 之间。</p>
<ul>
<li>weight：各类别的 loss 设置权值</li>
<li>ignore_index：忽略某个类别的 loss 计算</li>
<li><strong>reduction：计算模式</strong>，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<blockquote>
<p><strong>==下面介绍熵的一些基本概念==</strong></p>
<ul>
<li><strong>自信息</strong>：<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BI%7D%28x%29%3D-%5Clog+%5Bp%28x%29%5D" alt="[公式]"></li>
<li>信息熵就是求自信息的期望：<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BH%7D%28%5Cmathrm%7BP%7D%29%3DE_%7Bx+%5Csim+p%7D%5BI%28x%29%5D%3D-%5Csum_%7Bi%7D%5E%7BN%7D+P%5Cleft%28x_%7Bi%7D%5Cright%29+%5Clog+P%5Cleft%28x_%7Bi%7D%5Cright%29" alt="[公式]"></li>
<li><strong>相对熵</strong>，也被称为 KL
散度，用于衡量两个分布的相似性(距离)：<img src="https://www.zhihu.com/equation?tex=%5Cboldsymbol%7BD%7D_%7BK+L%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29%3D%5Cboldsymbol%7BE%7D_%7B%5Cboldsymbol%7Bx%7D+%5Csim+p%7D%5Cleft%5B%5Clog+%5Cfrac%7B%5Cboldsymbol%7BP%7D%28%5Cboldsymbol%7Bx%7D%29%7D%7BQ%28%5Cboldsymbol%7Bx%7D%29%7D%5Cright%5D" alt="[公式]">。其中 <img src="https://www.zhihu.com/equation?tex=P%28X%29" alt="[公式]">
是真实分布，<img src="https://www.zhihu.com/equation?tex=Q%28X%29" alt="[公式]"> 是拟合的分布</li>
<li><strong>交叉熵</strong>：<img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BH%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29%3D-%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%5Cboldsymbol%7BP%7D%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29+%5Clog+%5Cboldsymbol%7BQ%7D%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29" alt="[公式]"></li>
</ul>
<p>相对熵展开可得：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+%5Cboldsymbol%7BD%7D_%7BK+L%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29+%26%3D%5Cboldsymbol%7BE%7D_%7B%5Cboldsymbol%7Bx%7D+%5Csim+p%7D%5Cleft%5B%5Clog+%5Cfrac%7BP%28x%29%7D%7BQ%28%5Cboldsymbol%7Bx%7D%29%7D%5Cright%5D+%5C%5C+%26%3D%5Cboldsymbol%7BE%7D_%7B%5Cboldsymbol%7Bx%7D+%5Csim+p%7D%5B%5Clog+P%28%5Cboldsymbol%7Bx%7D%29-%5Clog+Q%28%5Cboldsymbol%7Bx%7D%29%5D+%5C%5C+%26%3D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+P%5Cleft%28x_%7Bi%7D%5Cright%29%5Cleft%5B%5Clog+P%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29-%5Clog+Q%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29%5Cright%5D+%5C%5C+%26%3D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+P%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29+%5Clog+P%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29-%5Csum_%7Bi%3D1%7D%5E%7BN%7D+P%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29+%5Clog+%5Cboldsymbol%7BQ%7D%5Cleft%28%5Cboldsymbol%7Bx%7D_%7Bi%7D%5Cright%29+%5C%5C+%26%3D+H%28P%2CQ%29+-H%28P%29+%5Cend%7Baligned%7D" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>所以<strong>交叉熵 = 信息熵 + 相对熵</strong>，即 <img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BH%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29%3D%5Cboldsymbol%7BD%7D_%7BK+%5Cboldsymbol%7BL%7D%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29%2B%5Cmathrm%7BH%7D%28%5Cboldsymbol%7BP%7D%29" alt="[公式]">，又由于信息熵 <img src="https://www.zhihu.com/equation?tex=H%28P%29" alt="[公式]">
是固定的，因此<strong>==优化交叉熵 <img src="https://www.zhihu.com/equation?tex=H%28P%2CQ%29" alt="[公式]">
等价于优化相对熵==</strong> <img src="https://www.zhihu.com/equation?tex=D_%7BKL%7D%28P%2CQ%29" alt="[公式]">。</p>
</blockquote>
<p>所以对于<strong>每一个样本</strong>的 Loss 计算公式为：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cmathrm%7BH%7D%28%5Cboldsymbol%7BP%7D%2C+%5Cboldsymbol%7BQ%7D%29%3D-%5Csum_%7Bi%3D1%7D%5E%7BN%7D+%5Cboldsymbol%7BP%7D%5Cleft%28%5Cboldsymbol%7Bx%7D_%7B%5Cboldsymbol%7Bi%7D%7D%5Cright%29+%5Clog+Q%5Cleft%28%5Cboldsymbol%7Bx%7D_%7B%5Cboldsymbol%7Bi%7D%7D%5Cright%29+%3D+logQ%28x_%7Bi%7D%29" alt="[公式]">，因为 <img src="https://www.zhihu.com/equation?tex=N%3D1" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=P%28x_%7Bi%7D%29%3D1" alt="[公式]">。</p>
<p>所以 <img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+%5Ctext+%7B+class+%7D%29%3D-%5Clog+%5Cleft%28%5Cfrac%7B%5Cexp+%28x%5B%5Ctext+%7B+class+%7D%5D%29%7D%7B%5Csum_%7Bj%7D+%5Cexp+%28x%5Bj%5D%29%7D%5Cright%29%3D-x%5B%5Ctext+%7B+class+%7D%5D%2B%5Clog+%5Cleft%28%5Csum_%7Bj%7D+%5Cexp+%28x%5Bj%5D%29%5Cright%29" alt="[公式]">。</p>
<p>如果了类别的权重，则 <img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+%5Ctext+%7B+class+%7D%29%3D%5Coperatorname%7Bweight%7D%5B%5Ctext+%7B+class+%7D%5D%5Cleft%28-x%5B%5Ctext+%7B+class+%7D%5D%2B%5Clog+%5Cleft%28%5Csum_%7Bj%7D+%5Cexp+%28x%5Bj%5D%29%5Cright%29%5Cright%29" alt="[公式]">。</p>
<p>下面设有 3 个样本做 2 分类。inputs 的形状为 <img src="https://www.zhihu.com/equation?tex=3+%5Ctimes+2" alt="[公式]">，表示每个样本有两个神经元输出两个分类。target 的形状为
<img src="https://www.zhihu.com/equation?tex=3+%5Ctimes+1" alt="[公式]">，注意类别从 0 开始，类型为<code>torch.long</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># fake data</span></span><br><span class="line">inputs = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">3</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">target = torch.tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>], dtype=torch.long)</span><br><span class="line"></span><br><span class="line"><span class="comment"># def loss function</span></span><br><span class="line">loss_f_none = nn.CrossEntropyLoss(weight=<span class="literal">None</span>, reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">loss_f_sum = nn.CrossEntropyLoss(weight=<span class="literal">None</span>, reduction=<span class="string">&#x27;sum&#x27;</span>)</span><br><span class="line">loss_f_mean = nn.CrossEntropyLoss(weight=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># forward</span></span><br><span class="line">loss_none = loss_f_none(inputs, target)</span><br><span class="line">loss_sum = loss_f_sum(inputs, target)</span><br><span class="line">loss_mean = loss_f_mean(inputs, target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># view</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Cross Entropy Loss:&quot;</span>, loss_none, loss_sum, loss_mean)</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cross Entropy Loss: tensor([<span class="number">1.3133</span>, <span class="number">0.1269</span>, <span class="number">0.1269</span>]) tensor(<span class="number">1.5671</span>) tensor(<span class="number">0.5224</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="12-nnnllloss">1.2 <strong>nn.NLLLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.NLLLoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, ignore_index=-<span class="number">100</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：实现<strong>负对数似然函数</strong>中的符号功能</p>
<p>主要参数：</p>
<ul>
<li><strong>weight</strong>：各类别的 loss 权值设置</li>
<li><strong>ignore_index</strong>：忽略某个类别</li>
<li><strong>reduction：计算模式</strong>，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p><strong>每个样本的 loss 公式为：</strong><img src="https://www.zhihu.com/equation?tex=l_%7Bn%7D%3D-w_%7By_%7Bn%7D%7D+x_%7Bn%2C+y_%7Bn%7D%7D" alt="[公式]">。还是使用上面的例子，第一个样本的输出为 [1,2]，类别为
0，则第一个样本的 loss 为 -1；第一个样本的输出为 [1,3]，类别为
1，则第一个样本的 loss 为 -3。</p>
<h4><span id="13-nnbceloss"><strong>1.3 nn.BCELoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.BCELoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>计算二分类的交叉熵</strong>。需要注意的是：输出值区间为
[0,1]。</p>
<p>主要参数：</p>
<ul>
<li>weight：各类别的 loss 权值设置</li>
<li>ignore_index：忽略某个类别</li>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p><strong>计算公式</strong>为：<img src="https://www.zhihu.com/equation?tex=l_%7Bn%7D%3D-w_%7Bn%7D%5Cleft%5By_%7Bn%7D+%5Ccdot+%5Clog+x_%7Bn%7D%2B%5Cleft%281-y_%7Bn%7D%5Cright%29+%5Ccdot+%5Clog+%5Cleft%281-x_%7Bn%7D%5Cright%29%5Cright%5D" alt="[公式]"></p>
<p>使用这个函数有两个不同的地方：</p>
<ul>
<li><strong>预测的标签需要经过 sigmoid 变换到 [0,1] 之间</strong>。</li>
<li><strong>真实的标签需要转换为 one hot
向量，类型为<code>torch.float</code>。</strong></li>
</ul>
<h4><span id="14nnbcewithlogitsloss">1.4
<strong>nn.BCEWithLogitsLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.BCEWithLogitsLoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>, pos_weight=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>结合 sigmoid
与二分类交叉熵</strong>。需要注意的是，网络最后的输出不用经过 sigmoid
函数。这个 loss 出现的原因是有时网络模型最后一层输出不希望是归一化到
[0,1] 之间，但是在计算 loss 时又需要归一化到 [0,1] 之间。</p>
<p>主要参数：</p>
<ul>
<li><strong>weight</strong>：<strong>各输出类别的 loss
权值设置</strong></li>
<li><strong>pos_weight</strong>：<strong>==设置输入样本类别对应的神经元的输出的
loss 权值==</strong></li>
<li>ignore_index：忽略某个类别</li>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<h4><span id="15-nnl1loss">1.5 <strong>nn.L1Loss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.L1Loss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>计算 inputs 与 target 之差的绝对值</strong></p>
<p>主要参数：</p>
<ul>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p>公式：<img src="https://www.zhihu.com/equation?tex=l_%7Bn%7D%3D%5Cleft%7Cx_%7Bn%7D-y_%7Bn%7D%5Cright%7C" alt="[公式]"></p>
<h4><span id="16-nnmseloss">1.6 <strong>nn.MSELoss</strong></span></h4>
<p>功能：计算 inputs 与 target 之差的平方</p>
<p>公式：<img src="https://www.zhihu.com/equation?tex=l_%7Bn%7D%3D%5Cleft%28x_%7Bn%7D-y_%7Bn%7D%5Cright%29%5E%7B2%7D" alt="[公式]"></p>
<p>主要参数：</p>
<ul>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<h4><span id="17-nnsmoothl1loss"><strong>1.7 nn.SmoothL1Loss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.SmoothL1Loss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：平滑的 L1Loss</p>
<p>公式：<img src="https://www.zhihu.com/equation?tex=z_%7Bi%7D%3D%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bll%7D0.5%5Cleft%28x_%7Bi%7D-y_%7Bi%7D%5Cright%29%5E%7B2%7D%2C+%26+%5Ctext+%7B+if+%7D%5Cleft%7Cx_%7Bi%7D-y_%7Bi%7D%5Cright%7C%3C1+%5C%5C+%5Cleft%7Cx_%7Bi%7D-y_%7Bi%7D%5Cright%7C-0.5%2C+%26+%5Ctext+%7B+otherwise+%7D%5Cend%7Barray%7D%5Cright." alt="[公式]"></p>
<p>下图中橙色曲线是 L1Loss，蓝色曲线是 Smooth L1Loss</p>
<p><img src="https://pic3.zhimg.com/80/v2-59bedd97c18dff6fe2bf9fd96494cac2_1440w.jpg" alt="img" style="zoom: 50%;"></p>
<p>主要参数：</p>
<ul>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<h4><span id="18-nnpoissonnllloss">1.8 <strong>nn.PoissonNLLLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.PoissonNLLLoss(log_input=<span class="literal">True</span>, full=<span class="literal">False</span>, size_average=<span class="literal">None</span>, eps=<span class="number">1e-08</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>泊松分布的负对数似然损失函数</strong></p>
<p>主要参数：</p>
<ul>
<li><p>log_input：输入是否为对数形式，决定计算公式</p></li>
<li><ul>
<li>当 log_input =
True，表示输入数据已经是经过对数运算之后的，loss(input, target) =
exp(input) - target * input</li>
<li>当 log_input = False，，表示输入数据还没有取对数，loss(input,
target) = input - target * log(input+eps)</li>
</ul></li>
<li><p>full：计算所有 loss，默认为 loss</p></li>
<li><p>eps：修正项，避免 log(input) 为 nan</p></li>
</ul>
<h4><span id="19-nnkldivloss">1.9 <strong>nn.KLDivLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.KLDivLoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>计算 KLD(divergence)，KL 散度，相对熵</strong></p>
<p>注意事项：需要提前将输入计算
log-probabilities，如通过<code>nn.logsoftmax()</code></p>
<p>主要参数：</p>
<ul>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)，batchmean(batchsize
维度求平均值)</li>
</ul>
<p>公式：<img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Baligned%7D+D_%7BK+L%7D%28P+%5C%7C+Q%29%3DE_%7Bx-p%7D%5Cleft%5B%5Clog+%5Cfrac%7BP%28x%29%7D%7BQ%28x%29%7D%5Cright%5D+%26%3DE_%7Bx-p%7D%5B%5Clog+P%28x%29-%5Clog+Q%28x%29%5D+%3D%5Csum_%7Bi%3D1%7D%5E%7BN%7D+P%5Cleft%28x_%7Bi%7D%5Cright%29%5Cleft%28%5Clog+P%5Cleft%28x_%7Bi%7D%5Cright%29-%5Clog+Q%5Cleft%28x_%7Bi%7D%5Cright%29%5Cright%29+%5Cend%7Baligned%7D" alt="[公式]"></p>
<p>对于每个样本来说，计算公式如下，其中 <img src="https://www.zhihu.com/equation?tex=y_%7Bn%7D" alt="[公式]">
是真实值 <img src="https://www.zhihu.com/equation?tex=P%28x%29" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=x_%7Bn%7D" alt="[公式]"> 是经过对数运算之后的预测值 <img src="https://www.zhihu.com/equation?tex=logQ%28x%29" alt="[公式]">。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=l_%7Bn%7D%3Dy_%7Bn%7D+%5Ccdot%5Cleft%28%5Clog+y_%7Bn%7D-x_%7Bn%7D%5Cright%29" alt="[公式]">
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h4><span id="110nnmarginrankingloss">1.10
<strong>nn.MarginRankingLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.MarginRankingLoss(margin=<span class="number">0.0</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>计算两个向量之间的相似度，用于排序任务</strong></p>
<p>特别说明：<strong>该方法计算 两组数据之间的差异，返回一个 <img src="https://www.zhihu.com/equation?tex=n+%5Ctimes+n" alt="[公式]"> 的
loss 矩阵</strong></p>
<p>主要参数：</p>
<ul>
<li>margin：边界值，<img src="https://www.zhihu.com/equation?tex=x_%7B1%7D" alt="[公式]"> 与
<img src="https://www.zhihu.com/equation?tex=x_%7B2%7D" alt="[公式]">
之间的差异值</li>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p>计算公式：<img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+y%29%3D%5Cmax+%280%2C-y+%2A%28x+1-x+2%29%2B%5Coperatorname%7Bmargin%7D%29" alt="[公式]">，<img src="https://www.zhihu.com/equation?tex=y" alt="[公式]"> 的取值有 +1 和 -1。</p>
<ul>
<li>当 <img src="https://www.zhihu.com/equation?tex=y%3D1" alt="[公式]"> 时，希望 <img src="https://www.zhihu.com/equation?tex=x_%7B1%7D+%3E+x_%7B2%7D" alt="[公式]">，当 <img src="https://www.zhihu.com/equation?tex=x_%7B1%7D+%3E+x_%7B2%7D" alt="[公式]">，不产生 loss</li>
<li>当 <img src="https://www.zhihu.com/equation?tex=y%3D-1" alt="[公式]"> 时，希望 <img src="https://www.zhihu.com/equation?tex=x_%7B1%7D+%3C+x_%7B2%7D" alt="[公式]">，当 <img src="https://www.zhihu.com/equation?tex=x_%7B1%7D+%3C+x_%7B2%7D" alt="[公式]">，不产生 loss</li>
</ul>
<h4><span id="111-nnsoftmarginloss">1.11 <strong>nn.SoftMarginLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.SoftMarginLoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：<strong>计算二分类的 logistic 损失</strong></p>
<p>主要参数：</p>
<ul>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p>计算公式：<img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+y%29%3D%5Csum_%7Bi%7D+%5Cfrac%7B%5Clog+%281%2B%5Cexp+%28-y%5Bi%5D+%2A+x%5Bi%5D%29%29%7D%7B%5Ctext+%7B+x.nelement+%7D+0%7D" alt="[公式]"></p>
<h4><span id="112nnmultimarginloss">1.12
<strong>nn.MultiMarginLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.MultiMarginLoss(p=<span class="number">1</span>, margin=<span class="number">1.0</span>, weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>功能：计算多分类的折页损失</p>
<p>主要参数：</p>
<ul>
<li>p：可以选择 1 或 2</li>
<li>weight：各类别的 loss 权值设置</li>
<li>margin：边界值</li>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p>计算公式：<img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+y%29%3D%5Cfrac%7B%5Cleft.%5Csum_%7Bi%7D+%5Cmax+%280%2C+%5Coperatorname%7Bmargin%7D-x%5By%5D%2Bx%5Bi%5D%29%5Cright%29%5E%7Bp%7D%7D%7B%5Cquad+%5Ctext+%7B+x.size+%7D%280%29%7D" alt="[公式]">，其中 y 表示真实标签对应的神经元输出，x
表示其他神经元的输出。</p>
<h4><span id="113nncosineembeddingloss">1.13
<strong>nn.CosineEmbeddingLoss</strong></span></h4>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CosineEmbeddingLoss(margin=0.0, size_average=None, reduce=None, reduction=&#x27;mean&#x27;)</span><br></pre></td></tr></table></figure>
<p>功能：采用余弦相似度计算两个输入的相似性</p>
<p>主要参数：</p>
<ul>
<li>margin：边界值，可取值 [-1, 1]，推荐为 [0, 0.5]</li>
<li>reduction：计算模式，，可以为
none(逐个元素计算)，sum(所有元素求和，返回标量)，mean(加权平均，返回标量)</li>
</ul>
<p>计算公式：<img src="https://www.zhihu.com/equation?tex=%5Coperatorname%7Bloss%7D%28x%2C+y%29%3D%5Cleft%5C%7B%5Cbegin%7Barray%7D%7Bll%7D1-%5Ccos+%5Cleft%28x_%7B1%7D%2C+x_%7B2%7D%5Cright%29%2C+%26+%5Ctext+%7B+if+%7D+y%3D1+%5C%5C+%5Cmax+%5Cleft%280%2C+%5Ccos+%5Cleft%28x_%7B1%7D%2C+x_%7B2%7D%5Cright%29-%5Coperatorname%7Bmargin%7D%5Cright%29%2C+%26+%5Ctext+%7B+if+%7D+y%3D-1%5Cend%7Barray%7D%5Cright." alt="[公式]"></p>
<p>其中 <img src="https://www.zhihu.com/equation?tex=%5Ccos+%28%5Ctheta%29%3D%5Cfrac%7BA+%5Ccdot+B%7D%7B%5C%7CA%5C%7C%5C%7CB%5C%7C%7D%3D%5Cfrac%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+A_%7Bi%7D+%5Ctimes+B_%7Bi%7D%7D%7B%5Csqrt%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cleft%28A_%7Bi%7D%5Cright%29%5E%7B2%7D%7D+%5Ctimes+%5Csqrt%7B%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cleft%28B_%7Bi%7D%5Cright%29%5E%7B2%7D%7D%7D" alt="[公式]"></p>
<h2><span id="二-损失函数qampa">二、损失函数Q&amp;A</span></h2>
<h4><span id="21nncrossentropyloss-softmaxxlogxnnnllloss">2.1
nn.CrossEntropyLoss = softmax(x)+log(x)+nn.NLLLoss?</span></h4>
<p>在各种深度学习框架中，我们最常用的损失函数就是交叉熵（torch.nn.CrossEntropyLoss），<strong>熵是用来描述一个系统的混乱程度,通过交叉熵我们就能够确定预测数据与真是数据之间的相近程度</strong>。交叉熵越小，表示数据越接近真实样本。</p>
<p><strong>交叉熵计算公式：</strong></p>
<p><img src="https://img-blog.csdnimg.cn/20191024155805924.png" alt="img" style="zoom:50%;"></p>
<p><strong>softmax函数</strong>又称为归一化指数函数，它可以把一个多维向量压缩在（0，1）之间，并且它们的和为1.</p>
<p><strong>计算公式：</strong></p>
<p><img src="https://img-blog.csdnimg.cn/20191024162238579.png" alt="1" style="zoom:50%;"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line">z = [<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]</span><br><span class="line">z_exp = [math.exp(i) <span class="keyword">for</span> i <span class="keyword">in</span> z]  </span><br><span class="line"><span class="built_in">print</span>(z_exp)  <span class="comment"># Result: [2.72, 7.39, 20.09, 54.6, 2.72, 7.39, 20.09] </span></span><br><span class="line">sum_z_exp = <span class="built_in">sum</span>(z_exp)  </span><br><span class="line"><span class="built_in">print</span>(sum_z_exp)  <span class="comment"># Result: 114.98 </span></span><br><span class="line">softmax = [<span class="built_in">round</span>(i / sum_z_exp, <span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> z_exp]</span><br><span class="line"><span class="built_in">print</span>(softmax)  <span class="comment"># Result: [0.024, 0.064, 0.175, 0.475, 0.024, 0.064, 0.175]</span></span><br></pre></td></tr></table></figure>
<p><strong>log_softmax</strong>是指在softmax函数的基础上，再进行一次log运算，此时结果有正有负，<strong>log函数的值域是负无穷到正无穷，当x在0—1之间的时候，log(x)值在负无穷到0之间</strong>。</p>
<p><strong>nn.NLLLoss</strong>的结果就是把上面的<strong>输出与Label对应的那个值拿出来，再去掉负号，再求均值</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">input</span>=torch.randn(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">soft_input = torch.nn.Softmax(dim=<span class="number">0</span>)</span><br><span class="line">soft_input(<span class="built_in">input</span>)</span><br><span class="line">Out[<span class="number">20</span>]: </span><br><span class="line">tensor([[<span class="number">0.7284</span>, <span class="number">0.7364</span>, <span class="number">0.3343</span>],</span><br><span class="line">        [<span class="number">0.1565</span>, <span class="number">0.0365</span>, <span class="number">0.0408</span>],</span><br><span class="line">        [<span class="number">0.1150</span>, <span class="number">0.2270</span>, <span class="number">0.6250</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment">#对softmax结果取log</span></span><br><span class="line">torch.log(soft_input(<span class="built_in">input</span>))</span><br><span class="line">Out[<span class="number">21</span>]: </span><br><span class="line">tensor([[-<span class="number">0.3168</span>, -<span class="number">0.3059</span>, -<span class="number">1.0958</span>],</span><br><span class="line">        [-<span class="number">1.8546</span>, -<span class="number">3.3093</span>, -<span class="number">3.1995</span>],</span><br><span class="line">        [-<span class="number">2.1625</span>, -<span class="number">1.4827</span>, -<span class="number">0.4701</span>]])</span><br></pre></td></tr></table></figure>
<p>假设标签是[0,1,2]，第一行取第0个元素，第二行取第1个，第三行取第2个，去掉负号，即[0.3168,3.3093,0.4701],求平均值，就可以得到损失值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">0.3168</span>+<span class="number">3.3093</span>+<span class="number">0.4701</span>)/<span class="number">3</span></span><br><span class="line">Out[<span class="number">22</span>]: <span class="number">1.3654000000000002</span></span><br><span class="line"><span class="comment">#验证一下</span></span><br><span class="line">loss=torch.nn.NLLLoss()</span><br><span class="line">target=torch.tensor([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">loss(<span class="built_in">input</span>,target)</span><br><span class="line">Out[<span class="number">26</span>]: tensor(<span class="number">0.1365</span>)</span><br></pre></td></tr></table></figure>
<h4><span id="nncrossentropyloss"><strong>nn.CrossEntropyLoss</strong></span></h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">loss=torch.nn.NLLLoss()</span><br><span class="line">target=torch.tensor([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">loss(<span class="built_in">input</span>,target)</span><br><span class="line">Out[<span class="number">26</span>]: tensor(-<span class="number">0.1399</span>)</span><br><span class="line">loss =torch.nn.CrossEntropyLoss()</span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[ <span class="number">1.1879</span>,  <span class="number">1.0780</span>,  <span class="number">0.5312</span>],</span><br><span class="line">        [-<span class="number">0.3499</span>, -<span class="number">1.9253</span>, -<span class="number">1.5725</span>],</span><br><span class="line">        [-<span class="number">0.6578</span>, -<span class="number">0.0987</span>,  <span class="number">1.1570</span>]])</span><br><span class="line">target = torch.tensor([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">loss(<span class="built_in">input</span>,target)</span><br><span class="line">Out[<span class="number">30</span>]: tensor(<span class="number">0.1365</span>)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/14/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><span class="page-number current">15</span><a class="page-number" href="/page/16/">16</a><span class="space">&hellip;</span><a class="page-number" href="/page/26/">26</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/16/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">lzy</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>-->
<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("03/01/2023 10:00:00"); //此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒.";
    }
setInterval("createtime()",250);
</script>

    </div>
  </footer>

  

  <a href="https://github.com/PowerLZY" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.4.3/mermaid.min.js","integrity":"sha256-e0o3JYsdjqKajf9eOe22FhioYSz9WofRY4dLKo3F6do="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>




        <script src="//cdn.jsdelivr.net/npm/js-base64/base64.min.js"></script>
        <script>
        const hasAttr = (e,a) => a.some(_=> e.attr(_)!==undefined);
        $('a').each(function() {
          const $this = $(this);
          if(hasAttr($this,["data-fancybox","ignore-external-link"])) return;
          const href = $this.attr('href');
          if (href && href.match('^((http|https|thunder|qqdl|ed2k|Flashget|qbrowser|ftp|rtsp|mms)://)')) {
            const strs = href.split('/');
            if (strs.length >= 3) {
                const host = strs[2];
                if (host !== 'powerlzy.github.io' || window.location.host) {
                    $this.attr('href', '/go.html?u='+Base64.encode(href)+'').attr('rel', 'external nofollow noopener noreferrer');
                    if (true) {
                        $this.attr('target', '_blank');
                    }
                }
            }
          }
        });
        </script></body>
</html>
